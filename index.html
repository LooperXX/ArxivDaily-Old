 
<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="ArxivDaily" href="feed.atom" />
    <link href="index.css" rel="stylesheet" />
    <!-- %before-head-end.html% -->
</head>

<body>
    <!-- %after-body-begin.html% -->
    <a href="https://github.com/LooperXX/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">LooperXX/ArxivDaily</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-12">2021-07-12</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text-to-Text Pre-Training for Data-to-Text Tasks. (arXiv:2005.10433v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1">Mihir Kale</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1">Abhinav Rastogi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.10433">
                                    <div class="article-summary-box-inner">
                                        <span>We study the pre-train + fine-tune strategy for data-to-text tasks. Our
experiments indicate that text-to-text pre-training in the form of T5, enables
simple, end-to-end transformer based models to outperform pipelined neural
architectures tailored for data-to-text generation, as well as alternative
language model based pre-training techniques such as BERT and GPT-2.
Importantly, T5 pre-training leads to better generalization, as evidenced by
large improvements on out-of-domain test sets. We hope our work serves as a
useful baseline for future research, as transfer learning becomes ever more
prevalent for data-to-text tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Robust Deep Ensemble Classifier for Figurative Language Detection. (arXiv:2107.04372v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Potamias_R/0/1/0/all/0/1">Rolandos Alexandros Potamias</a>, <a href="http://arxiv.org/find/cs/1/au:+Siolas_G/0/1/0/all/0/1">Georgios Siolas</a>, <a href="http://arxiv.org/find/cs/1/au:+Stafylopatis_A/0/1/0/all/0/1">Andreas - Georgios Stafylopatis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04372">
                                    <div class="article-summary-box-inner">
                                        <span>Recognition and classification of Figurative Language (FL) is an open problem
of Sentiment Analysis in the broader field of Natural Language Processing (NLP)
due to the contradictory meaning contained in phrases with metaphorical
content. The problem itself contains three interrelated FL recognition tasks:
sarcasm, irony and metaphor which, in the present paper, are dealt with
advanced Deep Learning (DL) techniques. First, we introduce a data
prepossessing framework towards efficient data representation formats so that
to optimize the respective inputs to the DL models. In addition, special
features are extracted in order to characterize the syntactic, expressive,
emotional and temper content reflected in the respective social media text
references. These features aim to capture aspects of the social network user&#x27;s
writing method. Finally, features are fed to a robust, Deep Ensemble Soft
Classifier (DESC) which is based on the combination of different DL techniques.
Using three different benchmark datasets (one of them containing various FL
forms) we conclude that the DESC model achieves a very good performance, worthy
of comparison with relevant methodologies and state-of-the-art technologies in
the challenging field of FL recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Summary-Oriented Question Generation for Informational Queries. (arXiv:2010.09692v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xusen Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Li Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Small_K/0/1/0/all/0/1">Kevin Small</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09692">
                                    <div class="article-summary-box-inner">
                                        <span>Users frequently ask simple factoid questions for question answering (QA)
systems, attenuating the impact of myriad recent works that support more
complex questions. Prompting users with automatically generated suggested
questions (SQs) can improve user understanding of QA system capabilities and
thus facilitate more effective use. We aim to produce self-explanatory
questions that focus on main document topics and are answerable with variable
length passages as appropriate. We satisfy these requirements by using a
BERT-based Pointer-Generator Network trained on the Natural Questions (NQ)
dataset. Our model shows SOTA performance of SQ generation on the NQ dataset
(20.1 BLEU-4). We further apply our model on out-of-domain news articles,
evaluating with a QA system due to the lack of gold questions and demonstrate
that our model produces better SQs for news articles -- with further
confirmation via a human evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The USTC-NELSLIP Systems for Simultaneous Speech Translation Task at IWSLT 2021. (arXiv:2107.00279v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1">Mengge Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoxi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yuchen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_L/0/1/0/all/0/1">Lirong Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00279">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes USTC-NELSLIP&#x27;s submissions to the IWSLT2021 Simultaneous
Speech Translation task. We proposed a novel simultaneous translation model,
Cross Attention Augmented Transducer (CAAT), which extends conventional RNN-T
to sequence-to-sequence tasks without monotonic constraints, e.g., simultaneous
translation. Experiments on speech-to-text (S2T) and text-to-text (T2T)
simultaneous translation tasks shows CAAT achieves better quality-latency
trade-offs compared to \textit{wait-k}, one of the previous state-of-the-art
approaches. Based on CAAT architecture and data augmentation, we build S2T and
T2T simultaneous translation systems in this evaluation campaign. Compared to
last year&#x27;s optimal systems, our S2T simultaneous translation system improves
by an average of 11.3 BLEU for all latency regimes, and our T2T simultaneous
translation system improves by an average of 4.6 BLEU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TAN-NTM: Topic Attention Networks for Neural Topic Modeling. (arXiv:2012.01524v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Panwar_M/0/1/0/all/0/1">Madhur Panwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shailabh_S/0/1/0/all/0/1">Shashank Shailabh</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_M/0/1/0/all/0/1">Milan Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1">Balaji Krishnamurthy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01524">
                                    <div class="article-summary-box-inner">
                                        <span>Topic models have been widely used to learn text representations and gain
insight into document corpora. To perform topic discovery, most existing neural
models either take document bag-of-words (BoW) or sequence of tokens as input
followed by variational inference and BoW reconstruction to learn topic-word
distribution. However, leveraging topic-word distribution for learning better
features during document encoding has not been explored much. To this end, we
develop a framework TAN-NTM, which processes document as a sequence of tokens
through a LSTM whose contextual outputs are attended in a topic-aware manner.
We propose a novel attention mechanism which factors in topic-word distribution
to enable the model to attend on relevant words that convey topic related cues.
The output of topic attention module is then used to carry out variational
inference. We perform extensive ablations and experiments resulting in ~9-15
percentage improvement over score of existing SOTA topic models in NPMI
coherence on several benchmark datasets - 20Newsgroups, Yelp Review Polarity
and AGNews. Further, we show that our method learns better latent
document-topic features compared to existing topic models through improvement
on two downstream tasks: document classification and topic guided keyphrase
generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilingual Byte2Speech Models for Scalable Low-resource Speech Synthesis. (arXiv:2103.03541v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1">Mutian He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jingzhou Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Soong_F/0/1/0/all/0/1">Frank K. Soong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03541">
                                    <div class="article-summary-box-inner">
                                        <span>To scale neural speech synthesis to various real-world languages, we present
a multilingual end-to-end framework that maps byte inputs to spectrograms, thus
allowing arbitrary input scripts. Besides strong results on 40+ languages, the
framework demonstrates capabilities to adapt to new languages under extreme
low-resource and even few-shot scenarios of merely 40s transcribed recording,
without the need of per-language resources like lexicon, extra corpus,
auxiliary models, or linguistic expertise, thus ensuring scalability. While it
retains satisfactory intelligibility and naturalness matching rich-resource
models. Exhaustive comparative and ablation studies are performed to reveal the
potential of the framework for low-resource languages. Furthermore, we propose
a novel method to extract language-specific sub-networks in a multilingual
model for a better understanding of its mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-interpretable Convolutional Neural Networks for Text Classification. (arXiv:2105.08589v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1">Rahul Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_T/0/1/0/all/0/1">Tarun Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudjianto_A/0/1/0/all/0/1">Agus Sudjianto</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1">Vijayan N. Nair</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08589">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models for natural language processing (NLP) are inherently
complex and often viewed as black box in nature. This paper develops an
approach for interpreting convolutional neural networks for text classification
problems by exploiting the local-linear models inherent in ReLU-DNNs. The CNN
model combines the word embedding through convolutional layers, filters them
using max-pooling, and optimizes using a ReLU-DNN for classification. To get an
overall self-interpretable model, the system of local linear models from the
ReLU DNN are mapped back through the max-pool filter to the appropriate
n-grams. Our results on experimental datasets demonstrate that our proposed
technique produce parsimonious models that are self-interpretable and have
comparable performance with respect to a more complex CNN model. We also study
the impact of the complexity of the convolutional layers and the classification
layers on the model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlling Hallucinations at Word Level in Data-to-Text Generation. (arXiv:2102.02810v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rebuffel_C/0/1/0/all/0/1">Cl&#xe9;ment Rebuffel</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberti_M/0/1/0/all/0/1">Marco Roberti</a>, <a href="http://arxiv.org/find/cs/1/au:+Soulier_L/0/1/0/all/0/1">Laure Soulier</a>, <a href="http://arxiv.org/find/cs/1/au:+Scoutheeten_G/0/1/0/all/0/1">Geoffrey Scoutheeten</a>, <a href="http://arxiv.org/find/cs/1/au:+Cancelliere_R/0/1/0/all/0/1">Rossella Cancelliere</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02810">
                                    <div class="article-summary-box-inner">
                                        <span>Data-to-Text Generation (DTG) is a subfield of Natural Language Generation
aiming at transcribing structured data in natural language descriptions. The
field has been recently boosted by the use of neural-based generators which
exhibit on one side great syntactic skills without the need of hand-crafted
pipelines; on the other side, the quality of the generated text reflects the
quality of the training data, which in realistic settings only offer
imperfectly aligned structure-text pairs. Consequently, state-of-art neural
models include misleading statements - usually called hallucinations - in their
outputs. The control of this phenomenon is today a major challenge for DTG, and
is the problem addressed in the paper.

Previous work deal with this issue at the instance level: using an alignment
score for each table-reference pair. In contrast, we propose a finer-grained
approach, arguing that hallucinations should rather be treated at the word
level. Specifically, we propose a Multi-Branch Decoder which is able to
leverage word-level labels to learn the relevant parts of each training
instance. These labels are obtained following a simple and efficient scoring
procedure based on co-occurrence analysis and dependency parsing. Extensive
evaluations, via automated metrics and human judgment on the standard WikiBio
benchmark, show the accuracy of our alignment labels and the effectiveness of
the proposed Multi-Branch Decoder. Our model is able to reduce and control
hallucinations, while keeping fluency and coherence in generated texts. Further
experiments on a degraded version of ToTTo show that our model could be
successfully used on very noisy settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SHAP values for Explaining CNN-based Text Classification Models. (arXiv:2008.11825v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_T/0/1/0/all/0/1">Tarun Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1">Vijayan N. Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudjianto_A/0/1/0/all/0/1">Agus Sudjianto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11825">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are increasingly used in natural language processing
(NLP) models. However, the need to interpret and explain the results from
complex algorithms are limiting their widespread adoption in regulated
industries such as banking. There has been recent work on interpretability of
machine learning algorithms with structured data. But there are only limited
techniques for NLP applications where the problem is more challenging due to
the size of the vocabulary, high-dimensional nature, and the need to consider
textual coherence and language structure. This paper develops a methodology to
compute SHAP values for local explainability of CNN-based text classification
models. The approach is also extended to compute global scores to assess the
importance of features. The results are illustrated on sentiment analysis of
Amazon Electronic Review data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Deep Neural Networks Predict Data Correlations from Column Names?. (arXiv:2107.04553v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trummer_I/0/1/0/all/0/1">Immanuel Trummer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04553">
                                    <div class="article-summary-box-inner">
                                        <span>For humans, it is often possible to predict data correlations from column
names. We conduct experiments to find out whether deep neural networks can
learn to do the same. If so, e.g., it would open up the possibility of tuning
tools that use NLP analysis on schema elements to prioritize their efforts for
correlation detection.

We analyze correlations for around 120,000 column pairs, taken from around
4,000 data sets. We try to predict correlations, based on column names alone.
For predictions, we exploit pre-trained language models, based on the recently
proposed Transformer architecture. We consider different types of correlations,
multiple prediction methods, and various prediction scenarios. We study the
impact of factors such as column name length or the amount of training data on
prediction accuracy. Altogether, we find that deep neural networks can predict
correlations with a relatively high accuracy in many scenarios (e.g., with an
accuracy of 95% for long column names).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchmarking for Biomedical Natural Language Processing Tasks with a Domain Specific ALBERT. (arXiv:2107.04374v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naseem_U/0/1/0/all/0/1">Usman Naseem</a>, <a href="http://arxiv.org/find/cs/1/au:+Dunn_A/0/1/0/all/0/1">Adam G. Dunn</a>, <a href="http://arxiv.org/find/cs/1/au:+Khushi_M/0/1/0/all/0/1">Matloob Khushi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jinman Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04374">
                                    <div class="article-summary-box-inner">
                                        <span>The availability of biomedical text data and advances in natural language
processing (NLP) have made new applications in biomedical NLP possible.
Language models trained or fine tuned using domain specific corpora can
outperform general models, but work to date in biomedical NLP has been limited
in terms of corpora and tasks. We present BioALBERT, a domain-specific
adaptation of A Lite Bidirectional Encoder Representations from Transformers
(ALBERT), trained on biomedical (PubMed and PubMed Central) and clinical
(MIMIC-III) corpora and fine tuned for 6 different tasks across 20 benchmark
datasets. Experiments show that BioALBERT outperforms the state of the art on
named entity recognition (+11.09% BLURB score improvement), relation extraction
(+0.80% BLURB score), sentence similarity (+1.05% BLURB score), document
classification (+0.62% F1-score), and question answering (+2.83% BLURB score).
It represents a new state of the art in 17 out of 20 benchmark datasets. By
making BioALBERT models and data available, our aim is to help the biomedical
NLP community avoid computational costs of training and establish a new set of
baselines for future efforts across a broad range of biomedical NLP tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systematic Survey of Text Worlds as Embodied Natural Language Environments. (arXiv:2107.04132v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jansen_P/0/1/0/all/0/1">Peter A Jansen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04132">
                                    <div class="article-summary-box-inner">
                                        <span>Text Worlds are virtual environments for embodied agents that, unlike 2D or
3D environments, are rendered exclusively using textual descriptions. These
environments offer an alternative to higher-fidelity 3D environments due to
their low barrier to entry, providing the ability to study semantics,
compositional inference, and other high-level tasks with rich high-level action
spaces while controlling for perceptual input. This systematic survey outlines
recent developments in tooling, environments, and agent modeling for Text
Worlds, while examining recent trends in knowledge graphs, common sense
reasoning, transfer learning of Text World performance to higher-fidelity
environments, as well as near-term development targets that, once achieved,
make Text Worlds an attractive general research paradigm for natural language
processing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Low-Resource Neural Machine Translation. (arXiv:2107.04239v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1">Renqian Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04239">
                                    <div class="article-summary-box-inner">
                                        <span>Neural approaches have achieved state-of-the-art accuracy on machine
translation but suffer from the high cost of collecting large scale parallel
data. Thus, a lot of research has been conducted for neural machine translation
(NMT) with very limited parallel data, i.e., the low-resource setting. In this
paper, we provide a survey for low-resource NMT and classify related works into
three categories according to the auxiliary data they used: (1) exploiting
monolingual data of source and/or target languages, (2) exploiting data from
auxiliary languages, and (3) exploiting multi-modal data. We hope that our
survey can help researchers to better understand this field and inspire them to
design better algorithms, and help industry practitioners to choose appropriate
algorithms for their applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Syntactic Dense Embedding with Correlation Graph for Automatic Readability Assessment. (arXiv:2107.04268v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xinying Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hanwu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1">Jian-Yun Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuming Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1">Dawei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04268">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models for automatic readability assessment generally discard
linguistic features traditionally used in machine learning models for the task.
We propose to incorporate linguistic features into neural network models by
learning syntactic dense embeddings based on linguistic features. To cope with
the relationships between the features, we form a correlation graph among
features and use it to learn their embeddings so that similar features will be
represented by similar embeddings. Experiments with six data sets of two
proficiency levels demonstrate that our proposed methodology can complement
BERT-only model to achieve significantly better performances for automatic
readability assessment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Language Identification Through Cross-Lingual Self-Supervised Learning. (arXiv:2107.04082v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tjandra_A/0/1/0/all/0/1">Andros Tjandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhury_D/0/1/0/all/0/1">Diptanu Gon Choudhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Frank Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kritika Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1">Alexei Baevski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sela_A/0/1/0/all/0/1">Assaf Sela</a>, <a href="http://arxiv.org/find/cs/1/au:+Saraf_Y/0/1/0/all/0/1">Yatharth Saraf</a>, <a href="http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1">Michael Auli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04082">
                                    <div class="article-summary-box-inner">
                                        <span>Language identification greatly impacts the success of downstream tasks such
as automatic speech recognition. Recently, self-supervised speech
representations learned by wav2vec 2.0 have been shown to be very effective for
a range of speech tasks. We extend previous self-supervised work on language
identification by experimenting with pre-trained models which were learned on
real-world unconstrained speech in multiple languages and not just on English.
We show that models pre-trained on many languages perform better and enable
language identification systems that require very little labeled data to
perform well. Results on a 25 languages setup show that with only 10 minutes of
labeled data per language, a cross-lingually pre-trained model can achieve over
93% accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Levi Graph AMR Parser using Heterogeneous Attention. (arXiv:2107.04152v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">Han He</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jinho D. Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04152">
                                    <div class="article-summary-box-inner">
                                        <span>Coupled with biaffine decoders, transformers have been effectively adapted to
text-to-graph transduction and achieved state-of-the-art performance on AMR
parsing. Many prior works, however, rely on the biaffine decoder for either or
both arc and label predictions although most features used by the decoder may
be learned by the transformer already. This paper presents a novel approach to
AMR parsing by combining heterogeneous data (tokens, concepts, labels) as one
input to a transformer to learn attention, and use only attention matrices from
the transformer to predict all elements in AMR graphs (concepts, arcs, labels).
Although our models use significantly fewer parameters than the previous
state-of-the-art graph parser, they show similar or better accuracy on AMR 2.0
and 3.0.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Models for Answer Verification in Question Answering Systems. (arXiv:2107.04217v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zeyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1">Thuy Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moschitti_A/0/1/0/all/0/1">Alessandro Moschitti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04217">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies joint models for selecting correct answer sentences among
the top $k$ provided by answer sentence selection (AS2) modules, which are core
components of retrieval-based Question Answering (QA) systems. Our work shows
that a critical step to effectively exploit an answer set regards modeling the
interrelated information between pair of answers. For this purpose, we build a
three-way multi-classifier, which decides if an answer supports, refutes, or is
neutral with respect to another one. More specifically, our neural architecture
integrates a state-of-the-art AS2 model with the multi-classifier, and a joint
layer connecting all components. We tested our models on WikiQA, TREC-QA, and a
real-world dataset. The results show that our models obtain the new state of
the art in AS2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring and Improving Model-Moderator Collaboration using Uncertainty Estimation. (arXiv:2107.04212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kivlichan_I/0/1/0/all/0/1">Ian D. Kivlichan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jeremiah Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasserman_L/0/1/0/all/0/1">Lucy Vasserman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04212">
                                    <div class="article-summary-box-inner">
                                        <span>Content moderation is often performed by a collaboration between humans and
machine learning models. However, it is not well understood how to design the
collaborative process so as to maximize the combined moderator-model system
performance. This work presents a rigorous study of this problem, focusing on
an approach that incorporates model uncertainty into the collaborative process.
First, we introduce principled metrics to describe the performance of the
collaborative system under capacity constraints on the human moderator,
quantifying how efficiently the combined system utilizes human decisions. Using
these metrics, we conduct a large benchmark study evaluating the performance of
state-of-the-art uncertainty models under different collaborative review
strategies. We find that an uncertainty-based strategy consistently outperforms
the widely used strategy based on toxicity scores, and moreover that the choice
of review strategy drastically changes the overall system performance. Our
results demonstrate the importance of rigorous metrics for understanding and
developing effective moderator-model systems for content moderation, as well as
the utility of uncertainty estimation in this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Machine Translation to Localize Task Oriented NLG Output. (arXiv:2107.04512v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Scott Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Brunk_C/0/1/0/all/0/1">Cliff Brunk</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kyu-Young Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Justin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Freitag_M/0/1/0/all/0/1">Markus Freitag</a>, <a href="http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1">Mihir Kale</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_G/0/1/0/all/0/1">Gagan Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mudgal_S/0/1/0/all/0/1">Sidharth Mudgal</a>, <a href="http://arxiv.org/find/cs/1/au:+Varano_C/0/1/0/all/0/1">Chris Varano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04512">
                                    <div class="article-summary-box-inner">
                                        <span>One of the challenges in a task oriented natural language application like
the Google Assistant, Siri, or Alexa is to localize the output to many
languages. This paper explores doing this by applying machine translation to
the English output. Using machine translation is very scalable, as it can work
with any English output and can handle dynamic text, but otherwise the problem
is a poor fit. The required quality bar is close to perfection, the range of
sentences is extremely narrow, and the sentences are often very different than
the ones in the machine translation training data. This combination of
requirements is novel in the field of domain adaptation for machine
translation. We are able to reach the required quality bar by building on
existing ideas and adding new ones: finetuning on in-domain translations,
adding sentences from the Web, adding semantic annotations, and using automatic
error detection. The paper shares our approach and results, together with a
distillation model to serve the translation models at scale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniRE: A Unified Label Space for Entity Relation Extraction. (arXiv:2107.04292v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yijun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changzhi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuanbin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04292">
                                    <div class="article-summary-box-inner">
                                        <span>Many joint entity relation extraction models setup two separated label spaces
for the two sub-tasks (i.e., entity detection and relation classification). We
argue that this setting may hinder the information interaction between entities
and relations. In this work, we propose to eliminate the different treatment on
the two sub-tasks&#x27; label spaces. The input of our model is a table containing
all word pairs from a sentence. Entities and relations are represented by
squares and rectangles in the table. We apply a unified classifier to predict
each cell&#x27;s label, which unifies the learning of two sub-tasks. For testing, an
effective (yet fast) approximate decoder is proposed for finding squares and
rectangles from tables. Experiments on three benchmarks (ACE04, ACE05, SciERC)
show that, using only half the number of parameters, our model achieves
competitive accuracy with the best extractor, and is faster.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HPNet: Deep Primitive Segmentation Using Hybrid Representations. (arXiv:2105.10620v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Siming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhenpei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chongyang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haibin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vouga_E/0/1/0/all/0/1">Etienne Vouga</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qixing Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10620">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces HPNet, a novel deep-learning approach for segmenting a
3D shape represented as a point cloud into primitive patches. The key to deep
primitive segmentation is learning a feature representation that can separate
points of different primitives. Unlike utilizing a single feature
representation, HPNet leverages hybrid representations that combine one learned
semantic descriptor, two spectral descriptors derived from predicted geometric
parameters, as well as an adjacency matrix that encodes sharp edges. Moreover,
instead of merely concatenating the descriptors, HPNet optimally combines
hybrid representations by learning combination weights. This weighting module
builds on the entropy of input features. The output primitive segmentation is
obtained from a mean-shift clustering module. Experimental results on benchmark
datasets ANSI and ABCParts show that HPNet leads to significant performance
gains from baseline approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EPIC-Survival: End-to-end Part Inferred Clustering for Survival Analysis, Featuring Prognostic Stratification Boosting. (arXiv:2101.11085v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muhammad_H/0/1/0/all/0/1">Hassan Muhammad</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1">Chensu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Sigel_C/0/1/0/all/0/1">Carlie S. Sigel</a>, <a href="http://arxiv.org/find/cs/1/au:+Doukas_M/0/1/0/all/0/1">Michael Doukas</a>, <a href="http://arxiv.org/find/cs/1/au:+Alpert_L/0/1/0/all/0/1">Lindsay Alpert</a>, <a href="http://arxiv.org/find/cs/1/au:+Jarnagin_W/0/1/0/all/0/1">William R. Jarnagin</a>, <a href="http://arxiv.org/find/cs/1/au:+Simpson_A/0/1/0/all/0/1">Amber Simpson</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuchs_T/0/1/0/all/0/1">Thomas J. Fuchs</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11085">
                                    <div class="article-summary-box-inner">
                                        <span>Histopathology-based survival modelling has two major hurdles. Firstly, a
well-performing survival model has minimal clinical application if it does not
contribute to the stratification of a cancer patient cohort into different risk
groups, preferably driven by histologic morphologies. In the clinical setting,
individuals are not given specific prognostic predictions, but are rather
predicted to lie within a risk group which has a general survival trend. Thus,
It is imperative that a survival model produces well-stratified risk groups.
Secondly, until now, survival modelling was done in a two-stage approach
(encoding and aggregation). The massive amount of pixels in digitized whole
slide images were never utilized to their fullest extent due to technological
constraints on data processing, forcing decoupled learning. EPIC-Survival
bridges encoding and aggregation into an end-to-end survival modelling
approach, while introducing stratification boosting to encourage the model to
not only optimize ranking, but also to discriminate between risk groups. In
this study we show that EPIC-Survival performs better than other approaches in
modelling intrahepatic cholangiocarcinoma, a historically difficult cancer to
model. Further, we show that stratification boosting improves further improves
model performance, resulting in a concordance-index of 0.880 on a held-out test
set. Finally, we were able to identify specific histologic differences, not
commonly sought out in ICC, between low and high risk groups.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLIB: Towards Automated Test Oracle for Graphically-Rich Applications. (arXiv:2106.10507v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Ke Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yufei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingfeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Changjie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhipeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10507">
                                    <div class="article-summary-box-inner">
                                        <span>Graphically-rich applications such as games are ubiquitous with attractive
visual effects of Graphical User Interface (GUI) that offers a bridge between
software applications and end-users. However, various types of graphical
glitches may arise from such GUI complexity and have become one of the main
component of software compatibility issues. Our study on bug reports from game
development teams in NetEase Inc. indicates that graphical glitches frequently
occur during the GUI rendering and severely degrade the quality of
graphically-rich applications such as video games. Existing automated testing
techniques for such applications focus mainly on generating various GUI test
sequences and check whether the test sequences can cause crashes. These
techniques require constant human attention to captures non-crashing bugs such
as bugs causing graphical glitches. In this paper, we present the first step in
automating the test oracle for detecting non-crashing bugs in graphically-rich
applications. Specifically, we propose \texttt{GLIB} based on a code-based data
augmentation technique to detect game GUI glitches. We perform an evaluation of
\texttt{GLIB} on 20 real-world game apps (with bug reports available) and the
result shows that \texttt{GLIB} can achieve 100\% precision and 99.5\% recall
in detecting non-crashing bugs such as game GUI glitches. Practical application
of \texttt{GLIB} on another 14 real-world games (without bug reports) further
demonstrates that \texttt{GLIB} can effectively uncover GUI glitches, with 48
of 53 bugs reported by \texttt{GLIB} having been confirmed and fixed so far.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">StyleCariGAN: Caricature Generation via StyleGAN Feature Map Modulation. (arXiv:2107.04331v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jang_W/0/1/0/all/0/1">Wonjong Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_G/0/1/0/all/0/1">Gwangjin Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_Y/0/1/0/all/0/1">Yucheol Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiaolong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1">Xin Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seungyong Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04331">
                                    <div class="article-summary-box-inner">
                                        <span>We present a caricature generation framework based on shape and style
manipulation using StyleGAN. Our framework, dubbed StyleCariGAN, automatically
creates a realistic and detailed caricature from an input photo with optional
controls on shape exaggeration degree and color stylization type. The key
component of our method is shape exaggeration blocks that are used for
modulating coarse layer feature maps of StyleGAN to produce desirable
caricature shape exaggerations. We first build a layer-mixed StyleGAN for
photo-to-caricature style conversion by swapping fine layers of the StyleGAN
for photos to the corresponding layers of the StyleGAN trained to generate
caricatures. Given an input photo, the layer-mixed model produces detailed
color stylization for a caricature but without shape exaggerations. We then
append shape exaggeration blocks to the coarse layers of the layer-mixed model
and train the blocks to create shape exaggerations while preserving the
characteristic appearances of the input. Experimental results show that our
StyleCariGAN generates realistic and detailed caricatures compared to the
current state-of-the-art methods. We demonstrate StyleCariGAN also supports
other StyleGAN-based image manipulations, such as facial expression control.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Event-Based Feature Tracking in Continuous Time with Sliding Window Optimization. (arXiv:2107.04536v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chui_J/0/1/0/all/0/1">Jason Chui</a>, <a href="http://arxiv.org/find/cs/1/au:+Klenk_S/0/1/0/all/0/1">Simon Klenk</a>, <a href="http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1">Daniel Cremers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04536">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel method for continuous-time feature tracking in event
cameras. To this end, we track features by aligning events along an estimated
trajectory in space-time such that the projection on the image plane results in
maximally sharp event patch images. The trajectory is parameterized by $n^{th}$
order B-splines, which are continuous up to $(n-2)^{th}$ derivative. In
contrast to previous work, we optimize the curve parameters in a sliding window
fashion. On a public dataset we experimentally confirm that the proposed
sliding-window B-spline optimization leads to longer and more accurate feature
tracks than in previous work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sli2Vol: Annotate a 3D Volume from a Single Slice with Self-Supervised Learning. (arXiv:2105.12722v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yeung_P/0/1/0/all/0/1">Pak-Hei Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Namburete_A/0/1/0/all/0/1">Ana I.L. Namburete</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Weidi Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12722">
                                    <div class="article-summary-box-inner">
                                        <span>The objective of this work is to segment any arbitrary structures of interest
(SOI) in 3D volumes by only annotating a single slice, (i.e. semi-automatic 3D
segmentation). We show that high accuracy can be achieved by simply propagating
the 2D slice segmentation with an affinity matrix between consecutive slices,
which can be learnt in a self-supervised manner, namely slice reconstruction.
Specifically, we compare the proposed framework, termed as Sli2Vol, with
supervised approaches and two other unsupervised/ self-supervised slice
registration approaches, on 8 public datasets (both CT and MRI scans), spanning
9 different SOIs. Without any parameter-tuning, the same model achieves
superior performance with Dice scores (0-100 scale) of over 80 for most of the
benchmarks, including the ones that are unseen during training. Our results
show generalizability of the proposed approach across data from different
machines and with different SOIs: a major use case of semi-automatic
segmentation methods where fully supervised approaches would normally struggle.
The source code will be made publicly available at
https://github.com/pakheiyeung/Sli2Vol.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Seven Basic Expression Recognition Using ResNet-18. (arXiv:2107.04569v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Satnam Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Schicker_D/0/1/0/all/0/1">Doris Schicker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04569">
                                    <div class="article-summary-box-inner">
                                        <span>We propose to use a ResNet-18 architecture that was pre-trained on the FER+
dataset for tackling the problem of affective behavior analysis in-the-wild
(ABAW) for classification of the seven basic expressions, namely, neutral,
anger, disgust, fear, happiness, sadness and surprise. As part of the second
workshop and competition on affective behavior analysis in-the-wild (ABAW2), a
database consisting of 564 videos with around 2.8M frames is provided along
with labels for these seven basic expressions. We resampled the dataset to
counter class-imbalances by under-sampling the over-represented classes and
over-sampling the under-represented classes along with class-wise weights. To
avoid overfitting we performed data-augmentation and used L2 regularisation.
Our classifier reaches an ABAW2 score of 0.4 and therefore exceeds the baseline
results provided by the hosts of the competition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Distributions of Aggregation Layers in Deep Neural Networks. (arXiv:2107.04458v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ong_E/0/1/0/all/0/1">Eng-Jon Ong</a>, <a href="http://arxiv.org/find/cs/1/au:+Husain_S/0/1/0/all/0/1">Sameed Husain</a>, <a href="http://arxiv.org/find/cs/1/au:+Bober_M/0/1/0/all/0/1">Miroslaw Bober</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04458">
                                    <div class="article-summary-box-inner">
                                        <span>The process of aggregation is ubiquitous in almost all deep nets models. It
functions as an important mechanism for consolidating deep features into a more
compact representation, whilst increasing robustness to overfitting and
providing spatial invariance in deep nets. In particular, the proximity of
global aggregation layers to the output layers of DNNs mean that aggregated
features have a direct influence on the performance of a deep net. A better
understanding of this relationship can be obtained using information theoretic
methods. However, this requires the knowledge of the distributions of the
activations of aggregation layers. To achieve this, we propose a novel
mathematical formulation for analytically modelling the probability
distributions of output values of layers involved with deep feature
aggregation. An important outcome is our ability to analytically predict the
KL-divergence of output nodes in a DNN. We also experimentally verify our
theoretical predictions against empirical observations across a range of
different classification tasks and datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memes in the Wild: Assessing the Generalizability of the Hateful Memes Challenge Dataset. (arXiv:2107.04313v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kirk_H/0/1/0/all/0/1">Hannah Rose Kirk</a>, <a href="http://arxiv.org/find/cs/1/au:+Jun_Y/0/1/0/all/0/1">Yennie Jun</a>, <a href="http://arxiv.org/find/cs/1/au:+Rauba_P/0/1/0/all/0/1">Paulius Rauba</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachtel_G/0/1/0/all/0/1">Gal Wachtel</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruining Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xingjian Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Broestl_N/0/1/0/all/0/1">Noah Broestl</a>, <a href="http://arxiv.org/find/cs/1/au:+Doff_Sotta_M/0/1/0/all/0/1">Martin Doff-Sotta</a>, <a href="http://arxiv.org/find/cs/1/au:+Shtedritski_A/0/1/0/all/0/1">Aleksandar Shtedritski</a>, <a href="http://arxiv.org/find/cs/1/au:+Asano_Y/0/1/0/all/0/1">Yuki M. Asano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04313">
                                    <div class="article-summary-box-inner">
                                        <span>Hateful memes pose a unique challenge for current machine learning systems
because their message is derived from both text- and visual-modalities. To this
effect, Facebook released the Hateful Memes Challenge, a dataset of memes with
pre-extracted text captions, but it is unclear whether these synthetic examples
generalize to &#x60;memes in the wild&#x27;. In this paper, we collect hateful and
non-hateful memes from Pinterest to evaluate out-of-sample performance on
models pre-trained on the Facebook dataset. We find that memes in the wild
differ in two key aspects: 1) Captions must be extracted via OCR, injecting
noise and diminishing performance of multimodal models, and 2) Memes are more
diverse than &#x60;traditional memes&#x27;, including screenshots of conversations or
text on a plain background. This paper thus serves as a reality check for the
current benchmark of hateful meme detection and its applicability for detecting
real world hate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modality specific U-Net variants for biomedical image segmentation: A survey. (arXiv:2107.04537v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Punn_N/0/1/0/all/0/1">Narinder Singh Punn</a>, <a href="http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1">Sonali Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04537">
                                    <div class="article-summary-box-inner">
                                        <span>With the advent of advancements in deep learning approaches, such as deep
convolution neural network, residual neural network, adversarial network; U-Net
architectures are most widely utilized in biomedical image segmentation to
address the automation in identification and detection of the target regions or
sub-regions. In recent studies, U-Net based approaches have illustrated
state-of-the-art performance in different applications for the development of
computer-aided diagnosis systems for early diagnosis and treatment of diseases
such as brain tumor, lung cancer, alzheimer, breast cancer, etc. This article
contributes to present the success of these approaches by describing the U-Net
framework, followed by the comprehensive analysis of the U-Net variants for
different medical imaging or modalities such as magnetic resonance imaging,
X-ray, computerized tomography/computerized axial tomography, ultrasound,
positron emission tomography, etc. Besides, this article also highlights the
contribution of U-Net based frameworks in the on-going pandemic, severe acute
respiratory syndrome coronavirus 2 (SARS-CoV-2) also known as COVID-19.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ANCER: Anisotropic Certification via Sample-wise Volume Maximization. (arXiv:2107.04570v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eiras_F/0/1/0/all/0/1">Francisco Eiras</a>, <a href="http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1">Motasem Alfarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1">M. Pawan Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H. S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Dokania_P/0/1/0/all/0/1">Puneet K. Dokania</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>, <a href="http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1">Adel Bibi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04570">
                                    <div class="article-summary-box-inner">
                                        <span>Randomized smoothing has recently emerged as an effective tool that enables
certification of deep neural network classifiers at scale. All prior art on
randomized smoothing has focused on isotropic $\ell_p$ certification, which has
the advantage of yielding certificates that can be easily compared among
isotropic methods via $\ell_p$-norm radius. However, isotropic certification
limits the region that can be certified around an input to worst-case
adversaries, \ie it cannot reason about other &quot;close&quot;, potentially large,
constant prediction safe regions. To alleviate this issue, (i) we theoretically
extend the isotropic randomized smoothing $\ell_1$ and $\ell_2$ certificates to
their generalized anisotropic counterparts following a simplified analysis.
Moreover, (ii) we propose evaluation metrics allowing for the comparison of
general certificates - a certificate is superior to another if it certifies a
superset region - with the quantification of each certificate through the
volume of the certified region. We introduce ANCER, a practical framework for
obtaining anisotropic certificates for a given test set sample via volume
maximization. Our empirical results demonstrate that ANCER achieves
state-of-the-art $\ell_1$ and $\ell_2$ certified accuracy on both CIFAR-10 and
ImageNet at multiple radii, while certifying substantially larger regions in
terms of volume, thus highlighting the benefits of moving away from isotropic
analysis. Code used in our experiments is available in
https://github.com/MotasemAlfarra/ANCER.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">1st Place Solution for YouTubeVOS Challenge 2021:Video Instance Segmentation. (arXiv:2106.06649v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thuy C. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1">Tuan N. Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_N/0/1/0/all/0/1">Nam LH. Phan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_C/0/1/0/all/0/1">Chuong H. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamazaki_M/0/1/0/all/0/1">Masayuki Yamazaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamanaka_M/0/1/0/all/0/1">Masao Yamanaka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06649">
                                    <div class="article-summary-box-inner">
                                        <span>Video Instance Segmentation (VIS) is a multi-task problem performing
detection, segmentation, and tracking simultaneously. Extended from image set
applications, video data additionally induces the temporal information, which,
if handled appropriately, is very useful to identify and predict object
motions. In this work, we design a unified model to mutually learn these tasks.
Specifically, we propose two modules, named Temporally Correlated Instance
Segmentation (TCIS) and Bidirectional Tracking (BiTrack), to take the benefit
of the temporal correlation between the object&#x27;s instance masks across adjacent
frames. On the other hand, video data is often redundant due to the frame&#x27;s
overlap. Our analysis shows that this problem is particularly severe for the
YoutubeVOS-VIS2021 data. Therefore, we propose a Multi-Source Data (MSD)
training mechanism to compensate for the data deficiency. By combining these
techniques with a bag of tricks, the network performance is significantly
boosted compared to the baseline, and outperforms other methods by a
considerable margin on the YoutubeVOS-VIS 2019 and 2021 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">(Un)Masked COVID-19 Trends from Social Media. (arXiv:2011.00052v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Asmit Kumar Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehan_P/0/1/0/all/0/1">Paras Mehan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_D/0/1/0/all/0/1">Divyanshu Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_R/0/1/0/all/0/1">Rohan Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethi_T/0/1/0/all/0/1">Tavpritesh Sethi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1">Ponnurangam Kumaraguru</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00052">
                                    <div class="article-summary-box-inner">
                                        <span>Wearing masks is a useful protection method against COVID-19, which has
caused widespread economic and social impact worldwide. Across the globe,
governments have put mandates for the use of face masks, which have received
both positive and negative reaction. Online social media provides an exciting
platform to study the use of masks and analyze underlying mask-wearing
patterns. In this article, we analyze 2.04 million social media images for six
US cities. An increase in masks worn in images is seen as the COVID-19 cases
rose, particularly when their respective states imposed strict regulations. We
also found a decrease in the posting of group pictures as stay-at-home laws
were put into place. Furthermore, mask compliance in the Black Lives Matter
protest was analyzed, eliciting that 40% of the people in group photos wore
masks, and 45% of them wore the masks with a fit score of greater than 80%. We
introduce two new datasets, VAriety MAsks - Classification (VAMA-C) and VAriety
MAsks - Segmentation (VAMA-S), for mask detection and mask fit analysis tasks,
respectively. For the analysis, we create two frameworks, face mask detector
(for classifying masked and unmasked faces) and mask fit analyzer (a semantic
segmentation based model to calculate a mask-fit score). The face mask detector
achieved a classification accuracy of 98%, and the semantic segmentation model
for the mask fit analyzer achieved an Intersection Over Union (IOU) score of
98%. We conclude that such a framework can be used to evaluate the
effectiveness of such public health strategies using social media platforms in
times of pandemic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RGBD-Net: Predicting color and depth images for novel views synthesis. (arXiv:2011.14398v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1">Phong Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Karnewar_A/0/1/0/all/0/1">Animesh Karnewar</a>, <a href="http://arxiv.org/find/cs/1/au:+Huynh_L/0/1/0/all/0/1">Lam Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahtu_E/0/1/0/all/0/1">Esa Rahtu</a>, <a href="http://arxiv.org/find/cs/1/au:+Matas_J/0/1/0/all/0/1">Jiri Matas</a>, <a href="http://arxiv.org/find/cs/1/au:+Heikkila_J/0/1/0/all/0/1">Janne Heikkila</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14398">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new cascaded architecture for novel view synthesis, called
RGBD-Net, which consists of two core components: a hierarchical depth
regression network and a depth-aware generator network. The former one predicts
depth maps of the target views by using adaptive depth scaling, while the
latter one leverages the predicted depths and renders spatially and temporally
consistent target images. In the experimental evaluation on standard datasets,
RGBD-Net not only outperforms the state-of-the-art by a clear margin, but it
also generalizes well to new scenes without per-scene optimization. Moreover,
we show that RGBD-Net can be optionally trained without depth supervision while
still retaining high-quality rendering. Thanks to the depth regression network,
RGBD-Net can be also used for creating dense 3D point clouds that are more
accurate than those produced by some state-of-the-art multi-view stereo
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Contrastive Motion Learning for Video Action Recognition. (arXiv:2007.10321v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xitong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaodong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sifei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1">Deqing Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1">Larry Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1">Jan Kautz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.10321">
                                    <div class="article-summary-box-inner">
                                        <span>One central question for video action recognition is how to model motion. In
this paper, we present hierarchical contrastive motion learning, a new
self-supervised learning framework to extract effective motion representations
from raw video frames. Our approach progressively learns a hierarchy of motion
features that correspond to different abstraction levels in a network. This
hierarchical design bridges the semantic gap between low-level motion cues and
high-level recognition tasks, and promotes the fusion of appearance and motion
information at multiple levels. At each level, an explicit motion
self-supervision is provided via contrastive learning to enforce the motion
features at the current level to predict the future ones at the previous level.
Thus, the motion features at higher levels are trained to gradually capture
semantic dynamics and evolve more discriminative for action recognition. Our
motion learning module is lightweight and flexible to be embedded into various
backbone networks. Extensive experiments on four benchmarks show that the
proposed approach consistently achieves superior results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Retinal OCT Denoising with Pseudo-Multimodal Fusion Network. (arXiv:2107.04288v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hu_D/0/1/0/all/0/1">Dewei Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Malone_J/0/1/0/all/0/1">Joseph D. Malone</a>, <a href="http://arxiv.org/find/eess/1/au:+Atay_Y/0/1/0/all/0/1">Yigit Atay</a>, <a href="http://arxiv.org/find/eess/1/au:+Tao_Y/0/1/0/all/0/1">Yuankai K. Tao</a>, <a href="http://arxiv.org/find/eess/1/au:+Oguz_I/0/1/0/all/0/1">Ipek Oguz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04288">
                                    <div class="article-summary-box-inner">
                                        <span>Optical coherence tomography (OCT) is a prevalent imaging technique for
retina. However, it is affected by multiplicative speckle noise that can
degrade the visibility of essential anatomical structures, including blood
vessels and tissue layers. Although averaging repeated B-scan frames can
significantly improve the signal-to-noise-ratio (SNR), this requires longer
acquisition time, which can introduce motion artifacts and cause discomfort to
patients. In this study, we propose a learning-based method that exploits
information from the single-frame noisy B-scan and a pseudo-modality that is
created with the aid of the self-fusion method. The pseudo-modality provides
good SNR for layers that are barely perceptible in the noisy B-scan but can
over-smooth fine features such as small vessels. By using a fusion network,
desired features from each modality can be combined, and the weight of their
contribution is adjustable. Evaluated by intensity-based and structural
metrics, the result shows that our method can effectively suppress the speckle
noise and enhance the contrast between retina layers while the overall
structure and small blood vessels are preserved. Compared to the single
modality network, our method improves the structural similarity with low noise
B-scan from 0.559 +\- 0.033 to 0.576 +\- 0.031.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Discontinuity-Preserving Image Registration Network. (arXiv:2107.04440v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1">Xiang Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Ravikumar_N/0/1/0/all/0/1">Nishant Ravikumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Xia_Y/0/1/0/all/0/1">Yan Xia</a>, <a href="http://arxiv.org/find/eess/1/au:+Frangi_A/0/1/0/all/0/1">Alejandro F Frangi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04440">
                                    <div class="article-summary-box-inner">
                                        <span>Image registration aims to establish spatial correspondence across pairs, or
groups of images, and is a cornerstone of medical image computing and
computer-assisted-interventions. Currently, most deep learning-based
registration methods assume that the desired deformation fields are globally
smooth and continuous, which is not always valid for real-world scenarios,
especially in medical image registration (e.g. cardiac imaging and abdominal
imaging). Such a global constraint can lead to artefacts and increased errors
at discontinuous tissue interfaces. To tackle this issue, we propose a
weakly-supervised Deep Discontinuity-preserving Image Registration network
(DDIR), to obtain better registration performance and realistic deformation
fields. We demonstrate that our method achieves significant improvements in
registration accuracy and predicts more realistic deformations, in registration
experiments on cardiac magnetic resonance (MR) images from UK Biobank Imaging
Study (UKBB), than state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Robust General Medical Image Segmentation. (arXiv:2107.04263v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Daza_L/0/1/0/all/0/1">Laura Daza</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_J/0/1/0/all/0/1">Juan C. P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbel&#xe1;ez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04263">
                                    <div class="article-summary-box-inner">
                                        <span>The reliability of Deep Learning systems depends on their accuracy but also
on their robustness against adversarial perturbations to the input data.
Several attacks and defenses have been proposed to improve the performance of
Deep Neural Networks under the presence of adversarial noise in the natural
image domain. However, robustness in computer-aided diagnosis for volumetric
data has only been explored for specific tasks and with limited attacks. We
propose a new framework to assess the robustness of general medical image
segmentation systems. Our contributions are two-fold: (i) we propose a new
benchmark to evaluate robustness in the context of the Medical Segmentation
Decathlon (MSD) by extending the recent AutoAttack natural image classification
framework to the domain of volumetric data segmentation, and (ii) we present a
novel lattice architecture for RObust Generic medical image segmentation (ROG).
Our results show that ROG is capable of generalizing across different tasks of
the MSD and largely surpasses the state-of-the-art under sophisticated
adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Does Form Follow Function? An Empirical Exploration of the Impact of Deep Neural Network Architecture Design on Hardware-Specific Acceleration. (arXiv:2107.04144v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abbasi_S/0/1/0/all/0/1">Saad Abbasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiee_M/0/1/0/all/0/1">Mohammad Javad Shafiee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_E/0/1/0/all/0/1">Ellick Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alexander Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04144">
                                    <div class="article-summary-box-inner">
                                        <span>The fine-grained relationship between form and function with respect to deep
neural network architecture design and hardware-specific acceleration is one
area that is not well studied in the research literature, with form often
dictated by accuracy as opposed to hardware function. In this study, a
comprehensive empirical exploration is conducted to investigate the impact of
deep neural network architecture design on the degree of inference speedup that
can be achieved via hardware-specific acceleration. More specifically, we
empirically study the impact of a variety of commonly used macro-architecture
design patterns across different architectural depths through the lens of
OpenVINO microprocessor-specific and GPU-specific acceleration. Experimental
results showed that while leveraging hardware-specific acceleration achieved an
average inference speed-up of 380%, the degree of inference speed-up varied
drastically depending on the macro-architecture design pattern, with the
greatest speedup achieved on the depthwise bottleneck convolution design
pattern at 550%. Furthermore, we conduct an in-depth exploration of the
correlation between FLOPs requirement, level 3 cache efficacy, and network
latency with increasing architectural depth and width. Finally, we analyze the
inference time reductions using hardware-specific acceleration when compared to
native deep learning frameworks across a wide variety of hand-crafted deep
convolutional neural network architecture designs as well as ones found via
neural architecture search strategies. We found that the DARTS-derived
architecture to benefit from the greatest improvement from hardware-specific
software acceleration (1200%) while the depthwise bottleneck convolution-based
MobileNet-V2 to have the lowest overall inference time of around 2.4 ms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparison of 2D vs. 3D U-Net Organ Segmentation in abdominal 3D CT images. (arXiv:2107.04062v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zettler_N/0/1/0/all/0/1">Nico Zettler</a>, <a href="http://arxiv.org/find/eess/1/au:+Mastmeyer_A/0/1/0/all/0/1">Andre Mastmeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04062">
                                    <div class="article-summary-box-inner">
                                        <span>A two-step concept for 3D segmentation on 5 abdominal organs inside
volumetric CT images is presented. First each relevant organ&#x27;s volume of
interest is extracted as bounding box. The extracted volume acts as input for a
second stage, wherein two compared U-Nets with different architectural
dimensions re-construct an organ segmentation as label mask. In this work, we
focus on comparing 2D U-Nets vs. 3D U-Net counterparts. Our initial results
indicate Dice improvements of about 6\% at maximum. In this study to our
surprise, liver and kidneys for instance were tackled significantly better
using the faster and GPU-memory saving 2D U-Nets. For other abdominal key
organs, there were no significant differences, but we observe highly
significant advantages for the 2D U-Net in terms of GPU computational efforts
for all organs under study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D RegNet: Deep Learning Model for COVID-19 Diagnosis on Chest CT Image. (arXiv:2107.04055v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Qi_H/0/1/0/all/0/1">Haibo Qi</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yuhan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xinyu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04055">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, a 3D-RegNet-based neural network is proposed for diagnosing
the physical condition of patients with coronavirus (Covid-19) infection. In
the application of clinical medicine, lung CT images are utilized by
practitioners to determine whether a patient is infected with coronavirus.
However, there are some laybacks can be considered regarding to this diagnostic
method, such as time consuming and low accuracy. As a relatively large organ of
human body, important spatial features would be lost if the lungs were
diagnosed utilizing two dimensional slice image. Therefore, in this paper, a
deep learning model with 3D image was designed. The 3D image as input data was
comprised of two-dimensional pulmonary image sequence and from which relevant
coronavirus infection 3D features were extracted and classified. The results
show that the test set of the 3D model, the result: f1 score of 0.8379 and AUC
value of 0.8807 have been achieved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NDPNet: A novel non-linear data projection network for few-shot fine-grained image classification. (arXiv:2106.06988v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weichuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuefang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1">Zhe Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yongsheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changming Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06988">
                                    <div class="article-summary-box-inner">
                                        <span>Metric-based few-shot fine-grained image classification (FSFGIC) aims to
learn a transferable feature embedding network by estimating the similarities
between query images and support classes from very few examples. In this work,
we propose, for the first time, to introduce the non-linear data projection
concept into the design of FSFGIC architecture in order to address the limited
sample problem in few-shot learning and at the same time to increase the
discriminability of the model for fine-grained image classification.
Specifically, we first design a feature re-abstraction embedding network that
has the ability to not only obtain the required semantic features for effective
metric learning but also re-enhance such features with finer details from input
images. Then the descriptors of the query images and the support classes are
projected into different non-linear spaces in our proposed similarity metric
learning network to learn discriminative projection factors. This design can
effectively operate in the challenging and restricted condition of a FSFGIC
task for making the distance between the samples within the same class smaller
and the distance between samples from different classes larger and for reducing
the coupling relationship between samples from different categories.
Furthermore, a novel similarity measure based on the proposed non-linear data
project is presented for evaluating the relationships of feature information
between a query image and a support set. It is worth to note that our proposed
architecture can be easily embedded into any episodic training mechanisms for
end-to-end training from scratch. Extensive experiments on FSFGIC tasks
demonstrate the superiority of the proposed methods over the state-of-the-art
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Just Noticeable Difference for Machine Perception and Generation of Regularized Adversarial Images with Minimal Perturbation. (arXiv:2102.08079v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akan_A/0/1/0/all/0/1">Adil Kaan Akan</a>, <a href="http://arxiv.org/find/cs/1/au:+Akbas_E/0/1/0/all/0/1">Emre Akbas</a>, <a href="http://arxiv.org/find/cs/1/au:+Vural_F/0/1/0/all/0/1">Fatos T. Yarman Vural</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08079">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, we introduce a measure for machine perception, inspired by the
concept of Just Noticeable Difference (JND) of human perception. Based on this
measure, we suggest an adversarial image generation algorithm, which
iteratively distorts an image by an additive noise until the machine learning
model detects the change in the image by outputting a false label. The amount
of noise added to the original image is defined as the gradient of the cost
function of the machine learning model. This cost function explicitly minimizes
the amount of perturbation applied on the input image and it is regularized by
bounded range and total variation functions to assure perceptual similarity of
the adversarial image to the input. We evaluate the adversarial images
generated by our algorithm both qualitatively and quantitatively on CIFAR10,
ImageNet, and MS COCO datasets. Our experiments on image classification and
object detection tasks show that adversarial images generated by our method are
both more successful in deceiving the recognition/detection model and less
perturbed compared to the images generated by the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Psychophysical Oriented Saliency Map Prediction Model. (arXiv:2011.04076v10 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04076">
                                    <div class="article-summary-box-inner">
                                        <span>Visual attention is one of the most significant characteristics for selecting
and understanding the visual redundancy of the external world. Complex scenes
include enormous redundancy. The human vision system cannot process all
information simultaneously, due to the visual information bottleneck. The human
visual system mainly focuses on dominant parts of scenes, in order to reduce
the redundant input of visual information. This is commonly known as visual
attention prediction or visual saliency map prediction. This paper proposes a
new psychophysical saliency prediction architecture, WECSF, inspired by
multi-channel model of visual cortex functioning in humans. The model consists
of opponent color channels, a wavelet transform and wavelet energy map, and a
contrast sensitivity function for extracting low-level image features and
providing maximum approximation to the human visual system. In this paper, the
proposed model is evaluated using several data sets, including the MIT1003,
MIT300, TORONTO, SID4VAM, and UCF Sports data sets, in order to demonstrate its
efficiency. We also quantitatively and qualitatively compare the saliency
prediction performance with that of other state-of-the-art models. Our model
achieved stable and very good performance. Additionally, Fourier and
spectral-inspired saliency prediction models outperformed other
state-of-the-art non-neural networks (and even deep neural network) models on
psychophysical synthetic images. Finally, the proposed model can also be
applied to spatial-temporal saliency prediction and achieved superior
performance in the evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ViTGAN: Training GANs with Vision Transformers. (arXiv:2107.04589v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kwonjoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Huiwen Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhuowen Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Ce Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04589">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Vision Transformers (ViTs) have shown competitive performance on
image recognition while requiring less vision-specific inductive biases. In
this paper, we investigate if such observation can be extended to image
generation. To this end, we integrate the ViT architecture into generative
adversarial networks (GANs). We observe that existing regularization methods
for GANs interact poorly with self-attention, causing serious instability
during training. To resolve this issue, we introduce novel regularization
techniques for training GANs with ViTs. Empirically, our approach, named
ViTGAN, achieves comparable performance to state-of-the-art CNN-based StyleGAN2
on CIFAR-10, CelebA, and LSUN bedroom datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Cascaded Detection Tasks with Weakly-Supervised Domain Adaptation. (arXiv:2107.04523v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hanselmann_N/0/1/0/all/0/1">Niklas Hanselmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_N/0/1/0/all/0/1">Nick Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortelt_B/0/1/0/all/0/1">Benedikt Ortelt</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1">Andreas Geiger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04523">
                                    <div class="article-summary-box-inner">
                                        <span>In order to handle the challenges of autonomous driving, deep learning has
proven to be crucial in tackling increasingly complex tasks, such as 3D
detection or instance segmentation. State-of-the-art approaches for image-based
detection tasks tackle this complexity by operating in a cascaded fashion: they
first extract a 2D bounding box based on which additional attributes, e.g.
instance masks, are inferred. While these methods perform well, a key challenge
remains the lack of accurate and cheap annotations for the growing variety of
tasks. Synthetic data presents a promising solution but, despite the effort in
domain adaptation research, the gap between synthetic and real data remains an
open problem. In this work, we propose a weakly supervised domain adaptation
setting which exploits the structure of cascaded detection tasks. In
particular, we learn to infer the attributes solely from the source domain
while leveraging 2D bounding boxes as weak labels in both domains to explain
the domain shift. We further encourage domain-invariant features through
class-wise feature alignment using ground-truth class information, which is not
available in the unsupervised setting. As our experiments demonstrate, the
approach is competitive with fully supervised settings while outperforming
unsupervised adaptation approaches by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Challenges of Open World Recognitionunder Shifting Visual Domains. (arXiv:2107.04461v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fontanel_D/0/1/0/all/0/1">Dario Fontanel</a>, <a href="http://arxiv.org/find/cs/1/au:+Cermelli_F/0/1/0/all/0/1">Fabio Cermelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Mancini_M/0/1/0/all/0/1">Massimiliano Mancini</a>, <a href="http://arxiv.org/find/cs/1/au:+Caputo_B/0/1/0/all/0/1">Barbara Caputo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04461">
                                    <div class="article-summary-box-inner">
                                        <span>Robotic visual systems operating in the wild must act in unconstrained
scenarios, under different environmental conditions while facing a variety of
semantic concepts, including unknown ones. To this end, recent works tried to
empower visual object recognition methods with the capability to i) detect
unseen concepts and ii) extended their knowledge over time, as images of new
semantic classes arrive. This setting, called Open World Recognition (OWR), has
the goal to produce systems capable of breaking the semantic limits present in
the initial training set. However, this training set imposes to the system not
only its own semantic limits, but also environmental ones, due to its bias
toward certain acquisition conditions that do not necessarily reflect the high
variability of the real-world. This discrepancy between training and test
distribution is called domain-shift. This work investigates whether OWR
algorithms are effective under domain-shift, presenting the first benchmark
setup for assessing fairly the performances of OWR algorithms, with and without
domain-shift. We then use this benchmark to conduct analyses in various
scenarios, showing how existing OWR algorithms indeed suffer a severe
performance degradation when train and test distributions differ. Our analysis
shows that this degradation is only slightly mitigated by coupling OWR with
domain generalization techniques, indicating that the mere plug-and-play of
existing algorithms is not enough to recognize new and unknown categories in
unseen domains. Our results clearly point toward open issues and future
research directions, that need to be investigated for building robot visual
systems able to function reliably under these challenging yet very real
conditions. Code available at
https://github.com/DarioFontanel/OWR-VisualDomains</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">White-Box Cartoonization Using An Extended GAN Framework. (arXiv:2107.04551v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thakur_A/0/1/0/all/0/1">Amey Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizvi_H/0/1/0/all/0/1">Hasan Rizvi</a>, <a href="http://arxiv.org/find/cs/1/au:+Satish_M/0/1/0/all/0/1">Mega Satish</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04551">
                                    <div class="article-summary-box-inner">
                                        <span>In the present study, we propose to implement a new framework for estimating
generative models via an adversarial process to extend an existing GAN
framework and develop a white-box controllable image cartoonization, which can
generate high-quality cartooned images/videos from real-world photos and
videos. The learning purposes of our system are based on three distinct
representations: surface representation, structure representation, and texture
representation. The surface representation refers to the smooth surface of the
images. The structure representation relates to the sparse colour blocks and
compresses generic content. The texture representation shows the texture,
curves, and features in cartoon images. Generative Adversarial Network (GAN)
framework decomposes the images into different representations and learns from
them to generate cartoon images. This decomposition makes the framework more
controllable and flexible which allows users to make changes based on the
required output. This approach overcomes any previous system in terms of
maintaining clarity, colours, textures, shapes of images yet showing the
characteristics of cartoon images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Object-Centric Representation Learning for Video Question Answering. (arXiv:2104.05166v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dang_L/0/1/0/all/0/1">Long Hoang Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1">Thao Minh Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1">Vuong Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1">Truyen Tran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05166">
                                    <div class="article-summary-box-inner">
                                        <span>Video question answering (Video QA) presents a powerful testbed for
human-like intelligent behaviors. The task demands new capabilities to
integrate video processing, language understanding, binding abstract linguistic
concepts to concrete visual artifacts, and deliberative reasoning over
spacetime. Neural networks offer a promising approach to reach this potential
through learning from examples rather than handcrafting features and rules.
However, neural networks are predominantly feature-based - they map data to
unstructured vectorial representation and thus can fall into the trap of
exploiting shortcuts through surface statistics instead of true systematic
reasoning seen in symbolic systems. To tackle this issue, we advocate for
object-centric representation as a basis for constructing spatio-temporal
structures from videos, essentially bridging the semantic gap between low-level
pattern recognition and high-level symbolic algebra. To this end, we propose a
new query-guided representation framework to turn a video into an evolving
relational graph of objects, whose features and interactions are dynamically
and conditionally inferred. The object lives are then summarized into resumes,
lending naturally for deliberative relational reasoning that produces an answer
to the query. The framework is evaluated on major Video QA datasets,
demonstrating clear benefits of the object-centric approach to video reasoning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Camera Alignment Network for Unsupervised Cross-camera Person Re-identification. (arXiv:1908.00862v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lei Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_J/0/1/0/all/0/1">Jing Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yinghuan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xin Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.00862">
                                    <div class="article-summary-box-inner">
                                        <span>In person re-identification (Re-ID), supervised methods usually need a large
amount of expensive label information, while unsupervised ones are still unable
to deliver satisfactory identification performance. In this paper, we introduce
a novel person Re-ID task called unsupervised cross-camera person Re-ID, which
only needs the within-camera (intra-camera) label information but not
cross-camera (inter-camera) labels which are more expensive to obtain. In
real-world applications, the intra-camera label information can be easily
captured by tracking algorithms or few manual annotations. In this situation,
the main challenge becomes the distribution discrepancy across different camera
views, caused by the various body pose, occlusion, image resolution,
illumination conditions, and background noises in different cameras. To address
this situation, we propose a novel Adversarial Camera Alignment Network (ACAN)
for unsupervised cross-camera person Re-ID. It consists of the camera-alignment
task and the supervised within-camera learning task. To achieve the camera
alignment, we develop a Multi-Camera Adversarial Learning (MCAL) to map images
of different cameras into a shared subspace. Particularly, we investigate two
different schemes, including the existing GRL (i.e., gradient reversal layer)
scheme and the proposed scheme called &quot;other camera equiprobability&quot; (OCE), to
conduct the multi-camera adversarial task. Based on this shared subspace, we
then leverage the within-camera labels to train the network. Extensive
experiments on five large-scale datasets demonstrate the superiority of ACAN
over multiple state-of-the-art unsupervised methods that take advantage of
labeled source domains and generated images by GAN-based models. In particular,
we verify that the proposed multi-camera adversarial task does contribute to
the significant improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Detect Adversarial Examples Based on Class Scores. (arXiv:2107.04435v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Uelwer_T/0/1/0/all/0/1">Tobias Uelwer</a>, <a href="http://arxiv.org/find/cs/1/au:+Michels_F/0/1/0/all/0/1">Felix Michels</a>, <a href="http://arxiv.org/find/cs/1/au:+Candido_O/0/1/0/all/0/1">Oliver De Candido</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04435">
                                    <div class="article-summary-box-inner">
                                        <span>Given the increasing threat of adversarial attacks on deep neural networks
(DNNs), research on efficient detection methods is more important than ever. In
this work, we take a closer look at adversarial attack detection based on the
class scores of an already trained classification model. We propose to train a
support vector machine (SVM) on the class scores to detect adversarial
examples. Our method is able to detect adversarial examples generated by
various attacks, and can be easily adopted to a plethora of deep classification
models. We show that our approach yields an improved detection rate compared to
an existing method, whilst being easy to implement. We perform an extensive
empirical analysis on different deep classification models, investigating
various state-of-the-art adversarial attacks. Moreover, we observe that our
proposed method is better at detecting a combination of adversarial attacks.
This work indicates the potential of detecting various adversarial attacks
simply by using the class scores of an already trained classification model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio-visual Attentive Fusion for Continuous Emotion Recognition. (arXiv:2107.01175v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Su Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01175">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an audio-visual spatial-temporal deep neural network with: (1) a
visual block containing a pretrained 2D-CNN followed by a temporal
convolutional network (TCN); (2) an aural block containing several parallel
TCNs; and (3) a leader-follower attentive fusion block combining the
audio-visual information. The TCN with large history coverage enables our model
to exploit spatial-temporal information within a much larger window length
(i.e., 300) than that from the baseline and state-of-the-art methods (i.e., 36
or 48). The fusion block emphasizes the visual modality while exploits the
noisy aural modality using the inter-modality attention mechanism. To make full
use of the data and alleviate over-fitting, cross-validation is carried out on
the training and validation set. The concordance correlation coefficient (CCC)
centering is used to merge the results from each fold. On the development set,
the achieved CCC is 0.469 for valence and 0.649 for arousal, which
significantly outperforms the baseline method with the corresponding CCC of
0.210 and 0.230 for valence and arousal, respectively. The code is available at
https://github.com/sucv/ABAW2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information-Theoretic Registration with Explicit Reorientation of Diffusion-Weighted Images. (arXiv:1905.12056v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jensen_H/0/1/0/all/0/1">Henrik Gr&#xf8;nholt Jensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lauze_F/0/1/0/all/0/1">Fran&#xe7;ois Lauze</a>, <a href="http://arxiv.org/find/cs/1/au:+Darkner_S/0/1/0/all/0/1">Sune Darkner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.12056">
                                    <div class="article-summary-box-inner">
                                        <span>We present an information-theoretic approach to the registration of images
with directional information, and especially for diffusion-Weighted Images
(DWI), with explicit optimization over the directional scale. We call it
Locally Orderless Registration with Directions (LORD). We focus on normalized
mutual information as a robust information-theoretic similarity measure for
DWI. The framework is an extension of the LOR-DWI density-based hierarchical
scale-space model that varies and optimizes the integration, spatial,
directional, and intensity scales. As affine transformations are insufficient
for inter-subject registration, we extend the model to non-rigid deformations.
We illustrate that the proposed model deforms orientation distribution
functions (ODFs) correctly and is capable of handling the classic complex
challenges in DWI-registrations, such as the registration of fiber-crossings
along with kissing, fanning, and interleaving fibers. Our experimental results
clearly illustrate a novel promising regularizing effect, that comes from the
nonlinear orientation-based cost function. We show the properties of the
different image scales and, we show that including orientational information in
our model makes the model better at retrieving deformations in contrast to
standard scalar-based registration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResT: An Efficient Transformer for Visual Recognition. (arXiv:2105.13677v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qinglong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yubin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13677">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents an efficient multi-scale vision Transformer, called ResT,
that capably served as a general-purpose backbone for image recognition. Unlike
existing Transformer methods, which employ standard Transformer blocks to
tackle raw images with a fixed resolution, our ResT have several advantages:
(1) A memory-efficient multi-head self-attention is built, which compresses the
memory by a simple depth-wise convolution, and projects the interaction across
the attention-heads dimension while keeping the diversity ability of
multi-heads; (2) Position encoding is constructed as spatial attention, which
is more flexible and can tackle with input images of arbitrary size without
interpolation or fine-tune; (3) Instead of the straightforward tokenization at
the beginning of each stage, we design the patch embedding as a stack of
overlapping convolution operation with stride on the 2D-reshaped token map. We
comprehensively validate ResT on image classification and downstream tasks.
Experimental results show that the proposed ResT can outperform the recently
state-of-the-art backbones by a large margin, demonstrating the potential of
ResT as strong backbones. The code and models will be made publicly available
at https://github.com/wofmanaf/ResT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prior-Guided Multi-View 3D Head Reconstruction. (arXiv:2107.04277v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xueying Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yudong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhongqi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Juyong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04277">
                                    <div class="article-summary-box-inner">
                                        <span>Recovering a 3D head model including the complete face and hair regions is
still a challenging problem in computer vision and graphics. In this paper, we
consider this problem with a few multi-view portrait images as input. Previous
multi-view stereo methods, either based on the optimization strategies or deep
learning techniques, suffer from low-frequency geometric structures such as
unclear head structures and inaccurate reconstruction in hair regions. To
tackle this problem, we propose a prior-guided implicit neural rendering
network. Specifically, we model the head geometry with a learnable signed
distance field (SDF) and optimize it via an implicit differentiable renderer
with the guidance of some human head priors, including the facial prior
knowledge, head semantic segmentation information and 2D hair orientation maps.
The utilization of these priors can improve the reconstruction accuracy and
robustness, leading to a high-quality integrated 3D head model. Extensive
ablation studies and comparisons with state-of-the-art methods demonstrate that
our method could produce high-fidelity 3D head geometries with the guidance of
these priors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-Awareness Attention for Few-Shot Object Detection. (arXiv:2102.12152v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tung-I Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yueh-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hung-Ting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yu-Cheng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yu-Hsiang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_J/0/1/0/all/0/1">Jia-Fong Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Winston H. Hsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12152">
                                    <div class="article-summary-box-inner">
                                        <span>While recent progress has significantly boosted few-shot classification (FSC)
performance, few-shot object detection (FSOD) remains challenging for modern
learning systems. Existing FSOD systems follow FSC approaches, ignoring the
issues of spatial misalignment and vagueness in class representations, and
consequently result in low performance. Observing this, we propose a novel
Dual-Awareness Attention (DAnA) mechanism that can adaptively generate
query-position-aware (QPA) support features and guide the detection networks
precisely. The generated QPA features represent local information of a support
image conditioned on a given region of the query. By taking the spatial
relationships across different images into consideration, our approach
conspicuously outperforms previous FSOD methods (+6.9 AP relatively) and
achieves remarkable results even under a challenging cross-dataset evaluation
setting. Furthermore, the proposed DAnA component is flexible and adaptable to
multiple existing object detection frameworks. By equipping DAnA, conventional
object detection models, Faster R-CNN and RetinaNet, which are not designed
explicitly for few-shot learning, reach state-of-the-art performance in FSOD
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CMRNet: Camera to LiDAR-Map Registration. (arXiv:1906.10109v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cattaneo_D/0/1/0/all/0/1">Daniele Cattaneo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaghi_M/0/1/0/all/0/1">Matteo Vaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballardini_A/0/1/0/all/0/1">Augusto Luis Ballardini</a>, <a href="http://arxiv.org/find/cs/1/au:+Fontana_S/0/1/0/all/0/1">Simone Fontana</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorrenti_D/0/1/0/all/0/1">Domenico Giorgio Sorrenti</a>, <a href="http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1">Wolfram Burgard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.10109">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present CMRNet, a realtime approach based on a Convolutional
Neural Network to localize an RGB image of a scene in a map built from LiDAR
data. Our network is not trained in the working area, i.e. CMRNet does not
learn the map. Instead it learns to match an image to the map. We validate our
approach on the KITTI dataset, processing each frame independently without any
tracking procedure. CMRNet achieves 0.27m and 1.07deg median localization
accuracy on the sequence 00 of the odometry dataset, starting from a rough pose
estimate displaced up to 3.5m and 17deg. To the best of our knowledge this is
the first CNN-based approach that learns to match images from a monocular
camera to a given, preexisting 3D LiDAR-map.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Negative Transfer. (arXiv:2009.00909v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Lingfei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongrui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00909">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning (TL) tries to utilize data or knowledge from one or more
source domains to facilitate the learning in a target domain. It is
particularly useful when the target domain has few or no labeled data, due to
annotation expense, privacy concerns, etc. Unfortunately, the effectiveness of
TL is not always guaranteed. Negative transfer (NT), i.e., the source domain
data/knowledge cause reduced learning performance in the target domain, has
been a long-standing and challenging problem in TL. Various approaches to
handle NT have been proposed in the literature. However, this filed lacks a
systematic survey on the formalization of NT, their factors and the algorithms
that handle NT. This paper proposes to fill this gap. First, the definition of
negative transfer is considered and a taxonomy of the factors are discussed.
Then, near fifty representative approaches for handling NT are categorized and
reviewed, from four perspectives: secure transfer, domain similarity
estimation, distant transfer and negative transfer mitigation. NT in related
fields, e.g., multi-task learning, lifelong learning, and adversarial attacks
are also discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">iGibson, a Simulation Environment for Interactive Tasks in Large Realistic Scenes. (arXiv:2012.02924v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1">Bokui Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_F/0/1/0/all/0/1">Fei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chengshu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_Martin_R/0/1/0/all/0/1">Roberto Mart&#xed;n-Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Linxi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_DArpino_C/0/1/0/all/0/1">Claudia P&#xe9;rez-D&#x27;Arpino</a>, <a href="http://arxiv.org/find/cs/1/au:+Buch_S/0/1/0/all/0/1">Shyamal Buch</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1">Sanjana Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Tchapmi_L/0/1/0/all/0/1">Lyne P. Tchapmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tchapmi_M/0/1/0/all/0/1">Micael E. Tchapmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vainio_K/0/1/0/all/0/1">Kent Vainio</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1">Silvio Savarese</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02924">
                                    <div class="article-summary-box-inner">
                                        <span>We present iGibson, a novel simulation environment to develop robotic
solutions for interactive tasks in large-scale realistic scenes. Our
environment contains 15 fully interactive home-sized scenes with 108 rooms
populated with rigid and articulated objects. The scenes are replicas of
real-world homes, with distribution and the layout of objects aligned to those
of the real world. iGibson integrates several key features to facilitate the
study of interactive tasks: i) generation of high-quality virtual sensor
signals (RGB, depth, segmentation, LiDAR, flow and so on), ii) domain
randomization to change the materials of the objects (both visual and physical)
and/or their shapes, iii) integrated sampling-based motion planners to generate
collision-free trajectories for robot bases and arms, and iv) intuitive
human-iGibson interface that enables efficient collection of human
demonstrations. Through experiments, we show that the full interactivity of the
scenes enables agents to learn useful visual representations that accelerate
the training of downstream manipulation tasks. We also show that iGibson
features enable the generalization of navigation agents, and that the
human-iGibson interface and integrated motion planners facilitate efficient
imitation learning of human demonstrated (mobile) manipulation behaviors.
iGibson is open-source, equipped with comprehensive examples and documentation.
For more information, visit our project website:
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASC-Net : Adversarial-based Selective Network for Unsupervised Anomaly Segmentation. (arXiv:2103.03664v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dey_R/0/1/0/all/0/1">Raunak Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yi Hong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03664">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a neural network framework, utilizing adversarial learning to
partition an image into two cuts, with one cut falling into a reference
distribution provided by the user. This concept tackles the task of
unsupervised anomaly segmentation, which has attracted increasing attention in
recent years due to their broad applications in tasks with unlabelled data.
This Adversarial-based Selective Cutting network (ASC-Net) bridges the two
domains of cluster-based deep learning methods and adversarial-based
anomaly/novelty detection algorithms. We evaluate this unsupervised learning
model on BraTS brain tumor segmentation, LiTS liver lesion segmentation, and
MS-SEG2015 segmentation tasks. Compared to existing methods like the AnoGAN
family, our model demonstrates tremendous performance gains in unsupervised
anomaly segmentation tasks. Although there is still room to further improve
performance compared to supervised learning algorithms, the promising
experimental results shed light on building an unsupervised learning algorithm
using user-defined knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MutualEyeContact: A conversation analysis tool with focus on eye contact. (arXiv:2107.04476v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schafer_A/0/1/0/all/0/1">Alexander Sch&#xe4;fer</a>, <a href="http://arxiv.org/find/cs/1/au:+Isomura_T/0/1/0/all/0/1">Tomoko Isomura</a>, <a href="http://arxiv.org/find/cs/1/au:+Reis_G/0/1/0/all/0/1">Gerd Reis</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_K/0/1/0/all/0/1">Katsumi Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1">Didier Stricker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04476">
                                    <div class="article-summary-box-inner">
                                        <span>Eye contact between individuals is particularly important for understanding
human behaviour. To further investigate the importance of eye contact in social
interactions, portable eye tracking technology seems to be a natural choice.
However, the analysis of available data can become quite complex. Scientists
need data that is calculated quickly and accurately. Additionally, the relevant
data must be automatically separated to save time. In this work, we propose a
tool called MutualEyeContact which excels in those tasks and can help
scientists to understand the importance of (mutual) eye contact in social
interactions. We combine state-of-the-art eye tracking with face recognition
based on machine learning and provide a tool for analysis and visualization of
social interaction sessions. This work is a joint collaboration of computer
scientists and cognitive scientists. It combines the fields of social and
behavioural science with computer vision and deep learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Activated Gradients for Deep Neural Networks. (arXiv:2107.04228v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liangming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1">Xiaohao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Long Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_M/0/1/0/all/0/1">Mingsheng Shang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04228">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks often suffer from poor performance or even training
failure due to the ill-conditioned problem, the vanishing/exploding gradient
problem, and the saddle point problem. In this paper, a novel method by acting
the gradient activation function (GAF) on the gradient is proposed to handle
these challenges. Intuitively, the GAF enlarges the tiny gradients and
restricts the large gradient. Theoretically, this paper gives conditions that
the GAF needs to meet, and on this basis, proves that the GAF alleviates the
problems mentioned above. In addition, this paper proves that the convergence
rate of SGD with the GAF is faster than that without the GAF under some
assumptions. Furthermore, experiments on CIFAR, ImageNet, and PASCAL visual
object classes confirm the GAF&#x27;s effectiveness. The experimental results also
demonstrate that the proposed method is able to be adopted in various deep
neural networks to improve their performance. The source code is publicly
available at
https://github.com/LongJin-lab/Activated-Gradients-for-Deep-Neural-Networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantile-Quantile Embedding for Distribution Transformation and Manifold Embedding with Ability to Choose the Embedding Distribution. (arXiv:2006.11385v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1">Benyamin Ghojogh</a>, <a href="http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1">Fakhri Karray</a>, <a href="http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1">Mark Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11385">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new embedding method, named Quantile-Quantile Embedding (QQE),
for distribution transformation and manifold embedding with the ability to
choose the embedding distribution. QQE, which uses the concept of
quantile-quantile plot from visual statistical tests, can transform the
distribution of data to any theoretical desired distribution or empirical
reference sample. Moreover, QQE gives the user a choice of embedding
distribution in embedding the manifold of data into the low dimensional
embedding space. It can also be used for modifying the embedding distribution
of other dimensionality reduction methods, such as PCA, t-SNE, and deep metric
learning, for better representation or visualization of data. We propose QQE in
both unsupervised and supervised forms. QQE can also transform a distribution
to either an exact reference distribution or its shape. We show that QQE allows
for better discrimination of classes in some cases. Our experiments on
different synthetic and image datasets show the effectiveness of the proposed
embedding method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAC Bayesian Performance Guarantees for Deep (Stochastic) Networks in Medical Imaging. (arXiv:2104.05600v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sicilia_A/0/1/0/all/0/1">Anthony Sicilia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xingchen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sosnovskikh_A/0/1/0/all/0/1">Anastasia Sosnovskikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Seong Jae Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05600">
                                    <div class="article-summary-box-inner">
                                        <span>Application of deep neural networks to medical imaging tasks has in some
sense become commonplace. Still, a &quot;thorn in the side&quot; of the deep learning
movement is the argument that deep networks are prone to overfitting and are
thus unable to generalize well when datasets are small (as is common in medical
imaging tasks). One way to bolster confidence is to provide mathematical
guarantees, or bounds, on network performance after training which explicitly
quantify the possibility of overfitting. In this work, we explore recent
advances using the PAC-Bayesian framework to provide bounds on generalization
error for large (stochastic) networks. While previous efforts focus on
classification in larger natural image datasets (e.g., MNIST and CIFAR-10), we
apply these techniques to both classification and segmentation in a smaller
medical imagining dataset: the ISIC 2018 challenge set. We observe the
resultant bounds are competitive compared to a simpler baseline, while also
being more explainable and alleviating the need for holdout sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mutually-aware Sub-Graphs Differentiable Architecture Search. (arXiv:2107.04324v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Haoxian Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Sheng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yujie Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Weilin Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04324">
                                    <div class="article-summary-box-inner">
                                        <span>Differentiable architecture search is prevalent in the field of NAS because
of its simplicity and efficiency, where two paradigms, multi-path algorithms
and single-path methods, are dominated. Multi-path framework (e.g. DARTS) is
intuitive but suffers from memory usage and training collapse. Single-path
methods (e.g.GDAS and ProxylessNAS) mitigate the memory issue and shrink the
gap between searching and evaluation but sacrifice the performance. In this
paper, we propose a conceptually simple yet efficient method to bridge these
two paradigms, referred as Mutually-aware Sub-Graphs Differentiable
Architecture Search (MSG-DAS). The core of our framework is a differentiable
Gumbel-TopK sampler that produces multiple mutually exclusive single-path
sub-graphs. To alleviate the severer skip-connect issue brought by multiple
sub-graphs setting, we propose a Dropblock-Identity module to stabilize the
optimization. To make best use of the available models (super-net and
sub-graphs), we introduce a memory-efficient super-net guidance distillation to
improve training. The proposed framework strikes a balance between flexible
memory usage and searching quality. We demonstrate the effectiveness of our
methods on ImageNet and CIFAR10, where the searched models show a comparable
performance as the most recent approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Icon Annotation For Mobile Applications. (arXiv:2107.04452v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zang_X/0/1/0/all/0/1">Xiaoxue Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Ying Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jindong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04452">
                                    <div class="article-summary-box-inner">
                                        <span>Annotating user interfaces (UIs) that involves localization and
classification of meaningful UI elements on a screen is a critical step for
many mobile applications such as screen readers and voice control of devices.
Annotating object icons, such as menu, search, and arrow backward, is
especially challenging due to the lack of explicit labels on screens, their
similarity to pictures, and their diverse shapes. Existing studies either use
view hierarchy or pixel based methods to tackle the task. Pixel based
approaches are more popular as view hierarchy features on mobile platforms are
often incomplete or inaccurate, however it leaves out instructional information
in the view hierarchy such as resource-ids or content descriptions. We propose
a novel deep learning based multi-modal approach that combines the benefits of
both pixel and view hierarchy features as well as leverages the
state-of-the-art object detection techniques. In order to demonstrate the
utility provided, we create a high quality UI dataset by manually annotating
the most commonly used 29 icons in Rico, a large scale mobile design dataset
consisting of 72k UI screenshots. The experimental results indicate the
effectiveness of our multi-modal approach. Our model not only outperforms a
widely used object classification baseline but also pixel based object
detection models. Our study sheds light on how to combine view hierarchy with
pixel features for annotating UI elements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable Compositional Convolutional Neural Networks. (arXiv:2107.04474v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">Wen Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhihua Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shikun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Binbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Jiaqi Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Ping Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Quanshi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04474">
                                    <div class="article-summary-box-inner">
                                        <span>The reasonable definition of semantic interpretability presents the core
challenge in explainable AI. This paper proposes a method to modify a
traditional convolutional neural network (CNN) into an interpretable
compositional CNN, in order to learn filters that encode meaningful visual
patterns in intermediate convolutional layers. In a compositional CNN, each
filter is supposed to consistently represent a specific compositional object
part or image region with a clear meaning. The compositional CNN learns from
image labels for classification without any annotations of parts or regions for
supervision. Our method can be broadly applied to different types of CNNs.
Experiments have demonstrated the effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-modal Attention for MRI and Ultrasound Volume Registration. (arXiv:2107.04548v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xinrui Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hengtao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xuanang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_H/0/1/0/all/0/1">Hanqing Chao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Sheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Turkbey_B/0/1/0/all/0/1">Baris Turkbey</a>, <a href="http://arxiv.org/find/cs/1/au:+Wood_B/0/1/0/all/0/1">Bradford J. Wood</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Ge Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_P/0/1/0/all/0/1">Pingkun Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04548">
                                    <div class="article-summary-box-inner">
                                        <span>Prostate cancer biopsy benefits from accurate fusion of transrectal
ultrasound (TRUS) and magnetic resonance (MR) images. In the past few years,
convolutional neural networks (CNNs) have been proved powerful in extracting
image features crucial for image registration. However, challenging
applications and recent advances in computer vision suggest that CNNs are quite
limited in its ability to understand spatial correspondence between features, a
task in which the self-attention mechanism excels. This paper aims to develop a
self-attention mechanism specifically for cross-modal image registration. Our
proposed cross-modal attention block effectively maps each of the features in
one volume to all features in the corresponding volume. Our experimental
results demonstrate that a CNN network designed with the cross-modal attention
block embedded outperforms an advanced CNN network 10 times of its size. We
also incorporated visualization techniques to improve the interpretability of
our network. The source code of our work is available at
https://github.com/DIAL-RPI/Attention-Reg .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncovering the Connections Between Adversarial Transferability and Knowledge Transferability. (arXiv:2006.14512v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1">Kaizhao Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jacky Y. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuolin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1">Oluwasanmi Koyejo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.14512">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge transferability, or transfer learning, has been widely adopted to
allow a pre-trained model in the source domain to be effectively adapted to
downstream tasks in the target domain. It is thus important to explore and
understand the factors affecting knowledge transferability. In this paper, as
the first work, we analyze and demonstrate the connections between knowledge
transferability and another important phenomenon--adversarial transferability,
\emph{i.e.}, adversarial examples generated against one model can be
transferred to attack other models. Our theoretical studies show that
adversarial transferability indicates knowledge transferability and vice versa.
Moreover, based on the theoretical insights, we propose two practical
adversarial transferability metrics to characterize this process, serving as
bidirectional indicators between adversarial and knowledge transferability. We
conduct extensive experiments for different scenarios on diverse datasets,
showing a positive correlation between adversarial transferability and
knowledge transferability. Our findings will shed light on future research
about effective knowledge transfer learning and adversarial transferability
analyses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hacking VMAF and VMAF NEG: metrics vulnerability to different preprocessing. (arXiv:2107.04510v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Siniukov_M/0/1/0/all/0/1">Maksim Siniukov</a>, <a href="http://arxiv.org/find/cs/1/au:+Antsiferova_A/0/1/0/all/0/1">Anastasia Antsiferova</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulikov_D/0/1/0/all/0/1">Dmitriy Kulikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Vatolin_D/0/1/0/all/0/1">Dmitriy Vatolin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04510">
                                    <div class="article-summary-box-inner">
                                        <span>Video quality measurement plays a critical role in the development of video
processing applications. In this paper, we show how popular quality metrics
VMAF and its tuning-resistant version VMAF NEG can be artificially increased by
video preprocessing. We propose a pipeline for tuning parameters of processing
algorithms that allows increasing VMAF by up to 218.8%. A subjective comparison
of preprocessed videos showed that with the majority of methods visual quality
drops down or stays unchanged. We show that VMAF NEG scores can also be
increased by some preprocessing methods by up to 23.6%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient-Based Quantification of Epistemic Uncertainty for Deep Object Detectors. (arXiv:2107.04517v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Riedlinger_T/0/1/0/all/0/1">Tobias Riedlinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1">Matthias Rottmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schubert_M/0/1/0/all/0/1">Marius Schubert</a>, <a href="http://arxiv.org/find/cs/1/au:+Gottschalk_H/0/1/0/all/0/1">Hanno Gottschalk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04517">
                                    <div class="article-summary-box-inner">
                                        <span>Reliable epistemic uncertainty estimation is an essential component for
backend applications of deep object detectors in safety-critical environments.
Modern network architectures tend to give poorly calibrated confidences with
limited predictive power. Here, we introduce novel gradient-based uncertainty
metrics and investigate them for different object detection architectures.
Experiments on the MS COCO, PASCAL VOC and the KITTI dataset show significant
improvements in true positive / false positive discrimination and prediction of
intersection over union as compared to network confidence. We also find
improvement over Monte-Carlo dropout uncertainty metrics and further
significant boosts by aggregating different sources of uncertainty metrics.The
resulting uncertainty models generate well-calibrated confidences in all
instances. Furthermore, we implement our uncertainty quantification models into
object detection pipelines as a means to discern true against false
predictions, replacing the ordinary score-threshold-based decision rule. In our
experiments, we achieve a significant boost in detection performance in terms
of mean average precision. With respect to computational complexity, we find
that computing gradient uncertainty metrics results in floating point operation
counts similar to those of Monte-Carlo dropout.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Score refinement for confidence-based 3D multi-object tracking. (arXiv:2107.04327v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Benbarka_N/0/1/0/all/0/1">Nuri Benbarka</a>, <a href="http://arxiv.org/find/cs/1/au:+Schroder_J/0/1/0/all/0/1">Jona Schr&#xf6;der</a>, <a href="http://arxiv.org/find/cs/1/au:+Zell_A/0/1/0/all/0/1">Andreas Zell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04327">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-object tracking is a critical component in autonomous navigation, as it
provides valuable information for decision-making. Many researchers tackled the
3D multi-object tracking task by filtering out the frame-by-frame 3D
detections; however, their focus was mainly on finding useful features or
proper matching metrics. Our work focuses on a neglected part of the tracking
system: score refinement and tracklet termination. We show that manipulating
the scores depending on time consistency while terminating the tracklets
depending on the tracklet score improves tracking results. We do this by
increasing the matched tracklets&#x27; score with score update functions and
decreasing the unmatched tracklets&#x27; score. Compared to count-based methods, our
method consistently produces better AMOTA and MOTA scores when utilizing
various detectors and filtering algorithms on different datasets. The
improvements in AMOTA score went up to 1.83 and 2.96 in MOTA. We also used our
method as a late-fusion ensembling method, and it performed better than
voting-based ensemble methods by a solid margin. It achieved an AMOTA score of
67.6 on nuScenes test evaluation, which is comparable to other state-of-the-art
trackers. Code is publicly available at:
\url{https://github.com/cogsys-tuebingen/CBMOT}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hoechst Is All You Need: LymphocyteClassification with Deep Learning. (arXiv:2107.04388v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cooper_J/0/1/0/all/0/1">Jessica Cooper</a>, <a href="http://arxiv.org/find/cs/1/au:+Um_I/0/1/0/all/0/1">In Hwa Um</a>, <a href="http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1">Ognjen Arandjelovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Harrison_D/0/1/0/all/0/1">David J Harrison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04388">
                                    <div class="article-summary-box-inner">
                                        <span>Multiplex immunofluorescence and immunohistochemistry benefit patients by
allowing cancer pathologists to identify several proteins expressed on the
surface of cells, enabling cell classification, better understanding of the
tumour micro-environment, more accurate diagnoses, prognoses, and tailored
immunotherapy based on the immune status of individual patients. However, they
are expensive and time consuming processes which require complex staining and
imaging techniques by expert technicians. Hoechst staining is much cheaper and
easier to perform, but is not typically used in this case as it binds to DNA
rather than to the proteins targeted by immunofluorescent techniques, and it
was not previously thought possible to differentiate cells expressing these
proteins based only on DNA morphology. In this work we show otherwise, training
a deep convolutional neural network to identify cells expressing three proteins
(T lymphocyte markers CD3 and CD8, and the B lymphocyte marker CD20) with
greater than 90% precision and recall, from Hoechst 33342 stained tissue only.
Our model learns previously unknown morphological features associated with
expression of these proteins which can be used to accurately differentiate
lymphocyte subtypes for use in key prognostic metrics such as assessment of
immune cell infiltration,and thereby predict and improve patient outcomes
without the need for costly multiplex immunofluorescence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JPGNet: Joint Predictive Filtering and Generative Network for Image Inpainting. (arXiv:2107.04281v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoguang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Juefei_Xu_F/0/1/0/all/0/1">Felix Juefei-Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hongkai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+wang_S/0/1/0/all/0/1">Song wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04281">
                                    <div class="article-summary-box-inner">
                                        <span>Image inpainting aims to restore the missing regions and make the recovery
results identical to the originally complete image, which is different from the
common generative task emphasizing the naturalness of generated images.
Nevertheless, existing works usually regard it as a pure generation problem and
employ cutting-edge generative techniques to address it. The generative
networks fill the main missing parts with realistic contents but usually
distort the local structures. In this paper, we formulate image inpainting as a
mix of two problems, i.e., predictive filtering and deep generation. Predictive
filtering is good at preserving local structures and removing artifacts but
falls short to complete the large missing regions. The deep generative network
can fill the numerous missing pixels based on the understanding of the whole
scene but hardly restores the details identical to the original ones. To make
use of their respective advantages, we propose the joint predictive filtering
and generative network (JPGNet) that contains three branches: predictive
filtering &amp; uncertainty network (PFUNet), deep generative network, and
uncertainty-aware fusion network (UAFNet). The PFUNet can adaptively predict
pixel-wise kernels for filtering-based inpainting according to the input image
and output an uncertainty map. This map indicates the pixels should be
processed by filtering or generative networks, which is further fed to the
UAFNet for a smart combination between filtering and generative results. Note
that, our method as a novel framework for the image inpainting problem can
benefit any existing generation-based methods. We validate our method on three
public datasets, i.e., Dunhuang, Places2, and CelebA, and demonstrate that our
method can enhance three state-of-the-art generative methods (i.e., StructFlow,
EdgeConnect, and RFRNet) significantly with the slightly extra time cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Segmentation on Multiple Visual Domains. (arXiv:2107.04326v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naber_F/0/1/0/all/0/1">Floris Naber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04326">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation models only perform well on the domain they are trained
on and datasets for training are scarce and often have a small label-spaces,
because the pixel level annotations required are expensive to make. Thus
training models on multiple existing domains is desired to increase the output
label-space. Current research shows that there is potential to improve accuracy
across datasets by using multi-domain training, but this has not yet been
successfully extended to datasets of three different non-overlapping domains
without manual labelling. In this paper a method for this is proposed for the
datasets Cityscapes, SUIM and SUN RGB-D, by creating a label-space that spans
all classes of the datasets. Duplicate classes are merged and discrepant
granularity is solved by keeping classes separate. Results show that accuracy
of the multi-domain model has higher accuracy than all baseline models
together, if hardware performance is equalized, as resources are not limitless,
showing that models benefit from additional data even from domains that have
nothing in common.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Farthest Point Sampling in Point-Wise Analysis. (arXiv:2107.04291v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yiqun Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lichang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haibin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1">Chongyang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xiaoguang Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04291">
                                    <div class="article-summary-box-inner">
                                        <span>Sampling, grouping, and aggregation are three important components in the
multi-scale analysis of point clouds. In this paper, we present a novel
data-driven sampler learning strategy for point-wise analysis tasks. Unlike the
widely used sampling technique, Farthest Point Sampling (FPS), we propose to
learn sampling and downstream applications jointly. Our key insight is that
uniform sampling methods like FPS are not always optimal for different tasks:
sampling more points around boundary areas can make the point-wise
classification easier for segmentation. Towards the end, we propose a novel
sampler learning strategy that learns sampling point displacement supervised by
task-related ground truth information and can be trained jointly with the
underlying tasks. We further demonstrate our methods in various point-wise
analysis architectures, including semantic part segmentation, point cloud
completion, and keypoint detection. Our experiments show that jointly learning
of the sampler and task brings remarkable improvement over previous baseline
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hepatocellular Carcinoma Segmentation fromDigital Subtraction Angiography Videos usingLearnable Temporal Difference. (arXiv:2107.04306v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Jiang_W/0/1/0/all/0/1">Wenting Jiang</a>, <a href="http://arxiv.org/find/eess/1/au:+Jiang_Y/0/1/0/all/0/1">Yicheng Jiang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Changmiao Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_X/0/1/0/all/0/1">Xiaoguang Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_S/0/1/0/all/0/1">Shuixing Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wan_X/0/1/0/all/0/1">Xiang Wan</a>, <a href="http://arxiv.org/find/eess/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04306">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic segmentation of hepatocellular carcinoma (HCC)in Digital
Subtraction Angiography (DSA) videos can assist radiologistsin efficient
diagnosis of HCC and accurate evaluation of tumors in clinical practice. Few
studies have investigated HCC segmentation from DSAvideos. It shows great
challenging due to motion artifacts in filming, ambiguous boundaries of tumor
regions and high similarity in imaging toother anatomical tissues. In this
paper, we raise the problem of HCCsegmentation in DSA videos, and build our own
DSA dataset. We alsopropose a novel segmentation network called DSA-LTDNet,
including asegmentation sub-network, a temporal difference learning (TDL)
moduleand a liver region segmentation (LRS) sub-network for providing
additional guidance. DSA-LTDNet is preferable for learning the latent
motioninformation from DSA videos proactively and boosting segmentation
performance. All of experiments are conducted on our self-collected
dataset.Experimental results show that DSA-LTDNet increases the DICE scoreby
nearly 4% compared to the U-Net baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-task Mean Teacher for Semi-supervised Facial Affective Behavior Analysis. (arXiv:2107.04225v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lingfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shisen Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04225">
                                    <div class="article-summary-box-inner">
                                        <span>Affective Behavior Analysis is an important part in human?computer
interaction. Existing successful affective behavior analysis method such as
TSAV[9] suffer from challenge of incomplete labeled datasets. To boost its
performance, this paper presents a multi-task mean teacher model for
semi?supervised Affective Behavior Analysis to learn from missing labels and
exploring the learning of multiple correlated task simultaneously. To be
specific, we first utilize TSAV as baseline model to simultaneously recognize
the three tasks. We have modified the preprocessing method of rendering mask to
provide better semantics information. After that, we extended TSAV model to
semi-supervised model using mean teacher, which allow it to be benefited from
unlabeled data. Experimental results on validation datasets show that our
method achieves better performance than TSAV model, which verifies that the
proposed network can effectively learn additional unlabeled data to boost the
affective behavior analysis performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LIFE: A Generalizable Autodidactic Pipeline for 3D OCT-A Vessel Segmentation. (arXiv:2107.04282v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hu_D/0/1/0/all/0/1">Dewei Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Cui_C/0/1/0/all/0/1">Can Cui</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Larson_K/0/1/0/all/0/1">Kathleen E. Larson</a>, <a href="http://arxiv.org/find/eess/1/au:+Tao_Y/0/1/0/all/0/1">Yuankai K. Tao</a>, <a href="http://arxiv.org/find/eess/1/au:+Oguz_I/0/1/0/all/0/1">Ipek Oguz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04282">
                                    <div class="article-summary-box-inner">
                                        <span>Optical coherence tomography (OCT) is a non-invasive imaging technique widely
used for ophthalmology. It can be extended to OCT angiography (OCT-A), which
reveals the retinal vasculature with improved contrast. Recent deep learning
algorithms produced promising vascular segmentation results; however, 3D
retinal vessel segmentation remains difficult due to the lack of manually
annotated training data. We propose a learning-based method that is only
supervised by a self-synthesized modality named local intensity fusion (LIF).
LIF is a capillary-enhanced volume computed directly from the input OCT-A. We
then construct the local intensity fusion encoder (LIFE) to map a given OCT-A
volume and its LIF counterpart to a shared latent space. The latent space of
LIFE has the same dimensions as the input data and it contains features common
to both modalities. By binarizing this latent space, we obtain a volumetric
vessel segmentation. Our method is evaluated in a human fovea OCT-A and three
zebrafish OCT-A volumes with manual labels. It yields a Dice score of 0.7736 on
human data and 0.8594 +/- 0.0275 on zebrafish data, a dramatic improvement over
existing unsupervised algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CASPIANET++: A Multidimensional Channel-Spatial Asymmetric Attention Network with Noisy Student Curriculum Learning Paradigm for Brain Tumor Segmentation. (arXiv:2107.04099v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Liew_A/0/1/0/all/0/1">Andrea Liew</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_C/0/1/0/all/0/1">Chun Cheng Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Lan_B/0/1/0/all/0/1">Boon Leong Lan</a>, <a href="http://arxiv.org/find/eess/1/au:+Tan_M/0/1/0/all/0/1">Maxine Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04099">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have been used quite successfully for
semantic segmentation of brain tumors. However, current CNNs and attention
mechanisms are stochastic in nature and neglect the morphological indicators
used by radiologists to manually annotate regions of interest. In this paper,
we introduce a channel and spatial wise asymmetric attention (CASPIAN) by
leveraging the inherent structure of tumors to detect regions of saliency. To
demonstrate the efficacy of our proposed layer, we integrate this into a
well-established convolutional neural network (CNN) architecture to achieve
higher Dice scores, with less GPU resources. Also, we investigate the inclusion
of auxiliary multiscale and multiplanar attention branches to increase the
spatial context crucial in semantic segmentation tasks. The resulting
architecture is the new CASPIANET++, which achieves Dice Scores of 91.19% whole
tumor, 87.6% for tumor core and 81.03% for enhancing tumor. Furthermore, driven
by the scarcity of brain tumor data, we investigate the Noisy Student method
for segmentation tasks. Our new Noisy Student Curriculum Learning paradigm,
which infuses noise incrementally to increase the complexity of the training
images exposed to the network, further boosts the enhancing tumor region to
81.53%. Additional validation performed on the BraTS2020 data shows that the
Noisy Student Curriculum Learning method works well without any additional
training or finetuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal Association based Grouping for Form Structure Extraction. (arXiv:2107.04396v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_M/0/1/0/all/0/1">Milan Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_M/0/1/0/all/0/1">Mausoom Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1">Hiresh Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1">Balaji Krishnamurthy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04396">
                                    <div class="article-summary-box-inner">
                                        <span>Document structure extraction has been a widely researched area for decades.
Recent work in this direction has been deep learning-based, mostly focusing on
extracting structure using fully convolution NN through semantic segmentation.
In this work, we present a novel multi-modal approach for form structure
extraction. Given simple elements such as textruns and widgets, we extract
higher-order structures such as TextBlocks, Text Fields, Choice Fields, and
Choice Groups, which are essential for information collection in forms. To
achieve this, we obtain a local image patch around each low-level element
(reference) by identifying candidate elements closest to it. We process textual
and spatial representation of candidates sequentially through a BiLSTM to
obtain context-aware representations and fuse them with image patch features
obtained by processing it through a CNN. Subsequently, the sequential decoder
takes this fused feature vector to predict the association type between
reference and candidates. These predicted associations are utilized to
determine larger structures through connected components analysis. Experimental
results show the effectiveness of our approach achieving a recall of 90.29%,
73.80%, 83.12%, and 52.72% for the above structures, respectively,
outperforming semantic segmentation baselines significantly. We show the
efficacy of our method through ablations, comparing it against using individual
modalities. We also introduce our new rich human-annotated Forms Dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially private training of neural networks with Langevin dynamics forcalibrated predictive uncertainty. (arXiv:2107.04296v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Knolle_M/0/1/0/all/0/1">Moritz Knolle</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziller_A/0/1/0/all/0/1">Alexander Ziller</a>, <a href="http://arxiv.org/find/cs/1/au:+Usynin_D/0/1/0/all/0/1">Dmitrii Usynin</a>, <a href="http://arxiv.org/find/cs/1/au:+Braren_R/0/1/0/all/0/1">Rickmer Braren</a>, <a href="http://arxiv.org/find/cs/1/au:+Makowski_M/0/1/0/all/0/1">Marcus R. Makowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04296">
                                    <div class="article-summary-box-inner">
                                        <span>We show that differentially private stochastic gradient descent (DP-SGD) can
yield poorly calibrated, overconfident deep learning models. This represents a
serious issue for safety-critical applications, e.g. in medical diagnosis. We
highlight and exploit parallels between stochastic gradient Langevin dynamics,
a scalable Bayesian inference technique for training deep neural networks, and
DP-SGD, in order to train differentially private, Bayesian neural networks with
minor adjustments to the original (DP-SGD) algorithm. Our approach provides
considerably more reliable uncertainty estimates than DP-SGD, as demonstrated
empirically by a reduction in expected calibration error (MNIST $\sim{5}$-fold,
Pediatric Pneumonia Dataset $\sim{2}$-fold).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UrbanScene3D: A Large Scale Urban Scene Dataset and Simulator. (arXiv:2107.04286v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yilin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1">Fuyou Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Hui Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04286">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to perceive the environments in different ways is essential to
robotic research. This involves the analysis of both 2D and 3D data sources. We
present a large scale urban scene dataset associated with a handy simulator
based on Unreal Engine 4 and AirSim, which consists of both man-made and
real-world reconstruction scenes in different scales, referred to as
UrbanScene3D. Unlike previous works that purely based on 2D information or
man-made 3D CAD models, UrbanScene3D contains both compact man-made models and
detailed real-world models reconstructed by aerial images. Each building has
been manually extracted from the entire scene model and then has been assigned
with a unique label, forming an instance segmentation map. The provided 3D
ground-truth textured models with instance segmentation labels in UrbanScene3D
allow users to obtain all kinds of data they would like to have: instance
segmentation map, depth map in arbitrary resolution, 3D point cloud/mesh in
both visible and invisible places, etc. In addition, with the help of AirSim,
users can also simulate the robots (cars/drones)to test a variety of autonomous
tasks in the proposed city environment. Please refer to our paper and
website(https://vcc.tech/UrbanScene3D/) for further details and applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-based Deep Generative Modelling for Document Layout Generation. (arXiv:2107.04357v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1">Sanket Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1">Pau Riba</a>, <a href="http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1">Josep Llad&#xf3;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_U/0/1/0/all/0/1">Umapada Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04357">
                                    <div class="article-summary-box-inner">
                                        <span>One of the major prerequisites for any deep learning approach is the
availability of large-scale training data. When dealing with scanned document
images in real world scenarios, the principal information of its content is
stored in the layout itself. In this work, we have proposed an automated deep
generative model using Graph Neural Networks (GNNs) to generate synthetic data
with highly variable and plausible document layouts that can be used to train
document interpretation systems, in this case, specially in digital mailroom
applications. It is also the first graph-based approach for document layout
generation task experimented on administrative document images, in this case,
invoices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Pixel-Matching for Video Object Segmentation. (arXiv:2107.04279v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Siyue Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1">Jimin Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">BingFeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_E/0/1/0/all/0/1">Eng Gee Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04279">
                                    <div class="article-summary-box-inner">
                                        <span>Video object segmentation, aiming to segment the foreground objects given the
annotation of the first frame, has been attracting increasing attentions. Many
state-of-the-art approaches have achieved great performance by relying on
online model updating or mask-propagation techniques. However, most online
models require high computational cost due to model fine-tuning during
inference. Most mask-propagation based models are faster but with relatively
low performance due to failure to adapt to object appearance variation. In this
paper, we are aiming to design a new model to make a good balance between speed
and performance. We propose a model, called NPMCA-net, which directly localizes
foreground objects based on mask-propagation and non-local technique by
matching pixels in reference and target frames. Since we bring in information
of both first and previous frames, our network is robust to large object
appearance variation, and can better adapt to occlusions. Extensive experiments
show that our approach can achieve a new state-of-the-art performance with a
fast speed at the same time (86.5% IoU on DAVIS-2016 and 72.2% IoU on
DAVIS-2017, with speed of 0.11s per frame) under the same level comparison.
Source code is available at https://github.com/siyueyu/NPMCA-net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Matrix Decomposition for Deep Convolutional Neural Networks Compression. (arXiv:2107.04386v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shaowu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jihao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Weize Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lei Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04386">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks (CNNs) with a large number of parameters
requires huge computational resources, which has limited the application of
CNNs on resources constrained appliances. Decomposition-based methods,
therefore, have been utilized to compress CNNs in recent years. However, since
the compression factor and performance are negatively correlated, the
state-of-the-art works either suffer from severe performance degradation or
have limited low compression factors. To overcome these problems, unlike
previous works compressing layers separately, we propose to compress CNNs and
alleviate performance degradation via joint matrix decomposition. The idea is
inspired by the fact that there are lots of repeated modules in CNNs, and by
projecting weights with the same structures into the same subspace, networks
can be further compressed and even accelerated. In particular, three joint
matrix decomposition schemes are developed, and the corresponding optimization
approaches based on Singular Values Decomposition are proposed. Extensive
experiments are conducted across three challenging compact CNNs and 3 benchmark
data sets to demonstrate the superior performance of our proposed algorithms.
As a result, our methods can compress the size of ResNet-34 by 22x with
slighter accuracy degradation compared with several state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning models for benign and malign Ocular Tumor Growth Estimation. (arXiv:2107.04220v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Goswami_M/0/1/0/all/0/1">Mayank Goswami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04220">
                                    <div class="article-summary-box-inner">
                                        <span>Relatively abundant availability of medical imaging data has provided
significant support in the development and testing of Neural Network based
image processing methods. Clinicians often face issues in selecting suitable
image processing algorithm for medical imaging data. A strategy for the
selection of a proper model is presented here. The training data set comprises
optical coherence tomography (OCT) and angiography (OCT-A) images of 50 mice
eyes with more than 100 days follow-up. The data contains images from treated
and untreated mouse eyes. Four deep learning variants are tested for automatic
(a) differentiation of tumor region with healthy retinal layer and (b)
segmentation of 3D ocular tumor volumes. Exhaustive sensitivity analysis of
deep learning models is performed with respect to the number of training and
testing images using 8 eight performance indices to study accuracy,
reliability/reproducibility, and speed. U-net with UVgg16 is best for malign
tumor data set with treatment (having considerable variation) and U-net with
Inception backbone for benign tumor data (with minor variation). Loss value and
root mean square error (R.M.S.E.) are found most and least sensitive
performance indices, respectively. The performance (via indices) is found to be
exponentially improving regarding a number of training images. The segmented
OCT-Angiography data shows that neovascularization drives the tumor volume.
Image analysis shows that photodynamic imaging-assisted tumor treatment
protocol is transforming an aggressively growing tumor into a cyst. An
empirical expression is obtained to help medical professionals to choose a
particular model given the number of images and types of characteristics. We
recommend that the presented exercise should be taken as standard practice
before employing a particular deep learning model for biomedical image
analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effectiveness of State-of-the-Art Super Resolution Algorithms in Surveillance Environment. (arXiv:2107.04133v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Farooq_M/0/1/0/all/0/1">Muhammad Ali Farooq</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Ammar Ali Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_A/0/1/0/all/0/1">Ansar Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Raza_R/0/1/0/all/0/1">Rana Hammad Raza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04133">
                                    <div class="article-summary-box-inner">
                                        <span>Image Super Resolution (SR) finds applications in areas where images need to
be closely inspected by the observer to extract enhanced information. One such
focused application is an offline forensic analysis of surveillance feeds. Due
to the limitations of camera hardware, camera pose, limited bandwidth, varying
illumination conditions, and occlusions, the quality of the surveillance feed
is significantly degraded at times, thereby compromising monitoring of
behavior, activities, and other sporadic information in the scene. For the
proposed research work, we have inspected the effectiveness of four
conventional yet effective SR algorithms and three deep learning-based SR
algorithms to seek the finest method that executes well in a surveillance
environment with limited training data op-tions. These algorithms generate an
enhanced resolution output image from a sin-gle low-resolution (LR) input
image. For performance analysis, a subset of 220 images from six surveillance
datasets has been used, consisting of individuals with varying distances from
the camera, changing illumination conditions, and complex backgrounds. The
performance of these algorithms has been evaluated and compared using both
qualitative and quantitative metrics. These SR algo-rithms have also been
compared based on face detection accuracy. By analyzing and comparing the
performance of all the algorithms, a Convolutional Neural Network (CNN) based
SR technique using an external dictionary proved to be best by achieving robust
face detection accuracy and scoring optimal quantitative metric results under
different surveillance conditions. This is because the CNN layers progressively
learn more complex features using an external dictionary.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Action Unit Detection with Joint Adaptive Attention and Graph Relation. (arXiv:2107.04389v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chenggong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Juan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1">Weilong Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_R/0/1/0/all/0/1">Ruomeng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhilei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04389">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes an approach to the facial action unit (AU) detection. In
this work, we present our submission to the Field Affective Behavior Analysis
(ABAW) 2021 competition. The proposed method uses the pre-trained JAA model as
the feature extractor, and extracts global features, face alignment features
and AU local features on the basis of multi-scale features. We take the AU
local features as the input of the graph convolution to further consider the
correlation between AU, and finally use the fused features to classify AU. The
detected accuracy was evaluated by 0.5*accuracy + 0.5*F1. Our model achieves
0.674 on the challenging Aff-Wild2 database.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wavelet Transform-assisted Adaptive Generative Modeling for Colorization. (arXiv:2107.04261v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wanyun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zichen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiegen Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04261">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised deep learning has recently demonstrated the promise to produce
high-quality samples. While it has tremendous potential to promote the image
colorization task, the performance is limited owing to the manifold hypothesis
in machine learning. This study presents a novel scheme that exploiting the
score-based generative model in wavelet domain to address the issue. By taking
advantage of the multi-scale and multi-channel representation via wavelet
transform, the proposed model learns the priors from stacked wavelet
coefficient components, thus learns the image characteristics under coarse and
detail frequency spectrums jointly and effectively. Moreover, such a highly
flexible generative model without adversarial optimization can execute
colorization tasks better under dual consistency terms in wavelet domain,
namely data-consistency and structure-consistency. Specifically, in the
training phase, a set of multi-channel tensors consisting of wavelet
coefficients are used as the input to train the network by denoising score
matching. In the test phase, samples are iteratively generated via annealed
Langevin dynamics with data and structure consistencies. Experiments
demonstrated remarkable improvements of the proposed model on colorization
quality, particularly on colorization robustness and diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unity Perception: Generate Synthetic Data for Computer Vision. (arXiv:2107.04259v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Borkman_S/0/1/0/all/0/1">Steve Borkman</a>, <a href="http://arxiv.org/find/cs/1/au:+Crespi_A/0/1/0/all/0/1">Adam Crespi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhakad_S/0/1/0/all/0/1">Saurav Dhakad</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganguly_S/0/1/0/all/0/1">Sujoy Ganguly</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogins_J/0/1/0/all/0/1">Jonathan Hogins</a>, <a href="http://arxiv.org/find/cs/1/au:+Jhang_Y/0/1/0/all/0/1">You-Cyuan Jhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamalzadeh_M/0/1/0/all/0/1">Mohsen Kamalzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bowen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Leal_S/0/1/0/all/0/1">Steven Leal</a>, <a href="http://arxiv.org/find/cs/1/au:+Parisi_P/0/1/0/all/0/1">Pete Parisi</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_C/0/1/0/all/0/1">Cesar Romero</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_W/0/1/0/all/0/1">Wesley Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Thaman_A/0/1/0/all/0/1">Alex Thaman</a>, <a href="http://arxiv.org/find/cs/1/au:+Warren_S/0/1/0/all/0/1">Samuel Warren</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_N/0/1/0/all/0/1">Nupur Yadav</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04259">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the Unity Perception package which aims to simplify and
accelerate the process of generating synthetic datasets for computer vision
tasks by offering an easy-to-use and highly customizable toolset. This
open-source package extends the Unity Editor and engine components to generate
perfectly annotated examples for several common computer vision tasks.
Additionally, it offers an extensible Randomization framework that lets the
user quickly construct and configure randomized simulation parameters in order
to introduce variation into the generated datasets. We provide an overview of
the provided tools and how they work, and demonstrate the value of the
generated synthetic datasets by training a 2D object detection model. The model
trained with mostly synthetic data outperforms the model trained using only
real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic and Geometric Unfolding of StyleGAN Latent Space. (arXiv:2107.04481v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shukor_M/0/1/0/all/0/1">Mustafa Shukor</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Damodaran_B/0/1/0/all/0/1">Bharath Bhushan Damodaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Hellier_P/0/1/0/all/0/1">Pierre Hellier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04481">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GANs) have proven to be surprisingly
efficient for image editing by inverting and manipulating the latent code
corresponding to a natural image. This property emerges from the disentangled
nature of the latent space. In this paper, we identify two geometric
limitations of such latent space: (a) euclidean distances differ from image
perceptual distance, and (b) disentanglement is not optimal and facial
attribute separation using linear model is a limiting hypothesis. We thus
propose a new method to learn a proxy latent representation using normalizing
flows to remedy these limitations, and show that this leads to a more efficient
space for face image editing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multitask Multi-database Emotion Recognition. (arXiv:2107.04127v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vu_M/0/1/0/all/0/1">Manh Tu Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Beurton_Aimar_M/0/1/0/all/0/1">Marie Beurton-Aimar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04127">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce our submission to the 2nd Affective Behavior
Analysis in-the-wild (ABAW) 2021 competition. We train a unified deep learning
model on multi-databases to perform two tasks: seven basic facial expressions
prediction and valence-arousal estimation. Since these databases do not
contains labels for all the two tasks, we have applied the distillation
knowledge technique to train two networks: one teacher and one student model.
The student model will be trained using both ground truth labels and soft
labels derived from the pretrained teacher model. During the training, we add
one more task, which is the combination of the two mentioned tasks, for better
exploiting inter-task correlations. We also exploit the sharing videos between
the two tasks of the AffWild2 database that is used in the competition, to
further improve the performance of the network. Experiment results shows that
the network have achieved promising results on the validation set of the
AffWild2 database. Code and pretrained model are publicly available at
https://github.com/glmanhtu/multitask-abaw-2021</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-modal and Multi-task Learning Method for Action Unit and Expression Recognition. (arXiv:2107.04187v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yue Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_T/0/1/0/all/0/1">Tianqing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_C/0/1/0/all/0/1">Chao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_G/0/1/0/all/0/1">Guoqiang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04187">
                                    <div class="article-summary-box-inner">
                                        <span>Analyzing human affect is vital for human-computer interaction systems. Most
methods are developed in restricted scenarios which are not practical for
in-the-wild settings. The Affective Behavior Analysis in-the-wild (ABAW) 2021
Contest provides a benchmark for this in-the-wild problem. In this paper, we
introduce a multi-modal and multi-task learning method by using both visual and
audio information. We use both AU and expression annotations to train the model
and apply a sequence model to further extract associations between video
frames. We achieve an AU score of 0.712 and an expression score of 0.477 on the
validation set. These results demonstrate the effectiveness of our approach in
improving model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Dropout Discriminator for Domain Adaptation. (arXiv:2107.04231v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1">Vinod K Kurmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_V/0/1/0/all/0/1">Venkatesh K Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1">Vinay P. Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04231">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptation of a classifier to new domains is one of the challenging problems
in machine learning. This has been addressed using many deep and non-deep
learning based methods. Among the methodologies used, that of adversarial
learning is widely applied to solve many deep learning problems along with
domain adaptation. These methods are based on a discriminator that ensures
source and target distributions are close. However, here we suggest that rather
than using a point estimate obtaining by a single discriminator, it would be
useful if a distribution based on ensembles of discriminators could be used to
bridge this gap. This could be achieved using multiple classifiers or using
traditional ensemble methods. In contrast, we suggest that a Monte Carlo
dropout based ensemble discriminator could suffice to obtain the distribution
based discriminator. Specifically, we propose a curriculum based dropout
discriminator that gradually increases the variance of the sample based
distribution and the corresponding reverse gradients are used to align the
source and target feature representations. An ensemble of discriminators helps
the model to learn the data distribution efficiently. It also provides a better
gradient estimates to train the feature extractor. The detailed results and
thorough ablation analysis show that our model outperforms state-of-the-art
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RGB Stream Is Enough for Temporal Action Detection. (arXiv:2107.04362v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chenhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Hongxiang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuxin Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yichao Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04362">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art temporal action detectors to date are based on two-stream
input including RGB frames and optical flow. Although combining RGB frames and
optical flow boosts performance significantly, optical flow is a hand-designed
representation which not only requires heavy computation, but also makes it
methodologically unsatisfactory that two-stream methods are often not learned
end-to-end jointly with the flow. In this paper, we argue that optical flow is
dispensable in high-accuracy temporal action detection and image level data
augmentation (ILDA) is the key solution to avoid performance degradation when
optical flow is removed. To evaluate the effectiveness of ILDA, we design a
simple yet efficient one-stage temporal action detector based on single RGB
stream named DaoTAD. Our results show that when trained with ILDA, DaoTAD has
comparable accuracy with all existing state-of-the-art two-stream detectors
while surpassing the inference speed of previous methods by a large margin and
the inference speed is astounding 6668 fps on GeForce GTX 1080 Ti. Code is
available at \url{https://github.com/Media-Smart/vedatad}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Image Synthesis from Intuitive User Input: A Review and Perspectives. (arXiv:2107.04240v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1">Yuan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuan-Chen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Song-Hai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaolei Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04240">
                                    <div class="article-summary-box-inner">
                                        <span>In many applications of computer graphics, art and design, it is desirable
for a user to provide intuitive non-image input, such as text, sketch, stroke,
graph or layout, and have a computer system automatically generate
photo-realistic images that adhere to the input content. While classic works
that allow such automatic image content generation have followed a framework of
image retrieval and composition, recent advances in deep generative models such
as generative adversarial networks (GANs), variational autoencoders (VAEs), and
flow-based methods have enabled more powerful and versatile image generation
tasks. This paper reviews recent works for image synthesis given intuitive user
input, covering advances in input versatility, image generation methodology,
benchmark datasets, and evaluation metrics. This motivates new perspectives on
input representation and interactivity, cross pollination between major image
generation paradigms, and evaluation and comparison of generation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Emotion Recognition with Incomplete Labels Using Modified Multi-task Learning Technique. (arXiv:2107.04192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thinh_P/0/1/0/all/0/1">Phan Tran Dac Thinh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hung_H/0/1/0/all/0/1">Hoang Manh Hung</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hyung-Jeong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Soo-Hyung Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Guee-Sang Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04192">
                                    <div class="article-summary-box-inner">
                                        <span>The task of predicting affective information in the wild such as seven basic
emotions or action units from human faces has gradually become more interesting
due to the accessibility and availability of massive annotated datasets. In
this study, we propose a method that utilizes the association between seven
basic emotions and twelve action units from the AffWild2 dataset. The method
based on the architecture of ResNet50 involves the multi-task learning
technique for the incomplete labels of the two tasks. By combining the
knowledge for two correlated tasks, both performances are improved by a large
margin compared to those with the model employing only one kind of label.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EasyCom: An Augmented Reality Dataset to Support Algorithms for Easy Communication in Noisy Environments. (arXiv:2107.04174v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Donley_J/0/1/0/all/0/1">Jacob Donley</a>, <a href="http://arxiv.org/find/cs/1/au:+Tourbabin_V/0/1/0/all/0/1">Vladimir Tourbabin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jung-Suk Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Broyles_M/0/1/0/all/0/1">Mark Broyles</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jie Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pantic_M/0/1/0/all/0/1">Maja Pantic</a>, <a href="http://arxiv.org/find/cs/1/au:+Ithapu_V/0/1/0/all/0/1">Vamsi Krishna Ithapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehra_R/0/1/0/all/0/1">Ravish Mehra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04174">
                                    <div class="article-summary-box-inner">
                                        <span>Augmented Reality (AR) as a platform has the potential to facilitate the
reduction of the cocktail party effect. Future AR headsets could potentially
leverage information from an array of sensors spanning many different
modalities. Training and testing signal processing and machine learning
algorithms on tasks such as beam-forming and speech enhancement require high
quality representative data. To the best of the author&#x27;s knowledge, as of
publication there are no available datasets that contain synchronized
egocentric multi-channel audio and video with dynamic movement and
conversations in a noisy environment. In this work, we describe, evaluate and
release a dataset that contains over 5 hours of multi-modal data useful for
training and testing algorithms for the application of improving conversations
for an AR glasses wearer. We provide speech intelligibility, quality and
signal-to-noise ratio improvement results for a baseline method and show
improvements across all tested metrics. The dataset we are releasing contains
AR glasses egocentric multi-channel microphone array audio, wide field-of-view
RGB video, speech source pose, headset microphone audio, annotated voice
activity, speech transcriptions, head bounding boxes, target of speech and
source identification labels. We have created and are releasing this dataset to
facilitate research in multi-modal AR solutions to the cocktail party problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural content-aware collaborative filtering for cold-start music recommendation. (arXiv:2102.12369v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Magron_P/0/1/0/all/0/1">Paul Magron</a>, <a href="http://arxiv.org/find/cs/1/au:+Fevotte_C/0/1/0/all/0/1">C&#xe9;dric F&#xe9;votte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12369">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art music recommender systems are based on collaborative
filtering, which builds upon learning similarities between users and songs from
the available listening data. These approaches inherently face the cold-start
problem, as they cannot recommend novel songs with no listening history.
Content-aware recommendation addresses this issue by incorporating content
information about the songs on top of collaborative filtering. However, methods
falling in this category rely on a shallow user/item interaction that
originates from a matrix factorization framework. In this work, we introduce
neural content-aware collaborative filtering, a unified framework which
alleviates these limits, and extends the recently introduced neural
collaborative filtering to its content-aware counterpart. We propose a
generative model which leverages deep learning for both extracting content
information from low-level acoustic features and for modeling the interaction
between users and songs embeddings. The deep content feature extractor can
either directly predict the item embedding, or serve as a regularization prior,
yielding two variants (strict} and relaxed) of our model. Experimental results
show that the proposed method reaches state-of-the-art results for a cold-start
music recommendation task. We notably observe that exploiting deep neural
networks for learning refined user/item interactions outperforms approaches
using a more simple interaction model in a content-aware framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Positional Information for Session-based Recommendation. (arXiv:2107.00846v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1">Ruihong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hongzhi Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00846">
                                    <div class="article-summary-box-inner">
                                        <span>For present e-commerce platforms, session-based recommender systems are
developed to predict users&#x27; preference for next-item recommendation. Although a
session can usually reflect a user&#x27;s current preference, a local shift of the
user&#x27;s intention within the session may still exist. Specifically, the
interactions that take place in the early positions within a session generally
indicate the user&#x27;s initial intention, while later interactions are more likely
to represent the latest intention. Such positional information has been rarely
considered in existing methods, which restricts their ability to capture the
significance of interactions at different positions. To thoroughly exploit the
positional information within a session, a theoretical framework is developed
in this paper to provide an in-depth analysis of the positional information. We
formally define the properties of forward-awareness and backward-awareness to
evaluate the ability of positional encoding schemes in capturing the initial
and the latest intention. According to our analysis, existing positional
encoding schemes are generally forward-aware only, which can hardly represent
the dynamics of the intention in a session. To enhance the positional encoding
scheme for the session-based recommendation, a dual positional encoding (DPE)
is proposed to account for both forward-awareness and backward-awareness. Based
on DPE, we propose a novel Positional Recommender (PosRec) model with a
well-designed Position-aware Gated Graph Neural Network module to fully exploit
the positional information for session-based recommendation tasks. Extensive
experiments are conducted on two e-commerce benchmark datasets, Yoochoose and
Diginetica and the experimental results show the superiority of the PosRec by
comparing it with the state-of-the-art session-based recommender models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Cross-Session Information for Session-based Recommendation with Graph Neural Networks. (arXiv:2107.00852v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1">Ruihong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hongzhi Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00852">
                                    <div class="article-summary-box-inner">
                                        <span>Different from the traditional recommender system, the session-based
recommender system introduces the concept of the session, i.e., a sequence of
interactions between a user and multiple items within a period, to preserve the
user&#x27;s recent interest. The existing work on the session-based recommender
system mainly relies on mining sequential patterns within individual sessions,
which are not expressive enough to capture more complicated dependency
relationships among items. In addition, it does not consider the cross-session
information due to the anonymity of the session data, where the linkage between
different sessions is prevented. In this paper, we solve these problems with
the graph neural networks technique. First, each session is represented as a
graph rather than a linear sequence structure, based on which a novel Full
Graph Neural Network (FGNN) is proposed to learn complicated item dependency.
To exploit and incorporate cross-session information in the individual
session&#x27;s representation learning, we further construct a Broadly Connected
Session (BCS) graph to link different sessions and a novel Mask-Readout
function to improve session embedding based on the BCS graph. Extensive
experiments have been conducted on two e-commerce benchmark datasets, i.e.,
Yoochoose and Diginetica, and the experimental results demonstrate the
superiority of our proposal through comparisons with state-of-the-art
session-based recommender models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAG: Global Attributed Graph Neural Network for Streaming Session-based Recommendation. (arXiv:2007.02747v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1">Ruihong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hongzhi Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.02747">
                                    <div class="article-summary-box-inner">
                                        <span>Streaming session-based recommendation (SSR) is a challenging task that
requires the recommender system to do the session-based recommendation (SR) in
the streaming scenario. In the real-world applications of e-commerce and social
media, a sequence of user-item interactions generated within a certain period
are grouped as a session, and these sessions consecutively arrive in the form
of streams. Most of the recent SR research has focused on the static setting
where the training data is first acquired and then used to train a
session-based recommender model. They need several epochs of training over the
whole dataset, which is infeasible in the streaming setting. Besides, they can
hardly well capture long-term user interests because of the neglect or the
simple usage of the user information. Although some streaming recommendation
strategies have been proposed recently, they are designed for streams of
individual interactions rather than streams of sessions. In this paper, we
propose a Global Attributed Graph (GAG) neural network model with a Wasserstein
reservoir for the SSR problem. On one hand, when a new session arrives, a
session graph with a global attribute is constructed based on the current
session and its associate user. Thus, the GAG can take both the global
attribute and the current session into consideration to learn more
comprehensive representations of the session and the user, yielding a better
performance in the recommendation. On the other hand, for the adaptation to the
streaming session scenario, a Wasserstein reservoir is proposed to help
preserve a representative sketch of the historical data. Extensive experiments
on two real-world datasets have been conducted to verify the superiority of the
GAG model compared with the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">News Recommender System: A review of recent progress, challenges, and opportunities. (arXiv:2009.04964v4 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raza_S/0/1/0/all/0/1">Shaina Raza</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Chen Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04964">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, more and more news readers tend to read news online where they have
access to millions of news articles from multiple sources. In order to help
users to find the right and relevant content, news recommender systems (NRS)
are developed to relieve the information overload problem and suggest news
items that users might be interested in. In this paper, we highlight the major
challenges faced by the news recommendation domain and identify the possible
solutions from the state-of-the-art. Due to the rapid growth of building
recommender systems using deep learning models, we divide our discussion in two
parts. In the first part, we present an overview of the conventional
recommendation solutions, datasets, evaluation criteria beyond accuracy and
recommendation platforms being used in NRS. In the second part, we explain the
deep learning-based recommendation solutions applied in NRS. Different from
previous surveys, we also study the effects of news recommendations on user
behavior and try to suggest the possible remedies to mitigate these effects. By
providing the state-of-the-art knowledge, this survey can help researchers and
practical professionals in their understanding of developments in news
recommendation algorithms. It also sheds light on potential new directions</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking the Item Order in Session-based Recommendation with Graph Neural Networks. (arXiv:1911.11942v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1">Ruihong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hongzhi Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.11942">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting a user&#x27;s preference in a short anonymous interaction session
instead of long-term history is a challenging problem in the real-life
session-based recommendation, e.g., e-commerce and media stream. Recent
research of the session-based recommender system mainly focuses on sequential
patterns by utilizing the attention mechanism, which is straightforward for the
session&#x27;s natural sequence sorted by time. However, the user&#x27;s preference is
much more complicated than a solely consecutive time pattern in the transition
of item choices. In this paper, therefore, we study the item transition pattern
by constructing a session graph and propose a novel model which collaboratively
considers the sequence order and the latent order in the session graph for a
session-based recommender system. We formulate the next item recommendation
within the session as a graph classification problem. Specifically, we propose
a weighted attention graph layer and a Readout function to learn embeddings of
items and sessions for the next item recommendation. Extensive experiments have
been conducted on two benchmark E-commerce datasets, Yoochoose and Diginetica,
and the experimental results show that our model outperforms other
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crowd Sensing and Living Lab Outdoor Experimentation Made Easy. (arXiv:2107.04117v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pournaras_E/0/1/0/all/0/1">Evangelos Pournaras</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghulam_A/0/1/0/all/0/1">Atif Nabi Ghulam</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunz_R/0/1/0/all/0/1">Renato Kunz</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanggli_R/0/1/0/all/0/1">Regula H&#xe4;nggli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04117">
                                    <div class="article-summary-box-inner">
                                        <span>Outdoor &#x60;living lab&#x27; experimentation using pervasive computing provides new
opportunities: higher realism, external validity and large-scale
socio-spatio-temporal observations. However, experimentation &#x60;in the wild&#x27; is
highly complex and costly. Noise, biases, privacy concerns to comply with
standards of ethical review boards, remote moderation, control of experimental
conditions and equipment perplex the collection of high-quality data for causal
inference. This article introduces Smart Agora, a novel open-source software
platform for rigorous systematic outdoor experimentation. Without writing a
single line of code, highly complex experimental scenarios are visually
designed and automatically deployed to smart phones. Novel geolocated survey
and sensor data are collected subject of participants verifying desired
experimental conditions, for instance. their presence at certain urban spots.
This new approach drastically improves the quality and purposefulness of crowd
sensing, tailored to conditions that confirm/reject hypotheses. The features
that support this innovative functionality and the broad spectrum of its
applicability are demonstrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Sensor Fusion Algorithms Against Voice Command Attacks in Autonomous Vehicles. (arXiv:2104.09872v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1">Jiwei Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yipeng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jolfa_A/0/1/0/all/0/1">Alireza Jolfa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09872">
                                    <div class="article-summary-box-inner">
                                        <span>With recent advances in autonomous driving, Voice Control Systems have become
increasingly adopted as human-vehicle interaction methods. This technology
enables drivers to use voice commands to control the vehicle and will be soon
available in Advanced Driver Assistance Systems (ADAS). Prior work has shown
that Siri, Alexa and Cortana, are highly vulnerable to inaudible command
attacks. This could be extended to ADAS in real-world applications and such
inaudible command threat is difficult to detect due to microphone
nonlinearities. In this paper, we aim to develop a more practical solution by
using camera views to defend against inaudible command attacks where ADAS are
capable of detecting their environment via multi-sensors. To this end, we
propose a novel multimodal deep learning classification system to defend
against inaudible command attacks. Our experimental results confirm the
feasibility of the proposed defense methods and the best classification
accuracy reaches 89.2%. Code is available at
https://github.com/ITSEG-MQ/Sensor-Fusion-Against-VoiceCommand-Attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Adaptation to Label Distribution Shift. (arXiv:2107.04520v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Ruihan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1">Kilian Q. Weinberger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04520">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models often encounter distribution shifts when deployed in
the real world. In this paper, we focus on adaptation to label distribution
shift in the online setting, where the test-time label distribution is
continually changing and the model must dynamically adapt to it without
observing the true label. Leveraging a novel analysis, we show that the lack of
true label does not hinder estimation of the expected test loss, which enables
the reduction of online label shift adaptation to conventional online learning.
Informed by this observation, we propose adaptation algorithms inspired by
classical online learning techniques such as Follow The Leader (FTL) and Online
Gradient Descent (OGD) and derive their regret bounds. We empirically verify
our findings under both simulated and real world label distribution shifts and
show that OGD is particularly effective and robust to a variety of challenging
label shift scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Annealed Flow Transport Monte Carlo. (arXiv:2102.07501v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Arbel_M/0/1/0/all/0/1">Michael Arbel</a>, <a href="http://arxiv.org/find/stat/1/au:+Matthews_A/0/1/0/all/0/1">Alexander G. D. G. Matthews</a>, <a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07501">
                                    <div class="article-summary-box-inner">
                                        <span>Annealed Importance Sampling (AIS) and its Sequential Monte Carlo (SMC)
extensions are state-of-the-art methods for estimating normalizing constants of
probability distributions. We propose here a novel Monte Carlo algorithm,
Annealed Flow Transport (AFT), that builds upon AIS and SMC and combines them
with normalizing flows (NFs) for improved performance. This method transports a
set of particles using not only importance sampling (IS), Markov chain Monte
Carlo (MCMC) and resampling steps - as in SMC, but also relies on NFs which are
learned sequentially to push particles towards the successive annealed targets.
We provide limit theorems for the resulting Monte Carlo estimates of the
normalizing constant and expectations with respect to the target distribution.
Additionally, we show that a continuous-time scaling limit of the population
version of AFT is given by a Feynman--Kac measure which simplifies to the law
of a controlled diffusion for expressive NFs. We demonstrate experimentally the
benefits and limitations of our methodology on a variety of applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization of the Change of Variables Formula with Applications to Residual Flows. (arXiv:2107.04346v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Koenen_N/0/1/0/all/0/1">Niklas Koenen</a>, <a href="http://arxiv.org/find/stat/1/au:+Wright_M/0/1/0/all/0/1">Marvin N. Wright</a>, <a href="http://arxiv.org/find/stat/1/au:+Maass_P/0/1/0/all/0/1">Peter Maa&#xdf;</a>, <a href="http://arxiv.org/find/stat/1/au:+Behrmann_J/0/1/0/all/0/1">Jens Behrmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04346">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows leverage the Change of Variables Formula (CVF) to define
flexible density models. Yet, the requirement of smooth transformations
(diffeomorphisms) in the CVF poses a significant challenge in the construction
of these models. To enlarge the design space of flows, we introduce
$\mathcal{L}$-diffeomorphisms as generalized transformations which may violate
these requirements on zero Lebesgue-measure sets. This relaxation allows e.g.
the use of non-smooth activation functions such as ReLU. Finally, we apply the
obtained results to planar, radial, and contractive residual flows.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CMRNet: Camera to LiDAR-Map Registration. (arXiv:1906.10109v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cattaneo_D/0/1/0/all/0/1">Daniele Cattaneo</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaghi_M/0/1/0/all/0/1">Matteo Vaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballardini_A/0/1/0/all/0/1">Augusto Luis Ballardini</a>, <a href="http://arxiv.org/find/cs/1/au:+Fontana_S/0/1/0/all/0/1">Simone Fontana</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorrenti_D/0/1/0/all/0/1">Domenico Giorgio Sorrenti</a>, <a href="http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1">Wolfram Burgard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.10109">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present CMRNet, a realtime approach based on a Convolutional
Neural Network to localize an RGB image of a scene in a map built from LiDAR
data. Our network is not trained in the working area, i.e. CMRNet does not
learn the map. Instead it learns to match an image to the map. We validate our
approach on the KITTI dataset, processing each frame independently without any
tracking procedure. CMRNet achieves 0.27m and 1.07deg median localization
accuracy on the sequence 00 of the odometry dataset, starting from a rough pose
estimate displaced up to 3.5m and 17deg. To the best of our knowledge this is
the first CNN-based approach that learns to match images from a monocular
camera to a given, preexisting 3D LiDAR-map.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An $O(s^r)$-Resolution ODE Framework for Understanding Discrete-Time Algorithms and Applications to the Linear Convergence of Minimax Problems. (arXiv:2001.08826v7 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Lu_H/0/1/0/all/0/1">Haihao Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.08826">
                                    <div class="article-summary-box-inner">
                                        <span>There has been a long history of using ordinary differential equations (ODEs)
to understand the dynamics of discrete-time algorithms (DTAs). Surprisingly,
there are still two fundamental and unanswered questions: (i) it is unclear how
to obtain a \emph{suitable} ODE from a given DTA, and (ii) it is unclear the
connection between the convergence of a DTA and its corresponding ODEs. In this
paper, we propose a new machinery -- an $O(s^r)$-resolution ODE framework --
for analyzing the behavior of a generic DTA, which (partially) answers the
above two questions. The framework contains three steps: 1. To obtain a
suitable ODE from a given DTA, we define a hierarchy of $O(s^r)$-resolution
ODEs of a DTA parameterized by the degree $r$, where $s$ is the step-size of
the DTA. We present a principal approach to construct the unique
$O(s^r)$-resolution ODEs from a DTA; 2. To analyze the resulting ODE, we
propose the $O(s^r)$-linear-convergence condition of a DTA with respect to an
energy function, under which the $O(s^r)$-resolution ODE converges linearly to
an optimal solution; 3. To bridge the convergence properties of a DTA and its
corresponding ODEs, we define the properness of an energy function and show
that the linear convergence of the $O(s^r)$-resolution ODE with respect to a
proper energy function can automatically guarantee the linear convergence of
the DTA. To better illustrate this machinery, we utilize it to study three
classic algorithms -- gradient descent ascent (GDA), proximal point method
(PPM) and extra-gradient method (EGM) -- for solving the unconstrained minimax
problem $\min_{x\in\RR^n} \max_{y\in \RR^m} L(x,y)$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias in Machine Learning Software: Why? How? What to do?. (arXiv:2105.12195v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_J/0/1/0/all/0/1">Joymallya Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_S/0/1/0/all/0/1">Suvodeep Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Menzies_T/0/1/0/all/0/1">Tim Menzies</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12195">
                                    <div class="article-summary-box-inner">
                                        <span>Increasingly, software is making autonomous decisions in case of criminal
sentencing, approving credit cards, hiring employees, and so on. Some of these
decisions show bias and adversely affect certain social groups (e.g. those
defined by sex, race, age, marital status). Many prior works on bias mitigation
take the following form: change the data or learners in multiple ways, then see
if any of that improves fairness. Perhaps a better approach is to postulate
root causes of bias and then applying some resolution strategy. This paper
postulates that the root causes of bias are the prior decisions that affect-
(a) what data was selected and (b) the labels assigned to those examples. Our
Fair-SMOTE algorithm removes biased labels; and rebalances internal
distributions such that based on sensitive attribute, examples are equal in
both positive and negative classes. On testing, it was seen that this method
was just as effective at reducing bias as prior approaches. Further, models
generated via Fair-SMOTE achieve higher performance (measured in terms of
recall and F1) than other state-of-the-art fairness improvement algorithms. To
the best of our knowledge, measured in terms of number of analyzed learners and
datasets, this study is one of the largest studies on bias mitigation yet
presented in the literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Gradient-based Algorithms for Non-concave Bandit Optimization. (arXiv:2107.04518v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1">Baihe Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaixuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham M. Kakade</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1">Qi Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Runzhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiaqi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04518">
                                    <div class="article-summary-box-inner">
                                        <span>Bandit problems with linear or concave reward have been extensively studied,
but relatively few works have studied bandits with non-concave reward. This
work considers a large family of bandit problems where the unknown underlying
reward function is non-concave, including the low-rank generalized linear
bandit problems and two-layer neural network with polynomial activation bandit
problem. For the low-rank generalized linear bandit problem, we provide a
minimax-optimal algorithm in the dimension, refuting both conjectures in
[LMT21, JWWN19]. Our algorithms are based on a unified zeroth-order
optimization paradigm that applies in great generality and attains optimal
rates in several structured polynomial settings (in the dimension). We further
demonstrate the applicability of our algorithms in RL in the generative model
setting, resulting in improved sample complexity over prior approaches.
Finally, we show that the standard optimistic algorithms (e.g., UCB) are
sub-optimal by dimension factors. In the neural net setting (with polynomial
activation functions) with noiseless reward, we provide a bandit algorithm with
sample complexity equal to the intrinsic algebraic dimension. Again, we show
that optimistic approaches have worse sample complexity, polynomial in the
extrinsic dimension (which could be exponentially worse in the polynomial
degree).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Multilayer Network Exploration by Random Walk with Restart. (arXiv:2107.04565v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baptista_A/0/1/0/all/0/1">Anthony Baptista</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_A/0/1/0/all/0/1">Aitor Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Baudot_A/0/1/0/all/0/1">Ana&#xef;s Baudot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04565">
                                    <div class="article-summary-box-inner">
                                        <span>The amount and variety of data is increasing drastically for several years.
These data are often represented as networks, which are then explored with
approaches arising from network theory. Recent years have witnessed the
extension of network exploration methods to leverage more complex and richer
network frameworks. Random walks, for instance, have been extended to explore
multilayer networks. However, current random walk approaches are limited in the
combination and heterogeneity of network layers they can handle. New analytical
and numerical random walk methods are needed to cope with the increasing
diversity and complexity of multilayer networks. We propose here MultiXrank, a
Python package that enables Random Walk with Restart (RWR) on any kind of
multilayer network with an optimized implementation. This package is supported
by a universal mathematical formulation of the RWR. We evaluated MultiXrank
with leave-one-out cross-validation and link prediction, and introduced
protocols to measure the impact of the addition or removal of multilayer
network data on prediction performances. We further measured the sensitivity of
MultiXrank to input parameters by in-depth exploration of the parameter space.
Finally, we illustrate the versatility of MultiXrank with different use-cases
of unsupervised node prioritization and supervised classification in the
context of human genetic diseases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Delegate for Large-scale Vehicle Routing. (arXiv:2107.04139v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sirui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhongxia Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Cathy Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04139">
                                    <div class="article-summary-box-inner">
                                        <span>Vehicle routing problems (VRPs) are a class of combinatorial problems with
wide practical applications. While previous heuristic or learning-based works
achieve decent solutions on small problem instances of up to 100 customers,
their performance does not scale to large problems. This article presents a
novel learning-augmented local search algorithm to solve large-scale VRP. The
method iteratively improves the solution by identifying appropriate subproblems
and $\textit{delegating}$ their improvement to a black box subsolver. At each
step, we leverage spatial locality to consider only a linear number of
subproblems, rather than exponential. We frame subproblem selection as a
regression problem and train a Transformer on a generated training set of
problem instances. We show that our method achieves state-of-the-art
performance, with a speed-up of up to 15 times over strong baselines, on VRPs
with sizes ranging from 500 to 3000.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedAdapt: Adaptive Offloading for IoT Devices in Federated Learning. (arXiv:2107.04271v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullah_R/0/1/0/all/0/1">Rehmat Ullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Harvey_P/0/1/0/all/0/1">Paul Harvey</a>, <a href="http://arxiv.org/find/cs/1/au:+Kilpatrick_P/0/1/0/all/0/1">Peter Kilpatrick</a>, <a href="http://arxiv.org/find/cs/1/au:+Spence_I/0/1/0/all/0/1">Ivor Spence</a>, <a href="http://arxiv.org/find/cs/1/au:+Varghese_B/0/1/0/all/0/1">Blesson Varghese</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04271">
                                    <div class="article-summary-box-inner">
                                        <span>Applying Federated Learning (FL) on Internet-of-Things devices is
necessitated by the large volumes of data they produce and growing concerns of
data privacy. However, there are three challenges that need to be addressed to
make FL efficient: (i) execute on devices with limited computational
capabilities, (ii) account for stragglers due to computational heterogeneity of
devices, and (iii) adapt to the changing network bandwidths. This paper
presents FedAdapt, an adaptive offloading FL framework to mitigate the
aforementioned challenges. FedAdapt accelerates local training in
computationally constrained devices by leveraging layer offloading of deep
neural networks (DNNs) to servers. Further, FedAdapt adopts reinforcement
learning-based optimization and clustering to adaptively identify which layers
of the DNN should be offloaded for each individual device on to a server to
tackle the challenges of computational heterogeneity and changing network
bandwidth. Experimental studies are carried out on a lab-based testbed
comprising five IoT devices. By offloading a DNN from the device to the server
FedAdapt reduces the training time of a typical IoT device by over half
compared to classic FL. The training time of extreme stragglers and the overall
training time can be reduced by up to 57%. Furthermore, with changing network
bandwidth, FedAdapt is demonstrated to reduce the training time by up to 40%
when compared to classic FL, without sacrificing accuracy. FedAdapt can be
downloaded from https://github.com/qub-blesson/FedAdapt.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lithography Hotspot Detection via Heterogeneous Federated Learning with Local Adaptation. (arXiv:2107.04367v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xuezhong Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jingyu Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jinming Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiran Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_C/0/1/0/all/0/1">Cheng Zhuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04367">
                                    <div class="article-summary-box-inner">
                                        <span>As technology scaling is approaching the physical limit, lithography hotspot
detection has become an essential task in design for manufacturability. While
the deployment of pattern matching or machine learning in hotspot detection can
help save significant simulation time, such methods typically demand for
non-trivial quality data to build the model, which most design houses are short
of. Moreover, the design houses are also unwilling to directly share such data
with the other houses to build a unified model, which can be ineffective for
the design house with unique design patterns due to data insufficiency. On the
other hand, with data homogeneity in each design house, the locally trained
models can be easily over-fitted, losing generalization ability and robustness.
In this paper, we propose a heterogeneous federated learning framework for
lithography hotspot detection that can address the aforementioned issues. On
one hand, the framework can build a more robust centralized global sub-model
through heterogeneous knowledge sharing while keeping local data private. On
the other hand, the global sub-model can be combined with a local sub-model to
better adapt to local data heterogeneity. The experimental results show that
the proposed framework can overcome the challenge of non-independent and
identically distributed (non-IID) data and heterogeneous communication to
achieve very high performance in comparison to other state-of-the-art methods
while guaranteeing a good convergence rate in various scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Domain Adaptation with Self-Training for EEG-based Sleep Stage Classification. (arXiv:2107.04470v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eldele_E/0/1/0/all/0/1">Emadeldeen Eldele</a>, <a href="http://arxiv.org/find/cs/1/au:+Ragab_M/0/1/0/all/0/1">Mohamed Ragab</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenghua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Min Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwoh_C/0/1/0/all/0/1">Chee-Keong Kwoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoli Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04470">
                                    <div class="article-summary-box-inner">
                                        <span>Sleep staging is of great importance in the diagnosis and treatment of sleep
disorders. Recently, numerous data driven deep learning models have been
proposed for automatic sleep staging. They mainly rely on the assumption that
training and testing data are drawn from the same distribution which may not
hold in real-world scenarios. Unsupervised domain adaption (UDA) has been
recently developed to handle this domain shift problem. However, previous UDA
methods applied for sleep staging has two main limitations. First, they rely on
a totally shared model for the domain alignment, which may lose the
domain-specific information during feature extraction. Second, they only align
the source and target distributions globally without considering the class
information in the target domain, which hinders the classification performance
of the model. In this work, we propose a novel adversarial learning framework
to tackle the domain shift problem in the unlabeled target domain. First, we
develop unshared attention mechanisms to preserve the domain-specific features
in the source and target domains. Second, we design a self-training strategy to
align the fine-grained class distributions for the source and target domains
via target domain pseudo labels. We also propose dual distinct classifiers to
increase the robustness and quality of the pseudo labels. The experimental
results on six cross-domain scenarios validate the efficacy of our proposed
framework for sleep staging and its advantage over state-of-the-art UDA
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attend2Pack: Bin Packing through Deep Reinforcement Learning with Attention. (arXiv:2107.04333v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_B/0/1/0/all/0/1">Bin Zi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_X/0/1/0/all/0/1">Xiaoyu Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04333">
                                    <div class="article-summary-box-inner">
                                        <span>This paper seeks to tackle the bin packing problem (BPP) through a learning
perspective. Building on self-attention-based encoding and deep reinforcement
learning algorithms, we propose a new end-to-end learning model for this task
of interest. By decomposing the combinatorial action space, as well as
utilizing a new training technique denoted as prioritized oversampling, which
is a general scheme to speed up on-policy learning, we achieve state-of-the-art
performance in a range of experimental settings. Moreover, although the
proposed approach attend2pack targets offline-BPP, we strip our method down to
the strict online-BPP setting where it is also able to achieve state-of-the-art
performance. With a set of ablation studies as well as comparisons against a
range of previous works, we hope to offer as a valid baseline approach to this
field of study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scopeformer: n-CNN-ViT Hybrid Model for Intracranial Hemorrhage Classification. (arXiv:2107.04575v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Barhoumi_Y/0/1/0/all/0/1">Yassine Barhoumi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghulam_R/0/1/0/all/0/1">Rasool Ghulam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04575">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a feature generator backbone composed of an ensemble of
convolutional neuralnetworks (CNNs) to improve the recently emerging Vision
Transformer (ViT) models. We tackled the RSNA intracranial hemorrhage
classification problem, i.e., identifying various hemorrhage types from
computed tomography (CT) slices. We show that by gradually stacking several
feature maps extracted using multiple Xception CNNs, we can develop a
feature-rich input for the ViT model. Our approach allowed the ViT model to pay
attention to relevant features at multiple levels. Moreover, pretraining the n
CNNs using various paradigms leads to a diverse feature set and further
improves the performance of the proposed n-CNN-ViT. We achieved a test accuracy
of 98.04% with a weighted logarithmic loss value of 0.0708. The proposed
architecture is modular and scalable in both the number of CNNs used for
feature extraction and the size of the ViT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Robust Active Feature Acquisition. (arXiv:2107.04163v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1">Siyuan Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliva_J/0/1/0/all/0/1">Junier B. Oliva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04163">
                                    <div class="article-summary-box-inner">
                                        <span>Truly intelligent systems are expected to make critical decisions with
incomplete and uncertain data. Active feature acquisition (AFA), where features
are sequentially acquired to improve the prediction, is a step towards this
goal. However, current AFA models all deal with a small set of candidate
features and have difficulty scaling to a large feature space. Moreover, they
are ignorant about the valid domains where they can predict confidently, thus
they can be vulnerable to out-of-distribution (OOD) inputs. In order to remedy
these deficiencies and bring AFA models closer to practical use, we propose
several techniques to advance the current AFA approaches. Our framework can
easily handle a large number of features using a hierarchical acquisition
policy and is more robust to OOD inputs with the help of an OOD detector for
partially observed data. Extensive experiments demonstrate the efficacy of our
framework over strong baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Distributions of Aggregation Layers in Deep Neural Networks. (arXiv:2107.04458v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ong_E/0/1/0/all/0/1">Eng-Jon Ong</a>, <a href="http://arxiv.org/find/cs/1/au:+Husain_S/0/1/0/all/0/1">Sameed Husain</a>, <a href="http://arxiv.org/find/cs/1/au:+Bober_M/0/1/0/all/0/1">Miroslaw Bober</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04458">
                                    <div class="article-summary-box-inner">
                                        <span>The process of aggregation is ubiquitous in almost all deep nets models. It
functions as an important mechanism for consolidating deep features into a more
compact representation, whilst increasing robustness to overfitting and
providing spatial invariance in deep nets. In particular, the proximity of
global aggregation layers to the output layers of DNNs mean that aggregated
features have a direct influence on the performance of a deep net. A better
understanding of this relationship can be obtained using information theoretic
methods. However, this requires the knowledge of the distributions of the
activations of aggregation layers. To achieve this, we propose a novel
mathematical formulation for analytically modelling the probability
distributions of output values of layers involved with deep feature
aggregation. An important outcome is our ability to analytically predict the
KL-divergence of output nodes in a DNN. We also experimentally verify our
theoretical predictions against empirical observations across a range of
different classification tasks and datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantitative Evaluation of Explainable Graph Neural Networks for Molecular Property Prediction. (arXiv:2107.04119v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Rao_J/0/1/0/all/0/1">Jiahua Rao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zheng_S/0/1/0/all/0/1">Shuangjia Zheng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_Y/0/1/0/all/0/1">Yuedong Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04119">
                                    <div class="article-summary-box-inner">
                                        <span>Advances in machine learning have led to graph neural network-based methods
for drug discovery, yielding promising results in molecular design, chemical
synthesis planning, and molecular property prediction. However, current graph
neural networks (GNNs) remain of limited acceptance in drug discovery is
limited due to their lack of interpretability. Although this major weakness has
been mitigated by the development of explainable artificial intelligence (XAI)
techniques, the &quot;ground truth&quot; assignment in most explainable tasks ultimately
rests with subjective judgments by humans so that the quality of model
interpretation is hard to evaluate in quantity. In this work, we first build
three levels of benchmark datasets to quantitatively assess the
interpretability of the state-of-the-art GNN models. Then we implemented recent
XAI methods in combination with different GNN algorithms to highlight the
benefits, limitations, and future opportunities for drug discovery. As a
result, GradInput and IG generally provide the best model interpretability for
GNNs, especially when combined with GraphNet and CMPNN. The integrated and
developed XAI package is fully open-sourced and can be used by practitioners to
train new models on other drug discovery tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intuitively Assessing ML Model Reliability through Example-Based Explanations and Editing Model Inputs. (arXiv:2102.08540v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suresh_H/0/1/0/all/0/1">Harini Suresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_K/0/1/0/all/0/1">Kathleen M. Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Guttag_J/0/1/0/all/0/1">John V. Guttag</a>, <a href="http://arxiv.org/find/cs/1/au:+Satyanarayan_A/0/1/0/all/0/1">Arvind Satyanarayan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08540">
                                    <div class="article-summary-box-inner">
                                        <span>Interpretability methods aim to help users build trust in and understand the
capabilities of machine learning models. However, existing approaches often
rely on abstract, complex visualizations that poorly map to the task at hand or
require non-trivial ML expertise to interpret. Here, we present two visual
analytics modules that facilitate an intuitive assessment of model reliability.
To help users better characterize and reason about a model&#x27;s uncertainty, we
visualize raw and aggregate information about a given input&#x27;s nearest
neighbors. Using an interactive editor, users can manipulate this input in
semantically-meaningful ways, determine the effect on the output, and compare
against their prior expectations. We evaluate our interface using an
electrocardiogram beat classification case study. Compared to a baseline
feature importance interface, we find that 14 physicians are better able to
align the model&#x27;s uncertainty with domain-relevant factors and build intuition
about its capabilities and limitations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stock Market Analysis with Text Data: A Review. (arXiv:2106.12985v2 [q-fin.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Fataliyev_K/0/1/0/all/0/1">Kamaladdin Fataliyev</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Chivukula_A/0/1/0/all/0/1">Aneesh Chivukula</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Prasad_M/0/1/0/all/0/1">Mukesh Prasad</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12985">
                                    <div class="article-summary-box-inner">
                                        <span>Stock market movements are influenced by public and private information
shared through news articles, company reports, and social media discussions.
Analyzing these vast sources of data can give market participants an edge to
make profit. However, the majority of the studies in the literature are based
on traditional approaches that come short in analyzing unstructured, vast
textual data. In this study, we provide a review on the immense amount of
existing literature of text-based stock market analysis. We present input data
types and cover main textual data sources and variations. Feature
representation techniques are then presented. Then, we cover the analysis
techniques and create a taxonomy of the main stock market forecast models.
Importantly, we discuss representative work in each category of the taxonomy,
analyzing their respective contributions. Finally, this paper shows the
findings on unaddressed open problems and gives suggestions for future work.
The aim of this study is to survey the main stock market analysis models, text
representation techniques for financial market prediction, shortcomings of
existing techniques, and propose promising directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SHAP values for Explaining CNN-based Text Classification Models. (arXiv:2008.11825v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_T/0/1/0/all/0/1">Tarun Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1">Vijayan N. Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudjianto_A/0/1/0/all/0/1">Agus Sudjianto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11825">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are increasingly used in natural language processing
(NLP) models. However, the need to interpret and explain the results from
complex algorithms are limiting their widespread adoption in regulated
industries such as banking. There has been recent work on interpretability of
machine learning algorithms with structured data. But there are only limited
techniques for NLP applications where the problem is more challenging due to
the size of the vocabulary, high-dimensional nature, and the need to consider
textual coherence and language structure. This paper develops a methodology to
compute SHAP values for local explainability of CNN-based text classification
models. The approach is also extended to compute global scores to assess the
importance of features. The results are illustrated on sentiment analysis of
Amazon Electronic Review data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Model Pruning of Convolutional Networks on Tensor Processing Units. (arXiv:2107.04191v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kongtao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Franko_K/0/1/0/all/0/1">Ken Franko</a>, <a href="http://arxiv.org/find/cs/1/au:+Sang_R/0/1/0/all/0/1">Ruoxin Sang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04191">
                                    <div class="article-summary-box-inner">
                                        <span>The deployment of convolutional neural networks is often hindered by high
computational and storage requirements. Structured model pruning is a promising
approach to alleviate these requirements. Using the VGG-16 model as an example,
we measure the accuracy-efficiency trade-off for various structured model
pruning methods and datasets (CIFAR-10 and ImageNet) on Tensor Processing Units
(TPUs). To measure the actual performance of models, we develop a structured
model pruning library for TensorFlow2 to modify models in place (instead of
adding mask layers). We show that structured model pruning can significantly
improve model memory usage and speed on TPUs without losing accuracy,
especially for small datasets (e.g., CIFAR-10).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerating Finite-temperature Kohn-Sham Density Functional Theory with Deep Neural Networks. (arXiv:2010.04905v2 [cond-mat.mtrl-sci] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Ellis_J/0/1/0/all/0/1">J. Austin Ellis</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Fiedler_L/0/1/0/all/0/1">Lenz Fiedler</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Popoola_G/0/1/0/all/0/1">Gabriel A. Popoola</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Modine_N/0/1/0/all/0/1">Normand A. Modine</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Stephens_J/0/1/0/all/0/1">J. Adam Stephens</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Thompson_A/0/1/0/all/0/1">Aidan P. Thompson</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Cangi_A/0/1/0/all/0/1">Attila Cangi</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Rajamanickam_S/0/1/0/all/0/1">Sivasankaran Rajamanickam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04905">
                                    <div class="article-summary-box-inner">
                                        <span>We present a numerical modeling workflow based on machine learning (ML) which
reproduces the the total energies produced by Kohn-Sham density functional
theory (DFT) at finite electronic temperature to within chemical accuracy at
negligible computational cost. Based on deep neural networks, our workflow
yields the local density of states (LDOS) for a given atomic configuration.
From the LDOS, spatially-resolved, energy-resolved, and integrated quantities
can be calculated, including the DFT total free energy, which serves as the
Born-Oppenheimer potential energy surface for the atoms. We demonstrate the
efficacy of this approach for both solid and liquid metals and compare results
between independent and unified machine-learning models for solid and liquid
aluminum. Our machine-learning density functional theory framework opens up the
path towards multiscale materials modeling for matter under ambient and extreme
conditions at a computational scale and cost that is unattainable with current
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sli2Vol: Annotate a 3D Volume from a Single Slice with Self-Supervised Learning. (arXiv:2105.12722v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yeung_P/0/1/0/all/0/1">Pak-Hei Yeung</a>, <a href="http://arxiv.org/find/cs/1/au:+Namburete_A/0/1/0/all/0/1">Ana I.L. Namburete</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_W/0/1/0/all/0/1">Weidi Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12722">
                                    <div class="article-summary-box-inner">
                                        <span>The objective of this work is to segment any arbitrary structures of interest
(SOI) in 3D volumes by only annotating a single slice, (i.e. semi-automatic 3D
segmentation). We show that high accuracy can be achieved by simply propagating
the 2D slice segmentation with an affinity matrix between consecutive slices,
which can be learnt in a self-supervised manner, namely slice reconstruction.
Specifically, we compare the proposed framework, termed as Sli2Vol, with
supervised approaches and two other unsupervised/ self-supervised slice
registration approaches, on 8 public datasets (both CT and MRI scans), spanning
9 different SOIs. Without any parameter-tuning, the same model achieves
superior performance with Dice scores (0-100 scale) of over 80 for most of the
benchmarks, including the ones that are unseen during training. Our results
show generalizability of the proposed approach across data from different
machines and with different SOIs: a major use case of semi-automatic
segmentation methods where fully supervised approaches would normally struggle.
The source code will be made publicly available at
https://github.com/pakheiyeung/Sli2Vol.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring and Improving Model-Moderator Collaboration using Uncertainty Estimation. (arXiv:2107.04212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kivlichan_I/0/1/0/all/0/1">Ian D. Kivlichan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jeremiah Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasserman_L/0/1/0/all/0/1">Lucy Vasserman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04212">
                                    <div class="article-summary-box-inner">
                                        <span>Content moderation is often performed by a collaboration between humans and
machine learning models. However, it is not well understood how to design the
collaborative process so as to maximize the combined moderator-model system
performance. This work presents a rigorous study of this problem, focusing on
an approach that incorporates model uncertainty into the collaborative process.
First, we introduce principled metrics to describe the performance of the
collaborative system under capacity constraints on the human moderator,
quantifying how efficiently the combined system utilizes human decisions. Using
these metrics, we conduct a large benchmark study evaluating the performance of
state-of-the-art uncertainty models under different collaborative review
strategies. We find that an uncertainty-based strategy consistently outperforms
the widely used strategy based on toxicity scores, and moreover that the choice
of review strategy drastically changes the overall system performance. Our
results demonstrate the importance of rigorous metrics for understanding and
developing effective moderator-model systems for content moderation, as well as
the utility of uncertainty estimation in this domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-headed Neural Ensemble Search. (arXiv:2107.04369v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Narayanan_A/0/1/0/all/0/1">Ashwin Raaghav Narayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zela_A/0/1/0/all/0/1">Arber Zela</a>, <a href="http://arxiv.org/find/cs/1/au:+Saikia_T/0/1/0/all/0/1">Tonmoy Saikia</a>, <a href="http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1">Thomas Brox</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04369">
                                    <div class="article-summary-box-inner">
                                        <span>Ensembles of CNN models trained with different seeds (also known as Deep
Ensembles) are known to achieve superior performance over a single copy of the
CNN. Neural Ensemble Search (NES) can further boost performance by adding
architectural diversity. However, the scope of NES remains prohibitive under
limited computational resources. In this work, we extend NES to multi-headed
ensembles, which consist of a shared backbone attached to multiple prediction
heads. Unlike Deep Ensembles, these multi-headed ensembles can be trained end
to end, which enables us to leverage one-shot NAS methods to optimize an
ensemble objective. With extensive empirical evaluations, we demonstrate that
multi-headed ensemble search finds robust ensembles 3 times faster, while
having comparable performance to other ensemble search methods, in both
predictive performance and uncertainty calibration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ARC: Adversarially Robust Control Policies for Autonomous Vehicles. (arXiv:2107.04487v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuutti_S/0/1/0/all/0/1">Sampo Kuutti</a>, <a href="http://arxiv.org/find/cs/1/au:+Fallah_S/0/1/0/all/0/1">Saber Fallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowden_R/0/1/0/all/0/1">Richard Bowden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04487">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have demonstrated their capability to learn control
policies for a variety of tasks. However, these neural network-based policies
have been shown to be susceptible to exploitation by adversarial agents.
Therefore, there is a need to develop techniques to learn control policies that
are robust against adversaries. We introduce Adversarially Robust Control
(ARC), which trains the protagonist policy and the adversarial policy
end-to-end on the same loss. The aim of the protagonist is to maximise this
loss, whilst the adversary is attempting to minimise it. We demonstrate the
proposed ARC training in a highway driving scenario, where the protagonist
controls the follower vehicle whilst the adversary controls the lead vehicle.
By training the protagonist against an ensemble of adversaries, it learns a
significantly more robust control policy, which generalises to a variety of
adversarial strategies. The approach is shown to reduce the amount of
collisions against new adversaries by up to 90.25%, compared to the original
policy. Moreover, by utilising an auxiliary distillation loss, we show that the
fine-tuned control policy shows no drop in performance across its original
training distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extracting the Auditory Attention in a Dual-Speaker Scenario from EEG using a Joint CNN-LSTM Model. (arXiv:2102.03957v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuruvila_I/0/1/0/all/0/1">Ivine Kuruvila</a>, <a href="http://arxiv.org/find/cs/1/au:+Muncke_J/0/1/0/all/0/1">Jan Muncke</a>, <a href="http://arxiv.org/find/cs/1/au:+Fischer_E/0/1/0/all/0/1">Eghart Fischer</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoppe_U/0/1/0/all/0/1">Ulrich Hoppe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03957">
                                    <div class="article-summary-box-inner">
                                        <span>Human brain performs remarkably well in segregating a particular speaker from
interfering ones in a multi-speaker scenario. It has been recently shown that
we can quantitatively evaluate the segregation capability by modelling the
relationship between the speech signals present in an auditory scene and the
cortical signals of the listener measured using electroencephalography (EEG).
This has opened up avenues to integrate neuro-feedback into hearing aids
whereby the device can infer user&#x27;s attention and enhance the attended speaker.
Commonly used algorithms to infer the auditory attention are based on linear
systems theory where the speech cues such as envelopes are mapped on to the EEG
signals. Here, we present a joint convolutional neural network (CNN) - long
short-term memory (LSTM) model to infer the auditory attention. Our joint
CNN-LSTM model takes the EEG signals and the spectrogram of the multiple
speakers as inputs and classifies the attention to one of the speakers. We
evaluated the reliability of our neural network using three different datasets
comprising of 61 subjects where, each subject undertook a dual-speaker
experiment. The three datasets analysed corresponded to speech stimuli
presented in three different languages namely German, Danish and Dutch. Using
the proposed joint CNN-LSTM model, we obtained a median decoding accuracy of
77.2% at a trial duration of three seconds. Furthermore, we evaluated the
amount of sparsity that our model can tolerate by means of magnitude pruning
and found that the model can tolerate up to 50% sparsity without substantial
loss of decoding accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerating Spherical k-Means. (arXiv:2107.04074v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schubert_E/0/1/0/all/0/1">Erich Schubert</a>, <a href="http://arxiv.org/find/cs/1/au:+Lang_A/0/1/0/all/0/1">Andreas Lang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feher_G/0/1/0/all/0/1">Gloria Feher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04074">
                                    <div class="article-summary-box-inner">
                                        <span>Spherical k-means is a widely used clustering algorithm for sparse and
high-dimensional data such as document vectors. While several improvements and
accelerations have been introduced for the original k-means algorithm, not all
easily translate to the spherical variant: Many acceleration techniques, such
as the algorithms of Elkan and Hamerly, rely on the triangle inequality of
Euclidean distances. However, spherical k-means uses Cosine similarities
instead of distances for computational efficiency. In this paper, we
incorporate the Elkan and Hamerly accelerations to the spherical k-means
algorithm working directly with the Cosines instead of Euclidean distances to
obtain a substantial speedup and evaluate these spherical accelerations on real
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When is Particle Filtering Efficient for Planning in Partially Observed Linear Dynamical Systems?. (arXiv:2006.05975v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon S. Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhiyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_R/0/1/0/all/0/1">Ruoqi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiajun Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05975">
                                    <div class="article-summary-box-inner">
                                        <span>Particle filtering is a popular method for inferring latent states in
stochastic dynamical systems, whose theoretical properties have been well
studied in machine learning and statistics communities. In many control
problems, e.g., partially observed linear dynamical systems (POLDS), oftentimes
the inferred latent state is further used for planning at each step. This paper
initiates a rigorous study on the efficiency of particle filtering for
sequential planning, and gives the first particle complexity bounds. Though
errors in past actions may affect the future, we are able to bound the number
of particles needed so that the long-run reward of the policy based on particle
filtering is close to that based on exact inference. In particular, we show
that, in stable systems, polynomially many particles suffice. Key in our proof
is a coupling of the ideal sequence based on the exact planning and the
sequence generated by approximate planning based on particle filtering. We
believe this technique can be useful in other sequential decision-making
problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">White-Box Cartoonization Using An Extended GAN Framework. (arXiv:2107.04551v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thakur_A/0/1/0/all/0/1">Amey Thakur</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizvi_H/0/1/0/all/0/1">Hasan Rizvi</a>, <a href="http://arxiv.org/find/cs/1/au:+Satish_M/0/1/0/all/0/1">Mega Satish</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04551">
                                    <div class="article-summary-box-inner">
                                        <span>In the present study, we propose to implement a new framework for estimating
generative models via an adversarial process to extend an existing GAN
framework and develop a white-box controllable image cartoonization, which can
generate high-quality cartooned images/videos from real-world photos and
videos. The learning purposes of our system are based on three distinct
representations: surface representation, structure representation, and texture
representation. The surface representation refers to the smooth surface of the
images. The structure representation relates to the sparse colour blocks and
compresses generic content. The texture representation shows the texture,
curves, and features in cartoon images. Generative Adversarial Network (GAN)
framework decomposes the images into different representations and learns from
them to generate cartoon images. This decomposition makes the framework more
controllable and flexible which allows users to make changes based on the
required output. This approach overcomes any previous system in terms of
maintaining clarity, colours, textures, shapes of images yet showing the
characteristics of cartoon images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fixed-Budget Best-Arm Identification in Contextual Bandits: A Static-Adaptive Algorithm. (arXiv:2106.04763v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azizi_M/0/1/0/all/0/1">Mohammad Javad Azizi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1">Branislav Kveton</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1">Mohammad Ghavamzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04763">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of best-arm identification (BAI) in contextual bandits
in the fixed-budget setting. We propose a general successive elimination
algorithm that proceeds in stages and eliminates a fixed fraction of suboptimal
arms in each stage. This design takes advantage of the strengths of static and
adaptive allocations. We analyze the algorithm in linear models and obtain a
better error bound than prior work. We also apply it to generalized linear
models (GLMs) and bound its error. This is the first BAI algorithm for GLMs in
the fixed-budget setting. Our extensive numerical experiments show that our
algorithm outperforms the state of art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Dropout Discriminator for Domain Adaptation. (arXiv:2107.04231v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1">Vinod K Kurmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Subramanian_V/0/1/0/all/0/1">Venkatesh K Subramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1">Vinay P. Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04231">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptation of a classifier to new domains is one of the challenging problems
in machine learning. This has been addressed using many deep and non-deep
learning based methods. Among the methodologies used, that of adversarial
learning is widely applied to solve many deep learning problems along with
domain adaptation. These methods are based on a discriminator that ensures
source and target distributions are close. However, here we suggest that rather
than using a point estimate obtaining by a single discriminator, it would be
useful if a distribution based on ensembles of discriminators could be used to
bridge this gap. This could be achieved using multiple classifiers or using
traditional ensemble methods. In contrast, we suggest that a Monte Carlo
dropout based ensemble discriminator could suffice to obtain the distribution
based discriminator. Specifically, we propose a curriculum based dropout
discriminator that gradually increases the variance of the sample based
distribution and the corresponding reverse gradients are used to align the
source and target feature representations. An ensemble of discriminators helps
the model to learn the data distribution efficiently. It also provides a better
gradient estimates to train the feature extractor. The detailed results and
thorough ablation analysis show that our model outperforms state-of-the-art
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Form2Seq : A Framework for Higher-Order Form Structure Extraction. (arXiv:2107.04419v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_M/0/1/0/all/0/1">Milan Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_H/0/1/0/all/0/1">Hiresh Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_M/0/1/0/all/0/1">Mausoom Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1">Balaji Krishnamurthy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04419">
                                    <div class="article-summary-box-inner">
                                        <span>Document structure extraction has been a widely researched area for decades
with recent works performing it as a semantic segmentation task over document
images using fully-convolution networks. Such methods are limited by image
resolution due to which they fail to disambiguate structures in dense regions
which appear commonly in forms. To mitigate this, we propose Form2Seq, a novel
sequence-to-sequence (Seq2Seq) inspired framework for structure extraction
using text, with a specific focus on forms, which leverages relative spatial
arrangement of structures. We discuss two tasks; 1) Classification of low-level
constituent elements (TextBlock and empty fillable Widget) into ten types such
as field captions, list items, and others; 2) Grouping lower-level elements
into higher-order constructs, such as Text Fields, ChoiceFields and
ChoiceGroups, used as information collection mechanism in forms. To achieve
this, we arrange the constituent elements linearly in natural reading order,
feed their spatial and textual representations to Seq2Seq framework, which
sequentially outputs prediction of each element depending on the final task. We
modify Seq2Seq for grouping task and discuss improvements obtained through
cascaded end-to-end training of two tasks versus training in isolation.
Experimental results show the effectiveness of our text-based approach
achieving an accuracy of 90% on classification task and an F1 of 75.82, 86.01,
61.63 on groups discussed above respectively, outperforming segmentation
baselines. Further we show our framework achieves state of the results for
table structure recognition on ICDAR 2013 dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Likelihood ratio-based policy gradient methods for distorted risk measures: A non-asymptotic analysis. (arXiv:2107.04422v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vijayan_N/0/1/0/all/0/1">Nithia Vijayan</a>, <a href="http://arxiv.org/find/cs/1/au:+A_P/0/1/0/all/0/1">Prashanth L. A</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04422">
                                    <div class="article-summary-box-inner">
                                        <span>We propose policy-gradient algorithms for solving the problem of control in a
risk-sensitive reinforcement learning (RL) context. The objective of our
algorithm is to maximize the distorted risk measure (DRM) of the cumulative
reward in an episodic Markov decision process (MDP). We derive a variant of the
policy gradient theorem that caters to the DRM objective. Using this theorem in
conjunction with a likelihood ratio (LR) based gradient estimation scheme, we
propose policy gradient algorithms for optimizing DRM in both on-policy and
off-policy RL settings. We derive non-asymptotic bounds that establish the
convergence of our algorithms to an approximate stationary point of the DRM
objective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Behavior Self-Organization Supports Task Inference for Continual Robot Learning. (arXiv:2107.04533v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hafez_M/0/1/0/all/0/1">Muhammad Burhan Hafez</a>, <a href="http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1">Stefan Wermter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04533">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in robot learning have enabled robots to become increasingly
better at mastering a predefined set of tasks. On the other hand, as humans, we
have the ability to learn a growing set of tasks over our lifetime. Continual
robot learning is an emerging research direction with the goal of endowing
robots with this ability. In order to learn new tasks over time, the robot
first needs to infer the task at hand. Task inference, however, has received
little attention in the multi-task learning literature. In this paper, we
propose a novel approach to continual learning of robotic control tasks. Our
approach performs unsupervised learning of behavior embeddings by incrementally
self-organizing demonstrated behaviors. Task inference is made by finding the
nearest behavior embedding to a demonstrated behavior, which is used together
with the environment state as input to a multi-task policy trained with
reinforcement learning to optimize performance over tasks. Unlike previous
approaches, our approach makes no assumptions about task distribution and
requires no task exploration to infer tasks. We evaluate our approach in
experiments with concurrently and sequentially presented tasks and show that it
outperforms other multi-task learning approaches in terms of generalization
performance and convergence speed, particularly in the continual learning
setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NDPNet: A novel non-linear data projection network for few-shot fine-grained image classification. (arXiv:2106.06988v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weichuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuefang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1">Zhe Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yongsheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changming Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06988">
                                    <div class="article-summary-box-inner">
                                        <span>Metric-based few-shot fine-grained image classification (FSFGIC) aims to
learn a transferable feature embedding network by estimating the similarities
between query images and support classes from very few examples. In this work,
we propose, for the first time, to introduce the non-linear data projection
concept into the design of FSFGIC architecture in order to address the limited
sample problem in few-shot learning and at the same time to increase the
discriminability of the model for fine-grained image classification.
Specifically, we first design a feature re-abstraction embedding network that
has the ability to not only obtain the required semantic features for effective
metric learning but also re-enhance such features with finer details from input
images. Then the descriptors of the query images and the support classes are
projected into different non-linear spaces in our proposed similarity metric
learning network to learn discriminative projection factors. This design can
effectively operate in the challenging and restricted condition of a FSFGIC
task for making the distance between the samples within the same class smaller
and the distance between samples from different classes larger and for reducing
the coupling relationship between samples from different categories.
Furthermore, a novel similarity measure based on the proposed non-linear data
project is presented for evaluating the relationships of feature information
between a query image and a support set. It is worth to note that our proposed
architecture can be easily embedded into any episodic training mechanisms for
end-to-end training from scratch. Extensive experiments on FSFGIC tasks
demonstrate the superiority of the proposed methods over the state-of-the-art
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Program and Layout Transformations to enable DNN Operators on Specialized Hardware based on Constraint Programming. (arXiv:2104.04731v3 [cs.DC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rieber_D/0/1/0/all/0/1">Dennis Rieber</a>, <a href="http://arxiv.org/find/cs/1/au:+Acosta_A/0/1/0/all/0/1">Axel Acosta</a>, <a href="http://arxiv.org/find/cs/1/au:+Froning_H/0/1/0/all/0/1">Holger Fr&#xf6;ning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04731">
                                    <div class="article-summary-box-inner">
                                        <span>The success of Deep Artificial Neural Networks (DNNs) in many domains created
a rich body of research concerned with hardwareaccelerators for
compute-intensive DNN operators. However, implementing such operators
efficiently with complex hardwareintrinsics such as matrix multiply is a task
not yet automated gracefully. Solving this task often requires joint program
and data layouttransformations. First solutions to this problem have been
proposed, such as TVM, UNIT or ISAMIR, which work on a loop-levelrepresentation
of operators and specify data layout and possible program transformations
before the embedding into the operator isperformed. This top-down approach
creates a tension between exploration range and search space complexity,
especially when alsoexploring data layout transformations such as im2col,
channel packing or padding.In this work, we propose a new approach to this
problem. We created a bottom-up method that allows the joint transformation
ofboth compuation and data layout based on the found embedding. By formulating
the embedding as a constraint satisfaction problemover the scalar dataflow,
every possible embedding solution is contained in the search space. Adding
additional constraints andoptmization targets to the solver generates the
subset of preferable solutions.An evaluation using the VTA hardware accelerator
with the Baidu DeepBench inference benchmark shows that our approach
canautomatically generate code competitive to reference implementations.
Further, we show that dynamically determining the data layoutbased on intrinsic
and workload is beneficial for hardware utilization and performance. In cases
where the reference implementationhas low hardware utilization due to its fixed
deployment strategy, we achieve a geomean speedup of up to x2.813, while
individualoperators can improve as much as x170.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncovering the Connections Between Adversarial Transferability and Knowledge Transferability. (arXiv:2006.14512v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1">Kaizhao Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jacky Y. Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Boxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuolin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1">Oluwasanmi Koyejo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.14512">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge transferability, or transfer learning, has been widely adopted to
allow a pre-trained model in the source domain to be effectively adapted to
downstream tasks in the target domain. It is thus important to explore and
understand the factors affecting knowledge transferability. In this paper, as
the first work, we analyze and demonstrate the connections between knowledge
transferability and another important phenomenon--adversarial transferability,
\emph{i.e.}, adversarial examples generated against one model can be
transferred to attack other models. Our theoretical studies show that
adversarial transferability indicates knowledge transferability and vice versa.
Moreover, based on the theoretical insights, we propose two practical
adversarial transferability metrics to characterize this process, serving as
bidirectional indicators between adversarial and knowledge transferability. We
conduct extensive experiments for different scenarios on diverse datasets,
showing a positive correlation between adversarial transferability and
knowledge transferability. Our findings will shed light on future research
about effective knowledge transfer learning and adversarial transferability
analyses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aligning an optical interferometer with beam divergence control and continuous action space. (arXiv:2107.04457v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Makarenko_S/0/1/0/all/0/1">Stepan Makarenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorokin_D/0/1/0/all/0/1">Dmitry Sorokin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulanov_A/0/1/0/all/0/1">Alexander Ulanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Lvovsky_A/0/1/0/all/0/1">A. I. Lvovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04457">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning is finding its way to real-world problem application,
transferring from simulated environments to physical setups. In this work, we
implement vision-based alignment of an optical Mach-Zehnder interferometer with
a confocal telescope in one arm, which controls the diameter and divergence of
the corresponding beam. We use a continuous action space; exponential scaling
enables us to handle actions within a range of over two orders of magnitude.
Our agent trains only in a simulated environment with domain randomizations. In
an experimental evaluation, the agent significantly outperforms an existing
solution and a human expert.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Counterfactual Explanations on Graph Neural Networks. (arXiv:2107.04086v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bajaj_M/0/1/0/all/0/1">Mohit Bajaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_L/0/1/0/all/0/1">Lingyang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1">Zi Yu Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1">Jian Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lanjun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lam_P/0/1/0/all/0/1">Peter Cho-Ho Lam</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04086">
                                    <div class="article-summary-box-inner">
                                        <span>Massive deployment of Graph Neural Networks (GNNs) in high-stake applications
generates a strong demand for explanations that are robust to noise and align
well with human intuition. Most existing methods generate explanations by
identifying a subgraph of an input graph that has a strong correlation with the
prediction. These explanations are not robust to noise because independently
optimizing the correlation for a single input can easily overfit noise.
Moreover, they do not align well with human intuition because removing an
identified subgraph from an input graph does not necessarily change the
prediction result. In this paper, we propose a novel method to generate robust
counterfactual explanations on GNNs by explicitly modelling the common decision
logic of GNNs on similar input graphs. Our explanations are naturally robust to
noise because they are produced from the common decision boundaries of a GNN
that govern the predictions of many similar input graphs. The explanations also
align well with human intuition because removing the set of edges identified by
an explanation from the input graph changes the prediction significantly.
Exhaustive experiments on many public datasets demonstrate the superior
performance of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Breath Phase and Continuous Adventitious Sound Detection in Lung and Tracheal Sound Using Mixed Set Training and Domain Adaptation. (arXiv:2107.04229v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_F/0/1/0/all/0/1">Fu-Shun Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shang-Ran Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chang-Fu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chien-Wen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yuan-Ren Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chun-Chieh Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chun-Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chung-Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1">Yen-Chun Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_T/0/1/0/all/0/1">Tang-Wei Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_N/0/1/0/all/0/1">Nian-Jhen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_W/0/1/0/all/0/1">Wan-Ling Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Ching-Shiang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_F/0/1/0/all/0/1">Feipei Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04229">
                                    <div class="article-summary-box-inner">
                                        <span>Previously, we established a lung sound database, HF_Lung_V2 and proposed
convolutional bidirectional gated recurrent unit (CNN-BiGRU) models with
adequate ability for inhalation, exhalation, continuous adventitious sound
(CAS), and discontinuous adventitious sound detection in the lung sound. In
this study, we proceeded to build a tracheal sound database, HF_Tracheal_V1,
containing 11107 of 15-second tracheal sound recordings, 23087 inhalation
labels, 16728 exhalation labels, and 6874 CAS labels. The tracheal sound in
HF_Tracheal_V1 and the lung sound in HF_Lung_V2 were either combined or used
alone to train the CNN-BiGRU models for respective lung and tracheal sound
analysis. Different training strategies were investigated and compared: (1)
using full training (training from scratch) to train the lung sound models
using lung sound alone and train the tracheal sound models using tracheal sound
alone, (2) using a mixed set that contains both the lung and tracheal sound to
train the models, and (3) using domain adaptation that finetuned the
pre-trained lung sound models with the tracheal sound data and vice versa.
Results showed that the models trained only by lung sound performed poorly in
the tracheal sound analysis and vice versa. However, the mixed set training and
domain adaptation can improve the performance of exhalation and CAS detection
in the lung sound, and inhalation, exhalation, and CAS detection in the
tracheal sound compared to positive controls (lung models trained only by lung
sound and vice versa). Especially, a model derived from the mixed set training
prevails in the situation of killing two birds with one stone.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Convolutional Networks for Model-Based Learning in Nonlinear Inverse Problems. (arXiv:2103.15138v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Herzberg_W/0/1/0/all/0/1">William Herzberg</a>, <a href="http://arxiv.org/find/eess/1/au:+Rowe_D/0/1/0/all/0/1">Daniel B. Rowe</a>, <a href="http://arxiv.org/find/eess/1/au:+Hauptmann_A/0/1/0/all/0/1">Andreas Hauptmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Hamilton_S/0/1/0/all/0/1">Sarah J. Hamilton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15138">
                                    <div class="article-summary-box-inner">
                                        <span>The majority of model-based learned image reconstruction methods in medical
imaging have been limited to uniform domains, such as pixelated images. If the
underlying model is solved on nonuniform meshes, arising from a finite element
method typical for nonlinear inverse problems, interpolation and embeddings are
needed. To overcome this, we present a flexible framework to extend model-based
learning directly to nonuniform meshes, by interpreting the mesh as a graph and
formulating our network architectures using graph convolutional neural
networks. This gives rise to the proposed iterative Graph Convolutional
Newton-type Method (GCNM), which includes the forward model in the solution of
the inverse problem, while all updates are directly computed by the network on
the problem specific mesh. We present results for Electrical Impedance
Tomography, a severely ill-posed nonlinear inverse problem that is frequently
solved via optimization-based methods, where the forward problem is solved by
finite element methods. Results for absolute EIT imaging are compared to
standard iterative methods as well as a graph residual network. We show that
the GCNM has strong generalizability to different domain shapes and meshes, out
of distribution data as well as experimental data, from purely simulated
training data and without transfer training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Variance of the Fisher Information for Deep Learning. (arXiv:2107.04205v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soen_A/0/1/0/all/0/1">Alexander Soen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1">Ke Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04205">
                                    <div class="article-summary-box-inner">
                                        <span>The Fisher information matrix (FIM) has been applied to the realm of deep
learning. It is closely related to the loss landscape, the variance of the
parameters, second order optimization, and deep learning theory. The exact FIM
is either unavailable in closed form or too expensive to compute. In practice,
it is almost always estimated based on empirical samples. We investigate two
such estimators based on two equivalent representations of the FIM. They are
both unbiased and consistent with respect to the underlying &quot;true&quot; FIM. Their
estimation quality is characterized by their variance given in closed form. We
bound their variances and analyze how the parametric structure of a deep neural
network can impact the variance. We discuss the meaning of this variance
measure and our bounds in the context of deep learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Triangle Inequality for Cosine Similarity. (arXiv:2107.04071v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schubert_E/0/1/0/all/0/1">Erich Schubert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04071">
                                    <div class="article-summary-box-inner">
                                        <span>Similarity search is a fundamental problem for many data analysis techniques.
Many efficient search techniques rely on the triangle inequality of metrics,
which allows pruning parts of the search space based on transitive bounds on
distances. Recently, Cosine similarity has become a popular alternative choice
to the standard Euclidean metric, in particular in the context of textual data
and neural network embeddings. Unfortunately, Cosine similarity is not metric
and does not satisfy the standard triangle inequality. Instead, many search
techniques for Cosine rely on approximation techniques such as locality
sensitive hashing. In this paper, we derive a triangle inequality for Cosine
similarity that is suitable for efficient similarity search with many standard
search structures (such as the VP-tree, Cover-tree, and M-tree); show that this
bound is tight and discuss fast approximations for it. We hope that this spurs
new research on accelerating exact similarity search for cosine similarity, and
possible other similarity measures beyond the existing work for distance
metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Quantum-Secure Authentication and Key Agreement via Abstract Multi-Agent Interaction. (arXiv:2007.09327v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmed_I/0/1/0/all/0/1">Ibrahim H. Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanna_J/0/1/0/all/0/1">Josiah P. Hanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Fosong_E/0/1/0/all/0/1">Elliot Fosong</a>, <a href="http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1">Stefano V. Albrecht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.09327">
                                    <div class="article-summary-box-inner">
                                        <span>Current methods for authentication and key agreement based on public-key
cryptography are vulnerable to quantum computing. We propose a novel approach
based on artificial intelligence research in which communicating parties are
viewed as autonomous agents which interact repeatedly using their private
decision models. Authentication and key agreement are decided based on the
agents&#x27; observed behaviors during the interaction. The security of this
approach rests upon the difficulty of modeling the decisions of interacting
agents from limited observations, a problem which we conjecture is also hard
for quantum computing. We release PyAMI, a prototype authentication and key
agreement system based on the proposed method. We empirically validate our
method for authenticating legitimate users while detecting different types of
adversarial attacks. Finally, we show how reinforcement learning techniques can
be used to train server models which effectively probe a client&#x27;s decisions to
achieve more sample-efficient authentication.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inter-domain Multi-relational Link Prediction. (arXiv:2106.06171v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Phuc_L/0/1/0/all/0/1">Luu Huu Phuc</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeuchi_K/0/1/0/all/0/1">Koh Takeuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Okajima_S/0/1/0/all/0/1">Seiji Okajima</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolmachev_A/0/1/0/all/0/1">Arseny Tolmachev</a>, <a href="http://arxiv.org/find/cs/1/au:+Takebayashi_T/0/1/0/all/0/1">Tomoyoshi Takebayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Maruhashi_K/0/1/0/all/0/1">Koji Maruhashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1">Hisashi Kashima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06171">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-relational graph is a ubiquitous and important data structure, allowing
flexible representation of multiple types of interactions and relations between
entities. Similar to other graph-structured data, link prediction is one of the
most important tasks on multi-relational graphs and is often used for knowledge
completion. When related graphs coexist, it is of great benefit to build a
larger graph via integrating the smaller ones. The integration requires
predicting hidden relational connections between entities belonged to different
graphs (inter-domain link prediction). However, this poses a real challenge to
existing methods that are exclusively designed for link prediction between
entities of the same graph only (intra-domain link prediction). In this study,
we propose a new approach to tackle the inter-domain link prediction problem by
softly aligning the entity distributions between different domains with optimal
transport and maximum mean discrepancy regularizers. Experiments on real-world
datasets show that optimal transport regularizer is beneficial and considerably
improves the performance of baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilingual Byte2Speech Models for Scalable Low-resource Speech Synthesis. (arXiv:2103.03541v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_M/0/1/0/all/0/1">Mutian He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jingzhou Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Soong_F/0/1/0/all/0/1">Frank K. Soong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03541">
                                    <div class="article-summary-box-inner">
                                        <span>To scale neural speech synthesis to various real-world languages, we present
a multilingual end-to-end framework that maps byte inputs to spectrograms, thus
allowing arbitrary input scripts. Besides strong results on 40+ languages, the
framework demonstrates capabilities to adapt to new languages under extreme
low-resource and even few-shot scenarios of merely 40s transcribed recording,
without the need of per-language resources like lexicon, extra corpus,
auxiliary models, or linguistic expertise, thus ensuring scalability. While it
retains satisfactory intelligibility and naturalness matching rich-resource
models. Exhaustive comparative and ablation studies are performed to reveal the
potential of the framework for low-resource languages. Furthermore, we propose
a novel method to extract language-specific sub-networks in a multilingual
model for a better understanding of its mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Best of Many Worlds: Dual Mirror Descent for Online Allocation Problems. (arXiv:2011.10124v2 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balseiro_S/0/1/0/all/0/1">Santiago Balseiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haihao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10124">
                                    <div class="article-summary-box-inner">
                                        <span>Online allocation problems with resource constraints are central problems in
revenue management and online advertising. In these problems, requests arrive
sequentially during a finite horizon and, for each request, a decision maker
needs to choose an action that consumes a certain amount of resources and
generates reward. The objective is to maximize cumulative rewards subject to a
constraint on the total consumption of resources. In this paper, we consider a
data-driven setting in which the reward and resource consumption of each
request are generated using an input model that is unknown to the decision
maker.

We design a general class of algorithms that attain good performance in
various inputs models without knowing which type of input they are facing. In
particular, our algorithms are asymptotically optimal under stochastic i.i.d.
input model as well as various non-stationary stochastic input models, and they
attain an asymptotically optimal fixed competitive ratio when the input is
adversarial. Our algorithms operate in the Lagrangian dual space: they maintain
a dual multiplier for each resource that is updated using online mirror
descent. By choosing the reference function accordingly, we recover dual
sub-gradient descent and dual exponential weights algorithm. The resulting
algorithms are simple, fast, and have minimal requirements on the reward
functions, consumption functions and the action space, in contrast to existing
methods for online allocation problems. We discuss applications to network
revenue management, online bidding in repeated auctions with budget
constraints, online proportional matching with high entropy, and personalized
assortment optimization with limited inventories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Negative Transfer. (arXiv:2009.00909v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Lingfei Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongrui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00909">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning (TL) tries to utilize data or knowledge from one or more
source domains to facilitate the learning in a target domain. It is
particularly useful when the target domain has few or no labeled data, due to
annotation expense, privacy concerns, etc. Unfortunately, the effectiveness of
TL is not always guaranteed. Negative transfer (NT), i.e., the source domain
data/knowledge cause reduced learning performance in the target domain, has
been a long-standing and challenging problem in TL. Various approaches to
handle NT have been proposed in the literature. However, this filed lacks a
systematic survey on the formalization of NT, their factors and the algorithms
that handle NT. This paper proposes to fill this gap. First, the definition of
negative transfer is considered and a taxonomy of the factors are discussed.
Then, near fifty representative approaches for handling NT are categorized and
reviewed, from four perspectives: secure transfer, domain similarity
estimation, distant transfer and negative transfer mitigation. NT in related
fields, e.g., multi-task learning, lifelong learning, and adversarial attacks
are also discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Speech Recognition from Federated Acoustic Models. (arXiv:2104.14297v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Parcollet_T/0/1/0/all/0/1">Titouan Parcollet</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaiem_S/0/1/0/all/0/1">Salah Zaiem</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Marques_J/0/1/0/all/0/1">Javier Fernandez-Marques</a>, <a href="http://arxiv.org/find/cs/1/au:+Gusmao_P/0/1/0/all/0/1">Pedro P. B. de Gusmao</a>, <a href="http://arxiv.org/find/cs/1/au:+Beutel_D/0/1/0/all/0/1">Daniel J. Beutel</a>, <a href="http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1">Nicholas D. Lane</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14297">
                                    <div class="article-summary-box-inner">
                                        <span>Training Automatic Speech Recognition (ASR) models under federated learning
(FL) settings has attracted a lot of attention recently. However, the FL
scenarios often presented in the literature are artificial and fail to capture
the complexity of real FL systems. In this paper, we construct a challenging
and realistic ASR federated experimental setup consisting of clients with
heterogeneous data distributions using the French and Italian sets of the
CommonVoice dataset, a large heterogeneous dataset containing thousands of
different speakers, acoustic environments and noises. We present the first
empirical study on attention-based sequence-to-sequence End-to-End (E2E) ASR
model with three aggregation weighting strategies -- standard FedAvg,
loss-based aggregation and a novel word error rate (WER)-based aggregation,
compared in two realistic FL scenarios: cross-silo with 10 clients and
cross-device with 2K and 4K clients. Our analysis on E2E ASR from heterogeneous
and realistic federated acoustic models provides the foundations for future
research and development of realistic FL-based ASR applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid Generative Models for Two-Dimensional Datasets. (arXiv:2106.00203v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shajari_H/0/1/0/all/0/1">Hoda Shajari</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jaemoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ranka_S/0/1/0/all/0/1">Sanjay Ranka</a>, <a href="http://arxiv.org/find/cs/1/au:+Rangarajan_A/0/1/0/all/0/1">Anand Rangarajan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00203">
                                    <div class="article-summary-box-inner">
                                        <span>Two-dimensional array-based datasets are pervasive in a variety of domains.
Current approaches for generative modeling have typically been limited to
conventional image datasets and performed in the pixel domain which do not
explicitly capture the correlation between pixels. Additionally, these
approaches do not extend to scientific and other applications where each
element value is continuous and is not limited to a fixed range. In this paper,
we propose a novel approach for generating two-dimensional datasets by moving
the computations to the space of representation bases and show its usefulness
for two different datasets, one from imaging and another from scientific
computing. The proposed approach is general and can be applied to any dataset,
representation basis, or generative model. We provide a comprehensive
performance comparison of various combinations of generative models and
representation basis spaces. We also propose a new evaluation metric which
captures the deficiency of generating images in pixel space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlling Hallucinations at Word Level in Data-to-Text Generation. (arXiv:2102.02810v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rebuffel_C/0/1/0/all/0/1">Cl&#xe9;ment Rebuffel</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberti_M/0/1/0/all/0/1">Marco Roberti</a>, <a href="http://arxiv.org/find/cs/1/au:+Soulier_L/0/1/0/all/0/1">Laure Soulier</a>, <a href="http://arxiv.org/find/cs/1/au:+Scoutheeten_G/0/1/0/all/0/1">Geoffrey Scoutheeten</a>, <a href="http://arxiv.org/find/cs/1/au:+Cancelliere_R/0/1/0/all/0/1">Rossella Cancelliere</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02810">
                                    <div class="article-summary-box-inner">
                                        <span>Data-to-Text Generation (DTG) is a subfield of Natural Language Generation
aiming at transcribing structured data in natural language descriptions. The
field has been recently boosted by the use of neural-based generators which
exhibit on one side great syntactic skills without the need of hand-crafted
pipelines; on the other side, the quality of the generated text reflects the
quality of the training data, which in realistic settings only offer
imperfectly aligned structure-text pairs. Consequently, state-of-art neural
models include misleading statements - usually called hallucinations - in their
outputs. The control of this phenomenon is today a major challenge for DTG, and
is the problem addressed in the paper.

Previous work deal with this issue at the instance level: using an alignment
score for each table-reference pair. In contrast, we propose a finer-grained
approach, arguing that hallucinations should rather be treated at the word
level. Specifically, we propose a Multi-Branch Decoder which is able to
leverage word-level labels to learn the relevant parts of each training
instance. These labels are obtained following a simple and efficient scoring
procedure based on co-occurrence analysis and dependency parsing. Extensive
evaluations, via automated metrics and human judgment on the standard WikiBio
benchmark, show the accuracy of our alignment labels and the effectiveness of
the proposed Multi-Branch Decoder. Our model is able to reduce and control
hallucinations, while keeping fluency and coherence in generated texts. Further
experiments on a degraded version of ToTTo show that our model could be
successfully used on very noisy settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum-inspired Machine Learning on high-energy physics data. (arXiv:2004.13747v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Felser_T/0/1/0/all/0/1">Timo Felser</a>, <a href="http://arxiv.org/find/stat/1/au:+Trenti_M/0/1/0/all/0/1">Marco Trenti</a>, <a href="http://arxiv.org/find/stat/1/au:+Sestini_L/0/1/0/all/0/1">Lorenzo Sestini</a>, <a href="http://arxiv.org/find/stat/1/au:+Gianelle_A/0/1/0/all/0/1">Alessio Gianelle</a>, <a href="http://arxiv.org/find/stat/1/au:+Zuliani_D/0/1/0/all/0/1">Davide Zuliani</a>, <a href="http://arxiv.org/find/stat/1/au:+Lucchesi_D/0/1/0/all/0/1">Donatella Lucchesi</a>, <a href="http://arxiv.org/find/stat/1/au:+Montangero_S/0/1/0/all/0/1">Simone Montangero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.13747">
                                    <div class="article-summary-box-inner">
                                        <span>Tensor Networks, a numerical tool originally designed for simulating quantum
many-body systems, have recently been applied to solve Machine Learning
problems. Exploiting a tree tensor network, we apply a quantum-inspired machine
learning technique to a very important and challenging big data problem in high
energy physics: the analysis and classification of data produced by the Large
Hadron Collider at CERN. In particular, we present how to effectively classify
so-called b-jets, jets originating from b-quarks from proton-proton collisions
in the LHCb experiment, and how to interpret the classification results. We
exploit the Tensor Network approach to select important features and adapt the
network geometry based on information acquired in the learning process.
Finally, we show how to adapt the tree tensor network to achieve optimal
precision or fast response in time without the need of repeating the learning
process. These results pave the way to the implementation of high-frequency
real-time applications, a key ingredient needed among others for current and
future LHCb event classification able to trigger events at the tens of MHz
scale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Query-efficient Planning in MDPs under Linear Realizability of the Optimal State-value Function. (arXiv:2102.02049v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1">Gell&#xe9;rt Weisz</a>, <a href="http://arxiv.org/find/cs/1/au:+Amortila_P/0/1/0/all/0/1">Philip Amortila</a>, <a href="http://arxiv.org/find/cs/1/au:+Janzer_B/0/1/0/all/0/1">Barnab&#xe1;s Janzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1">Yasin Abbasi-Yadkori</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1">Csaba Szepesv&#xe1;ri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02049">
                                    <div class="article-summary-box-inner">
                                        <span>We consider local planning in fixed-horizon MDPs with a generative model
under the assumption that the optimal value function lies close to the span of
a feature map. The generative model provides a local access to the MDP: The
planner can ask for random transitions from previously returned states and
arbitrary actions, and features are only accessible for states that are
encountered in this process. As opposed to previous work (e.g. Lattimore et al.
(2020)) where linear realizability of all policies was assumed, we consider the
significantly relaxed assumption of a single linearly realizable
(deterministic) policy. A recent lower bound by Weisz et al. (2020) established
that the related problem when the action-value function of the optimal policy
is linearly realizable requires an exponential number of queries, either in $H$
(the horizon of the MDP) or $d$ (the dimension of the feature mapping). Their
construction crucially relies on having an exponentially large action set. In
contrast, in this work, we establish that poly$(H,d)$ planning is possible with
state value function realizability whenever the action set has a constant size.
In particular, we present the TensorPlan algorithm which uses
poly$((dH/\delta)^A)$ simulator queries to find a $\delta$-optimal policy
relative to any deterministic policy for which the value function is linearly
realizable with some bounded parameter. This is the first algorithm to give a
polynomial query complexity guarantee using only linear-realizability of a
single competing value function. Whether the computation cost is similarly
bounded remains an open question. We extend the upper bound to the
near-realizable case and to the infinite-horizon discounted setup. We also
present a lower bound in the infinite-horizon episodic setting: Planners that
achieve constant suboptimality need exponentially many queries, either in $d$
or the number of actions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autocalibration and Tweedie-dominance for Insurance Pricing with Machine Learning. (arXiv:2103.03635v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Denuit_M/0/1/0/all/0/1">Michel Denuit</a>, <a href="http://arxiv.org/find/stat/1/au:+Charpentier_A/0/1/0/all/0/1">Arthur Charpentier</a>, <a href="http://arxiv.org/find/stat/1/au:+Trufin_J/0/1/0/all/0/1">Julien Trufin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03635">
                                    <div class="article-summary-box-inner">
                                        <span>Boosting techniques and neural networks are particularly effective machine
learning methods for insurance pricing. Often in practice, there are
nevertheless endless debates about the choice of the right loss function to be
used to train the machine learning model, as well as about the appropriate
metric to assess the performances of competing models. Also, the sum of fitted
values can depart from the observed totals to a large extent and this often
confuses actuarial analysts. The lack of balance inherent to training models by
minimizing deviance outside the familiar GLM with canonical link setting has
been empirically documented in W\&quot;uthrich (2019, 2020) who attributes it to the
early stopping rule in gradient descent methods for model fitting. The present
paper aims to further study this phenomenon when learning proceeds by
minimizing Tweedie deviance. It is shown that minimizing deviance involves a
trade-off between the integral of weighted differences of lower partial moments
and the bias measured on a specific scale. Autocalibration is then proposed as
a remedy. This new method to correct for bias adds an extra local GLM step to
the analysis. Theoretically, it is shown that it implements the autocalibration
concept in pure premium calculation and ensures that balance also holds on a
local scale, not only at portfolio level as with existing bias-correction
techniques. The convex order appears to be the natural tool to compare
competing models, putting a new light on the diagnostic graphs and associated
metrics proposed by Denuit et al. (2019).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantile-Quantile Embedding for Distribution Transformation and Manifold Embedding with Ability to Choose the Embedding Distribution. (arXiv:2006.11385v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1">Benyamin Ghojogh</a>, <a href="http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1">Fakhri Karray</a>, <a href="http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1">Mark Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11385">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new embedding method, named Quantile-Quantile Embedding (QQE),
for distribution transformation and manifold embedding with the ability to
choose the embedding distribution. QQE, which uses the concept of
quantile-quantile plot from visual statistical tests, can transform the
distribution of data to any theoretical desired distribution or empirical
reference sample. Moreover, QQE gives the user a choice of embedding
distribution in embedding the manifold of data into the low dimensional
embedding space. It can also be used for modifying the embedding distribution
of other dimensionality reduction methods, such as PCA, t-SNE, and deep metric
learning, for better representation or visualization of data. We propose QQE in
both unsupervised and supervised forms. QQE can also transform a distribution
to either an exact reference distribution or its shape. We show that QQE allows
for better discrimination of classes in some cases. Our experiments on
different synthetic and image datasets show the effectiveness of the proposed
embedding method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAC Bayesian Performance Guarantees for Deep (Stochastic) Networks in Medical Imaging. (arXiv:2104.05600v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sicilia_A/0/1/0/all/0/1">Anthony Sicilia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xingchen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sosnovskikh_A/0/1/0/all/0/1">Anastasia Sosnovskikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Seong Jae Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05600">
                                    <div class="article-summary-box-inner">
                                        <span>Application of deep neural networks to medical imaging tasks has in some
sense become commonplace. Still, a &quot;thorn in the side&quot; of the deep learning
movement is the argument that deep networks are prone to overfitting and are
thus unable to generalize well when datasets are small (as is common in medical
imaging tasks). One way to bolster confidence is to provide mathematical
guarantees, or bounds, on network performance after training which explicitly
quantify the possibility of overfitting. In this work, we explore recent
advances using the PAC-Bayesian framework to provide bounds on generalization
error for large (stochastic) networks. While previous efforts focus on
classification in larger natural image datasets (e.g., MNIST and CIFAR-10), we
apply these techniques to both classification and segmentation in a smaller
medical imagining dataset: the ISIC 2018 challenge set. We observe the
resultant bounds are competitive compared to a simpler baseline, while also
being more explainable and alleviating the need for holdout sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gemmini: Enabling Systematic Deep-Learning Architecture Evaluation via Full-Stack Integration. (arXiv:1911.09925v3 [cs.DC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Genc_H/0/1/0/all/0/1">Hasan Genc</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seah Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Amid_A/0/1/0/all/0/1">Alon Amid</a>, <a href="http://arxiv.org/find/cs/1/au:+Haj_Ali_A/0/1/0/all/0/1">Ameer Haj-Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_V/0/1/0/all/0/1">Vighnesh Iyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_P/0/1/0/all/0/1">Pranav Prakash</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jerry Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Grubb_D/0/1/0/all/0/1">Daniel Grubb</a>, <a href="http://arxiv.org/find/cs/1/au:+Liew_H/0/1/0/all/0/1">Harrison Liew</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1">Howard Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_A/0/1/0/all/0/1">Albert Ou</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_C/0/1/0/all/0/1">Colin Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Steffl_S/0/1/0/all/0/1">Samuel Steffl</a>, <a href="http://arxiv.org/find/cs/1/au:+Wright_J/0/1/0/all/0/1">John Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a>, <a href="http://arxiv.org/find/cs/1/au:+Ragan_Kelley_J/0/1/0/all/0/1">Jonathan Ragan-Kelley</a>, <a href="http://arxiv.org/find/cs/1/au:+Asanovic_K/0/1/0/all/0/1">Krste Asanovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolic_B/0/1/0/all/0/1">Borivoje Nikolic</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1">Yakun Sophia Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.09925">
                                    <div class="article-summary-box-inner">
                                        <span>DNN accelerators are often developed and evaluated in isolation without
considering the cross-stack, system-level effects in real-world environments.
This makes it difficult to appreciate the impact of System-on-Chip (SoC)
resource contention, OS overheads, and programming-stack inefficiencies on
overall performance/energy-efficiency. To address this challenge, we present
Gemmini, an open-source*, full-stack DNN accelerator generator. Gemmini
generates a wide design-space of efficient ASIC accelerators from a flexible
architectural template, together with flexible programming stacks and full SoCs
with shared resources that capture system-level effects. Gemmini-generated
accelerators have also been fabricated, delivering up to three
orders-of-magnitude speedups over high-performance CPUs on various DNN
benchmarks.

* https://github.com/ucb-bar/gemmini</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Mean Field Games and Mean Field Control with Applications to Finance. (arXiv:2107.04568v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Carmona_R/0/1/0/all/0/1">Ren&#xe9; Carmona</a>, <a href="http://arxiv.org/find/math/1/au:+Lauriere_M/0/1/0/all/0/1">Mathieu Lauri&#xe8;re</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04568">
                                    <div class="article-summary-box-inner">
                                        <span>Financial markets and more generally macro-economic models involve a large
number of individuals interacting through variables such as prices resulting
from the aggregate behavior of all the agents. Mean field games have been
introduced to study Nash equilibria for such problems in the limit when the
number of players is infinite. The theory has been extensively developed in the
past decade, using both analytical and probabilistic tools, and a wide range of
applications have been discovered, from economics to crowd motion. More
recently the interaction with machine learning has attracted a growing
interest. This aspect is particularly relevant to solve very large games with
complex structures, in high dimension or with common sources of randomness. In
this chapter, we review the literature on the interplay between mean field
games and deep learning, with a focus on three families of methods. A special
emphasis is given to financial applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finite-Sample Analysis of Nonlinear Stochastic Approximation with Applications in Reinforcement Learning. (arXiv:1905.11425v6 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Chen_Z/0/1/0/all/0/1">Zaiwei Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_S/0/1/0/all/0/1">Sheng Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Doan_T/0/1/0/all/0/1">Thinh T. Doan</a>, <a href="http://arxiv.org/find/math/1/au:+Clarke_J/0/1/0/all/0/1">John-Paul Clarke</a>, <a href="http://arxiv.org/find/math/1/au:+Maguluri_S/0/1/0/all/0/1">Siva Theja Maguluri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.11425">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by applications in reinforcement learning (RL), we study a
nonlinear stochastic approximation (SA) algorithm under Markovian noise, and
establish its finite-sample convergence bounds under various stepsizes.
Specifically, we show that when using constant stepsize (i.e.,
$\epsilon_k\equiv \epsilon$), the algorithm achieves exponential fast
convergence with asymptotic accuracy $\mathcal{O}(\epsilon\log(1/\epsilon))$.
When using diminishing stepsizes with appropriate decay rate, the algorithm
converges with rate $\mathcal{O}(\log(k)/k)$. Our proof is based on the
Lyapunov drift arguments, and to handle the Markovian noise, we exploit the
fast mixing of the underlying Markov chain. To demonstrate the generality of
our theoretical results on Markovian SA, we use it to derive the finite-sample
bounds of the popular $Q$-learning with linear function approximation
algorithm, under a condition on the behavior policy. Importantly, we do not
need to make the unrealistic assumption that the samples are i.i.d., and do not
require an additional projection step in the algorithm to maintain the
boundedness of the iterates. Numerical simulations corroborate our theoretical
findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlling Graph Dynamics with Reinforcement Learning and Graph Neural Networks. (arXiv:2010.05313v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meirom_E/0/1/0/all/0/1">Eli A. Meirom</a>, <a href="http://arxiv.org/find/cs/1/au:+Maron_H/0/1/0/all/0/1">Haggai Maron</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05313">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of controlling a partially-observed dynamic process
on a graph by a limited number of interventions. This problem naturally arises
in contexts such as scheduling virus tests to curb an epidemic; targeted
marketing in order to promote a product; and manually inspecting posts to
detect fake news spreading on social networks.

We formulate this setup as a sequential decision problem over a temporal
graph process. In face of an exponential state space, combinatorial action
space and partial observability, we design a novel tractable scheme to control
dynamical processes on temporal graphs. We successfully apply our approach to
two popular problems that fall into our framework: prioritizing which nodes
should be tested in order to curb the spread of an epidemic, and influence
maximization on a graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BrainNetGAN: Data augmentation of brain connectivity using generative adversarial network for dementia classification. (arXiv:2103.08494v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yiran Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola-Bibiane Schonlieb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08494">
                                    <div class="article-summary-box-inner">
                                        <span>Alzheimer&#x27;s disease (AD) is the most common age-related dementia. It remains
a challenge to identify the individuals at risk of dementia for precise
management. Brain MRI offers a noninvasive biomarker to detect brain aging.
Previous evidence shows that the brain structural change detected by diffusion
MRI is associated with dementia. Mounting studies has conceptualised the brain
as a complex network, which has shown the utility of this approach in
characterising various neurological and psychiatric disorders. Therefore, the
structural connectivity shows promise in dementia classification. The proposed
BrainNetGAN is a generative adversarial network variant to augment the brain
structural connectivity matrices for binary dementia classification tasks.
Structural connectivity matrices between separated brain regions are
constructed using tractography on diffusion MRI data. The BrainNetGAN model is
trained to generate fake brain connectivity matrices, which are expected to
reflect latent distribution of the real brain network data. Finally, a
convolutional neural network classifier is proposed for binary dementia
classification. Numerical results show that the binary classification
performance in the testing set was improved using the BrainNetGAN augmented
dataset. The proposed methodology allows quick synthesis of an arbitrary number
of augmented connectivity matrices and can be easily transferred to similar
classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimising cost vs accuracy of decentralised analytics in fog computing environments. (arXiv:2012.05266v2 [cs.DC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Valerio_L/0/1/0/all/0/1">Lorenzo Valerio</a>, <a href="http://arxiv.org/find/cs/1/au:+Passarella_A/0/1/0/all/0/1">Andrea Passarella</a>, <a href="http://arxiv.org/find/cs/1/au:+Conti_M/0/1/0/all/0/1">Marco Conti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05266">
                                    <div class="article-summary-box-inner">
                                        <span>The exponential growth of devices and data at the edges of the Internet is
rising scalability and privacy concerns on approaches based exclusively on
remote cloud platforms. Data gravity, a fundamental concept in Fog Computing,
points towards decentralisation of computation for data analysis, as a viable
alternative to address those concerns. Decentralising AI tasks on several
cooperative devices means identifying the optimal set of locations or
Collection Points (CP for short) to use, in the continuum between full
centralisation (i.e., all data on a single device) and full decentralisation
(i.e., data on source locations). We propose an analytical framework able to
find the optimal operating point in this continuum, linking the accuracy of the
learning task with the corresponding network and computational cost for moving
data and running the distributed training at the CPs. We show through
simulations that the model accurately predicts the optimal trade-off, quite
often an intermediate point between full centralisation and full
decentralisation, showing also a significant cost saving w.r.t. both of them.
Finally, the analytical model admits closed-form or numeric solutions, making
it not only a performance evaluation instrument but also a design tool to
configure a given distributed learning task optimally before its deployment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold Density Estimation via Generalized Dequantization. (arXiv:2102.07143v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Brofos_J/0/1/0/all/0/1">James A. Brofos</a>, <a href="http://arxiv.org/find/stat/1/au:+Brubaker_M/0/1/0/all/0/1">Marcus A. Brubaker</a>, <a href="http://arxiv.org/find/stat/1/au:+Lederman_R/0/1/0/all/0/1">Roy R. Lederman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07143">
                                    <div class="article-summary-box-inner">
                                        <span>Density estimation is an important technique for characterizing distributions
given observations. Much existing research on density estimation has focused on
cases wherein the data lies in a Euclidean space. However, some kinds of data
are not well-modeled by supposing that their underlying geometry is Euclidean.
Instead, it can be useful to model such data as lying on a {\it manifold} with
some known structure. For instance, some kinds of data may be known to lie on
the surface of a sphere. We study the problem of estimating densities on
manifolds. We propose a method, inspired by the literature on &quot;dequantization,&quot;
which we interpret through the lens of a coordinate transformation of an
ambient Euclidean space and a smooth manifold of interest. Using methods from
normalizing flows, we apply this method to the dequantization of smooth
manifold structures in order to model densities on the sphere, tori, and the
orthogonal group.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Drug-Target Interaction Prediction via an Ensemble of Weighted Nearest Neighbors with Interaction Recovery. (arXiv:2012.12325v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pliakos_K/0/1/0/all/0/1">Konstantinos Pliakos</a>, <a href="http://arxiv.org/find/cs/1/au:+Vens_C/0/1/0/all/0/1">Celine Vens</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1">Grigorios Tsoumakas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12325">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting drug-target interactions (DTI) via reliable computational methods
is an effective and efficient way to mitigate the enormous costs and time of
the drug discovery process. Structure-based drug similarities and
sequence-based target protein similarities are the commonly used information
for DTI prediction. Among numerous computational methods, neighborhood-based
chemogenomic approaches that leverage drug and target similarities to perform
predictions directly are simple but promising ones. However, existing
similarity-based methods need to be re-trained to predict interactions for any
new drugs or targets and cannot directly perform predictions for both new
drugs, new targets, and new drug-target pairs. Furthermore, a large amount of
missing (undetected) interactions in current DTI datasets hinders most DTI
prediction methods. To address these issues, we propose a new method denoted as
Weighted k-Nearest Neighbor with Interaction Recovery (WkNNIR). Not only can
WkNNIR estimate interactions of any new drugs and/or new targets without any
need of re-training, but it can also recover missing interactions (false
negatives). In addition, WkNNIR exploits local imbalance to promote the
influence of more reliable similarities on the interaction recovery and
prediction processes. We also propose a series of ensemble methods that employ
diverse sampling strategies and could be coupled with WkNNIR as well as any
other DTI prediction method to improve performance. Experimental results over
five benchmark datasets demonstrate the effectiveness of our approaches in
predicting drug-target interactions. Lastly, we confirm the practical
prediction ability of proposed methods to discover reliable interactions that
were not reported in the original benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ViTGAN: Training GANs with Vision Transformers. (arXiv:2107.04589v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kwonjoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Huiwen Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhuowen Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Ce Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04589">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Vision Transformers (ViTs) have shown competitive performance on
image recognition while requiring less vision-specific inductive biases. In
this paper, we investigate if such observation can be extended to image
generation. To this end, we integrate the ViT architecture into generative
adversarial networks (GANs). We observe that existing regularization methods
for GANs interact poorly with self-attention, causing serious instability
during training. To resolve this issue, we introduce novel regularization
techniques for training GANs with ViTs. Empirically, our approach, named
ViTGAN, achieves comparable performance to state-of-the-art CNN-based StyleGAN2
on CIFAR-10, CelebA, and LSUN bedroom datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Bayesian Learning Rule. (arXiv:2107.04562v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1">Mohammad Emtiyaz Khan</a>, <a href="http://arxiv.org/find/stat/1/au:+Rue_H/0/1/0/all/0/1">H&#xe5;vard Rue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04562">
                                    <div class="article-summary-box-inner">
                                        <span>We show that many machine-learning algorithms are specific instances of a
single algorithm called the Bayesian learning rule. The rule, derived from
Bayesian principles, yields a wide-range of algorithms from fields such as
optimization, deep learning, and graphical models. This includes classical
algorithms such as ridge regression, Newton&#x27;s method, and Kalman filter, as
well as modern deep-learning algorithms such as stochastic-gradient descent,
RMSprop, and Dropout. The key idea in deriving such algorithms is to
approximate the posterior using candidate distributions estimated by using
natural gradients. Different candidate distributions result in different
algorithms and further approximations to natural gradients give rise to
variants of those algorithms. Our work not only unifies, generalizes, and
improves existing algorithms, but also helps us design new ones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Machine Translation to Localize Task Oriented NLG Output. (arXiv:2107.04512v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Scott Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Brunk_C/0/1/0/all/0/1">Cliff Brunk</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kyu-Young Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Justin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Freitag_M/0/1/0/all/0/1">Markus Freitag</a>, <a href="http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1">Mihir Kale</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_G/0/1/0/all/0/1">Gagan Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mudgal_S/0/1/0/all/0/1">Sidharth Mudgal</a>, <a href="http://arxiv.org/find/cs/1/au:+Varano_C/0/1/0/all/0/1">Chris Varano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04512">
                                    <div class="article-summary-box-inner">
                                        <span>One of the challenges in a task oriented natural language application like
the Google Assistant, Siri, or Alexa is to localize the output to many
languages. This paper explores doing this by applying machine translation to
the English output. Using machine translation is very scalable, as it can work
with any English output and can handle dynamic text, but otherwise the problem
is a poor fit. The required quality bar is close to perfection, the range of
sentences is extremely narrow, and the sentences are often very different than
the ones in the machine translation training data. This combination of
requirements is novel in the field of domain adaptation for machine
translation. We are able to reach the required quality bar by building on
existing ideas and adding new ones: finetuning on in-domain translations,
adding sentences from the Web, adding semantic annotations, and using automatic
error detection. The paper shares our approach and results, together with a
distillation model to serve the translation models at scale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLIB: Towards Automated Test Oracle for Graphically-Rich Applications. (arXiv:2106.10507v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Ke Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yufei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yingfeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Changjie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhipeng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10507">
                                    <div class="article-summary-box-inner">
                                        <span>Graphically-rich applications such as games are ubiquitous with attractive
visual effects of Graphical User Interface (GUI) that offers a bridge between
software applications and end-users. However, various types of graphical
glitches may arise from such GUI complexity and have become one of the main
component of software compatibility issues. Our study on bug reports from game
development teams in NetEase Inc. indicates that graphical glitches frequently
occur during the GUI rendering and severely degrade the quality of
graphically-rich applications such as video games. Existing automated testing
techniques for such applications focus mainly on generating various GUI test
sequences and check whether the test sequences can cause crashes. These
techniques require constant human attention to captures non-crashing bugs such
as bugs causing graphical glitches. In this paper, we present the first step in
automating the test oracle for detecting non-crashing bugs in graphically-rich
applications. Specifically, we propose \texttt{GLIB} based on a code-based data
augmentation technique to detect game GUI glitches. We perform an evaluation of
\texttt{GLIB} on 20 real-world game apps (with bug reports available) and the
result shows that \texttt{GLIB} can achieve 100\% precision and 99.5\% recall
in detecting non-crashing bugs such as game GUI glitches. Practical application
of \texttt{GLIB} on another 14 real-world games (without bug reports) further
demonstrates that \texttt{GLIB} can effectively uncover GUI glitches, with 48
of 53 bugs reported by \texttt{GLIB} having been confirmed and fixed so far.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Learning of General-Purpose Embeddings for Code Changes. (arXiv:2106.02087v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pravilov_M/0/1/0/all/0/1">Mikhail Pravilov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bogomolov_E/0/1/0/all/0/1">Egor Bogomolov</a>, <a href="http://arxiv.org/find/cs/1/au:+Golubev_Y/0/1/0/all/0/1">Yaroslav Golubev</a>, <a href="http://arxiv.org/find/cs/1/au:+Bryksin_T/0/1/0/all/0/1">Timofey Bryksin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02087">
                                    <div class="article-summary-box-inner">
                                        <span>Applying machine learning to tasks that operate with code changes requires
their numerical representation. In this work, we propose an approach for
obtaining such representations during pre-training and evaluate them on two
different downstream tasks - applying changes to code and commit message
generation. During pre-training, the model learns to apply the given code
change in a correct way. This task requires only code changes themselves, which
makes it unsupervised. In the task of applying code changes, our model
outperforms baseline models by 5.9 percentage points in accuracy. As for the
commit message generation, our model demonstrated the same results as
supervised models trained for this specific task, which indicates that it can
encode code changes well and can be improved in the future by pre-training on a
larger dataset of easily gathered code changes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASC-Net : Adversarial-based Selective Network for Unsupervised Anomaly Segmentation. (arXiv:2103.03664v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dey_R/0/1/0/all/0/1">Raunak Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yi Hong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03664">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a neural network framework, utilizing adversarial learning to
partition an image into two cuts, with one cut falling into a reference
distribution provided by the user. This concept tackles the task of
unsupervised anomaly segmentation, which has attracted increasing attention in
recent years due to their broad applications in tasks with unlabelled data.
This Adversarial-based Selective Cutting network (ASC-Net) bridges the two
domains of cluster-based deep learning methods and adversarial-based
anomaly/novelty detection algorithms. We evaluate this unsupervised learning
model on BraTS brain tumor segmentation, LiTS liver lesion segmentation, and
MS-SEG2015 segmentation tasks. Compared to existing methods like the AnoGAN
family, our model demonstrates tremendous performance gains in unsupervised
anomaly segmentation tasks. Although there is still room to further improve
performance compared to supervised learning algorithms, the promising
experimental results shed light on building an unsupervised learning algorithm
using user-defined knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-level Stress Assessment from ECG in a Virtual Reality Environment using Multimodal Fusion. (arXiv:2107.04566v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmad_Z/0/1/0/all/0/1">Zeeshan Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabbani_S/0/1/0/all/0/1">Suha Rabbani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zafar_M/0/1/0/all/0/1">Muhammad Rehman Zafar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishaque_S/0/1/0/all/0/1">Syem Ishaque</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnan_S/0/1/0/all/0/1">Sridhar Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naimul Khan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04566">
                                    <div class="article-summary-box-inner">
                                        <span>ECG is an attractive option to assess stress in serious Virtual Reality (VR)
applications due to its non-invasive nature. However, the existing Machine
Learning (ML) models perform poorly. Moreover, existing studies only perform a
binary stress assessment, while to develop a more engaging biofeedback-based
application, multi-level assessment is necessary. Existing studies annotate and
classify a single experience (e.g. watching a VR video) to a single stress
level, which again prevents design of dynamic experiences where real-time
in-game stress assessment can be utilized. In this paper, we report our
findings on a new study on VR stress assessment, where three stress levels are
assessed. ECG data was collected from 9 users experiencing a VR roller coaster.
The VR experience was then manually labeled in 10-seconds segments to three
stress levels by three raters. We then propose a novel multimodal deep fusion
model utilizing spectrogram and 1D ECG that can provide a stress prediction
from just a 1-second window. Experimental results demonstrate that the proposed
model outperforms the classical HRV-based ML models (9% increase in accuracy)
and baseline deep learning models (2.5% increase in accuracy). We also report
results on the benchmark WESAD dataset to show the supremacy of the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline reinforcement learning with uncertainty for treatment strategies in sepsis. (arXiv:2107.04491v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ran Liu</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Greenstein_J/0/1/0/all/0/1">Joseph L. Greenstein</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Fackler_J/0/1/0/all/0/1">James C. Fackler</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Bergmann_J/0/1/0/all/0/1">Jules Bergmann</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Bembea_M/0/1/0/all/0/1">Melania M. Bembea</a> (3 and 4), <a href="http://arxiv.org/find/cs/1/au:+Winslow_R/0/1/0/all/0/1">Raimond L. Winslow</a> (1 and 2) ((1) Institute for Computational Medicine, the Johns Hopkins University, (2) Department of Biomedical Engineering, the Johns Hopkins University School of Medicine and Whiting School of Engineering, (3) Department of Anesthesiology and Critical Care Medicine, the Johns Hopkins University, (4) Department of Pediatrics, the Johns Hopkins University School of Medicine)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04491">
                                    <div class="article-summary-box-inner">
                                        <span>Guideline-based treatment for sepsis and septic shock is difficult because
sepsis is a disparate range of life-threatening organ dysfunctions whose
pathophysiology is not fully understood. Early intervention in sepsis is
crucial for patient outcome, yet those interventions have adverse effects and
are frequently overadministered. Greater personalization is necessary, as no
single action is suitable for all patients. We present a novel application of
reinforcement learning in which we identify optimal recommendations for sepsis
treatment from data, estimate their confidence level, and identify treatment
options infrequently observed in training data. Rather than a single
recommendation, our method can present several treatment options. We examine
learned policies and discover that reinforcement learning is biased against
aggressive intervention due to the confounding relationship between mortality
and level of treatment received. We mitigate this bias using subspace learning,
and develop methodology that can yield more accurate learning policies across
healthcare applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low Rank Saddle Free Newton: Scalable Stochastic Nonconvex Optimization. (arXiv:2002.02881v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+OLeary_Roseberry_T/0/1/0/all/0/1">Thomas O&#x27;Leary-Roseberry</a>, <a href="http://arxiv.org/find/math/1/au:+Alger_N/0/1/0/all/0/1">Nick Alger</a>, <a href="http://arxiv.org/find/math/1/au:+Ghattas_O/0/1/0/all/0/1">Omar Ghattas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.02881">
                                    <div class="article-summary-box-inner">
                                        <span>Newton methods have fallen out of favor for modern optimization problems
(e.g. deep learning) because of concerns about per-iteration computational
complexity. In this setting highly subsampled first order methods are
preferred. In this work we motivate the extension of Newton methods to the
highly stochastic regime, and argue for the use of the scalable low rank saddle
free Newton (LRSFN) method. In this setting, iterative updates are dominated by
stochastic noise, and stability of the method is key. In stability analysis, we
demonstrate that stochastic errors for Newton methods can be greatly amplified
by ill-conditioned matrix operators. The LRSFN algorithm mitigates this issue
by the use of Levenberg-Marquardt damping, but generally second order methods
with stochastic Hessian and gradient information may need to take small steps,
unlike in deterministic problems. Numerical results show that even under
restrictive step-length conditions, LRSFN can outperform popular first order
methods on nontrivial deep learning tasks in terms of generalizability for
equivalent computational work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison of Contextual and Non-Contextual Preference Ranking for Set Addition Problems. (arXiv:2107.04438v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bertram_T/0/1/0/all/0/1">Timo Bertram</a>, <a href="http://arxiv.org/find/cs/1/au:+Furnkranz_J/0/1/0/all/0/1">Johannes F&#xfc;rnkranz</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_M/0/1/0/all/0/1">Martin M&#xfc;ller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04438">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the problem of evaluating the addition of elements to
a set. This problem is difficult, because it can, in the general case, not be
reduced to unconditional preferences between the choices. Therefore, we model
preferences based on the context of the decision. We discuss and compare two
different Siamese network architectures for this task: a twin network that
compares the two sets resulting after the addition, and a triplet network that
models the contribution of each candidate to the existing set. We evaluate the
two settings on a real-world task; learning human card preferences for deck
building in the collectible card game Magic: The Gathering. We show that the
triplet approach achieves a better result than the twin network and that both
outperform previous results on this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Reduced Order Modelling and Efficient Temporal Evolution of Fluid Simulations. (arXiv:2107.04556v1 [physics.flu-dyn])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Pant_P/0/1/0/all/0/1">Pranshu Pant</a>, <a href="http://arxiv.org/find/physics/1/au:+Doshi_R/0/1/0/all/0/1">Ruchit Doshi</a>, <a href="http://arxiv.org/find/physics/1/au:+Bahl_P/0/1/0/all/0/1">Pranav Bahl</a>, <a href="http://arxiv.org/find/physics/1/au:+Farimani_A/0/1/0/all/0/1">Amir Barati Farimani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04556">
                                    <div class="article-summary-box-inner">
                                        <span>Reduced Order Modelling (ROM) has been widely used to create lower order,
computationally inexpensive representations of higher-order dynamical systems.
Using these representations, ROMs can efficiently model flow fields while using
significantly lesser parameters. Conventional ROMs accomplish this by linearly
projecting higher-order manifolds to lower-dimensional space using
dimensionality reduction techniques such as Proper Orthogonal Decomposition
(POD). In this work, we develop a novel deep learning framework DL-ROM (Deep
Learning - Reduced Order Modelling) to create a neural network capable of
non-linear projections to reduced order states. We then use the learned reduced
state to efficiently predict future time steps of the simulation using 3D
Autoencoder and 3D U-Net based architectures. Our model DL-ROM is able to
create highly accurate reconstructions from the learned ROM and is thus able to
efficiently predict future time steps by temporally traversing in the learned
reduced state. All of this is achieved without ground truth supervision or
needing to iteratively solve the expensive Navier-Stokes(NS) equations thereby
resulting in massive computational savings. To test the effectiveness and
performance of our approach, we evaluate our implementation on five different
Computational Fluid Dynamics (CFD) datasets using reconstruction performance
and computational runtime metrics. DL-ROM can reduce the computational runtimes
of iterative solvers by nearly two orders of magnitude while maintaining an
acceptable error threshold.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BayesSimIG: Scalable Parameter Inference for Adaptive Domain Randomization with IsaacGym. (arXiv:2107.04527v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antonova_R/0/1/0/all/0/1">Rika Antonova</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1">Fabio Ramos</a>, <a href="http://arxiv.org/find/cs/1/au:+Possas_R/0/1/0/all/0/1">Rafael Possas</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04527">
                                    <div class="article-summary-box-inner">
                                        <span>BayesSim is a statistical technique for domain randomization in reinforcement
learning based on likelihood-free inference of simulation parameters. This
paper outlines BayesSimIG: a library that provides an implementation of
BayesSim integrated with the recently released NVIDIA IsaacGym. This
combination allows large-scale parameter inference with end-to-end GPU
acceleration. Both inference and simulation get GPU speedup, with support for
running more than 10K parallel simulation environments for complex robotics
tasks that can have more than 100 simulation parameters to estimate. BayesSimIG
provides an integration with TensorBoard to easily visualize slices of
high-dimensional posteriors. The library is built in a modular way to support
research experiments with novel ways to collect and process the trajectories
from the parallel IsaacGym environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Redescription Model Mining. (arXiv:2107.04462v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stamm_F/0/1/0/all/0/1">Felix I. Stamm</a>, <a href="http://arxiv.org/find/cs/1/au:+Becker_M/0/1/0/all/0/1">Martin Becker</a>, <a href="http://arxiv.org/find/cs/1/au:+Strohmaier_M/0/1/0/all/0/1">Markus Strohmaier</a>, <a href="http://arxiv.org/find/cs/1/au:+Lemmerich_F/0/1/0/all/0/1">Florian Lemmerich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04462">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces Redescription Model Mining, a novel approach to
identify interpretable patterns across two datasets that share only a subset of
attributes and have no common instances. In particular, Redescription Model
Mining aims to find pairs of describable data subsets -- one for each dataset
-- that induce similar exceptional models with respect to a prespecified model
class. To achieve this, we combine two previously separate research areas:
Exceptional Model Mining and Redescription Mining. For this new problem
setting, we develop interestingness measures to select promising patterns,
propose efficient algorithms, and demonstrate their potential on synthetic and
real-world data. Uncovered patterns can hint at common underlying phenomena
that manifest themselves across datasets, enabling the discovery of possible
associations between (combinations of) attributes that do not appear in the
same dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymptotic Optimality of Conditioned Stochastic Gradient Descent. (arXiv:2006.02745v3 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Leluc_R/0/1/0/all/0/1">R&#xe9;mi Leluc</a>, <a href="http://arxiv.org/find/math/1/au:+Portier_F/0/1/0/all/0/1">Fran&#xe7;ois Portier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.02745">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate a general class of stochastic gradient descent
(SGD) algorithms, called conditioned SGD, based on a preconditioning of the
gradient direction. Under some mild assumptions, namely the $L$-smoothness of
the non-convex objective function and some weak growth condition on the noise,
we establish the almost sure convergence and the asymptotic normality for a
broad class of conditioning matrices. In particular, when the conditioning
matrix is an estimate of the inverse Hessian at the optimal point, the
algorithm is proved to be asymptotically optimal. The benefits of this approach
are validated on simulated and real datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ANCER: Anisotropic Certification via Sample-wise Volume Maximization. (arXiv:2107.04570v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eiras_F/0/1/0/all/0/1">Francisco Eiras</a>, <a href="http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1">Motasem Alfarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1">M. Pawan Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H. S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Dokania_P/0/1/0/all/0/1">Puneet K. Dokania</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>, <a href="http://arxiv.org/find/cs/1/au:+Bibi_A/0/1/0/all/0/1">Adel Bibi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04570">
                                    <div class="article-summary-box-inner">
                                        <span>Randomized smoothing has recently emerged as an effective tool that enables
certification of deep neural network classifiers at scale. All prior art on
randomized smoothing has focused on isotropic $\ell_p$ certification, which has
the advantage of yielding certificates that can be easily compared among
isotropic methods via $\ell_p$-norm radius. However, isotropic certification
limits the region that can be certified around an input to worst-case
adversaries, \ie it cannot reason about other &quot;close&quot;, potentially large,
constant prediction safe regions. To alleviate this issue, (i) we theoretically
extend the isotropic randomized smoothing $\ell_1$ and $\ell_2$ certificates to
their generalized anisotropic counterparts following a simplified analysis.
Moreover, (ii) we propose evaluation metrics allowing for the comparison of
general certificates - a certificate is superior to another if it certifies a
superset region - with the quantification of each certificate through the
volume of the certified region. We introduce ANCER, a practical framework for
obtaining anisotropic certificates for a given test set sample via volume
maximization. Our empirical results demonstrate that ANCER achieves
state-of-the-art $\ell_1$ and $\ell_2$ certified accuracy on both CIFAR-10 and
ImageNet at multiple radii, while certifying substantially larger regions in
terms of volume, thus highlighting the benefits of moving away from isotropic
analysis. Code used in our experiments is available in
https://github.com/MotasemAlfarra/ANCER.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group-Node Attention for Community Evolution Prediction. (arXiv:2107.04522v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Revelle_M/0/1/0/all/0/1">Matt Revelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Domeniconi_C/0/1/0/all/0/1">Carlotta Domeniconi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gelman_B/0/1/0/all/0/1">Ben Gelman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04522">
                                    <div class="article-summary-box-inner">
                                        <span>Communities in social networks evolve over time as people enter and leave the
network and their activity behaviors shift. The task of predicting structural
changes in communities over time is known as community evolution prediction.
Existing work in this area has focused on the development of frameworks for
defining events while using traditional classification methods to perform the
actual prediction. We present a novel graph neural network for predicting
community evolution events from structural and temporal information. The model
(GNAN) includes a group-node attention component which enables support for
variable-sized inputs and learned representation of groups based on member and
neighbor node features. A comparative evaluation with standard baseline methods
is performed and we demonstrate that our model outperforms the baselines.
Additionally, we show the effects of network trends on model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bib2Auth: Deep Learning Approach for Author Disambiguation using Bibliographic Data. (arXiv:2107.04382v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boukhers_Z/0/1/0/all/0/1">Zeyd Boukhers</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahubali_N/0/1/0/all/0/1">Nagaraj Bahubali</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandrasekaran_A/0/1/0/all/0/1">Abinaya Thulsi Chandrasekaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1">Adarsh Anand</a>, <a href="http://arxiv.org/find/cs/1/au:+Prasadand_S/0/1/0/all/0/1">Soniya Manchenahalli Gnanendra Prasadand</a>, <a href="http://arxiv.org/find/cs/1/au:+Aralappa_S/0/1/0/all/0/1">Sriram Aralappa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04382">
                                    <div class="article-summary-box-inner">
                                        <span>Author name ambiguity remains a critical open problem in digital libraries
due to synonymy and homonymy of names. In this paper, we propose a novel
approach to link author names to their real-world entities by relying on their
co-authorship pattern and area of research. Our supervised deep learning model
identifies an author by capturing his/her relationship with his/her co-authors
and area of research, which is represented by the titles and sources of the
target author&#x27;s publications. These attributes are encoded by their semantic
and symbolic representations. To this end, Bib2Auth uses ~ 22K bibliographic
records from the DBLP repository and is trained with each pair of co-authors.
The extensive experiments have proved the capability of the approach to
distinguish between authors sharing the same name and recognize authors with
different name variations. Bib2Auth has shown good performance on a relatively
large dataset, which qualifies it to be directly integrated into bibliographic
indices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Learning in the Teacher-Student Setup: Impact of Task Similarity. (arXiv:2107.04384v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1">Sebastian Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Goldt_S/0/1/0/all/0/1">Sebastian Goldt</a>, <a href="http://arxiv.org/find/stat/1/au:+Saxe_A/0/1/0/all/0/1">Andrew Saxe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04384">
                                    <div class="article-summary-box-inner">
                                        <span>Continual learning-the ability to learn many tasks in sequence-is critical
for artificial learning systems. Yet standard training methods for deep
networks often suffer from catastrophic forgetting, where learning new tasks
erases knowledge of earlier tasks. While catastrophic forgetting labels the
problem, the theoretical reasons for interference between tasks remain unclear.
Here, we attempt to narrow this gap between theory and practice by studying
continual learning in the teacher-student setup. We extend previous analytical
work on two-layer networks in the teacher-student setup to multiple teachers.
Using each teacher to represent a different task, we investigate how the
relationship between teachers affects the amount of forgetting and transfer
exhibited by the student when the task switches. In line with recent work, we
find that when tasks depend on similar features, intermediate task similarity
leads to greatest forgetting. However, feature similarity is only one way in
which tasks may be related. The teacher-student approach allows us to
disentangle task similarity at the level of readouts (hidden-to-output weights)
and features (input-to-hidden weights). We find a complex interplay between
both types of similarity, initial transfer/forgetting rates, maximum
transfer/forgetting, and long-term transfer/forgetting. Together, these results
help illuminate the diverse factors contributing to catastrophic forgetting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Mixture Density Networks: Learning to Drive Safely from Collision Data. (arXiv:2107.04485v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuutti_S/0/1/0/all/0/1">Sampo Kuutti</a>, <a href="http://arxiv.org/find/cs/1/au:+Fallah_S/0/1/0/all/0/1">Saber Fallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowden_R/0/1/0/all/0/1">Richard Bowden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04485">
                                    <div class="article-summary-box-inner">
                                        <span>Imitation learning has been widely used to learn control policies for
autonomous driving based on pre-recorded data. However, imitation learning
based policies have been shown to be susceptible to compounding errors when
encountering states outside of the training distribution. Further, these agents
have been demonstrated to be easily exploitable by adversarial road users
aiming to create collisions. To overcome these shortcomings, we introduce
Adversarial Mixture Density Networks (AMDN), which learns two distributions
from separate datasets. The first is a distribution of safe actions learned
from a dataset of naturalistic human driving. The second is a distribution
representing unsafe actions likely to lead to collision, learned from a dataset
of collisions. During training, we leverage these two distributions to provide
an additional loss based on the similarity of the two distributions. By
penalising the safe action distribution based on its similarity to the unsafe
action distribution when training on the collision dataset, a more robust and
safe control policy is obtained. We demonstrate the proposed AMDN approach in a
vehicle following use-case, and evaluate under naturalistic and adversarial
testing environments. We show that despite its simplicity, AMDN provides
significant benefits for the safety of the learned control policy, when
compared to pure imitation learning or standard mixture density network
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UniRE: A Unified Label Space for Entity Relation Extraction. (arXiv:2107.04292v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yijun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changzhi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuanbin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04292">
                                    <div class="article-summary-box-inner">
                                        <span>Many joint entity relation extraction models setup two separated label spaces
for the two sub-tasks (i.e., entity detection and relation classification). We
argue that this setting may hinder the information interaction between entities
and relations. In this work, we propose to eliminate the different treatment on
the two sub-tasks&#x27; label spaces. The input of our model is a table containing
all word pairs from a sentence. Entities and relations are represented by
squares and rectangles in the table. We apply a unified classifier to predict
each cell&#x27;s label, which unifies the learning of two sub-tasks. For testing, an
effective (yet fast) approximate decoder is proposed for finding squares and
rectangles from tables. Experiments on three benchmarks (ACE04, ACE05, SciERC)
show that, using only half the number of parameters, our model achieves
competitive accuracy with the best extractor, and is faster.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Batch Inverse-Variance Weighting: Deep Heteroscedastic Regression. (arXiv:2107.04497v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mai_V/0/1/0/all/0/1">Vincent Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Khamies_W/0/1/0/all/0/1">Waleed Khamies</a>, <a href="http://arxiv.org/find/cs/1/au:+Paull_L/0/1/0/all/0/1">Liam Paull</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04497">
                                    <div class="article-summary-box-inner">
                                        <span>Heteroscedastic regression is the task of supervised learning where each
label is subject to noise from a different distribution. This noise can be
caused by the labelling process, and impacts negatively the performance of the
learning algorithm as it violates the i.i.d. assumptions. In many situations
however, the labelling process is able to estimate the variance of such
distribution for each label, which can be used as an additional information to
mitigate this impact. We adapt an inverse-variance weighted mean square error,
based on the Gauss-Markov theorem, for parameter optimization on neural
networks. We introduce Batch Inverse-Variance, a loss function which is robust
to near-ground truth samples, and allows to control the effective learning
rate. Our experimental results show that BIV improves significantly the
performance of the networks on two noisy datasets, compared to L2 loss,
inverse-variance weighting, as well as a filtering-based baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding surrogate explanations: the interplay between complexity, fidelity and coverage. (arXiv:2107.04309v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Poyiadzi_R/0/1/0/all/0/1">Rafael Poyiadzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Renard_X/0/1/0/all/0/1">Xavier Renard</a>, <a href="http://arxiv.org/find/cs/1/au:+Laugel_T/0/1/0/all/0/1">Thibault Laugel</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_Rodriguez_R/0/1/0/all/0/1">Raul Santos-Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Detyniecki_M/0/1/0/all/0/1">Marcin Detyniecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04309">
                                    <div class="article-summary-box-inner">
                                        <span>This paper analyses the fundamental ingredients behind surrogate explanations
to provide a better understanding of their inner workings. We start our
exposition by considering global surrogates, describing the trade-off between
complexity of the surrogate and fidelity to the black-box being modelled. We
show that transitioning from global to local - reducing coverage - allows for
more favourable conditions on the Pareto frontier of fidelity-complexity of a
surrogate. We discuss the interplay between complexity, fidelity and coverage,
and consider how different user needs can lead to problem formulations where
these are either constraints or penalties. We also present experiments that
demonstrate how the local surrogate interpretability procedure can be made
interactive and lead to better explanations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiaccurate Proxies for Downstream Fairness. (arXiv:2107.04423v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diana_E/0/1/0/all/0/1">Emily Diana</a>, <a href="http://arxiv.org/find/cs/1/au:+Gill_W/0/1/0/all/0/1">Wesley Gill</a>, <a href="http://arxiv.org/find/cs/1/au:+Kearns_M/0/1/0/all/0/1">Michael Kearns</a>, <a href="http://arxiv.org/find/cs/1/au:+Kenthapadi_K/0/1/0/all/0/1">Krishnaram Kenthapadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_A/0/1/0/all/0/1">Aaron Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharifi_Malvajerdi_S/0/1/0/all/0/1">Saeed Sharifi-Malvajerdi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04423">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of training a model that must obey demographic fairness
conditions when the sensitive features are not available at training time -- in
other words, how can we train a model to be fair by race when we don&#x27;t have
data about race? We adopt a fairness pipeline perspective, in which an
&quot;upstream&quot; learner that does have access to the sensitive features will learn a
proxy model for these features from the other attributes. The goal of the proxy
is to allow a general &quot;downstream&quot; learner -- with minimal assumptions on their
prediction task -- to be able to use the proxy to train a model that is fair
with respect to the true sensitive features. We show that obeying multiaccuracy
constraints with respect to the downstream model class suffices for this
purpose, and provide sample- and oracle efficient-algorithms and generalization
bounds for learning such proxies. In general, multiaccuracy can be much easier
to satisfy than classification accuracy, and can be satisfied even when the
sensitive features are hard to predict.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A First Look at Class Incremental Learning in Deep Learning Mobile Traffic Classification. (arXiv:2107.04464v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bovenzi_G/0/1/0/all/0/1">Giampaolo Bovenzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lixuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Finamore_A/0/1/0/all/0/1">Alessandro Finamore</a>, <a href="http://arxiv.org/find/cs/1/au:+Aceto_G/0/1/0/all/0/1">Giuseppe Aceto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciuonzo_D/0/1/0/all/0/1">Domenico Ciuonzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pescape_A/0/1/0/all/0/1">Antonio Pescap&#xe8;</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossi_D/0/1/0/all/0/1">Dario Rossi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04464">
                                    <div class="article-summary-box-inner">
                                        <span>The recent popularity growth of Deep Learning (DL) re-ignited the interest
towards traffic classification, with several studies demonstrating the accuracy
of DL-based classifiers to identify Internet applications&#x27; traffic. Even with
the aid of hardware accelerators (GPUs, TPUs), DL model training remains
expensive, and limits the ability to operate frequent model updates necessary
to fit to the ever evolving nature of Internet traffic, and mobile traffic in
particular. To address this pain point, in this work we explore Incremental
Learning (IL) techniques to add new classes to models without a full
retraining, hence speeding up model&#x27;s updates cycle. We consider iCarl, a state
of the art IL method, and MIRAGE-2019, a public dataset with traffic from 40
Android apps, aiming to understand &quot;if there is a case for incremental learning
in traffic classification&quot;. By dissecting iCarl internals, we discuss ways to
improve its design, contributing a revised version, namely iCarl+. Despite our
analysis reveals their infancy, IL techniques are a promising research area on
the roadmap towards automated DL-based traffic analysis systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Detect Adversarial Examples Based on Class Scores. (arXiv:2107.04435v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Uelwer_T/0/1/0/all/0/1">Tobias Uelwer</a>, <a href="http://arxiv.org/find/cs/1/au:+Michels_F/0/1/0/all/0/1">Felix Michels</a>, <a href="http://arxiv.org/find/cs/1/au:+Candido_O/0/1/0/all/0/1">Oliver De Candido</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04435">
                                    <div class="article-summary-box-inner">
                                        <span>Given the increasing threat of adversarial attacks on deep neural networks
(DNNs), research on efficient detection methods is more important than ever. In
this work, we take a closer look at adversarial attack detection based on the
class scores of an already trained classification model. We propose to train a
support vector machine (SVM) on the class scores to detect adversarial
examples. Our method is able to detect adversarial examples generated by
various attacks, and can be easily adopted to a plethora of deep classification
models. We show that our approach yields an improved detection rate compared to
an existing method, whilst being easy to implement. We perform an extensive
empirical analysis on different deep classification models, investigating
various state-of-the-art adversarial attacks. Moreover, we observe that our
proposed method is better at detecting a combination of adversarial attacks.
This work indicates the potential of detecting various adversarial attacks
simply by using the class scores of an already trained classification model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Model Robustness with Latent Distribution Locally and Globally. (arXiv:2107.04401v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_Z/0/1/0/all/0/1">Zhuang Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shufei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qiufeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xinping Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04401">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we consider model robustness of deep neural networks against
adversarial attacks from a global manifold perspective. Leveraging both the
local and global latent information, we propose a novel adversarial training
method through robust optimization, and a tractable way to generate Latent
Manifold Adversarial Examples (LMAEs) via an adversarial game between a
discriminator and a classifier. The proposed adversarial training with latent
distribution (ATLD) method defends against adversarial attacks by crafting
LMAEs with the latent manifold in an unsupervised manner. ATLD preserves the
local and global information of latent manifold and promises improved
robustness against adversarial attacks. To verify the effectiveness of our
proposed method, we conduct extensive experiments over different datasets
(e.g., CIFAR-10, CIFAR-100, SVHN) with different adversarial attacks (e.g.,
PGD, CW), and show that our method substantially outperforms the
state-of-the-art (e.g., Feature Scattering) in adversarial robustness by a
large accuracy margin. The source codes are available at
https://github.com/LitterQ/ATLD-pytorch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autoencoder-driven Spiral Representation Learning for Gravitational Wave Surrogate Modelling. (arXiv:2107.04312v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nousi_P/0/1/0/all/0/1">Paraskevi Nousi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fragkouli_S/0/1/0/all/0/1">Styliani-Christina Fragkouli</a>, <a href="http://arxiv.org/find/cs/1/au:+Passalis_N/0/1/0/all/0/1">Nikolaos Passalis</a>, <a href="http://arxiv.org/find/cs/1/au:+Iosif_P/0/1/0/all/0/1">Panagiotis Iosif</a>, <a href="http://arxiv.org/find/cs/1/au:+Apostolatos_T/0/1/0/all/0/1">Theocharis Apostolatos</a>, <a href="http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1">George Pappas</a>, <a href="http://arxiv.org/find/cs/1/au:+Stergioulas_N/0/1/0/all/0/1">Nikolaos Stergioulas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tefas_A/0/1/0/all/0/1">Anastasios Tefas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04312">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, artificial neural networks have been gaining momentum in the field
of gravitational wave astronomy, for example in surrogate modelling of
computationally expensive waveform models for binary black hole inspiral and
merger. Surrogate modelling yields fast and accurate approximations of
gravitational waves and neural networks have been used in the final step of
interpolating the coefficients of the surrogate model for arbitrary waveforms
outside the training sample. We investigate the existence of underlying
structures in the empirical interpolation coefficients using autoencoders. We
demonstrate that when the coefficient space is compressed to only two
dimensions, a spiral structure appears, wherein the spiral angle is linearly
related to the mass ratio. Based on this finding, we design a spiral module
with learnable parameters, that is used as the first layer in a neural network,
which learns to map the input space to the coefficients. The spiral module is
evaluated on multiple neural network architectures and consistently achieves
better speed-accuracy trade-off than baseline models. A thorough experimental
study is conducted and the final result is a surrogate model which can evaluate
millions of input parameters in a single forward pass in under 1ms on a desktop
GPU, while the mismatch between the corresponding generated waveforms and the
ground-truth waveforms is better than the compared baseline methods. We
anticipate the existence of analogous underlying structures and corresponding
computational gains also in the case of spinning black hole binaries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model compression as constrained optimization, with application to neural nets. Part V: combining compressions. (arXiv:2107.04380v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Carreira_Perpinan_M/0/1/0/all/0/1">Miguel &#xc1;. Carreira-Perpi&#xf1;&#xe1;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Idelbayev_Y/0/1/0/all/0/1">Yerlan Idelbayev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04380">
                                    <div class="article-summary-box-inner">
                                        <span>Model compression is generally performed by using quantization, low-rank
approximation or pruning, for which various algorithms have been researched in
recent years. One fundamental question is: what types of compression work
better for a given model? Or even better: can we improve by combining
compressions in a suitable way? We formulate this generally as a problem of
optimizing the loss but where the weights are constrained to equal an additive
combination of separately compressed parts; and we give an algorithm to learn
the corresponding parts&#x27; parameters. Experimentally with deep neural nets, we
observe that 1) we can find significantly better models in the
error-compression space, indicating that different compression types have
complementary benefits, and 2) the best type of combination depends exquisitely
on the type of neural net. For example, we can compress ResNets and AlexNet
using only 1 bit per weight without error degradation at the cost of adding a
few floating point weights. However, VGG nets can be better compressed by
combining low-rank with a few floating point weights.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to choose an Explainability Method? Towards a Methodical Implementation of XAI in Practice. (arXiv:2107.04427v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vermeire_T/0/1/0/all/0/1">Tom Vermeire</a>, <a href="http://arxiv.org/find/cs/1/au:+Laugel_T/0/1/0/all/0/1">Thibault Laugel</a>, <a href="http://arxiv.org/find/cs/1/au:+Renard_X/0/1/0/all/0/1">Xavier Renard</a>, <a href="http://arxiv.org/find/cs/1/au:+Martens_D/0/1/0/all/0/1">David Martens</a>, <a href="http://arxiv.org/find/cs/1/au:+Detyniecki_M/0/1/0/all/0/1">Marcin Detyniecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04427">
                                    <div class="article-summary-box-inner">
                                        <span>Explainability is becoming an important requirement for organizations that
make use of automated decision-making due to regulatory initiatives and a shift
in public awareness. Various and significantly different algorithmic methods to
provide this explainability have been introduced in the field, but the existing
literature in the machine learning community has paid little attention to the
stakeholder whose needs are rather studied in the human-computer interface
community. Therefore, organizations that want or need to provide this
explainability are confronted with the selection of an appropriate method for
their use case. In this paper, we argue there is a need for a methodology to
bridge the gap between stakeholder needs and explanation methods. We present
our ongoing work on creating this methodology to help data scientists in the
process of providing explainability to stakeholders. In particular, our
contributions include documents used to characterize XAI methods and user
requirements (shown in Appendix), which our methodology builds upon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Low-Resource Neural Machine Translation. (arXiv:2107.04239v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1">Renqian Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04239">
                                    <div class="article-summary-box-inner">
                                        <span>Neural approaches have achieved state-of-the-art accuracy on machine
translation but suffer from the high cost of collecting large scale parallel
data. Thus, a lot of research has been conducted for neural machine translation
(NMT) with very limited parallel data, i.e., the low-resource setting. In this
paper, we provide a survey for low-resource NMT and classify related works into
three categories according to the auxiliary data they used: (1) exploiting
monolingual data of source and/or target languages, (2) exploiting data from
auxiliary languages, and (3) exploiting multi-modal data. We hope that our
survey can help researchers to better understand this field and inspire them to
design better algorithms, and help industry practitioners to choose appropriate
algorithms for their applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convergence analysis for gradient flows in the training of artificial neural networks with ReLU activation. (arXiv:2107.04479v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jentzen_A/0/1/0/all/0/1">Arnulf Jentzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Riekert_A/0/1/0/all/0/1">Adrian Riekert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04479">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient descent (GD) type optimization schemes are the standard methods to
train artificial neural networks (ANNs) with rectified linear unit (ReLU)
activation. Such schemes can be considered as discretizations of gradient flows
(GFs) associated to the training of ANNs with ReLU activation and most of the
key difficulties in the mathematical convergence analysis of GD type
optimization schemes in the training of ANNs with ReLU activation seem to be
already present in the dynamics of the corresponding GF differential equations.
It is the key subject of this work to analyze such GF differential equations in
the training of ANNs with ReLU activation and three layers (one input layer,
one hidden layer, and one output layer). In particular, in this article we
prove in the case where the target function is possibly multi-dimensional and
continuous and in the case where the probability distribution of the input data
is absolutely continuous with respect to the Lebesgue measure that the risk of
every bounded GF trajectory converges to the risk of a critical point. In
addition, in this article we show in the case of a 1-dimensional affine linear
target function and in the case where the probability distribution of the input
data coincides with the standard uniform distribution that the risk of every
bounded GF trajectory converges to zero if the initial risk is sufficiently
small. Finally, in the special situation where there is only one neuron on the
hidden layer (1-dimensional hidden layer) we strengthen the above named result
for affine linear target functions by proving that that the risk of every (not
necessarily bounded) GF trajectory converges to zero if the initial risk is
sufficiently small.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Trajectory Prediction with Structural Constraints. (arXiv:2107.04193v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhi_W/0/1/0/all/0/1">Weiming Zhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ott_L/0/1/0/all/0/1">Lionel Ott</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1">Fabio Ramos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04193">
                                    <div class="article-summary-box-inner">
                                        <span>This work addresses the problem of predicting the motion trajectories of
dynamic objects in the environment. Recent advances in predicting motion
patterns often rely on machine learning techniques to extrapolate motion
patterns from observed trajectories, with no mechanism to directly incorporate
known rules. We propose a novel framework, which combines probabilistic
learning and constrained trajectory optimisation. The learning component of our
framework provides a distribution over future motion trajectories conditioned
on observed past coordinates. This distribution is then used as a prior to a
constrained optimisation problem which enforces chance constraints on the
trajectory distribution. This results in constraint-compliant trajectory
distributions which closely resemble the prior. In particular, we focus our
investigation on collision constraints, such that extrapolated future
trajectory distributions conform to the environment structure. We empirically
demonstrate on real-world and simulated datasets the ability of our framework
to learn complex probabilistic motion trajectories for motion data, while
directly enforcing constraints to improve generalisability, producing more
robust and higher quality trajectory distributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multitask Multi-database Emotion Recognition. (arXiv:2107.04127v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vu_M/0/1/0/all/0/1">Manh Tu Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Beurton_Aimar_M/0/1/0/all/0/1">Marie Beurton-Aimar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04127">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce our submission to the 2nd Affective Behavior
Analysis in-the-wild (ABAW) 2021 competition. We train a unified deep learning
model on multi-databases to perform two tasks: seven basic facial expressions
prediction and valence-arousal estimation. Since these databases do not
contains labels for all the two tasks, we have applied the distillation
knowledge technique to train two networks: one teacher and one student model.
The student model will be trained using both ground truth labels and soft
labels derived from the pretrained teacher model. During the training, we add
one more task, which is the combination of the two mentioned tasks, for better
exploiting inter-task correlations. We also exploit the sharing videos between
the two tasks of the AffWild2 database that is used in the competition, to
further improve the performance of the network. Experiment results shows that
the network have achieved promising results on the validation set of the
AffWild2 database. Code and pretrained model are publicly available at
https://github.com/glmanhtu/multitask-abaw-2021</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hoechst Is All You Need: LymphocyteClassification with Deep Learning. (arXiv:2107.04388v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cooper_J/0/1/0/all/0/1">Jessica Cooper</a>, <a href="http://arxiv.org/find/cs/1/au:+Um_I/0/1/0/all/0/1">In Hwa Um</a>, <a href="http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1">Ognjen Arandjelovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Harrison_D/0/1/0/all/0/1">David J Harrison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04388">
                                    <div class="article-summary-box-inner">
                                        <span>Multiplex immunofluorescence and immunohistochemistry benefit patients by
allowing cancer pathologists to identify several proteins expressed on the
surface of cells, enabling cell classification, better understanding of the
tumour micro-environment, more accurate diagnoses, prognoses, and tailored
immunotherapy based on the immune status of individual patients. However, they
are expensive and time consuming processes which require complex staining and
imaging techniques by expert technicians. Hoechst staining is much cheaper and
easier to perform, but is not typically used in this case as it binds to DNA
rather than to the proteins targeted by immunofluorescent techniques, and it
was not previously thought possible to differentiate cells expressing these
proteins based only on DNA morphology. In this work we show otherwise, training
a deep convolutional neural network to identify cells expressing three proteins
(T lymphocyte markers CD3 and CD8, and the B lymphocyte marker CD20) with
greater than 90% precision and recall, from Hoechst 33342 stained tissue only.
Our model learns previously unknown morphological features associated with
expression of these proteins which can be used to accurately differentiate
lymphocyte subtypes for use in key prognostic metrics such as assessment of
immune cell infiltration,and thereby predict and improve patient outcomes
without the need for costly multiplex immunofluorescence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Image Synthesis from Intuitive User Input: A Review and Perspectives. (arXiv:2107.04240v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1">Yuan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuan-Chen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Han Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Song-Hai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaolei Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04240">
                                    <div class="article-summary-box-inner">
                                        <span>In many applications of computer graphics, art and design, it is desirable
for a user to provide intuitive non-image input, such as text, sketch, stroke,
graph or layout, and have a computer system automatically generate
photo-realistic images that adhere to the input content. While classic works
that allow such automatic image content generation have followed a framework of
image retrieval and composition, recent advances in deep generative models such
as generative adversarial networks (GANs), variational autoencoders (VAEs), and
flow-based methods have enabled more powerful and versatile image generation
tasks. This paper reviews recent works for image synthesis given intuitive user
input, covering advances in input versatility, image generation methodology,
benchmark datasets, and evaluation metrics. This motivates new perspectives on
input representation and interactivity, cross pollination between major image
generation paradigms, and evaluation and comparison of generation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Specialists Outperform Generalists in Ensemble Classification. (arXiv:2107.04381v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meyen_S/0/1/0/all/0/1">Sascha Meyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Goppert_F/0/1/0/all/0/1">Frieder G&#xf6;ppert</a>, <a href="http://arxiv.org/find/cs/1/au:+Alber_H/0/1/0/all/0/1">Helen Alber</a>, <a href="http://arxiv.org/find/cs/1/au:+Luxburg_U/0/1/0/all/0/1">Ulrike von Luxburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Franz_V/0/1/0/all/0/1">Volker H. Franz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04381">
                                    <div class="article-summary-box-inner">
                                        <span>Consider an ensemble of $k$ individual classifiers whose accuracies are
known. Upon receiving a test point, each of the classifiers outputs a predicted
label and a confidence in its prediction for this particular test point. In
this paper, we address the question of whether we can determine the accuracy of
the ensemble. Surprisingly, even when classifiers are combined in the
statistically optimal way in this setting, the accuracy of the resulting
ensemble classifier cannot be computed from the accuracies of the individual
classifiers-as would be the case in the standard setting of confidence weighted
majority voting. We prove tight upper and lower bounds on the ensemble
accuracy. We explicitly construct the individual classifiers that attain the
upper and lower bounds: specialists and generalists. Our theoretical results
have very practical consequences: (1) If we use ensemble methods and have the
choice to construct our individual (independent) classifiers from scratch, then
we should aim for specialist classifiers rather than generalists. (2) Our
bounds can be used to determine how many classifiers are at least required to
achieve a desired ensemble accuracy. Finally, we improve our bounds by
considering the mutual information between the true label and the individual
classifier&#x27;s output.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IDRLnet: A Physics-Informed Neural Network Library. (arXiv:2107.04320v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Weien Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xiaoyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1">Wen Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoqian Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04320">
                                    <div class="article-summary-box-inner">
                                        <span>Physics Informed Neural Network (PINN) is a scientific computing framework
used to solve both forward and inverse problems modeled by Partial Differential
Equations (PDEs). This paper introduces IDRLnet, a Python toolbox for modeling
and solving problems through PINN systematically. IDRLnet constructs the
framework for a wide range of PINN algorithms and applications. It provides a
structured way to incorporate geometric objects, data sources, artificial
neural networks, loss metrics, and optimizers within Python. Furthermore, it
provides functionality to solve noisy inverse problems, variational
minimization, and integral differential equations. New PINN variants can be
integrated into the framework easily. Source code, tutorials, and documentation
are available at \url{https://github.com/idrl-lab/idrlnet}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">REX: Revisiting Budgeted Training with an Improved Schedule. (arXiv:2107.04197v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">John Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1">Anastasios Kyrillidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04197">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning practitioners often operate on a computational and monetary
budget. Thus, it is critical to design optimization algorithms that perform
well under any budget. The linear learning rate schedule is considered the best
budget-aware schedule, as it outperforms most other schedules in the low budget
regime. On the other hand, learning rate schedules -- such as the
\texttt{30-60-90} step schedule -- are known to achieve high performance when
the model can be trained for many epochs. Yet, it is often not known a priori
whether one&#x27;s budget will be large or small; thus, the optimal choice of
learning rate schedule is made on a case-by-case basis. In this paper, we frame
the learning rate schedule selection problem as a combination of $i)$ selecting
a profile (i.e., the continuous function that models the learning rate
schedule), and $ii)$ choosing a sampling rate (i.e., how frequently the
learning rate is updated/sampled from this profile). We propose a novel profile
and sampling rate combination called the Reflected Exponential (REX) schedule,
which we evaluate across seven different experimental settings with both SGD
and Adam optimizers. REX outperforms the linear schedule in the low budget
regime, while matching or exceeding the performance of several state-of-the-art
learning rate schedules (linear, step, exponential, cosine, step decay on
plateau, and OneCycle) in both high and low budget regimes. Furthermore, REX
requires no added computation, storage, or hyperparameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training a Deep Neural Network via Policy Gradients for Blind Source Separation in Polyphonic Music Recordings. (arXiv:2107.04235v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Schulze_S/0/1/0/all/0/1">S&#xf6;ren Schulze</a>, <a href="http://arxiv.org/find/eess/1/au:+Leuschner_J/0/1/0/all/0/1">Johannes Leuschner</a>, <a href="http://arxiv.org/find/eess/1/au:+King_E/0/1/0/all/0/1">Emily J. King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04235">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a method for the blind separation of sounds of musical instruments
in audio signals. We describe the individual tones via a parametric model,
training a dictionary to capture the relative amplitudes of the harmonics. The
model parameters are predicted via a U-Net, which is a type of deep neural
network. The network is trained without ground truth information, based on the
difference between the model prediction and the individual STFT time frames.
Since some of the model parameters do not yield a useful backpropagation
gradient, we model them stochastically and employ the policy gradient instead.
To provide phase information and account for inaccuracies in the
dictionary-based representation, we also let the network output a direct
prediction, which we then use to resynthesize the audio signals for the
individual instruments. Due to the flexibility of the neural network,
inharmonicity can be incorporated seamlessly and no preprocessing of the input
spectra is required. Our algorithm yields high-quality separation results with
particularly low interference on a variety of different audio samples, both
acoustic and synthetic, provided that the sample contains enough data for the
training and that the spectral characteristics of the musical instruments are
sufficiently stable to be approximated by the dictionary.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sensitivity analysis in differentially private machine learning using hybrid automatic differentiation. (arXiv:2107.04265v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ziller_A/0/1/0/all/0/1">Alexander Ziller</a>, <a href="http://arxiv.org/find/cs/1/au:+Usynin_D/0/1/0/all/0/1">Dmitrii Usynin</a>, <a href="http://arxiv.org/find/cs/1/au:+Knolle_M/0/1/0/all/0/1">Moritz Knolle</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_K/0/1/0/all/0/1">Kritika Prakash</a>, <a href="http://arxiv.org/find/cs/1/au:+Trask_A/0/1/0/all/0/1">Andrew Trask</a>, <a href="http://arxiv.org/find/cs/1/au:+Braren_R/0/1/0/all/0/1">Rickmer Braren</a>, <a href="http://arxiv.org/find/cs/1/au:+Makowski_M/0/1/0/all/0/1">Marcus Makowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04265">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, formal methods of privacy protection such as differential
privacy (DP), capable of deployment to data-driven tasks such as machine
learning (ML), have emerged. Reconciling large-scale ML with the closed-form
reasoning required for the principled analysis of individual privacy loss
requires the introduction of new tools for automatic sensitivity analysis and
for tracking an individual&#x27;s data and their features through the flow of
computation. For this purpose, we introduce a novel \textit{hybrid} automatic
differentiation (AD) system which combines the efficiency of reverse-mode AD
with an ability to obtain a closed-form expression for any given quantity in
the computational graph. This enables modelling the sensitivity of arbitrary
differentiable function compositions, such as the training of neural networks
on private data. We demonstrate our approach by analysing the individual DP
guarantees of statistical database queries. Moreover, we investigate the
application of our technique to the training of DP neural networks. Our
approach can enable the principled reasoning about privacy loss in the setting
of data processing, and further the development of automatic sensitivity
analysis and privacy budgeting systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially private training of neural networks with Langevin dynamics forcalibrated predictive uncertainty. (arXiv:2107.04296v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Knolle_M/0/1/0/all/0/1">Moritz Knolle</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziller_A/0/1/0/all/0/1">Alexander Ziller</a>, <a href="http://arxiv.org/find/cs/1/au:+Usynin_D/0/1/0/all/0/1">Dmitrii Usynin</a>, <a href="http://arxiv.org/find/cs/1/au:+Braren_R/0/1/0/all/0/1">Rickmer Braren</a>, <a href="http://arxiv.org/find/cs/1/au:+Makowski_M/0/1/0/all/0/1">Marcus R. Makowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04296">
                                    <div class="article-summary-box-inner">
                                        <span>We show that differentially private stochastic gradient descent (DP-SGD) can
yield poorly calibrated, overconfident deep learning models. This represents a
serious issue for safety-critical applications, e.g. in medical diagnosis. We
highlight and exploit parallels between stochastic gradient Langevin dynamics,
a scalable Bayesian inference technique for training deep neural networks, and
DP-SGD, in order to train differentially private, Bayesian neural networks with
minor adjustments to the original (DP-SGD) algorithm. Our approach provides
considerably more reliable uncertainty estimates than DP-SGD, as demonstrated
empirically by a reduction in expected calibration error (MNIST $\sim{5}$-fold,
Pediatric Pneumonia Dataset $\sim{2}$-fold).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Exploration by Solving Early Terminated MDP. (arXiv:2107.04200v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Ziping Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1">Meng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhenghao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiadong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Bo Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04200">
                                    <div class="article-summary-box-inner">
                                        <span>Safe exploration is crucial for the real-world application of reinforcement
learning (RL). Previous works consider the safe exploration problem as
Constrained Markov Decision Process (CMDP), where the policies are being
optimized under constraints. However, when encountering any potential dangers,
human tends to stop immediately and rarely learns to behave safely in danger.
Motivated by human learning, we introduce a new approach to address safe RL
problems under the framework of Early Terminated MDP (ET-MDP). We first define
the ET-MDP as an unconstrained MDP with the same optimal value function as its
corresponding CMDP. An off-policy algorithm based on context models is then
proposed to solve the ET-MDP, which thereby solves the corresponding CMDP with
better asymptotic performance and improved learning efficiency. Experiments on
various CMDP tasks show a substantial improvement over previous methods that
directly solve CMDP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EasyCom: An Augmented Reality Dataset to Support Algorithms for Easy Communication in Noisy Environments. (arXiv:2107.04174v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Donley_J/0/1/0/all/0/1">Jacob Donley</a>, <a href="http://arxiv.org/find/cs/1/au:+Tourbabin_V/0/1/0/all/0/1">Vladimir Tourbabin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jung-Suk Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Broyles_M/0/1/0/all/0/1">Mark Broyles</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jie Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pantic_M/0/1/0/all/0/1">Maja Pantic</a>, <a href="http://arxiv.org/find/cs/1/au:+Ithapu_V/0/1/0/all/0/1">Vamsi Krishna Ithapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehra_R/0/1/0/all/0/1">Ravish Mehra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04174">
                                    <div class="article-summary-box-inner">
                                        <span>Augmented Reality (AR) as a platform has the potential to facilitate the
reduction of the cocktail party effect. Future AR headsets could potentially
leverage information from an array of sensors spanning many different
modalities. Training and testing signal processing and machine learning
algorithms on tasks such as beam-forming and speech enhancement require high
quality representative data. To the best of the author&#x27;s knowledge, as of
publication there are no available datasets that contain synchronized
egocentric multi-channel audio and video with dynamic movement and
conversations in a noisy environment. In this work, we describe, evaluate and
release a dataset that contains over 5 hours of multi-modal data useful for
training and testing algorithms for the application of improving conversations
for an AR glasses wearer. We provide speech intelligibility, quality and
signal-to-noise ratio improvement results for a baseline method and show
improvements across all tested metrics. The dataset we are releasing contains
AR glasses egocentric multi-channel microphone array audio, wide field-of-view
RGB video, speech source pose, headset microphone audio, annotated voice
activity, speech transcriptions, head bounding boxes, target of speech and
source identification labels. We have created and are releasing this dataset to
facilitate research in multi-modal AR solutions to the cocktail party problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-based Deep Generative Modelling for Document Layout Generation. (arXiv:2107.04357v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1">Sanket Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1">Pau Riba</a>, <a href="http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1">Josep Llad&#xf3;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_U/0/1/0/all/0/1">Umapada Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04357">
                                    <div class="article-summary-box-inner">
                                        <span>One of the major prerequisites for any deep learning approach is the
availability of large-scale training data. When dealing with scanned document
images in real world scenarios, the principal information of its content is
stored in the layout itself. In this work, we have proposed an automated deep
generative model using Graph Neural Networks (GNNs) to generate synthetic data
with highly variable and plausible document layouts that can be used to train
document interpretation systems, in this case, specially in digital mailroom
applications. It is also the first graph-based approach for document layout
generation task experimented on administrative document images, in this case,
invoices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Greedy structure learning from data that contains systematic missing values. (arXiv:2107.04184v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Constantinou_A/0/1/0/all/0/1">Anthony C. Constantinou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04184">
                                    <div class="article-summary-box-inner">
                                        <span>Learning from data that contain missing values represents a common phenomenon
in many domains. Relatively few Bayesian Network structure learning algorithms
account for missing data, and those that do tend to rely on standard approaches
that assume missing data are missing at random, such as the
Expectation-Maximisation algorithm. Because missing data are often systematic,
there is a need for more pragmatic methods that can effectively deal with data
sets containing missing values not missing at random. The absence of approaches
that deal with systematic missing data impedes the application of BN structure
learning methods to real-world problems where missingness are not random. This
paper describes three variants of greedy search structure learning that utilise
pairwise deletion and inverse probability weighting to maximally leverage the
observed data and to limit potential bias caused by missing values. The first
two of the variants can be viewed as sub-versions of the third and best
performing variant, but are important in their own in illustrating the
successive improvements in learning accuracy. The empirical investigations show
that the proposed approach outperforms the commonly used and state-of-the-art
Structural EM algorithm, both in terms of learning accuracy and efficiency, as
well as both when data are missing at random and not at random.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Federated Learning over non-IID Data for Indoor Localization. (arXiv:2107.04189v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Peng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Imbiriba_T/0/1/0/all/0/1">Tales Imbiriba</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Junha Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sunwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Closas_P/0/1/0/all/0/1">Pau Closas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04189">
                                    <div class="article-summary-box-inner">
                                        <span>Localization and tracking of objects using data-driven methods is a popular
topic due to the complexity in characterizing the physics of wireless channel
propagation models. In these modeling approaches, data needs to be gathered to
accurately train models, at the same time that user&#x27;s privacy is maintained. An
appealing scheme to cooperatively achieve these goals is known as Federated
Learning (FL). A challenge in FL schemes is the presence of non-independent and
identically distributed (non-IID) data, caused by unevenly exploration of
different areas. In this paper, we consider the use of recent FL schemes to
train a set of personalized models that are then optimally fused through
Bayesian rules, which makes it appropriate in the context of indoor
localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-path Convolutional Neural Networks Efficiently Improve Feature Extraction in Continuous Adventitious Lung Sound Detection. (arXiv:2107.04226v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_F/0/1/0/all/0/1">Fu-Shun Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shang-Ran Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chien-Wen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chun-Chieh Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yuan-Ren Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_F/0/1/0/all/0/1">Feipei Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04226">
                                    <div class="article-summary-box-inner">
                                        <span>We previously established a large lung sound database, HF_Lung_V2 (Lung_V2).
We trained convolutional-bidirectional gated recurrent unit (CNN-BiGRU)
networks for detecting inhalation, exhalation, continuous adventitious sound
(CAS) and discontinuous adventitious sound at the recording level on the basis
of Lung_V2. However, the performance of CAS detection was poor due to many
reasons, one of which is the highly diversified CAS patterns. To make the
original CNN-BiGRU model learn the CAS patterns more effectively and not cause
too much computing burden, three strategies involving minimal modifications of
the network architecture of the CNN layers were investigated: (1) making the
CNN layers a bit deeper by using the residual blocks, (2) making the CNN layers
a bit wider by increasing the number of CNN kernels, and (3) separating the
feature input into multiple paths (the model was denoted by Multi-path
CNN-BiGRU). The performance of CAS segment and event detection were evaluated.
Results showed that improvement in CAS detection was observed among all the
proposed architecture-modified models. The F1 score for CAS event detection of
the proposed models increased from 0.445 to 0.491-0.530, which was deemed
significant. However, the Multi-path CNN-BiGRU model outperformed the other
models in terms of the number of winning titles (five) in total nine evaluation
metrics. In addition, the Multi-path CNN-BiGRU model did not cause extra
computing burden (0.97-fold inference time) compared to the original CNN-BiGRU
model. Conclusively, the Multi-path CNN layers can efficiently improve the
effectiveness of feature extraction and subsequently result in better CAS
detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On lattice-free boosted MMI training of HMM and CTC-based full-context ASR models. (arXiv:2107.04154v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1">Xiaohui Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Manohar_V/0/1/0/all/0/1">Vimal Manohar</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_D/0/1/0/all/0/1">David Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1">Frank Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1">Yangyang Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Singhal_N/0/1/0/all/0/1">Nayan Singhal</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_J/0/1/0/all/0/1">Julian Chan</a>, <a href="http://arxiv.org/find/eess/1/au:+Peng_F/0/1/0/all/0/1">Fuchun Peng</a>, <a href="http://arxiv.org/find/eess/1/au:+Saraf_Y/0/1/0/all/0/1">Yatharth Saraf</a>, <a href="http://arxiv.org/find/eess/1/au:+Seltzer_M/0/1/0/all/0/1">Mike Seltzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04154">
                                    <div class="article-summary-box-inner">
                                        <span>Hybrid automatic speech recognition (ASR) models are typically sequentially
trained with CTC or LF-MMI criteria. However, they have vastly different
legacies and are usually implemented in different frameworks. In this paper, by
decoupling the concepts of modeling units and label topologies and building
proper numerator/denominator graphs accordingly, we establish a generalized
framework for hybrid acoustic modeling (AM). In this framework, we show that
LF-MMI is a powerful training criterion applicable to both limited-context and
full-context models, for wordpiece/mono-char/bi-char/chenone units, with both
HMM/CTC topologies. From this framework, we propose three novel training
schemes: chenone(ch)/wordpiece(wp)-CTC-bMMI, and wordpiece(wp)-HMM-bMMI with
different advantages in training performance, decoding efficiency and decoding
time-stamp accuracy. The advantages of different training schemes are evaluated
comprehensively on Librispeech, and wp-CTC-bMMI and ch-CTC-bMMI are evaluated
on two real world ASR tasks to show their effectiveness. Besides, we also show
bi-char(bc) HMM-MMI models can serve as better alignment models than
traditional non-neural GMM-HMMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Gaussian Processes with Derivative Information Using Variational Inference. (arXiv:2107.04061v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Padidar_M/0/1/0/all/0/1">Misha Padidar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xinran Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Leo Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1">Jacob R. Gardner</a>, <a href="http://arxiv.org/find/cs/1/au:+Bindel_D/0/1/0/all/0/1">David Bindel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04061">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes with derivative information are useful in many settings
where derivative information is available, including numerous Bayesian
optimization and regression tasks that arise in the natural sciences.
Incorporating derivative observations, however, comes with a dominating
$O(N^3D^3)$ computational cost when training on $N$ points in $D$ input
dimensions. This is intractable for even moderately sized problems. While
recent work has addressed this intractability in the low-$D$ setting, the
high-$N$, high-$D$ setting is still unexplored and of great value, particularly
as machine learning problems increasingly become high dimensional. In this
paper, we introduce methods to achieve fully scalable Gaussian process
regression with derivatives using variational inference. Analogous to the use
of inducing values to sparsify the labels of a training set, we introduce the
concept of inducing directional derivatives to sparsify the partial derivative
information of a training set. This enables us to construct a variational
posterior that incorporates derivative information but whose size depends
neither on the full dataset size $N$ nor the full dimensionality $D$. We
demonstrate the full scalability of our approach on a variety of tasks, ranging
from a high dimensional stellarator fusion regression task to training graph
convolutional neural networks on Pubmed using Bayesian optimization.
Surprisingly, we find that our approach can improve regression performance even
in settings where only label data is available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Model-Based Multi-Agent Mean-Field Reinforcement Learning. (arXiv:2107.04050v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pasztor_B/0/1/0/all/0/1">Barna Pasztor</a>, <a href="http://arxiv.org/find/stat/1/au:+Bogunovic_I/0/1/0/all/0/1">Ilija Bogunovic</a>, <a href="http://arxiv.org/find/stat/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04050">
                                    <div class="article-summary-box-inner">
                                        <span>Learning in multi-agent systems is highly challenging due to the inherent
complexity introduced by agents&#x27; interactions. We tackle systems with a huge
population of interacting agents (e.g., swarms) via Mean-Field Control (MFC).
MFC considers an asymptotically infinite population of identical agents that
aim to collaboratively maximize the collective reward. Specifically, we
consider the case of unknown system dynamics where the goal is to
simultaneously optimize for the rewards and learn from experience. We propose
an efficient model-based reinforcement learning algorithm
$\text{M}^3\text{-UCRL}$ that runs in episodes and provably solves this
problem. $\text{M}^3\text{-UCRL}$ uses upper-confidence bounds to balance
exploration and exploitation during policy learning. Our main theoretical
contributions are the first general regret bounds for model-based RL for MFC,
obtained via a novel mean-field type analysis. $\text{M}^3\text{-UCRL}$ can be
instantiated with different models such as neural networks or Gaussian
Processes, and effectively combined with neural network policy learning. We
empirically demonstrate the convergence of $\text{M}^3\text{-UCRL}$ on the
swarm motion problem of controlling an infinite population of agents seeking to
maximize location-dependent reward and avoid congested areas.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensembles of Randomized NNs for Pattern-based Time Series Forecasting. (arXiv:2107.04091v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1">Grzegorz Dudek</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelka_P/0/1/0/all/0/1">Pawe&#x142; Pe&#x142;ka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04091">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose an ensemble forecasting approach based on randomized
neural networks. Improved randomized learning streamlines the fitting abilities
of individual learners by generating network parameters in accordance with the
data and target function features. A pattern-based representation of time
series makes the proposed approach suitable for forecasting time series with
multiple seasonality. We propose six strategies for controlling the diversity
of ensemble members. Case studies conducted on four real-world forecasting
problems verified the effectiveness and superior performance of the proposed
ensemble forecasting approach. It outperformed statistical models as well as
state-of-the-art machine learning models in terms of forecasting accuracy. The
proposed approach has several advantages: fast and easy training, simple
architecture, ease of implementation, high accuracy and the ability to deal
with nonstationarity and multiple seasonality in time series.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MCMC Variational Inference via Uncorrected Hamiltonian Annealing. (arXiv:2107.04150v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geffner_T/0/1/0/all/0/1">Tomas Geffner</a>, <a href="http://arxiv.org/find/cs/1/au:+Domke_J/0/1/0/all/0/1">Justin Domke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04150">
                                    <div class="article-summary-box-inner">
                                        <span>Given an unnormalized target distribution we want to obtain approximate
samples from it and a tight lower bound on its (log) normalization constant log
Z. Annealed Importance Sampling (AIS) with Hamiltonian MCMC is a powerful
method that can be used to do this. Its main drawback is that it uses
non-differentiable transition kernels, which makes tuning its many parameters
hard. We propose a framework to use an AIS-like procedure with Uncorrected
Hamiltonian MCMC, called Uncorrected Hamiltonian Annealing. Our method leads to
tight and differentiable lower bounds on log Z. We show empirically that our
method yields better performances than other competing approaches, and that the
ability to tune its parameters using reparameterization gradients may lead to
large performance improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparison of 2D vs. 3D U-Net Organ Segmentation in abdominal 3D CT images. (arXiv:2107.04062v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zettler_N/0/1/0/all/0/1">Nico Zettler</a>, <a href="http://arxiv.org/find/eess/1/au:+Mastmeyer_A/0/1/0/all/0/1">Andre Mastmeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04062">
                                    <div class="article-summary-box-inner">
                                        <span>A two-step concept for 3D segmentation on 5 abdominal organs inside
volumetric CT images is presented. First each relevant organ&#x27;s volume of
interest is extracted as bounding box. The extracted volume acts as input for a
second stage, wherein two compared U-Nets with different architectural
dimensions re-construct an organ segmentation as label mask. In this work, we
focus on comparing 2D U-Nets vs. 3D U-Net counterparts. Our initial results
indicate Dice improvements of about 6\% at maximum. In this study to our
surprise, liver and kidneys for instance were tackled significantly better
using the faster and GPU-memory saving 2D U-Nets. For other abdominal key
organs, there were no significant differences, but we observe highly
significant advantages for the 2D U-Net in terms of GPU computational efforts
for all organs under study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Does Form Follow Function? An Empirical Exploration of the Impact of Deep Neural Network Architecture Design on Hardware-Specific Acceleration. (arXiv:2107.04144v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abbasi_S/0/1/0/all/0/1">Saad Abbasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiee_M/0/1/0/all/0/1">Mohammad Javad Shafiee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_E/0/1/0/all/0/1">Ellick Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alexander Wong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04144">
                                    <div class="article-summary-box-inner">
                                        <span>The fine-grained relationship between form and function with respect to deep
neural network architecture design and hardware-specific acceleration is one
area that is not well studied in the research literature, with form often
dictated by accuracy as opposed to hardware function. In this study, a
comprehensive empirical exploration is conducted to investigate the impact of
deep neural network architecture design on the degree of inference speedup that
can be achieved via hardware-specific acceleration. More specifically, we
empirically study the impact of a variety of commonly used macro-architecture
design patterns across different architectural depths through the lens of
OpenVINO microprocessor-specific and GPU-specific acceleration. Experimental
results showed that while leveraging hardware-specific acceleration achieved an
average inference speed-up of 380%, the degree of inference speed-up varied
drastically depending on the macro-architecture design pattern, with the
greatest speedup achieved on the depthwise bottleneck convolution design
pattern at 550%. Furthermore, we conduct an in-depth exploration of the
correlation between FLOPs requirement, level 3 cache efficacy, and network
latency with increasing architectural depth and width. Finally, we analyze the
inference time reductions using hardware-specific acceleration when compared to
native deep learning frameworks across a wide variety of hand-crafted deep
convolutional neural network architecture designs as well as ones found via
neural architecture search strategies. We found that the DARTS-derived
architecture to benefit from the greatest improvement from hardware-specific
software acceleration (1200%) while the depthwise bottleneck convolution-based
MobileNet-V2 to have the lowest overall inference time of around 2.4 ms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D RegNet: Deep Learning Model for COVID-19 Diagnosis on Chest CT Image. (arXiv:2107.04055v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Qi_H/0/1/0/all/0/1">Haibo Qi</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yuhan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xinyu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04055">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, a 3D-RegNet-based neural network is proposed for diagnosing
the physical condition of patients with coronavirus (Covid-19) infection. In
the application of clinical medicine, lung CT images are utilized by
practitioners to determine whether a patient is infected with coronavirus.
However, there are some laybacks can be considered regarding to this diagnostic
method, such as time consuming and low accuracy. As a relatively large organ of
human body, important spatial features would be lost if the lungs were
diagnosed utilizing two dimensional slice image. Therefore, in this paper, a
deep learning model with 3D image was designed. The 3D image as input data was
comprised of two-dimensional pulmonary image sequence and from which relevant
coronavirus infection 3D features were extracted and classified. The results
show that the test set of the 3D model, the result: f1 score of 0.8379 and AUC
value of 0.8807 have been achieved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Many Objective Bayesian Optimization. (arXiv:2107.04126v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Martin_L/0/1/0/all/0/1">Lucia Asencio Mart&#xed;n</a>, <a href="http://arxiv.org/find/stat/1/au:+Garrido_Merchan_E/0/1/0/all/0/1">Eduardo C. Garrido-Merch&#xe1;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04126">
                                    <div class="article-summary-box-inner">
                                        <span>Some real problems require the evaluation of expensive and noisy objective
functions. Moreover, the analytical expression of these objective functions may
be unknown. These functions are known as black-boxes, for example, estimating
the generalization error of a machine learning algorithm and computing its
prediction time in terms of its hyper-parameters. Multi-objective Bayesian
optimization (MOBO) is a set of methods that has been successfully applied for
the simultaneous optimization of black-boxes. Concretely, BO methods rely on a
probabilistic model of the objective functions, typically a Gaussian process.
This model generates a predictive distribution of the objectives. However, MOBO
methods have problems when the number of objectives in a multi-objective
optimization problem are 3 or more, which is the many objective setting. In
particular, the BO process is more costly as more objectives are considered,
computing the quality of the solution via the hyper-volume is also more costly
and, most importantly, we have to evaluate every objective function, wasting
expensive computational, economic or other resources. However, as more
objectives are involved in the optimization problem, it is highly probable that
some of them are redundant and not add information about the problem solution.
A measure that represents how similar are GP predictive distributions is
proposed. We also propose a many objective Bayesian optimization algorithm that
uses this metric to determine whether two objectives are redundant. The
algorithm stops evaluating one of them if the similarity is found, saving
resources and not hurting the performance of the multi-objective BO algorithm.
We show empirical evidence in a set of toy, synthetic, benchmark and real
experiments that GPs predictive distributions of the effectiveness of the
metric and the algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Even Faster SNN Simulation with Lazy+Event-driven Plasticity and Shared Atomics. (arXiv:2107.04092v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bautembach_D/0/1/0/all/0/1">Dennis Bautembach</a>, <a href="http://arxiv.org/find/cs/1/au:+Oikonomidis_I/0/1/0/all/0/1">Iason Oikonomidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Argyros_A/0/1/0/all/0/1">Antonis Argyros</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04092">
                                    <div class="article-summary-box-inner">
                                        <span>We present two novel optimizations that accelerate clock-based spiking neural
network (SNN) simulators. The first one targets spike timing dependent
plasticity (STDP). It combines lazy- with event-driven plasticity and
efficiently facilitates the computation of pre- and post-synaptic spikes using
bitfields and integer intrinsics. It offers higher bandwidth than event-driven
plasticity alone and achieves a 1.5x-2x speedup over our closest competitor.
The second optimization targets spike delivery. We partition our graph
representation in a way that bounds the number of neurons that need be updated
at any given time which allows us to perform said update in shared memory
instead of global memory. This is 2x-2.5x faster than our closest competitor.
Both optimizations represent the final evolutionary stages of years of
iteration on STDP and spike delivery inside &quot;Spice&quot; (/spaIk/), our state of the
art SNN simulator. The proposed optimizations are not exclusive to our graph
representation or pipeline but are applicable to a multitude of simulator
designs. We evaluate our performance on three well-established models and
compare ourselves against three other state of the art simulators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fedlearn-Algo: A flexible open-source privacy-preserving machine learning platform. (arXiv:2107.04129v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1">Chaowei Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiazhou Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_T/0/1/0/all/0/1">Tao Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_H/0/1/0/all/0/1">Huasong Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1">Houpu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_H/0/1/0/all/0/1">Huang Heng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_P/0/1/0/all/0/1">Peng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bo_L/0/1/0/all/0/1">Liefeng Bo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanqing Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04129">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present Fedlearn-Algo, an open-source privacy preserving
machine learning platform. We use this platform to demonstrate our research and
development results on privacy preserving machine learning algorithms. As the
first batch of novel FL algorithm examples, we release vertical federated
kernel binary classification model and vertical federated random forest model.
They have been tested to be more efficient than existing vertical federated
learning models in our practice. Besides the novel FL algorithm examples, we
also release a machine communication module. The uniform data transfer
interface supports transfering widely used data formats between machines. We
will maintain this platform by adding more functional modules and algorithm
examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning for Stuttering Identification: Review, Challenges &amp; Future Directions. (arXiv:2107.04057v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheikh_S/0/1/0/all/0/1">Shakeel Ahmad Sheikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahidullah_M/0/1/0/all/0/1">Md Sahidullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Hirsch_F/0/1/0/all/0/1">Fabrice Hirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouni_S/0/1/0/all/0/1">Slim Ouni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04057">
                                    <div class="article-summary-box-inner">
                                        <span>Stuttering is a speech disorder during which the flow of speech is
interrupted by involuntary pauses and repetition of sounds. Stuttering
identification is an interesting interdisciplinary domain research problem
which involves pathology, psychology, acoustics, and signal processing that
makes it hard and complicated to detect. Recent developments in machine and
deep learning have dramatically revolutionized speech domain, however minimal
attention has been given to stuttering identification. This work fills the gap
by trying to bring researchers together from interdisciplinary fields. In this
paper, we review comprehensively acoustic features, statistical and deep
learning based stuttering/disfluency classification methods. We also present
several challenges and possible future directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio-visual Attentive Fusion for Continuous Emotion Recognition. (arXiv:2107.01175v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Su Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yi Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_C/0/1/0/all/0/1">Cuntai Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01175">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an audio-visual spatial-temporal deep neural network with: (1) a
visual block containing a pretrained 2D-CNN followed by a temporal
convolutional network (TCN); (2) an aural block containing several parallel
TCNs; and (3) a leader-follower attentive fusion block combining the
audio-visual information. The TCN with large history coverage enables our model
to exploit spatial-temporal information within a much larger window length
(i.e., 300) than that from the baseline and state-of-the-art methods (i.e., 36
or 48). The fusion block emphasizes the visual modality while exploits the
noisy aural modality using the inter-modality attention mechanism. To make full
use of the data and alleviate over-fitting, cross-validation is carried out on
the training and validation set. The concordance correlation coefficient (CCC)
centering is used to merge the results from each fold. On the development set,
the achieved CCC is 0.469 for valence and 0.649 for arousal, which
significantly outperforms the baseline method with the corresponding CCC of
0.210 and 0.230 for valence and arousal, respectively. The code is available at
https://github.com/sucv/ABAW2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hacking VMAF and VMAF NEG: metrics vulnerability to different preprocessing. (arXiv:2107.04510v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Siniukov_M/0/1/0/all/0/1">Maksim Siniukov</a>, <a href="http://arxiv.org/find/cs/1/au:+Antsiferova_A/0/1/0/all/0/1">Anastasia Antsiferova</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulikov_D/0/1/0/all/0/1">Dmitriy Kulikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Vatolin_D/0/1/0/all/0/1">Dmitriy Vatolin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04510">
                                    <div class="article-summary-box-inner">
                                        <span>Video quality measurement plays a critical role in the development of video
processing applications. In this paper, we show how popular quality metrics
VMAF and its tuning-resistant version VMAF NEG can be artificially increased by
video preprocessing. We propose a pipeline for tuning parameters of processing
algorithms that allows increasing VMAF by up to 218.8%. A subjective comparison
of preprocessed videos showed that with the majority of methods visual quality
drops down or stays unchanged. We show that VMAF NEG scores can also be
increased by some preprocessing methods by up to 23.6%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-09">2021-07-09</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-sentence Neural Language Models for Conversational Speech Recognition. (arXiv:2106.06922v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chiu_S/0/1/0/all/0/1">Shih-Hsuan Chiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_T/0/1/0/all/0/1">Tien-Hong Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Berlin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06922">
                                    <div class="article-summary-box-inner">
                                        <span>An important research direction in automatic speech recognition (ASR) has
centered around the development of effective methods to rerank the output
hypotheses of an ASR system with more sophisticated language models (LMs) for
further gains. A current mainstream school of thoughts for ASR N-best
hypothesis reranking is to employ a recurrent neural network (RNN)-based LM or
its variants, with performance superiority over the conventional n-gram LMs
across a range of ASR tasks. In real scenarios such as a long conversation, a
sequence of consecutive sentences may jointly contain ample cues of
conversation-level information such as topical coherence, lexical entrainment
and adjacency pairs, which however remains to be underexplored. In view of
this, we first formulate ASR N-best reranking as a prediction problem, putting
forward an effective cross-sentence neural LM approach that reranks the ASR
N-best hypotheses of an upcoming sentence by taking into consideration the word
usage in its precedent sentences. Furthermore, we also explore to extract
task-specific global topical information of the cross-sentence history in an
unsupervised manner for better ASR performance. Extensive experiments conducted
on the AMI conversational benchmark corpus indicate the effectiveness and
feasibility of our methods in comparison to several state-of-the-art reranking
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-based Conditional Variational Autoencoder for Controllable Story Generation. (arXiv:2101.00828v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1">Le Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_T/0/1/0/all/0/1">Tao Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chaochun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bo_L/0/1/0/all/0/1">Liefeng Bo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1">Wen Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Changyou Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00828">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate large-scale latent variable models (LVMs) for neural story
generation -- an under-explored application for open-domain long text -- with
objectives in two threads: generation effectiveness and controllability. LVMs,
especially the variational autoencoder (VAE), have achieved both effective and
controllable generation through exploiting flexible distributional latent
representations. Recently, Transformers and its variants have achieved
remarkable effectiveness without explicit latent representation learning, thus
lack satisfying controllability in generation. In this paper, we advocate to
revive latent variable modeling, essentially the power of representation
learning, in the era of Transformers to enhance controllability without hurting
state-of-the-art generation effectiveness. Specifically, we integrate latent
representation vectors with a Transformer-based pre-trained architecture to
build conditional variational autoencoder (CVAE). Model components such as
encoder, decoder and the variational posterior are all built on top of
pre-trained language models -- GPT2 specifically in this paper. Experiments
demonstrate state-of-the-art conditional generation ability of our model, as
well as its excellent representation learning capability and controllability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoding Methods for Neural Narrative Generation. (arXiv:2010.07375v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DeLucia_A/0/1/0/all/0/1">Alexandra DeLucia</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_A/0/1/0/all/0/1">Aaron Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Lisa Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sedoc_J/0/1/0/all/0/1">Jo&#xe3;o Sedoc</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07375">
                                    <div class="article-summary-box-inner">
                                        <span>Narrative generation is an open-ended NLP task in which a model generates a
story given a prompt. The task is similar to neural response generation for
chatbots; however, innovations in response generation are often not applied to
narrative generation, despite the similarity between these tasks. We aim to
bridge this gap by applying and evaluating advances in decoding methods for
neural response generation to neural narrative generation. In particular, we
employ GPT-2 and perform ablations across nucleus sampling thresholds and
diverse decoding hyperparameters -- specifically, maximum mutual information --
analyzing results over multiple criteria with automatic and human evaluation.
We find that (1) nucleus sampling is generally best with thresholds between 0.7
and 0.9; (2) a maximum mutual information objective can improve the quality of
generated stories; and (3) established automatic metrics do not correlate well
with human judgments of narrative quality on any qualitative metric.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse and Structured Visual Attention. (arXiv:2002.05556v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Martins_P/0/1/0/all/0/1">Pedro Henrique Martins</a>, <a href="http://arxiv.org/find/cs/1/au:+Niculae_V/0/1/0/all/0/1">Vlad Niculae</a>, <a href="http://arxiv.org/find/cs/1/au:+Marinho_Z/0/1/0/all/0/1">Zita Marinho</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1">Andr&#xe9; Martins</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05556">
                                    <div class="article-summary-box-inner">
                                        <span>Visual attention mechanisms are widely used in multimodal tasks, as visual
question answering (VQA). One drawback of softmax-based attention mechanisms is
that they assign some probability mass to all image regions, regardless of
their adjacency structure and of their relevance to the text. In this paper, to
better link the image structure with the text, we replace the traditional
softmax attention mechanism with two alternative sparsity-promoting
transformations: sparsemax, which is able to select only the relevant regions
(assigning zero weight to the rest), and a newly proposed Total-Variation
Sparse Attention (TVmax), which further encourages the joint selection of
adjacent spatial locations. Experiments in VQA show gains in accuracy as well
as higher similarity to human attention, which suggests better
interpretability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The value of text for small business default prediction: A deep learning approach. (arXiv:2003.08964v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stevenson_M/0/1/0/all/0/1">Matthew Stevenson</a>, <a href="http://arxiv.org/find/cs/1/au:+Mues_C/0/1/0/all/0/1">Christophe Mues</a>, <a href="http://arxiv.org/find/cs/1/au:+Bravo_C/0/1/0/all/0/1">Cristi&#xe1;n Bravo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.08964">
                                    <div class="article-summary-box-inner">
                                        <span>Compared to consumer lending, Micro, Small and Medium Enterprise (mSME)
credit risk modelling is particularly challenging, as, often, the same sources
of information are not available. Therefore, it is standard policy for a loan
officer to provide a textual loan assessment to mitigate limited data
availability. In turn, this statement is analysed by a credit expert alongside
any available standard credit data. In our paper, we exploit recent advances
from the field of Deep Learning and Natural Language Processing (NLP),
including the BERT (Bidirectional Encoder Representations from Transformers)
model, to extract information from 60 000 textual assessments provided by a
lender. We consider the performance in terms of the AUC (Area Under the
receiver operating characteristic Curve) and Brier Score metrics and find that
the text alone is surprisingly effective for predicting default. However, when
combined with traditional data, it yields no additional predictive capability,
with performance dependent on the text&#x27;s length. Our proposed deep learning
model does, however, appear to be robust to the quality of the text and
therefore suitable for partly automating the mSME lending process. We also
demonstrate how the content of loan assessments influences performance, leading
us to a series of recommendations on a new strategy for collecting future mSME
loan assessments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FarsTail: A Persian Natural Language Inference Dataset. (arXiv:2009.08820v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amirkhani_H/0/1/0/all/0/1">Hossein Amirkhani</a>, <a href="http://arxiv.org/find/cs/1/au:+AzariJafari_M/0/1/0/all/0/1">Mohammad AzariJafari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pourjafari_Z/0/1/0/all/0/1">Zohreh Pourjafari</a>, <a href="http://arxiv.org/find/cs/1/au:+Faridan_Jahromi_S/0/1/0/all/0/1">Soroush Faridan-Jahromi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kouhkan_Z/0/1/0/all/0/1">Zeinab Kouhkan</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirak_A/0/1/0/all/0/1">Azadeh Amirak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08820">
                                    <div class="article-summary-box-inner">
                                        <span>Natural language inference (NLI) is known as one of the central tasks in
natural language processing (NLP) which encapsulates many fundamental aspects
of language understanding. With the considerable achievements of data-hungry
deep learning methods in NLP tasks, a great amount of e ort has been devoted to
develop more diverse datasets for di erent languages. In this paper, we present
a new dataset for the NLI task in the Persian language, also known as Farsi,
which is one of the dominant languages in the Middle East. This dataset, named
FarsTail, includes 10,367 samples which are provided in both the Persian
language as well as the indexed format to be useful for non-Persian
researchers. The samples are generated from 3,539 multiple-choice questions
with the least amount of annotator interventions in a way similar to the
SciTail dataset. A carefully designed multi-step process is adopted to ensure
the quality of the dataset. We also present the results of traditional and
state-of-the-art methods on FarsTail including di erent embedding methods such
as word2vec, fastText, ELMo, BERT, and LASER, as well as di erent modeling
approaches such as DecompAtt, ESIM, HBMP, and ULMFiT to provide a solid
baseline for the future research. The best obtained test accuracy is 83.38%
which shows that there is a big room for improving the current methods to be
useful for real-world NLP applications in di erent languages. We also
investigate the extent to which the models exploit super cial clues, also known
as dataset biases, in FarsTail, and partition the test set into easy and hard
subsets according to the success of biased models. The dataset is available at
https://github.com/dml-qom/ FarsTail.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comprehensive Assessment of Dialog Evaluation Metrics. (arXiv:2106.03706v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yeh_Y/0/1/0/all/0/1">Yi-Ting Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Eskenazi_M/0/1/0/all/0/1">Maxine Eskenazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehri_S/0/1/0/all/0/1">Shikib Mehri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03706">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic evaluation metrics are a crucial component of dialog systems
research. Standard language evaluation metrics are known to be ineffective for
evaluating dialog. As such, recent research has proposed a number of novel,
dialog-specific metrics that correlate better with human judgements. Due to the
fast pace of research, many of these metrics have been assessed on different
datasets and there has as yet been no time for a systematic comparison between
them. To this end, this paper provides a comprehensive assessment of recently
proposed dialog evaluation metrics on a number of datasets. In this paper, 23
different automatic evaluation metrics are evaluated on 10 different datasets.
Furthermore, the metrics are assessed in different settings, to better qualify
their respective strengths and weaknesses. Metrics are assessed (1) on both the
turn level and the dialog level, (2) for different dialog lengths, (3) for
different dialog qualities (e.g., coherence, engaging), (4) for different types
of response generation models (i.e., generative, retrieval, simple models and
state-of-the-art models), (5) taking into account the similarity of different
metrics and (6) exploring combinations of different metrics. This comprehensive
assessment offers several takeaways pertaining to dialog evaluation metrics in
general. It also suggests how to best assess evaluation metrics and indicates
promising directions for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Conditioned Imitation Learning over Unstructured Data. (arXiv:2005.07648v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lynch_C/0/1/0/all/0/1">Corey Lynch</a>, <a href="http://arxiv.org/find/cs/1/au:+Sermanet_P/0/1/0/all/0/1">Pierre Sermanet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.07648">
                                    <div class="article-summary-box-inner">
                                        <span>Natural language is perhaps the most flexible and intuitive way for humans to
communicate tasks to a robot. Prior work in imitation learning typically
requires each task be specified with a task id or goal image -- something that
is often impractical in open-world environments. On the other hand, previous
approaches in instruction following allow agent behavior to be guided by
language, but typically assume structure in the observations, actuators, or
language that limit their applicability to complex settings like robotics. In
this work, we present a method for incorporating free-form natural language
conditioning into imitation learning. Our approach learns perception from
pixels, natural language understanding, and multitask continuous control
end-to-end as a single neural network. Unlike prior work in imitation learning,
our method is able to incorporate unlabeled and unstructured demonstration data
(i.e. no task or language labels). We show this dramatically improves language
conditioned performance, while reducing the cost of language annotation to less
than 1% of total data. At test time, a single language conditioned visuomotor
policy trained with our method can perform a wide variety of robotic
manipulation skills in a 3D environment, specified only with natural language
descriptions of each task (e.g. &quot;open the drawer...now pick up the block...now
press the green button...&quot;). To scale up the number of instructions an agent
can follow, we propose combining text conditioned policies with large
pretrained neural language models. We find this allows a policy to be robust to
many out-of-distribution synonym instructions, without requiring new
demonstrations. See videos of a human typing live text commands to our agent at
language-play.github.io</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Spoken Language Understanding using RNN-Transducer ASR. (arXiv:2106.15919v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raju_A/0/1/0/all/0/1">Anirudh Raju</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_G/0/1/0/all/0/1">Gautam Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_M/0/1/0/all/0/1">Milind Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dheram_P/0/1/0/all/0/1">Pranav Dheram</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_B/0/1/0/all/0/1">Bryan Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_B/0/1/0/all/0/1">Bach Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastrow_A/0/1/0/all/0/1">Ariya Rastrow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15919">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an end-to-end trained spoken language understanding (SLU) system
that extracts transcripts, intents and slots from an input speech utterance. It
consists of a streaming recurrent neural network transducer (RNNT) based
automatic speech recognition (ASR) model connected to a neural natural language
understanding (NLU) model through a neural interface. This interface allows for
end-to-end training using multi-task RNNT and NLU losses. Additionally, we
introduce semantic sequence loss training for the joint RNNT-NLU system that
allows direct optimization of non-differentiable SLU metrics. This end-to-end
SLU model paradigm can leverage state-of-the-art advancements and pretrained
models in both ASR and NLU research communities, outperforming recently
proposed direct speech-to-semantics models, and conventional pipelined ASR and
NLU systems. We show that this method improves both ASR and NLU metrics on both
public SLU datasets and large proprietary datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inspiration through Observation: Demonstrating the Influence of Automatically Generated Text on Creative Writing. (arXiv:2107.04007v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roemmele_M/0/1/0/all/0/1">Melissa Roemmele</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04007">
                                    <div class="article-summary-box-inner">
                                        <span>Getting machines to generate text perceived as creative is a long-pursued
goal. A growing body of research directs this goal towards augmenting the
creative writing abilities of human authors. In this paper, we pursue this
objective by analyzing how observing examples of automatically generated text
influences writing. In particular, we examine a task referred to as sentence
infilling, which involves transforming a list of words into a complete
sentence. We emphasize &quot;storiability&quot; as a desirable feature of the resulting
sentences, where &quot;storiable&quot; sentences are those that suggest a story a reader
would be curious to hear about. Both humans and an automated system (based on a
neural language model) performed this sentence infilling task. In one setting,
people wrote sentences on their own; in a different setting, people observed
the sentences produced by the model while writing their own sentences. Readers
then assigned storiability preferences to the resulting sentences in a
subsequent evaluation. We find that human-authored sentences were judged as
more storiable when authors observed the generated examples, and that
storiability increased as authors derived more semantic content from the
examples. This result gives evidence of an &quot;inspiration through observation&quot;
paradigm for human-computer collaborative writing, through which human writing
can be enhanced by text generation models without directly copying their
output.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Lingual Transfer in Zero-Shot Cross-Language Entity Linking. (arXiv:2010.09828v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schumacher_E/0/1/0/all/0/1">Elliot Schumacher</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayfield_J/0/1/0/all/0/1">James Mayfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Dredze_M/0/1/0/all/0/1">Mark Dredze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09828">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-language entity linking grounds mentions in multiple languages to a
single-language knowledge base. We propose a neural ranking architecture for
this task that uses multilingual BERT representations of the mention and the
context in a neural network. We find that the multilingual ability of BERT
leads to robust performance in monolingual and multilingual settings.
Furthermore, we explore zero-shot language transfer and find surprisingly
robust performance. We investigate the zero-shot degradation and find that it
can be partially mitigated by a proposed auxiliary training objective, but that
the remaining error can best be attributed to domain shift rather than language
transfer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meeting the SDGs : Enabling the Goals by Cooperation with Crowd using a Conversational AI Platform. (arXiv:2107.04011v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Haqbeen_J/0/1/0/all/0/1">J. Haqbeen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1">T. Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahab_S/0/1/0/all/0/1">S. Sahab</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadfi_R/0/1/0/all/0/1">R. Hadfi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1">T. Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Okuhara_S/0/1/0/all/0/1">S. Okuhara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04011">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we report about a large-scale online discussion with 1099
citizens on the Afghanistan Sustainable Development Goals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vector Space Morphology with Linear Discriminative Learning. (arXiv:2107.03950v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yu-Ying Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_M/0/1/0/all/0/1">Mihi Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xuefeng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Baayen_R/0/1/0/all/0/1">R. Harald Baayen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03950">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents three case studies of modeling aspects of lexical
processing with Linear Discriminative Learning (LDL), the computational engine
of the Discriminative Lexicon model (Baayen et al., 2019). With numeric
representations of word forms and meanings, LDL learns to map one vector space
onto the other, without being informed about any morphological structure or
inflectional classes. The modeling results demonstrated that LDL not only
performs well for understanding and producing morphologically complex words,
but also generates quantitative measures that are predictive for human
behavioral data. LDL models are straightforward to implement with the JudiLing
package (Luo et al., 2021). Worked examples are provided for three modeling
challenges: producing and understanding Korean verb inflection, predicting
primed Dutch lexical decision latencies, and predicting the acoustic duration
of Mandarin words.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Worry, coping and resignation -- A repeated-measures study on emotional responses after a year in the pandemic. (arXiv:2107.03466v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mozes_M/0/1/0/all/0/1">Maximilian Mozes</a>, <a href="http://arxiv.org/find/cs/1/au:+Vegt_I/0/1/0/all/0/1">Isabelle van der Vegt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_B/0/1/0/all/0/1">Bennett Kleinberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03466">
                                    <div class="article-summary-box-inner">
                                        <span>The introduction of COVID-19 lockdown measures and an outlook on return to
normality are demanding societal changes. Among the most pressing questions is
how individuals adjust to the pandemic. This paper examines the emotional
responses to the pandemic in a repeated-measures design. Data (n&#x3D;1698) were
collected in April 2020 (during strict lockdown measures) and in April 2021
(when vaccination programmes gained traction). We asked participants to report
their emotions and express these in text data. Statistical tests revealed an
average trend towards better adjustment to the pandemic. However, clustering
analyses suggested a more complex heterogeneous pattern with a well-coping and
a resigning subgroup of participants. Linguistic computational analyses
uncovered that topics and n-gram frequencies shifted towards attention to the
vaccination programme and away from general worrying. Implications for public
mental health efforts in identifying people at heightened risk are discussed.
The dataset is made publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy Concerns in Chatbot Interactions: When to Trust and When to Worry. (arXiv:2107.03959v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saglam_R/0/1/0/all/0/1">Rahime Belen Saglam</a>, <a href="http://arxiv.org/find/cs/1/au:+Nurse_J/0/1/0/all/0/1">Jason R.C. Nurse</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodges_D/0/1/0/all/0/1">Duncan Hodges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03959">
                                    <div class="article-summary-box-inner">
                                        <span>Through advances in their conversational abilities, chatbots have started to
request and process an increasing variety of sensitive personal information.
The accurate disclosure of sensitive information is essential where it is used
to provide advice and support to users in the healthcare and finance sectors.
In this study, we explore users&#x27; concerns regarding factors associated with the
use of sensitive data by chatbot providers. We surveyed a representative sample
of 491 British citizens. Our results show that the user concerns focus on
deleting personal information and concerns about their data&#x27;s inappropriate
use. We also identified that individuals were concerned about losing control
over their data after a conversation with conversational agents. We found no
effect from a user&#x27;s gender or education but did find an effect from the user&#x27;s
age, with those over 45 being more concerned than those under 45. We also
considered the factors that engender trust in a chatbot. Our respondents&#x27;
primary focus was on the chatbot&#x27;s technical elements, with factors such as the
response quality being identified as the most critical factor. We again found
no effect from the user&#x27;s gender or education level; however, when we
considered some social factors (e.g. avatars or perceived &#x27;friendliness&#x27;), we
found those under 45 years old rated these as more important than those over
45. The paper concludes with a discussion of these results within the context
of designing inclusive, digital systems that support a wide range of users.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CANDLE: Decomposing Conditional and Conjunctive Queries for Task-Oriented Dialogue Systems. (arXiv:2107.03884v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Aadesh Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhole_K/0/1/0/all/0/1">Kaustubh D.Dhole</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarway_R/0/1/0/all/0/1">Rahul Tarway</a>, <a href="http://arxiv.org/find/cs/1/au:+Prabhakar_S/0/1/0/all/0/1">Swetha Prabhakar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1">Ashish Shrivastava</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03884">
                                    <div class="article-summary-box-inner">
                                        <span>Domain-specific dialogue systems generally determine user intents by relying
on sentence-level classifiers which mainly focus on single action sentences.
Such classifiers are not designed to effectively handle complex queries
composed of conditional and sequential clauses that represent multiple actions.
We attempt to decompose such queries into smaller single-action sub-queries
that are reasonable for intent classifiers to understand in a dialogue
pipeline. We release CANDLE (Conditional &amp; AND type Expressions), a dataset
consisting of 3124 utterances manually tagged with conditional and sequential
labels and demonstrates this decomposition by training two baseline taggers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using CollGram to Compare Formulaic Language in Human and Neural Machine Translation. (arXiv:2107.03625v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bestgen_Y/0/1/0/all/0/1">Yves Bestgen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03625">
                                    <div class="article-summary-box-inner">
                                        <span>A comparison of formulaic sequences in human and neural machine translation
of quality newspaper articles shows that neural machine translations contain
less lower-frequency, but strongly-associated formulaic sequences, and more
high-frequency formulaic sequences. These differences were statistically
significant and the effect sizes were almost always medium or large. These
observations can be related to the differences between second language learners
of various levels and between translated and untranslated texts. The comparison
between the neural machine translation systems indicates that some systems
produce more formulaic sequences of both types than other systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Bangla Natural Language Processing Tasks and the Utility of Transformer Models. (arXiv:2107.03844v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1">Firoj Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Arid Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1">Tanvir Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Akib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tajrin_J/0/1/0/all/0/1">Janntatul Tajrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naira Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03844">
                                    <div class="article-summary-box-inner">
                                        <span>Bangla -- ranked as the 6th most widely spoken language across the world
(https://www.ethnologue.com/guides/ethnologue200), with 230 million native
speakers -- is still considered as a low-resource language in the natural
language processing (NLP) community. With three decades of research, Bangla NLP
(BNLP) is still lagging behind mainly due to the scarcity of resources and the
challenges that come with it. There is sparse work in different areas of BNLP;
however, a thorough survey reporting previous work and recent advances is yet
to be done. In this study, we first provide a review of Bangla NLP tasks,
resources, and tools available to the research community; we benchmark datasets
collected from various platforms for nine NLP tasks using current
state-of-the-art algorithms (i.e., transformer-based models). We provide
comparative results for the studied NLP tasks by comparing monolingual vs.
multilingual models of varying sizes. We report our results using both
individual and consolidated datasets and provide data splits for future
research. We reviewed a total of 108 papers and conducted 175 sets of
experiments. Our results show promising performance using transformer-based
models while highlighting the trade-off with computational costs. We hope that
such a comprehensive survey will motivate the community to build on and further
advance the research on Bangla NLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Handling Heavily Abbreviated Manuscripts: HTR engines vs text normalisation approaches. (arXiv:2107.03450v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Camps_J/0/1/0/all/0/1">Jean-Baptiste Camps</a>, <a href="http://arxiv.org/find/cs/1/au:+Vidal_Gorene_C/0/1/0/all/0/1">Chahan Vidal-Gor&#xe8;ne</a>, <a href="http://arxiv.org/find/cs/1/au:+Vernet_M/0/1/0/all/0/1">Marguerite Vernet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03450">
                                    <div class="article-summary-box-inner">
                                        <span>Although abbreviations are fairly common in handwritten sources, particularly
in medieval and modern Western manuscripts, previous research dealing with
computational approaches to their expansion is scarce. Yet abbreviations
present particular challenges to computational approaches such as handwritten
text recognition and natural language processing tasks. Often, pre-processing
ultimately aims to lead from a digitised image of the source to a normalised
text, which includes expansion of the abbreviations. We explore different
setups to obtain such a normalised text, either directly, by training HTR
engines on normalised (i.e., expanded, disabbreviated) text, or by decomposing
the process into discrete steps, each making use of specialist models for
recognition, word segmentation and normalisation. The case studies considered
here are drawn from the medieval Latin tradition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilingual Speech Evaluation: Case Studies on English, Malay and Tamil. (arXiv:2107.03675v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huayun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1">Ke Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nancy F. Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03675">
                                    <div class="article-summary-box-inner">
                                        <span>Speech evaluation is an essential component in computer-assisted language
learning (CALL). While speech evaluation on English has been popular, automatic
speech scoring on low resource languages remains challenging. Work in this area
has focused on monolingual specific designs and handcrafted features stemming
from resource-rich languages like English. Such approaches are often difficult
to generalize to other languages, especially if we also want to consider
suprasegmental qualities such as rhythm. In this work, we examine three
different languages that possess distinct rhythm patterns: English
(stress-timed), Malay (syllable-timed), and Tamil (mora-timed). We exploit
robust feature representations inspired by music processing and vector
representation learning. Empirical validations show consistent gains for all
three languages when predicting pronunciation, rhythm and intonation
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COMBO: a new module for EUD parsing. (arXiv:2107.03809v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Klimaszewski_M/0/1/0/all/0/1">Mateusz Klimaszewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Wroblewska_A/0/1/0/all/0/1">Alina Wr&#xf3;blewska</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03809">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the COMBO-based approach for EUD parsing and its implementation,
which took part in the IWPT 2021 EUD shared task. The goal of this task is to
parse raw texts in 17 languages into Enhanced Universal Dependencies (EUD). The
proposed approach uses COMBO to predict UD trees and EUD graphs. These
structures are then merged into the final EUD graphs. Some EUD edge labels are
extended with case information using a single language-independent expansion
rule. In the official evaluation, the solution ranked fourth, achieving an
average ELAS of 83.79%. The source code is available at
https://gitlab.clarin-pl.eu/syntactic-tools/combo.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling. (arXiv:2107.03451v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dinan_E/0/1/0/all/0/1">Emily Dinan</a>, <a href="http://arxiv.org/find/cs/1/au:+Abercrombie_G/0/1/0/all/0/1">Gavin Abercrombie</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergman_A/0/1/0/all/0/1">A. Stevie Bergman</a>, <a href="http://arxiv.org/find/cs/1/au:+Spruit_S/0/1/0/all/0/1">Shannon Spruit</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_D/0/1/0/all/0/1">Dirk Hovy</a>, <a href="http://arxiv.org/find/cs/1/au:+Boureau_Y/0/1/0/all/0/1">Y-Lan Boureau</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1">Verena Rieser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03451">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last several years, end-to-end neural conversational agents have
vastly improved in their ability to carry a chit-chat conversation with humans.
However, these models are often trained on large datasets from the internet,
and as a result, may learn undesirable behaviors from this data, such as toxic
or otherwise harmful language. Researchers must thus wrestle with the issue of
how and when to release these models. In this paper, we survey the problem
landscape for safety for end-to-end conversational AI and discuss recent and
related work. We highlight tensions between values, potential positive impact
and potential harms, and provide a framework for making decisions about whether
and how to release these models, following the tenets of value-sensitive
design. We additionally provide a suite of tools to enable researchers to make
better-informed decisions about training and releasing end-to-end
conversational AI models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">POSLAN: Disentangling Chat with Positional and Language encoded Post Embeddings. (arXiv:2107.03529v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abeysinghe_B/0/1/0/all/0/1">Bhashithe Abeysinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1">Dhara Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Freas_C/0/1/0/all/0/1">Chris Freas</a>, <a href="http://arxiv.org/find/cs/1/au:+Harrison_R/0/1/0/all/0/1">Robert Harrison</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunderraman_R/0/1/0/all/0/1">Rajshekhar Sunderraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03529">
                                    <div class="article-summary-box-inner">
                                        <span>Most online message threads inherently will be cluttered and any new user or
an existing user visiting after a hiatus will have a difficult time
understanding whats being discussed in the thread. Similarly cluttered
responses in a message thread makes analyzing the messages a difficult problem.
The need for disentangling the clutter is much higher when the platform where
the discussion is taking place does not provide functions to retrieve reply
relations of the messages. This introduces an interesting problem to which
\cite{wang2011learning} phrases as a structural learning problem. We create
vector embeddings for posts in a thread so that it captures both linguistic and
positional features in relation to a context of where a given message is in.
Using these embeddings for posts we compute a similarity based connectivity
matrix which then converted into a graph. After employing a pruning mechanisms
the resultant graph can be used to discover the reply relation for the posts in
the thread. The process of discovering or disentangling chat is kept as an
unsupervised mechanism. We present our experimental results on a data set
obtained from Telegram with limited meta data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HinGE: A Dataset for Generation and Evaluation of Code-Mixed Hinglish Text. (arXiv:2107.03760v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Srivastava_V/0/1/0/all/0/1">Vivek Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Mayank Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03760">
                                    <div class="article-summary-box-inner">
                                        <span>Text generation is a highly active area of research in the computational
linguistic community. The evaluation of the generated text is a challenging
task and multiple theories and metrics have been proposed over the years.
Unfortunately, text generation and evaluation are relatively understudied due
to the scarcity of high-quality resources in code-mixed languages where the
words and phrases from multiple languages are mixed in a single utterance of
text and speech. To address this challenge, we present a corpus (HinGE) for a
widely popular code-mixed language Hinglish (code-mixing of Hindi and English
languages). HinGE has Hinglish sentences generated by humans as well as two
rule-based algorithms corresponding to the parallel Hindi-English sentences. In
addition, we demonstrate the inefficacy of widely-used evaluation metrics on
the code-mixed data. The HinGE dataset will facilitate the progress of natural
language generation research in code-mixed languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keep it Simple: Unsupervised Simplification of Multi-Paragraph Text. (arXiv:2107.03444v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laban_P/0/1/0/all/0/1">Philippe Laban</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnabel_T/0/1/0/all/0/1">Tobias Schnabel</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1">Paul Bennett</a>, <a href="http://arxiv.org/find/cs/1/au:+Hearst_M/0/1/0/all/0/1">Marti A. Hearst</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03444">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents Keep it Simple (KiS), a new approach to unsupervised text
simplification which learns to balance a reward across three properties:
fluency, salience and simplicity. We train the model with a novel algorithm to
optimize the reward (k-SCST), in which the model proposes several candidate
simplifications, computes each candidate&#x27;s reward, and encourages candidates
that outperform the mean reward. Finally, we propose a realistic text
comprehension task as an evaluation method for text simplification. When tested
on the English news domain, the KiS model outperforms strong supervised
baselines by more than 4 SARI points, and can help people complete a
comprehension task an average of 18% faster while retaining accuracy, when
compared to the original text. Code available:
https://github.com/tingofurro/keep_it_simple</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Transformer Models Measure Coherence In Text? Re-Thinking the Shuffle Test. (arXiv:2107.03448v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laban_P/0/1/0/all/0/1">Philippe Laban</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_L/0/1/0/all/0/1">Luke Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Bandarkar_L/0/1/0/all/0/1">Lucas Bandarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hearst_M/0/1/0/all/0/1">Marti A. Hearst</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03448">
                                    <div class="article-summary-box-inner">
                                        <span>The Shuffle Test is the most common task to evaluate whether NLP models can
measure coherence in text. Most recent work uses direct supervision on the
task; we show that by simply finetuning a RoBERTa model, we can achieve a near
perfect accuracy of 97.8%, a state-of-the-art. We argue that this outstanding
performance is unlikely to lead to a good model of text coherence, and suggest
that the Shuffle Test should be approached in a Zero-Shot setting: models
should be evaluated without being trained on the task itself. We evaluate
common models in this setting, such as Generative and Bi-directional
Transformers, and find that larger architectures achieve high-performance
out-of-the-box. Finally, we suggest the k-Block Shuffle Test, a modification of
the original by increasing the size of blocks shuffled. Even though human
reader performance remains high (around 95% accuracy), model performance drops
from 94% to 78% as block size increases, creating a conceptually simple
challenge to benchmark NLP models. Code available:
https://github.com/tingofurro/shuffle_test/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LanguageRefer: Spatial-Language Model for 3D Visual Grounding. (arXiv:2107.03438v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roh_J/0/1/0/all/0/1">Junha Roh</a>, <a href="http://arxiv.org/find/cs/1/au:+Desingh_K/0/1/0/all/0/1">Karthik Desingh</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03438">
                                    <div class="article-summary-box-inner">
                                        <span>To realize robots that can understand human instructions and perform
meaningful tasks in the near future, it is important to develop learned models
that can understand referential language to identify common objects in
real-world 3D scenes. In this paper, we develop a spatial-language model for a
3D visual grounding problem. Specifically, given a reconstructed 3D scene in
the form of a point cloud with 3D bounding boxes of potential object
candidates, and a language utterance referring to a target object in the scene,
our model identifies the target object from a set of potential candidates. Our
spatial-language model uses a transformer-based architecture that combines
spatial embedding from bounding-box with a finetuned language embedding from
DistilBert and reasons among the objects in the 3D scene to find the target
object. We show that our model performs competitively on visio-linguistic
datasets proposed by ReferIt3D. We provide additional analysis of performance
in spatial reasoning tasks decoupled from perception noise, the effect of
view-dependent utterances in terms of accuracy, and view-point annotations for
potential robotics applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning. (arXiv:2106.05956v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1">Ekdeep Singh Lubana</a>, <a href="http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1">Robert P. Dick</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1">Hidenori Tanaka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05956">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by BatchNorm, there has been an explosion of normalization layers
for deep neural networks (DNNs). However, these alternative normalization
layers have seen minimal use, partially due to a lack of guiding principles
that can help identify when these layers can serve as a replacement for
BatchNorm. To address this problem, we take a theoretical approach,
generalizing the known beneficial mechanisms of BatchNorm to several recently
proposed normalization techniques. Our generalized theory leads to the
following set of principles: (i) similar to BatchNorm, activations-based
normalization layers can prevent exponential growth of activations in ResNets,
but parametric layers require explicit remedies; (ii) use of GroupNorm can
ensure informative forward propagation, with different samples being assigned
dissimilar activations, but increasing group size results in increasingly
indistinguishable activations for different samples, explaining slow
convergence speed in models with LayerNorm; (iii) small group sizes result in
large gradient norm in earlier layers, hence explaining training instability
issues in Instance Normalization and illustrating a speed-stability tradeoff in
GroupNorm. Overall, our analysis reveals a unified set of mechanisms that
underpin the success of normalization methods in deep learning, providing us
with a compass to systematically explore the vast design space of DNN
normalization layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Neural Scene Representations for Visuomotor Control. (arXiv:2107.04004v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunzhu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1">Vincent Sitzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1">Pulkit Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1">Antonio Torralba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04004">
                                    <div class="article-summary-box-inner">
                                        <span>Humans have a strong intuitive understanding of the 3D environment around us.
The mental model of the physics in our brain applies to objects of different
materials and enables us to perform a wide range of manipulation tasks that are
far beyond the reach of current robots. In this work, we desire to learn models
for dynamic 3D scenes purely from 2D visual observations. Our model combines
Neural Radiance Fields (NeRF) and time contrastive learning with an
autoencoding framework, which learns viewpoint-invariant 3D-aware scene
representations. We show that a dynamics model, constructed over the learned
representation space, enables visuomotor control for challenging manipulation
tasks involving both rigid bodies and fluids, where the target is specified in
a viewpoint different from what the robot operates on. When coupled with an
auto-decoding framework, it can even support goal specification from camera
viewpoints that are outside the training distribution. We further demonstrate
the richness of the learned 3D dynamics model by performing future prediction
and novel view synthesis. Finally, we provide detailed ablation studies
regarding different system designs and qualitative analysis of the learned
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Conditioned Imitation Learning over Unstructured Data. (arXiv:2005.07648v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lynch_C/0/1/0/all/0/1">Corey Lynch</a>, <a href="http://arxiv.org/find/cs/1/au:+Sermanet_P/0/1/0/all/0/1">Pierre Sermanet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.07648">
                                    <div class="article-summary-box-inner">
                                        <span>Natural language is perhaps the most flexible and intuitive way for humans to
communicate tasks to a robot. Prior work in imitation learning typically
requires each task be specified with a task id or goal image -- something that
is often impractical in open-world environments. On the other hand, previous
approaches in instruction following allow agent behavior to be guided by
language, but typically assume structure in the observations, actuators, or
language that limit their applicability to complex settings like robotics. In
this work, we present a method for incorporating free-form natural language
conditioning into imitation learning. Our approach learns perception from
pixels, natural language understanding, and multitask continuous control
end-to-end as a single neural network. Unlike prior work in imitation learning,
our method is able to incorporate unlabeled and unstructured demonstration data
(i.e. no task or language labels). We show this dramatically improves language
conditioned performance, while reducing the cost of language annotation to less
than 1% of total data. At test time, a single language conditioned visuomotor
policy trained with our method can perform a wide variety of robotic
manipulation skills in a 3D environment, specified only with natural language
descriptions of each task (e.g. &quot;open the drawer...now pick up the block...now
press the green button...&quot;). To scale up the number of instructions an agent
can follow, we propose combining text conditioned policies with large
pretrained neural language models. We find this allows a policy to be robust to
many out-of-distribution synonym instructions, without requiring new
demonstrations. See videos of a human typing live text commands to our agent at
language-play.github.io</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">No-Reference Quality Assessment for Colored Point Cloud and Mesh Based on Natural Scene Statistics. (arXiv:2107.02041v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zicheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+sun_W/0/1/0/all/0/1">Wei sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Wei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_X/0/1/0/all/0/1">Xiongkuo Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wei Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02041">
                                    <div class="article-summary-box-inner">
                                        <span>To improve the viewer&#x27;s quality of experience and optimize processing systems
in computer graphics applications, the 3D quality assessment (3D-QA) has become
an important task in the multimedia area. Point cloud and mesh are the two most
widely used electronic representation formats of 3D models, the quality of
which is quite sensitive to operations like simplification and compression.
Therefore, many studies concerning point cloud quality assessment (PCQA) and
mesh quality assessment (MQA) have been carried out to measure the visual
quality degradations caused by lossy operations. However, a large part of
previous studies utilizes full-reference (FR) metrics, which means they may
fail to predict the accurate quality level of 3D models when the reference 3D
model is not available. Furthermore, limited numbers of 3D-QA metrics are
carried out to take color features into consideration, which significantly
restricts the effectiveness and scope of application. In many quality
assessment studies, natural scene statistics (NSS) have shown a good ability to
quantify the distortion of natural scenes to statistical parameters. Therefore,
we propose an NSS-based no-reference quality assessment metric for colored 3D
models. In this paper, quality-aware features are extracted from the aspects of
color and geometry directly from the 3D models. Then the statistic parameters
are estimated using different distribution models to describe the
characteristic of the 3D models. Our method is mainly validated on the colored
point cloud quality assessment database (SJTU-PCQA) and the colored mesh
quality assessment database (CMDM). The experimental results show that the
proposed method outperforms all the state-of-art NR 3D-QA metrics and obtains
an acceptable gap with the state-of-art FR 3D-QA metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse and Structured Visual Attention. (arXiv:2002.05556v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Martins_P/0/1/0/all/0/1">Pedro Henrique Martins</a>, <a href="http://arxiv.org/find/cs/1/au:+Niculae_V/0/1/0/all/0/1">Vlad Niculae</a>, <a href="http://arxiv.org/find/cs/1/au:+Marinho_Z/0/1/0/all/0/1">Zita Marinho</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1">Andr&#xe9; Martins</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05556">
                                    <div class="article-summary-box-inner">
                                        <span>Visual attention mechanisms are widely used in multimodal tasks, as visual
question answering (VQA). One drawback of softmax-based attention mechanisms is
that they assign some probability mass to all image regions, regardless of
their adjacency structure and of their relevance to the text. In this paper, to
better link the image structure with the text, we replace the traditional
softmax attention mechanism with two alternative sparsity-promoting
transformations: sparsemax, which is able to select only the relevant regions
(assigning zero weight to the rest), and a newly proposed Total-Variation
Sparse Attention (TVmax), which further encourages the joint selection of
adjacent spatial locations. Experiments in VQA show gains in accuracy as well
as higher similarity to human attention, which suggests better
interpretability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OXnet: Omni-supervised Thoracic Disease Detection from Chest X-rays. (arXiv:2104.03218v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1">Luyang Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yanning Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Huangjing Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pheng_P/0/1/0/all/0/1">Pheng-Ann Pheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03218">
                                    <div class="article-summary-box-inner">
                                        <span>Chest X-ray (CXR) is the most typical diagnostic X-ray examination for
screening various thoracic diseases. Automatically localizing lesions from CXR
is promising for alleviating radiologists&#x27; reading burden. However, CXR
datasets are often with massive image-level annotations and scarce lesion-level
annotations, and more often, without annotations. Thus far, unifying different
supervision granularities to develop thoracic disease detection algorithms has
not been comprehensively addressed. In this paper, we present OXnet, the first
deep omni-supervised thoracic disease detection network to our best knowledge
that uses as much available supervision as possible for CXR diagnosis. We first
introduce supervised learning via a one-stage detection model. Then, we inject
a global classification head to the detection model and propose dual attention
alignment to guide the global gradient to the local detection branch, which
enables learning lesion detection from image-level annotations. We also impose
intra-class compactness and inter-class separability with global prototype
alignment to further enhance the global information learning. Moreover, we
leverage a soft focal loss to distill the soft pseudo-labels of unlabeled data
generated by a teacher model. Extensive experiments on a large-scale chest
X-ray dataset show the proposed OXnet outperforms competitive methods with
significant margins. Further, we investigate omni-supervision under various
annotation granularities and corroborate OXnet is a promising choice to
mitigate the plight of annotation shortage for medical image diagnosis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training. (arXiv:2103.06561v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1">Yuqi Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Manli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangzhen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haoyu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yizhao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guoxing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Jingyuan Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Heng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Baogui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Weihao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1">Zongzheng Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yueqian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1">Anwen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jinming Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruichen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yida Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yuqing Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1">Xin Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1">Wanqing Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_D/0/1/0/all/0/1">Danyang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingyan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peiyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1">Zheng Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Chuhao Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuchong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shizhe Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhiwu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zhicheng Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1">Qin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yanyan Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1">Ruihua Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06561">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-modal pre-training models have been intensively explored to bridge
vision and language in recent years. However, most of them explicitly model the
cross-modal interaction between image-text pairs, by assuming that there exists
strong semantic correlation between the text and image modalities. Since this
strong assumption is often invalid in real-world scenarios, we choose to
implicitly model the cross-modal correlation for large-scale multi-modal
pre-training, which is the focus of the Chinese project &#x60;WenLan&#x27; led by our
team. Specifically, with the weak correlation assumption over image-text pairs,
we propose a two-tower pre-training model called BriVL within the cross-modal
contrastive learning framework. Unlike OpenAI CLIP that adopts a simple
contrastive learning method, we devise a more advanced algorithm by adapting
the latest method MoCo into the cross-modal scenario. By building a large
queue-based dictionary, our BriVL can incorporate more negative samples in
limited GPU resources. We further construct a large Chinese multi-source
image-text dataset called RUC-CAS-WenLan for pre-training our BriVL model.
Extensive experiments demonstrate that the pre-trained BriVL model outperforms
both UNITER and OpenAI CLIP on various downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task Fingerprinting for Meta Learning in Biomedical Image Analysis. (arXiv:2107.03949v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Godau_P/0/1/0/all/0/1">Patrick Godau</a>, <a href="http://arxiv.org/find/cs/1/au:+Maier_Hein_L/0/1/0/all/0/1">Lena Maier-Hein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03949">
                                    <div class="article-summary-box-inner">
                                        <span>Shortage of annotated data is one of the greatest bottlenecks in biomedical
image analysis. Meta learning studies how learning systems can increase in
efficiency through experience and could thus evolve as an important concept to
overcome data sparsity. However, the core capability of meta learning-based
approaches is the identification of similar previous tasks given a new task - a
challenge largely unexplored in the biomedical imaging domain. In this paper,
we address the problem of quantifying task similarity with a concept that we
refer to as task fingerprinting. The concept involves converting a given task,
represented by imaging data and corresponding labels, to a fixed-length vector
representation. In fingerprint space, different tasks can be directly compared
irrespective of their data set sizes, types of labels or specific resolutions.
An initial feasibility study in the field of surgical data science (SDS) with
26 classification tasks from various medical and non-medical domains suggests
that task fingerprinting could be leveraged for both (1) selecting appropriate
data sets for pretraining and (2) selecting appropriate architectures for a new
task. Task fingerprinting could thus become an important tool for meta learning
in SDS and other fields of biomedical image analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TGHop: An Explainable, Efficient and Lightweight Method for Texture Generation. (arXiv:2107.04020v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1">Xuejing Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Ganning Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaitai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04020">
                                    <div class="article-summary-box-inner">
                                        <span>An explainable, efficient and lightweight method for texture generation,
called TGHop (an acronym of Texture Generation PixelHop), is proposed in this
work. Although synthesis of visually pleasant texture can be achieved by deep
neural networks, the associated models are large in size, difficult to explain
in theory, and computationally expensive in training. In contrast, TGHop is
small in its model size, mathematically transparent, efficient in training and
inference, and able to generate high quality texture. Given an exemplary
texture, TGHop first crops many sample patches out of it to form a collection
of sample patches called the source. Then, it analyzes pixel statistics of
samples from the source and obtains a sequence of fine-to-coarse subspaces for
these patches by using the PixelHop++ framework. To generate texture patches
with TGHop, we begin with the coarsest subspace, which is called the core, and
attempt to generate samples in each subspace by following the distribution of
real samples. Finally, texture patches are stitched to form texture images of a
large size. It is demonstrated by experimental results that TGHop can generate
texture images of superior quality with a small model size and at a fast speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascaded Diffusion Models for High Fidelity Image Generation. (arXiv:2106.15282v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Saharia_C/0/1/0/all/0/1">Chitwan Saharia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1">William Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1">David J. Fleet</a>, <a href="http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1">Mohammad Norouzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Salimans_T/0/1/0/all/0/1">Tim Salimans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15282">
                                    <div class="article-summary-box-inner">
                                        <span>We show that cascaded diffusion models are capable of generating high
fidelity images on the class-conditional ImageNet generation challenge, without
any assistance from auxiliary image classifiers to boost sample quality. A
cascaded diffusion model comprises a pipeline of multiple diffusion models that
generate images of increasing resolution, beginning with a standard diffusion
model at the lowest resolution, followed by one or more super-resolution
diffusion models that successively upsample the image and add higher resolution
details. We find that the sample quality of a cascading pipeline relies
crucially on conditioning augmentation, our proposed method of data
augmentation of the lower resolution conditioning inputs to the
super-resolution models. Our experiments show that conditioning augmentation
prevents compounding error during sampling in a cascaded model, helping us to
train cascading pipelines achieving FID scores of 1.48 at 64x64, 3.52 at
128x128 and 4.88 at 256x256 resolutions, outperforming BigGAN-deep, and
classification accuracy scores of 63.02% (top-1) and 84.06% (top-5) at 256x256,
outperforming VQ-VAE-2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BANet: Blur-aware Attention Networks for Dynamic Scene Deblurring. (arXiv:2101.07518v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsai%2A_F/0/1/0/all/0/1">Fu-Jen Tsai*</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng%2A_Y/0/1/0/all/0/1">Yan-Tsung Peng*</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yen-Yu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_C/0/1/0/all/0/1">Chung-Chi Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chia-Wen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07518">
                                    <div class="article-summary-box-inner">
                                        <span>Image motion blur usually results from moving objects or camera shakes. Such
blur is generally directional and non-uniform. Previous research efforts
attempt to solve non-uniform blur by using self-recurrent multi-scale or
multi-patch architectures accompanying with self-attention. However, using
self-recurrent frameworks typically leads to a longer inference time, while
inter-pixel or inter-channel self-attention may cause excessive memory usage.
This paper proposes blur-aware attention networks (BANet) that accomplish
accurate and efficient deblurring via a single forward pass. Our BANet utilizes
region-based self-attention with multi-kernel strip pooling to disentangle blur
patterns of different degrees and with cascaded parallel dilated convolution to
aggregate multi-scale content features. Extensive experimental results on the
GoPro and HIDE benchmarks demonstrate that the proposed BANet performs
favorably against the state-of-the-art in blurred image restoration and can
provide deblurred results in real-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flexibly Regularized Mixture Models and Application to Image Segmentation. (arXiv:1905.10629v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vacher_J/0/1/0/all/0/1">Jonathan Vacher</a>, <a href="http://arxiv.org/find/cs/1/au:+Launay_C/0/1/0/all/0/1">Claire Launay</a>, <a href="http://arxiv.org/find/cs/1/au:+Coen_Cagli_R/0/1/0/all/0/1">Ruben Coen-Cagli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10629">
                                    <div class="article-summary-box-inner">
                                        <span>Probabilistic finite mixture models are widely used for unsupervised
clustering. These models can often be improved by adapting them to the topology
of the data. For instance, in order to classify spatially adjacent data points
similarly, it is common to introduce a Laplacian constraint on the posterior
probability that each data point belongs to a class. Alternatively, the mixing
probabilities can be treated as free parameters, while assuming Gauss-Markov or
more complex priors to regularize those mixing probabilities. However, these
approaches are constrained by the shape of the prior and often lead to
complicated or intractable inference. Here, we propose a new parametrization of
the Dirichlet distribution to flexibly regularize the mixing probabilities of
over-parametrized mixture distributions. Using the Expectation-Maximization
algorithm, we show that our approach allows us to define any linear update rule
for the mixing probabilities, including spatial smoothing regularization as a
special case. We then show that this flexible design can be extended to share
class information between multiple mixture models. We apply our algorithm to
artificial and natural image segmentation tasks, and we provide quantitative
and qualitative comparison of the performance of Gaussian and Student-t
mixtures on the Berkeley Segmentation Dataset. We also demonstrate how to
propagate class information across the layers of deep convolutional neural
networks in a probabilistically optimal way, suggesting a new interpretation
for feedback signals in biological visual systems. Our flexible approach can be
easily generalized to adapt probabilistic mixture models to arbitrary data
topologies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modality Completion via Gaussian Process Prior Variational Autoencoders for Multi-Modal Glioma Segmentation. (arXiv:2107.03442v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hamghalam_M/0/1/0/all/0/1">Mohammad Hamghalam</a>, <a href="http://arxiv.org/find/eess/1/au:+Frangi_A/0/1/0/all/0/1">Alejandro F. Frangi</a>, <a href="http://arxiv.org/find/eess/1/au:+Lei_B/0/1/0/all/0/1">Baiying Lei</a>, <a href="http://arxiv.org/find/eess/1/au:+Simpson_A/0/1/0/all/0/1">Amber L. Simpson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03442">
                                    <div class="article-summary-box-inner">
                                        <span>In large studies involving multi protocol Magnetic Resonance Imaging (MRI),
it can occur to miss one or more sub-modalities for a given patient owing to
poor quality (e.g. imaging artifacts), failed acquisitions, or hallway
interrupted imaging examinations. In some cases, certain protocols are
unavailable due to limited scan time or to retrospectively harmonise the
imaging protocols of two independent studies. Missing image modalities pose a
challenge to segmentation frameworks as complementary information contributed
by the missing scans is then lost. In this paper, we propose a novel model,
Multi-modal Gaussian Process Prior Variational Autoencoder (MGP-VAE), to impute
one or more missing sub-modalities for a patient scan. MGP-VAE can leverage the
Gaussian Process (GP) prior on the Variational Autoencoder (VAE) to utilize the
subjects/patients and sub-modalities correlations. Instead of designing one
network for each possible subset of present sub-modalities or using frameworks
to mix feature maps, missing data can be generated from a single model based on
all the available samples. We show the applicability of MGP-VAE on brain tumor
segmentation where either, two, or three of four sub-modalities may be missing.
Our experiments against competitive segmentation baselines with missing
sub-modality on BraTS&#x27;19 dataset indicate the effectiveness of the MGP-VAE
model for segmentation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MotionRNN: A Flexible Model for Video Prediction with Spacetime-Varying Motions. (arXiv:2103.02243v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Haixu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhiyu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianmin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1">Mingsheng Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02243">
                                    <div class="article-summary-box-inner">
                                        <span>This paper tackles video prediction from a new dimension of predicting
spacetime-varying motions that are incessantly changing across both space and
time. Prior methods mainly capture the temporal state transitions but overlook
the complex spatiotemporal variations of the motion itself, making them
difficult to adapt to ever-changing motions. We observe that physical world
motions can be decomposed into transient variation and motion trend, while the
latter can be regarded as the accumulation of previous motions. Thus,
simultaneously capturing the transient variation and the motion trend is the
key to make spacetime-varying motions more predictable. Based on these
observations, we propose the MotionRNN framework, which can capture the complex
variations within motions and adapt to spacetime-varying scenarios. MotionRNN
has two main contributions. The first is that we design the MotionGRU unit,
which can model the transient variation and motion trend in a unified way. The
second is that we apply the MotionGRU to RNN-based predictive models and
indicate a new flexible video prediction architecture with a Motion Highway
that can significantly improve the ability to predict changeable motions and
avoid motion vanishing for stacked multiple-layer predictive models. With high
flexibility, this framework can adapt to a series of models for deterministic
spatiotemporal prediction. Our MotionRNN can yield significant improvements on
three challenging benchmarks for video prediction with spacetime-varying
motions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-Time Ellipse Detection for Robotics Applications. (arXiv:2102.12670v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keipour_A/0/1/0/all/0/1">Azarakhsh Keipour</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_G/0/1/0/all/0/1">Guilherme A. S. Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1">Sebastian Scherer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12670">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new algorithm for real-time detection and tracking of elliptic
patterns suitable for real-world robotics applications. The method fits
ellipses to each contour in the image frame and rejects ellipses that do not
yield a good fit. The resulting detection and tracking method is lightweight
enough to be used on robots&#x27; resource-limited onboard computers, can deal with
lighting variations and detect the pattern even when the view is partial. The
method is tested on an example application of an autonomous UAV landing on a
fast-moving vehicle to show its performance indoors, outdoors, and in
simulation on a real-world robotics task. The comparison with other well-known
ellipse detection methods shows that our proposed algorithm outperforms other
methods with the F1 score of 0.981 on a dataset with over 1500 frames. The
videos of experiments, the source codes, and the collected dataset are provided
with the paper at https://theairlab.org/landing-on-vehicle .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking annotation granularity for overcoming deep shortcut learning: A retrospective study on chest radiographs. (arXiv:2104.10553v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Luo_L/0/1/0/all/0/1">Luyang Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiao_Y/0/1/0/all/0/1">Yongjie Xiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_Y/0/1/0/all/0/1">Yanning Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1">Xi Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Vardhanabhuti_V/0/1/0/all/0/1">Varut Vardhanabhuti</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_M/0/1/0/all/0/1">Mingxiang Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Heng_P/0/1/0/all/0/1">Pheng-Ann Heng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10553">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has demonstrated radiograph screening performances that are
comparable or superior to radiologists. However, recent studies show that deep
models for thoracic disease classification usually show degraded performance
when applied to external data. Such phenomena can be categorized into shortcut
learning, where the deep models learn unintended decision rules that can fit
the identically distributed training and test set but fail to generalize to
other distributions. A natural way to alleviate this defect is explicitly
indicating the lesions and focusing the model on learning the intended
features. In this paper, we conduct extensive retrospective experiments to
compare a popular thoracic disease classification model, CheXNet, and a
thoracic lesion detection model, CheXDet. We first showed that the two models
achieved similar image-level classification performance on the internal test
set with no significant differences under many scenarios. Meanwhile, we found
incorporating external training data even led to performance degradation for
CheXNet. Then, we compared the models&#x27; internal performance on the lesion
localization task and showed that CheXDet achieved significantly better
performance than CheXNet even when given 80% less training data. By further
visualizing the models&#x27; decision-making regions, we revealed that CheXNet
learned patterns other than the target lesions, demonstrating its shortcut
learning defect. Moreover, CheXDet achieved significantly better external
performance than CheXNet on both the image-level classification task and the
lesion localization task. Our findings suggest improving annotation granularity
for training deep learning systems as a promising way to elevate future deep
learning-based diagnosis systems for clinical usage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral decoupling allows training transferable neural networks in medical imaging. (arXiv:2103.17171v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pohjonen_J/0/1/0/all/0/1">Joona Pohjonen</a>, <a href="http://arxiv.org/find/eess/1/au:+Sturenberg_C/0/1/0/all/0/1">Carolin St&#xfc;renberg</a>, <a href="http://arxiv.org/find/eess/1/au:+Rannikko_A/0/1/0/all/0/1">Antti Rannikko</a>, <a href="http://arxiv.org/find/eess/1/au:+Mirtti_T/0/1/0/all/0/1">Tuomas Mirtti</a>, <a href="http://arxiv.org/find/eess/1/au:+Pitkanen_E/0/1/0/all/0/1">Esa Pitk&#xe4;nen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17171">
                                    <div class="article-summary-box-inner">
                                        <span>Many current neural networks for medical imaging generalise poorly to data
unseen during training. Such behaviour can be caused by networks overfitting
easy-to-learn, or statistically dominant, features while disregarding other
potentially informative features. For example, indistinguishable differences in
the sharpness of the images from two different scanners can degrade the
performance of the network significantly. All neural networks intended for
clinical practice need to be robust to variation in data caused by differences
in imaging equipment, sample preparation and patient populations.

To address these challenges, we evaluate the utility of spectral decoupling
as an implicit bias mitigation method. Spectral decoupling encourages the
neural network to learn more features by simply regularising the networks&#x27;
unnormalised prediction scores with an L2 penalty, thus having no added
computational costs.

We show that spectral decoupling allows training neural networks on datasets
with strong spurious correlations. Networks trained without spectral decoupling
do not learn the original task and appear to make false predictions based on
the spurious correlations. Spectral decoupling also increases networks&#x27;
robustness for data distribution shifts. To validate our findings, we train
networks with and without spectral decoupling to detect prostate cancer tissue
slides and COVID-19 in chest radiographs. Networks trained with spectral
decoupling achieve substantially higher performance on all evaluation datasets.

Our results show that spectral decoupling helps with generalisation issues
associated with neural networks. We recommend using spectral decoupling as an
implicit bias mitigation method in any neural network intended for clinical
use.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly-Supervised Online Hashing. (arXiv:2009.07436v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_Y/0/1/0/all/0/1">Yu-Wei Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhen-Duo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xin-Shun Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07436">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of social websites, recent years have witnessed an
explosive growth of social images with user-provided tags which continuously
arrive in a streaming fashion. Due to the fast query speed and low storage
cost, hashing-based methods for image search have attracted increasing
attention. However, existing hashing methods for social image retrieval are
based on batch mode which violates the nature of social images, i.e., social
images are usually generated periodically or collected in a stream fashion.
Although there exist many online image hashing methods, they either adopt
unsupervised learning which ignore the relevant tags, or are designed in the
supervised manner which needs high-quality labels. In this paper, to overcome
the above limitations, we propose a new method named Weakly-supervised Online
Hashing (WOH). In order to learn high-quality hash codes, WOH exploits the weak
supervision by considering the semantics of tags and removing the noise.
Besides, We develop a discrete online optimization algorithm for WOH, which is
efficient and scalable. Extensive experiments conducted on two real-world
datasets demonstrate the superiority of WOH compared with several
state-of-the-art hashing baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Worsening Perception: Real-time Degradation of Autonomous Vehicle Perception Performance for Simulation of Adverse Weather Conditions. (arXiv:2103.02760v4 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fursa_I/0/1/0/all/0/1">Ivan Fursa</a>, <a href="http://arxiv.org/find/cs/1/au:+Fandi_E/0/1/0/all/0/1">Elias Fandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Musat_V/0/1/0/all/0/1">Valentina Musat</a>, <a href="http://arxiv.org/find/cs/1/au:+Culley_J/0/1/0/all/0/1">Jacob Culley</a>, <a href="http://arxiv.org/find/cs/1/au:+Gil_E/0/1/0/all/0/1">Enric Gil</a>, <a href="http://arxiv.org/find/cs/1/au:+Teeti_I/0/1/0/all/0/1">Izzeddin Teeti</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilous_L/0/1/0/all/0/1">Louise Bilous</a>, <a href="http://arxiv.org/find/cs/1/au:+Sluis_I/0/1/0/all/0/1">Isaac Vander Sluis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rast_A/0/1/0/all/0/1">Alexander Rast</a>, <a href="http://arxiv.org/find/cs/1/au:+Bradley_A/0/1/0/all/0/1">Andrew Bradley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02760">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous vehicles rely heavily upon their perception subsystems to see the
environment in which they operate. Unfortunately, the effect of variable
weather conditions presents a significant challenge to object detection
algorithms, and thus it is imperative to test the vehicle extensively in all
conditions which it may experience. However, development of robust autonomous
vehicle subsystems requires repeatable, controlled testing - while real weather
is unpredictable and cannot be scheduled. Real-world testing in adverse
conditions is an expensive and time-consuming task, often requiring access to
specialist facilities. Simulation is commonly relied upon as a substitute, with
increasingly visually realistic representations of the real-world being
developed. In the context of the complete autonomous vehicle control pipeline,
subsystems downstream of perception need to be tested with accurate recreations
of the perception system output, rather than focusing on subjective visual
realism of the input - whether in simulation or the real world. This study
develops the untapped potential of a lightweight weather augmentation method in
an autonomous racing vehicle - focusing not on visual accuracy, but rather the
effect upon perception subsystem performance in real time. With minimal
adjustment, the prototype developed in this study can replicate the effects of
water droplets on the camera lens, and fading light conditions. This approach
introduces a latency of less than 8 ms using compute hardware well suited to
being carried in the vehicle - rendering it ideal for real-time implementation
that can be run during experiments in simulation, and augmented reality testing
in the real world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Safety Envelopes using Light Curtains with Probabilistic Guarantees. (arXiv:2107.04000v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ancha_S/0/1/0/all/0/1">Siddharth Ancha</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_G/0/1/0/all/0/1">Gaurav Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_S/0/1/0/all/0/1">Srinivasa G. Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1">David Held</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04000">
                                    <div class="article-summary-box-inner">
                                        <span>To safely navigate unknown environments, robots must accurately perceive
dynamic obstacles. Instead of directly measuring the scene depth with a LiDAR
sensor, we explore the use of a much cheaper and higher resolution sensor:
programmable light curtains. Light curtains are controllable depth sensors that
sense only along a surface that a user selects. We use light curtains to
estimate the safety envelope of a scene: a hypothetical surface that separates
the robot from all obstacles. We show that generating light curtains that sense
random locations (from a particular distribution) can quickly discover the
safety envelope for scenes with unknown objects. Importantly, we produce
theoretical safety guarantees on the probability of detecting an obstacle using
random curtains. We combine random curtains with a machine learning based model
that forecasts and tracks the motion of the safety envelope efficiently. Our
method accurately estimates safety envelopes while providing probabilistic
safety guarantees that can be used to certify the efficacy of a robot
perception system to detect and avoid dynamic obstacles. We evaluate our
approach in a simulated urban driving environment and a real-world environment
with moving pedestrians using a light curtain device and show that we can
estimate safety envelopes efficiently and effectively. Project website:
https://siddancha.github.io/projects/active-safety-envelopes-with-guarantees</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-frame Collaboration for Effective Endoscopic Video Polyp Detection via Spatial-Temporal Feature Transformation. (arXiv:2107.03609v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lingyun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiqiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yuanfeng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shaoting Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03609">
                                    <div class="article-summary-box-inner">
                                        <span>Precise localization of polyp is crucial for early cancer screening in
gastrointestinal endoscopy. Videos given by endoscopy bring both richer
contextual information as well as more challenges than still images. The
camera-moving situation, instead of the common camera-fixed-object-moving one,
leads to significant background variation between frames. Severe internal
artifacts (e.g. water flow in the human body, specular reflection by tissues)
can make the quality of adjacent frames vary considerately. These factors
hinder a video-based model to effectively aggregate features from neighborhood
frames and give better predictions. In this paper, we present Spatial-Temporal
Feature Transformation (STFT), a multi-frame collaborative framework to address
these issues. Spatially, STFT mitigates inter-frame variations in the
camera-moving situation with feature alignment by proposal-guided deformable
convolutions. Temporally, STFT proposes a channel-aware attention module to
simultaneously estimate the quality and correlation of adjacent frames for
adaptive feature aggregation. Empirical studies and superior results
demonstrate the effectiveness and stability of our method. For example, STFT
improves the still image baseline FCOS by 10.6% and 20.6% on the comprehensive
F1-score of the polyp localization task in CVC-Clinic and ASUMayo datasets,
respectively, and outperforms the state-of-the-art video-based method by 3.6%
and 8.0%, respectively. Code is available at
\url{https://github.com/lingyunwu14/STFT}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Based Image Retrieval in the JPEG Compressed Domain. (arXiv:2107.03648v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Temburwar_S/0/1/0/all/0/1">Shrikant Temburwar</a>, <a href="http://arxiv.org/find/eess/1/au:+Rajesh_B/0/1/0/all/0/1">Bulla Rajesh</a>, <a href="http://arxiv.org/find/eess/1/au:+Javed_M/0/1/0/all/0/1">Mohammed Javed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03648">
                                    <div class="article-summary-box-inner">
                                        <span>Content-based image retrieval (CBIR) systems on pixel domain use low-level
features, such as colour, texture and shape, to retrieve images. In this
context, two types of image representations i.e. local and global image
features have been studied in the literature. Extracting these features from
pixel images and comparing them with images from the database is very
time-consuming. Therefore, in recent years, there has been some effort to
accomplish image analysis directly in the compressed domain with lesser
computations. Furthermore, most of the images in our daily transactions are
stored in the JPEG compressed format. Therefore, it would be ideal if we could
retrieve features directly from the partially decoded or compressed data and
use them for retrieval. Here, we propose a unified model for image retrieval
which takes DCT coefficients as input and efficiently extracts global and local
features directly in the JPEG compressed domain for accurate image retrieval.
The experimental findings indicate that our proposed model performed similarly
to the current DELG model which takes RGB features as an input with reference
to mean average precision while having a faster training and retrieval speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers. (arXiv:2107.03996v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruihan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansen_N/0/1/0/all/0/1">Nicklas Hansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huazhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03996">
                                    <div class="article-summary-box-inner">
                                        <span>We propose to address quadrupedal locomotion tasks using Reinforcement
Learning (RL) with a Transformer-based model that learns to combine
proprioceptive information and high-dimensional depth sensor inputs. While
learning-based locomotion has made great advances using RL, most methods still
rely on domain randomization for training blind agents that generalize to
challenging terrains. Our key insight is that proprioceptive states only offer
contact measurements for immediate reaction, whereas an agent equipped with
visual sensory observations can learn to proactively maneuver environments with
obstacles and uneven terrain by anticipating changes in the environment many
steps ahead. In this paper, we introduce LocoTransformer, an end-to-end RL
method for quadrupedal locomotion that leverages a Transformer-based model for
fusing proprioceptive states and visual observations. We evaluate our method in
challenging simulated environments with different obstacles and uneven terrain.
We show that our method obtains significant improvements over policies with
only proprioceptive state inputs, and that Transformer-based models further
improve generalization across environments. Our project page with videos is at
https://RchalYang.github.io/LocoTransformer .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consensus Clustering With Unsupervised Representation Learning. (arXiv:2010.01245v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Regatti_J/0/1/0/all/0/1">Jayanth Reddy Regatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshmukh_A/0/1/0/all/0/1">Aniket Anand Deshmukh</a>, <a href="http://arxiv.org/find/cs/1/au:+Manavoglu_E/0/1/0/all/0/1">Eren Manavoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dogan_U/0/1/0/all/0/1">Urun Dogan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01245">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep clustering and unsupervised representation learning
are based on the idea that different views of an input image (generated through
data augmentation techniques) must either be closer in the representation
space, or have a similar cluster assignment. Bootstrap Your Own Latent (BYOL)
is one such representation learning algorithm that has achieved
state-of-the-art results in self-supervised image classification on ImageNet
under the linear evaluation protocol. However, the utility of the learnt
features of BYOL to perform clustering is not explored. In this work, we study
the clustering ability of BYOL and observe that features learnt using BYOL may
not be optimal for clustering. We propose a novel consensus clustering based
loss function, and train BYOL with the proposed loss in an end-to-end way that
improves the clustering ability and outperforms similar clustering based
methods on some popular computer vision datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video 3D Sampling for Self-supervised Representation Learning. (arXiv:2107.03578v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_D/0/1/0/all/0/1">Dezhao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_B/0/1/0/all/0/1">Bo Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Weiping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03578">
                                    <div class="article-summary-box-inner">
                                        <span>Most of the existing video self-supervised methods mainly leverage temporal
signals of videos, ignoring that the semantics of moving objects and
environmental information are all critical for video-related tasks. In this
paper, we propose a novel self-supervised method for video representation
learning, referred to as Video 3D Sampling (V3S). In order to sufficiently
utilize the information (spatial and temporal) provided in videos, we
pre-process a video from three dimensions (width, height, time). As a result,
we can leverage the spatial information (the size of objects), temporal
information (the direction and magnitude of motions) as our learning target. In
our implementation, we combine the sampling of the three dimensions and propose
the scale and projection transformations in space and time respectively. The
experimental results show that, when applied to action recognition, video
retrieval and action similarity labeling, our approach improves the
state-of-the-arts with significant margins.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting the relationship between visual and textual features in social networks for image classification with zero-shot deep learning. (arXiv:2107.03751v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lucas_L/0/1/0/all/0/1">Luis Lucas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomas_D/0/1/0/all/0/1">David Tomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_Rodriguez_J/0/1/0/all/0/1">Jose Garcia-Rodriguez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03751">
                                    <div class="article-summary-box-inner">
                                        <span>One of the main issues related to unsupervised machine learning is the cost
of processing and extracting useful information from large datasets. In this
work, we propose a classifier ensemble based on the transferable learning
capabilities of the CLIP neural network architecture in multimodal environments
(image and text) from social media. For this purpose, we used the InstaNY100K
dataset and proposed a validation approach based on sampling techniques. Our
experiments, based on image classification tasks according to the labels of the
Places dataset, are performed by first considering only the visual part, and
then adding the associated texts as support. The results obtained demonstrated
that trained neural networks such as CLIP can be successfully applied to image
classification with little fine-tuning, and considering the associated texts to
the images can help to improve the accuracy depending on the goal. The results
demonstrated what seems to be a promising research direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Technical Report for Valence-Arousal Estimation in ABAW2 Challenge. (arXiv:2107.03891v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Hong-Xia Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1">I-Hsuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_L/0/1/0/all/0/1">Ling Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shuai_H/0/1/0/all/0/1">Hong-Han Shuai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1">Wen-Huang Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03891">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we describe our method for tackling the valence-arousal
estimation challenge from ABAW2 ICCV-2021 Competition. The competition
organizers provide an in-the-wild Aff-Wild2 dataset for participants to analyze
affective behavior in real-life settings. We use a two stream model to learn
emotion features from appearance and action respectively. To solve data
imbalanced problem, we apply label distribution smoothing (LDS) to re-weight
labels. Our proposed method achieves Concordance Correlation Coefficient (CCC)
of 0.591 and 0.617 for valence and arousal on the validation set of Aff-wild2
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Case-based similar image retrieval for weakly annotated large histopathological images of malignant lymphoma using deep metric learning. (arXiv:2107.03602v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hashimoto_N/0/1/0/all/0/1">Noriaki Hashimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Takagi_Y/0/1/0/all/0/1">Yusuke Takagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Masuda_H/0/1/0/all/0/1">Hiroki Masuda</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyoshi_H/0/1/0/all/0/1">Hiroaki Miyoshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohno_K/0/1/0/all/0/1">Kei Kohno</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagaishi_M/0/1/0/all/0/1">Miharu Nagaishi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_K/0/1/0/all/0/1">Kensaku Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeuchi_M/0/1/0/all/0/1">Mai Takeuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Furuta_T/0/1/0/all/0/1">Takuya Furuta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawamoto_K/0/1/0/all/0/1">Keisuke Kawamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamada_K/0/1/0/all/0/1">Kyohei Yamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Moritsubo_M/0/1/0/all/0/1">Mayuko Moritsubo</a>, <a href="http://arxiv.org/find/cs/1/au:+Inoue_K/0/1/0/all/0/1">Kanako Inoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Shimasaki_Y/0/1/0/all/0/1">Yasumasa Shimasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogura_Y/0/1/0/all/0/1">Yusuke Ogura</a>, <a href="http://arxiv.org/find/cs/1/au:+Imamoto_T/0/1/0/all/0/1">Teppei Imamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishina_T/0/1/0/all/0/1">Tatsuzo Mishina</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohshima_K/0/1/0/all/0/1">Koichi Ohshima</a>, <a href="http://arxiv.org/find/cs/1/au:+Hontani_H/0/1/0/all/0/1">Hidekata Hontani</a>, <a href="http://arxiv.org/find/cs/1/au:+Takeuchi_I/0/1/0/all/0/1">Ichiro Takeuchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03602">
                                    <div class="article-summary-box-inner">
                                        <span>In the present study, we propose a novel case-based similar image retrieval
(SIR) method for hematoxylin and eosin (H&amp;E)-stained histopathological images
of malignant lymphoma. When a whole slide image (WSI) is used as an input
query, it is desirable to be able to retrieve similar cases by focusing on
image patches in pathologically important regions such as tumor cells. To
address this problem, we employ attention-based multiple instance learning,
which enables us to focus on tumor-specific regions when the similarity between
cases is computed. Moreover, we employ contrastive distance metric learning to
incorporate immunohistochemical (IHC) staining patterns as useful supervised
information for defining appropriate similarity between heterogeneous malignant
lymphoma cases. In the experiment with 249 malignant lymphoma patients, we
confirmed that the proposed method exhibited higher evaluation measures than
the baseline case-based SIR methods. Furthermore, the subjective evaluation by
pathologists revealed that our similarity measure using IHC staining patterns
is appropriate for representing the similarity of H&amp;E-stained tissue images for
malignant lymphoma.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CamTuner: Reinforcement-Learning based System for Camera Parameter Tuning to enhance Analytics. (arXiv:2107.03964v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1">Sibendu Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_K/0/1/0/all/0/1">Kunal Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Coviello_G/0/1/0/all/0/1">Giuseppe Coviello</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankaradas_M/0/1/0/all/0/1">Murugan Sankaradas</a>, <a href="http://arxiv.org/find/cs/1/au:+Po_O/0/1/0/all/0/1">Oliver Po</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Y. Charlie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakradhar_S/0/1/0/all/0/1">Srimat T. Chakradhar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03964">
                                    <div class="article-summary-box-inner">
                                        <span>Complex sensors like video cameras include tens of configurable parameters,
which can be set by end-users to customize the sensors to specific application
scenarios. Although parameter settings significantly affect the quality of the
sensor output and the accuracy of insights derived from sensor data, most
end-users use a fixed parameter setting because they lack the skill or
understanding to appropriately configure these parameters. We propose CamTuner,
which is a system to automatically, and dynamically adapt the complex sensor to
changing environments. CamTuner includes two key components. First, a bespoke
analytics quality estimator, which is a deep-learning model to automatically
and continuously estimate the quality of insights from an analytics unit as the
environment around a sensor change. Second, a reinforcement learning (RL)
module, which reacts to the changes in quality, and automatically adjusts the
camera parameters to enhance the accuracy of insights. We improve the training
time of the RL module by an order of magnitude by designing virtual models to
mimic essential behavior of the camera: we design virtual knobs that can be set
to different values to mimic the effects of assigning different values to the
camera&#x27;s configurable parameters, and we design a virtual camera model that
mimics the output from a video camera at different times of the day. These
virtual models significantly accelerate training because (a) frame rates from a
real camera are limited to 25-30 fps while the virtual models enable processing
at 300 fps, (b) we do not have to wait until the real camera sees different
environments, which could take weeks or months, and (c) virtual knobs can be
updated instantly, while it can take 200-500 ms to change the camera parameter
settings. Our dynamic tuning approach results in up to 12% improvement in the
accuracy of insights from several video analytics tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Effectiveness and Efficiency of Stochastic Neighbour Embedding with Isolation Kernel. (arXiv:1906.09744v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Ye Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ting_K/0/1/0/all/0/1">Kai Ming Ting</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.09744">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new insight into improving the performance of
Stochastic Neighbour Embedding (t-SNE) by using Isolation kernel instead of
Gaussian kernel. Isolation kernel outperforms Gaussian kernel in two aspects.
First, the use of Isolation kernel in t-SNE overcomes the drawback of
misrepresenting some structures in the data, which often occurs when Gaussian
kernel is applied in t-SNE. This is because Gaussian kernel determines each
local bandwidth based on one local point only, while Isolation kernel is
derived directly from the data based on space partitioning. Second, the use of
Isolation kernel yields a more efficient similarity computation because
data-dependent Isolation kernel has only one parameter that needs to be tuned.
In contrast, the use of data-independent Gaussian kernel increases the
computational cost by determining n bandwidths for a dataset of n points. As
the root cause of these deficiencies in t-SNE is Gaussian kernel, we show that
simply replacing Gaussian kernel with Isolation kernel in t-SNE significantly
improves the quality of the final visualisation output (without creating
misrepresented structures) and removes one key obstacle that prevents t-SNE
from processing large datasets. Moreover, Isolation kernel enables t-SNE to
deal with large-scale datasets in less runtime without trading off accuracy,
unlike existing methods in speeding up t-SNE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectroscopic Approach to Correction and Visualisation of Bright-Field Light Transmission Microscopy Biological Data. (arXiv:1903.06519v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Platonova_G/0/1/0/all/0/1">Ganna Platonova</a>, <a href="http://arxiv.org/find/eess/1/au:+Stys_D/0/1/0/all/0/1">Dalibor Stys</a>, <a href="http://arxiv.org/find/eess/1/au:+Soucek_P/0/1/0/all/0/1">Pavel Soucek</a>, <a href="http://arxiv.org/find/eess/1/au:+Lonhus_K/0/1/0/all/0/1">Kirill Lonhus</a>, <a href="http://arxiv.org/find/eess/1/au:+Valenta_J/0/1/0/all/0/1">Jan Valenta</a>, <a href="http://arxiv.org/find/eess/1/au:+Rychtarikova_R/0/1/0/all/0/1">Renata Rychtarikova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.06519">
                                    <div class="article-summary-box-inner">
                                        <span>The most realistic information about the transparent sample such as a live
cell can be obtained only using bright-field light microscopy. At
high-intensity pulsing LED illumination, we captured a primary
12-bit-per-channel (bpc) response from an observed sample using a bright-field
microscope equipped with a high-resolution (4872x3248) image sensor. In order
to suppress data distortions originating from the light interactions with
elements in the optical path, poor sensor reproduction (geometrical defects of
the camera sensor and some peculiarities of sensor sensitivity), we propose a
spectroscopic approach for the correction of this uncompressed 12-bpc data by
simultaneous calibration of all parts of the experimental arrangement.
Moreover, the final intensities of the corrected images are proportional to the
photon fluxes detected by a camera sensor. It can be visualized in 8-bpc
intensity depth after the Least Information Loss compression [Lect. Notes
Bioinform. 9656, 527 (2016)].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regional Differential Information Entropy for Super-Resolution Image Quality Assessment. (arXiv:2107.03642v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xu_N/0/1/0/all/0/1">Ningyuan Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhuang_J/0/1/0/all/0/1">Jiayan Zhuang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiao_J/0/1/0/all/0/1">Jiangjian Xiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Peng_C/0/1/0/all/0/1">Chengbin Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03642">
                                    <div class="article-summary-box-inner">
                                        <span>PSNR and SSIM are the most widely used metrics in super-resolution problems,
because they are easy to use and can evaluate the similarities between
generated images and reference images. However, single image super-resolution
is an ill-posed problem, there are multiple corresponding high-resolution
images for the same low-resolution image. The similarities can&#x27;t totally
reflect the restoration effect. The perceptual quality of generated images is
also important, but PSNR and SSIM do not reflect perceptual quality well. To
solve the problem, we proposed a method called regional differential
information entropy to measure both of the similarities and perceptual quality.
To overcome the problem that traditional image information entropy can&#x27;t
reflect the structure information, we proposed to measure every region&#x27;s
information entropy with sliding window. Considering that the human visual
system is more sensitive to the brightness difference at low brightness, we
take $\gamma$ quantization rather than linear quantization. To accelerate the
method, we reorganized the calculation procedure of information entropy with a
neural network. Through experiments on our IQA dataset and PIPAL, this paper
proves that RDIE can better quantify perceptual quality of images especially
GAN-based images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Embedded Iris Recognition System Optimization using Dynamically ReconfigurableDecoder with LDPC Codes. (arXiv:2107.03688v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Longyu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sham_C/0/1/0/all/0/1">Chiu-Wing Sham</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_C/0/1/0/all/0/1">Chun Yan Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_X/0/1/0/all/0/1">Xinchao Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03688">
                                    <div class="article-summary-box-inner">
                                        <span>Extracting and analyzing iris textures for biometric recognition has been
extensively studied. As the transition of iris recognition from lab technology
to nation-scale applications, most systems are facing high complexity in either
time or space, leading to unfitness for embedded devices. In this paper, the
proposed design includes a minimal set of computer vision modules and
multi-mode QC-LDPC decoder which can alleviate variability and noise caused by
iris acquisition and follow-up process. Several classes of QC-LDPC code from
IEEE 802.16 are tested for the validity of accuracy improvement. Some of the
codes mentioned above are used for further QC-LDPC decoder quantization,
validation and comparison to each other. We show that we can apply Dynamic
Partial Reconfiguration technology to implement the multi-mode QC-LDPC decoder
for the iris recognition system. The results show that the implementation is
power-efficient and good for edge applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty-Aware Camera Pose Estimation from Points and Lines. (arXiv:2107.03890v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vakhitov_A/0/1/0/all/0/1">Alexander Vakhitov</a>, <a href="http://arxiv.org/find/cs/1/au:+Colomina_L/0/1/0/all/0/1">Luis Ferraz Colomina</a>, <a href="http://arxiv.org/find/cs/1/au:+Agudo_A/0/1/0/all/0/1">Antonio Agudo</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_Noguer_F/0/1/0/all/0/1">Francesc Moreno-Noguer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03890">
                                    <div class="article-summary-box-inner">
                                        <span>Perspective-n-Point-and-Line (P$n$PL) algorithms aim at fast, accurate, and
robust camera localization with respect to a 3D model from 2D-3D feature
correspondences, being a major part of modern robotic and AR/VR systems.
Current point-based pose estimation methods use only 2D feature detection
uncertainties, and the line-based methods do not take uncertainties into
account. In our setup, both 3D coordinates and 2D projections of the features
are considered uncertain. We propose PnP(L) solvers based on EPnP and DLS for
the uncertainty-aware pose estimation. We also modify motion-only bundle
adjustment to take 3D uncertainties into account. We perform exhaustive
synthetic and real experiments on two different visual odometry datasets. The
new PnP(L) methods outperform the state-of-the-art on real data in isolation,
showing an increase in mean translation accuracy by 18% on a representative
subset of KITTI, while the new uncertain refinement improves pose accuracy for
most of the solvers, e.g. decreasing mean translation error for the EPnP by 16%
compared to the standard refinement on the same dataset. The code is available
at https://alexandervakhitov.github.io/uncertain-pnp/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grid Partitioned Attention: Efficient TransformerApproximation with Inductive Bias for High Resolution Detail Generation. (arXiv:2107.03742v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jetchev_N/0/1/0/all/0/1">Nikolay Jetchev</a>, <a href="http://arxiv.org/find/cs/1/au:+Yildirim_G/0/1/0/all/0/1">G&#xf6;khan Yildirim</a>, <a href="http://arxiv.org/find/cs/1/au:+Bracher_C/0/1/0/all/0/1">Christian Bracher</a>, <a href="http://arxiv.org/find/cs/1/au:+Vollgraf_R/0/1/0/all/0/1">Roland Vollgraf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03742">
                                    <div class="article-summary-box-inner">
                                        <span>Attention is a general reasoning mechanism than can flexibly deal with image
information, but its memory requirements had made it so far impractical for
high resolution image generation. We present Grid Partitioned Attention (GPA),
a new approximate attention algorithm that leverages a sparse inductive bias
for higher computational and memory efficiency in image domains: queries attend
only to few keys, spatially close queries attend to close keys due to
correlations. Our paper introduces the new attention layer, analyzes its
complexity and how the trade-off between memory usage and model power can be
tuned by the hyper-parameters.We will show how such attention enables novel
deep learning architectures with copying modules that are especially useful for
conditional image generation tasks like pose morphing. Our contributions are
(i) algorithm and code1of the novel GPA layer, (ii) a novel deep
attention-copying architecture, and (iii) new state-of-the art experimental
results in human pose morphing generation benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adiabatic Quantum Graph Matching with Permutation Matrix Constraints. (arXiv:2107.04032v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Benkner_M/0/1/0/all/0/1">Marcel Seelbach Benkner</a>, <a href="http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1">Vladislav Golyanik</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Moeller_M/0/1/0/all/0/1">Michael Moeller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04032">
                                    <div class="article-summary-box-inner">
                                        <span>Matching problems on 3D shapes and images are challenging as they are
frequently formulated as combinatorial quadratic assignment problems (QAPs)
with permutation matrix constraints, which are NP-hard. In this work, we
address such problems with emerging quantum computing technology and propose
several reformulations of QAPs as unconstrained problems suitable for efficient
execution on quantum hardware. We investigate several ways to inject
permutation matrix constraints in a quadratic unconstrained binary optimization
problem which can be mapped to quantum hardware. We focus on obtaining a
sufficient spectral gap, which further increases the probability to measure
optimal solutions and valid permutation matrices in a single run. We perform
our experiments on the quantum computer D-Wave 2000Q (2^11 qubits, adiabatic).
Despite the observed discrepancy between simulated adiabatic quantum computing
and execution on real quantum hardware, our reformulation of permutation matrix
constraints increases the robustness of the numerical computations over other
penalty approaches in our experiments. The proposed algorithm has the potential
to scale to higher dimensions on future quantum computing architectures, which
opens up multiple new directions for solving matching problems in 3D computer
vision and graphics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">4D Attention: Comprehensive Framework for Spatio-Temporal Gaze Mapping. (arXiv:2107.03606v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oishi_S/0/1/0/all/0/1">Shuji Oishi</a>, <a href="http://arxiv.org/find/cs/1/au:+Koide_K/0/1/0/all/0/1">Kenji Koide</a>, <a href="http://arxiv.org/find/cs/1/au:+Yokozuka_M/0/1/0/all/0/1">Masashi Yokozuka</a>, <a href="http://arxiv.org/find/cs/1/au:+Banno_A/0/1/0/all/0/1">Atsuhiko Banno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03606">
                                    <div class="article-summary-box-inner">
                                        <span>This study presents a framework for capturing human attention in the
spatio-temporal domain using eye-tracking glasses. Attention mapping is a key
technology for human perceptual activity analysis or Human-Robot Interaction
(HRI) to support human visual cognition; however, measuring human attention in
dynamic environments is challenging owing to the difficulty in localizing the
subject and dealing with moving objects. To address this, we present a
comprehensive framework, 4D Attention, for unified gaze mapping onto static and
dynamic objects. Specifically, we estimate the glasses pose by leveraging a
loose coupling of direct visual localization and Inertial Measurement Unit
(IMU) values. Further, by installing reconstruction components into our
framework, dynamic objects not captured in the 3D environment map are
instantiated based on the input images. Finally, a scene rendering component
synthesizes a first-person view with identification (ID) textures and performs
direct 2D-3D gaze association. Quantitative evaluations showed the
effectiveness of our framework. Additionally, we demonstrated the applications
of 4D Attention through experiments in real situations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AC-VRNN: Attentive Conditional-VRNN for Multi-Future Trajectory Prediction. (arXiv:2005.08307v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bertugli_A/0/1/0/all/0/1">Alessia Bertugli</a>, <a href="http://arxiv.org/find/cs/1/au:+Calderara_S/0/1/0/all/0/1">Simone Calderara</a>, <a href="http://arxiv.org/find/cs/1/au:+Coscia_P/0/1/0/all/0/1">Pasquale Coscia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballan_L/0/1/0/all/0/1">Lamberto Ballan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1">Rita Cucchiara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.08307">
                                    <div class="article-summary-box-inner">
                                        <span>Anticipating human motion in crowded scenarios is essential for developing
intelligent transportation systems, social-aware robots and advanced video
surveillance applications. A key component of this task is represented by the
inherently multi-modal nature of human paths which makes socially acceptable
multiple futures when human interactions are involved. To this end, we propose
a generative architecture for multi-future trajectory predictions based on
Conditional Variational Recurrent Neural Networks (C-VRNNs). Conditioning
mainly relies on prior belief maps, representing most likely moving directions
and forcing the model to consider past observed dynamics in generating future
positions. Human interactions are modeled with a graph-based attention
mechanism enabling an online attentive hidden state refinement of the recurrent
estimation. To corroborate our model, we perform extensive experiments on
publicly-available datasets (e.g., ETH/UCY, Stanford Drone Dataset, STATS
SportVU NBA, Intersection Drone Dataset and TrajNet++) and demonstrate its
effectiveness in crowded scenes compared to several state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Resolution Susceptibility of Face Recognition Models. (arXiv:2107.03769v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Knoche_M/0/1/0/all/0/1">Martin Knoche</a>, <a href="http://arxiv.org/find/cs/1/au:+Hormann_S/0/1/0/all/0/1">Stefan H&#xf6;rmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1">Gerhard Rigoll</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03769">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition approaches often rely on equal image resolution for
verification faces on two images. However, in practical applications, those
image resolutions are usually not in the same range due to different image
capture mechanisms or sources. In this work, we first analyze the impact of
image resolutions on the face verification performance with a state-of-the-art
face recognition model. For images, synthetically reduced to $5\, \times 5\,
\mathrm{px}$ resolution, the verification performance drops from $99.23\%$
increasingly down to almost $55\%$. Especially, for cross-resolution image
pairs (one high- and one low-resolution image), the verification accuracy
decreases even further. We investigate this behavior more in-depth by looking
at the feature distances for every 2-image test pair. To tackle this problem,
we propose the following two methods: 1) Train a state-of-the-art
face-recognition model straightforward with $50\%$ low-resolution images
directly within each batch. \\ 2) Train a siamese-network structure and adding
a cosine distance feature loss between high- and low-resolution features. Both
methods show an improvement for cross-resolution scenarios and can increase the
accuracy at very low resolution to approximately $70\%$. However, a
disadvantage is that a specific model needs to be trained for every
resolution-pair ...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Atlas-Based Segmentation of Intracochlear Anatomy in Metal Artifact Affected CT Images of the Ear with Co-trained Deep Neural Networks. (arXiv:2107.03987v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jianing Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Su_D/0/1/0/all/0/1">Dingjie Su</a>, <a href="http://arxiv.org/find/eess/1/au:+Fan_Y/0/1/0/all/0/1">Yubo Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+Chakravorti_S/0/1/0/all/0/1">Srijata Chakravorti</a>, <a href="http://arxiv.org/find/eess/1/au:+Noble_J/0/1/0/all/0/1">Jack H. Noble</a>, <a href="http://arxiv.org/find/eess/1/au:+Dawant_B/0/1/0/all/0/1">Be-noit M. Dawant</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03987">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an atlas-based method to segment the intracochlear anatomy (ICA)
in the post-implantation CT (Post-CT) images of cochlear implant (CI)
recipients that preserves the point-to-point correspondence between the meshes
in the atlas and the segmented volumes. To solve this problem, which is
challenging because of the strong artifacts produced by the implant, we use a
pair of co-trained deep networks that generate dense deformation fields (DDFs)
in opposite directions. One network is tasked with registering an atlas image
to the Post-CT images and the other network is tasked with registering the
Post-CT images to the atlas image. The networks are trained using loss
functions based on voxel-wise labels, image content, fiducial registration
error, and cycle-consistency constraint. The segmentation of the ICA in the
Post-CT images is subsequently obtained by transferring the predefined
segmentation meshes of the ICA in the atlas image to the Post-CT images using
the corresponding DDFs generated by the trained registration networks. Our
model can learn the underlying geometric features of the ICA even though they
are obscured by the metal artifacts. We show that our end-to-end network
produces results that are comparable to the current state of the art (SOTA)
that relies on a two-steps approach that first uses conditional generative
adversarial networks to synthesize artifact-free images from the Post-CT images
and then uses an active shape model-based method to segment the ICA in the
synthetic images. Our method requires a fraction of the time needed by the
SOTA, which is important for end-user acceptance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label-set Loss Functions for Partial Supervision: Application to Fetal Brain 3D MRI Parcellation. (arXiv:2107.03846v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fidon_L/0/1/0/all/0/1">Lucas Fidon</a>, <a href="http://arxiv.org/find/eess/1/au:+Aertsen_M/0/1/0/all/0/1">Michael Aertsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Emam_D/0/1/0/all/0/1">Doaa Emam</a>, <a href="http://arxiv.org/find/eess/1/au:+Mufti_N/0/1/0/all/0/1">Nada Mufti</a>, <a href="http://arxiv.org/find/eess/1/au:+Guffens_F/0/1/0/all/0/1">Frederic Guffens</a>, <a href="http://arxiv.org/find/eess/1/au:+Deprest_T/0/1/0/all/0/1">Thomas Deprest</a>, <a href="http://arxiv.org/find/eess/1/au:+Demaerel_P/0/1/0/all/0/1">Philippe Demaerel</a>, <a href="http://arxiv.org/find/eess/1/au:+David_A/0/1/0/all/0/1">Anna L. David</a>, <a href="http://arxiv.org/find/eess/1/au:+Melbourne_A/0/1/0/all/0/1">Andrew Melbourne</a>, <a href="http://arxiv.org/find/eess/1/au:+Ourselin_S/0/1/0/all/0/1">Sebastien Ourselin</a>, <a href="http://arxiv.org/find/eess/1/au:+Deprest_J/0/1/0/all/0/1">Jam Deprest</a>, <a href="http://arxiv.org/find/eess/1/au:+Vercauteren_T/0/1/0/all/0/1">Tom Vercauteren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03846">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have increased the accuracy of automatic segmentation,
however, their accuracy depends on the availability of a large number of fully
segmented images. Methods to train deep neural networks using images for which
some, but not all, regions of interest are segmented are necessary to make
better use of partially annotated datasets. In this paper, we propose the first
axiomatic definition of label-set loss functions that are the loss functions
that can handle partially segmented images. We prove that there is one and only
one method to convert a classical loss function for fully segmented images into
a proper label-set loss function. Our theory also allows us to define the
leaf-Dice loss, a label-set generalization of the Dice loss particularly suited
for partial supervision with only missing labels. Using the leaf-Dice loss, we
set a new state of the art in partially supervised learning for fetal brain 3D
MRI segmentation. We achieve a deep neural network able to segment white
matter, ventricles, cerebellum, extra-ventricular CSF, cortical gray matter,
deep gray matter, brainstem, and corpus callosum based on fetal brain 3D MRI of
anatomically normal fetuses or with open spina bifida. Our implementation of
the proposed label-set loss functions is available at
https://github.com/LucasFidon/label-set-loss-functions</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ACAE-REMIND for Online Continual Learning with Compressed Feature Replay. (arXiv:2105.08595v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Herranz_L/0/1/0/all/0/1">Luis Herranz</a>, <a href="http://arxiv.org/find/cs/1/au:+Weijer_J/0/1/0/all/0/1">Joost van de Weijer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08595">
                                    <div class="article-summary-box-inner">
                                        <span>Online continual learning aims to learn from a non-IID stream of data from a
number of different tasks, where the learner is only allowed to consider data
once. Methods are typically allowed to use a limited buffer to store some of
the images in the stream. Recently, it was found that feature replay, where an
intermediate layer representation of the image is stored (or generated) leads
to superior results than image replay, while requiring less memory. Quantized
exemplars can further reduce the memory usage. However, a drawback of these
methods is that they use a fixed (or very intransigent) backbone network. This
significantly limits the learning of representations that can discriminate
between all tasks. To address this problem, we propose an auxiliary classifier
auto-encoder (ACAE) module for feature replay at intermediate layers with high
compression rates. The reduced memory footprint per image allows us to save
more exemplars for replay. In our experiments, we conduct task-agnostic
evaluation under online continual learning setting and get state-of-the-art
performance on ImageNet-Subset, CIFAR100 and CIFAR10 dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relation-Based Associative Joint Location for Human Pose Estimation in Videos. (arXiv:2107.03591v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dang_Y/0/1/0/all/0/1">Yonghao Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Jianqin Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03591">
                                    <div class="article-summary-box-inner">
                                        <span>Video-based human pose estimation (HPE) is a vital yet challenging task.
While deep learning methods have made significant progress for the HPE, most
approaches to this task detect each joint independently, damaging the pose
structural information. In this paper, unlike the prior methods, we propose a
Relation-based Pose Semantics Transfer Network (RPSTN) to locate joints
associatively. Specifically, we design a lightweight joint relation extractor
(JRE) to model the pose structural features and associatively generate heatmaps
for joints by modeling the relation between any two joints heuristically
instead of building each joint heatmap independently. Actually, the proposed
JRE module models the spatial configuration of human poses through the
relationship between any two joints. Moreover, considering the temporal
semantic continuity of videos, the pose semantic information in the current
frame is beneficial for guiding the location of joints in the next frame.
Therefore, we use the idea of knowledge reuse to propagate the pose semantic
information between consecutive frames. In this way, the proposed RPSTN
captures temporal dynamics of poses. On the one hand, the JRE module can infer
invisible joints according to the relationship between the invisible joints and
other visible joints in space. On the other hand, in the time, the propose
model can transfer the pose semantic features from the non-occluded frame to
the occluded frame to locate occluded joints. Therefore, our method is robust
to the occlusion and achieves state-of-the-art results on the two challenging
datasets, which demonstrates its effectiveness for video-based human pose
estimation. We will release the code and models publicly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tensor Methods in Computer Vision and Deep Learning. (arXiv:2107.03436v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Panagakis_Y/0/1/0/all/0/1">Yannis Panagakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1">Jean Kossaifi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1">Grigorios G. Chrysos</a>, <a href="http://arxiv.org/find/cs/1/au:+Oldfield_J/0/1/0/all/0/1">James Oldfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Nicolaou_M/0/1/0/all/0/1">Mihalis A. Nicolaou</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1">Stefanos Zafeiriou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03436">
                                    <div class="article-summary-box-inner">
                                        <span>Tensors, or multidimensional arrays, are data structures that can naturally
represent visual data of multiple dimensions. Inherently able to efficiently
capture structured, latent semantic spaces and high-order interactions, tensors
have a long history of applications in a wide span of computer vision problems.
With the advent of the deep learning paradigm shift in computer vision, tensors
have become even more fundamental. Indeed, essential ingredients in modern deep
learning architectures, such as convolutions and attention mechanisms, can
readily be considered as tensor mappings. In effect, tensor methods are
increasingly finding significant applications in deep learning, including the
design of memory and compute efficient network architectures, improving
robustness to random noise and adversarial attacks, and aiding the theoretical
understanding of deep networks.

This article provides an in-depth and practical review of tensors and tensor
methods in the context of representation learning and deep learning, with a
particular focus on visual data analysis and computer vision applications.
Concretely, besides fundamental work in tensor-based visual data analysis
methods, we focus on recent developments that have brought on a gradual
increase of tensor methods, especially in deep learning architectures, and
their implications in computer vision applications. To further enable the
newcomer to grasp such concepts quickly, we provide companion Python notebooks,
covering key aspects of the paper and implementing them, step-by-step with
TensorLy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Complete Scanning Application Using OpenCv. (arXiv:2107.03700v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gangal_A/0/1/0/all/0/1">Ayushe Gangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Peeyush Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumari_S/0/1/0/all/0/1">Sunita Kumari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03700">
                                    <div class="article-summary-box-inner">
                                        <span>In the following paper, we have combined the various basic functionalities
provided by the NumPy library and OpenCv library, which is an open source for
Computer Vision applications, like conversion of colored images to grayscale,
calculating threshold, finding contours and using those contour points to take
perspective transform of the image inputted by the user, using Python version
3.7. Additional features include cropping, rotating and saving as well. All
these functions and features, when implemented step by step, results in a
complete scanning application. The applied procedure involves the following
steps: Finding contours, applying Perspective transform and brightening the
image, Adaptive Thresholding and applying filters for noise cancellation, and
Rotation features and perspective transform for a special cropping algorithm.
The described technique is implemented on various samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Pyramid Network for Multi-task Affective Analysis. (arXiv:2107.03670v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1">Ruian He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_Z/0/1/0/all/0/1">Zhen Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1">Bo Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03670">
                                    <div class="article-summary-box-inner">
                                        <span>Affective Analysis is not a single task, and the valence-arousal value,
expression class and action unit can be predicted at the same time. Previous
researches failed to take them as a whole task or ignore the entanglement and
hierarchical relation of this three facial attributes. We propose a novel model
named feature pyramid networks for multi-task affect analysis. The hierarchical
features are extracted to predict three labels and we apply teacher-student
training strategy to learn from pretrained single-task models. Extensive
experiment results demonstrate the proposed model outperform other models. The
code and model are available for research purposes at
$\href{https://github.com/ryanhe312/ABAW2-FPNMAA}{\text{this link}}$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EEG-ConvTransformer for Single-Trial EEG based Visual Stimuli Classification. (arXiv:2107.03983v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bagchi_S/0/1/0/all/0/1">Subhranil Bagchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bathula_D/0/1/0/all/0/1">Deepti R. Bathula</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03983">
                                    <div class="article-summary-box-inner">
                                        <span>Different categories of visual stimuli activate different responses in the
human brain. These signals can be captured with EEG for utilization in
applications such as Brain-Computer Interface (BCI). However, accurate
classification of single-trial data is challenging due to low signal-to-noise
ratio of EEG. This work introduces an EEG-ConvTranformer network that is based
on multi-headed self-attention. Unlike other transformers, the model
incorporates self-attention to capture inter-region interactions. It further
extends to adjunct convolutional filters with multi-head attention as a single
module to learn temporal patterns. Experimental results demonstrate that
EEG-ConvTransformer achieves improved classification accuracy over the
state-of-the-art techniques across five different visual stimuli classification
tasks. Finally, quantitative analysis of inter-head diversity also shows low
similarity in representational subspaces, emphasizing the implicit diversity of
multi-head attention.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">$S^3$: Sign-Sparse-Shift Reparametrization for Effective Training of Low-bit Shift Networks. (arXiv:2107.03453v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yaoliang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wulong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nia_V/0/1/0/all/0/1">Vahid Partovi Nia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03453">
                                    <div class="article-summary-box-inner">
                                        <span>Shift neural networks reduce computation complexity by removing expensive
multiplication operations and quantizing continuous weights into low-bit
discrete values, which are fast and energy efficient compared to conventional
neural networks. However, existing shift networks are sensitive to the weight
initialization, and also yield a degraded performance caused by vanishing
gradient and weight sign freezing problem. To address these issues, we propose
S low-bit re-parameterization, a novel technique for training low-bit shift
networks. Our method decomposes a discrete parameter in a sign-sparse-shift
3-fold manner. In this way, it efficiently learns a low-bit network with a
weight dynamics similar to full-precision networks and insensitive to weight
initialization. Our proposed training method pushes the boundaries of shift
neural networks and shows 3-bit shift networks out-performs their
full-precision counterparts in terms of top-1 accuracy on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SCSS-Net: Superpoint Constrained Semi-supervised Segmentation Network for 3D Indoor Scenes. (arXiv:2107.03601v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shuang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1">Qiulei Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03601">
                                    <div class="article-summary-box-inner">
                                        <span>Many existing deep neural networks (DNNs) for 3D point cloud semantic
segmentation require a large amount of fully labeled training data. However,
manually assigning point-level labels on the complex scenes is time-consuming.
While unlabeled point clouds can be easily obtained from sensors or
reconstruction, we propose a superpoint constrained semi-supervised
segmentation network for 3D point clouds, named as SCSS-Net. Specifically, we
use the pseudo labels predicted from unlabeled point clouds for self-training,
and the superpoints produced by geometry-based and color-based Region Growing
algorithms are combined to modify and delete pseudo labels with low confidence.
Additionally, we propose an edge prediction module to constrain the features
from edge points of geometry and color. A superpoint feature aggregation module
and superpoint feature consistency loss functions are introduced to smooth the
point features in each superpoint. Extensive experimental results on two 3D
public indoor datasets demonstrate that our method can achieve better
performance than some state-of-the-art point cloud segmentation networks and
some popular semi-supervised segmentation methods with few labeled scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An audiovisual and contextual approach for categorical and continuous emotion recognition in-the-wild. (arXiv:2107.03465v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antoniadis_P/0/1/0/all/0/1">Panagiotis Antoniadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Pikoulis_I/0/1/0/all/0/1">Ioannis Pikoulis</a>, <a href="http://arxiv.org/find/cs/1/au:+Filntisis_P/0/1/0/all/0/1">Panagiotis P. Filntisis</a>, <a href="http://arxiv.org/find/cs/1/au:+Maragos_P/0/1/0/all/0/1">Petros Maragos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03465">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we tackle the task of video-based audio-visual emotion
recognition, within the premises of the 2nd Workshop and Competition on
Affective Behavior Analysis in-the-wild (ABAW). Standard methodologies that
rely solely on the extraction of facial features often fall short of accurate
emotion prediction in cases where the aforementioned source of affective
information is inaccessible due to head/body orientation, low resolution and
poor illumination. We aspire to alleviate this problem by leveraging bodily as
well as contextual features, as part of a broader emotion recognition
framework. A standard CNN-RNN cascade constitutes the backbone of our proposed
model for sequence-to-sequence (seq2seq) learning. Apart from learning through
the \textit{RGB} input modality, we construct an aural stream which operates on
sequences of extracted mel-spectrograms. Our extensive experiments on the
challenging and newly assembled Affect-in-the-wild-2 (Aff-Wild2) dataset verify
the superiority of our methods over existing approaches, while by properly
incorporating all of the aforementioned modules in a network ensemble, we
manage to surpass the previous best published recognition scores, in the
official validation set. All the code was implemented using
PyTorch\footnote{\url{https://pytorch.org/}} and is publicly
available\footnote{\url{https://github.com/PanosAntoniadis/NTUA-ABAW2021}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking of Pedestrian Attribute Recognition: A Reliable Evaluation under Zero-Shot Pedestrian Identity Setting. (arXiv:2107.03576v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jian Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Houjing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaotang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaiqi Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03576">
                                    <div class="article-summary-box-inner">
                                        <span>Pedestrian attribute recognition aims to assign multiple attributes to one
pedestrian image captured by a video surveillance camera. Although numerous
methods are proposed and make tremendous progress, we argue that it is time to
step back and analyze the status quo of the area. We review and rethink the
recent progress from three perspectives. First, given that there is no explicit
and complete definition of pedestrian attribute recognition, we formally define
and distinguish pedestrian attribute recognition from other similar tasks.
Second, based on the proposed definition, we expose the limitations of the
existing datasets, which violate the academic norm and are inconsistent with
the essential requirement of practical industry application. Thus, we propose
two datasets, PETA\textsubscript{$ZS$} and RAP\textsubscript{$ZS$}, constructed
following the zero-shot settings on pedestrian identity. In addition, we also
introduce several realistic criteria for future pedestrian attribute dataset
construction. Finally, we reimplement existing state-of-the-art methods and
introduce a strong baseline method to give reliable evaluations and fair
comparisons. Experiments are conducted on four existing datasets and two
proposed datasets to measure progress on pedestrian attribute recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A hybrid deep learning framework for Covid-19 detection via 3D Chest CT Images. (arXiv:2107.03904v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Liang_S/0/1/0/all/0/1">Shuang Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03904">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a hybrid deep learning framework named CTNet which
combines convolutional neural network and transformer together for the
detection of COVID-19 via 3D chest CT images. It consists of a CNN feature
extractor module with SE attention to extract sufficient features from CT
scans, together with a transformer model to model the discriminative features
of the 3D CT scans. Compared to previous works, CTNet provides an effective and
efficient method to perform COVID-19 diagnosis via 3D CT scans with data
resampling strategy. Advanced results on a large and public benchmarks,
COV19-CT-DB database was achieved by the proposed CTNet, over the
state-of-the-art baseline approachproposed together with the dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal affect prediction model using a facial image sequence. (arXiv:2107.03886v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oh_G/0/1/0/all/0/1">Geesung Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_E/0/1/0/all/0/1">Euiseok Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Sejoon Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03886">
                                    <div class="article-summary-box-inner">
                                        <span>Among human affective behavior research, facial expression recognition
research is improving in performance along with the development of deep
learning. However, for improved performance, not only past images but also
future images should be used along with corresponding facial images, but there
are obstacles to the application of this technique to real-time environments.
In this paper, we propose the causal affect prediction network (CAPNet), which
uses only past facial images to predict corresponding affective valence and
arousal. We train CAPNet to learn causal inference between past images and
corresponding affective valence and arousal through supervised learning by
pairing the sequence of past images with the current label using the Aff-Wild2
dataset. We show through experiments that the well-trained CAPNet outperforms
the baseline of the second challenge of the Affective Behavior Analysis
in-the-wild (ABAW2) Competition by predicting affective valence and arousal
only with past facial images one-third of a second earlier. Therefore, in
real-time application, CAPNet can reliably predict affective valence and
arousal only with past data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GPNAS: A Neural Network Architecture Search Framework Based on Graphical Predictor. (arXiv:2103.11820v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ai_D/0/1/0/all/0/1">Dige Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11820">
                                    <div class="article-summary-box-inner">
                                        <span>In practice, the problems encountered in Neural Architecture Search (NAS)
training are not simple problems, but often a series of difficult combinations
(wrong compensation estimation, curse of dimension, overfitting, high
complexity, etc.). In this paper, we propose a framework to decouple network
structure from operator search space, and use two BOHBs to search
alternatively. Considering that activation function and initialization are also
important parts of neural network, the generalization ability of the model will
be affected. We introduce an activation function and an initialization method
domain, and add them into the operator search space to form a generalized
search space, so as to improve the generalization ability of the child model.
We then trained a GCN-based predictor using feedback from the child model. This
can not only improve the search efficiency, but also solve the problem of
dimension curse. Next, unlike other NAS studies, we used predictors to analyze
the stability of different network structures. Finally, we applied our
framework to neural structure search and achieved significant improvements on
multiple datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modality Task Cascade for 3D Object Detection. (arXiv:2107.04013v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jinhyung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_X/0/1/0/all/0/1">Xinshuo Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Man_Y/0/1/0/all/0/1">Yunze Man</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1">Kris Kitani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04013">
                                    <div class="article-summary-box-inner">
                                        <span>Point clouds and RGB images are naturally complementary modalities for 3D
visual understanding - the former provides sparse but accurate locations of
points on objects, while the latter contains dense color and texture
information. Despite this potential for close sensor fusion, many methods train
two models in isolation and use simple feature concatenation to represent 3D
sensor data. This separated training scheme results in potentially sub-optimal
performance and prevents 3D tasks from being used to benefit 2D tasks that are
often useful on their own. To provide a more integrated approach, we propose a
novel Multi-Modality Task Cascade network (MTC-RCNN) that leverages 3D box
proposals to improve 2D segmentation predictions, which are then used to
further refine the 3D boxes. We show that including a 2D network between two
stages of 3D modules significantly improves both 2D and 3D task performance.
Moreover, to prevent the 3D module from over-relying on the overfitted 2D
predictions, we propose a dual-head 2D segmentation training and inference
scheme, allowing the 2nd 3D module to learn to interpret imperfect 2D
segmentation predictions. Evaluating our model on the challenging SUN RGB-D
dataset, we improve upon state-of-the-art results of both single modality and
fusion networks by a large margin ($\textbf{+3.8}$ mAP@0.5). Code will be
released $\href{https://github.com/Divadi/MTC_RCNN}{\text{here.}}$</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Semantic Hallucination for Domain Generalized Semantic Segmentation. (arXiv:2106.04144v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tjio_G/0/1/0/all/0/1">Gabriel Tjio</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Ping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Joey Tianyi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Goh_R/0/1/0/all/0/1">Rick Siow Mong Goh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04144">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks may perform poorly when the test and train data
are from different domains. While this problem can be mitigated by using the
target domain data to align the source and target domain feature
representations, the target domain data may be unavailable due to privacy
concerns. Consequently, there is a need for methods that generalize well
without access to target domain data during training. In this work, we propose
an adversarial hallucination approach, which combines a class-wise
hallucination module and a semantic segmentation module. Since the segmentation
performance varies across different classes, we design a semantic-conditioned
style hallucination layer to adaptively stylize each class. The classwise
stylization parameters are generated from the semantic knowledge in the
segmentation probability maps of the source domain image. Both modules compete
adversarially, with the hallucination module generating increasingly
&#x27;difficult&#x27; style images to challenge the segmentation module. In response, the
segmentation module improves its performance as it is trained with generated
samples at an appropriate class-wise difficulty level. Experiments on state of
the art domain adaptation work demonstrate the efficacy of our proposed method
when no target domain data are available for training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural Architecture Search. (arXiv:2107.03463v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marvasti_Zadeh_S/0/1/0/all/0/1">Seyed Mojtaba Marvasti-Zadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Khaghani_J/0/1/0/all/0/1">Javad Khaghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Li Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanei_Yakhdan_H/0/1/0/all/0/1">Hossein Ghanei-Yakhdan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasaei_S/0/1/0/all/0/1">Shohreh Kasaei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03463">
                                    <div class="article-summary-box-inner">
                                        <span>A strong visual object tracker nowadays relies on its well-crafted modules,
which typically consist of manually-designed network architectures to deliver
high-quality tracking results. Not surprisingly, the manual design process
becomes a particularly challenging barrier, as it demands sufficient prior
experience, enormous effort, intuition and perhaps some good luck. Meanwhile,
neural architecture search has gaining grounds in practical applications such
as image segmentation, as a promising method in tackling the issue of automated
search of feasible network structures. In this work, we propose a novel
cell-level differentiable architecture search mechanism to automate the network
design of the tracking module, aiming to adapt backbone features to the
objective of a tracking network during offline training. The proposed approach
is simple, efficient, and with no need to stack a series of modules to
construct a network. Our approach is easy to be incorporated into existing
trackers, which is empirically validated using different differentiable
architecture search-based methods and tracking objectives. Extensive
experimental evaluations demonstrate the superior performance of our approach
over five commonly-used benchmarks. Meanwhile, our automated searching process
takes 41 (18) hours for the second (first) order DARTS method on the
TrackingNet dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Motion Correction and Super Resolution for Cardiac Segmentation via Latent Optimisation. (arXiv:2107.03887v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Shuo Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Qin_C/0/1/0/all/0/1">Chen Qin</a>, <a href="http://arxiv.org/find/eess/1/au:+Savioli_N/0/1/0/all/0/1">Nicolo Savioli</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+ORegan_D/0/1/0/all/0/1">Declan O&#x27;Regan</a>, <a href="http://arxiv.org/find/eess/1/au:+Cook_S/0/1/0/all/0/1">Stuart Cook</a>, <a href="http://arxiv.org/find/eess/1/au:+Guo_Y/0/1/0/all/0/1">Yike Guo</a>, <a href="http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Bai_W/0/1/0/all/0/1">Wenjia Bai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03887">
                                    <div class="article-summary-box-inner">
                                        <span>In cardiac magnetic resonance (CMR) imaging, a 3D high-resolution
segmentation of the heart is essential for detailed description of its
anatomical structures. However, due to the limit of acquisition duration and
respiratory/cardiac motion, stacks of multi-slice 2D images are acquired in
clinical routine. The segmentation of these images provides a low-resolution
representation of cardiac anatomy, which may contain artefacts caused by
motion. Here we propose a novel latent optimisation framework that jointly
performs motion correction and super resolution for cardiac image
segmentations. Given a low-resolution segmentation as input, the framework
accounts for inter-slice motion in cardiac MR imaging and super-resolves the
input into a high-resolution segmentation consistent with input. A multi-view
loss is incorporated to leverage information from both short-axis view and
long-axis view of cardiac imaging. To solve the inverse problem, iterative
optimisation is performed in a latent space, which ensures the anatomical
plausibility. This alleviates the need of paired low-resolution and
high-resolution images for supervised learning. Experiments on two cardiac MR
datasets show that the proposed framework achieves high performance, comparable
to state-of-the-art super-resolution approaches and with better cross-domain
generalisability and anatomical plausibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Temporal Contrastive Learning of Video Transformers. (arXiv:2106.09212v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertasius_G/0/1/0/all/0/1">Gedas Bertasius</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_D/0/1/0/all/0/1">Du Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Torresani_L/0/1/0/all/0/1">Lorenzo Torresani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09212">
                                    <div class="article-summary-box-inner">
                                        <span>Video transformers have recently emerged as a competitive alternative to 3D
CNNs for video understanding. However, due to their large number of parameters
and reduced inductive biases, these models require supervised pretraining on
large-scale image datasets to achieve top performance. In this paper, we
empirically demonstrate that self-supervised pretraining of video transformers
on video-only datasets can lead to action recognition results that are on par
or better than those obtained with supervised pretraining on large-scale image
datasets, even massive ones such as ImageNet-21K. Since transformer-based
models are effective at capturing dependencies over extended temporal spans, we
propose a simple learning procedure that forces the model to match a long-term
view to a short-term view of the same video. Our approach, named Long-Short
Temporal Contrastive Learning (LSTCL), enables video transformers to learn an
effective clip-level representation by predicting temporal context captured
from a longer temporal extent. To demonstrate the generality of our findings,
we implement and validate our approach under three different self-supervised
contrastive learning frameworks (MoCo v3, BYOL, SimSiam) using two distinct
video-transformer architectures, including an improved variant of the Swin
Transformer augmented with space-time attention. We conduct a thorough ablation
study and show that LSTCL achieves competitive performance on multiple video
benchmarks and represents a convincing alternative to supervised image-based
pretraining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs. (arXiv:2107.03815v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yikang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhao Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03815">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a Collaboration of Experts (CoE) framework to pool
together the expertise of multiple networks towards a common aim. Each expert
is an individual network with expertise on a unique portion of the dataset,
which enhances the collective capacity. Given a sample, an expert is selected
by the delegator, which simultaneously outputs a rough prediction to support
early termination. To fulfill this framework, we propose three modules to impel
each model to play its role, namely weight generation module (WGM), label
generation module (LGM) and variance calculation module (VCM). Our method
achieves the state-of-the-art performance on ImageNet, 80.7% top-1 accuracy
with 194M FLOPs. Combined with PWLU activation function and CondConv, CoE
further achieves the accuracy of 80.0% with only 100M FLOPs for the first time.
More importantly, our method is hardware friendly and achieves a 3-6x speedup
compared with some existing conditional computation approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prior Aided Streaming Network for Multi-task Affective Recognitionat the 2nd ABAW2 Competition. (arXiv:2107.03708v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zunhu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Keyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lincheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhimeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yu Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03708">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic affective recognition has been an important research topic in human
computer interaction (HCI) area. With recent development of deep learning
techniques and large scale in-the-wild annotated datasets, the facial emotion
analysis is now aimed at challenges in the real world settings. In this paper,
we introduce our submission to the 2nd Affective Behavior Analysis in-the-wild
(ABAW2) Competition. In dealing with different emotion representations,
including Categorical Emotions (CE), Action Units (AU), and Valence Arousal
(VA), we propose a multi-task streaming network by a heuristic that the three
representations are intrinsically associated with each other. Besides, we
leverage an advanced facial expression embedding as prior knowledge, which is
capable of capturing identity-invariant expression features while preserving
the expression similarities, to aid the down-streaming recognition tasks. The
extensive quantitative evaluations as well as ablation studies on the Aff-Wild2
dataset prove the effectiveness of our proposed prior aided streaming network
approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Object Behavioral Feature Extraction for Potential Risk Analysis based on Video Sensor. (arXiv:2107.03554v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Noh_B/0/1/0/all/0/1">Byeongjoon Noh</a>, <a href="http://arxiv.org/find/cs/1/au:+Noh_W/0/1/0/all/0/1">Wonjun Noh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">David Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_H/0/1/0/all/0/1">Hwasoo Yeo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03554">
                                    <div class="article-summary-box-inner">
                                        <span>Pedestrians are exposed to risk of death or serious injuries on roads,
especially unsignalized crosswalks, for a variety of reasons. To date, an
extensive variety of studies have reported on vision based traffic safety
system. However, many studies required manual inspection of the volumes of
traffic video to reliably obtain traffic related objects behavioral factors. In
this paper, we propose an automated and simpler system for effectively
extracting object behavioral features from video sensors deployed on the road.
We conduct basic statistical analysis on these features, and show how they can
be useful for monitoring the traffic behavior on the road. We confirm the
feasibility of the proposed system by applying our prototype to two
unsignalized crosswalks in Osan city, South Korea. To conclude, we compare
behaviors of vehicles and pedestrians in those two areas by simple statistical
analysis. This study demonstrates the potential for a network of connected
video sensors to provide actionable data for smart cities to improve pedestrian
safety in dangerous road environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Malware Classification Using Deep Boosted Learning. (arXiv:2107.04008v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asam_M/0/1/0/all/0/1">Muhammad Asam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Saddam Hussain Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamal_T/0/1/0/all/0/1">Tauseef Jamal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zahoora_U/0/1/0/all/0/1">Umme Zahoora</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Asifullah Khan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04008">
                                    <div class="article-summary-box-inner">
                                        <span>Malicious activities in cyberspace have gone further than simply hacking
machines and spreading viruses. It has become a challenge for a nations
survival and hence has evolved to cyber warfare. Malware is a key component of
cyber-crime, and its analysis is the first line of defence against attack. This
work proposes a novel deep boosted hybrid learning-based malware classification
framework and named as Deep boosted Feature Space-based Malware classification
(DFS-MC). In the proposed framework, the discrimination power is enhanced by
fusing the feature spaces of the best performing customized CNN architectures
models and its discrimination by an SVM for classification. The discrimination
capacity of the proposed classification framework is assessed by comparing it
against the standard customized CNNs. The customized CNN models are implemented
in two ways: softmax classifier and deep hybrid learning-based malware
classification. In the hybrid learning, Deep features are extracted from
customized CNN architectures and fed into the conventional machine learning
classifier to improve the classification performance. We also introduced the
concept of transfer learning in a customized CNN architecture based malware
classification framework through fine-tuning. The performance of the proposed
malware classification approaches are validated on the MalImg malware dataset
using the hold-out cross-validation technique. Experimental comparisons were
conducted by employing innovative, customized CNN, trained from scratch and
fine-tuning the customized CNN using transfer learning. The proposed
classification framework DFS-MC showed improved results, Accuracy: 98.61%,
F-score: 0.96, Precision: 0.96, and Recall: 0.96.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty-aware Human Motion Prediction. (arXiv:2107.03575v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1">Pengxiang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1">Jianqin Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03575">
                                    <div class="article-summary-box-inner">
                                        <span>Human motion prediction is essential for tasks such as human motion analysis
and human-robot interactions. Most existing approaches have been proposed to
realize motion prediction. However, they ignore an important task, the
evaluation of the quality of the predicted result. It is far more enough for
current approaches in actual scenarios because people can&#x27;t know how to
interact with the machine without the evaluation of prediction, and unreliable
predictions may mislead the machine to harm the human. Hence, we propose an
uncertainty-aware framework for human motion prediction (UA-HMP). Concretely,
we first design an uncertainty-aware predictor through Gaussian modeling to
achieve the value and the uncertainty of predicted motion. Then, an
uncertainty-guided learning scheme is proposed to quantitate the uncertainty
and reduce the negative effect of the noisy samples during optimization for
better performance. Our proposed framework is easily combined with current SOTA
baselines to overcome their weakness in uncertainty modeling with slight
parameters increment. Extensive experiments also show that they can achieve
better performance in both short and long-term predictions in H3.6M, CMU-Mocap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crowd Counting via Perspective-Guided Fractional-Dilation Convolution. (arXiv:2107.03665v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhaoyi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruimao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongzhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingfu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1">Wangmeng Zuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03665">
                                    <div class="article-summary-box-inner">
                                        <span>Crowd counting is critical for numerous video surveillance scenarios. One of
the main issues in this task is how to handle the dramatic scale variations of
pedestrians caused by the perspective effect. To address this issue, this paper
proposes a novel convolution neural network-based crowd counting method, termed
Perspective-guided Fractional-Dilation Network (PFDNet). By modeling the
continuous scale variations, the proposed PFDNet is able to select the proper
fractional dilation kernels for adapting to different spatial locations. It
significantly improves the flexibility of the state-of-the-arts that only
consider the discrete representative scales. In addition, by avoiding the
multi-scale or multi-column architecture that used in other methods, it is
computationally more efficient. In practice, the proposed PFDNet is constructed
by stacking multiple Perspective-guided Fractional-Dilation Convolutions (PFC)
on a VGG16-BN backbone. By introducing a novel generalized dilation convolution
operation, the PFC can handle fractional dilation ratios in the spatial domain
under the guidance of perspective annotations, achieving continuous scales
modeling of pedestrians. To deal with the problem of unavailable perspective
information in some cases, we further introduce an effective perspective
estimation branch to the proposed PFDNet, which can be trained in either
supervised or weakly-supervised setting once the branch has been pre-trained.
Extensive experiments show that the proposed PFDNet outperforms
state-of-the-art methods on ShanghaiTech A, ShanghaiTech B, WorldExpo&#x27;10,
UCF-QNRF, UCF_CC_50 and TRANCOS dataset, achieving MAE 53.8, 6.5, 6.8, 84.3,
205.8, and 3.06 respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Elastic deformation of optical coherence tomography images of diabetic macular edema for deep-learning models training: how far to go?. (arXiv:2107.03651v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bar_David_D/0/1/0/all/0/1">Daniel Bar-David</a>, <a href="http://arxiv.org/find/eess/1/au:+Bar_David_L/0/1/0/all/0/1">Laura Bar-David</a>, <a href="http://arxiv.org/find/eess/1/au:+Shapira_Y/0/1/0/all/0/1">Yinon Shapira</a>, <a href="http://arxiv.org/find/eess/1/au:+Leibu_R/0/1/0/all/0/1">Rina Leibu</a>, <a href="http://arxiv.org/find/eess/1/au:+Dori_D/0/1/0/all/0/1">Dalia Dori</a>, <a href="http://arxiv.org/find/eess/1/au:+Schneor_R/0/1/0/all/0/1">Ronit Schneor</a>, <a href="http://arxiv.org/find/eess/1/au:+Fischer_A/0/1/0/all/0/1">Anath Fischer</a>, <a href="http://arxiv.org/find/eess/1/au:+Soudry_S/0/1/0/all/0/1">Shiri Soudry</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03651">
                                    <div class="article-summary-box-inner">
                                        <span>To explore the clinical validity of elastic deformation of optical coherence
tomography (OCT) images for data augmentation in the development of
deep-learning model for detection of diabetic macular edema (DME).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Use of Affective Visual Information for Summarization of Human-Centric Videos. (arXiv:2107.03783v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kopru_B/0/1/0/all/0/1">Berkay K&#xf6;pr&#xfc;</a>, <a href="http://arxiv.org/find/cs/1/au:+Erzin_E/0/1/0/all/0/1">Engin Erzin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03783">
                                    <div class="article-summary-box-inner">
                                        <span>Increasing volume of user-generated human-centric video content and their
applications, such as video retrieval and browsing, require compact
representations that are addressed by the video summarization literature.
Current supervised studies formulate video summarization as a
sequence-to-sequence learning problem and the existing solutions often neglect
the surge of human-centric view, which inherently contains affective content.
In this study, we investigate the affective-information enriched supervised
video summarization task for human-centric videos. First, we train a visual
input-driven state-of-the-art continuous emotion recognition model (CER-NET) on
the RECOLA dataset to estimate emotional attributes. Then, we integrate the
estimated emotional attributes and the high-level representations from the
CER-NET with the visual information to define the proposed affective video
summarization architectures (AVSUM). In addition, we investigate the use of
attention to improve the AVSUM architectures and propose two new architectures
based on temporal attention (TA-AVSUM) and spatial attention (SA-AVSUM). We
conduct video summarization experiments on the TvSum database. The proposed
AVSUM-GRU architecture with an early fusion of high level GRU embeddings and
the temporal attention based TA-AVSUM architecture attain competitive video
summarization performances by bringing strong performance improvements for the
human-centric videos compared to the state-of-the-art in terms of F-score and
self-defined face recall metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Defending Against Multiple and Unforeseen Adversarial Videos. (arXiv:2009.05244v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1">Shao-Yuan Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05244">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial robustness of deep neural networks has been actively
investigated. However, most existing defense approaches are limited to a
specific type of adversarial perturbations. Specifically, they often fail to
offer resistance to multiple attack types simultaneously, i.e., they lack
multi-perturbation robustness. Furthermore, compared to image recognition
problems, the adversarial robustness of video recognition models is relatively
unexplored. While several studies have proposed how to generate adversarial
videos, only a handful of approaches about the defense strategies have been
published in the literature. In this paper, we propose one of the first defense
strategies against multiple types of adversarial videos for video recognition.
The proposed method, referred to as MultiBN, performs adversarial training on
multiple adversarial video types using multiple independent batch normalization
(BN) layers with a learning-based BN selection module. With a multiple BN
structure, each BN brach is responsible for learning the distribution of a
single perturbation type and thus provides more precise distribution
estimations. This mechanism benefits dealing with multiple perturbation types.
The BN selection module detects the attack type of an input video and sends it
to the corresponding BN branch, making MultiBN fully automatic and allow
end-to-end training. Compared to present adversarial training approaches, the
proposed MultiBN exhibits stronger multi-perturbation robustness against
different and even unforeseen adversarial video types, ranging from Lp-bounded
attacks and physically realizable attacks. This holds true on different
datasets and target models. Moreover, we conduct an extensive analysis to study
the properties of the multiple BN structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instance-Level Relative Saliency Ranking with Graph Reasoning. (arXiv:2107.03824v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1">Nian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Long Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wangbo Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Junwei Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03824">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional salient object detection models cannot differentiate the
importance of different salient objects. Recently, two works have been proposed
to detect saliency ranking by assigning different degrees of saliency to
different objects. However, one of these models cannot differentiate object
instances and the other focuses more on sequential attention shift order
inference. In this paper, we investigate a practical problem setting that
requires simultaneously segment salient instances and infer their relative
saliency rank order. We present a novel unified model as the first end-to-end
solution, where an improved Mask R-CNN is first used to segment salient
instances and a saliency ranking branch is then added to infer the relative
saliency. For relative saliency ranking, we build a new graph reasoning module
by combining four graphs to incorporate the instance interaction relation,
local contrast, global contrast, and a high-level semantic prior, respectively.
A novel loss function is also proposed to effectively train the saliency
ranking branch. Besides, a new dataset and an evaluation metric are proposed
for this task, aiming at pushing forward this field of research. Finally,
experimental results demonstrate that our proposed model is more effective than
previous methods. We also show an example of its practical usage on adaptive
image retargeting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Staying in Shape: Learning Invariant Shape Representations using Contrastive Learning. (arXiv:2107.03552v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jeffrey Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeung_S/0/1/0/all/0/1">Serena Yeung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03552">
                                    <div class="article-summary-box-inner">
                                        <span>Creating representations of shapes that are invari-ant to isometric or
almost-isometric transforma-tions has long been an area of interest in shape
anal-ysis, since enforcing invariance allows the learningof more effective and
robust shape representations.Most existing invariant shape representations
arehandcrafted, and previous work on learning shaperepresentations do not focus
on producing invariantrepresentations. To solve the problem of
learningunsupervised invariant shape representations, weuse contrastive
learning, which produces discrimi-native representations through learning
invarianceto user-specified data augmentations. To producerepresentations that
are specifically isometry andalmost-isometry invariant, we propose new
dataaugmentations that randomly sample these transfor-mations. We show
experimentally that our methodoutperforms previous unsupervised learning
ap-proaches in both effectiveness and robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification of Urban Morphology with Deep Learning: Application on Urban Vitality. (arXiv:2105.09908v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wangyang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1">Abraham Noah Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Biljecki_F/0/1/0/all/0/1">Filip Biljecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09908">
                                    <div class="article-summary-box-inner">
                                        <span>There is a prevailing trend to study urban morphology quantitatively thanks
to the growing accessibility to various forms of spatial big data, increasing
computing power, and use cases benefiting from such information. The methods
developed up to now measure urban morphology with numerical indices describing
density, proportion, and mixture, but they do not directly represent
morphological features from the human&#x27;s visual and intuitive perspective. We
take the first step to bridge the gap by proposing a deep learning-based
technique to automatically classify road networks into four classes on a visual
basis. The method is implemented by generating an image of the street network
(Colored Road Hierarchy Diagram), which we introduce in this paper, and
classifying it using a deep convolutional neural network (ResNet-34). The model
achieves an overall classification accuracy of 0.875. Nine cities around the
world are selected as the study areas with their road networks acquired from
OpenStreetMap. Latent subgroups among the cities are uncovered through
clustering on the percentage of each road network category. In the subsequent
part of the paper, we focus on the usability of such classification: we apply
our method in a case study of urban vitality prediction. An advanced tree-based
regression model (LightGBM) is for the first time designated to establish the
relationship between morphological indices and vitality indicators. The effect
of road network classification is found to be small but positively associated
with urban vitality. This work expands the toolkit of quantitative urban
morphology study with new techniques, supporting further studies in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RMA: Rapid Motor Adaptation for Legged Robots. (arXiv:2107.04034v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Ashish Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zipeng Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1">Deepak Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1">Jitendra Malik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04034">
                                    <div class="article-summary-box-inner">
                                        <span>Successful real-world deployment of legged robots would require them to adapt
in real-time to unseen scenarios like changing terrains, changing payloads,
wear and tear. This paper presents Rapid Motor Adaptation (RMA) algorithm to
solve this problem of real-time online adaptation in quadruped robots. RMA
consists of two components: a base policy and an adaptation module. The
combination of these components enables the robot to adapt to novel situations
in fractions of a second. RMA is trained completely in simulation without using
any domain knowledge like reference trajectories or predefined foot trajectory
generators and is deployed on the A1 robot without any fine-tuning. We train
RMA on a varied terrain generator using bioenergetics-inspired rewards and
deploy it on a variety of difficult terrains including rocky, slippery,
deformable surfaces in environments with grass, long vegetation, concrete,
pebbles, stairs, sand, etc. RMA shows state-of-the-art performance across
diverse real-world as well as simulation experiments. Video results at
https://ashish-kmr.github.io/rma-legged-robots/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weight Reparametrization for Budget-Aware Network Pruning. (arXiv:2107.03909v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dupont_R/0/1/0/all/0/1">Robin Dupont</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahbi_H/0/1/0/all/0/1">Hichem Sahbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Michel_G/0/1/0/all/0/1">Guillaume Michel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03909">
                                    <div class="article-summary-box-inner">
                                        <span>Pruning seeks to design lightweight architectures by removing redundant
weights in overparameterized networks. Most of the existing techniques first
remove structured sub-networks (filters, channels,...) and then fine-tune the
resulting networks to maintain a high accuracy. However, removing a whole
structure is a strong topological prior and recovering the accuracy, with
fine-tuning, is highly cumbersome. In this paper, we introduce an &quot;end-to-end&quot;
lightweight network design that achieves training and pruning simultaneously
without fine-tuning. The design principle of our method relies on
reparametrization that learns not only the weights but also the topological
structure of the lightweight sub-network. This reparametrization acts as a
prior (or regularizer) that defines pruning masks implicitly from the weights
of the underlying network, without increasing the number of training
parameters. Sparsity is induced with a budget loss that provides an accurate
pruning. Extensive experiments conducted on the CIFAR10 and the TinyImageNet
datasets, using standard architectures (namely Conv4, VGG19 and ResNet18), show
compelling results without fine-tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Data Processing in Space for Object Detection in Satellite Imagery. (arXiv:2107.03774v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lofqvist_M/0/1/0/all/0/1">Martina Lofqvist</a>, <a href="http://arxiv.org/find/cs/1/au:+Cano_J/0/1/0/all/0/1">Jos&#xe9; Cano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03774">
                                    <div class="article-summary-box-inner">
                                        <span>There is a proliferation in the number of satellites launched each year,
resulting in downlinking of terabytes of data each day. The data received by
ground stations is often unprocessed, making this an expensive process
considering the large data sizes and that not all of the data is useful. This,
coupled with the increasing demand for real-time data processing, has led to a
growing need for on-orbit processing solutions. In this work, we investigate
the performance of CNN-based object detectors on constrained devices by
applying different image compression techniques to satellite data. We examine
the capabilities of the NVIDIA Jetson Nano and NVIDIA Jetson AGX Xavier;
low-power, high-performance computers, with integrated GPUs, small enough to
fit on-board a nanosatellite. We take a closer look at object detection
networks, including the Single Shot MultiBox Detector (SSD) and Region-based
Fully Convolutional Network (R-FCN) models that are pre-trained on DOTA - a
Large Scale Dataset for Object Detection in Aerial Images. The performance is
measured in terms of execution time, memory consumption, and accuracy, and are
compared against a baseline containing a server with two powerful GPUs. The
results show that by applying image compression techniques, we are able to
improve the execution time and memory consumption, achieving a fully runnable
dataset. A lossless compression technique achieves roughly a 10% reduction in
execution time and about a 3% reduction in memory consumption, with no impact
on the accuracy. While a lossy compression technique improves the execution
time by up to 144% and the memory consumption is reduced by as much as 97%.
However, it has a significant impact on accuracy, varying depending on the
compression ratio. Thus the application and ratio of these compression
techniques may differ depending on the required level of accuracy for a
particular task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparing ML based Segmentation Models on Jet Fire Radiation Zone. (arXiv:2107.03461v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perez_Guerrero_C/0/1/0/all/0/1">Carmina P&#xe9;rez-Guerrero</a>, <a href="http://arxiv.org/find/cs/1/au:+Palacios_A/0/1/0/all/0/1">Adriana Palacios</a>, <a href="http://arxiv.org/find/cs/1/au:+Ochoa_Ruiz_G/0/1/0/all/0/1">Gilberto Ochoa-Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Mata_C/0/1/0/all/0/1">Christian Mata</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Mendoza_M/0/1/0/all/0/1">Miguel Gonzalez-Mendoza</a>, <a href="http://arxiv.org/find/cs/1/au:+Falcon_Morales_L/0/1/0/all/0/1">Luis Eduardo Falc&#xf3;n-Morales</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03461">
                                    <div class="article-summary-box-inner">
                                        <span>Risk assessment is relevant in any workplace, however there is a degree of
unpredictability when dealing with flammable or hazardous materials so that
detection of fire accidents by itself may not be enough. An example of this is
the impingement of jet fires, where the heat fluxes of the flame could reach
nearby equipment and dramatically increase the probability of a domino effect
with catastrophic results. Because of this, the characterization of such fire
accidents is important from a risk management point of view. One such
characterization would be the segmentation of different radiation zones within
the flame, so this paper presents an exploratory research regarding several
traditional computer vision and Deep Learning segmentation approaches to solve
this specific problem. A data set of propane jet fires is used to train and
evaluate the different approaches and given the difference in the distribution
of the zones and background of the images, different loss functions, that seek
to alleviate data imbalance, are also explored. Additionally, different metrics
are correlated to a manual ranking performed by experts to make an evaluation
that closely resembles the expert&#x27;s criteria. The Hausdorff Distance and
Adjsted Random Index were the metrics with the highest correlation and the best
results were obtained from the UNet architecture with a Weighted Cross-Entropy
Loss. These results can be used in future research to extract more geometric
information from the segmentation masks or could even be implemented on other
types of fire accidents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigate the Essence of Long-Tailed Recognition from a Unified Perspective. (arXiv:2107.03758v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Li Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03758">
                                    <div class="article-summary-box-inner">
                                        <span>As the data scale grows, deep recognition models often suffer from
long-tailed data distributions due to the heavy imbalanced sample number across
categories. Indeed, real-world data usually exhibit some similarity relation
among different categories (e.g., pigeons and sparrows), called category
similarity in this work. It is doubly difficult when the imbalance occurs
between such categories with similar appearances. However, existing solutions
mainly focus on the sample number to re-balance data distribution. In this
work, we systematically investigate the essence of the long-tailed problem from
a unified perspective. Specifically, we demonstrate that long-tailed
recognition suffers from both sample number and category similarity.
Intuitively, using a toy example, we first show that sample number is not the
unique influence factor for performance dropping of long-tailed recognition.
Theoretically, we demonstrate that (1) category similarity, as an inevitable
factor, would also influence the model learning under long-tailed distribution
via similar samples, (2) using more discriminative representation methods
(e.g., self-supervised learning) for similarity reduction, the classifier bias
can be further alleviated with greatly improved performance. Extensive
experiments on several long-tailed datasets verify the rationality of our
theoretical analysis, and show that based on existing state-of-the-arts
(SOTAs), the performance could be further improved by similarity reduction. Our
investigations highlight the essence behind the long-tailed problem, and claim
several feasible directions for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NccFlow: Unsupervised Learning of Optical Flow With Non-occlusion from Geometry. (arXiv:2107.03610v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guangming Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Shuaiqi Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hesheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03610">
                                    <div class="article-summary-box-inner">
                                        <span>Optical flow estimation is a fundamental problem of computer vision and has
many applications in the fields of robot learning and autonomous driving. This
paper reveals novel geometric laws of optical flow based on the insight and
detailed definition of non-occlusion. Then, two novel loss functions are
proposed for the unsupervised learning of optical flow based on the geometric
laws of non-occlusion. Specifically, after the occlusion part of the images are
masked, the flowing process of pixels is carefully considered and geometric
constraints are conducted based on the geometric laws of optical flow. First,
neighboring pixels in the first frame will not intersect during the pixel
displacement to the second frame. Secondly, when the cluster containing
adjacent four pixels in the first frame moves to the second frame, no other
pixels will flow into the quadrilateral formed by them. According to the two
geometrical constraints, the optical flow non-intersection loss and the optical
flow non-blocking loss in the non-occlusion regions are proposed. Two loss
functions punish the irregular and inexact optical flows in the non-occlusion
regions. The experiments on datasets demonstrated that the proposed
unsupervised losses of optical flow based on the geometric laws in
non-occlusion regions make the estimated optical flow more refined in detail,
and improve the performance of unsupervised learning of optical flow. In
addition, the experiments training on synthetic data and evaluating on real
data show that the generalization ability of optical flow network is improved
by our proposed unsupervised approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Transformer Generators with Convolutional Discriminators. (arXiv:2105.10189v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Durall_R/0/1/0/all/0/1">Ricard Durall</a>, <a href="http://arxiv.org/find/cs/1/au:+Frolov_S/0/1/0/all/0/1">Stanislav Frolov</a>, <a href="http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1">Andreas Dengel</a>, <a href="http://arxiv.org/find/cs/1/au:+Keuper_J/0/1/0/all/0/1">Janis Keuper</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10189">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer models have recently attracted much interest from computer vision
researchers and have since been successfully employed for several problems
traditionally addressed with convolutional neural networks. At the same time,
image synthesis using generative adversarial networks (GANs) has drastically
improved over the last few years. The recently proposed TransGAN is the first
GAN using only transformer-based architectures and achieves competitive results
when compared to convolutional GANs. However, since transformers are
data-hungry architectures, TransGAN requires data augmentation, an auxiliary
super-resolution task during training, and a masking prior to guide the
self-attention mechanism. In this paper, we study the combination of a
transformer-based generator and convolutional discriminator and successfully
remove the need of the aforementioned required design choices. We evaluate our
approach by conducting a benchmark of well-known CNN discriminators, ablate the
size of the transformer-based generator, and show that combining both
architectural elements into a hybrid model leads to better results.
Furthermore, we investigate the frequency spectrum properties of generated
images and observe that our model retains the benefits of an attention based
generator.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dataset and Method for Hallux Valgus Angle Estimation Based on Deep Learing. (arXiv:2107.03640v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1">Ningyuan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_J/0/1/0/all/0/1">Jiayan Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yaojun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_J/0/1/0/all/0/1">Jiangjian Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03640">
                                    <div class="article-summary-box-inner">
                                        <span>Angular measurements is essential to make a resonable treatment for Hallux
valgus (HV), a common forefoot deformity. However, it still depends on manual
labeling and measurement, which is time-consuming and sometimes unreliable.
Automating this process is a thing of concern. However, it lack of dataset and
the keypoints based method which made a great success in pose estimation is not
suitable for this field.To solve the problems, we made a dataset and developed
an algorithm based on deep learning and linear regression. It shows great
fitting ability to the ground truth.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-Consistency Semi-Supervised Learning with Uncertainty Quantification for COVID-19 Lesion Segmentation from CT Images. (arXiv:2104.03225v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yanwen Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_L/0/1/0/all/0/1">Luyang Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Lin_H/0/1/0/all/0/1">Huangjing Lin</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Heng_P/0/1/0/all/0/1">Pheng-Ann Heng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03225">
                                    <div class="article-summary-box-inner">
                                        <span>The novel coronavirus disease 2019 (COVID-19) characterized by atypical
pneumonia has caused millions of deaths worldwide. Automatically segmenting
lesions from chest Computed Tomography (CT) is a promising way to assist
doctors in COVID-19 screening, treatment planning, and follow-up monitoring.
However, voxel-wise annotations are extremely expert-demanding and scarce,
especially when it comes to novel diseases, while an abundance of unlabeled
data could be available. To tackle the challenge of limited annotations, in
this paper, we propose an uncertainty-guided dual-consistency learning network
(UDC-Net) for semi-supervised COVID-19 lesion segmentation from CT images.
Specifically, we present a dual-consistency learning scheme that simultaneously
imposes image transformation equivalence and feature perturbation invariance to
effectively harness the knowledge from unlabeled data. We then quantify the
segmentation uncertainty in two forms and employ them together to guide the
consistency regularization for more reliable unsupervised learning. Extensive
experiments showed that our proposed UDC-Net improves the fully supervised
method by 6.3% in Dice and outperforms other competitive semi-supervised
approaches by significant margins, demonstrating high potential in real-world
clinical practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LanguageRefer: Spatial-Language Model for 3D Visual Grounding. (arXiv:2107.03438v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roh_J/0/1/0/all/0/1">Junha Roh</a>, <a href="http://arxiv.org/find/cs/1/au:+Desingh_K/0/1/0/all/0/1">Karthik Desingh</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03438">
                                    <div class="article-summary-box-inner">
                                        <span>To realize robots that can understand human instructions and perform
meaningful tasks in the near future, it is important to develop learned models
that can understand referential language to identify common objects in
real-world 3D scenes. In this paper, we develop a spatial-language model for a
3D visual grounding problem. Specifically, given a reconstructed 3D scene in
the form of a point cloud with 3D bounding boxes of potential object
candidates, and a language utterance referring to a target object in the scene,
our model identifies the target object from a set of potential candidates. Our
spatial-language model uses a transformer-based architecture that combines
spatial embedding from bounding-box with a finetuned language embedding from
DistilBert and reasons among the objects in the 3D scene to find the target
object. We show that our model performs competitively on visio-linguistic
datasets proposed by ReferIt3D. We provide additional analysis of performance
in spatial reasoning tasks decoupled from perception noise, the effect of
view-dependent utterances in terms of accuracy, and view-point annotations for
potential robotics applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical Matting: A New Perspective on Medical Segmentation with Uncertainty. (arXiv:2106.09887v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ju_L/0/1/0/all/0/1">Lie Ju</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Donghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1">Wanji He</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yelin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhiwen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xuan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiufen Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1">Zongyuan Ge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.09887">
                                    <div class="article-summary-box-inner">
                                        <span>In medical image segmentation, it is difficult to mark ambiguous areas
accurately with binary masks, especially when dealing with small lesions.
Therefore, it is a challenge for radiologists to reach a consensus by using
binary masks under the condition of multiple annotations. However, these areas
may contain anatomical structures that are conducive to diagnosis. Uncertainty
is introduced to study these situations. Nevertheless, the uncertainty is
usually measured by the variances between predictions in a multiple trial way.
It is not intuitive, and there is no exact correspondence in the image.
Inspired by image matting, we introduce matting as a soft segmentation method
and a new perspective to deal with and represent uncertain regions into medical
scenes, namely medical matting. More specifically, because there is no
available medical matting dataset, we first labeled two medical datasets with
alpha matte. Secondly, the matting method applied to the natural image is not
suitable for the medical scene, so we propose a new architecture to generate
binary masks and alpha matte in a row. Thirdly, the uncertainty map is
introduced to highlight the ambiguous regions from the binary results and
improve the matting performance. Evaluated on these datasets, the proposed
model outperformed state-of-the-art matting algorithms by a large margin, and
alpha matte is proved to be a more efficient labeling form than a binary mask.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation of Field-Aware Neural Ranking Models for Recipe Search. (arXiv:2105.05710v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Takiguchi_K/0/1/0/all/0/1">Kentaro Takiguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fain_M/0/1/0/all/0/1">Mikhail Fain</a>, <a href="http://arxiv.org/find/cs/1/au:+Twomey_N/0/1/0/all/0/1">Niall Twomey</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaquero_L/0/1/0/all/0/1">Luis M Vaquero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05710">
                                    <div class="article-summary-box-inner">
                                        <span>Explicitly modelling field interactions and correlations in complex document
structures has recently gained popularity in neural document embedding and
retrieval tasks. Although this requires the specification of bespoke
task-dependent models, encouraging empirical results are beginning to emerge.
We present the first in-depth analyses of non-linear multi-field interaction
(NL-MFI) ranking in the cooking domain in this work. Our results show that
field-weighted factorisation machines models provide a statistically
significant improvement over baselines in recipe retrieval tasks. Additionally,
we show that sparsely capturing subsets of field interactions based on domain
knowledge and feature selection heuristics offers significant advantages over
baselines and exhaustive alternatives. Although field-interaction aware models
are more elaborate from an architectural basis, they are often more
data-efficient in optimisation and are better suited for explainability due to
mirrored document and model factorisation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Multi-Step Critiquing for VAE-based Recommender Systems. (arXiv:2105.00774v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antognini_D/0/1/0/all/0/1">Diego Antognini</a>, <a href="http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1">Boi Faltings</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00774">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies have shown that providing personalized explanations alongside
recommendations increases trust and perceived quality. Furthermore, it gives
users an opportunity to refine the recommendations by critiquing parts of the
explanations. On one hand, current recommender systems model the
recommendation, explanation, and critiquing objectives jointly, but this
creates an inherent trade-off between their respective performance. On the
other hand, although recent latent linear critiquing approaches are built upon
an existing recommender system, they suffer from computational inefficiency at
inference due to the objective optimized at each conversation&#x27;s turn. We
address these deficiencies with M&amp;Ms-VAE, a novel variational autoencoder for
recommendation and explanation that is based on multimodal modeling
assumptions. We train the model under a weak supervision scheme to simulate
both fully and partially observed variables. Then, we leverage the
generalization ability of a trained M&amp;Ms-VAE model to embed the user preference
and the critique separately. Our work&#x27;s most important innovation is our
critiquing module, which is built upon and trained in a self-supervised manner
with a simple ranking objective. Experiments on four real-world datasets
demonstrate that among state-of-the-art models, our system is the first to
dominate or match the performance in terms of recommendation, explanation, and
multi-step critiquing. Moreover, M&amp;Ms-VAE processes the critiques up to 25.6x
faster than the best baselines. Finally, we show that our model infers coherent
joint and cross generation, even under weak supervision, thanks to our
multimodal-based modeling and training scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WenLan: Bridging Vision and Language by Large-Scale Multi-Modal Pre-Training. (arXiv:2103.06561v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1">Yuqi Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Manli Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangzhen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haoyu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yizhao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guoxing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Jingyuan Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Heng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Baogui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Weihao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xi_Z/0/1/0/all/0/1">Zongzheng Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yueqian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_A/0/1/0/all/0/1">Anwen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jinming Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruichen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yida Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Liang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yuqing Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_X/0/1/0/all/0/1">Xin Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_W/0/1/0/all/0/1">Wanqing Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_D/0/1/0/all/0/1">Danyang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingyan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peiyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_Z/0/1/0/all/0/1">Zheng Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Chuhao Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuchong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shizhe Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhiwu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zhicheng Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1">Qin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yanyan Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1">Ruihua Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06561">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-modal pre-training models have been intensively explored to bridge
vision and language in recent years. However, most of them explicitly model the
cross-modal interaction between image-text pairs, by assuming that there exists
strong semantic correlation between the text and image modalities. Since this
strong assumption is often invalid in real-world scenarios, we choose to
implicitly model the cross-modal correlation for large-scale multi-modal
pre-training, which is the focus of the Chinese project &#x60;WenLan&#x27; led by our
team. Specifically, with the weak correlation assumption over image-text pairs,
we propose a two-tower pre-training model called BriVL within the cross-modal
contrastive learning framework. Unlike OpenAI CLIP that adopts a simple
contrastive learning method, we devise a more advanced algorithm by adapting
the latest method MoCo into the cross-modal scenario. By building a large
queue-based dictionary, our BriVL can incorporate more negative samples in
limited GPU resources. We further construct a large Chinese multi-source
image-text dataset called RUC-CAS-WenLan for pre-training our BriVL model.
Extensive experiments demonstrate that the pre-trained BriVL model outperforms
both UNITER and OpenAI CLIP on various downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized News Recommendation: A Survey. (arXiv:2106.08934v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chuhan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongfeng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xing Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08934">
                                    <div class="article-summary-box-inner">
                                        <span>Personalized news recommendation is an important technique to help users find
their interested news information and alleviate their information overload. It
has been extensively studied over decades and has achieved notable success in
improving users&#x27; news reading experience. However, there are still many
unsolved problems and challenges that need to be further studied. To help
researchers master the advances in personalized news recommendation over the
past years, in this paper we present a comprehensive overview of personalized
news recommendation. Instead of following the conventional taxonomy of news
recommendation methods, in this paper we propose a novel perspective to
understand personalized news recommendation based on its core problems and the
associated techniques and challenges. We first review the techniques for
tackling each core problem in a personalized news recommender system and the
challenges they face. Next, we introduce the public datasets and evaluation
methods for personalized news recommendation. We then discuss the key points on
improving the responsibility of personalized news recommender systems. Finally,
we raise several research directions that are worth investigating in the
future. This paper can provide up-to-date and comprehensive views to help
readers understand the personalized news recommendation field. We hope this
paper can facilitate research on personalized news recommendation and as well
as related fields in natural language processing and data mining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Graph-based Approach for Mitigating Multi-sided Exposure Bias in Recommender Systems. (arXiv:2107.03415v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mansoury_M/0/1/0/all/0/1">Masoud Mansoury</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdollahpouri_H/0/1/0/all/0/1">Himan Abdollahpouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Mobasher_B/0/1/0/all/0/1">Bamshad Mobasher</a>, <a href="http://arxiv.org/find/cs/1/au:+Burke_R/0/1/0/all/0/1">Robin Burke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03415">
                                    <div class="article-summary-box-inner">
                                        <span>Fairness is a critical system-level objective in recommender systems that has
been the subject of extensive recent research. A specific form of fairness is
supplier exposure fairness where the objective is to ensure equitable coverage
of items across all suppliers in recommendations provided to users. This is
especially important in multistakeholder recommendation scenarios where it may
be important to optimize utilities not just for the end-user, but also for
other stakeholders such as item sellers or producers who desire a fair
representation of their items. This type of supplier fairness is sometimes
accomplished by attempting to increasing aggregate diversity in order to
mitigate popularity bias and to improve the coverage of long-tail items in
recommendations. In this paper, we introduce FairMatch, a general graph-based
algorithm that works as a post processing approach after recommendation
generation to improve exposure fairness for items and suppliers. The algorithm
iteratively adds high quality items that have low visibility or items from
suppliers with low exposure to the users&#x27; final recommendation lists. A
comprehensive set of experiments on two datasets and comparison with
state-of-the-art baselines show that FairMatch, while significantly improves
exposure fairness and aggregate diversity, maintains an acceptable level of
relevance of the recommendations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rating and aspect-based opinion graph embeddings for explainable recommendations. (arXiv:2107.03385v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cantador_I/0/1/0/all/0/1">Iv&#xe1;n Cantador</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvallo_A/0/1/0/all/0/1">Andr&#xe9;s Carvallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Diez_F/0/1/0/all/0/1">Fernando Diez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03385">
                                    <div class="article-summary-box-inner">
                                        <span>The success of neural network embeddings has entailed a renewed interest in
using knowledge graphs for a wide variety of machine learning and information
retrieval tasks. In particular, recent recommendation methods based on graph
embeddings have shown state-of-the-art performance. In general, these methods
encode latent rating patterns and content features. Differently from previous
work, in this paper, we propose to exploit embeddings extracted from graphs
that combine information from ratings and aspect-based opinions expressed in
textual reviews. We then adapt and evaluate state-of-the-art graph embedding
techniques over graphs generated from Amazon and Yelp reviews on six domains,
outperforming baseline recommenders. Additionally, our method has the advantage
of providing explanations that involve the coverage of aspect-based opinions
given by users about recommended items.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Neural Pre-training for Enhancing Recommendations using Side Information. (arXiv:2107.03936v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_Z/0/1/0/all/0/1">Zaiqiao Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Macdonald_C/0/1/0/all/0/1">Craig Macdonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Ounis_I/0/1/0/all/0/1">Iadh Ounis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03936">
                                    <div class="article-summary-box-inner">
                                        <span>Leveraging the side information associated with entities (i.e.\ users and
items) to enhance the performance of recommendation systems has been widely
recognized as an important modelling dimension. While many existing approaches
focus on the \emph{integration scheme} to incorporate entity side information
-- by combining the recommendation loss function with an extra side
information-aware loss -- in this paper, we propose instead a novel
\emph{pre-training scheme} for leveraging the side information. In particular,
we first pre-train a representation model using the side information of the
entities, and then fine-tune it using an existing general representation-based
recommendation model. Specifically, we propose two pre-training models, named
\gcn{} and \com{}, by considering the entities and their relations constructed
from side information as two different types of graphs respectively, to
pre-train entity embeddings. For the \gcn{} model, two single-relational graphs
are constructed from all the users&#x27; and items&#x27; side information respectively,
to pre-train entity representations by using the Graph Convolutional Networks.
For the \com{} model, two multi-relational graphs are constructed to pre-train
the entity representations by using the Composition-based Graph Convolutional
Networks. An extensive evaluation of our pre-training models fine-tuned under
four general representation-based recommender models, i.e.\ MF, NCF, NGCF and
LightGCN, shows that effectively pre-training embeddings with both the user&#x27;s
and item&#x27;s side information can significantly improve these original models in
terms of both effectiveness and stability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Proxy Selection for Session-based Recommender Systems. (arXiv:2107.03564v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Junsu Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1">SeongKu Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hyun_D/0/1/0/all/0/1">Dongmin Hyun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hwanjo Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03564">
                                    <div class="article-summary-box-inner">
                                        <span>Session-based Recommender Systems (SRSs) have been actively developed to
recommend the next item of an anonymous short item sequence (i.e., session).
Unlike sequence-aware recommender systems where the whole interaction sequence
of each user can be used to model both the short-term interest and the general
interest of the user, the absence of user-dependent information in SRSs makes
it difficult to directly derive the user&#x27;s general interest from data.
Therefore, existing SRSs have focused on how to effectively model the
information about short-term interest within the sessions, but they are
insufficient to capture the general interest of users. To this end, we propose
a novel framework to overcome the limitation of SRSs, named ProxySR, which
imitates the missing information in SRSs (i.e., general interest of users) by
modeling proxies of sessions. ProxySR selects a proxy for the input session in
an unsupervised manner, and combines it with the encoded short-term interest of
the session. As a proxy is jointly learned with the short-term interest and
selected by multiple sessions, a proxy learns to play the role of the general
interest of a user and ProxySR learns how to select a suitable proxy for an
input session. Moreover, we propose another real-world situation of SRSs where
a few users are logged-in and leave their identifiers in sessions, and a
revision of ProxySR for the situation. Our experiments on real-world datasets
show that ProxySR considerably outperforms the state-of-the-art competitors,
and the proxies successfully imitate the general interest of the users without
any user-dependent information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Bangla Natural Language Processing Tasks and the Utility of Transformer Models. (arXiv:2107.03844v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1">Firoj Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Arid Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1">Tanvir Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Akib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tajrin_J/0/1/0/all/0/1">Janntatul Tajrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naira Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03844">
                                    <div class="article-summary-box-inner">
                                        <span>Bangla -- ranked as the 6th most widely spoken language across the world
(https://www.ethnologue.com/guides/ethnologue200), with 230 million native
speakers -- is still considered as a low-resource language in the natural
language processing (NLP) community. With three decades of research, Bangla NLP
(BNLP) is still lagging behind mainly due to the scarcity of resources and the
challenges that come with it. There is sparse work in different areas of BNLP;
however, a thorough survey reporting previous work and recent advances is yet
to be done. In this study, we first provide a review of Bangla NLP tasks,
resources, and tools available to the research community; we benchmark datasets
collected from various platforms for nine NLP tasks using current
state-of-the-art algorithms (i.e., transformer-based models). We provide
comparative results for the studied NLP tasks by comparing monolingual vs.
multilingual models of varying sizes. We report our results using both
individual and consolidated datasets and provide data splits for future
research. We reviewed a total of 108 papers and conducted 175 sets of
experiments. Our results show promising performance using transformer-based
models while highlighting the trade-off with computational costs. We hope that
such a comprehensive survey will motivate the community to build on and further
advance the research on Bangla NLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heterogeneous Global Graph Neural Networks for Personalized Session-based Recommendation. (arXiv:2107.03813v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_Y/0/1/0/all/0/1">Yitong Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Lingfei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Q/0/1/0/all/0/1">Qi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yiming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhihua Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Fangli Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ethan Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_B/0/1/0/all/0/1">Bo Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03813">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting the next interaction of a short-term interaction session is a
challenging task in session-based recommendation. Almost all existing works
rely on item transition patterns, and neglect the impact of user historical
sessions while modeling user preference, which often leads to non-personalized
recommendation. Additionally, existing personalized session-based recommenders
capture user preference only based on the sessions of the current user, but
ignore the useful item-transition patterns from other user&#x27;s historical
sessions. To address these issues, we propose a novel Heterogeneous Global
Graph Neural Networks (HG-GNN) to exploit the item transitions over all
sessions in a subtle manner for better inferring user preference from the
current and historical sessions. To effectively exploit the item transitions
over all sessions from users, we propose a novel heterogeneous global graph
that contains item transitions of sessions, user-item interactions and global
co-occurrence items. Moreover, to capture user preference from sessions
comprehensively, we propose to learn two levels of user representations from
the global graph via two graph augmented preference encoders. Specifically, we
design a novel heterogeneous graph neural network (HGNN) on the heterogeneous
global graph to learn the long-term user preference and item representations
with rich semantics. Based on the HGNN, we propose the Current Preference
Encoder and the Historical Preference Encoder to capture the different levels
of user preference from the current and historical sessions, respectively. To
achieve personalized recommendation, we integrate the representations of the
user current preference and historical interests to generate the final user
preference representation. Extensive experimental results on three real-world
datasets show that our model outperforms other state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Frequentist Consistency of Variational Bayes. (arXiv:1705.03439v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1">Yixin Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1">David M. Blei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1705.03439">
                                    <div class="article-summary-box-inner">
                                        <span>A key challenge for modern Bayesian statistics is how to perform scalable
inference of posterior distributions. To address this challenge, variational
Bayes (VB) methods have emerged as a popular alternative to the classical
Markov chain Monte Carlo (MCMC) methods. VB methods tend to be faster while
achieving comparable predictive performance. However, there are few theoretical
results around VB. In this paper, we establish frequentist consistency and
asymptotic normality of VB methods. Specifically, we connect VB methods to
point estimates based on variational approximations, called frequentist
variational approximations, and we use the connection to prove a variational
Bernstein-von Mises theorem. The theorem leverages the theoretical
characterizations of frequentist variational approximations to understand
asymptotic properties of VB. In summary, we prove that (1) the VB posterior
converges to the Kullback-Leibler (KL) minimizer of a normal distribution,
centered at the truth and (2) the corresponding variational expectation of the
parameter is consistent and asymptotically normal. As applications of the
theorem, we derive asymptotic properties of VB posteriors in Bayesian mixture
models, Bayesian generalized linear mixed models, and Bayesian stochastic block
models. We conduct a simulation study to illustrate these theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Limits of Unsupervised Domain Adaptation via Data Poisoning. (arXiv:2107.03919v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mehra_A/0/1/0/all/0/1">Akshay Mehra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1">Bhavya Kailkhura</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Pin-Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamm_J/0/1/0/all/0/1">Jihun Hamm</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03919">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) enables cross-domain learning without
target domain labels by transferring knowledge from a labeled source domain
whose distribution differs from the target. However, UDA is not always
successful and several accounts of &quot;negative transfer&quot; have been reported in
the literature. In this work, we prove a simple lower bound on the target
domain error that complements the existing upper bound. Our bound shows the
insufficiency of minimizing source domain error and marginal distribution
mismatch for a guaranteed reduction in the target domain error, due to the
possible increase of induced labeling function mismatch. This insufficiency is
further illustrated through simple distributions for which the same UDA
approach succeeds, fails, and may succeed or fail with an equal chance.
Motivated from this, we propose novel data poisoning attacks to fool UDA
methods into learning representations that produce large target domain errors.
We evaluate the effect of these attacks on popular UDA methods using benchmark
datasets where they have been previously shown to be successful. Our results
show that poisoning can significantly decrease the target domain accuracy,
dropping it to almost 0\% in some cases, with the addition of only 10\%
poisoned data in the source domain. The failure of UDA methods demonstrates the
limitations of UDA at guaranteeing cross-domain generalization consistent with
the lower bound. Thus, evaluation of UDA methods in adversarial settings such
as data poisoning can provide a better sense of their robustness in scenarios
unfavorable for UDA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparing Supervised Models And Learned Speech Representations For Classifying Intelligibility Of Disordered Speech On Selected Phrases. (arXiv:2107.03985v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Venugopalan_S/0/1/0/all/0/1">Subhashini Venugopalan</a>, <a href="http://arxiv.org/find/eess/1/au:+Shor_J/0/1/0/all/0/1">Joel Shor</a>, <a href="http://arxiv.org/find/eess/1/au:+Plakal_M/0/1/0/all/0/1">Manoj Plakal</a>, <a href="http://arxiv.org/find/eess/1/au:+Tobin_J/0/1/0/all/0/1">Jimmy Tobin</a>, <a href="http://arxiv.org/find/eess/1/au:+Tomanek_K/0/1/0/all/0/1">Katrin Tomanek</a>, <a href="http://arxiv.org/find/eess/1/au:+Green_J/0/1/0/all/0/1">Jordan R. Green</a>, <a href="http://arxiv.org/find/eess/1/au:+Brenner_M/0/1/0/all/0/1">Michael P. Brenner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03985">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic classification of disordered speech can provide an objective tool
for identifying the presence and severity of speech impairment. Classification
approaches can also help identify hard-to-recognize speech samples to teach ASR
systems about the variable manifestations of impaired speech. Here, we develop
and compare different deep learning techniques to classify the intelligibility
of disordered speech on selected phrases. We collected samples from a diverse
set of 661 speakers with a variety of self-reported disorders speaking 29 words
or phrases, which were rated by speech-language pathologists for their overall
intelligibility using a five-point Likert scale. We then evaluated classifiers
developed using 3 approaches: (1) a convolutional neural network (CNN) trained
for the task, (2) classifiers trained on non-semantic speech representations
from CNNs that used an unsupervised objective [1], and (3) classifiers trained
on the acoustic (encoder) embeddings from an ASR system trained on typical
speech [2]. We found that the ASR encoder&#x27;s embeddings considerably outperform
the other two on detecting and classifying disordered speech. Further analysis
shows that the ASR embeddings cluster speech by the spoken phrase, while the
non-semantic embeddings cluster speech by speaker. Also, longer phrases are
more indicative of intelligibility deficits than single words.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Neural Scene Representations for Visuomotor Control. (arXiv:2107.04004v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunzhu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1">Vincent Sitzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1">Pulkit Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1">Antonio Torralba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04004">
                                    <div class="article-summary-box-inner">
                                        <span>Humans have a strong intuitive understanding of the 3D environment around us.
The mental model of the physics in our brain applies to objects of different
materials and enables us to perform a wide range of manipulation tasks that are
far beyond the reach of current robots. In this work, we desire to learn models
for dynamic 3D scenes purely from 2D visual observations. Our model combines
Neural Radiance Fields (NeRF) and time contrastive learning with an
autoencoding framework, which learns viewpoint-invariant 3D-aware scene
representations. We show that a dynamics model, constructed over the learned
representation space, enables visuomotor control for challenging manipulation
tasks involving both rigid bodies and fluids, where the target is specified in
a viewpoint different from what the robot operates on. When coupled with an
auto-decoding framework, it can even support goal specification from camera
viewpoints that are outside the training distribution. We further demonstrate
the richness of the learned 3D dynamics model by performing future prediction
and novel view synthesis. Finally, we provide detailed ablation studies
regarding different system designs and qualitative analysis of the learned
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CamTuner: Reinforcement-Learning based System for Camera Parameter Tuning to enhance Analytics. (arXiv:2107.03964v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1">Sibendu Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_K/0/1/0/all/0/1">Kunal Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Coviello_G/0/1/0/all/0/1">Giuseppe Coviello</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankaradas_M/0/1/0/all/0/1">Murugan Sankaradas</a>, <a href="http://arxiv.org/find/cs/1/au:+Po_O/0/1/0/all/0/1">Oliver Po</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Y. Charlie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakradhar_S/0/1/0/all/0/1">Srimat T. Chakradhar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03964">
                                    <div class="article-summary-box-inner">
                                        <span>Complex sensors like video cameras include tens of configurable parameters,
which can be set by end-users to customize the sensors to specific application
scenarios. Although parameter settings significantly affect the quality of the
sensor output and the accuracy of insights derived from sensor data, most
end-users use a fixed parameter setting because they lack the skill or
understanding to appropriately configure these parameters. We propose CamTuner,
which is a system to automatically, and dynamically adapt the complex sensor to
changing environments. CamTuner includes two key components. First, a bespoke
analytics quality estimator, which is a deep-learning model to automatically
and continuously estimate the quality of insights from an analytics unit as the
environment around a sensor change. Second, a reinforcement learning (RL)
module, which reacts to the changes in quality, and automatically adjusts the
camera parameters to enhance the accuracy of insights. We improve the training
time of the RL module by an order of magnitude by designing virtual models to
mimic essential behavior of the camera: we design virtual knobs that can be set
to different values to mimic the effects of assigning different values to the
camera&#x27;s configurable parameters, and we design a virtual camera model that
mimics the output from a video camera at different times of the day. These
virtual models significantly accelerate training because (a) frame rates from a
real camera are limited to 25-30 fps while the virtual models enable processing
at 300 fps, (b) we do not have to wait until the real camera sees different
environments, which could take weeks or months, and (c) virtual knobs can be
updated instantly, while it can take 200-500 ms to change the camera parameter
settings. Our dynamic tuning approach results in up to 12% improvement in the
accuracy of insights from several video analytics tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold Hypothesis in Data Analysis: Double Geometrically-Probabilistic Approach to Manifold Dimension Estimation. (arXiv:2107.03903v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ivanov_A/0/1/0/all/0/1">Alexander Ivanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Nosovskiy_G/0/1/0/all/0/1">Gleb Nosovskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chekunov_A/0/1/0/all/0/1">Alexey Chekunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Fedoseev_D/0/1/0/all/0/1">Denis Fedoseev</a>, <a href="http://arxiv.org/find/cs/1/au:+Kibkalo_V/0/1/0/all/0/1">Vladislav Kibkalo</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikulin_M/0/1/0/all/0/1">Mikhail Nikulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Popelenskiy_F/0/1/0/all/0/1">Fedor Popelenskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Komkov_S/0/1/0/all/0/1">Stepan Komkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazurenko_I/0/1/0/all/0/1">Ivan Mazurenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Petiushko_A/0/1/0/all/0/1">Aleksandr Petiushko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03903">
                                    <div class="article-summary-box-inner">
                                        <span>Manifold hypothesis states that data points in high-dimensional space
actually lie in close vicinity of a manifold of much lower dimension. In many
cases this hypothesis was empirically verified and used to enhance unsupervised
and semi-supervised learning. Here we present new approach to manifold
hypothesis checking and underlying manifold dimension estimation. In order to
do it we use two very different methods simultaneously - one geometric, another
probabilistic - and check whether they give the same result. Our geometrical
method is a modification for sparse data of a well-known box-counting algorithm
for Minkowski dimension calculation. The probabilistic method is new. Although
it exploits standard nearest neighborhood distance, it is different from
methods which were previously used in such situations. This method is robust,
fast and includes special preliminary data transformation. Experiments on real
datasets show that the suggested approach based on two methods combination is
powerful and effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Vision-Guided Quadrupedal Locomotion End-to-End with Cross-Modal Transformers. (arXiv:2107.03996v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1">Ruihan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansen_N/0/1/0/all/0/1">Nicklas Hansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huazhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03996">
                                    <div class="article-summary-box-inner">
                                        <span>We propose to address quadrupedal locomotion tasks using Reinforcement
Learning (RL) with a Transformer-based model that learns to combine
proprioceptive information and high-dimensional depth sensor inputs. While
learning-based locomotion has made great advances using RL, most methods still
rely on domain randomization for training blind agents that generalize to
challenging terrains. Our key insight is that proprioceptive states only offer
contact measurements for immediate reaction, whereas an agent equipped with
visual sensory observations can learn to proactively maneuver environments with
obstacles and uneven terrain by anticipating changes in the environment many
steps ahead. In this paper, we introduce LocoTransformer, an end-to-end RL
method for quadrupedal locomotion that leverages a Transformer-based model for
fusing proprioceptive states and visual observations. We evaluate our method in
challenging simulated environments with different obstacles and uneven terrain.
We show that our method obtains significant improvements over policies with
only proprioceptive state inputs, and that Transformer-based models further
improve generalization across environments. Our project page with videos is at
https://RchalYang.github.io/LocoTransformer .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Patient Embeddings in Healthcare and Insurance Applications. (arXiv:2107.03913v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blinov_P/0/1/0/all/0/1">Pavel Blinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokh_V/0/1/0/all/0/1">Vladimir Kokh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03913">
                                    <div class="article-summary-box-inner">
                                        <span>The paper researches the problem of concept and patient representations in
the medical domain. We present the patient histories from Electronic Health
Records (EHRs) as temporal sequences of ICD concepts for which embeddings are
learned in an unsupervised setup with a transformer-based neural network model.
The model training was performed on the collection of one million patients&#x27;
histories in 6 years. The predictive power of such a model is assessed in
comparison with several baseline methods. A series of experiments on the
MIMIC-III data show the advantage of the presented model compared to a similar
system. Further, we analyze the obtained embedding space with regards to
concept relations and show how knowledge from the medical domain can be
successfully transferred to the practical task of insurance scoring in the form
of patient embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RMA: Rapid Motor Adaptation for Legged Robots. (arXiv:2107.04034v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Ashish Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zipeng Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1">Deepak Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1">Jitendra Malik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04034">
                                    <div class="article-summary-box-inner">
                                        <span>Successful real-world deployment of legged robots would require them to adapt
in real-time to unseen scenarios like changing terrains, changing payloads,
wear and tear. This paper presents Rapid Motor Adaptation (RMA) algorithm to
solve this problem of real-time online adaptation in quadruped robots. RMA
consists of two components: a base policy and an adaptation module. The
combination of these components enables the robot to adapt to novel situations
in fractions of a second. RMA is trained completely in simulation without using
any domain knowledge like reference trajectories or predefined foot trajectory
generators and is deployed on the A1 robot without any fine-tuning. We train
RMA on a varied terrain generator using bioenergetics-inspired rewards and
deploy it on a variety of difficult terrains including rocky, slippery,
deformable surfaces in environments with grass, long vegetation, concrete,
pebbles, stairs, sand, etc. RMA shows state-of-the-art performance across
diverse real-world as well as simulation experiments. Video results at
https://ashish-kmr.github.io/rma-legged-robots/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning for Multi-Center Imaging Diagnostics: A Study in Cardiovascular Disease. (arXiv:2107.03901v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Linardos_A/0/1/0/all/0/1">Akis Linardos</a>, <a href="http://arxiv.org/find/eess/1/au:+Kushibar_K/0/1/0/all/0/1">Kaisar Kushibar</a>, <a href="http://arxiv.org/find/eess/1/au:+Walsh_S/0/1/0/all/0/1">Sean Walsh</a>, <a href="http://arxiv.org/find/eess/1/au:+Gkontra_P/0/1/0/all/0/1">Polyxeni Gkontra</a>, <a href="http://arxiv.org/find/eess/1/au:+Lekadir_K/0/1/0/all/0/1">Karim Lekadir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03901">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models can enable accurate and efficient disease diagnosis, but
have thus far been hampered by the data scarcity present in the medical world.
Automated diagnosis studies have been constrained by underpowered single-center
datasets, and although some results have shown promise, their generalizability
to other institutions remains questionable as the data heterogeneity between
institutions is not taken into account. By allowing models to be trained in a
distributed manner that preserves patients&#x27; privacy, federated learning
promises to alleviate these issues, by enabling diligent multi-center studies.
We present the first federated learning study on the modality of cardiovascular
magnetic resonance (CMR) and use four centers derived from subsets of the M\&amp;M
and ACDC datasets, focusing on the diagnosis of hypertrophic cardiomyopathy
(HCM). We adapt a 3D-CNN network pretrained on action recognition and explore
two different ways of incorporating shape prior information to the model, and
four different data augmentation set-ups, systematically analyzing their impact
on the different collaborative learning choices. We show that despite the small
size of data (180 subjects derived from four centers), the privacy preserving
federated learning achieves promising results that are competitive with
traditional centralized learning. We further find that federatively trained
models exhibit increased robustness and are more sensitive to domain shift
effects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable AI (XAI) for PHM of Industrial Asset: A State-of-The-Art, PRISMA-Compliant Systematic Review. (arXiv:2107.03869v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+NOR_A/0/1/0/all/0/1">Ahmad Kamal BIN MOHD NOR</a>, <a href="http://arxiv.org/find/cs/1/au:+PEDAPATI_S/0/1/0/all/0/1">Srinivasa Rao PEDAPATI</a>, <a href="http://arxiv.org/find/cs/1/au:+MUHAMMAD_M/0/1/0/all/0/1">Masdi MUHAMMAD</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03869">
                                    <div class="article-summary-box-inner">
                                        <span>A state-of-the-art systematic review on XAI applied to Prognostic and Health
Management (PHM) of industrial asset is presented. The work attempts to provide
an overview of the general trend of XAI in PHM, answers the question of
accuracy versus explainability, investigates the extent of human role,
explainability evaluation and uncertainty management in PHM XAI. Research
articles linked to PHM XAI, in English language, from 2015 to 2021 are selected
from IEEE Xplore, ScienceDirect, SpringerLink, ACM Digital Library and Scopus
databases using PRISMA guidelines. Data was extracted from 35 selected articles
and examined using MS. Excel. Several findings were synthesized. Firstly, while
the discipline is still young, the analysis indicates the growing acceptance of
XAI in PHM domain. Secondly, XAI functions as a double edge sword, where it is
assimilated as a tool to execute PHM tasks as well as a mean of explanation, in
particular in diagnostic and anomaly detection. There is thus a need for XAI in
PHM. Thirdly, the review shows that PHM XAI papers produce either good or
excellent results in general, suggesting that PHM performance is unaffected by
XAI. Fourthly, human role, explainability metrics and uncertainty management
are areas requiring further attention by the PHM community. Adequate
explainability metrics to cater for PHM need are urgently needed. Finally, most
case study featured on the accepted articles are based on real, indicating that
available AI and XAI approaches are equipped to solve complex real-world
challenges, increasing the confidence of AI model adoption in the industry.
This work is funded by the Universiti Teknologi Petronas Foundation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessing putative bias in prediction of anti-microbial resistance from real-world genotyping data under explicit causal assumptions. (arXiv:2107.03383v1 [q-bio.GN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Prosperi_M/0/1/0/all/0/1">Mattia Prosperi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Marini_S/0/1/0/all/0/1">Simone Marini</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Boucher_C/0/1/0/all/0/1">Christina Boucher</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03383">
                                    <div class="article-summary-box-inner">
                                        <span>Whole genome sequencing (WGS) is quickly becoming the customary means for
identification of antimicrobial resistance (AMR) due to its ability to obtain
high resolution information about the genes and mechanisms that are causing
resistance and driving pathogen mobility. By contrast, traditional phenotypic
(antibiogram) testing cannot easily elucidate such information. Yet development
of AMR prediction tools from genotype-phenotype data can be biased, since
sampling is non-randomized. Sample provenience, period of collection, and
species representation can confound the association of genetic traits with AMR.
Thus, prediction models can perform poorly on new data with sampling
distribution shifts. In this work -- under an explicit set of causal
assumptions -- we evaluate the effectiveness of propensity-based rebalancing
and confounding adjustment on AMR prediction using genotype-phenotype AMR data
from the Pathosystems Resource Integration Center (PATRIC). We select bacterial
genotypes (encoded as k-mer signatures, i.e. DNA fragments of length k),
country, year, species, and AMR phenotypes for the tetracycline drug class,
preparing test data with recent genomes coming from a single country. We test
boosted logistic regression (BLR) and random forests (RF) with/without
bias-handling. On 10,936 instances, we find evidence of species, location and
year imbalance with respect to the AMR phenotype. The crude versus
bias-adjusted change in effect of genetic signatures on AMR varies but only
moderately (selecting the top 20,000 out of 40+ million k-mers). The area under
the receiver operating characteristic (AUROC) of the RF (0.95) is comparable to
that of BLR (0.94) on both out-of-bag samples from bootstrap and the external
test (n&#x3D;1,085), where AUROCs do not decrease. We observe a 1%-5% gain in AUROC
with bias-handling compared to the sole use of genetic signatures. ...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization Error of GAN from the Discriminator&#x27;s Perspective. (arXiv:2107.03633v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongkang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+E_W/0/1/0/all/0/1">Weinan E</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03633">
                                    <div class="article-summary-box-inner">
                                        <span>The generative adversarial network (GAN) is a well-known model for learning
high-dimensional distributions, but the mechanism for its generalization
ability is not understood. In particular, GAN is vulnerable to the memorization
phenomenon, the eventual convergence to the empirical distribution. We consider
a simplified GAN model with the generator replaced by a density, and analyze
how the discriminator contributes to generalization. We show that with early
stopping, the generalization error measured by Wasserstein metric escapes from
the curse of dimensionality, despite that in the long term, memorization is
inevitable. In addition, we present a hardness of learning result for WGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consistency of the Maximal Information Coefficient Estimator. (arXiv:2107.03836v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lazarsfeld_J/0/1/0/all/0/1">John Lazarsfeld</a>, <a href="http://arxiv.org/find/stat/1/au:+Johnson_A/0/1/0/all/0/1">Aaron Johnson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03836">
                                    <div class="article-summary-box-inner">
                                        <span>The Maximal Information Coefficient (MIC) of Reshef et al. (Science, 2011) is
a statistic for measuring dependence between variable pairs in large datasets.
In this note, we prove that MIC is a consistent estimator of the corresponding
population statistic MIC$_*$. This corrects an error in an argument of Reshef
et al. (JMLR, 2016), which we describe.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analytically Tractable Hidden-States Inference in Bayesian Neural Networks. (arXiv:2107.03759v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_L/0/1/0/all/0/1">Luong-Ha Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Goulet_J/0/1/0/all/0/1">James-A. Goulet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03759">
                                    <div class="article-summary-box-inner">
                                        <span>With few exceptions, neural networks have been relying on backpropagation and
gradient descent as the inference engine in order to learn the model
parameters, because the closed-form Bayesian inference for neural networks has
been considered to be intractable. In this paper, we show how we can leverage
the tractable approximate Gaussian inference&#x27;s (TAGI) capabilities to infer
hidden states, rather than only using it for inferring the network&#x27;s
parameters. One novel aspect it allows is to infer hidden states through the
imposition of constraints designed to achieve specific objectives, as
illustrated through three examples: (1) the generation of adversarial-attack
examples, (2) the usage of a neural network as a black-box optimization method,
and (3) the application of inference on continuous-action reinforcement
learning. These applications showcase how tasks that were previously reserved
to gradient-based optimization approaches can now be approached with
analytically tractable inference</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Safety Envelopes using Light Curtains with Probabilistic Guarantees. (arXiv:2107.04000v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ancha_S/0/1/0/all/0/1">Siddharth Ancha</a>, <a href="http://arxiv.org/find/cs/1/au:+Pathak_G/0/1/0/all/0/1">Gaurav Pathak</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_S/0/1/0/all/0/1">Srinivasa G. Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1">David Held</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04000">
                                    <div class="article-summary-box-inner">
                                        <span>To safely navigate unknown environments, robots must accurately perceive
dynamic obstacles. Instead of directly measuring the scene depth with a LiDAR
sensor, we explore the use of a much cheaper and higher resolution sensor:
programmable light curtains. Light curtains are controllable depth sensors that
sense only along a surface that a user selects. We use light curtains to
estimate the safety envelope of a scene: a hypothetical surface that separates
the robot from all obstacles. We show that generating light curtains that sense
random locations (from a particular distribution) can quickly discover the
safety envelope for scenes with unknown objects. Importantly, we produce
theoretical safety guarantees on the probability of detecting an obstacle using
random curtains. We combine random curtains with a machine learning based model
that forecasts and tracks the motion of the safety envelope efficiently. Our
method accurately estimates safety envelopes while providing probabilistic
safety guarantees that can be used to certify the efficacy of a robot
perception system to detect and avoid dynamic obstacles. We evaluate our
approach in a simulated urban driving environment and a real-world environment
with moving pedestrians using a light curtain device and show that we can
estimate safety envelopes efficiently and effectively. Project website:
https://siddancha.github.io/projects/active-safety-envelopes-with-guarantees</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Short-term Renewable Energy Forecasting in Greece using Prophet Decomposition and Tree-based Ensembles. (arXiv:2107.03825v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vartholomaios_A/0/1/0/all/0/1">Argyrios Vartholomaios</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlos_S/0/1/0/all/0/1">Stamatis Karlos</a>, <a href="http://arxiv.org/find/cs/1/au:+Kouloumpris_E/0/1/0/all/0/1">Eleftherios Kouloumpris</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1">Grigorios Tsoumakas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03825">
                                    <div class="article-summary-box-inner">
                                        <span>Energy production using renewable sources exhibits inherent uncertainties due
to their intermittent nature. Nevertheless, the unified European energy market
promotes the increasing penetration of renewable energy sources (RES) by the
regional energy system operators. Consequently, RES forecasting can assist in
the integration of these volatile energy sources, since it leads to higher
reliability and reduced ancillary operational costs for power systems. This
paper presents a new dataset for solar and wind energy generation forecast in
Greece and introduces a feature engineering pipeline that enriches the
dimensional space of the dataset. In addition, we propose a novel method that
utilizes the innovative Prophet model, an end-to-end forecasting tool that
considers several kinds of nonlinear trends in decomposing the energy time
series before a tree-based ensemble provides short-term predictions. The
performance of the system is measured through representative evaluation
metrics, and by estimating the model&#x27;s generalization under an industryprovided
scheme of absolute error thresholds. The proposed hybrid model competes with
baseline persistence models, tree-based regression ensembles, and the Prophet
model, managing to outperform them, presenting both lower error rates and more
favorable error distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowledge Transfer by Discriminative Pre-training for Academic Performance Prediction. (arXiv:2107.04009v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Byungsoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hangyeol Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_D/0/1/0/all/0/1">Dongmin Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Youngduck Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04009">
                                    <div class="article-summary-box-inner">
                                        <span>The needs for precisely estimating a student&#x27;s academic performance have been
emphasized with an increasing amount of attention paid to Intelligent Tutoring
System (ITS). However, since labels for academic performance, such as test
scores, are collected from outside of ITS, obtaining the labels is costly,
leading to label-scarcity problem which brings challenge in taking machine
learning approaches for academic performance prediction. To this end, inspired
by the recent advancement of pre-training method in natural language processing
community, we propose DPA, a transfer learning framework with Discriminative
Pre-training tasks for Academic performance prediction. DPA pre-trains two
models, a generator and a discriminator, and fine-tunes the discriminator on
academic performance prediction. In DPA&#x27;s pre-training phase, a sequence of
interactions where some tokens are masked is provided to the generator which is
trained to reconstruct the original sequence. Then, the discriminator takes an
interaction sequence where the masked tokens are replaced by the generator&#x27;s
outputs, and is trained to predict the originalities of all tokens in the
sequence. Compared to the previous state-of-the-art generative pre-training
method, DPA is more sample efficient, leading to fast convergence to lower
academic performance prediction error. We conduct extensive experimental
studies on a real-world dataset obtained from a multi-platform ITS application
and show that DPA outperforms the previous state-of-the-art generative
pre-training method with a reduction of 4.05% in mean absolute error and more
robust to increased label-scarcity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bootstrapping Generalization of Process Models Discovered From Event Data. (arXiv:2107.03876v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Polyvyanyy_A/0/1/0/all/0/1">Artem Polyvyanyy</a>, <a href="http://arxiv.org/find/cs/1/au:+Moffat_A/0/1/0/all/0/1">Alistair Moffat</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_Banuelos_L/0/1/0/all/0/1">Luciano Garc&#xed;a-Ba&#xf1;uelos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03876">
                                    <div class="article-summary-box-inner">
                                        <span>Process mining studies ways to derive value from process executions recorded
in event logs of IT-systems, with process discovery the task of inferring a
process model for an event log emitted by some unknown system. One quality
criterion for discovered process models is generalization. Generalization seeks
to quantify how well the discovered model describes future executions of the
system, and is perhaps the least understood quality criterion in process
mining. The lack of understanding is primarily a consequence of generalization
seeking to measure properties over the entire future behavior of the system,
when the only available sample of behavior is that provided by the event log
itself. In this paper, we draw inspiration from computational statistics, and
employ a bootstrap approach to estimate properties of a population based on a
sample. Specifically, we define an estimator of the model&#x27;s generalization
based on the event log it was discovered from, and then use bootstrapping to
measure the generalization of the model with respect to the system, and its
statistical significance. Experiments demonstrate the feasibility of the
approach in industrial settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Price of Diversity. (arXiv:2107.03900v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bandi_H/0/1/0/all/0/1">Hari Bandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1">Dimitris Bertsimas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03900">
                                    <div class="article-summary-box-inner">
                                        <span>Systemic bias with respect to gender, race and ethnicity, often unconscious,
is prevalent in datasets involving choices among individuals. Consequently,
society has found it challenging to alleviate bias and achieve diversity in a
way that maintains meritocracy in such settings. We propose (a) a novel
optimization approach based on optimally flipping outcome labels and training
classification models simultaneously to discover changes to be made in the
selection process so as to achieve diversity without significantly affecting
meritocracy, and (b) a novel implementation tool employing optimal
classification trees to provide insights on which attributes of individuals
lead to flipping of their labels, and to help make changes in the current
selection processes in a manner understandable by human decision makers. We
present case studies on three real-world datasets consisting of parole,
admissions to the bar and lending decisions, and demonstrate that the price of
diversity is low and sometimes negative, that is we can modify our selection
processes in a way that enhances diversity without affecting meritocracy
significantly, and sometimes improving it.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locally differentially private estimation of nonlinear functionals of discrete distributions. (arXiv:2107.03940v1 [math.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Butucea_C/0/1/0/all/0/1">Cristina Butucea</a>, <a href="http://arxiv.org/find/math/1/au:+Issartel_Y/0/1/0/all/0/1">Yann Issartel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03940">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of estimating non-linear functionals of discrete
distributions in the context of local differential privacy. The initial data
$x_1,\ldots,x_n \in [K]$ are supposed i.i.d. and distributed according to an
unknown discrete distribution $p &#x3D; (p_1,\ldots,p_K)$. Only $\alpha$-locally
differentially private (LDP) samples $z_1,...,z_n$ are publicly available,
where the term &#x27;local&#x27; means that each $z_i$ is produced using one individual
attribute $x_i$. We exhibit privacy mechanisms (PM) that are interactive (i.e.
they are allowed to use already published confidential data) or
non-interactive. We describe the behavior of the quadratic risk for estimating
the power sum functional $F_{\gamma} &#x3D; \sum_{k&#x3D;1}^K p_k^{\gamma}$, $\gamma &gt;0$
as a function of $K, \, n$ and $\alpha$. In the non-interactive case, we study
two plug-in type estimators of $F_{\gamma}$, for all $\gamma &gt;0$, that are
similar to the MLE analyzed by Jiao et al. (2017) in the multinomial model.
However, due to the privacy constraint the rates we attain are slower and
similar to those obtained in the Gaussian model by Collier et al. (2020). In
the interactive case, we introduce for all $\gamma &gt;1$ a two-step procedure
which attains the faster parametric rate $(n \alpha^2)^{-1/2}$ when $\gamma
\geq 2$. We give lower bounds results over all $\alpha$-LDP mechanisms and all
estimators using the private samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring Financial Time Series Similarity With a View to Identifying Profitable Stock Market Opportunities. (arXiv:2107.03926v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Dolphin_R/0/1/0/all/0/1">Rian Dolphin</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Smyth_B/0/1/0/all/0/1">Barry Smyth</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Xu_Y/0/1/0/all/0/1">Yang Xu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Dong_R/0/1/0/all/0/1">Ruihai Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03926">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting stock returns is a challenging problem due to the highly
stochastic nature of the market and the vast array of factors and events that
can influence trading volume and prices. Nevertheless it has proven to be an
attractive target for machine learning research because of the potential for
even modest levels of prediction accuracy to deliver significant benefits. In
this paper, we describe a case-based reasoning approach to predicting stock
market returns using only historical pricing data. We argue that one of the
impediments for case-based stock prediction has been the lack of a suitable
similarity metric when it comes to identifying similar pricing histories as the
basis for a future prediction -- traditional Euclidean and correlation based
approaches are not effective for a variety of reasons -- and in this regard, a
key contribution of this work is the development of a novel similarity metric
for comparing historical pricing data. We demonstrate the benefits of this
metric and the case-based approach in a real-world application in comparison to
a variety of conventional benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Data Processing in Space for Object Detection in Satellite Imagery. (arXiv:2107.03774v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lofqvist_M/0/1/0/all/0/1">Martina Lofqvist</a>, <a href="http://arxiv.org/find/cs/1/au:+Cano_J/0/1/0/all/0/1">Jos&#xe9; Cano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03774">
                                    <div class="article-summary-box-inner">
                                        <span>There is a proliferation in the number of satellites launched each year,
resulting in downlinking of terabytes of data each day. The data received by
ground stations is often unprocessed, making this an expensive process
considering the large data sizes and that not all of the data is useful. This,
coupled with the increasing demand for real-time data processing, has led to a
growing need for on-orbit processing solutions. In this work, we investigate
the performance of CNN-based object detectors on constrained devices by
applying different image compression techniques to satellite data. We examine
the capabilities of the NVIDIA Jetson Nano and NVIDIA Jetson AGX Xavier;
low-power, high-performance computers, with integrated GPUs, small enough to
fit on-board a nanosatellite. We take a closer look at object detection
networks, including the Single Shot MultiBox Detector (SSD) and Region-based
Fully Convolutional Network (R-FCN) models that are pre-trained on DOTA - a
Large Scale Dataset for Object Detection in Aerial Images. The performance is
measured in terms of execution time, memory consumption, and accuracy, and are
compared against a baseline containing a server with two powerful GPUs. The
results show that by applying image compression techniques, we are able to
improve the execution time and memory consumption, achieving a fully runnable
dataset. A lossless compression technique achieves roughly a 10% reduction in
execution time and about a 3% reduction in memory consumption, with no impact
on the accuracy. While a lossy compression technique improves the execution
time by up to 144% and the memory consumption is reduced by as much as 97%.
However, it has a significant impact on accuracy, varying depending on the
compression ratio. Thus the application and ratio of these compression
techniques may differ depending on the required level of accuracy for a
particular task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modality Task Cascade for 3D Object Detection. (arXiv:2107.04013v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jinhyung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_X/0/1/0/all/0/1">Xinshuo Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Man_Y/0/1/0/all/0/1">Yunze Man</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1">Kris Kitani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04013">
                                    <div class="article-summary-box-inner">
                                        <span>Point clouds and RGB images are naturally complementary modalities for 3D
visual understanding - the former provides sparse but accurate locations of
points on objects, while the latter contains dense color and texture
information. Despite this potential for close sensor fusion, many methods train
two models in isolation and use simple feature concatenation to represent 3D
sensor data. This separated training scheme results in potentially sub-optimal
performance and prevents 3D tasks from being used to benefit 2D tasks that are
often useful on their own. To provide a more integrated approach, we propose a
novel Multi-Modality Task Cascade network (MTC-RCNN) that leverages 3D box
proposals to improve 2D segmentation predictions, which are then used to
further refine the 3D boxes. We show that including a 2D network between two
stages of 3D modules significantly improves both 2D and 3D task performance.
Moreover, to prevent the 3D module from over-relying on the overfitted 2D
predictions, we propose a dual-head 2D segmentation training and inference
scheme, allowing the 2nd 3D module to learn to interpret imperfect 2D
segmentation predictions. Evaluating our model on the challenging SUN RGB-D
dataset, we improve upon state-of-the-art results of both single modality and
fusion networks by a large margin ($\textbf{+3.8}$ mAP@0.5). Code will be
released $\href{https://github.com/Divadi/MTC_RCNN}{\text{here.}}$</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Margins and Derandomisation in PAC-Bayes. (arXiv:2107.03955v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biggs_F/0/1/0/all/0/1">Felix Biggs</a>, <a href="http://arxiv.org/find/cs/1/au:+Guedj_B/0/1/0/all/0/1">Benjamin Guedj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03955">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a framework for derandomising PAC-Bayesian generalisation bounds
achieving a margin on training data, relating this process to the
concentration-of-measure phenomenon. We apply these tools to linear prediction,
single-hidden-layer neural networks with an unusual erf activation function,
and deep ReLU networks, obtaining new bounds. The approach is also extended to
the idea of &quot;partial-derandomisation&quot; where only some layers are derandomised
and the others are stochastic. This allows empirical evaluation of
single-hidden-layer networks on more complex datasets, and helps bridge the gap
between generalisation bounds for non-stochastic deep networks and those for
randomised deep networks as generally examined in PAC-Bayes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmented Data as an Auxiliary Plug-in Towards Categorization of Crowdsourced Heritage Data. (arXiv:2107.03852v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kudari_S/0/1/0/all/0/1">Shashidhar Veerappa Kudari</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunari_A/0/1/0/all/0/1">Akshaykumar Gunari</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamadandi_A/0/1/0/all/0/1">Adarsh Jamadandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabib_R/0/1/0/all/0/1">Ramesh Ashok Tabib</a>, <a href="http://arxiv.org/find/cs/1/au:+Mudenagudi_U/0/1/0/all/0/1">Uma Mudenagudi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03852">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a strategy to mitigate the problem of inefficient
clustering performance by introducing data augmentation as an auxiliary
plug-in. Classical clustering techniques such as K-means, Gaussian mixture
model and spectral clustering are central to many data-driven applications.
However, recently unsupervised simultaneous feature learning and clustering
using neural networks also known as Deep Embedded Clustering (DEC) has gained
prominence. Pioneering works on deep feature clustering focus on defining
relevant clustering loss function and choosing the right neural network for
extracting features. A central problem in all these cases is data sparsity
accompanied by high intra-class and low inter-class variance, which
subsequently leads to poor clustering performance and erroneous candidate
assignments. Towards this, we employ data augmentation techniques to improve
the density of the clusters, thus improving the overall performance. We train a
variant of Convolutional Autoencoder (CAE) with augmented data to construct the
initial feature space as a novel model for deep clustering. We demonstrate the
results of proposed strategy on crowdsourced Indian Heritage dataset. Extensive
experiments show consistent improvements over existing works.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CSDI: Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation. (arXiv:2107.03502v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tashiro_Y/0/1/0/all/0/1">Yusuke Tashiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jiaming Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03502">
                                    <div class="article-summary-box-inner">
                                        <span>The imputation of missing values in time series has many applications in
healthcare and finance. While autoregressive models are natural candidates for
time series imputation, score-based diffusion models have recently outperformed
existing counterparts including autoregressive models in many tasks such as
image generation and audio synthesis, and would be promising for time series
imputation. In this paper, we propose Conditional Score-based Diffusion models
for Imputation (CSDI), a novel time series imputation method that utilizes
score-based diffusion models conditioned on observed data. Unlike existing
score-based approaches, the conditional diffusion model is explicitly trained
for imputation and can exploit correlations between observed values. On
healthcare and environmental data, CSDI improves by 40-70% over existing
probabilistic imputation methods on popular performance metrics. In addition,
deterministic imputation by CSDI reduces the error by 5-20% compared to the
state-of-the-art deterministic imputation methods. Furthermore, CSDI can also
be applied to time series interpolation and probabilistic forecasting, and is
competitive with existing baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">$S^3$: Sign-Sparse-Shift Reparametrization for Effective Training of Low-bit Shift Networks. (arXiv:2107.03453v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinlin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yaoliang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wulong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nia_V/0/1/0/all/0/1">Vahid Partovi Nia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03453">
                                    <div class="article-summary-box-inner">
                                        <span>Shift neural networks reduce computation complexity by removing expensive
multiplication operations and quantizing continuous weights into low-bit
discrete values, which are fast and energy efficient compared to conventional
neural networks. However, existing shift networks are sensitive to the weight
initialization, and also yield a degraded performance caused by vanishing
gradient and weight sign freezing problem. To address these issues, we propose
S low-bit re-parameterization, a novel technique for training low-bit shift
networks. Our method decomposes a discrete parameter in a sign-sparse-shift
3-fold manner. In this way, it efficiently learns a low-bit network with a
weight dynamics similar to full-precision networks and insensitive to weight
initialization. Our proposed training method pushes the boundaries of shift
neural networks and shows 3-bit shift networks out-performs their
full-precision counterparts in terms of top-1 accuracy on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral decoupling allows training transferable neural networks in medical imaging. (arXiv:2103.17171v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pohjonen_J/0/1/0/all/0/1">Joona Pohjonen</a>, <a href="http://arxiv.org/find/eess/1/au:+Sturenberg_C/0/1/0/all/0/1">Carolin St&#xfc;renberg</a>, <a href="http://arxiv.org/find/eess/1/au:+Rannikko_A/0/1/0/all/0/1">Antti Rannikko</a>, <a href="http://arxiv.org/find/eess/1/au:+Mirtti_T/0/1/0/all/0/1">Tuomas Mirtti</a>, <a href="http://arxiv.org/find/eess/1/au:+Pitkanen_E/0/1/0/all/0/1">Esa Pitk&#xe4;nen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17171">
                                    <div class="article-summary-box-inner">
                                        <span>Many current neural networks for medical imaging generalise poorly to data
unseen during training. Such behaviour can be caused by networks overfitting
easy-to-learn, or statistically dominant, features while disregarding other
potentially informative features. For example, indistinguishable differences in
the sharpness of the images from two different scanners can degrade the
performance of the network significantly. All neural networks intended for
clinical practice need to be robust to variation in data caused by differences
in imaging equipment, sample preparation and patient populations.

To address these challenges, we evaluate the utility of spectral decoupling
as an implicit bias mitigation method. Spectral decoupling encourages the
neural network to learn more features by simply regularising the networks&#x27;
unnormalised prediction scores with an L2 penalty, thus having no added
computational costs.

We show that spectral decoupling allows training neural networks on datasets
with strong spurious correlations. Networks trained without spectral decoupling
do not learn the original task and appear to make false predictions based on
the spurious correlations. Spectral decoupling also increases networks&#x27;
robustness for data distribution shifts. To validate our findings, we train
networks with and without spectral decoupling to detect prostate cancer tissue
slides and COVID-19 in chest radiographs. Networks trained with spectral
decoupling achieve substantially higher performance on all evaluation datasets.

Our results show that spectral decoupling helps with generalisation issues
associated with neural networks. We recommend using spectral decoupling as an
implicit bias mitigation method in any neural network intended for clinical
use.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID19-HPSMP: COVID-19 Adopted Hybrid and Parallel Deep Information Fusion Framework for Stock Price Movement Prediction. (arXiv:2101.02287v2 [q-fin.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Ronaghi_F/0/1/0/all/0/1">Farnoush Ronaghi</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Salimibeni_M/0/1/0/all/0/1">Mohammad Salimibeni</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Naderkhani_F/0/1/0/all/0/1">Farnoosh Naderkhani</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Mohammadi_A/0/1/0/all/0/1">Arash Mohammadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02287">
                                    <div class="article-summary-box-inner">
                                        <span>The novel of coronavirus (COVID-19) has suddenly and abruptly changed the
world as we knew at the start of the 3rd decade of the 21st century.
Particularly, COVID-19 pandemic has negatively affected financial econometrics
and stock markets across the globe. Artificial Intelligence (AI) and Machine
Learning (ML)-based prediction models, especially Deep Neural Network (DNN)
architectures, have the potential to act as a key enabling factor to reduce the
adverse effects of the COVID-19 pandemic and future possible ones on financial
markets. In this regard, first, a unique COVID-19 related PRIce MOvement
prediction (COVID19 PRIMO) dataset is introduced in this paper, which
incorporates effects of social media trends related to COVID-19 on stock market
price movements. Afterwards, a novel hybrid and parallel DNN-based framework is
proposed that integrates different and diversified learning architectures.
Referred to as the COVID-19 adopted Hybrid and Parallel deep fusion framework
for Stock price Movement Prediction (COVID19-HPSMP), innovative fusion
strategies are used to combine scattered social media news related to COVID-19
with historical mark data. The proposed COVID19-HPSMP consists of two parallel
paths (hence hybrid), one based on Convolutional Neural Network (CNN) with
Local/Global Attention modules, and one integrated CNN and Bi-directional Long
Short term Memory (BLSTM) path. The two parallel paths are followed by a
multilayer fusion layer acting as a fusion centre that combines localized
features. Performance evaluations are performed based on the introduced COVID19
PRIMO dataset illustrating superior performance of the proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fourier Sparse Leverage Scores and Approximate Kernel Learning. (arXiv:2006.07340v3 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Erdelyi_T/0/1/0/all/0/1">Tam&#xe1;s Erd&#xe9;lyi</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Cameron Musco</a>, <a href="http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1">Christopher Musco</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07340">
                                    <div class="article-summary-box-inner">
                                        <span>We prove new explicit upper bounds on the leverage scores of Fourier sparse
functions under both the Gaussian and Laplace measures. In particular, we study
$s$-sparse functions of the form $f(x) &#x3D; \sum_{j&#x3D;1}^s a_j e^{i \lambda_j x}$
for coefficients $a_j \in \mathbb{C}$ and frequencies $\lambda_j \in
\mathbb{R}$. Bounding Fourier sparse leverage scores under various measures is
of pure mathematical interest in approximation theory, and our work extends
existing results for the uniform measure [Erd17,CP19a]. Practically, our bounds
are motivated by two important applications in machine learning:

1. Kernel Approximation. They yield a new random Fourier features algorithm
for approximating Gaussian and Cauchy (rational quadratic) kernel matrices. For
low-dimensional data, our method uses a near optimal number of features, and
its runtime is polynomial in the $statistical\ dimension$ of the approximated
kernel matrix. It is the first &quot;oblivious sketching method&quot; with this property
for any kernel besides the polynomial kernel, resolving an open question of
[AKM+17,AKK+20b].

2. Active Learning. They can be used as non-uniform sampling distributions
for robust active learning when data follows a Gaussian or Laplace
distribution. Using the framework of [AKM+19], we provide essentially optimal
results for bandlimited and multiband interpolation, and Gaussian process
regression. These results generalize existing work that only applies to
uniformly distributed data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The value of text for small business default prediction: A deep learning approach. (arXiv:2003.08964v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stevenson_M/0/1/0/all/0/1">Matthew Stevenson</a>, <a href="http://arxiv.org/find/cs/1/au:+Mues_C/0/1/0/all/0/1">Christophe Mues</a>, <a href="http://arxiv.org/find/cs/1/au:+Bravo_C/0/1/0/all/0/1">Cristi&#xe1;n Bravo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.08964">
                                    <div class="article-summary-box-inner">
                                        <span>Compared to consumer lending, Micro, Small and Medium Enterprise (mSME)
credit risk modelling is particularly challenging, as, often, the same sources
of information are not available. Therefore, it is standard policy for a loan
officer to provide a textual loan assessment to mitigate limited data
availability. In turn, this statement is analysed by a credit expert alongside
any available standard credit data. In our paper, we exploit recent advances
from the field of Deep Learning and Natural Language Processing (NLP),
including the BERT (Bidirectional Encoder Representations from Transformers)
model, to extract information from 60 000 textual assessments provided by a
lender. We consider the performance in terms of the AUC (Area Under the
receiver operating characteristic Curve) and Brier Score metrics and find that
the text alone is surprisingly effective for predicting default. However, when
combined with traditional data, it yields no additional predictive capability,
with performance dependent on the text&#x27;s length. Our proposed deep learning
model does, however, appear to be robust to the quality of the text and
therefore suitable for partly automating the mSME lending process. We also
demonstrate how the content of loan assessments influences performance, leading
us to a series of recommendations on a new strategy for collecting future mSME
loan assessments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extending Lagrangian and Hamiltonian Neural Networks with Differentiable Contact Models. (arXiv:2102.06794v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yaofeng Desmond Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_B/0/1/0/all/0/1">Biswadip Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1">Amit Chakraborty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06794">
                                    <div class="article-summary-box-inner">
                                        <span>The incorporation of appropriate inductive bias plays a critical role in
learning dynamics from data. A growing body of work has been exploring ways to
enforce energy conservation in the learned dynamics by encoding Lagrangian or
Hamiltonian dynamics into the neural network architecture. These existing
approaches are based on differential equations, which do not allow
discontinuity in the states and thereby limit the class of systems one can
learn. However, in reality, most physical systems, such as legged robots and
robotic manipulators, involve contacts and collisions, which introduce
discontinuities in the states. In this paper, we introduce a differentiable
contact model, which can capture contact mechanics: frictionless/frictional, as
well as elastic/inelastic. This model can also accommodate inequality
constraints, such as limits on the joint angles. The proposed contact model
extends the scope of Lagrangian and Hamiltonian neural networks by allowing
simultaneous learning of contact and system properties. We demonstrate this
framework on a series of challenging 2D and 3D physical systems with different
coefficients of restitution and friction. The learned dynamics can be used as a
differentiable physics simulator for downstream gradient-based optimization
tasks, such as planning and control.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bag of Tricks for Neural Architecture Search. (arXiv:2107.03719v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elsken_T/0/1/0/all/0/1">Thomas Elsken</a>, <a href="http://arxiv.org/find/cs/1/au:+Staffler_B/0/1/0/all/0/1">Benedikt Staffler</a>, <a href="http://arxiv.org/find/cs/1/au:+Zela_A/0/1/0/all/0/1">Arber Zela</a>, <a href="http://arxiv.org/find/cs/1/au:+Metzen_J/0/1/0/all/0/1">Jan Hendrik Metzen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1">Frank Hutter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03719">
                                    <div class="article-summary-box-inner">
                                        <span>While neural architecture search methods have been successful in previous
years and led to new state-of-the-art performance on various problems, they
have also been criticized for being unstable, being highly sensitive with
respect to their hyperparameters, and often not performing better than random
search. To shed some light on this issue, we discuss some practical
considerations that help improve the stability, efficiency and overall
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impossibility results for fair representations. (arXiv:2107.03483v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lechner_T/0/1/0/all/0/1">Tosca Lechner</a>, <a href="http://arxiv.org/find/cs/1/au:+Ben_David_S/0/1/0/all/0/1">Shai Ben-David</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sushant Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ananthakrishnan_N/0/1/0/all/0/1">Nivasini Ananthakrishnan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03483">
                                    <div class="article-summary-box-inner">
                                        <span>With the growing awareness to fairness in machine learning and the
realization of the central role that data representation has in data processing
tasks, there is an obvious interest in notions of fair data representations.
The goal of such representations is that a model trained on data under the
representation (e.g., a classifier) will be guaranteed to respect some fairness
constraints.

Such representations are useful when they can be fixed for training models on
various different tasks and also when they serve as data filtering between the
raw data (known to the representation designer) and potentially malicious
agents that use the data under the representation to learn predictive models
and make decisions.

A long list of recent research papers strive to provide tools for achieving
these goals.

However, we prove that this is basically a futile effort. Roughly stated, we
prove that no representation can guarantee the fairness of classifiers for
different tasks trained using it; even the basic goal of achieving
label-independent Demographic Parity fairness fails once the marginal data
distribution shifts. More refined notions of fairness, like Odds Equality,
cannot be guaranteed by a representation that does not take into account the
task specific labeling rule with respect to which such fairness will be
evaluated (even if the marginal data distribution is known a priory).
Furthermore, except for trivial cases, no representation can guarantee Odds
Equality fairness for any two different tasks, while allowing accurate label
predictions for both.

While some of our conclusions are intuitive, we formulate (and prove) crisp
statements of such impossibilities, often contrasting impressions conveyed by
many recent works on fair representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Network Compression. (arXiv:2008.08733v3 [q-fin.RM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Amini_H/0/1/0/all/0/1">Hamed Amini</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Feinstein_Z/0/1/0/all/0/1">Zachary Feinstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08733">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a formulation of the optimal network compression
problem for financial systems. This general formulation is presented for
different levels of network compression or rerouting allowed from the initial
interbank network. We prove that this problem is, generically, NP-hard. We
focus on objective functions generated by systemic risk measures under
systematic shocks to the financial network. We conclude by studying the optimal
compression problem for specific networks; this permits us to study the
so-called robust fragility of certain network topologies more generally as well
as the potential benefits and costs of network compression. In particular,
under systematic shocks and heterogeneous financial networks the typical
heuristics of robust fragility no longer hold generally.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Certifying clusters from sum-of-norms clustering. (arXiv:2006.11355v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Vavasis_S/0/1/0/all/0/1">Stephen Vavasis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11355">
                                    <div class="article-summary-box-inner">
                                        <span>Sum-of-norms clustering is a clustering formulation based on convex
optimization that automatically induces hierarchy. Multiple algorithms have
been proposed to solve the optimization problem: subgradient descent by Hocking
et al., ADMM and ADA by Chi and Lange, stochastic incremental algorithm by
Panahi et al. and semismooth Newton-CG augmented Lagrangian method by Sun et
al. All algorithms yield approximate solutions, even though an exact solution
is demanded to determine the correct cluster assignment. The purpose of this
paper is to close the gap between the output from existing algorithms and the
exact solution to the optimization problem. We present a clustering test that
identifies and certifies the correct cluster assignment from an approximate
solution yielded by any primal-dual algorithm. Our certification validates
clustering for both unit and multiplicative weights. The test may not succeed
if the approximation is inaccurate. However, we show the correct cluster
assignment is guaranteed to be certified by a primal-dual path following
algorithm after sufficiently many iterations, provided that the model parameter
$\lambda$ avoids a finite number of bad values. Numerical experiments are
conducted on Gaussian mixture and half-moon data, which indicate that carefully
chosen multiplicative weights increase the recovery power of sum-of-norms
clustering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Preprocessing: Towards Understanding Compositional Fairness of Data Transformers in Machine Learning Pipeline. (arXiv:2106.06054v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1">Sumon Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajan_H/0/1/0/all/0/1">Hridesh Rajan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06054">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, many incidents have been reported where machine learning
models exhibited discrimination among people based on race, sex, age, etc.
Research has been conducted to measure and mitigate unfairness in machine
learning models. For a machine learning task, it is a common practice to build
a pipeline that includes an ordered set of data preprocessing stages followed
by a classifier. However, most of the research on fairness has considered a
single classifier based prediction task. What are the fairness impacts of the
preprocessing stages in machine learning pipeline? Furthermore, studies showed
that often the root cause of unfairness is ingrained in the data itself, rather
than the model. But no research has been conducted to measure the unfairness
caused by a specific transformation made in the data preprocessing stage. In
this paper, we introduced the causal method of fairness to reason about the
fairness impact of data preprocessing stages in ML pipeline. We leveraged
existing metrics to define the fairness measures of the stages. Then we
conducted a detailed fairness evaluation of the preprocessing stages in 37
pipelines collected from three different sources. Our results show that certain
data transformers are causing the model to exhibit unfairness. We identified a
number of fairness patterns in several categories of data transformers.
Finally, we showed how the local fairness of a preprocessing stage composes in
the global fairness of the pipeline. We used the fairness composition to choose
appropriate downstream transformer that mitigates unfairness in the machine
learning pipeline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Default Values: a Low Cost and Efficient Strategy to Define Hyperparameters. (arXiv:2008.00025v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mantovani_R/0/1/0/all/0/1">Rafael Gomes Mantovani</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossi_A/0/1/0/all/0/1">Andr&#xe9; Luis Debiaso Rossi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alcobaca_E/0/1/0/all/0/1">Edesio Alcoba&#xe7;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Gertrudes_J/0/1/0/all/0/1">Jadson Castro Gertrudes</a>, <a href="http://arxiv.org/find/cs/1/au:+Junior_S/0/1/0/all/0/1">Sylvio Barbon Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1">Andr&#xe9; Carlos Ponce de Leon Ferreira de Carvalho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00025">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning (ML) algorithms have been increasingly applied to problems
from several different areas. Despite their growing popularity, their
predictive performance is usually affected by the values assigned to their
hyperparameters (HPs). As consequence, researchers and practitioners face the
challenge of how to set these values. Many users have limited knowledge about
ML algorithms and the effect of their HP values and, therefore, do not take
advantage of suitable settings. They usually define the HP values by trial and
error, which is very subjective, not guaranteed to find good values and
dependent on the user experience. Tuning techniques search for HP values able
to maximize the predictive performance of induced models for a given dataset,
but have the drawback of a high computational cost. Thus, practitioners use
default values suggested by the algorithm developer or by tools implementing
the algorithm. Although default values usually result in models with acceptable
predictive performance, different implementations of the same algorithm can
suggest distinct default values. To maintain a balance between tuning and using
default values, we propose a strategy to generate new optimized default values.
Our approach is grounded on a small set of optimized values able to obtain
predictive performance values better than default settings provided by popular
tools. After performing a large experiment and a careful analysis of the
results, we concluded that our approach delivers better default values.
Besides, it leads to competitive solutions when compared to tuned values,
making it easier to use and having a lower cost. We also extracted simple rules
to guide practitioners in deciding whether to use our new methodology or a HP
tuning approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Use of Machine Learning Technique to maximize the signal over background for $H \rightarrow \tau \tau$. (arXiv:2106.14257v2 [physics.data-an] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Gupta_K/0/1/0/all/0/1">Kanhaiya Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14257">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, artificial neural networks (ANNs) have won numerous contests
in pattern recognition and machine learning. ANNS have been applied to problems
ranging from speech recognition to prediction of protein secondary structure,
classification of cancers, and gene prediction. Here, we intend to maximize the
chances of finding the Higgs boson decays to two $\tau$ leptons in the pseudo
dataset using a Machine Learning technique to classify the recorded events as
signal or background.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepShift: Towards Multiplication-Less Neural Networks. (arXiv:1905.13298v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elhoushi_M/0/1/0/all/0/1">Mostafa Elhoushi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zihao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiq_F/0/1/0/all/0/1">Farhan Shafiq</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Ye Henry Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Joey Yiwei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.13298">
                                    <div class="article-summary-box-inner">
                                        <span>The high computation, memory, and power budgets of inferring convolutional
neural networks (CNNs) are major bottlenecks of model deployment to edge
computing platforms, e.g., mobile devices and IoT. Moreover, training CNNs is
time and energy-intensive even on high-grade servers. Convolution layers and
fully connected layers, because of their intense use of multiplications, are
the dominant contributor to this computation budget.

We propose to alleviate this problem by introducing two new operations:
convolutional shifts and fully-connected shifts which replace multiplications
with bitwise shift and sign flipping during both training and inference. During
inference, both approaches require only 5 bits (or less) to represent the
weights. This family of neural network architectures (that use convolutional
shifts and fully connected shifts) is referred to as DeepShift models. We
propose two methods to train DeepShift models: DeepShift-Q which trains regular
weights constrained to powers of 2, and DeepShift-PS that trains the values of
the shifts and sign flips directly.

Very close accuracy, and in some cases higher accuracy, to baselines are
achieved. Converting pre-trained 32-bit floating-point baseline models of
ResNet18, ResNet50, VGG16, and GoogleNet to DeepShift and training them for 15
to 30 epochs, resulted in Top-1/Top-5 accuracies higher than that of the
original model.

Last but not least, we implemented the convolutional shifts and fully
connected shift GPU kernels and showed a reduction in latency time of 25% when
inferring ResNet18 compared to unoptimized multiplication-based GPU kernels.
The code can be found at https://github.com/mostafaelhoushi/DeepShift.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Probabilistic Interpretation of Self-Paced Learning with Applications to Reinforcement Learning. (arXiv:2102.13176v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Klink_P/0/1/0/all/0/1">Pascal Klink</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdulsamad_H/0/1/0/all/0/1">Hany Abdulsamad</a>, <a href="http://arxiv.org/find/cs/1/au:+Belousov_B/0/1/0/all/0/1">Boris Belousov</a>, <a href="http://arxiv.org/find/cs/1/au:+DEramo_C/0/1/0/all/0/1">Carlo D&#x27;Eramo</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jan Peters</a>, <a href="http://arxiv.org/find/cs/1/au:+Pajarinen_J/0/1/0/all/0/1">Joni Pajarinen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13176">
                                    <div class="article-summary-box-inner">
                                        <span>Across machine learning, the use of curricula has shown strong empirical
potential to improve learning from data by avoiding local optima of training
objectives. For reinforcement learning (RL), curricula are especially
interesting, as the underlying optimization has a strong tendency to get stuck
in local optima due to the exploration-exploitation trade-off. Recently, a
number of approaches for an automatic generation of curricula for RL have been
shown to increase performance while requiring less expert knowledge compared to
manually designed curricula. However, these approaches are seldomly
investigated from a theoretical perspective, preventing a deeper understanding
of their mechanics. In this paper, we present an approach for automated
curriculum generation in RL with a clear theoretical underpinning. More
precisely, we formalize the well-known self-paced learning paradigm as inducing
a distribution over training tasks, which trades off between task complexity
and the objective to match a desired task distribution. Experiments show that
training on this induced distribution helps to avoid poor local optima across
RL algorithms in different tasks with uninformative rewards and challenging
exploration requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synthetic Data -- Anonymisation Groundhog Day. (arXiv:2011.07018v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stadler_T/0/1/0/all/0/1">Theresa Stadler</a>, <a href="http://arxiv.org/find/cs/1/au:+Oprisanu_B/0/1/0/all/0/1">Bristena Oprisanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Troncoso_C/0/1/0/all/0/1">Carmela Troncoso</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07018">
                                    <div class="article-summary-box-inner">
                                        <span>Synthetic data has been advertised as a silver-bullet solution to
privacy-preserving data publishing that addresses the shortcomings of
traditional anonymisation techniques. The promise is that synthetic data drawn
from generative models preserves the statistical properties of the original
dataset but, at the same time, provides perfect protection against privacy
attacks. In this work, we present the first quantitative evaluation of the
privacy gain of synthetic data publishing and compare it to that of previous
anonymisation techniques.

Our evaluation of a wide range of state-of-the-art generative models
demonstrates that synthetic data either does not prevent inference attacks or
does not retain data utility. In other words, we empirically show that
synthetic data suffers from the same limitations as traditional anonymisation
techniques.

Furthermore, we find that, in contrast to traditional anonymisation, the
privacy-utility tradeoff of synthetic data publishing is hard to predict.
Because it is impossible to predict what signals a synthetic dataset will
preserve and what information will be lost, synthetic data leads to a highly
variable privacy gain and unpredictable utility loss. In summary, we find that
synthetic data is far from the holy grail of privacy-preserving data
publishing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sim-to-Real Transfer in Deep Reinforcement Learning for Robotics: a Survey. (arXiv:2009.13303v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenshuai Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Queralta_J/0/1/0/all/0/1">Jorge Pe&#xf1;a Queralta</a>, <a href="http://arxiv.org/find/cs/1/au:+Westerlund_T/0/1/0/all/0/1">Tomi Westerlund</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13303">
                                    <div class="article-summary-box-inner">
                                        <span>Deep reinforcement learning has recently seen huge success across multiple
areas in the robotics domain. Owing to the limitations of gathering real-world
data, i.e., sample inefficiency and the cost of collecting it, simulation
environments are utilized for training the different agents. This not only aids
in providing a potentially infinite data source, but also alleviates safety
concerns with real robots. Nonetheless, the gap between the simulated and real
worlds degrades the performance of the policies once the models are transferred
into real robots. Multiple research efforts are therefore now being directed
towards closing this sim-to-real gap and accomplish more efficient policy
transfer. Recent years have seen the emergence of multiple methods applicable
to different domains, but there is a lack, to the best of our knowledge, of a
comprehensive review summarizing and putting into context the different
methods. In this survey paper, we cover the fundamental background behind
sim-to-real transfer in deep reinforcement learning and overview the main
methods being utilized at the moment: domain randomization, domain adaptation,
imitation learning, meta-learning and knowledge distillation. We categorize
some of the most relevant recent works, and outline the main application
scenarios. Finally, we discuss the main opportunities and challenges of the
different approaches and point to the most promising directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reinforcement Learning Methods for Structure-Guided Processing Path Optimization. (arXiv:2009.09706v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dornheim_J/0/1/0/all/0/1">Johannes Dornheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Morand_L/0/1/0/all/0/1">Lukas Morand</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeitvogel_S/0/1/0/all/0/1">Samuel Zeitvogel</a>, <a href="http://arxiv.org/find/cs/1/au:+Iraki_T/0/1/0/all/0/1">Tarek Iraki</a>, <a href="http://arxiv.org/find/cs/1/au:+Link_N/0/1/0/all/0/1">Norbert Link</a>, <a href="http://arxiv.org/find/cs/1/au:+Helm_D/0/1/0/all/0/1">Dirk Helm</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.09706">
                                    <div class="article-summary-box-inner">
                                        <span>A major goal of materials design is to find material structures with desired
properties and in a second step to find a processing path to reach one of these
structures. In this paper, we propose and investigate a deep reinforcement
learning approach for the optimization of processing paths. The goal is to find
optimal processing paths in the material structure space that lead to
target-structures, which have been identified beforehand to result in desired
material properties. There exists a target set containing one or multiple
different structures. Our proposed methods can find an optimal path from a
start structure to a single target structure, or optimize the processing paths
to one of the equivalent target-structures in the set. In the latter case, the
algorithm learns during processing to simultaneously identify the best
reachable target structure and the optimal path to it. The proposed methods
belong to the family of model-free deep reinforcement learning algorithms. They
are guided by structure representations as features of the process state and by
a reward signal, which is formulated based on a distance function in the
structure space. Model-free reinforcement learning algorithms learn through
trial and error while interacting with the process. Thereby, they are not
restricted to information from a priori sampled processing data and are able to
adapt to the specific process. The optimization itself is model-free and does
not require any prior knowledge about the process itself. We instantiate and
evaluate the proposed methods by optimizing paths of a generic metal forming
process. We show the ability of both methods to find processing paths leading
close to target structures and the ability of the extended method to identify
target-structures that can be reached effectively and efficiently and to focus
on these targets for sample efficient processing path optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond BatchNorm: Towards a General Understanding of Normalization in Deep Learning. (arXiv:2106.05956v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1">Ekdeep Singh Lubana</a>, <a href="http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1">Robert P. Dick</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_H/0/1/0/all/0/1">Hidenori Tanaka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05956">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by BatchNorm, there has been an explosion of normalization layers
for deep neural networks (DNNs). However, these alternative normalization
layers have seen minimal use, partially due to a lack of guiding principles
that can help identify when these layers can serve as a replacement for
BatchNorm. To address this problem, we take a theoretical approach,
generalizing the known beneficial mechanisms of BatchNorm to several recently
proposed normalization techniques. Our generalized theory leads to the
following set of principles: (i) similar to BatchNorm, activations-based
normalization layers can prevent exponential growth of activations in ResNets,
but parametric layers require explicit remedies; (ii) use of GroupNorm can
ensure informative forward propagation, with different samples being assigned
dissimilar activations, but increasing group size results in increasingly
indistinguishable activations for different samples, explaining slow
convergence speed in models with LayerNorm; (iii) small group sizes result in
large gradient norm in earlier layers, hence explaining training instability
issues in Instance Normalization and illustrating a speed-stability tradeoff in
GroupNorm. Overall, our analysis reveals a unified set of mechanisms that
underpin the success of normalization methods in deep learning, providing us
with a compass to systematically explore the vast design space of DNN
normalization layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TensorFlow RiemOpt: a library for optimization on Riemannian manifolds. (arXiv:2105.13921v2 [cs.MS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Smirnov_O/0/1/0/all/0/1">Oleg Smirnov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13921">
                                    <div class="article-summary-box-inner">
                                        <span>The adoption of neural networks and deep learning in non-Euclidean domains
has been hindered until recently by the lack of scalable and efficient learning
frameworks. Existing toolboxes in this space were mainly motivated by research
and education use cases, whereas practical aspects, such as deploying and
maintaining machine learning models, were often overlooked.

We attempt to bridge this gap by proposing TensorFlow RiemOpt, a Python
library for optimization on Riemannian manifolds in TensorFlow. The library is
designed with the aim for a seamless integration with the TensorFlow ecosystem,
targeting not only research, but also streamlining production machine learning
pipelines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascaded Diffusion Models for High Fidelity Image Generation. (arXiv:2106.15282v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Saharia_C/0/1/0/all/0/1">Chitwan Saharia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_W/0/1/0/all/0/1">William Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1">David J. Fleet</a>, <a href="http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1">Mohammad Norouzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Salimans_T/0/1/0/all/0/1">Tim Salimans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15282">
                                    <div class="article-summary-box-inner">
                                        <span>We show that cascaded diffusion models are capable of generating high
fidelity images on the class-conditional ImageNet generation challenge, without
any assistance from auxiliary image classifiers to boost sample quality. A
cascaded diffusion model comprises a pipeline of multiple diffusion models that
generate images of increasing resolution, beginning with a standard diffusion
model at the lowest resolution, followed by one or more super-resolution
diffusion models that successively upsample the image and add higher resolution
details. We find that the sample quality of a cascading pipeline relies
crucially on conditioning augmentation, our proposed method of data
augmentation of the lower resolution conditioning inputs to the
super-resolution models. Our experiments show that conditioning augmentation
prevents compounding error during sampling in a cascaded model, helping us to
train cascading pipelines achieving FID scores of 1.48 at 64x64, 3.52 at
128x128 and 4.88 at 256x256 resolutions, outperforming BigGAN-deep, and
classification accuracy scores of 63.02% (top-1) and 84.06% (top-5) at 256x256,
outperforming VQ-VAE-2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Teacher&#x27;s pet: understanding and mitigating biases in distillation. (arXiv:2106.10494v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lukasik_M/0/1/0/all/0/1">Michal Lukasik</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1">Srinadh Bhojanapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1">Aditya Krishna Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sanjiv Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10494">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation is widely used as a means of improving the performance
of a relatively simple student model using the predictions from a complex
teacher model. Several works have shown that distillation significantly boosts
the student&#x27;s overall performance; however, are these gains uniform across all
data subgroups? In this paper, we show that distillation can harm performance
on certain subgroups, e.g., classes with few associated samples. We trace this
behaviour to errors made by the teacher distribution being transferred to and
amplified by the student model. To mitigate this problem, we present techniques
which soften the teacher influence for subgroups where it is less reliable.
Experiments on several image classification benchmarks show that these
modifications of distillation maintain boost in overall accuracy, while
additionally ensuring improvement in subgroup performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-world Ride-hailing Vehicle Repositioning using Deep Reinforcement Learning. (arXiv:2103.04555v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yan Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaocheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhiwei Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuaiji Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hongtu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jieping Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04555">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new practical framework based on deep reinforcement learning and
decision-time planning for real-world vehicle repositioning on ride-hailing (a
type of mobility-on-demand, MoD) platforms. Our approach learns the
spatiotemporal state-value function using a batch training algorithm with deep
value networks. The optimal repositioning action is generated on-demand through
value-based policy search, which combines planning and bootstrapping with the
value networks. For the large-fleet problems, we develop several algorithmic
features that we incorporate into our framework and that we demonstrate to
induce coordination among the algorithmically-guided vehicles. We benchmark our
algorithm with baselines in a ride-hailing simulation environment to
demonstrate its superiority in improving income efficiency meausred by
income-per-hour. We have also designed and run a real-world experiment program
with regular drivers on a major ride-hailing platform. We have observed
significantly positive results on key metrics comparing our method with
experienced drivers who performed idle-time repositioning based on their own
expertise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-based Conditional Variational Autoencoder for Controllable Story Generation. (arXiv:2101.00828v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1">Le Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_T/0/1/0/all/0/1">Tao Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chaochun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bo_L/0/1/0/all/0/1">Liefeng Bo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1">Wen Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Changyou Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00828">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate large-scale latent variable models (LVMs) for neural story
generation -- an under-explored application for open-domain long text -- with
objectives in two threads: generation effectiveness and controllability. LVMs,
especially the variational autoencoder (VAE), have achieved both effective and
controllable generation through exploiting flexible distributional latent
representations. Recently, Transformers and its variants have achieved
remarkable effectiveness without explicit latent representation learning, thus
lack satisfying controllability in generation. In this paper, we advocate to
revive latent variable modeling, essentially the power of representation
learning, in the era of Transformers to enhance controllability without hurting
state-of-the-art generation effectiveness. Specifically, we integrate latent
representation vectors with a Transformer-based pre-trained architecture to
build conditional variational autoencoder (CVAE). Model components such as
encoder, decoder and the variational posterior are all built on top of
pre-trained language models -- GPT2 specifically in this paper. Experiments
demonstrate state-of-the-art conditional generation ability of our model, as
well as its excellent representation learning capability and controllability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Defending Against Multiple and Unforeseen Adversarial Videos. (arXiv:2009.05244v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1">Shao-Yuan Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05244">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial robustness of deep neural networks has been actively
investigated. However, most existing defense approaches are limited to a
specific type of adversarial perturbations. Specifically, they often fail to
offer resistance to multiple attack types simultaneously, i.e., they lack
multi-perturbation robustness. Furthermore, compared to image recognition
problems, the adversarial robustness of video recognition models is relatively
unexplored. While several studies have proposed how to generate adversarial
videos, only a handful of approaches about the defense strategies have been
published in the literature. In this paper, we propose one of the first defense
strategies against multiple types of adversarial videos for video recognition.
The proposed method, referred to as MultiBN, performs adversarial training on
multiple adversarial video types using multiple independent batch normalization
(BN) layers with a learning-based BN selection module. With a multiple BN
structure, each BN brach is responsible for learning the distribution of a
single perturbation type and thus provides more precise distribution
estimations. This mechanism benefits dealing with multiple perturbation types.
The BN selection module detects the attack type of an input video and sends it
to the corresponding BN branch, making MultiBN fully automatic and allow
end-to-end training. Compared to present adversarial training approaches, the
proposed MultiBN exhibits stronger multi-perturbation robustness against
different and even unforeseen adversarial video types, ranging from Lp-bounded
attacks and physically realizable attacks. This holds true on different
datasets and target models. Moreover, we conduct an extensive analysis to study
the properties of the multiple BN structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flexibly Regularized Mixture Models and Application to Image Segmentation. (arXiv:1905.10629v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vacher_J/0/1/0/all/0/1">Jonathan Vacher</a>, <a href="http://arxiv.org/find/cs/1/au:+Launay_C/0/1/0/all/0/1">Claire Launay</a>, <a href="http://arxiv.org/find/cs/1/au:+Coen_Cagli_R/0/1/0/all/0/1">Ruben Coen-Cagli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10629">
                                    <div class="article-summary-box-inner">
                                        <span>Probabilistic finite mixture models are widely used for unsupervised
clustering. These models can often be improved by adapting them to the topology
of the data. For instance, in order to classify spatially adjacent data points
similarly, it is common to introduce a Laplacian constraint on the posterior
probability that each data point belongs to a class. Alternatively, the mixing
probabilities can be treated as free parameters, while assuming Gauss-Markov or
more complex priors to regularize those mixing probabilities. However, these
approaches are constrained by the shape of the prior and often lead to
complicated or intractable inference. Here, we propose a new parametrization of
the Dirichlet distribution to flexibly regularize the mixing probabilities of
over-parametrized mixture distributions. Using the Expectation-Maximization
algorithm, we show that our approach allows us to define any linear update rule
for the mixing probabilities, including spatial smoothing regularization as a
special case. We then show that this flexible design can be extended to share
class information between multiple mixture models. We apply our algorithm to
artificial and natural image segmentation tasks, and we provide quantitative
and qualitative comparison of the performance of Gaussian and Student-t
mixtures on the Berkeley Segmentation Dataset. We also demonstrate how to
propagate class information across the layers of deep convolutional neural
networks in a probabilistically optimal way, suggesting a new interpretation
for feedback signals in biological visual systems. Our flexible approach can be
easily generalized to adapt probabilistic mixture models to arbitrary data
topologies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Effectiveness and Efficiency of Stochastic Neighbour Embedding with Isolation Kernel. (arXiv:1906.09744v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Ye Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ting_K/0/1/0/all/0/1">Kai Ming Ting</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.09744">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new insight into improving the performance of
Stochastic Neighbour Embedding (t-SNE) by using Isolation kernel instead of
Gaussian kernel. Isolation kernel outperforms Gaussian kernel in two aspects.
First, the use of Isolation kernel in t-SNE overcomes the drawback of
misrepresenting some structures in the data, which often occurs when Gaussian
kernel is applied in t-SNE. This is because Gaussian kernel determines each
local bandwidth based on one local point only, while Isolation kernel is
derived directly from the data based on space partitioning. Second, the use of
Isolation kernel yields a more efficient similarity computation because
data-dependent Isolation kernel has only one parameter that needs to be tuned.
In contrast, the use of data-independent Gaussian kernel increases the
computational cost by determining n bandwidths for a dataset of n points. As
the root cause of these deficiencies in t-SNE is Gaussian kernel, we show that
simply replacing Gaussian kernel with Isolation kernel in t-SNE significantly
improves the quality of the final visualisation output (without creating
misrepresented structures) and removes one key obstacle that prevents t-SNE
from processing large datasets. Moreover, Isolation kernel enables t-SNE to
deal with large-scale datasets in less runtime without trading off accuracy,
unlike existing methods in speeding up t-SNE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Matrix Factorization with Grouping Effect. (arXiv:2106.13681v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Haiyan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Luwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13681">
                                    <div class="article-summary-box-inner">
                                        <span>Although many techniques have been applied to matrix factorization (MF), they
may not fully exploit the feature structure. In this paper, we incorporate the
grouping effect into MF and propose a novel method called Robust Matrix
Factorization with Grouping effect (GRMF). The grouping effect is a
generalization of the sparsity effect, which conducts denoising by clustering
similar values around multiple centers instead of just around 0. Compared with
existing algorithms, the proposed GRMF can automatically learn the grouping
structure and sparsity in MF without prior knowledge, by introducing a
naturally adjustable non-convex regularization to achieve simultaneous sparsity
and grouping effect. Specifically, GRMF uses an efficient alternating
minimization framework to perform MF, in which the original non-convex problem
is first converted into a convex problem through Difference-of-Convex (DC)
programming, and then solved by Alternating Direction Method of Multipliers
(ADMM). In addition, GRMF can be easily extended to the Non-negative Matrix
Factorization (NMF) settings. Extensive experiments have been conducted using
real-world data sets with outliers and contaminated noise, where the
experimental results show that GRMF has promoted performance and robustness,
compared to five benchmark algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consensus Clustering With Unsupervised Representation Learning. (arXiv:2010.01245v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Regatti_J/0/1/0/all/0/1">Jayanth Reddy Regatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshmukh_A/0/1/0/all/0/1">Aniket Anand Deshmukh</a>, <a href="http://arxiv.org/find/cs/1/au:+Manavoglu_E/0/1/0/all/0/1">Eren Manavoglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dogan_U/0/1/0/all/0/1">Urun Dogan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01245">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep clustering and unsupervised representation learning
are based on the idea that different views of an input image (generated through
data augmentation techniques) must either be closer in the representation
space, or have a similar cluster assignment. Bootstrap Your Own Latent (BYOL)
is one such representation learning algorithm that has achieved
state-of-the-art results in self-supervised image classification on ImageNet
under the linear evaluation protocol. However, the utility of the learnt
features of BYOL to perform clustering is not explored. In this work, we study
the clustering ability of BYOL and observe that features learnt using BYOL may
not be optimal for clustering. We propose a novel consensus clustering based
loss function, and train BYOL with the proposed loss in an end-to-end way that
improves the clustering ability and outperforms similar clustering based
methods on some popular computer vision datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification of Urban Morphology with Deep Learning: Application on Urban Vitality. (arXiv:2105.09908v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wangyang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1">Abraham Noah Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Biljecki_F/0/1/0/all/0/1">Filip Biljecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09908">
                                    <div class="article-summary-box-inner">
                                        <span>There is a prevailing trend to study urban morphology quantitatively thanks
to the growing accessibility to various forms of spatial big data, increasing
computing power, and use cases benefiting from such information. The methods
developed up to now measure urban morphology with numerical indices describing
density, proportion, and mixture, but they do not directly represent
morphological features from the human&#x27;s visual and intuitive perspective. We
take the first step to bridge the gap by proposing a deep learning-based
technique to automatically classify road networks into four classes on a visual
basis. The method is implemented by generating an image of the street network
(Colored Road Hierarchy Diagram), which we introduce in this paper, and
classifying it using a deep convolutional neural network (ResNet-34). The model
achieves an overall classification accuracy of 0.875. Nine cities around the
world are selected as the study areas with their road networks acquired from
OpenStreetMap. Latent subgroups among the cities are uncovered through
clustering on the percentage of each road network category. In the subsequent
part of the paper, we focus on the usability of such classification: we apply
our method in a case study of urban vitality prediction. An advanced tree-based
regression model (LightGBM) is for the first time designated to establish the
relationship between morphological indices and vitality indicators. The effect
of road network classification is found to be small but positively associated
with urban vitality. This work expands the toolkit of quantitative urban
morphology study with new techniques, supporting further studies in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Multi-Step Critiquing for VAE-based Recommender Systems. (arXiv:2105.00774v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antognini_D/0/1/0/all/0/1">Diego Antognini</a>, <a href="http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1">Boi Faltings</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00774">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies have shown that providing personalized explanations alongside
recommendations increases trust and perceived quality. Furthermore, it gives
users an opportunity to refine the recommendations by critiquing parts of the
explanations. On one hand, current recommender systems model the
recommendation, explanation, and critiquing objectives jointly, but this
creates an inherent trade-off between their respective performance. On the
other hand, although recent latent linear critiquing approaches are built upon
an existing recommender system, they suffer from computational inefficiency at
inference due to the objective optimized at each conversation&#x27;s turn. We
address these deficiencies with M&amp;Ms-VAE, a novel variational autoencoder for
recommendation and explanation that is based on multimodal modeling
assumptions. We train the model under a weak supervision scheme to simulate
both fully and partially observed variables. Then, we leverage the
generalization ability of a trained M&amp;Ms-VAE model to embed the user preference
and the critique separately. Our work&#x27;s most important innovation is our
critiquing module, which is built upon and trained in a self-supervised manner
with a simple ranking objective. Experiments on four real-world datasets
demonstrate that among state-of-the-art models, our system is the first to
dominate or match the performance in terms of recommendation, explanation, and
multi-step critiquing. Moreover, M&amp;Ms-VAE processes the critiques up to 25.6x
faster than the best baselines. Finally, we show that our model infers coherent
joint and cross generation, even under weak supervision, thanks to our
multimodal-based modeling and training scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ChemRL-GEM: Geometry Enhanced Molecular Representation Learning for Property Prediction. (arXiv:2106.06130v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xiaomin Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lihang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jieqiong Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Donglong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanzhuo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingbo Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haifeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06130">
                                    <div class="article-summary-box-inner">
                                        <span>Effective molecular representation learning is of great importance to
facilitate molecular property prediction, which is a fundamental task for the
drug and material industry. Recent advances in graph neural networks (GNNs)
have shown great promise in applying GNNs for molecular representation
learning. Moreover, a few recent studies have also demonstrated successful
applications of self-supervised learning methods to pre-train the GNNs to
overcome the problem of insufficient labeled molecules. However, existing GNNs
and pre-training strategies usually treat molecules as topological graph data
without fully utilizing the molecular geometry information. Whereas, the
three-dimensional (3D) spatial structure of a molecule, a.k.a molecular
geometry, is one of the most critical factors for determining molecular
physical, chemical, and biological properties. To this end, we propose a novel
Geometry Enhanced Molecular representation learning method (GEM) for Chemical
Representation Learning (ChemRL). At first, we design a geometry-based GNN
architecture that simultaneously models atoms, bonds, and bond angles in a
molecule. To be specific, we devised double graphs for a molecule: The first
one encodes the atom-bond relations; The second one encodes bond-angle
relations. Moreover, on top of the devised GNN architecture, we propose several
novel geometry-level self-supervised learning strategies to learn spatial
knowledge by utilizing the local and global molecular 3D structures. We compare
ChemRL-GEM with various state-of-the-art (SOTA) baselines on different
molecular benchmarks and exhibit that ChemRL-GEM can significantly outperform
all baselines in both regression and classification tasks. For example, the
experimental results show an overall improvement of 8.8% on average compared to
SOTA baselines on the regression tasks, demonstrating the superiority of the
proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convergence of Langevin Monte Carlo in Chi-Squared and Renyi Divergence. (arXiv:2007.11612v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Erdogdu_M/0/1/0/all/0/1">Murat A. Erdogdu</a>, <a href="http://arxiv.org/find/stat/1/au:+Hosseinzadeh_R/0/1/0/all/0/1">Rasa Hosseinzadeh</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1">Matthew S. Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.11612">
                                    <div class="article-summary-box-inner">
                                        <span>We study sampling from a target distribution $\nu_* &#x3D; e^{-f}$ using the
unadjusted Langevin Monte Carlo (LMC) algorithm when the potential $f$
satisfies a strong dissipativity condition and it is first-order smooth with a
Lipschitz gradient. We prove that, initialized with a Gaussian random vector
that has sufficiently small variance, iterating the LMC algorithm for
$\widetilde{\mathcal{O}}(\lambda^2 d\epsilon^{-1})$ steps is sufficient to
reach $\epsilon$-neighborhood of the target in both Chi-squared and Renyi
divergence, where $\lambda$ is the logarithmic Sobolev constant of $\nu_*$. Our
results do not require warm-start to deal with the exponential dimension
dependency in Chi-squared divergence at initialization. In particular, for
strongly convex and first-order smooth potentials, we show that the LMC
algorithm achieves the rate estimate $\widetilde{\mathcal{O}}(d\epsilon^{-1})$
which improves the previously known rates in both of these metrics, under the
same assumptions. Translating this rate to other metrics, our results also
recover the state-of-the-art rate estimates in KL divergence, total variation
and $2$-Wasserstein distance in the same setup. Finally, as we rely on the
logarithmic Sobolev inequality, our framework covers a range of non-convex
potentials that are first-order smooth and exhibit strong convexity outside of
a compact region.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AC-VRNN: Attentive Conditional-VRNN for Multi-Future Trajectory Prediction. (arXiv:2005.08307v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bertugli_A/0/1/0/all/0/1">Alessia Bertugli</a>, <a href="http://arxiv.org/find/cs/1/au:+Calderara_S/0/1/0/all/0/1">Simone Calderara</a>, <a href="http://arxiv.org/find/cs/1/au:+Coscia_P/0/1/0/all/0/1">Pasquale Coscia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballan_L/0/1/0/all/0/1">Lamberto Ballan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1">Rita Cucchiara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.08307">
                                    <div class="article-summary-box-inner">
                                        <span>Anticipating human motion in crowded scenarios is essential for developing
intelligent transportation systems, social-aware robots and advanced video
surveillance applications. A key component of this task is represented by the
inherently multi-modal nature of human paths which makes socially acceptable
multiple futures when human interactions are involved. To this end, we propose
a generative architecture for multi-future trajectory predictions based on
Conditional Variational Recurrent Neural Networks (C-VRNNs). Conditioning
mainly relies on prior belief maps, representing most likely moving directions
and forcing the model to consider past observed dynamics in generating future
positions. Human interactions are modeled with a graph-based attention
mechanism enabling an online attentive hidden state refinement of the recurrent
estimation. To corroborate our model, we perform extensive experiments on
publicly-available datasets (e.g., ETH/UCY, Stanford Drone Dataset, STATS
SportVU NBA, Intersection Drone Dataset and TrajNet++) and demonstrate its
effectiveness in crowded scenes compared to several state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GPNAS: A Neural Network Architecture Search Framework Based on Graphical Predictor. (arXiv:2103.11820v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ai_D/0/1/0/all/0/1">Dige Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11820">
                                    <div class="article-summary-box-inner">
                                        <span>In practice, the problems encountered in Neural Architecture Search (NAS)
training are not simple problems, but often a series of difficult combinations
(wrong compensation estimation, curse of dimension, overfitting, high
complexity, etc.). In this paper, we propose a framework to decouple network
structure from operator search space, and use two BOHBs to search
alternatively. Considering that activation function and initialization are also
important parts of neural network, the generalization ability of the model will
be affected. We introduce an activation function and an initialization method
domain, and add them into the operator search space to form a generalized
search space, so as to improve the generalization ability of the child model.
We then trained a GCN-based predictor using feedback from the child model. This
can not only improve the search efficiency, but also solve the problem of
dimension curse. Next, unlike other NAS studies, we used predictors to analyze
the stability of different network structures. Finally, we applied our
framework to neural structure search and achieved significant improvements on
multiple datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchpress: a scalable and platform-independent workflow for benchmarking structure learning algorithms for graphical models. (arXiv:2107.03863v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rios_F/0/1/0/all/0/1">Felix L. Rios</a>, <a href="http://arxiv.org/find/stat/1/au:+Moffa_G/0/1/0/all/0/1">Giusi Moffa</a>, <a href="http://arxiv.org/find/stat/1/au:+Kuipers_J/0/1/0/all/0/1">Jack Kuipers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03863">
                                    <div class="article-summary-box-inner">
                                        <span>Describing the relationship between the variables in a study domain and
modelling the data generating mechanism is a fundamental problem in many
empirical sciences. Probabilistic graphical models are one common approach to
tackle the problem. Learning the graphical structure is computationally
challenging and a fervent area of current research with a plethora of
algorithms being developed. To facilitate the benchmarking of different
methods, we present a novel automated workflow, called benchpress for producing
scalable, reproducible, and platform-independent benchmarks of structure
learning algorithms for probabilistic graphical models. Benchpress is
interfaced via a simple JSON-file, which makes it accessible for all users,
while the code is designed in a fully modular fashion to enable researchers to
contribute additional methodologies. Benchpress currently provides an interface
to a large number of state-of-the-art algorithms from libraries such as BiDAG,
bnlearn, GOBNILP, pcalg, r.blip, scikit-learn, TETRAD, and trilearn as well as
a variety of methods for data generating models and performance evaluation.
Alongside user-defined models and randomly generated datasets, the software
tool also includes a number of standard datasets and graphical models from the
literature, which may be included in a benchmarking workflow. We demonstrate
the applicability of this workflow for learning Bayesian networks in four
typical data scenarios. The source code and documentation is publicly available
from this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identification and Adaptation with Binary-Valued Observations under Non-Persistent Excitation Condition. (arXiv:2107.03588v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_L/0/1/0/all/0/1">Lantian Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Y/0/1/0/all/0/1">Yanlong Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Guo_L/0/1/0/all/0/1">Lei Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03588">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamical systems with binary-valued observations are widely used in
information industry, technology of biological pharmacy and other fields.
Though there have been much efforts devoted to the identification of such
systems, most of the previous investigations are based on first-order gradient
algorithm which usually has much slower convergence rate than the Quasi-Newton
algorithm. Moreover, persistence of excitation(PE) conditions are usually
required to guarantee consistent parameter estimates in the existing
literature, which are hard to be verified or guaranteed for feedback control
systems. In this paper, we propose an online projected Quasi-Newton type
algorithm for parameter estimation of stochastic regression models with
binary-valued observations and varying thresholds. By using both the stochastic
Lyapunov function and martingale estimation methods, we establish the strong
consistency of the estimation algorithm and provide the convergence rate, under
a signal condition which is considerably weaker than the traditional PE
condition and coincides with the weakest possible excitation known for the
classical least square algorithm of stochastic regression models. Convergence
of adaptive predictors and their applications in adaptive control are also
discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Direct detection of plasticity onset through total-strain profile evolution. (arXiv:2107.03738v1 [cond-mat.mtrl-sci])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Papanikolaou_S/0/1/0/all/0/1">Stefanos Papanikolaou</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Alava_M/0/1/0/all/0/1">Mikko J. Alava</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03738">
                                    <div class="article-summary-box-inner">
                                        <span>Plastic yielding in solids strongly depends on various conditions, such as
temperature and loading rate and indeed, sample-dependent knowledge of yield
points in structural materials promotes reliability in mechanical behavior.
Commonly, yielding is measured through controlled mechanical testing at small
or large scales, in ways that either distinguish elastic (stress) from total
deformation measurements, or by identifying plastic slip contributions. In this
paper we argue that instead of separate elastic/plastic measurements, yielding
can be unraveled through statistical analysis of total strain fluctuations
during the evolution sequence of profiles measured in-situ, through digital
image correlation. We demonstrate two distinct ways of precisely quantifying
yield locations in widely applicable crystal plasticity models, that apply in
polycrystalline solids, either by using principal component analysis or
discrete wavelet transforms. We test and compare these approaches in synthetic
data of polycrystal simulations and a variety of yielding responses, through
changes of the applied loading rates and the strain-rate sensitivity exponents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline Meta-Reinforcement Learning with Online Self-Supervision. (arXiv:2107.03974v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pong_V/0/1/0/all/0/1">Vitchyr H. Pong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1">Ashvin Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1">Laura Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Catherine Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03974">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-reinforcement learning (RL) can be used to train policies that quickly
adapt to new tasks with orders of magnitude less data than standard RL, but
this fast adaptation often comes at the cost of greatly increasing the amount
of reward supervision during meta-training time. Offline meta-RL removes the
need to continuously provide reward supervision because rewards must only be
provided once when the offline dataset is generated. In addition to the
challenges of offline RL, a unique distribution shift is present in meta RL:
agents learn exploration strategies that can gather the experience needed to
learn a new task, and also learn adaptation strategies that work well when
presented with the trajectories in the dataset, but the adaptation strategies
are not adapted to the data distribution that the learned exploration
strategies collect. Unlike the online setting, the adaptation and exploration
strategies cannot effectively adapt to each other, resulting in poor
performance. In this paper, we propose a hybrid offline meta-RL algorithm,
which uses offline data with rewards to meta-train an adaptive policy, and then
collects additional unsupervised online data, without any ground truth reward
labels, to bridge this distribution shift problem. Our method uses the offline
data to learn the distribution of reward functions, which is then sampled to
self-supervise reward labels for the additional online data. By removing the
need to provide reward labels for the online experience, our approach can be
more practical to use in settings where reward supervision would otherwise be
provided manually. We compare our method to prior work on offline meta-RL on
simulated robot locomotion and manipulation tasks and find that using
additional data and self-generated rewards significantly improves an agent&#x27;s
ability to generalize.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Management of Resource at the Network Edge for Federated Learning. (arXiv:2107.03428v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trindade_S/0/1/0/all/0/1">Silvana Trindade</a>, <a href="http://arxiv.org/find/cs/1/au:+Bittencourt_L/0/1/0/all/0/1">Luiz F. Bittencourt</a>, <a href="http://arxiv.org/find/cs/1/au:+Fonseca_N/0/1/0/all/0/1">Nelson L. S. da Fonseca</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03428">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning has been explored as a promising solution for training at
the edge, where end devices collaborate to train models without sharing data
with other entities. Since the execution of these learning models occurs at the
edge, where resources are limited, new solutions must be developed. In this
paper, we describe the recent work on resource management at the edge, and
explore the challenges and future directions to allow the execution of
federated learning at the edge. Some of the problems of this management, such
as discovery of resources, deployment, load balancing, migration, and energy
efficiency will be discussed in the paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recurrence-Aware Long-Term Cognitive Network for Explainable Pattern Classification. (arXiv:2107.03423v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Napoles_G/0/1/0/all/0/1">Gonzalo N&#xe1;poles</a>, <a href="http://arxiv.org/find/cs/1/au:+Salgueiro_Y/0/1/0/all/0/1">Yamisleydi Salgueiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Grau_I/0/1/0/all/0/1">Isel Grau</a>, <a href="http://arxiv.org/find/cs/1/au:+Espinosa_M/0/1/0/all/0/1">Maikel Leon Espinosa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03423">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning solutions for pattern classification problems are nowadays
widely deployed in society and industry. However, the lack of transparency and
accountability of most accurate models often hinders their meaningful and safe
use. Thus, there is a clear need for developing explainable artificial
intelligence mechanisms. There exist model-agnostic methods that summarize
feature contributions, but their interpretability is limited to specific
predictions made by black-box models. An open challenge is to develop models
that have intrinsic interpretability and produce their own explanations, even
for classes of models that are traditionally considered black boxes like
(recurrent) neural networks. In this paper, we propose an LTCN-based model for
interpretable pattern classification of structured data. Our method brings its
own mechanism for providing explanations by quantifying the relevance of each
feature in the decision process. For supporting the interpretability without
affecting the performance, the model incorporates more flexibility through a
quasi-nonlinear reasoning rule that allows controlling nonlinearity. Besides,
we propose a recurrence-aware decision model that evades the issues posed by
unique fixed points while introducing a deterministic learning method to
compute the learnable parameters. The simulations show that our interpretable
model obtains competitive performance when compared to the state-of-the-art
white and black boxes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generative Model for Raw Audio Using Transformer Architectures. (arXiv:2106.16036v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1">Prateek Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chafe_C/0/1/0/all/0/1">Chris Chafe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16036">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel way of doing audio synthesis at the waveform
level using Transformer architectures. We propose a deep neural network for
generating waveforms, similar to wavenet. This is fully probabilistic,
auto-regressive, and causal, i.e. each sample generated depends only on the
previously observed samples. Our approach outperforms a widely used wavenet
architecture by up to 9% on a similar dataset for predicting the next step.
Using the attention mechanism, we enable the architecture to learn which audio
samples are important for the prediction of the future sample. We show how
causal transformer generative models can be used for raw waveform synthesis. We
also show that this performance can be improved by another 2% by conditioning
samples over a wider context. The flexibility of the current model to
synthesize audio from latent representations suggests a large number of
potential applications. The novel approach of using generative transformer
architectures for raw audio synthesis is, however, still far away from
generating any meaningful music, without using latent codes/meta-data to aid
the generation process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy Efficient Federated Learning in Integrated Fog-Cloud Computing Enabled Internet-of-Things Networks. (arXiv:2107.03520v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Al_Abiad_M/0/1/0/all/0/1">Mohammed S. Al-Abiad</a>, <a href="http://arxiv.org/find/eess/1/au:+Hassan_M/0/1/0/all/0/1">Md. Zoheb Hassan</a>, <a href="http://arxiv.org/find/eess/1/au:+Hossain_M/0/1/0/all/0/1">Md. Jahangir Hossain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03520">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate resource allocation scheme to reduce the energy consumption of
federated learning (FL) in the integrated fog-cloud computing enabled
Internet-of-things (IoT) networks. In the envisioned system, IoT devices are
connected with the centralized cloud server (CS) via multiple fog access points
(F-APs). We consider two different scenarios for training the local models. In
the first scenario, local models are trained at the IoT devices and the F-APs
upload the local model parameters to the CS. In the second scenario, local
models are trained at the F-APs based on the collected data from the IoT
devices and the F-APs collaborate with the CS for updating the model
parameters. Our objective is to minimize the overall energy-consumption of both
scenarios subject to FL time constraint. Towards this goal, we devise a joint
optimization of scheduling of IoT devices with the F-APs, transmit power
allocation, computation frequency allocation at the devices and F-APs and
decouple it into two subproblems. In the first subproblem, we optimize the IoT
device scheduling and power allocation, while in the second subproblem, we
optimize the computation frequency allocation. For each scenario, we develop a
conflict graph based solution to iteratively solve the two subproblems.
Simulation results show that the proposed two schemes achieve a considerable
performance gain in terms of the energy consumption minimization. The presented
simulation results interestingly reveal that for a large number of IoT devices
and large data sizes, it is more energy efficient to train the local models at
the IoT devices instead of the F-APs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Long Short-Term Memory for AI Applications in Spike-based Neuromorphic Hardware. (arXiv:2107.03992v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Plank_P/0/1/0/all/0/1">Philipp Plank</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1">Arjun Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wild_A/0/1/0/all/0/1">Andreas Wild</a>, <a href="http://arxiv.org/find/cs/1/au:+Maass_W/0/1/0/all/0/1">Wolfgang Maass</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03992">
                                    <div class="article-summary-box-inner">
                                        <span>In spite of intensive efforts it has remained an open problem to what extent
current Artificial Intelligence (AI) methods that employ Deep Neural Networks
(DNNs) can be implemented more energy-efficiently on spike-based neuromorphic
hardware. This holds in particular for AI methods that solve sequence
processing tasks, a primary application target for spike-based neuromorphic
hardware. One difficulty is that DNNs for such tasks typically employ Long
Short-Term Memory (LSTM) units. Yet an efficient emulation of these units in
spike-based hardware has been missing. We present a biologically inspired
solution that solves this problem. This solution enables us to implement a
major class of DNNs for sequence processing tasks such as time series
classification and question answering with substantial energy savings on
neuromorphic hardware. In fact, the Relational Network for reasoning about
relations between objects that we use for question answering is the first
example of a large DNN that carries out a sequence processing task with
substantial energy-saving on neuromorphic hardware.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Likelihood-Free Frequentist Inference: Bridging Classical Statistics and Machine Learning in Simulation and Uncertainty Quantification. (arXiv:2107.03920v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dalmasso_N/0/1/0/all/0/1">Niccol&#xf2; Dalmasso</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhao_D/0/1/0/all/0/1">David Zhao</a>, <a href="http://arxiv.org/find/stat/1/au:+Izbicki_R/0/1/0/all/0/1">Rafael Izbicki</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_A/0/1/0/all/0/1">Ann B. Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03920">
                                    <div class="article-summary-box-inner">
                                        <span>Many areas of science make extensive use of computer simulators that
implicitly encode likelihood functions for complex systems. Classical
statistical methods are poorly suited for these so-called likelihood-free
inference (LFI) settings, outside the asymptotic and low-dimensional regimes.
Although new machine learning methods, such as normalizing flows, have
revolutionized the sample efficiency and capacity of LFI methods, it remains an
open question whether they produce reliable measures of uncertainty. In this
paper, we present a statistical framework for LFI that unifies classical
statistics with modern machine learning to: (1) construct frequentist
confidence sets and hypothesis tests with finite-sample guarantees of nominal
coverage (type I error control) and power, and (2) provide rigorous diagnostics
for assessing empirical coverage over the entire parameter space. We refer to
our framework as likelihood-free frequentist inference (LF2I). Any method that
estimates a test statistic, such as the likelihood ratio, can be plugged into
our framework to create powerful tests and confidence sets with correct
coverage. In this work, we specifically study two test statistics (ACORE and
BFF), which, respectively, maximize versus integrate an odds function over the
parameter space. Our theoretical and empirical results offer multifaceted
perspectives on error sources and challenges in likelihood-free frequentist
inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Matrix Sketching for Secure Collaborative Machine Learning. (arXiv:1909.11201v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mengjiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shusen Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.11201">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative learning allows participants to jointly train a model without
data sharing. To update the model parameters, the central server broadcasts
model parameters to the clients, and the clients send updating directions such
as gradients to the server. While data do not leave a client device, the
communicated gradients and parameters will leak a client&#x27;s privacy. Attacks
that infer clients&#x27; privacy from gradients and parameters have been developed
by prior work. Simple defenses such as dropout and differential privacy either
fail to defend the attacks or seriously hurt test accuracy.

We propose a practical defense which we call Double-Blind Collaborative
Learning (DBCL). The high-level idea is to apply random matrix sketching to the
parameters (aka weights) and re-generate random sketching after each iteration.
DBCL prevents clients from conducting gradient-based privacy inferences which
are the most effective attacks. DBCL works because from the attacker&#x27;s
perspective, sketching is effectively random noise that outweighs the signal.
Notably, DBCL does not much increase computation and communication costs and
does not hurt test accuracy at all.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Design Smells in Deep Learning Programs: An Empirical Study. (arXiv:2107.02279v2 [cs.SE] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikanjam_A/0/1/0/all/0/1">Amin Nikanjam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02279">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, we are witnessing an increasing adoption of Deep Learning (DL)
based software systems in many industries. Designing a DL program requires
constructing a deep neural network (DNN) and then training it on a dataset.
This process requires that developers make multiple architectural (e.g., type,
size, number, and order of layers) and configuration (e.g., optimizer,
regularization methods, and activation functions) choices that affect the
quality of the DL models, and consequently software quality. An under-specified
or poorly-designed DL model may train successfully but is likely to perform
poorly when deployed in production. Design smells in DL programs are poor
design and-or configuration decisions taken during the development of DL
components, that are likely to have a negative impact on the performance (i.e.,
prediction accuracy) and then quality of DL based software systems. In this
paper, we present a catalogue of 8 design smells for a popular DL architecture,
namely deep Feedforward Neural Networks which is widely employed in industrial
applications. The design smells were identified through a review of the
existing literature on DL design and a manual inspection of 659 DL programs
with performance issues and design inefficiencies. The smells are specified by
describing their context, consequences, and recommended refactorings. To
provide empirical evidence on the relevance and perceived impact of the
proposed design smells, we conducted a survey with 81 DL developers. In
general, the developers perceived the proposed design smells as reflective of
design or implementation problems, with agreement levels varying between 47\%
and 68\%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Malware Classification Using Deep Boosted Learning. (arXiv:2107.04008v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asam_M/0/1/0/all/0/1">Muhammad Asam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Saddam Hussain Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamal_T/0/1/0/all/0/1">Tauseef Jamal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zahoora_U/0/1/0/all/0/1">Umme Zahoora</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Asifullah Khan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04008">
                                    <div class="article-summary-box-inner">
                                        <span>Malicious activities in cyberspace have gone further than simply hacking
machines and spreading viruses. It has become a challenge for a nations
survival and hence has evolved to cyber warfare. Malware is a key component of
cyber-crime, and its analysis is the first line of defence against attack. This
work proposes a novel deep boosted hybrid learning-based malware classification
framework and named as Deep boosted Feature Space-based Malware classification
(DFS-MC). In the proposed framework, the discrimination power is enhanced by
fusing the feature spaces of the best performing customized CNN architectures
models and its discrimination by an SVM for classification. The discrimination
capacity of the proposed classification framework is assessed by comparing it
against the standard customized CNNs. The customized CNN models are implemented
in two ways: softmax classifier and deep hybrid learning-based malware
classification. In the hybrid learning, Deep features are extracted from
customized CNN architectures and fed into the conventional machine learning
classifier to improve the classification performance. We also introduced the
concept of transfer learning in a customized CNN architecture based malware
classification framework through fine-tuning. The performance of the proposed
malware classification approaches are validated on the MalImg malware dataset
using the hold-out cross-validation technique. Experimental comparisons were
conducted by employing innovative, customized CNN, trained from scratch and
fine-tuning the customized CNN using transfer learning. The proposed
classification framework DFS-MC showed improved results, Accuracy: 98.61%,
F-score: 0.96, Precision: 0.96, and Recall: 0.96.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Digitizing Handwriting with a Sensor Pen: A Writer-Independent Recognizer. (arXiv:2107.03704v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wehbi_M/0/1/0/all/0/1">Mohamad Wehbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamann_T/0/1/0/all/0/1">Tim Hamann</a>, <a href="http://arxiv.org/find/cs/1/au:+Barth_J/0/1/0/all/0/1">Jens Barth</a>, <a href="http://arxiv.org/find/cs/1/au:+Eskofier_B/0/1/0/all/0/1">Bjoern Eskofier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03704">
                                    <div class="article-summary-box-inner">
                                        <span>Online handwriting recognition has been studied for a long time with only few
practicable results when writing on normal paper. Previous approaches using
sensor-based devices encountered problems that limited the usage of the
developed systems in real-world applications. This paper presents a
writer-independent system that recognizes characters written on plain paper
with the use of a sensor-equipped pen. This system is applicable in real-world
applications and requires no user-specific training for recognition. The pen
provides linear acceleration, angular velocity, magnetic field, and force
applied by the user, and acts as a digitizer that transforms the analogue
signals of the sensors into timeseries data while writing on regular paper. The
dataset we collected with this pen consists of Latin lower-case and upper-case
alphabets. We present the results of a convolutional neural network model for
letter classification and show that this approach is practical and achieves
promising results for writer-independent character recognition. This work aims
at providing a realtime handwriting recognition system to be used for writing
on normal paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-stationary Reinforcement Learning without Prior Knowledge: An Optimal Black-box Approach. (arXiv:2102.05406v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Chen-Yu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haipeng Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05406">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a black-box reduction that turns a certain reinforcement learning
algorithm with optimal regret in a (near-)stationary environment into another
algorithm with optimal dynamic regret in a non-stationary environment,
importantly without any prior knowledge on the degree of non-stationarity. By
plugging different algorithms into our black-box, we provide a list of examples
showing that our approach not only recovers recent results for (contextual)
multi-armed bandits achieved by very specialized algorithms, but also
significantly improves the state of the art for (generalized) linear bandits,
episodic MDPs, and infinite-horizon MDPs in various ways. Specifically, in most
cases our algorithm achieves the optimal dynamic regret
$\widetilde{\mathcal{O}}(\min\{\sqrt{LT}, \Delta^{1/3}T^{2/3}\})$ where $T$ is
the number of rounds and $L$ and $\Delta$ are the number and amount of changes
of the world respectively, while previous works only obtain suboptimal bounds
and/or require the knowledge of $L$ and $\Delta$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recommendation system using a deep learning and graph analysis approach. (arXiv:2004.08100v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kherad_M/0/1/0/all/0/1">Mahdi Kherad</a>, <a href="http://arxiv.org/find/cs/1/au:+Bidgoly_A/0/1/0/all/0/1">Amir Jalaly Bidgoly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.08100">
                                    <div class="article-summary-box-inner">
                                        <span>When a user connects to the Internet to fulfill his needs, he often
encounters a huge amount of related information. Recommender systems are the
techniques for massively filtering information and offering the items that
users find them satisfying and interesting. The advances in machine learning
methods, especially deep learning, have led to great achievements in
recommender systems, although these systems still suffer from challenges such
as cold-start and sparsity problems. To solve these problems, context
information such as user communication network is usually used. In this paper,
we have proposed a novel recommendation method based on Matrix Factorization
and graph analysis methods. In addition, we leverage deep Autoencoders to
initialize users and items latent factors, and deep embedding method gathers
users&#x27; latent factors from the user trust graph. The proposed method is
implemented on two standard datasets. The experimental results and comparisons
demonstrate that the proposed approach is superior to the existing
state-of-the-art recommendation methods. Our approach outperforms other
comparative methods and achieves great improvements. This work has been
submitted to the IEEE for possible publication. Copyright may be transferred
without notice, after which this version may no longer be accessible</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rating and aspect-based opinion graph embeddings for explainable recommendations. (arXiv:2107.03385v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cantador_I/0/1/0/all/0/1">Iv&#xe1;n Cantador</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvallo_A/0/1/0/all/0/1">Andr&#xe9;s Carvallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Diez_F/0/1/0/all/0/1">Fernando Diez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03385">
                                    <div class="article-summary-box-inner">
                                        <span>The success of neural network embeddings has entailed a renewed interest in
using knowledge graphs for a wide variety of machine learning and information
retrieval tasks. In particular, recent recommendation methods based on graph
embeddings have shown state-of-the-art performance. In general, these methods
encode latent rating patterns and content features. Differently from previous
work, in this paper, we propose to exploit embeddings extracted from graphs
that combine information from ratings and aspect-based opinions expressed in
textual reviews. We then adapt and evaluate state-of-the-art graph embedding
techniques over graphs generated from Amazon and Yelp reviews on six domains,
outperforming baseline recommenders. Additionally, our method has the advantage
of providing explanations that involve the coverage of aspect-based opinions
given by users about recommended items.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Machine Learning Approach to Safer Airplane Landings: Predicting Runway Conditions using Weather and Flight Data. (arXiv:2107.04010v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Midtfjord_A/0/1/0/all/0/1">Alise Danielle Midtfjord</a>, <a href="http://arxiv.org/find/cs/1/au:+Bin_R/0/1/0/all/0/1">Riccardo De Bin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huseby_A/0/1/0/all/0/1">Arne Bang Huseby</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04010">
                                    <div class="article-summary-box-inner">
                                        <span>The presence of snow and ice on runway surfaces reduces the available
tire-pavement friction needed for retardation and directional control and
causes potential economic and safety threats for the aviation industry during
the winter seasons. To activate appropriate safety procedures, pilots need
accurate and timely information on the actual runway surface conditions. In
this study, XGBoost is used to create a combined runway assessment system,
which includes a classifcation model to predict slippery conditions and a
regression model to predict the level of slipperiness. The models are trained
on weather data and data from runway reports. The runway surface conditions are
represented by the tire-pavement friction coefficient, which is estimated from
flight sensor data from landing aircrafts. To evaluate the performance of the
models, they are compared to several state-of-the-art runway assessment
methods. The XGBoost models identify slippery runway conditions with a ROC AUC
of 0.95, predict the friction coefficient with a MAE of 0.0254, and outperforms
all the previous methods. The results show the strong abilities of machine
learning methods to model complex, physical phenomena with a good accuracy when
domain knowledge is used in the variable extraction. The XGBoost models are
combined with SHAP (SHapley Additive exPlanations) approximations to provide a
comprehensible decision support system for airport operators and pilots, which
can contribute to safer and more economic operations of airport runways.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-organized criticality in neural networks. (arXiv:2107.03402v1 [cond-mat.stat-mech])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Katsnelson_M/0/1/0/all/0/1">Mikhail I. Katsnelson</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Vanchurin_V/0/1/0/all/0/1">Vitaly Vanchurin</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Westerhout_T/0/1/0/all/0/1">Tom Westerhout</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03402">
                                    <div class="article-summary-box-inner">
                                        <span>We demonstrate, both analytically and numerically, that learning dynamics of
neural networks is generically attracted towards a self-organized critical
state. The effect can be modeled with quartic interactions between
non-trainable variables (e.g. states of neurons) and trainable variables (e.g.
weight matrix). Non-trainable variables are rapidly driven towards stochastic
equilibrium and trainable variables are slowly driven towards learning
equilibrium described by a scale-invariant distribution on a wide range of
scales. Our results suggest that the scale invariance observed in many physical
and biological systems might be due to some kind of learning dynamics and
support the claim that the universe might be a neural network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Three Ensemble Clustering (3EC) Algorithm for Pattern Discovery in Unsupervised Learning. (arXiv:2107.03729v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kundu/0/1/0/all/0/1">Kundu</a>, <a href="http://arxiv.org/find/cs/1/au:+Debasish/0/1/0/all/0/1">Debasish</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03729">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a multiple learner algorithm called the &#x27;Three Ensemble
Clustering 3EC&#x27; algorithm that classifies unlabeled data into quality clusters
as a part of unsupervised learning. It offers the flexibility to explore the
context of new clusters formed by an ensemble of algorithms based on internal
validation indices.

It is worth mentioning that the input data set is considered to be a cluster
of clusters. An anomaly can possibly manifest as a cluster as well. Each
partitioned cluster is considered to be a new data set and is a candidate to
explore the most optimal algorithm and its number of partition splits until a
predefined stopping criteria is met. The algorithms independently partition the
data set into clusters and the quality of the partitioning is assessed by an
ensemble of internal cluster validation indices. The 3EC algorithm presents the
validation index scores from a choice of algorithms and its configuration of
partitions and it is called the Tau Grid. 3EC chooses the most optimal score.
The 3EC algorithm owes its name to the two input ensembles of algorithms and
internal validation indices and an output ensemble of final clusters.

Quality plays an important role in this clustering approach and it also acts
as a stopping criteria from further partitioning. Quality is determined based
on the quality of the clusters provided by an algorithm and its optimal number
of splits. The 3EC algorithm determines this from the score of the ensemble of
validation indices. The user can configure the stopping criteria by providing
quality thresholds for the score range of each of the validation indices and
the optimal size of the output cluster. The users can experiment with different
sets of stopping criteria and choose the most &#x27;sensible group&#x27; of quality
clusters</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Output Randomization: A Novel Defense for both White-box and Black-box Adversarial Models. (arXiv:2107.03806v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Daniel Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_H/0/1/0/all/0/1">Haidar Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Azer Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gittens_A/0/1/0/all/0/1">Alex Gittens</a>, <a href="http://arxiv.org/find/cs/1/au:+Yener_B/0/1/0/all/0/1">B&#xfc;lent Yener</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03806">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial examples pose a threat to deep neural network models in a variety
of scenarios, from settings where the adversary has complete knowledge of the
model in a &quot;white box&quot; setting and to the opposite in a &quot;black box&quot; setting. In
this paper, we explore the use of output randomization as a defense against
attacks in both the black box and white box models and propose two defenses. In
the first defense, we propose output randomization at test time to thwart
finite difference attacks in black box settings. Since this type of attack
relies on repeated queries to the model to estimate gradients, we investigate
the use of randomization to thwart such adversaries from successfully creating
adversarial examples. We empirically show that this defense can limit the
success rate of a black box adversary using the Zeroth Order Optimization
attack to 0%. Secondly, we propose output randomization training as a defense
against white box adversaries. Unlike prior approaches that use randomization,
our defense does not require its use at test time, eliminating the Backward
Pass Differentiable Approximation attack, which was shown to be effective
against other randomization defenses. Additionally, this defense has low
overhead and is easily implemented, allowing it to be used together with other
defenses across various model architectures. We evaluate output randomization
training against the Projected Gradient Descent attacker and show that the
defense can reduce the PGD attack&#x27;s success rate down to 12% when using
cross-entropy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Community detection in the sparse hypergraph stochastic block model. (arXiv:1904.05981v6 [math.PR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Pal_S/0/1/0/all/0/1">Soumik Pal</a>, <a href="http://arxiv.org/find/math/1/au:+Zhu_Y/0/1/0/all/0/1">Yizhe Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.05981">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the community detection problem in sparse random hypergraphs.
Angelini et al. (2015) conjectured the existence of a sharp threshold on model
parameters for community detection in sparse hypergraphs generated by a
hypergraph stochastic block model. We solve the positive part of the conjecture
for the case of two blocks: above the threshold, there is a spectral algorithm
which asymptotically almost surely constructs a partition of the hypergraph
correlated with the true partition. Our method is a generalization to random
hypergraphs of the method developed by Massouli\&#x27;{e} (2014) for sparse random
graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imitation by Predicting Observations. (arXiv:2107.03851v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jaegle_A/0/1/0/all/0/1">Andrew Jaegle</a>, <a href="http://arxiv.org/find/cs/1/au:+Sulsky_Y/0/1/0/all/0/1">Yury Sulsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahuja_A/0/1/0/all/0/1">Arun Ahuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruce_J/0/1/0/all/0/1">Jake Bruce</a>, <a href="http://arxiv.org/find/cs/1/au:+Fergus_R/0/1/0/all/0/1">Rob Fergus</a>, <a href="http://arxiv.org/find/cs/1/au:+Wayne_G/0/1/0/all/0/1">Greg Wayne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03851">
                                    <div class="article-summary-box-inner">
                                        <span>Imitation learning enables agents to reuse and adapt the hard-won expertise
of others, offering a solution to several key challenges in learning behavior.
Although it is easy to observe behavior in the real-world, the underlying
actions may not be accessible. We present a new method for imitation solely
from observations that achieves comparable performance to experts on
challenging continuous control tasks while also exhibiting robustness in the
presence of observations unrelated to the task. Our method, which we call FORM
(for &quot;Future Observation Reward Model&quot;) is derived from an inverse RL objective
and imitates using a model of expert behavior learned by generative modelling
of the expert&#x27;s observations, without needing ground truth actions. We show
that FORM performs comparably to a strong baseline IRL method (GAIL) on the
DeepMind Control Suite benchmark, while outperforming GAIL in the presence of
task-irrelevant features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Optimized Speech Coding with Deep Neural Networks. (arXiv:1710.09064v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kankanahalli_S/0/1/0/all/0/1">Srihari Kankanahalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1710.09064">
                                    <div class="article-summary-box-inner">
                                        <span>Modern compression algorithms are often the result of laborious
domain-specific research; industry standards such as MP3, JPEG, and AMR-WB took
years to develop and were largely hand-designed. We present a deep neural
network model which optimizes all the steps of a wideband speech coding
pipeline (compression, quantization, entropy coding, and decompression)
end-to-end directly from raw speech data -- no manual feature engineering
necessary, and it trains in hours. In testing, our DNN-based coder performs on
par with the AMR-WB standard at a variety of bitrates (~9kbps up to ~24kbps).
It also runs in realtime on a 3.8GhZ Intel CPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MOD-Net: A Machine Learning Approach via Model-Operator-Data Network for Solving PDEs. (arXiv:2107.03673v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Zhang_L/0/1/0/all/0/1">Lulu Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Luo_T/0/1/0/all/0/1">Tao Luo</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1">Yaoyu Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Xu_Z/0/1/0/all/0/1">Zhi-Qin John Xu</a>, <a href="http://arxiv.org/find/math/1/au:+Ma_Z/0/1/0/all/0/1">Zheng Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03673">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a model-operator-data network (MOD-Net) for solving
PDEs. A MOD-Net is driven by a model to solve PDEs based on operator
representation with regularization from data. In this work, we use a deep
neural network to parameterize the Green&#x27;s function. The empirical risk
consists of the mean square of the governing equation, boundary conditions, and
a few labels, which are numerically computed by traditional schemes on coarse
grid points with cheap computation cost. With only the labeled dataset or only
the model constraints, it is insufficient to accurately train a MOD-Net for
complicate problems. Intuitively, the labeled dataset works as a regularization
in addition to the model constraints. The MOD-Net is much efficient than
original neural operator because the MOD-Net also uses the information of
governing equation and the boundary conditions of the PDE rather than purely
the expensive labels. Since the MOD-Net learns the Green&#x27;s function of a PDE,
it solves a type of PDEs but not a specific case. We numerically show MOD-Net
is very efficient in solving Poisson equation and one-dimensional Boltzmann
equation. For non-linear PDEs, where the concept of the Green&#x27;s function does
not apply, the non-linear MOD-Net can be similarly used as an ansatz for
solving non-linear PDEs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptation of Quadruped Robot Locomotion with Meta-Learning. (arXiv:2107.03741v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuzhamuratov_A/0/1/0/all/0/1">Arsen Kuzhamuratov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sorokin_D/0/1/0/all/0/1">Dmitry Sorokin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulanov_A/0/1/0/all/0/1">Alexander Ulanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Lvovsky_A/0/1/0/all/0/1">A. I. Lvovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03741">
                                    <div class="article-summary-box-inner">
                                        <span>Animals have remarkable abilities to adapt locomotion to different terrains
and tasks. However, robots trained by means of reinforcement learning are
typically able to solve only a single task and a transferred policy is usually
inferior to that trained from scratch. In this work, we demonstrate that
meta-reinforcement learning can be used to successfully train a robot capable
to solve a wide range of locomotion tasks. The performance of the meta-trained
robot is similar to that of a robot that is trained on a single task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Time Series Forecasting with Implicit Quantile Networks. (arXiv:2107.03743v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gouttes_A/0/1/0/all/0/1">Ad&#xe8;le Gouttes</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasul_K/0/1/0/all/0/1">Kashif Rasul</a>, <a href="http://arxiv.org/find/cs/1/au:+Koren_M/0/1/0/all/0/1">Mateusz Koren</a>, <a href="http://arxiv.org/find/cs/1/au:+Stephan_J/0/1/0/all/0/1">Johannes Stephan</a>, <a href="http://arxiv.org/find/cs/1/au:+Naghibi_T/0/1/0/all/0/1">Tofigh Naghibi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03743">
                                    <div class="article-summary-box-inner">
                                        <span>Here, we propose a general method for probabilistic time series forecasting.
We combine an autoregressive recurrent neural network to model temporal
dynamics with Implicit Quantile Networks to learn a large class of
distributions over a time-series target. When compared to other probabilistic
neural forecasting models on real- and simulated data, our approach is
favorable in terms of point-wise prediction accuracy as well as on estimating
the underlying temporal distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grid Partitioned Attention: Efficient TransformerApproximation with Inductive Bias for High Resolution Detail Generation. (arXiv:2107.03742v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jetchev_N/0/1/0/all/0/1">Nikolay Jetchev</a>, <a href="http://arxiv.org/find/cs/1/au:+Yildirim_G/0/1/0/all/0/1">G&#xf6;khan Yildirim</a>, <a href="http://arxiv.org/find/cs/1/au:+Bracher_C/0/1/0/all/0/1">Christian Bracher</a>, <a href="http://arxiv.org/find/cs/1/au:+Vollgraf_R/0/1/0/all/0/1">Roland Vollgraf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03742">
                                    <div class="article-summary-box-inner">
                                        <span>Attention is a general reasoning mechanism than can flexibly deal with image
information, but its memory requirements had made it so far impractical for
high resolution image generation. We present Grid Partitioned Attention (GPA),
a new approximate attention algorithm that leverages a sparse inductive bias
for higher computational and memory efficiency in image domains: queries attend
only to few keys, spatially close queries attend to close keys due to
correlations. Our paper introduces the new attention layer, analyzes its
complexity and how the trade-off between memory usage and model power can be
tuned by the hyper-parameters.We will show how such attention enables novel
deep learning architectures with copying modules that are especially useful for
conditional image generation tasks like pose morphing. Our contributions are
(i) algorithm and code1of the novel GPA layer, (ii) a novel deep
attention-copying architecture, and (iii) new state-of-the art experimental
results in human pose morphing generation benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSSE: Efficiently Erasing Samples from Trained Machine Learning Models. (arXiv:2107.03860v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peste_A/0/1/0/all/0/1">Alexandra Peste</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lampert_C/0/1/0/all/0/1">Christoph H. Lampert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03860">
                                    <div class="article-summary-box-inner">
                                        <span>The availability of large amounts of user-provided data has been key to the
success of machine learning for many real-world tasks. Recently, an increasing
awareness has emerged that users should be given more control about how their
data is used. In particular, users should have the right to prohibit the use of
their data for training machine learning systems, and to have it erased from
already trained systems. While several sample erasure methods have been
proposed, all of them have drawbacks which have prevented them from gaining
widespread adoption. Most methods are either only applicable to very specific
families of models, sacrifice too much of the original model&#x27;s accuracy, or
they have prohibitive memory or computational requirements. In this paper, we
propose an efficient and effective algorithm, SSSE, for samples erasure, that
is applicable to a wide class of machine learning models. From a second-order
analysis of the model&#x27;s loss landscape we derive a closed-form update step of
the model parameters that only requires access to the data to be erased, not to
the original training set. Experiments on three datasets, CelebFaces attributes
(CelebA), Animals with Attributes 2 (AwA2) and CIFAR10, show that in certain
cases SSSE can erase samples almost as well as the optimal, yet impractical,
gold standard of training a new model from scratch with only the permitted
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Encoding Domain Information with Sparse Priors for Inferring Explainable Latent Variables. (arXiv:2107.03730v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Qoku_A/0/1/0/all/0/1">Arber Qoku</a>, <a href="http://arxiv.org/find/stat/1/au:+Buettner_F/0/1/0/all/0/1">Florian Buettner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03730">
                                    <div class="article-summary-box-inner">
                                        <span>Latent variable models are powerful statistical tools that can uncover
relevant variation between patients or cells, by inferring unobserved hidden
states from observable high-dimensional data. A major shortcoming of current
methods, however, is their inability to learn sparse and interpretable hidden
states. Additionally, in settings where partial knowledge on the latent
structure of the data is readily available, a statistically sound integration
of prior information into current methods is challenging. To address these
issues, we propose spex-LVM, a factorial latent variable model with sparse
priors to encourage the inference of explainable factors driven by
domain-relevant information. spex-LVM utilizes existing knowledge of curated
biomedical pathways to automatically assign annotated attributes to latent
factors, yielding interpretable results tailored to the corresponding domain of
interest. Evaluations on simulated and real single-cell RNA-seq datasets
demonstrate that our model robustly identifies relevant structure in an
inherently explainable manner, distinguishes technical noise from sources of
biomedical variation, and provides dataset-specific adaptations of existing
pathway annotations. Implementation is available at
https://github.com/MLO-lab/spexlvm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpecGrav -- Detection of Gravitational Waves using Deep Learning. (arXiv:2107.03607v1 [astro-ph.IM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Dodia_H/0/1/0/all/0/1">Hrithika Dodia</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Tandel_H/0/1/0/all/0/1">Himanshu Tandel</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+DMello_L/0/1/0/all/0/1">Lynette D&#x27;Mello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03607">
                                    <div class="article-summary-box-inner">
                                        <span>Gravitational waves are ripples in the fabric of space-time that travel at
the speed of light. The detection of gravitational waves by LIGO is a major
breakthrough in the field of astronomy. Deep Learning has revolutionized many
industries including health care, finance and education. Deep Learning
techniques have also been explored for detection of gravitational waves to
overcome the drawbacks of traditional matched filtering method. However, in
several researches, the training phase of neural network is very time consuming
and hardware devices with large memory are required for the task. In order to
reduce the extensive amount of hardware resources and time required in training
a neural network for detecting gravitational waves, we made SpecGrav. We use 2D
Convolutional Neural Network and spectrograms of gravitational waves embedded
in noise to detect gravitational waves from binary black hole merger and binary
neutron star merger. The training phase of our neural network was of about just
19 minutes on a 2GB GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MAFIA: Machine Learning Acceleration on FPGAs for IoT Applications. (arXiv:2107.03653v1 [cs.AR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghanathe_N/0/1/0/all/0/1">Nikhil Pratap Ghanathe</a>, <a href="http://arxiv.org/find/cs/1/au:+Seshadri_V/0/1/0/all/0/1">Vivek Seshadri</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1">Rahul Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilton_S/0/1/0/all/0/1">Steve Wilton</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Aayan Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03653">
                                    <div class="article-summary-box-inner">
                                        <span>Recent breakthroughs in ML have produced new classes of models that allow ML
inference to run directly on milliwatt-powered IoT devices. On one hand,
existing ML-to-FPGA compilers are designed for deep neural-networks on large
FPGAs. On the other hand, general-purpose HLS tools fail to exploit properties
specific to ML inference, thereby resulting in suboptimal performance. We
propose MAFIA, a tool to compile ML inference on small form-factor FPGAs for
IoT applications. MAFIA provides native support for linear algebra operations
and can express a variety of ML algorithms, including state-of-the-art models.
We show that MAFIA-generated programs outperform best-performing variant of a
commercial HLS compiler by 2.5x on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BumbleBee: A Transformer for Music. (arXiv:2107.03443v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fenaux_L/0/1/0/all/0/1">Lucas Fenaux</a>, <a href="http://arxiv.org/find/cs/1/au:+Quintero_M/0/1/0/all/0/1">Maria Juliana Quintero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03443">
                                    <div class="article-summary-box-inner">
                                        <span>We will introduce BumbleBee, a transformer model that will generate MIDI
music data . We will tackle the issue of transformers applied to long sequences
by implementing a longformer generative model that uses dilating sliding
windows to compute the attention layers. We will compare our results to that of
the music transformer and Long-Short term memory (LSTM) to benchmark our
results. This analysis will be performed using piano MIDI files, in particular
, the JSB Chorales dataset that has already been used for other research works
(Huang et al., 2018)</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sublinear Regret for Learning POMDPs. (arXiv:2107.03635v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Ningyuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xuefeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xiang Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03635">
                                    <div class="article-summary-box-inner">
                                        <span>We study the model-based undiscounted reinforcement learning for partially
observable Markov decision processes (POMDPs). The oracle we consider is the
optimal policy of the POMDP with a known environment in terms of the average
reward over an infinite horizon. We propose a learning algorithm for this
problem, building on spectral method-of-moments estimations for hidden Markov
models, the belief error control in POMDPs and upper-confidence-bound methods
for online learning. We establish a regret bound of $O(T^{2/3}\sqrt{\log T})$
for the proposed learning algorithm where $T$ is the learning horizon. This is,
to the best of our knowledge, the first algorithm achieving sublinear regret
with respect to our oracle for learning general POMDPs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Disease Progress with Imprecise Lab Test Results. (arXiv:2107.03620v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jianwen Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhihua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03620">
                                    <div class="article-summary-box-inner">
                                        <span>In existing deep learning methods, almost all loss functions assume that
sample data values used to be predicted are the only correct ones. This
assumption does not hold for laboratory test data. Test results are often
within tolerable or imprecision ranges, with all values in the ranges
acceptable. By considering imprecision samples, we propose an imprecision range
loss (IR loss) method and incorporate it into Long Short Term Memory (LSTM)
model for disease progress prediction. In this method, each sample in
imprecision range space has a certain probability to be the real value,
participating in the loss calculation. The loss is defined as the integral of
the error of each point in the impression range space. A sampling method for
imprecision space is formulated. The continuous imprecision space is
discretized, and a sequence of imprecise data sets are obtained, which is
convenient for gradient descent learning. A heuristic learning algorithm is
developed to learn the model parameters based on the imprecise data sets.
Experimental results on real data show that the prediction method based on IR
loss can provide more stable and consistent prediction result when test samples
are generated from imprecision range.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label-set Loss Functions for Partial Supervision: Application to Fetal Brain 3D MRI Parcellation. (arXiv:2107.03846v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fidon_L/0/1/0/all/0/1">Lucas Fidon</a>, <a href="http://arxiv.org/find/eess/1/au:+Aertsen_M/0/1/0/all/0/1">Michael Aertsen</a>, <a href="http://arxiv.org/find/eess/1/au:+Emam_D/0/1/0/all/0/1">Doaa Emam</a>, <a href="http://arxiv.org/find/eess/1/au:+Mufti_N/0/1/0/all/0/1">Nada Mufti</a>, <a href="http://arxiv.org/find/eess/1/au:+Guffens_F/0/1/0/all/0/1">Frederic Guffens</a>, <a href="http://arxiv.org/find/eess/1/au:+Deprest_T/0/1/0/all/0/1">Thomas Deprest</a>, <a href="http://arxiv.org/find/eess/1/au:+Demaerel_P/0/1/0/all/0/1">Philippe Demaerel</a>, <a href="http://arxiv.org/find/eess/1/au:+David_A/0/1/0/all/0/1">Anna L. David</a>, <a href="http://arxiv.org/find/eess/1/au:+Melbourne_A/0/1/0/all/0/1">Andrew Melbourne</a>, <a href="http://arxiv.org/find/eess/1/au:+Ourselin_S/0/1/0/all/0/1">Sebastien Ourselin</a>, <a href="http://arxiv.org/find/eess/1/au:+Deprest_J/0/1/0/all/0/1">Jam Deprest</a>, <a href="http://arxiv.org/find/eess/1/au:+Vercauteren_T/0/1/0/all/0/1">Tom Vercauteren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03846">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have increased the accuracy of automatic segmentation,
however, their accuracy depends on the availability of a large number of fully
segmented images. Methods to train deep neural networks using images for which
some, but not all, regions of interest are segmented are necessary to make
better use of partially annotated datasets. In this paper, we propose the first
axiomatic definition of label-set loss functions that are the loss functions
that can handle partially segmented images. We prove that there is one and only
one method to convert a classical loss function for fully segmented images into
a proper label-set loss function. Our theory also allows us to define the
leaf-Dice loss, a label-set generalization of the Dice loss particularly suited
for partial supervision with only missing labels. Using the leaf-Dice loss, we
set a new state of the art in partially supervised learning for fetal brain 3D
MRI segmentation. We achieve a deep neural network able to segment white
matter, ventricles, cerebellum, extra-ventricular CSF, cortical gray matter,
deep gray matter, brainstem, and corpus callosum based on fetal brain 3D MRI of
anatomically normal fetuses or with open spina bifida. Our implementation of
the proposed label-set loss functions is available at
https://github.com/LucasFidon/label-set-loss-functions</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IowaRain: A Statewide Rain Event Dataset Based on Weather Radars and Quantitative Precipitation Estimation. (arXiv:2107.03432v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sit_M/0/1/0/all/0/1">Muhammed Sit</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_B/0/1/0/all/0/1">Bong-Chul Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Demir_I/0/1/0/all/0/1">Ibrahim Demir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03432">
                                    <div class="article-summary-box-inner">
                                        <span>Effective environmental planning and management to address climate change
could be achieved through extensive environmental modeling with machine
learning and conventional physical models. In order to develop and improve
these models, practitioners and researchers need comprehensive benchmark
datasets that are prepared and processed with environmental expertise that they
can rely on. This study presents an extensive dataset of rainfall events for
the state of Iowa (2016-2019) acquired from the National Weather Service Next
Generation Weather Radar (NEXRAD) system and processed by a quantitative
precipitation estimation system. The dataset presented in this study could be
used for better disaster monitoring, response and recovery by paving the way
for both predictive and prescriptive modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Random Access Memory using Lattices. (arXiv:2107.03474v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goucher_A/0/1/0/all/0/1">Adam P. Goucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Troll_R/0/1/0/all/0/1">Rajan Troll</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03474">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a differentiable random access memory module with $O(1)$
performance regardless of size, scaling to billions of entries. The design
stores entries on points of a chosen lattice to calculate nearest neighbours of
arbitrary points efficiently by exploiting symmetries. Augmenting a standard
neural network architecture with a single memory layer based on this, we can
scale the parameter count up to memory limits with negligible computational
overhead, giving better accuracy at similar cost. On large language modelling
tasks, these enhanced models with larger capacity significantly outperform the
unmodified transformer baseline. We found continued scaling with memory size up
to the limits tested.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modality Completion via Gaussian Process Prior Variational Autoencoders for Multi-Modal Glioma Segmentation. (arXiv:2107.03442v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hamghalam_M/0/1/0/all/0/1">Mohammad Hamghalam</a>, <a href="http://arxiv.org/find/eess/1/au:+Frangi_A/0/1/0/all/0/1">Alejandro F. Frangi</a>, <a href="http://arxiv.org/find/eess/1/au:+Lei_B/0/1/0/all/0/1">Baiying Lei</a>, <a href="http://arxiv.org/find/eess/1/au:+Simpson_A/0/1/0/all/0/1">Amber L. Simpson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03442">
                                    <div class="article-summary-box-inner">
                                        <span>In large studies involving multi protocol Magnetic Resonance Imaging (MRI),
it can occur to miss one or more sub-modalities for a given patient owing to
poor quality (e.g. imaging artifacts), failed acquisitions, or hallway
interrupted imaging examinations. In some cases, certain protocols are
unavailable due to limited scan time or to retrospectively harmonise the
imaging protocols of two independent studies. Missing image modalities pose a
challenge to segmentation frameworks as complementary information contributed
by the missing scans is then lost. In this paper, we propose a novel model,
Multi-modal Gaussian Process Prior Variational Autoencoder (MGP-VAE), to impute
one or more missing sub-modalities for a patient scan. MGP-VAE can leverage the
Gaussian Process (GP) prior on the Variational Autoencoder (VAE) to utilize the
subjects/patients and sub-modalities correlations. Instead of designing one
network for each possible subset of present sub-modalities or using frameworks
to mix feature maps, missing data can be generated from a single model based on
all the available samples. We show the applicability of MGP-VAE on brain tumor
segmentation where either, two, or three of four sub-modalities may be missing.
Our experiments against competitive segmentation baselines with missing
sub-modality on BraTS&#x27;19 dataset indicate the effectiveness of the MGP-VAE
model for segmentation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quadruplet Deep Metric Learning Model for Imbalanced Time-series Fault Diagnosis. (arXiv:2107.03786v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gui_X/0/1/0/all/0/1">Xingtai Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiyang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03786">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent diagnosis method based on data-driven and deep learning is an
attractive and meaningful field in recent years. However, in practical
application scenarios, the imbalance of time-series fault is an urgent problem
to be solved. From the perspective of Bayesian probability, this paper analyzes
how to improve the performance of imbalanced classification by adjusting the
distance between classes and the distribution within a class and proposes a
time-series fault diagnosis model based on deep metric learning. As a core of
deep metric learning, a novel quadruplet data pair design considering imbalance
class is proposed with reference to traditional deep metric learning. Based on
such data pair, this paper proposes a quadruplet loss function which takes into
account the inter-class distance and the intra-class data distribution, and
pays special attention to imbalanced sample pairs. The reasonable combination
of quadruplet loss and softmax loss function can reduce the impact of
imbalance. Experiments on two open datasets are carried out to verify the
effectiveness and robustness of the model. Experimental results show that the
proposed method can effectively improve the performance of imbalanced
classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaboration of Experts: Achieving 80% Top-1 Accuracy on ImageNet with 100M FLOPs. (arXiv:2107.03815v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yikang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhao Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03815">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a Collaboration of Experts (CoE) framework to pool
together the expertise of multiple networks towards a common aim. Each expert
is an individual network with expertise on a unique portion of the dataset,
which enhances the collective capacity. Given a sample, an expert is selected
by the delegator, which simultaneously outputs a rough prediction to support
early termination. To fulfill this framework, we propose three modules to impel
each model to play its role, namely weight generation module (WGM), label
generation module (LGM) and variance calculation module (VCM). Our method
achieves the state-of-the-art performance on ImageNet, 80.7% top-1 accuracy
with 194M FLOPs. Combined with PWLU activation function and CondConv, CoE
further achieves the accuracy of 80.0% with only 100M FLOPs for the first time.
More importantly, our method is hardware friendly and achieves a 3-6x speedup
compared with some existing conditional computation approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Selection for Generic Contextual Bandits. (arXiv:2107.03455v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghosh_A/0/1/0/all/0/1">Avishek Ghosh</a>, <a href="http://arxiv.org/find/stat/1/au:+Sankararaman_A/0/1/0/all/0/1">Abishek Sankararaman</a>, <a href="http://arxiv.org/find/stat/1/au:+Ramchandran_K/0/1/0/all/0/1">Kannan Ramchandran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03455">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of model selection for the general stochastic
contextual bandits under the realizability assumption. We propose a successive
refinement based algorithm called Adaptive Contextual Bandit ({\ttfamily ACB}),
that works in phases and successively eliminates model classes that are too
simple to fit the given instance. We prove that this algorithm is adaptive,
i.e., the regret rate order-wise matches that of {\ttfamily FALCON}, the
state-of-art contextual bandit algorithm of Levi et. al &#x27;20, that needs
knowledge of the true model class. The price of not knowing the correct model
class is only an additive term contributing to the second order term in the
regret bound. This cost possess the intuitive property that it becomes smaller
as the model class becomes easier to identify, and vice-versa. We then show
that a much simpler explore-then-commit (ETC) style algorithm also obtains a
regret rate of matching that of {\ttfamily FALCON}, despite not knowing the
true model class. However, the cost of model selection is higher in ETC as
opposed to in {\ttfamily ACB}, as expected. Furthermore, {\ttfamily ACB}
applied to the linear bandit setting with unknown sparsity, order-wise recovers
the model selection guarantees previously established by algorithms tailored to
the linear setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proceedings of the First Workshop on Weakly Supervised Learning (WeaSuL). (arXiv:2107.03690v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hedderich_M/0/1/0/all/0/1">Michael A. Hedderich</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1">Benjamin Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1">Katharina Kann</a>, <a href="http://arxiv.org/find/cs/1/au:+Plank_B/0/1/0/all/0/1">Barbara Plank</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratner_A/0/1/0/all/0/1">Alex Ratner</a>, <a href="http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1">Dietrich Klakow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03690">
                                    <div class="article-summary-box-inner">
                                        <span>Welcome to WeaSuL 2021, the First Workshop on Weakly Supervised Learning,
co-located with ICLR 2021. In this workshop, we want to advance theory, methods
and tools for allowing experts to express prior coded knowledge for automatic
data annotations that can be used to train arbitrary deep neural networks for
prediction. The ICLR 2021 Workshop on Weak Supervision aims at advancing
methods that help modern machine-learning methods to generalize from knowledge
provided by experts, in interaction with observable (unlabeled) data. In total,
15 papers were accepted. All the accepted contributions are listed in these
Proceedings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">In-Network Learning: Distributed Training and Inference in Networks. (arXiv:2107.03433v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moldoveanu_M/0/1/0/all/0/1">Matei Moldoveanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaidi_A/0/1/0/all/0/1">Abdellatif Zaidi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03433">
                                    <div class="article-summary-box-inner">
                                        <span>It is widely perceived that leveraging the success of modern machine learning
techniques to mobile devices and wireless networks has the potential of
enabling important new services. This, however, poses significant challenges,
essentially due to that both data and processing power are highly distributed
in a wireless network. In this paper, we develop a learning algorithm and an
architecture that make use of multiple data streams and processing units, not
only during the training phase but also during the inference phase. In
particular, the analysis reveals how inference propagates and fuses across a
network. We study the design criterion of our proposed method and its bandwidth
requirements. Also, we discuss implementation aspects using neural networks in
typical wireless radio access; and provide experiments that illustrate benefits
over state-of-the-art techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning as a Mean-Field Game. (arXiv:2107.03770v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mehrjou_A/0/1/0/all/0/1">Arash Mehrjou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03770">
                                    <div class="article-summary-box-inner">
                                        <span>We establish a connection between federated learning, a concept from machine
learning, and mean-field games, a concept from game theory and control theory.
In this analogy, the local federated learners are considered as the players and
the aggregation of the gradients in a central server is the mean-field effect.
We present federated learning as a differential game and discuss the properties
of the equilibrium of this game. We hope this novel view to federated learning
brings together researchers from these two distinct areas to work on
fundamental problems of large-scale distributed and privacy-preserving learning
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Two-Sided Matching. (arXiv:2107.03427v1 [cs.GT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ravindranath_S/0/1/0/all/0/1">Sai Srivatsa Ravindranath</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhe Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shira Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jonathan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kominers_S/0/1/0/all/0/1">Scott D. Kominers</a>, <a href="http://arxiv.org/find/cs/1/au:+Parkes_D/0/1/0/all/0/1">David C. Parkes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03427">
                                    <div class="article-summary-box-inner">
                                        <span>We initiate the use of a multi-layer neural network to model two-sided
matching and to explore the design space between strategy-proofness and
stability. It is well known that both properties cannot be achieved
simultaneously but the efficient frontier in this design space is not
understood. We show empirically that it is possible to achieve a good
compromise between stability and strategy-proofness-substantially better than
that achievable through a convex combination of deferred acceptance (stable and
strategy-proof for only one side of the market) and randomized serial
dictatorship (strategy-proof but not stable).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CHASE: Robust Visual Tracking via Cell-Level Differentiable Neural Architecture Search. (arXiv:2107.03463v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marvasti_Zadeh_S/0/1/0/all/0/1">Seyed Mojtaba Marvasti-Zadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Khaghani_J/0/1/0/all/0/1">Javad Khaghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1">Li Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanei_Yakhdan_H/0/1/0/all/0/1">Hossein Ghanei-Yakhdan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasaei_S/0/1/0/all/0/1">Shohreh Kasaei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03463">
                                    <div class="article-summary-box-inner">
                                        <span>A strong visual object tracker nowadays relies on its well-crafted modules,
which typically consist of manually-designed network architectures to deliver
high-quality tracking results. Not surprisingly, the manual design process
becomes a particularly challenging barrier, as it demands sufficient prior
experience, enormous effort, intuition and perhaps some good luck. Meanwhile,
neural architecture search has gaining grounds in practical applications such
as image segmentation, as a promising method in tackling the issue of automated
search of feasible network structures. In this work, we propose a novel
cell-level differentiable architecture search mechanism to automate the network
design of the tracking module, aiming to adapt backbone features to the
objective of a tracking network during offline training. The proposed approach
is simple, efficient, and with no need to stack a series of modules to
construct a network. Our approach is easy to be incorporated into existing
trackers, which is empirically validated using different differentiable
architecture search-based methods and tracking objectives. Extensive
experimental evaluations demonstrate the superior performance of our approach
over five commonly-used benchmarks. Meanwhile, our automated searching process
takes 41 (18) hours for the second (first) order DARTS method on the
TrackingNet dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Elastic deformation of optical coherence tomography images of diabetic macular edema for deep-learning models training: how far to go?. (arXiv:2107.03651v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bar_David_D/0/1/0/all/0/1">Daniel Bar-David</a>, <a href="http://arxiv.org/find/eess/1/au:+Bar_David_L/0/1/0/all/0/1">Laura Bar-David</a>, <a href="http://arxiv.org/find/eess/1/au:+Shapira_Y/0/1/0/all/0/1">Yinon Shapira</a>, <a href="http://arxiv.org/find/eess/1/au:+Leibu_R/0/1/0/all/0/1">Rina Leibu</a>, <a href="http://arxiv.org/find/eess/1/au:+Dori_D/0/1/0/all/0/1">Dalia Dori</a>, <a href="http://arxiv.org/find/eess/1/au:+Schneor_R/0/1/0/all/0/1">Ronit Schneor</a>, <a href="http://arxiv.org/find/eess/1/au:+Fischer_A/0/1/0/all/0/1">Anath Fischer</a>, <a href="http://arxiv.org/find/eess/1/au:+Soudry_S/0/1/0/all/0/1">Shiri Soudry</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03651">
                                    <div class="article-summary-box-inner">
                                        <span>To explore the clinical validity of elastic deformation of optical coherence
tomography (OCT) images for data augmentation in the development of
deep-learning model for detection of diabetic macular edema (DME).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Stress Testing for Adversarial Learning in a Financial Environment. (arXiv:2107.03577v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+El_Awady_K/0/1/0/all/0/1">Khalid El-Awady</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03577">
                                    <div class="article-summary-box-inner">
                                        <span>We demonstrate the use of Adaptive Stress Testing to detect and address
potential vulnerabilities in a financial environment. We develop a simplified
model for credit card fraud detection that utilizes a linear regression
classifier based on historical payment transaction data coupled with business
rules. We then apply the reinforcement learning model known as Adaptive Stress
Testing to train an agent, that can be thought of as a potential fraudster, to
find the most likely path to system failure -- successfully defrauding the
system. We show the connection between this most likely failure path and the
limits of the classifier and discuss how the fraud detection system&#x27;s business
rules can be further augmented to mitigate these failure modes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sleep syndromes onset detection based on automatic sleep staging algorithm. (arXiv:2107.03387v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Cvetko_T/0/1/0/all/0/1">Tim Cvetko</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Robek_T/0/1/0/all/0/1">Tinkara Robek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03387">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel method and a practical approach to
predicting early onsets of sleep syndromes, including restless leg syndrome,
insomnia, based on an algorithm that is comprised of two modules. A Fast
Fourier Transform is applied to 30 seconds long epochs of EEG recordings to
provide localized time-frequency information, and a deep convolutional LSTM
neural network is trained for sleep stage classification. Automating sleep
stages detection from EEG data offers great potential to tackling sleep
irregularities on a daily basis. Thereby, a novel approach for sleep stage
classification is proposed which combines the best of signal processing and
statistics. In this study, we used the PhysioNet Sleep European Data Format
(EDF) Database. The code evaluation showed impressive results, reaching an
accuracy of 86.43, precision of 77.76, recall of 93,32, F1-score of 89.12 with
the final mean false error loss of 0.09.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Resolution Susceptibility of Face Recognition Models. (arXiv:2107.03769v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Knoche_M/0/1/0/all/0/1">Martin Knoche</a>, <a href="http://arxiv.org/find/cs/1/au:+Hormann_S/0/1/0/all/0/1">Stefan H&#xf6;rmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rigoll_G/0/1/0/all/0/1">Gerhard Rigoll</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03769">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition approaches often rely on equal image resolution for
verification faces on two images. However, in practical applications, those
image resolutions are usually not in the same range due to different image
capture mechanisms or sources. In this work, we first analyze the impact of
image resolutions on the face verification performance with a state-of-the-art
face recognition model. For images, synthetically reduced to $5\, \times 5\,
\mathrm{px}$ resolution, the verification performance drops from $99.23\%$
increasingly down to almost $55\%$. Especially, for cross-resolution image
pairs (one high- and one low-resolution image), the verification accuracy
decreases even further. We investigate this behavior more in-depth by looking
at the feature distances for every 2-image test pair. To tackle this problem,
we propose the following two methods: 1) Train a state-of-the-art
face-recognition model straightforward with $50\%$ low-resolution images
directly within each batch. \\ 2) Train a siamese-network structure and adding
a cosine distance feature loss between high- and low-resolution features. Both
methods show an improvement for cross-resolution scenarios and can increase the
accuracy at very low resolution to approximately $70\%$. However, a
disadvantage is that a specific model needs to be trained for every
resolution-pair ...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Bangla Natural Language Processing Tasks and the Utility of Transformer Models. (arXiv:2107.03844v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1">Firoj Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Arid Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1">Tanvir Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Akib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tajrin_J/0/1/0/all/0/1">Janntatul Tajrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naira Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03844">
                                    <div class="article-summary-box-inner">
                                        <span>Bangla -- ranked as the 6th most widely spoken language across the world
(https://www.ethnologue.com/guides/ethnologue200), with 230 million native
speakers -- is still considered as a low-resource language in the natural
language processing (NLP) community. With three decades of research, Bangla NLP
(BNLP) is still lagging behind mainly due to the scarcity of resources and the
challenges that come with it. There is sparse work in different areas of BNLP;
however, a thorough survey reporting previous work and recent advances is yet
to be done. In this study, we first provide a review of Bangla NLP tasks,
resources, and tools available to the research community; we benchmark datasets
collected from various platforms for nine NLP tasks using current
state-of-the-art algorithms (i.e., transformer-based models). We provide
comparative results for the studied NLP tasks by comparing monolingual vs.
multilingual models of varying sizes. We report our results using both
individual and consolidated datasets and provide data splits for future
research. We reviewed a total of 108 papers and conducted 175 sets of
experiments. Our results show promising performance using transformer-based
models while highlighting the trade-off with computational costs. We hope that
such a comprehensive survey will motivate the community to build on and further
advance the research on Bangla NLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A hybrid virtual sensing approach for approximating non-linear dynamic system behavior using LSTM networks. (arXiv:2107.03645v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Heindel_L/0/1/0/all/0/1">Leonhard Heindel</a>, <a href="http://arxiv.org/find/eess/1/au:+Hantschke_P/0/1/0/all/0/1">Peter Hantschke</a>, <a href="http://arxiv.org/find/eess/1/au:+Kastner_M/0/1/0/all/0/1">Markus K&#xe4;stner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03645">
                                    <div class="article-summary-box-inner">
                                        <span>Modern Internet of Things solutions are used in a variety of different areas,
ranging from connected vehicles and healthcare to industrial applications. They
rely on a large amount of interconnected sensors, which can lead to both
technical and economical challenges. Virtual sensing techniques aim to reduce
the number of physical sensors in a system by using data from available
measurements to estimate additional unknown quantities of interest. Successful
model-based solutions include Kalman filters or the combination of finite
element models and modal analysis, while many data-driven methods rely on
machine learning algorithms. The presented hybrid virtual sensing approach
combines Long Short-Term Memory networks with frequency response function
models in order to estimate the behavior of non-linear dynamic systems with
multiple input and output channels. Network training and prediction make use of
short signal subsequences, which are later recombined by applying a windowing
technique. The frequency response function model acts as a baseline estimate
which perfectly captures linear dynamic systems and is augmented by the
non-linear Long Short-Term Memory network following two different hybrid
modeling strategies. The approach is tested using a non-linear experimental
dataset, which results from measurements of a three-component servo-hydraulic
fatigue test bench. A variety of metrics in time and frequency domains, as well
as fatigue strength under variable amplitudes are used to evaluate the
approximation quality of the proposed method. In addition to virtual sensing,
the algorithm is also applied to a forward prediction task. Synthetic data are
used in a separate study to estimate the prediction quality on datasets of
different size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generative Model for Raw Audio Using Transformer Architectures. (arXiv:2106.16036v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Verma_P/0/1/0/all/0/1">Prateek Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chafe_C/0/1/0/all/0/1">Chris Chafe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16036">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel way of doing audio synthesis at the waveform
level using Transformer architectures. We propose a deep neural network for
generating waveforms, similar to wavenet. This is fully probabilistic,
auto-regressive, and causal, i.e. each sample generated depends only on the
previously observed samples. Our approach outperforms a widely used wavenet
architecture by up to 9% on a similar dataset for predicting the next step.
Using the attention mechanism, we enable the architecture to learn which audio
samples are important for the prediction of the future sample. We show how
causal transformer generative models can be used for raw waveform synthesis. We
also show that this performance can be improved by another 2% by conditioning
samples over a wider context. The flexibility of the current model to
synthesize audio from latent representations suggests a large number of
potential applications. The novel approach of using generative transformer
architectures for raw audio synthesis is, however, still far away from
generating any meaningful music, without using latent codes/meta-data to aid
the generation process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-08">2021-07-08</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DORA: Toward Policy Optimization for Task-oriented Dialogue System with Efficient Context. (arXiv:2107.03286v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeon_H/0/1/0/all/0/1">Hyunmin Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gary Geunbae Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03286">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, reinforcement learning (RL) has been applied to task-oriented
dialogue systems by using latent actions to solve shortcomings of supervised
learning (SL). In this paper, we propose a multi-domain task-oriented dialogue
system, called Dialogue System with Optimizing a Recurrent Action Policy using
Efficient Context (DORA), that uses SL, with subsequently applied RL to
optimize dialogue systems using a recurrent dialogue policy. This dialogue
policy recurrently generates explicit system actions as a both word-level and
high-level policy. As a result, DORA is clearly optimized during both SL and RL
steps by using an explicit system action policy that considers an efficient
context instead of the entire dialogue history. The system actions are both
interpretable and controllable, whereas the latent actions are not. DORA
improved the success rate by 6.6 points on MultiWOZ 2.0 and by 10.9 points on
MultiWOZ 2.1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Prediction of Text Complexity: The Missing Preliminaries for Text Simplification. (arXiv:2007.15823v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garbacea_C/0/1/0/all/0/1">Cristina Garbacea</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mengtian Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Carton_S/0/1/0/all/0/1">Samuel Carton</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1">Qiaozhu Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15823">
                                    <div class="article-summary-box-inner">
                                        <span>Text simplification reduces the language complexity of professional content
for accessibility purposes. End-to-end neural network models have been widely
adopted to directly generate the simplified version of input text, usually
functioning as a blackbox. We show that text simplification can be decomposed
into a compact pipeline of tasks to ensure the transparency and explainability
of the process. The first two steps in this pipeline are often neglected: 1) to
predict whether a given piece of text needs to be simplified, and 2) if yes, to
identify complex parts of the text. The two tasks can be solved separately
using either lexical or deep learning methods, or solved jointly. Simply
applying explainable complexity prediction as a preliminary step, the
out-of-sample text simplification performance of the state-of-the-art,
black-box simplification models can be improved by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interventional Video Grounding with Dual Contrastive Learning. (arXiv:2106.11013v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nan_G/0/1/0/all/0/1">Guoshun Nan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_R/0/1/0/all/0/1">Rui Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Leng_S/0/1/0/all/0/1">Sicong Leng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11013">
                                    <div class="article-summary-box-inner">
                                        <span>Video grounding aims to localize a moment from an untrimmed video for a given
textual query. Existing approaches focus more on the alignment of visual and
language stimuli with various likelihood-based matching or regression
strategies, i.e., P(Y|X). Consequently, these models may suffer from spurious
correlations between the language and video features due to the selection bias
of the dataset. 1) To uncover the causality behind the model and data, we first
propose a novel paradigm from the perspective of the causal inference, i.e.,
interventional video grounding (IVG) that leverages backdoor adjustment to
deconfound the selection bias based on structured causal model (SCM) and
do-calculus P(Y|do(X)). Then, we present a simple yet effective method to
approximate the unobserved confounder as it cannot be directly sampled from the
dataset. 2) Meanwhile, we introduce a dual contrastive learning approach (DCL)
to better align the text and video by maximizing the mutual information (MI)
between query and video clips, and the MI between start/end frames of a target
moment and the others within a video to learn more informative visual
representations. Experiments on three standard benchmarks show the
effectiveness of our approaches. Our code is available on GitHub:
https://github.com/nanguoshun/IVG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trans4E: Link Prediction on Scholarly Knowledge Graphs. (arXiv:2107.03297v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nayyeri_M/0/1/0/all/0/1">Mojtaba Nayyeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Cil_G/0/1/0/all/0/1">Gokce Muge Cil</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahdati_S/0/1/0/all/0/1">Sahar Vahdati</a>, <a href="http://arxiv.org/find/cs/1/au:+Osborne_F/0/1/0/all/0/1">Francesco Osborne</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mahfuzur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Angioni_S/0/1/0/all/0/1">Simone Angioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Salatino_A/0/1/0/all/0/1">Angelo Salatino</a>, <a href="http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1">Diego Reforgiato Recupero</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilyeva_N/0/1/0/all/0/1">Nadezhda Vassilyeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Motta_E/0/1/0/all/0/1">Enrico Motta</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1">Jens Lehmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03297">
                                    <div class="article-summary-box-inner">
                                        <span>The incompleteness of Knowledge Graphs (KGs) is a crucial issue affecting the
quality of AI-based services. In the scholarly domain, KGs describing research
publications typically lack important information, hindering our ability to
analyse and predict research dynamics. In recent years, link prediction
approaches based on Knowledge Graph Embedding models became the first aid for
this issue. In this work, we present Trans4E, a novel embedding model that is
particularly fit for KGs which include N to M relations with N$\gg$M. This is
typical for KGs that categorize a large number of entities (e.g., research
articles, patents, persons) according to a relatively small set of categories.
Trans4E was applied on two large-scale knowledge graphs, the Academia/Industry
DynAmics (AIDA) and Microsoft Academic Graph (MAG), for completing the
information about Fields of Study (e.g., &#x27;neural networks&#x27;, &#x27;machine learning&#x27;,
&#x27;artificial intelligence&#x27;), and affiliation types (e.g., &#x27;education&#x27;,
&#x27;company&#x27;, &#x27;government&#x27;), improving the scope and accuracy of the resulting
data. We evaluated our approach against alternative solutions on AIDA, MAG, and
four other benchmarks (FB15k, FB15k-237, WN18, and WN18RR). Trans4E outperforms
the other models when using low embedding dimensions and obtains competitive
results in high dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text2App: A Framework for Creating Android Apps from Text Descriptions. (arXiv:2104.08301v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Masum Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehrab_K/0/1/0/all/0/1">Kazi Sajeed Mehrab</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1">Wasi Uddin Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahriyar_R/0/1/0/all/0/1">Rifat Shahriyar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08301">
                                    <div class="article-summary-box-inner">
                                        <span>We present Text2App -- a framework that allows users to create functional
Android applications from natural language specifications. The conventional
method of source code generation tries to generate source code directly, which
is impractical for creating complex software. We overcome this limitation by
transforming natural language into an abstract intermediate formal language
representing an application with a substantially smaller number of tokens. The
intermediate formal representation is then compiled into target source codes.
This abstraction of programming details allows seq2seq networks to learn
complex application structures with less overhead. In order to train sequence
models, we introduce a data synthesis method grounded in a human survey. We
demonstrate that Text2App generalizes well to unseen combination of app
components and it is capable of handling noisy natural language instructions.
We explore the possibility of creating applications from highly abstract
instructions by coupling our system with GPT-3 -- a large pretrained language
model. We perform an extensive human evaluation and identify the capabilities
and limitations of our system. The source code, a ready-to-run demo notebook,
and a demo video are publicly available at
\url{https://github.com/text2app/Text2App}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Over a Decade of Social Opinion Mining: A Systematic Review. (arXiv:2012.03091v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cortis_K/0/1/0/all/0/1">Keith Cortis</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_B/0/1/0/all/0/1">Brian Davis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03091">
                                    <div class="article-summary-box-inner">
                                        <span>Social media popularity and importance is on the increase due to people using
it for various types of social interaction across multiple channels. This
systematic review focuses on the evolving research area of Social Opinion
Mining, tasked with the identification of multiple opinion dimensions, such as
subjectivity, sentiment polarity, emotion, affect, sarcasm and irony, from
user-generated content represented across multiple social media platforms and
in various media formats, like text, image, video and audio. Through Social
Opinion Mining, natural language can be understood in terms of the different
opinion dimensions, as expressed by humans. This contributes towards the
evolution of Artificial Intelligence which in turn helps the advancement of
several real-world use cases, such as customer service and decision making. A
thorough systematic review was carried out on Social Opinion Mining research
which totals 485 published studies and spans a period of twelve years between
2007 and 2018. The in-depth analysis focuses on the social media platforms,
techniques, social datasets, language, modality, tools and technologies, and
other aspects derived. Social Opinion Mining can be utilised in many
application areas, ranging from marketing, advertising and sales for
product/service management, and in multiple domains and industries, such as
politics, technology, finance, healthcare, sports and government. The latest
developments in Social Opinion Mining beyond 2018 are also presented together
with future research directions, with the aim of leaving a wider academic and
societal impact in several real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">U2++: Unified Two-pass Bidirectional End-to-end Model for Speech Recognition. (arXiv:2106.05642v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Binbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhendong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wenjing Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1">Xin Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05642">
                                    <div class="article-summary-box-inner">
                                        <span>The unified streaming and non-streaming two-pass (U2) end-to-end model for
speech recognition has shown great performance in terms of streaming
capability, accuracy, real-time factor (RTF), and latency. In this paper, we
present U2++, an enhanced version of U2 to further improve the accuracy. The
core idea of U2++ is to use the forward and the backward information of the
labeling sequences at the same time at training to learn richer information,
and combine the forward and backward prediction at decoding to give more
accurate recognition results. We also proposed a new data augmentation method
called SpecSub to help the U2++ model to be more accurate and robust. Our
experiments show that, compared with U2, U2++ shows faster convergence at
training, better robustness to the decoding method, as well as consistent 5\% -
8\% word error rate reduction gain over U2. On the experiment of AISHELL-1, we
achieve a 4.63\% character error rate (CER) with a non-streaming setup and
5.05\% with a streaming setup with 320ms latency by U2++. To the best of our
knowledge, 5.05\% is the best-published streaming result on the AISHELL-1 test
set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation of Representation Models for Text Classification with AutoML Tools. (arXiv:2106.12798v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brandle_S/0/1/0/all/0/1">Sebastian Br&#xe4;ndle</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanussek_M/0/1/0/all/0/1">Marc Hanussek</a>, <a href="http://arxiv.org/find/cs/1/au:+Blohm_M/0/1/0/all/0/1">Matthias Blohm</a>, <a href="http://arxiv.org/find/cs/1/au:+Kintz_M/0/1/0/all/0/1">Maximilien Kintz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12798">
                                    <div class="article-summary-box-inner">
                                        <span>Automated Machine Learning (AutoML) has gained increasing success on tabular
data in recent years. However, processing unstructured data like text is a
challenge and not widely supported by open-source AutoML tools. This work
compares three manually created text representations and text embeddings
automatically created by AutoML tools. Our benchmark includes four popular
open-source AutoML tools and eight datasets for text classification purposes.
The results show that straightforward text representations perform better than
AutoML tools with automatically created text embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Assignment of Radiology Examination Protocols Using Pre-trained Language Models with Knowledge Distillation. (arXiv:2009.00694v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lau_W/0/1/0/all/0/1">Wilson Lau</a>, <a href="http://arxiv.org/find/cs/1/au:+Aaltonen_L/0/1/0/all/0/1">Laura Aaltonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunn_M/0/1/0/all/0/1">Martin Gunn</a>, <a href="http://arxiv.org/find/cs/1/au:+Yetisgen_M/0/1/0/all/0/1">Meliha Yetisgen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00694">
                                    <div class="article-summary-box-inner">
                                        <span>Selecting radiology examination protocol is a repetitive, and time-consuming
process. In this paper, we present a deep learning approach to automatically
assign protocols to computer tomography examinations, by pre-training a
domain-specific BERT model ($BERT_{rad}$). To handle the high data imbalance
across exam protocols, we used a knowledge distillation approach that
up-sampled the minority classes through data augmentation. We compared
classification performance of the described approach with the statistical
n-gram models using Support Vector Machine (SVM), Gradient Boosting Machine
(GBM), and Random Forest (RF) classifiers, as well as the Google&#x27;s
$BERT_{base}$ model. SVM, GBM and RF achieved macro-averaged F1 scores of 0.45,
0.45, and 0.6 while $BERT_{base}$ and $BERT_{rad}$ achieved 0.61 and 0.63.
Knowledge distillation improved overall performance on the minority classes,
achieving a F1 score of 0.66.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustifying Multi-hop QA through Pseudo-Evidentiality Training. (arXiv:2107.03242v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kyungjae Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Seung-won Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Sang-eun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dohyeon Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03242">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the bias problem of multi-hop question answering models,
of answering correctly without correct reasoning. One way to robustify these
models is by supervising to not only answer right, but also with right
reasoning chains. An existing direction is to annotate reasoning chains to
train models, requiring expensive additional annotations. In contrast, we
propose a new approach to learn evidentiality, deciding whether the answer
prediction is supported by correct evidences, without such annotations.
Instead, we compare counterfactual changes in answer confidence with and
without evidence sentences, to generate &quot;pseudo-evidentiality&quot; annotations. We
validate our proposed model on an original set and challenge set in HotpotQA,
showing that our method is accurate and robust in multi-hop reasoning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Plot and Rework: Modeling Storylines for Visual Storytelling. (arXiv:2105.06950v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1">Chi-Yang Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_Y/0/1/0/all/0/1">Yun-Wei Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Ting-Hao &#x27;Kenneth&#x27; Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ku_L/0/1/0/all/0/1">Lun-Wei Ku</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06950">
                                    <div class="article-summary-box-inner">
                                        <span>Writing a coherent and engaging story is not easy. Creative writers use their
knowledge and worldview to put disjointed elements together to form a coherent
storyline, and work and rework iteratively toward perfection. Automated visual
storytelling (VIST) models, however, make poor use of external knowledge and
iterative generation when attempting to create stories. This paper introduces
PR-VIST, a framework that represents the input image sequence as a story graph
in which it finds the best path to form a storyline. PR-VIST then takes this
path and learns to generate the final story via an iterative training process.
This framework produces stories that are superior in terms of diversity,
coherence, and humanness, per both automatic and human evaluations. An ablation
study shows that both plotting and reworking contribute to the model&#x27;s
superiority.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fibrational Initial Algebra-Final Coalgebra Coincidence over Initial Algebras: Turning Verification Witnesses Upside Down. (arXiv:2105.04817v2 [cs.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kori_M/0/1/0/all/0/1">Mayuko Kori</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasuo_I/0/1/0/all/0/1">Ichiro Hasuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Katsumata_S/0/1/0/all/0/1">Shin-ya Katsumata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04817">
                                    <div class="article-summary-box-inner">
                                        <span>The coincidence between initial algebras (IAs) and final coalgebras (FCs) is
a phenomenon that underpins various important results in theoretical computer
science. In this paper, we identify a general fibrational condition for the
IA-FC coincidence, namely in the fiber over an initial algebra in the base
category. Identifying (co)algebras in a fiber as (co)inductive predicates, our
fibrational IA-FC coincidence allows one to use coinductive witnesses (such as
invariants) for verifying inductive properties (such as liveness). Our general
fibrational theory features the technical condition of stability of chain
colimits; we extend the framework to the presence of a monadic effect, too,
restricting to fibrations of complete lattice-valued predicates. Practical
benefits of our categorical theory are exemplified by new &quot;upside-down&quot; witness
notions for three verification problems: probabilistic liveness, and acceptance
and model-checking with respect to bottom-up tree automata.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear-time calculation of the expected sum of edge lengths in random projective linearizations of trees. (arXiv:2107.03277v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alemany_Puig_L/0/1/0/all/0/1">Llu&#xed;s Alemany-Puig</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_i_Cancho_R/0/1/0/all/0/1">Ramon Ferrer-i-Cancho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03277">
                                    <div class="article-summary-box-inner">
                                        <span>The syntactic structure of a sentence is often represented using syntactic
dependency trees. The sum of the distances between syntactically related words
has been in the limelight for the past decades. Research on dependency
distances led to the formulation of the principle of dependency distance
minimization whereby words in sentences are ordered so as to minimize that sum.
Numerous random baselines have been defined to carry out related quantitative
studies on languages. The simplest random baseline is the expected value of the
sum in unconstrained random permutations of the words in the sentence, namely
when all the shufflings of the words of a sentence are allowed and equally
likely. Here we focus on a popular baseline: random projective permutations of
the words of the sentence, that is, permutations where the syntactic dependency
structure is projective, a formal constraint that sentences satisfy often in
languages. Thus far, the expectation of the sum of dependency distances in
random projective shufflings of a sentence has been estimated approximately
with a Monte Carlo procedure whose cost is of the order of $Zn$, where $n$ is
the number of words of the sentence and $Z$ is the number of samples; the
larger $Z$, the lower the error of the estimation but the larger the time cost.
Here we present formulae to compute that expectation without error in time of
the order of $n$. Furthermore, we show that star trees maximize it, and devise
a dynamic programming algorithm to retrieve the trees that minimize it.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vocabulary Learning via Optimal Transport for Machine Translation. (arXiv:2012.15671v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jingjing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chun Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zaixiang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15671">
                                    <div class="article-summary-box-inner">
                                        <span>The choice of token vocabulary affects the performance of machine
translation. This paper aims to figure out what is a good vocabulary and
whether one can find the optimal vocabulary without trial training. To answer
these questions, we first provide an alternative understanding of the role of
vocabulary from the perspective of information theory. Motivated by this, we
formulate the quest of vocabularization -- finding the best token dictionary
with a proper size -- as an optimal transport (OT) problem. We propose VOLT, a
simple and efficient solution without trial training. Empirical results show
that VOLT outperforms widely-used vocabularies in diverse scenarios, including
WMT-14 English-German and TED&#x27;s 52 translation directions. For example, VOLT
achieves almost 70% vocabulary size reduction and 0.5 BLEU gain on
English-German translation. Also, compared to BPE-search, VOLT reduces the
search time from 384 GPU hours to 30 GPU hours on English-German translation.
Codes are available at https://github.com/Jingjing-NLP/VOLT .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Training Instance Selection for Few-Shot Neural Text Generation. (arXiv:2107.03176v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ernie Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xiaoyu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_H/0/1/0/all/0/1">Hui-Syuan Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1">Vera Demberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03176">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale pretrained language models have led to dramatic improvements in
text generation. Impressive performance can be achieved by finetuning only on a
small number of instances (few-shot setting). Nonetheless, almost all previous
work simply applies random sampling to select the few-shot training instances.
Little to no attention has been paid to the selection strategies and how they
would affect model performance. In this work, we present a study on training
instance selection in few-shot neural text generation. The selection decision
is made based only on the unlabeled data so as to identify the most worthwhile
data points that should be annotated under some budget of labeling cost. Based
on the intuition that the few-shot training instances should be diverse and
representative of the entire data distribution, we propose a simple selection
strategy with K-means clustering. We show that even with the naive
clustering-based approach, the generation models consistently outperform random
sampling on three text generation tasks: data-to-text generation, document
summarization and question generation. We hope that this work will call for
more attention on this largely unexplored area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lemmatization of Historical Old Literary Finnish Texts in Modern Orthography. (arXiv:2107.03266v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hamalainen_M/0/1/0/all/0/1">Mika H&#xe4;m&#xe4;l&#xe4;inen</a>, <a href="http://arxiv.org/find/cs/1/au:+Partanen_N/0/1/0/all/0/1">Niko Partanen</a>, <a href="http://arxiv.org/find/cs/1/au:+Alnajjar_K/0/1/0/all/0/1">Khalid Alnajjar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03266">
                                    <div class="article-summary-box-inner">
                                        <span>Texts written in Old Literary Finnish represent the first literary work ever
written in Finnish starting from the 16th century. There have been several
projects in Finland that have digitized old publications and made them
available for research use. However, using modern NLP methods in such data
poses great challenges. In this paper we propose an approach for simultaneously
normalizing and lemmatizing Old Literary Finnish into modern spelling. Our best
model reaches to 96.3\% accuracy in texts written by Agricola and 87.7\%
accuracy in other contemporary out-of-domain text. Our method has been made
freely available on Zenodo and Github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MACCIF-TDNN: Multi aspect aggregation of channel and context interdependence features in TDNN-based speaker verification. (arXiv:2107.03104v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fangyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhigang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hongchen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Bo Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03104">
                                    <div class="article-summary-box-inner">
                                        <span>Most of the recent state-of-the-art results for speaker verification are
achieved by X-vector and its subsequent variants. In this paper, we propose a
new network architecture which aggregates the channel and context
interdependence features from multi aspect based on Time Delay Neural Network
(TDNN). Firstly, we use the SE-Res2Blocks as in ECAPA-TDNN to explicitly model
the channel interdependence to realize adaptive calibration of channel
features, and process local context features in a multi-scale way at a more
granular level compared with conventional TDNN-based methods. Secondly, we
explore to use the encoder structure of Transformer to model the global context
interdependence features at an utterance level which can capture better long
term temporal characteristics. Before the pooling layer, we aggregate the
outputs of SE-Res2Blocks and Transformer encoder to leverage the complementary
channel and context interdependence features learned by themself respectively.
Finally, instead of performing a single attentive statistics pooling, we also
find it beneficial to extend the pooling method in a multi-head way which can
discriminate features from multiple aspect. The proposed MACCIF-TDNN
architecture can outperform most of the state-of-the-art TDNN-based systems on
VoxCeleb1 test sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Extrapolation for Attribute-Enhanced Generation. (arXiv:2107.02968v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1">Alvin Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Madani_A/0/1/0/all/0/1">Ali Madani</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_B/0/1/0/all/0/1">Ben Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Naik_N/0/1/0/all/0/1">Nikhil Naik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02968">
                                    <div class="article-summary-box-inner">
                                        <span>Attribute extrapolation in sample generation is challenging for deep neural
networks operating beyond the training distribution. We formulate a new task
for extrapolation in sequence generation, focusing on natural language and
proteins, and propose GENhance, a generative framework that enhances attributes
through a learned latent space. Trained on movie reviews and a computed protein
stability dataset, GENhance can generate strongly-positive text reviews and
highly stable protein sequences without being exposed to similar data during
training. We release our benchmark tasks and models to contribute to the study
of generative modeling extrapolation and data-driven design in biology and
chemistry.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Text Classification of Urdu News using Deep Neural Network. (arXiv:2107.03141v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Javed_T/0/1/0/all/0/1">Taimoor Ahmed Javed</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahzad_W/0/1/0/all/0/1">Waseem Shahzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Arshad_U/0/1/0/all/0/1">Umair Arshad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03141">
                                    <div class="article-summary-box-inner">
                                        <span>Digital text is increasing day by day on the internet. It is very challenging
to classify a large and heterogeneous collection of data, which require
improved information processing methods to organize text. To classify large
size of corpus, one common approach is to use hierarchical text classification,
which aims to classify textual data in a hierarchical structure. Several
approaches have been proposed to tackle classification of text but most of the
research has been done on English language. This paper proposes a deep learning
model for hierarchical text classification of news in Urdu language -
consisting of 51,325 sentences from 8 online news websites belonging to the
following genres: Sports; Technology; and Entertainment. The objectives of this
paper are twofold: (1) to develop a large human-annotated dataset of news in
Urdu language for hierarchical text classification; and (2) to classify Urdu
news hierarchically using our proposed model based on LSTM mechanism named as
Hierarchical Multi-layer LSTMs (HMLSTM). Our model consists of two modules:
Text Representing Layer, for obtaining text representation in which we use
Word2vec embedding to transform the words to vector and Urdu Hierarchical LSTM
Layer (UHLSTML) an end-to-end fully connected deep LSTMs network to perform
automatic feature learning, we train one LSTM layer for each level of the class
hierarchy. We have performed extensive experiments on our self created dataset
named as Urdu News Dataset for Hierarchical Text Classification (UNDHTC). The
result shows that our proposed method is very effective for hierarchical text
classification and it outperforms baseline methods significantly and also
achieved good results as compare to deep neural model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Data Augmentation for Text Classification. (arXiv:2107.03158v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bayer_M/0/1/0/all/0/1">Markus Bayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaufhold_M/0/1/0/all/0/1">Marc-Andr&#xe9; Kaufhold</a>, <a href="http://arxiv.org/find/cs/1/au:+Reuter_C/0/1/0/all/0/1">Christian Reuter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03158">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation, the artificial creation of training data for machine
learning by transformations, is a widely studied research field across machine
learning disciplines. While it is useful for increasing the generalization
capabilities of a model, it can also address many other challenges and
problems, from overcoming a limited amount of training data over regularizing
the objective to limiting the amount data used to protect privacy. Based on a
precise description of the goals and applications of data augmentation (C1) and
a taxonomy for existing works (C2), this survey is concerned with data
augmentation methods for textual classification and aims to achieve a concise
and comprehensive overview for researchers and practitioners (C3). Derived from
the taxonomy, we divided more than 100 methods into 12 different groupings and
provide state-of-the-art references expounding which methods are highly
promising (C4). Finally, research perspectives that may constitute a building
block for future work are given (C5).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SinSpell: A Comprehensive Spelling Checker for Sinhala. (arXiv:2107.02983v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liyanapathirana_U/0/1/0/all/0/1">Upuli Liyanapathirana</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunasinghe_K/0/1/0/all/0/1">Kaumini Gunasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Dias_G/0/1/0/all/0/1">Gihan Dias</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02983">
                                    <div class="article-summary-box-inner">
                                        <span>We have built SinSpell, a comprehensive spelling checker for the Sinhala
language which is spoken by over 16 million people, mainly in Sri Lanka.
However, until recently, Sinhala had no spelling checker with acceptable
coverage. Sinspell is still the only open source Sinhala spelling checker.
SinSpell identifies possible spelling errors and suggests corrections. It also
contains a module which auto-corrects evident errors. To maintain accuracy,
SinSpell was designed as a rule-based system based on Hunspell. A set of words
was compiled from several sources and verified. These were divided into
morphological classes, and the valid roots, suffixes and prefixes for each
class were identified, together with lists of irregular words and exceptions.
The errors in a corpus of Sinhala documents were analysed and commonly
misspelled words and types of common errors were identified. We found that the
most common errors were in vowel length and similar sounding letters. Errors
due to incorrect typing and encoding were also found. This analysis was used to
develop the suggestion generator and auto-corrector.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Advancing CTC-CRF Based End-to-End Speech Recognition with Wordpieces and Conformers. (arXiv:2107.03007v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zheng_H/0/1/0/all/0/1">Huahuan Zheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Peng_W/0/1/0/all/0/1">Wenjie Peng</a>, <a href="http://arxiv.org/find/eess/1/au:+Ou_Z/0/1/0/all/0/1">Zhijian Ou</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jinsong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03007">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition systems have been largely improved in the past
few decades and current systems are mainly hybrid-based and end-to-end-based.
The recently proposed CTC-CRF framework inherits the data-efficiency of the
hybrid approach and the simplicity of the end-to-end approach. In this paper,
we further advance CTC-CRF based ASR technique with explorations on modeling
units and neural architectures. Specifically, we investigate techniques to
enable the recently developed wordpiece modeling units and Conformer neural
networks to be succesfully applied in CTC-CRFs. Experiments are conducted on
two English datasets (Switchboard, Librispeech) and a German dataset from
CommonVoice. Experimental results suggest that (i) Conformer can improve the
recognition performance significantly; (ii) Wordpiece-based systems perform
slightly worse compared with phone-based systems for the target language with a
low degree of grapheme-phoneme correspondence (e.g. English), while the two
systems can perform equally strong when such degree of correspondence is high
for the target language (e.g. German).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Answering Chinese Elementary School Social Study Multiple Choice Questions. (arXiv:2107.02893v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daniel Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chao-Chun Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_K/0/1/0/all/0/1">Keh-Yih Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02893">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach to answer the Chinese elementary school Social
Study Multiple Choice questions. Although BERT has demonstrated excellent
performance on Reading Comprehension tasks, it is found not good at handling
some specific types of questions, such as Negation, All-of-the-above, and
None-of-the-above. We thus propose a novel framework to cascade BERT with a
Pre-Processor and an Answer-Selector modules to tackle the above challenges.
Experimental results show the proposed approach effectively improves the
performance of BERT, and thus demonstrate the feasibility of supplementing BERT
with additional modules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Transformer for Direct Speech Translation. (arXiv:2107.03069v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alastruey_B/0/1/0/all/0/1">Belen Alastruey</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallego_G/0/1/0/all/0/1">Gerard I. G&#xe1;llego</a>, <a href="http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1">Marta R. Costa-juss&#xe0;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03069">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of Transformer-based models has surpassed the barriers of text.
When working with speech, we must face a problem: the sequence length of an
audio input is not suitable for the Transformer. To bypass this problem, a
usual approach is adding strided convolutional layers, to reduce the sequence
length before using the Transformer. In this paper, we propose a new approach
for direct Speech Translation, where thanks to an efficient Transformer we can
work with a spectrogram without having to use convolutional layers before the
Transformer. This allows the encoder to learn directly from the spectrogram and
no information is lost. We have created an encoder-decoder model, where the
encoder is an efficient Transformer -- the Longformer -- and the decoder is a
traditional Transformer decoder. Our results, which are close to the ones
obtained with the standard approach, show that this is a promising research
direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MedGPT: Medical Concept Prediction from Clinical Narratives. (arXiv:2107.03134v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kraljevic_Z/0/1/0/all/0/1">Zeljko Kraljevic</a>, <a href="http://arxiv.org/find/cs/1/au:+Shek_A/0/1/0/all/0/1">Anthony Shek</a>, <a href="http://arxiv.org/find/cs/1/au:+Bean_D/0/1/0/all/0/1">Daniel Bean</a>, <a href="http://arxiv.org/find/cs/1/au:+Bendayan_R/0/1/0/all/0/1">Rebecca Bendayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Teo_J/0/1/0/all/0/1">James Teo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dobson_R/0/1/0/all/0/1">Richard Dobson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03134">
                                    <div class="article-summary-box-inner">
                                        <span>The data available in Electronic Health Records (EHRs) provides the
opportunity to transform care, and the best way to provide better care for one
patient is through learning from the data available on all other patients.
Temporal modelling of a patient&#x27;s medical history, which takes into account the
sequence of past events, can be used to predict future events such as a
diagnosis of a new disorder or complication of a previous or existing disorder.
While most prediction approaches use mostly the structured data in EHRs or a
subset of single-domain predictions and outcomes, we present MedGPT a novel
transformer-based pipeline that uses Named Entity Recognition and Linking tools
(i.e. MedCAT) to structure and organize the free text portion of EHRs and
anticipate a range of future medical events (initially disorders). Since a
large portion of EHR data is in text form, such an approach benefits from a
granular and detailed view of a patient while introducing modest additional
noise. MedGPT effectively deals with the noise and the added granularity, and
achieves a precision of 0.344, 0.552 and 0.640 (vs LSTM 0.329, 0.538 and 0.633)
when predicting the top 1, 3 and 5 candidate future disorders on real world
hospital data from King&#x27;s College Hospital, London, UK (\textasciitilde600k
patients). We also show that our model captures medical knowledge by testing it
on an experimental medical multiple choice question answering task, and by
examining the attentional focus of the model using gradient-based saliency
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Natural Language Processing for Unstructured Data in Electronic Health Records: a Review. (arXiv:2107.02975v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_I/0/1/0/all/0/1">Irene Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jessica Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldwasser_J/0/1/0/all/0/1">Jeremy Goldwasser</a>, <a href="http://arxiv.org/find/cs/1/au:+Verma_N/0/1/0/all/0/1">Neha Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_W/0/1/0/all/0/1">Wai Pan Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nuzumlali_M/0/1/0/all/0/1">Muhammed Yavuz Nuzumlal&#x131;</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosand_B/0/1/0/all/0/1">Benjamin Rosand</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yixin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Matthew Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1">David Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_R/0/1/0/all/0/1">R. Andrew Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Krumholz_H/0/1/0/all/0/1">Harlan M. Krumholz</a>, <a href="http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1">Dragomir Radev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02975">
                                    <div class="article-summary-box-inner">
                                        <span>Electronic health records (EHRs), digital collections of patient healthcare
events and observations, are ubiquitous in medicine and critical to healthcare
delivery, operations, and research. Despite this central role, EHRs are
notoriously difficult to process automatically. Well over half of the
information stored within EHRs is in the form of unstructured text (e.g.
provider notes, operation reports) and remains largely untapped for secondary
use. Recently, however, newer neural network and deep learning approaches to
Natural Language Processing (NLP) have made considerable advances,
outperforming traditional statistical and rule-based systems on a variety of
tasks. In this survey paper, we summarize current neural NLP methods for EHR
applications. We focus on a broad scope of tasks, namely, classification and
prediction, word embeddings, extraction, generation, and other topics such as
question answering, phenotyping, knowledge graphs, medical dialogue,
multilinguality, interpretability, etc.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Denoising Diffusion Models in Discrete State-Spaces. (arXiv:2107.03006v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1">Jacob Austin</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_D/0/1/0/all/0/1">Daniel Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarlow_D/0/1/0/all/0/1">Danny Tarlow</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1">Rianne van den Berg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03006">
                                    <div class="article-summary-box-inner">
                                        <span>Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown
impressive results on image and waveform generation in continuous state spaces.
Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),
diffusion-like generative models for discrete data that generalize the
multinomial diffusion model of Hoogeboom et al. 2021, by going beyond
corruption processes with uniform transition probabilities. This includes
corruption with transition matrices that mimic Gaussian kernels in continuous
space, matrices based on nearest neighbors in embedding space, and matrices
that introduce absorbing states. The third allows us to draw a connection
between diffusion models and autoregressive and mask-based generative models.
We show that the choice of transition matrix is an important design decision
that leads to improved results in image and text domains. We also introduce a
new loss function that combines the variational lower bound with an auxiliary
cross entropy loss. For text, this model class achieves strong results on
character-level text generation while scaling to large vocabularies on LM1B. On
the image dataset CIFAR-10, our models approach the sample quality and exceed
the log-likelihood of the continuous-space DDPM model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Time-Aware Ancient Chinese Text Translation and Inference. (arXiv:2107.03179v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ernie Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiue_Y/0/1/0/all/0/1">Yow-Ting Shiue</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_H/0/1/0/all/0/1">Hui-Syuan Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1">Vera Demberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03179">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we aim to address the challenges surrounding the translation
of ancient Chinese text: (1) The linguistic gap due to the difference in eras
results in translations that are poor in quality, and (2) most translations are
missing the contextual information that is often very crucial to understanding
the text. To this end, we improve upon past translation techniques by proposing
the following: We reframe the task as a multi-label prediction task where the
model predicts both the translation and its particular era. We observe that
this helps to bridge the linguistic gap as chronological context is also used
as auxiliary information. % As a natural step of generalization, we pivot on
the modern Chinese translations to generate multilingual outputs. %We show
experimentally the efficacy of our framework in producing quality translation
outputs and also validate our framework on a collected task-specific parallel
corpus. We validate our framework on a parallel corpus annotated with
chronology information and show experimentally its efficacy in producing
quality translation outputs. We release both the code and the data
https://github.com/orina1123/time-aware-ancient-text-translation for future
research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Dialogue Summarization: Recent Advances and New Frontiers. (arXiv:2107.03175v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xiachong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xiaocheng Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_B/0/1/0/all/0/1">Bing Qin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03175">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of dialogue systems and natural language generation
techniques, the resurgence of dialogue summarization has attracted significant
research attentions, which aims to condense the original dialogue into a
shorter version covering salient information. However, there remains a lack of
comprehensive survey for this task. To this end, we take the first step and
present a thorough review of this research field. In detail, we provide an
overview of publicly available research datasets, summarize existing works
according to the domain of input dialogue as well as organize leaderboards
under unified metrics. Furthermore, we discuss some future directions and give
our thoughts. We hope that this first survey of dialogue summarization can
provide the community with a quick access and a general picture to this task
and motivate future researches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Android Security using NLP Techniques: A Review. (arXiv:2107.03072v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1">Sevil Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Can_B/0/1/0/all/0/1">Burcu Can</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03072">
                                    <div class="article-summary-box-inner">
                                        <span>Android is among the most targeted platform by attackers. While attackers are
improving their techniques, traditional solutions based on static and dynamic
analysis have been also evolving. In addition to the application code, Android
applications have some metadata that could be useful for security analysis of
applications. Unlike traditional application distribution mechanisms, Android
applications are distributed centrally in mobile markets. Therefore, beside
application packages, such markets contain app information provided by app
developers and app users. The availability of such useful textual data together
with the advancement in Natural Language Processing (NLP) that is used to
process and understand textual data has encouraged researchers to investigate
the use of NLP techniques in Android security. Especially, security solutions
based on NLP have accelerated in the last 5 years and proven to be useful. This
study reviews these proposals and aim to explore possible research directions
for future studies by presenting state-of-the-art in this domain. We mainly
focus on NLP-based solutions under four categories: description-to-behaviour
fidelity, description generation, privacy and malware detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EchoEA: Echo Information between Entities and Relations for Entity Alignment. (arXiv:2107.03054v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1">Xueyuan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+E_H/0/1/0/all/0/1">Haihong E</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_W/0/1/0/all/0/1">Wenyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haoran Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03054">
                                    <div class="article-summary-box-inner">
                                        <span>Entity alignment (EA) is to discover entities referring to the same object in
the real world from different knowledge graphs (KGs). It plays an important
role in automatically integrating KGs from multiple sources.

Existing knowledge graph embedding (KGE) methods based on Graph Neural
Networks (GNNs) have achieved promising results, which enhance entity
representation with relation information unidirectionally. Besides, more and
more methods introduce semi-supervision to ask for more labeled training data.

However, two challenges still exist in these methods: (1) Insufficient
interaction: The interaction between entities and relations is insufficiently
utilized. (2) Low-quality bootstrapping: The generated semi-supervised data is
of low quality.

In this paper, we propose a novel framework, Echo Entity Alignment (EchoEA),
which leverages self-attention mechanism to spread entity information to
relations and echo back to entities. The relation representation is dynamically
computed from entity representation. Symmetrically, the next entity
representation is dynamically calculated from relation representation, which
shows sufficient interaction.

Furthermore, we propose attribute-combined bi-directional global-filtered
strategy (ABGS) to improve bootstrapping, reduce false samples and generate
high-quality training data.

The experimental results on three real-world cross-lingual datasets are
stable at around 96\% at hits@1 on average, showing that our approach not only
significantly outperforms the state-of-the-art methods, but also is universal
and transferable for existing KGE methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Question Answering over Knowledge Graphs with Neural Machine Translation and Entity Linking. (arXiv:2107.02865v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diomedi_D/0/1/0/all/0/1">Daniel Diomedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hogan_A/0/1/0/all/0/1">Aidan Hogan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02865">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of Question Answering over Knowledge Graphs (KGQA) is to find
answers for natural language questions over a knowledge graph. Recent KGQA
approaches adopt a neural machine translation (NMT) approach, where the natural
language question is translated into a structured query language. However, NMT
suffers from the out-of-vocabulary problem, where terms in a question may not
have been seen during training, impeding their translation. This issue is
particularly problematic for the millions of entities that large knowledge
graphs describe. We rather propose a KGQA approach that delegates the
processing of entities to entity linking (EL) systems. NMT is then used to
create a query template with placeholders that are filled by entities
identified in an EL phase. Slot filling is used to decide which entity fills
which placeholder. Experiments for QA over Wikidata show that our approach
outperforms pure NMT: while there remains a strong dependence on having seen
similar query templates during training, errors relating to entities are
greatly reduced.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kosp2e: Korean Speech to English Translation Corpus. (arXiv:2107.02875v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cho_W/0/1/0/all/0/1">Won Ik Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seok Min Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1">Hyunchang Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1">Nam Soo Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02875">
                                    <div class="article-summary-box-inner">
                                        <span>Most speech-to-text (S2T) translation studies use English speech as a source,
which makes it difficult for non-English speakers to take advantage of the S2T
technologies. For some languages, this problem was tackled through corpus
construction, but the farther linguistically from English or the more
under-resourced, this deficiency and underrepresentedness becomes more
significant. In this paper, we introduce kosp2e (read as &#x60;kospi&#x27;), a corpus
that allows Korean speech to be translated into English text in an end-to-end
manner. We adopt open license speech recognition corpus, translation corpus,
and spoken language corpora to make our dataset freely available to the public,
and check the performance through the pipeline and training-based approaches.
Using pipeline and various end-to-end schemes, we obtain the highest BLEU of
21.3 and 18.0 for each based on the English hypothesis, validating the
feasibility of our data. We plan to supplement annotations for other target
languages through community contributions in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topic Modeling in the Voynich Manuscript. (arXiv:2107.02858v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sterneck_R/0/1/0/all/0/1">Rachel Sterneck</a>, <a href="http://arxiv.org/find/cs/1/au:+Polish_A/0/1/0/all/0/1">Annie Polish</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowern_C/0/1/0/all/0/1">Claire Bowern</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02858">
                                    <div class="article-summary-box-inner">
                                        <span>This article presents the results of investigations using topic modeling of
the Voynich Manuscript (Beinecke MS408). Topic modeling is a set of
computational methods which are used to identify clusters of subjects within
text. We use latent dirichlet allocation, latent semantic analysis, and
nonnegative matrix factorization to cluster Voynich pages into &#x60;topics&#x27;. We
then compare the topics derived from the computational models to clusters
derived from the Voynich illustrations and from paleographic analysis. We find
that computationally derived clusters match closely to a conjunction of scribe
and subject matter (as per the illustrations), providing further evidence that
the Voynich Manuscript contains meaningful text.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparative Study of Modular and Joint Approaches for Speaker-Attributed ASR on Monaural Long-Form Audio. (arXiv:2107.02852v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1">Naoyuki Kanda</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiao_X/0/1/0/all/0/1">Xiong Xiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_T/0/1/0/all/0/1">Tianyan Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Gaur_Y/0/1/0/all/0/1">Yashesh Gaur</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_X/0/1/0/all/0/1">Xiaofei Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1">Zhong Meng</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1">Zhuo Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yoshioka_T/0/1/0/all/0/1">Takuya Yoshioka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02852">
                                    <div class="article-summary-box-inner">
                                        <span>Speaker-attributed automatic speech recognition (SA-ASR) is a task to
recognize &quot;who spoke what&quot; from multi-talker recordings. An SA-ASR system
usually consists of multiple modules such as speech separation, speaker
diarization and ASR. On the other hand, considering the joint optimization, an
end-to-end (E2E) SA-ASR model has recently been proposed with promising results
on simulation data. In this paper, we present our recent study on the
comparison of such modular and joint approaches towards SA-ASR on real monaural
recordings. We develop state-of-the-art SA-ASR systems for both modular and
joint approaches by leveraging large-scale training data, including 75 thousand
hours of ASR training data and the VoxCeleb corpus for speaker representation
learning. We also propose a new pipeline that performs the E2E SA-ASR model
after speaker clustering. Our evaluation on the AMI meeting corpus reveals that
after fine-tuning with a small real data, the joint system performs 9.2--29.4%
better in accuracy compared to the best modular system while the modular system
performs better before such fine-tuning. We also conduct various error analyses
to show the remaining issues for the monaural SA-ASR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantically Controllable Scene Generation with Guidance of Explicit Knowledge. (arXiv:2106.04066v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenhao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Eun_K/0/1/0/all/0/1">Kim Ji Eun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04066">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Generative Models (DGMs) are known for their superior capability in
generating realistic data. Extending purely data-driven approaches, recent
specialized DGMs may satisfy additional controllable requirements such as
embedding a traffic sign in a driving scene, by manipulating patterns
\textit{implicitly} in the neuron or feature level. In this paper, we introduce
a novel method to incorporate domain knowledge \textit{explicitly} in the
generation process to achieve semantically controllable scene generation. We
categorize our knowledge into two types to be consistent with the composition
of natural scenes, where the first type represents the property of objects and
the second type represents the relationship among objects. We then propose a
tree-structured generative model to learn complex scene representation, whose
nodes and edges are naturally corresponding to the two types of knowledge
respectively. Knowledge can be explicitly integrated to enable semantically
controllable scene generation by imposing semantic rules on properties of nodes
and edges in the tree structure. We construct a synthetic example to illustrate
the controllability and explainability of our method in a clean setting. We
further extend the synthetic example to realistic autonomous vehicle driving
environments and conduct extensive experiments to show that our method
efficiently identifies adversarial traffic scenes against different
state-of-the-art 3D point cloud segmentation models satisfying the traffic
rules specified as the explicit knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ICDAR 2021 Competition on Components Segmentation Task of Document Photos. (arXiv:2106.08499v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Junior_C/0/1/0/all/0/1">Celso A. M. Lopes Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Junior_R/0/1/0/all/0/1">Ricardo B. das Neves Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Bezerra_B/0/1/0/all/0/1">Byron L. D. Bezerra</a>, <a href="http://arxiv.org/find/cs/1/au:+Toselli_A/0/1/0/all/0/1">Alejandro H. Toselli</a>, <a href="http://arxiv.org/find/cs/1/au:+Impedovo_D/0/1/0/all/0/1">Donato Impedovo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08499">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the short-term competition on Components Segmentation
Task of Document Photos that was prepared in the context of the 16th
International Conference on Document Analysis and Recognition (ICDAR 2021).
This competition aims to bring together researchers working on the filed of
identification document image processing and provides them a suitable benchmark
to compare their techniques on the component segmentation task of document
images. Three challenge tasks were proposed entailing different segmentation
assignments to be performed on a provided dataset. The collected data are from
several types of Brazilian ID documents, whose personal information was
conveniently replaced. There were 16 participants whose results obtained for
some or all the three tasks show different rates for the adopted metrics, like
Dice Similarity Coefficient ranging from 0.06 to 0.99. Different Deep Learning
models were applied by the entrants with diverse strategies to achieve the best
results in each of the tasks. Obtained results show that the current applied
methods for solving one of the proposed tasks (document boundary detection) are
already well stablished. However, for the other two challenge tasks (text zone
and handwritten sign detection) research and development of more robust
approaches are still required to achieve acceptable results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Shape Completion via IMLE. (arXiv:2106.16237v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arora_H/0/1/0/all/0/1">Himanshu Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Saurabh Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shichong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahdavi_Amiri_A/0/1/0/all/0/1">Ali Mahdavi-Amiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.16237">
                                    <div class="article-summary-box-inner">
                                        <span>Shape completion is the problem of completing partial input shapes such as
partial scans. This problem finds important applications in computer vision and
robotics due to issues such as occlusion or sparsity in real-world data.
However, most of the existing research related to shape completion has been
focused on completing shapes by learning a one-to-one mapping which limits the
diversity and creativity of the produced results. We propose a novel multimodal
shape completion technique that is effectively able to learn a one-to-many
mapping and generates diverse complete shapes. Our approach is based on the
conditional Implicit MaximumLikelihood Estimation (IMLE) technique wherein we
condition our inputs on partial 3D point clouds. We extensively evaluate our
approach by comparing it to various baselines both quantitatively and
qualitatively. We show that our method is superior to alternatives in terms of
completeness and diversity of shapes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interflow: Aggregating Multi-layer Feature Mappings with Attention Mechanism. (arXiv:2106.14073v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhicheng Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14073">
                                    <div class="article-summary-box-inner">
                                        <span>Traditionally, CNN models possess hierarchical structures and utilize the
feature mapping of the last layer to obtain the prediction output. However, it
can be difficulty to settle the optimal network depth and make the middle
layers learn distinguished features. This paper proposes the Interflow
algorithm specially for traditional CNN models. Interflow divides CNNs into
several stages according to the depth and makes predictions by the feature
mappings in each stage. Subsequently, we input these prediction branches into a
well-designed attention module, which learns the weights of these prediction
branches, aggregates them and obtains the final output. Interflow weights and
fuses the features learned in both shallower and deeper layers, making the
feature information at each stage processed reasonably and effectively,
enabling the middle layers to learn more distinguished features, and enhancing
the model representation ability. In addition, Interflow can alleviate gradient
vanishing problem, lower the difficulty of network depth selection, and lighten
possible over-fitting problem by introducing attention mechanism. Besides, it
can avoid network degradation as a byproduct. Compared with the original model,
the CNN model with Interflow achieves higher test accuracy on multiple
benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Face Hallucination via Split-Attention in Split-Attention Network. (arXiv:2010.11575v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanduo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Junjun Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11575">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, convolutional neural networks (CNNs) have been widely employed to
promote the face hallucination due to the ability to predict high-frequency
details from a large number of samples. However, most of them fail to take into
account the overall facial profile and fine texture details simultaneously,
resulting in reduced naturalness and fidelity of the reconstructed face, and
further impairing the performance of downstream tasks (e.g., face detection,
facial recognition). To tackle this issue, we propose a novel external-internal
split attention group (ESAG), which encompasses two paths responsible for
facial structure information and facial texture details, respectively. By
fusing the features from these two paths, the consistency of facial structure
and the fidelity of facial details are strengthened at the same time. Then, we
propose a split-attention in split-attention network (SISN) to reconstruct
photorealistic high-resolution facial images by cascading several ESAGs.
Experimental results on face hallucination and face recognition unveil that the
proposed method not only significantly improves the clarity of hallucinated
faces, but also encourages the subsequent face recognition performance
substantially. Codes have been released at
https://github.com/mdswyz/SISN-Face-Hallucination.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DSANet: Dynamic Segment Aggregation Network for Video-Level Representation Learning. (arXiv:2105.12085v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yanwu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_M/0/1/0/all/0/1">Mingde Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zichao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yifeng Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12085">
                                    <div class="article-summary-box-inner">
                                        <span>Long-range and short-range temporal modeling are two complementary and
crucial aspects of video recognition. Most of the state-of-the-arts focus on
short-range spatio-temporal modeling and then average multiple snippet-level
predictions to yield the final video-level prediction. Thus, their video-level
prediction does not consider spatio-temporal features of how video evolves
along the temporal dimension. In this paper, we introduce a novel Dynamic
Segment Aggregation (DSA) module to capture relationship among snippets. To be
more specific, we attempt to generate a dynamic kernel for a convolutional
operation to aggregate long-range temporal information among adjacent snippets
adaptively. The DSA module is an efficient plug-and-play module and can be
combined with the off-the-shelf clip-based models (i.e., TSM, I3D) to perform
powerful long-range modeling with minimal overhead. The final video
architecture, coined as DSANet. We conduct extensive experiments on several
video recognition benchmarks (i.e., Mini-Kinetics-200, Kinetics-400,
Something-Something V1 and ActivityNet) to show its superiority. Our proposed
DSA module is shown to benefit various video recognition models significantly.
For example, equipped with DSA modules, the top-1 accuracy of I3D ResNet-50 is
improved from 74.9% to 78.2% on Kinetics-400. Codes are available at
https://github.com/whwu95/DSANet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KaFiStO: A Kalman Filtering Framework for Stochastic Optimization. (arXiv:2107.03331v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Davtyan_A/0/1/0/all/0/1">Aram Davtyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sameni_S/0/1/0/all/0/1">Sepehr Sameni</a>, <a href="http://arxiv.org/find/cs/1/au:+Cerkezi_L/0/1/0/all/0/1">Llukman Cerkezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Meishvilli_G/0/1/0/all/0/1">Givi Meishvilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielski_A/0/1/0/all/0/1">Adam Bielski</a>, <a href="http://arxiv.org/find/cs/1/au:+Favaro_P/0/1/0/all/0/1">Paolo Favaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03331">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization is often cast as a deterministic problem, where the solution is
found through some iterative procedure such as gradient descent. However, when
training neural networks the loss function changes over (iteration) time due to
the randomized selection of a subset of the samples. This randomization turns
the optimization problem into a stochastic one. We propose to consider the loss
as a noisy observation with respect to some reference optimum. This
interpretation of the loss allows us to adopt Kalman filtering as an optimizer,
as its recursive formulation is designed to estimate unknown parameters from
noisy measurements. Moreover, we show that the Kalman Filter dynamical model
for the evolution of the unknown parameters can be used to capture the gradient
dynamics of advanced methods such as Momentum and Adam. We call this stochastic
optimization method KaFiStO. KaFiStO is an easy to implement, scalable, and
efficient method to train neural networks. We show that it also yields
parameter estimates that are on par with or better than existing optimization
algorithms across several neural network architectures and machine learning
tasks, such as computer vision and language modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Alternative Practice of Tropical Convolution to Traditional Convolutional Neural Networks. (arXiv:2103.02096v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_S/0/1/0/all/0/1">Shiqing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liying_L/0/1/0/all/0/1">Liu Liying</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Ye Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02096">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have been used in many machine learning
fields. In practical applications, the computational cost of convolutional
neural networks is often high with the deepening of the network and the growth
of data volume, mostly due to a large amount of multiplication operations of
floating-point numbers in convolution operations. To reduce the amount of
multiplications, we propose a new type of CNNs called Tropical Convolutional
Neural Networks (TCNNs) which are built on tropical convolutions in which the
multiplications and additions in conventional convolutional layers are replaced
by additions and min/max operations respectively. In addition, since tropical
convolution operators are essentially nonlinear operators, we expect TCNNs to
have higher nonlinear fitting ability than conventional CNNs. In the
experiments, we test and analyze several different architectures of TCNNs for
image classification tasks in comparison with similar-sized conventional CNNs.
The results show that TCNN can achieve higher expressive power than ordinary
convolutional layers on the MNIST and CIFAR10 image data set. In different
noise environments, there are wins and losses in the robustness of TCNN and
ordinary CNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interventional Video Grounding with Dual Contrastive Learning. (arXiv:2106.11013v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nan_G/0/1/0/all/0/1">Guoshun Nan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_R/0/1/0/all/0/1">Rui Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Leng_S/0/1/0/all/0/1">Sicong Leng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wei Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11013">
                                    <div class="article-summary-box-inner">
                                        <span>Video grounding aims to localize a moment from an untrimmed video for a given
textual query. Existing approaches focus more on the alignment of visual and
language stimuli with various likelihood-based matching or regression
strategies, i.e., P(Y|X). Consequently, these models may suffer from spurious
correlations between the language and video features due to the selection bias
of the dataset. 1) To uncover the causality behind the model and data, we first
propose a novel paradigm from the perspective of the causal inference, i.e.,
interventional video grounding (IVG) that leverages backdoor adjustment to
deconfound the selection bias based on structured causal model (SCM) and
do-calculus P(Y|do(X)). Then, we present a simple yet effective method to
approximate the unobserved confounder as it cannot be directly sampled from the
dataset. 2) Meanwhile, we introduce a dual contrastive learning approach (DCL)
to better align the text and video by maximizing the mutual information (MI)
between query and video clips, and the MI between start/end frames of a target
moment and the others within a video to learn more informative visual
representations. Experiments on three standard benchmarks show the
effectiveness of our approaches. Our code is available on GitHub:
https://github.com/nanguoshun/IVG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Architecture Pruning for Transfer Learning. (arXiv:2107.03375v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Colombo_N/0/1/0/all/0/1">Nicolo Colombo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03375">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new gradient-based approach for extracting sub-architectures
from a given large model. Contrarily to existing pruning methods, which are
unable to disentangle the network architecture and the corresponding weights,
our architecture-pruning scheme produces transferable new structures that can
be successfully retrained to solve different tasks. We focus on a
transfer-learning setup where architectures can be trained on a large data set
but very few data points are available for fine-tuning them on new tasks. We
define a new gradient-based algorithm that trains architectures of arbitrarily
low complexity independently from the attached weights. Given a search space
defined by an existing large neural model, we reformulate the architecture
search task as a complexity-penalized subset-selection problem and solve it
through a two-temperature relaxation scheme. We provide theoretical convergence
guarantees and validate the proposed transfer-learning strategy on real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An automatic multi-tissue human fetal brain segmentation benchmark using the Fetal Tissue Annotation Dataset. (arXiv:2010.15526v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Payette_K/0/1/0/all/0/1">Kelly Payette</a>, <a href="http://arxiv.org/find/eess/1/au:+Dumast_P/0/1/0/all/0/1">Priscille de Dumast</a>, <a href="http://arxiv.org/find/eess/1/au:+Kebiri_H/0/1/0/all/0/1">Hamza Kebiri</a>, <a href="http://arxiv.org/find/eess/1/au:+Ezhov_I/0/1/0/all/0/1">Ivan Ezhov</a>, <a href="http://arxiv.org/find/eess/1/au:+Paetzold_J/0/1/0/all/0/1">Johannes C. Paetzold</a>, <a href="http://arxiv.org/find/eess/1/au:+Shit_S/0/1/0/all/0/1">Suprosanna Shit</a>, <a href="http://arxiv.org/find/eess/1/au:+Iqbal_A/0/1/0/all/0/1">Asim Iqbal</a>, <a href="http://arxiv.org/find/eess/1/au:+Khan_R/0/1/0/all/0/1">Romesa Khan</a>, <a href="http://arxiv.org/find/eess/1/au:+Kottke_R/0/1/0/all/0/1">Raimund Kottke</a>, <a href="http://arxiv.org/find/eess/1/au:+Grehten_P/0/1/0/all/0/1">Patrice Grehten</a>, <a href="http://arxiv.org/find/eess/1/au:+Ji_H/0/1/0/all/0/1">Hui Ji</a>, <a href="http://arxiv.org/find/eess/1/au:+Lanczi_L/0/1/0/all/0/1">Levente Lanczi</a>, <a href="http://arxiv.org/find/eess/1/au:+Nagy_M/0/1/0/all/0/1">Marianna Nagy</a>, <a href="http://arxiv.org/find/eess/1/au:+Beresova_M/0/1/0/all/0/1">Monika Beresova</a>, <a href="http://arxiv.org/find/eess/1/au:+Nguyen_T/0/1/0/all/0/1">Thi Dao Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Natalucci_G/0/1/0/all/0/1">Giancarlo Natalucci</a>, <a href="http://arxiv.org/find/eess/1/au:+Karayannis_T/0/1/0/all/0/1">Theofanis Karayannis</a>, <a href="http://arxiv.org/find/eess/1/au:+Menze_B/0/1/0/all/0/1">Bjoern Menze</a>, <a href="http://arxiv.org/find/eess/1/au:+Cuadra_M/0/1/0/all/0/1">Meritxell Bach Cuadra</a>, <a href="http://arxiv.org/find/eess/1/au:+Jakab_A/0/1/0/all/0/1">Andras Jakab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15526">
                                    <div class="article-summary-box-inner">
                                        <span>It is critical to quantitatively analyse the developing human fetal brain in
order to fully understand neurodevelopment in both normal fetuses and those
with congenital disorders. To facilitate this analysis, automatic multi-tissue
fetal brain segmentation algorithms are needed, which in turn requires open
databases of segmented fetal brains. Here we introduce a publicly available
database of 50 manually segmented pathological and non-pathological fetal
magnetic resonance brain volume reconstructions across a range of gestational
ages (20 to 33 weeks) into 7 different tissue categories (external
cerebrospinal fluid, grey matter, white matter, ventricles, cerebellum, deep
grey matter, brainstem/spinal cord). In addition, we quantitatively evaluate
the accuracy of several automatic multi-tissue segmentation algorithms of the
developing human fetal brain. Four research groups participated, submitting a
total of 10 algorithms, demonstrating the benefits the database for the
development of automatic algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralised Learning from Independent Multi-Domain Labels for Person Re-Identification. (arXiv:2006.04150v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1">Guile Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1">Shaogang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04150">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has been successful for many computer vision tasks due to the
availability of shared and centralised large-scale training data. However,
increasing awareness of privacy concerns poses new challenges to deep learning,
especially for human subject related recognition such as person
re-identification (Re-ID). In this work, we solve the Re-ID problem by
decentralised learning from non-shared private training data distributed at
multiple user sites of independent multi-domain label spaces. We propose a
novel paradigm called Federated Person Re-Identification (FedReID) to construct
a generalisable global model (a central server) by simultaneously learning with
multiple privacy-preserved local models (local clients). Specifically, each
local client receives global model updates from the server and trains a local
model using its local data independent from all the other clients. Then, the
central server aggregates transferrable local model updates to construct a
generalisable global feature embedding model without accessing local data so to
preserve local privacy. This client-server collaborative learning process is
iteratively performed under privacy control, enabling FedReID to realise
decentralised learning without sharing distributed data nor collecting any
centralised data. Extensive experiments on ten Re-ID benchmarks show that
FedReID achieves compelling generalisation performance beyond any locally
trained models without using shared training data, whilst inherently protects
the privacy of each local client. This is uniquely advantageous over
contemporary Re-ID methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partial 3D Object Retrieval using Local Binary QUICCI Descriptors and Dissimilarity Tree Indexing. (arXiv:2107.03368v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blokland_B/0/1/0/all/0/1">Bart Iver van Blokland</a>, <a href="http://arxiv.org/find/cs/1/au:+Theoharis_T/0/1/0/all/0/1">Theoharis Theoharis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03368">
                                    <div class="article-summary-box-inner">
                                        <span>A complete pipeline is presented for accurate and efficient partial 3D object
retrieval based on Quick Intersection Count Change Image (QUICCI) binary local
descriptors and a novel indexing tree. It is shown how a modification to the
QUICCI query descriptor makes it ideal for partial retrieval. An indexing
structure called Dissimilarity Tree is proposed which can significantly
accelerate searching the large space of local descriptors; this is applicable
to QUICCI and other binary descriptors. The index exploits the distribution of
bits within descriptors for efficient retrieval. The retrieval pipeline is
tested on the artificial part of SHREC&#x27;16 dataset with near-ideal retrieval
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-VAE: Learning Disentangled View-common and View-peculiar Visual Representations for Multi-view Clustering. (arXiv:2106.11232v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yazhou Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Huayi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_X/0/1/0/all/0/1">Xiaorong Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaofeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Ming Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lifang He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11232">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-view clustering, a long-standing and important research problem,
focuses on mining complementary information from diverse views. However,
existing works often fuse multiple views&#x27; representations or handle clustering
in a common feature space, which may result in their entanglement especially
for visual representations. To address this issue, we present a novel VAE-based
multi-view clustering framework (Multi-VAE) by learning disentangled visual
representations. Concretely, we define a view-common variable and multiple
view-peculiar variables in the generative model. The prior of view-common
variable obeys approximately discrete Gumbel Softmax distribution, which is
introduced to extract the common cluster factor of multiple views. Meanwhile,
the prior of view-peculiar variable follows continuous Gaussian distribution,
which is used to represent each view&#x27;s peculiar visual factors. By controlling
the mutual information capacity to disentangle the view-common and
view-peculiar representations, continuous visual information of multiple views
can be separated so that their common discrete cluster information can be
effectively mined. Experimental results demonstrate that Multi-VAE enjoys the
disentangled and explainable visual representations, while obtaining superior
clustering performance compared with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Deep Neural Network Saliency Visualizations with Gradual Extrapolation. (arXiv:2104.04945v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Szandala_T/0/1/0/all/0/1">Tomasz Szandala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04945">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, an enhancement technique for the class activation mapping
methods such as gradient-weighted class activation maps or excitation
backpropagation is proposed to present the visual explanations of decisions
from convolutional neural network-based models. The proposed idea, called
Gradual Extrapolation, can supplement any method that generates a heatmap
picture by sharpening the output. Instead of producing a coarse localization
map that highlights the important predictive regions in the image, the proposed
method outputs the specific shape that most contributes to the model output.
Thus, the proposed method improves the accuracy of saliency maps. The effect
has been achieved by the gradual propagation of the crude map obtained in the
deep layer through all preceding layers with respect to their activations. In
validation tests conducted on a selected set of images, the faithfulness,
interpretability, and applicability of the method are evaluated. The proposed
technique significantly improves the localization detection of the neural
networks attention at low additional computational costs. Furthermore, the
proposed method is applicable to a variety deep neural network models. The code
for the method can be found at
https://github.com/szandala/gradual-extrapolation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monocular Depth Estimation via Listwise Ranking using the Plackett-Luce Model. (arXiv:2010.13118v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lienen_J/0/1/0/all/0/1">Julian Lienen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>, <a href="http://arxiv.org/find/cs/1/au:+Nommensen_N/0/1/0/all/0/1">Nils Nommensen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13118">
                                    <div class="article-summary-box-inner">
                                        <span>In many real-world applications, the relative depth of objects in an image is
crucial for scene understanding. Recent approaches mainly tackle the problem of
depth prediction in monocular images by treating the problem as a regression
task. Yet, being interested in an order relation in the first place, ranking
methods suggest themselves as a natural alternative to regression, and indeed,
ranking approaches leveraging pairwise comparisons as training information
(&quot;object A is closer to the camera than B&quot;) have shown promising performance on
this problem. In this paper, we elaborate on the use of so-called listwise
ranking as a generalization of the pairwise approach. Our method is based on
the Plackett-Luce (PL) model, a probability distribution on rankings, which we
combine with a state-of-the-art neural network architecture and a simple
sampling strategy to reduce training complexity. Moreover, taking advantage of
the representation of PL as a random utility model, the proposed predictor
offers a natural way to recover (shift-invariant) metric depth information from
ranking-only data provided at training time. An empirical evaluation on several
benchmark datasets in a &quot;zero-shot&quot; setting demonstrates the effectiveness of
our approach compared to existing ranking and regression methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reborn Mechanism: Rethinking the Negative Phase Information Flow in Convolutional Neural Network. (arXiv:2106.07026v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhicheng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Chenglei Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07026">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel nonlinear activation mechanism typically for
convolutional neural network (CNN), named as reborn mechanism. In sharp
contrast to ReLU which cuts off the negative phase value, the reborn mechanism
enjoys the capacity to reborn and reconstruct dead neurons. Compared to other
improved ReLU functions, reborn mechanism introduces a more proper way to
utilize the negative phase information. Extensive experiments validate that
this activation mechanism is able to enhance the model representation ability
more significantly and make the better use of the input data information while
maintaining the advantages of the original ReLU function. Moreover, reborn
mechanism enables a non-symmetry that is hardly achieved by traditional CNNs
and can act as a channel compensation method, offering competitive or even
better performance but with fewer learned parameters than traditional methods.
Reborn mechanism was tested on various benchmark datasets, all obtaining better
performance than previous nonlinear activation functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection and Mitigation of Rare Subclasses in Deep Neural Network Classifiers. (arXiv:1911.12780v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paterson_C/0/1/0/all/0/1">Colin Paterson</a>, <a href="http://arxiv.org/find/cs/1/au:+Calinescu_R/0/1/0/all/0/1">Radu Calinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Picardi_C/0/1/0/all/0/1">Chiara Picardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.12780">
                                    <div class="article-summary-box-inner">
                                        <span>Regions of high-dimensional input spaces that are underrepresented in
training datasets reduce machine-learnt classifier performance, and may lead to
corner cases and unwanted bias for classifiers used in decision making systems.
When these regions belong to otherwise well-represented classes, their presence
and negative impact are very hard to identify. We propose an approach for the
detection and mitigation of such rare subclasses in deep neural network
classifiers. The new approach is underpinned by an easy-to-compute commonality
metric that supports the detection of rare subclasses, and comprises methods
for reducing the impact of these subclasses during both model training and
model exploitation. We demonstrate our approach using two well-known datasets,
MNIST&#x27;s handwritten digits and Kaggle&#x27;s cats/dogs, identifying rare subclasses
and producing models which compensate for subclass rarity. In addition we
demonstrate how our run-time approach increases the ability of users to
identify samples likely to be misclassified at run-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Complexity Guided Network Compression for Biomedical Image Segmentation. (arXiv:2107.02927v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mishra_S/0/1/0/all/0/1">Suraj Mishra</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_D/0/1/0/all/0/1">Danny Z. Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_X/0/1/0/all/0/1">X. Sharon Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02927">
                                    <div class="article-summary-box-inner">
                                        <span>Compression is a standard procedure for making convolutional neural networks
(CNNs) adhere to some specific computing resource constraints. However,
searching for a compressed architecture typically involves a series of
time-consuming training/validation experiments to determine a good compromise
between network size and performance accuracy. To address this, we propose an
image complexity-guided network compression technique for biomedical image
segmentation. Given any resource constraints, our framework utilizes data
complexity and network architecture to quickly estimate a compressed model
which does not require network training. Specifically, we map the dataset
complexity to the target network accuracy degradation caused by compression.
Such mapping enables us to predict the final accuracy for different network
sizes, based on the computed dataset complexity. Thus, one may choose a
solution that meets both the network size and segmentation accuracy
requirements. Finally, the mapping is used to determine the convolutional
layer-wise multiplicative factor for generating a compressed network. We
conduct experiments using 5 datasets, employing 3 commonly-used CNN
architectures for biomedical image segmentation as representative networks. Our
proposed framework is shown to be effective for generating compressed
segmentation networks, retaining up to $\approx 95\%$ of the full-sized network
segmentation accuracy, and at the same time, utilizing $\approx 32x$ fewer
network trainable weights (average reduction) of the full-sized networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlled Caption Generation for Images Through Adversarial Attacks. (arXiv:2107.03050v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aafaq_N/0/1/0/all/0/1">Nayyer Aafaq</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mubarak Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1">Ajmal Mian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03050">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is found to be vulnerable to adversarial examples. However, its
adversarial susceptibility in image caption generation is under-explored. We
study adversarial examples for vision and language models, which typically
adopt an encoder-decoder framework consisting of two major components: a
Convolutional Neural Network (i.e., CNN) for image feature extraction and a
Recurrent Neural Network (RNN) for caption generation. In particular, we
investigate attacks on the visual encoder&#x27;s hidden layer that is fed to the
subsequent recurrent network. The existing methods either attack the
classification layer of the visual encoder or they back-propagate the gradients
from the language model. In contrast, we propose a GAN-based algorithm for
crafting adversarial examples for neural image captioning that mimics the
internal representation of the CNN such that the resulting deep features of the
input image enable a controlled incorrect caption generation through the
recurrent network. Our contribution provides new insights for understanding
adversarial attacks on vision systems with language component. The proposed
method employs two strategies for a comprehensive evaluation. The first
examines if a neural image captioning system can be misled to output targeted
image captions. The second analyzes the possibility of keywords into the
predicted captions. Experiments show that our algorithm can craft effective
adversarial images based on the CNN hidden layers to fool captioning framework.
Moreover, we discover the proposed attack to be highly transferable. Our work
leads to new robustness implications for neural image captioning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Security of Deepfake Detection. (arXiv:2107.02045v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiaoyu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1">Neil Zhenqiang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02045">
                                    <div class="article-summary-box-inner">
                                        <span>Deepfakes pose growing challenges to the trust of information on the
Internet. Thus, detecting deepfakes has attracted increasing attentions from
both academia and industry. State-of-the-art deepfake detection methods consist
of two key components, i.e., face extractor and face classifier, which extract
the face region in an image and classify it to be real/fake, respectively.
Existing studies mainly focused on improving the detection performance in
non-adversarial settings, leaving security of deepfake detection in adversarial
settings largely unexplored. In this work, we aim to bridge the gap. In
particular, we perform a systematic measurement study to understand the
security of the state-of-the-art deepfake detection methods in adversarial
settings. We use two large-scale public deepfakes data sources including
FaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes
are fake face images; and we train state-of-the-art deepfake detection methods.
These detection methods can achieve 0.94--0.99 accuracies in non-adversarial
settings on these datasets. However, our measurement results uncover multiple
security limitations of the deepfake detection methods in adversarial settings.
First, we find that an attacker can evade a face extractor, i.e., the face
extractor fails to extract the correct face regions, via adding small Gaussian
noise to its deepfake images. Second, we find that a face classifier trained
using deepfakes generated by one method cannot detect deepfakes generated by
another method, i.e., an attacker can evade detection via generating deepfakes
using a new method. Third, we find that an attacker can leverage backdoor
attacks developed by the adversarial machine learning community to evade a face
classifier. Our results highlight that deepfake detection should consider the
adversarial nature of the problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly detection and automatic labeling for solar cell quality inspection based on Generative Adversarial Network. (arXiv:2103.03518v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balzategui_J/0/1/0/all/0/1">Julen Balzategui</a>, <a href="http://arxiv.org/find/cs/1/au:+Eciolaza_L/0/1/0/all/0/1">Luka Eciolaza</a>, <a href="http://arxiv.org/find/cs/1/au:+Maestro_Watson_D/0/1/0/all/0/1">Daniel Maestro-Watson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03518">
                                    <div class="article-summary-box-inner">
                                        <span>Quality inspection applications in industry are required to move towards a
zero-defect manufacturing scenario, withnon-destructive inspection and
traceability of 100 % of produced parts. Developing robust fault detection and
classification modelsfrom the start-up of the lines is challenging due to the
difficulty in getting enough representative samples of the faulty patternsand
the need to manually label them. This work presents a methodology to develop a
robust inspection system, targeting thesepeculiarities, in the context of solar
cell manufacturing. The methodology is divided into two phases: In the first
phase, an anomalydetection model based on a Generative Adversarial Network
(GAN) is employed. This model enables the detection and localizationof
anomalous patterns within the solar cells from the beginning, using only
non-defective samples for training and without anymanual labeling involved. In
a second stage, as defective samples arise, the detected anomalies will be used
as automaticallygenerated annotations for the supervised training of a Fully
Convolutional Network that is capable of detecting multiple types offaults. The
experimental results using 1873 EL images of monocrystalline cells show that
(a) the anomaly detection scheme can beused to start detecting features with
very little available data, (b) the anomaly detection may serve as automatic
labeling in order totrain a supervised model, and (c) segmentation and
classification results of supervised models trained with automatic labels
arecomparable to the ones obtained from the models trained with manual labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised Left Atrium Segmentation with Mutual Consistency Training. (arXiv:2103.02911v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yicheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Minfeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Z/0/1/0/all/0/1">Zongyuan Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02911">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised learning has attracted great attention in the field of
machine learning, especially for medical image segmentation tasks, since it
alleviates the heavy burden of collecting abundant densely annotated data for
training. However, most of existing methods underestimate the importance of
challenging regions (e.g. small branches or blurred edges) during training. We
believe that these unlabeled regions may contain more crucial information to
minimize the uncertainty prediction for the model and should be emphasized in
the training process. Therefore, in this paper, we propose a novel Mutual
Consistency Network (MC-Net) for semi-supervised left atrium segmentation from
3D MR images. Particularly, our MC-Net consists of one encoder and two slightly
different decoders, and the prediction discrepancies of two decoders are
transformed as an unsupervised loss by our designed cycled pseudo label scheme
to encourage mutual consistency. Such mutual consistency encourages the two
decoders to have consistent and low-entropy predictions and enables the model
to gradually capture generalized features from these unlabeled challenging
regions. We evaluate our MC-Net on the public Left Atrium (LA) database and it
obtains impressive performance gains by exploiting the unlabeled data
effectively. Our MC-Net outperforms six recent semi-supervised methods for left
atrium segmentation, and sets the new state-of-the-art performance on the LA
database.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Residual Star Generative Adversarial Network for multi-domain Image Super-Resolution. (arXiv:2107.03145v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Umer_R/0/1/0/all/0/1">Rao Muhammad Umer</a>, <a href="http://arxiv.org/find/eess/1/au:+Munir_A/0/1/0/all/0/1">Asad Munir</a>, <a href="http://arxiv.org/find/eess/1/au:+Micheloni_C/0/1/0/all/0/1">Christian Micheloni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03145">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, most of state-of-the-art single image super-resolution (SISR)
methods have attained impressive performance by using deep convolutional neural
networks (DCNNs). The existing SR methods have limited performance due to a
fixed degradation settings, i.e. usually a bicubic downscaling of
low-resolution (LR) image. However, in real-world settings, the LR degradation
process is unknown which can be bicubic LR, bilinear LR, nearest-neighbor LR,
or real LR. Therefore, most SR methods are ineffective and inefficient in
handling more than one degradation settings within a single network. To handle
the multiple degradation, i.e. refers to multi-domain image super-resolution,
we propose a deep Super-Resolution Residual StarGAN (SR2*GAN), a novel and
scalable approach that super-resolves the LR images for the multiple LR domains
using only a single model. The proposed scheme is trained in a StarGAN like
network topology with a single generator and discriminator networks. We
demonstrate the effectiveness of our proposed approach in quantitative and
qualitative experiments compared to other state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Categorical Relation-Preserving Contrastive Knowledge Distillation for Medical Image Classification. (arXiv:2107.03225v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1">Xiaohan Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yuenan Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yixuan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_M/0/1/0/all/0/1">Max Q.-H. Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03225">
                                    <div class="article-summary-box-inner">
                                        <span>The amount of medical images for training deep classification models is
typically very scarce, making these deep models prone to overfit the training
data. Studies showed that knowledge distillation (KD), especially the
mean-teacher framework which is more robust to perturbations, can help mitigate
the over-fitting effect. However, directly transferring KD from computer vision
to medical image classification yields inferior performance as medical images
suffer from higher intra-class variance and class imbalance. To address these
issues, we propose a novel Categorical Relation-preserving Contrastive
Knowledge Distillation (CRCKD) algorithm, which takes the commonly used
mean-teacher model as the supervisor. Specifically, we propose a novel
Class-guided Contrastive Distillation (CCD) module to pull closer positive
image pairs from the same class in the teacher and student models, while
pushing apart negative image pairs from different classes. With this
regularization, the feature distribution of the student model shows higher
intra-class similarity and inter-class variance. Besides, we propose a
Categorical Relation Preserving (CRP) loss to distill the teacher&#x27;s relational
knowledge in a robust and class-balanced manner. With the contribution of the
CCD and CRP, our CRCKD algorithm can distill the relational knowledge more
comprehensively. Extensive experiments on the HAM10000 and APTOS datasets
demonstrate the superiority of the proposed CRCKD method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-View Exocentric to Egocentric Video Synthesis. (arXiv:2107.03120v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Gaowen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1">Hugo Latapie</a>, <a href="http://arxiv.org/find/cs/1/au:+Corso_J/0/1/0/all/0/1">Jason Corso</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yan Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03120">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-view video synthesis task seeks to generate video sequences of one view
from another dramatically different view. In this paper, we investigate the
exocentric (third-person) view to egocentric (first-person) view video
generation task. This is challenging because egocentric view sometimes is
remarkably different from the exocentric view. Thus, transforming the
appearances across the two different views is a non-trivial task. Particularly,
we propose a novel Bi-directional Spatial Temporal Attention Fusion Generative
Adversarial Network (STA-GAN) to learn both spatial and temporal information to
generate egocentric video sequences from the exocentric view. The proposed
STA-GAN consists of three parts: temporal branch, spatial branch, and attention
fusion. First, the temporal and spatial branches generate a sequence of fake
frames and their corresponding features. The fake frames are generated in both
downstream and upstream directions for both temporal and spatial branches.
Next, the generated four different fake frames and their corresponding features
(spatial and temporal branches in two directions) are fed into a novel
multi-generation attention fusion module to produce the final video sequence.
Meanwhile, we also propose a novel temporal and spatial dual-discriminator for
more robust network optimization. Extensive experiments on the Side2Ego and
Top2Ego datasets show that the proposed STA-GAN significantly outperforms the
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is 2D Heatmap Representation Even Necessary for Human Pose Estimation?. (arXiv:2107.03332v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanjie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shoukui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhicheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wankou Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shu-Tao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1">Erjin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03332">
                                    <div class="article-summary-box-inner">
                                        <span>The 2D heatmap representation has dominated human pose estimation for years
due to its high performance. However, heatmap-based approaches have some
drawbacks: 1) The performance drops dramatically in the low-resolution images,
which are frequently encountered in real-world scenarios. 2) To improve the
localization precision, multiple upsample layers may be needed to recover the
feature map resolution from low to high, which are computationally expensive.
3) Extra coordinate refinement is usually necessary to reduce the quantization
error of downscaled heatmaps. To address these issues, we propose a
\textbf{Sim}ple yet promising \textbf{D}isentangled \textbf{R}epresentation for
keypoint coordinate (\emph{SimDR}), reformulating human keypoint localization
as a task of classification. In detail, we propose to disentangle the
representation of horizontal and vertical coordinates for keypoint location,
leading to a more efficient scheme without extra upsampling and refinement.
Comprehensive experiments conducted over COCO dataset show that the proposed
\emph{heatmap-free} methods outperform \emph{heatmap-based} counterparts in all
tested input resolutions, especially in lower resolutions by a large margin.
Code will be made publicly available at \url{https://github.com/leeyegy/SimDR}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long Short-Term Transformer for Online Action Detection. (arXiv:2107.03377v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingze Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhuowen Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03377">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present Long Short-term TRansformer (LSTR), a new temporal
modeling algorithm for online action detection, by employing a long- and
short-term memories mechanism that is able to model prolonged sequence data. It
consists of an LSTR encoder that is capable of dynamically exploiting
coarse-scale historical information from an extensively long time window (e.g.,
2048 long-range frames of up to 8 minutes), together with an LSTR decoder that
focuses on a short time window (e.g., 32 short-range frames of 8 seconds) to
model the fine-scale characterization of the ongoing event. Compared to prior
work, LSTR provides an effective and efficient method to model long videos with
less heuristic algorithm design. LSTR achieves significantly improved results
on standard online action detection benchmarks, THUMOS&#x27;14, TVSeries, and HACS
Segment, over the existing state-of-the-art approaches. Extensive empirical
analysis validates the setup of the long- and short-term memories and the
design choices of LSTR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Space Regularization for Unsupervised Domain Adaptation in Semantic Segmentation. (arXiv:2104.02633v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbato_F/0/1/0/all/0/1">Francesco Barbato</a>, <a href="http://arxiv.org/find/cs/1/au:+Toldo_M/0/1/0/all/0/1">Marco Toldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Michieli_U/0/1/0/all/0/1">Umberto Michieli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanuttigh_P/0/1/0/all/0/1">Pietro Zanuttigh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02633">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks for semantic segmentation achieve
outstanding accuracy, however they also have a couple of major drawbacks:
first, they do not generalize well to distributions slightly different from the
one of the training data; second, they require a huge amount of labeled data
for their optimization. In this paper, we introduce feature-level space-shaping
regularization strategies to reduce the domain discrepancy in semantic
segmentation. In particular, for this purpose we jointly enforce a clustering
objective, a perpendicularity constraint and a norm alignment goal on the
feature vectors corresponding to source and target samples. Additionally, we
propose a novel measure able to capture the relative efficacy of an adaptation
strategy compared to supervised training. We verify the effectiveness of such
methods in the autonomous driving setting achieving state-of-the-art results in
multiple synthetic-to-real road scenes benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Samplets: A new paradigm for data compression. (arXiv:2107.03337v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Harbrecht_H/0/1/0/all/0/1">Helmut Harbrecht</a>, <a href="http://arxiv.org/find/math/1/au:+Multerer_M/0/1/0/all/0/1">Michael Multerer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03337">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we introduce the novel concept of samplets by transferring
the construction of Tausch-White wavelets to the realm of data. This way we
obtain a multilevel representation of discrete data which directly enables data
compression, detection of singularities and adaptivity. Applying samplets to
represent kernel matrices, as they arise in kernel based learning or Gaussian
process regression, we end up with quasi-sparse matrices. By thresholding small
entries, these matrices are compressible to O(N log N) relevant entries, where
N is the number of data points. This feature allows for the use of fill-in
reducing reorderings to obtain a sparse factorization of the compressed
matrices. Besides the comprehensive introduction to samplets and their
properties, we present extensive numerical studies to benchmark the approach.
Our results demonstrate that samplets mark a considerable step in the direction
of making large data sets accessible for analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Medical Transformer: Gated Axial-Attention for Medical Image Segmentation. (arXiv:2102.10662v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1">Jeya Maria Jose Valanarasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Oza_P/0/1/0/all/0/1">Poojan Oza</a>, <a href="http://arxiv.org/find/cs/1/au:+Hacihaliloglu_I/0/1/0/all/0/1">Ilker Hacihaliloglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10662">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past decade, Deep Convolutional Neural Networks have been widely
adopted for medical image segmentation and shown to achieve adequate
performance. However, due to the inherent inductive biases present in the
convolutional architectures, they lack understanding of long-range dependencies
in the image. Recently proposed Transformer-based architectures that leverage
self-attention mechanism encode long-range dependencies and learn
representations that are highly expressive. This motivates us to explore
Transformer-based solutions and study the feasibility of using
Transformer-based network architectures for medical image segmentation tasks.
Majority of existing Transformer-based network architectures proposed for
vision applications require large-scale datasets to train properly. However,
compared to the datasets for vision applications, for medical imaging the
number of data samples is relatively low, making it difficult to efficiently
train transformers for medical applications. To this end, we propose a Gated
Axial-Attention model which extends the existing architectures by introducing
an additional control mechanism in the self-attention module. Furthermore, to
train the model effectively on medical images, we propose a Local-Global
training strategy (LoGo) which further improves the performance. Specifically,
we operate on the whole image and patches to learn global and local features,
respectively. The proposed Medical Transformer (MedT) is evaluated on three
different medical image segmentation datasets and it is shown that it achieves
better performance than the convolutional and other related transformer-based
architectures. Code: https://github.com/jeya-maria-jose/Medical-Transformer</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Egocentric Videoconferencing. (arXiv:2107.03109v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elgharib_M/0/1/0/all/0/1">Mohamed Elgharib</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendiratta_M/0/1/0/all/0/1">Mohit Mendiratta</a>, <a href="http://arxiv.org/find/cs/1/au:+Thies_J/0/1/0/all/0/1">Justus Thies</a>, <a href="http://arxiv.org/find/cs/1/au:+Niessner_M/0/1/0/all/0/1">Matthias Nie&#xdf;ner</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidel_H/0/1/0/all/0/1">Hans-Peter Seidel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1">Ayush Tewari</a>, <a href="http://arxiv.org/find/cs/1/au:+Golyanik_V/0/1/0/all/0/1">Vladislav Golyanik</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03109">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a method for egocentric videoconferencing that enables
hands-free video calls, for instance by people wearing smart glasses or other
mixed-reality devices. Videoconferencing portrays valuable non-verbal
communication and face expression cues, but usually requires a front-facing
camera. Using a frontal camera in a hands-free setting when a person is on the
move is impractical. Even holding a mobile phone camera in the front of the
face while sitting for a long duration is not convenient. To overcome these
issues, we propose a low-cost wearable egocentric camera setup that can be
integrated into smart glasses. Our goal is to mimic a classical video call, and
therefore, we transform the egocentric perspective of this camera into a front
facing video. To this end, we employ a conditional generative adversarial
neural network that learns a transition from the highly distorted egocentric
views to frontal views common in videoconferencing. Our approach learns to
transfer expression details directly from the egocentric view without using a
complex intermediate parametric expressions model, as it is used by related
face reenactment methods. We successfully handle subtle expressions, not easily
captured by parametric blendshape-based solutions, e.g., tongue movement, eye
movements, eye blinking, strong expressions and depth varying movements. To get
control over the rigid head movements in the target view, we condition the
generator on synthetic renderings of a moving neutral face. This allows us to
synthesis results at different head poses. Our technique produces temporally
smooth video-realistic renderings in real-time using a video-to-video
translation network in conjunction with a temporal discriminator. We
demonstrate the improved capabilities of our technique by comparing against
related state-of-the art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HIDA: Towards Holistic Indoor Understanding for the Visually Impaired via Semantic Instance Segmentation with a Wearable Solid-State LiDAR Sensor. (arXiv:2107.03180v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Huayao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruiping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1">Kunyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiefelhagen_R/0/1/0/all/0/1">Rainer Stiefelhagen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03180">
                                    <div class="article-summary-box-inner">
                                        <span>Independently exploring unknown spaces or finding objects in an indoor
environment is a daily but challenging task for visually impaired people.
However, common 2D assistive systems lack depth relationships between various
objects, resulting in difficulty to obtain accurate spatial layout and relative
positions of objects. To tackle these issues, we propose HIDA, a lightweight
assistive system based on 3D point cloud instance segmentation with a
solid-state LiDAR sensor, for holistic indoor detection and avoidance. Our
entire system consists of three hardware components, two interactive
functions~(obstacle avoidance and object finding) and a voice user interface.
Based on voice guidance, the point cloud from the most recent state of the
changing indoor environment is captured through an on-site scanning performed
by the user. In addition, we design a point cloud segmentation model with dual
lightweight decoders for semantic and offset predictions, which satisfies the
efficiency of the whole system. After the 3D instance segmentation, we
post-process the segmented point cloud by removing outliers and projecting all
points onto a top-view 2D map representation. The system integrates the
information above and interacts with users intuitively by acoustic feedback.
The proposed 3D instance segmentation model has achieved state-of-the-art
performance on ScanNet v2 dataset. Comprehensive field tests with various tasks
in a user study verify the usability and effectiveness of our system for
assisting visually impaired people in holistic indoor understanding, obstacle
avoidance and object search.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Semantic Segmentation using Psychometric Learning. (arXiv:2107.03212v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_L/0/1/0/all/0/1">Lu Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Menkovski_V/0/1/0/all/0/1">Vlado Menkovski</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shiwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03212">
                                    <div class="article-summary-box-inner">
                                        <span>Assigning meaning to parts of image data is the goal of semantic image
segmentation. Machine learning methods, specifically supervised learning is
commonly used in a variety of tasks formulated as semantic segmentation. One of
the major challenges in the supervised learning approaches is expressing and
collecting the rich knowledge that experts have with respect to the meaning
present in the image data. Towards this, typically a fixed set of labels is
specified and experts are tasked with annotating the pixels, patches or
segments in the images with the given labels. In general, however, the set of
classes does not fully capture the rich semantic information present in the
images. For example, in medical imaging such as histology images, the different
parts of cells could be grouped and sub-grouped based on the expertise of the
pathologist.

To achieve such a precise semantic representation of the concepts in the
image, we need access to the full depth of knowledge of the annotator. In this
work, we develop a novel approach to collect segmentation annotations from
experts based on psychometric testing. Our method consists of the psychometric
testing procedure, active query selection, query enhancement, and a deep metric
learning model to achieve a patch-level image embedding that allows for
semantic segmentation of images. We show the merits of our method with
evaluation on the synthetically generated image, aerial image and histology
image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating Generation Shifts for Generalized Zero-Shot Learning. (arXiv:2107.03163v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yadan Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_R/0/1/0/all/0/1">Ruihong Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jingjing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03163">
                                    <div class="article-summary-box-inner">
                                        <span>Generalized Zero-Shot Learning (GZSL) is the task of leveraging semantic
information (e.g., attributes) to recognize the seen and unseen samples, where
unseen classes are not observable during training. It is natural to derive
generative models and hallucinate training samples for unseen classes based on
the knowledge learned from the seen samples. However, most of these models
suffer from the &#x60;generation shifts&#x27;, where the synthesized samples may drift
from the real distribution of unseen data. In this paper, we conduct an
in-depth analysis on this issue and propose a novel Generation Shifts
Mitigating Flow (GSMFlow) framework, which is comprised of multiple conditional
affine coupling layers for learning unseen data synthesis efficiently and
effectively. In particular, we identify three potential problems that trigger
the generation shifts, i.e., semantic inconsistency, variance decay, and
structural permutation and address them respectively. First, to reinforce the
correlations between the generated samples and the respective attributes, we
explicitly embed the semantic information into the transformations in each of
the coupling layers. Second, to recover the intrinsic variance of the
synthesized unseen features, we introduce a visual perturbation strategy to
diversify the intra-class variance of generated data and hereby help adjust the
decision boundary of the classifier. Third, to avoid structural permutation in
the semantic space, we propose a relative positioning strategy to manipulate
the attribute embeddings, guiding which to fully preserve the inter-class
geometric structure. Experimental results demonstrate that GSMFlow achieves
state-of-the-art recognition performance in both conventional and generalized
zero-shot settings. Our code is available at:
https://github.com/uqzhichen/GSMFlow</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Action Units Recognition Using Improved Pairwise Deep Architecture. (arXiv:2107.03143v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saito_J/0/1/0/all/0/1">Junya Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_X/0/1/0/all/0/1">Xiaoyu Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_A/0/1/0/all/0/1">Akiyoshi Uchida</a>, <a href="http://arxiv.org/find/cs/1/au:+Youoku_S/0/1/0/all/0/1">Sachihiro Youoku</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamamoto_T/0/1/0/all/0/1">Takahisa Yamamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Murase_K/0/1/0/all/0/1">Kentaro Murase</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03143">
                                    <div class="article-summary-box-inner">
                                        <span>Facial Action Units (AUs) represent a set of facial muscular activities and
various combinations of AUs can represent a wide range of emotions. AU
recognition is often used in many applications, including marketing,
healthcare, education, and so forth. Although a lot of studies have developed
various methods to improve recognition accuracy, it still remains a major
challenge for AU recognition. In the Affective Behavior Analysis in-the-wild
(ABAW) 2020 competition, we proposed a new automatic Action Units (AUs)
recognition method using a pairwise deep architecture to derive the
Pseudo-Intensities of each AU and then convert them into predicted intensities.
This year, we introduced a new technique to last year&#x27;s framework to further
reduce AU recognition errors due to temporary face occlusion such as temporary
face occlusion such as face hiding or large face orientation. We obtained a
score of 0.65 in the validation data set for this year&#x27;s competition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trans4Trans: Efficient Transformer for Transparent Object Segmentation to Help Visually Impaired People Navigate in the Real World. (arXiv:2107.03172v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Constantinescu_A/0/1/0/all/0/1">Angela Constantinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1">Kunyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1">Karin M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiefelhagen_R/0/1/0/all/0/1">Rainer Stiefelhagen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03172">
                                    <div class="article-summary-box-inner">
                                        <span>Common fully glazed facades and transparent objects present architectural
barriers and impede the mobility of people with low vision or blindness, for
instance, a path detected behind a glass door is inaccessible unless it is
correctly perceived and reacted. However, segmenting these safety-critical
objects is rarely covered by conventional assistive technologies. To tackle
this issue, we construct a wearable system with a novel dual-head Transformer
for Transparency (Trans4Trans) model, which is capable of segmenting general
and transparent objects and performing real-time wayfinding to assist people
walking alone more safely. Especially, both decoders created by our proposed
Transformer Parsing Module (TPM) enable effective joint learning from different
datasets. Besides, the efficient Trans4Trans model composed of symmetric
transformer-based encoder and decoder, requires little computational expenses
and is readily deployed on portable GPUs. Our Trans4Trans model outperforms
state-of-the-art methods on the test sets of Stanford2D3D and Trans10K-v2
datasets and obtains mIoU of 45.13% and 75.14%, respectively. Through various
pre-tests and a user study conducted in indoor and outdoor scenarios, the
usability and reliability of our assistive system have been extensively
verified.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation. (arXiv:2107.03358v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Bingchen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03358">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we tackle the problem of novel visual category discovery,
i.e., grouping unlabelled images from new classes into different semantic
partitions by leveraging a labelled dataset that contains images from other
different but relevant categories. This is a more realistic and challenging
setting than conventional semi-supervised learning. We propose a two-branch
learning framework for this problem, with one branch focusing on local
part-level information and the other branch focusing on overall
characteristics. To transfer knowledge from the labelled data to the
unlabelled, we propose using dual ranking statistics on both branches to
generate pseudo labels for training on the unlabelled data. We further
introduce a mutual knowledge distillation method to allow information exchange
and encourage agreement between the two branches for discovering new
categories, allowing our model to enjoy the benefits of global and local
features. We comprehensively evaluate our method on public benchmarks for
generic object classification, as well as the more challenging datasets for
fine-grained visual recognition, achieving state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speaker embeddings by modeling channel-wise correlations. (arXiv:2104.02571v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Stafylakis_T/0/1/0/all/0/1">Themos Stafylakis</a>, <a href="http://arxiv.org/find/eess/1/au:+Rohdin_J/0/1/0/all/0/1">Johan Rohdin</a>, <a href="http://arxiv.org/find/eess/1/au:+Burget_L/0/1/0/all/0/1">Lukas Burget</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02571">
                                    <div class="article-summary-box-inner">
                                        <span>Speaker embeddings extracted with deep 2D convolutional neural networks are
typically modeled as projections of first and second order statistics of
channel-frequency pairs onto a linear layer, using either average or attentive
pooling along the time axis. In this paper we examine an alternative pooling
method, where pairwise correlations between channels for given frequencies are
used as statistics. The method is inspired by style-transfer methods in
computer vision, where the style of an image, modeled by the matrix of
channel-wise correlations, is transferred to another image, in order to produce
a new image having the style of the first and the content of the second. By
drawing analogies between image style and speaker characteristics, and between
image content and phonetic sequence, we explore the use of such channel-wise
correlations features to train a ResNet architecture in an end-to-end fashion.
Our experiments on VoxCeleb demonstrate the effectiveness of the proposed
pooling method in speaker recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FBC-GAN: Diverse and Flexible Image Synthesis via Foreground-Background Composition. (arXiv:2107.03166v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1">Kaiwen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gongjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1">Fangneng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiaxing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03166">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GANs) have become the de-facto standard in
image synthesis. However, without considering the foreground-background
decomposition, existing GANs tend to capture excessive content correlation
between foreground and background, thus constraining the diversity in image
generation. This paper presents a novel Foreground-Background Composition GAN
(FBC-GAN) that performs image generation by generating foreground objects and
background scenes concurrently and independently, followed by composing them
with style and geometrical consistency. With this explicit design, FBC-GAN can
generate images with foregrounds and backgrounds that are mutually independent
in contents, thus lifting the undesirably learned content correlation
constraint and achieving superior diversity. It also provides excellent
flexibility by allowing the same foreground object with different background
scenes, the same background scene with varying foreground objects, or the same
foreground object and background scene with different object positions, sizes
and poses. It can compose foreground objects and background scenes sampled from
different datasets as well. Extensive experiments over multiple datasets show
that FBC-GAN achieves competitive visual realism and superior diversity as
compared with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting with Confidence on Unseen Distributions. (arXiv:2107.03315v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guillory_D/0/1/0/all/0/1">Devin Guillory</a>, <a href="http://arxiv.org/find/cs/1/au:+Shankar_V/0/1/0/all/0/1">Vaishaal Shankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ebrahimi_S/0/1/0/all/0/1">Sayna Ebrahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1">Ludwig Schmidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03315">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that the performance of machine learning models can
vary substantially when models are evaluated on data drawn from a distribution
that is close to but different from the training distribution. As a result,
predicting model performance on unseen distributions is an important challenge.
Our work connects techniques from domain adaptation and predictive uncertainty
literature, and allows us to predict model accuracy on challenging unseen
distributions without access to labeled data. In the context of distribution
shift, distributional distances are often used to adapt models and improve
their performance on new domains, however accuracy estimation, or other forms
of predictive uncertainty, are often neglected in these investigations. Through
investigating a wide range of established distributional distances, such as
Frechet distance or Maximum Mean Discrepancy, we determine that they fail to
induce reliable estimates of performance under distribution shift. On the other
hand, we find that the difference of confidences (DoC) of a classifier&#x27;s
predictions successfully estimates the classifier&#x27;s performance change over a
variety of shifts. We specifically investigate the distinction between
synthetic and natural distribution shifts and observe that despite its
simplicity DoC consistently outperforms other quantifications of distributional
difference. $DoC$ reduces predictive error by almost half ($46\%$) on several
realistic and challenging distribution shifts, e.g., on the ImageNet-Vid-Robust
and ImageNet-Rendition datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning based Micro-expression Recognition: A Survey. (arXiv:2107.02823v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yante Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jinsheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadifoumani_S/0/1/0/all/0/1">Seyednavid Mohammadifoumani</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guoying Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02823">
                                    <div class="article-summary-box-inner">
                                        <span>Micro-expressions (MEs) are involuntary facial movements revealing people&#x27;s
hidden feelings in high-stake situations and have practical importance in
medical treatment, national security, interrogations and many human-computer
interaction systems. Early methods for MER mainly based on traditional
appearance and geometry features. Recently, with the success of deep learning
(DL) in various fields, neural networks have received increasing interests in
MER. Different from macro-expressions, MEs are spontaneous, subtle, and rapid
facial movements, leading to difficult data collection, thus have small-scale
datasets. DL based MER becomes challenging due to above ME characters. To data,
various DL approaches have been proposed to solve the ME issues and improve MER
performance. In this survey, we provide a comprehensive review of deep
micro-expression recognition (MER), including datasets, deep MER pipeline, and
the bench-marking of most influential methods. This survey defines a new
taxonomy for the field, encompassing all aspects of MER based on DL. For each
aspect, the basic approaches and advanced developments are summarized and
discussed. In addition, we conclude the remaining challenges and and potential
directions for the design of robust deep MER systems. To the best of our
knowledge, this is the first survey of deep MER methods, and this survey can
serve as a reference point for future MER research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rotation Transformation Network: Learning View-Invariant Point Cloud for Classification and Segmentation. (arXiv:2107.03105v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shuang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1">Qiulei Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhanyi Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03105">
                                    <div class="article-summary-box-inner">
                                        <span>Many recent works show that a spatial manipulation module could boost the
performances of deep neural networks (DNNs) for 3D point cloud analysis. In
this paper, we aim to provide an insight into spatial manipulation modules.
Firstly, we find that the smaller the rotational degree of freedom (RDF) of
objects is, the more easily these objects are handled by these DNNs. Then, we
investigate the effect of the popular T-Net module and find that it could not
reduce the RDF of objects. Motivated by the above two issues, we propose a
rotation transformation network for point cloud analysis, called RTN, which
could reduce the RDF of input 3D objects to 0. The RTN could be seamlessly
inserted into many existing DNNs for point cloud analysis. Extensive
experimental results on 3D point cloud classification and segmentation tasks
demonstrate that the proposed RTN could improve the performances of several
state-of-the-art methods significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Introducing the structural bases of typicality effects in deep learning. (arXiv:2107.03279v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pino_O/0/1/0/all/0/1">Omar Vidal Pino</a>, <a href="http://arxiv.org/find/cs/1/au:+Nascimento_E/0/1/0/all/0/1">Erickson Rangel Nascimento</a>, <a href="http://arxiv.org/find/cs/1/au:+Campos_M/0/1/0/all/0/1">Mario Fernando Montenegro Campos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03279">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we hypothesize that the effects of the degree of typicality in
natural semantic categories can be generated based on the structure of
artificial categories learned with deep learning models. Motivated by the human
approach to representing natural semantic categories and based on the Prototype
Theory foundations, we propose a novel Computational Prototype Model (CPM) to
represent the internal structure of semantic categories. Unlike other prototype
learning approaches, our mathematical framework proposes a first approach to
provide deep neural networks with the ability to model abstract semantic
concepts such as category central semantic meaning, typicality degree of an
object&#x27;s image, and family resemblance relationship. We proposed several
methodologies based on the typicality&#x27;s concept to evaluate our CPM-model in
image semantic processing tasks such as image classification, a global semantic
description, and transfer learning. Our experiments on different image
datasets, such as ImageNet and Coco, showed that our approach might be an
admissible proposition in the effort to endow machines with greater power of
abstraction for the semantic representation of objects&#x27; categories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Data Balancing for Unlabeled Satellite Imagery. (arXiv:2107.03227v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Deep Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_E/0/1/0/all/0/1">Erin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1">Anirudh Koul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1">Siddha Ganju</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasam_M/0/1/0/all/0/1">Meher Anand Kasam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03227">
                                    <div class="article-summary-box-inner">
                                        <span>Data imbalance is a ubiquitous problem in machine learning. In large scale
collected and annotated datasets, data imbalance is either mitigated manually
by undersampling frequent classes and oversampling rare classes, or planned for
with imputation and augmentation techniques. In both cases balancing data
requires labels. In other words, only annotated data can be balanced.
Collecting fully annotated datasets is challenging, especially for large scale
satellite systems such as the unlabeled NASA&#x27;s 35 PB Earth Imagery dataset.
Although the NASA Earth Imagery dataset is unlabeled, there are implicit
properties of the data source that we can rely on to hypothesize about its
imbalance, such as distribution of land and water in the case of the Earth&#x27;s
imagery. We present a new iterative method to balance unlabeled data. Our
method utilizes image embeddings as a proxy for image labels that can be used
to balance data, and ultimately when trained increases overall accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WeClick: Weakly-Supervised Video Semantic Segmentation with Click Annotations. (arXiv:2107.03088v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peidong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zibin He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xiyu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shutao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Maowei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03088">
                                    <div class="article-summary-box-inner">
                                        <span>Compared with tedious per-pixel mask annotating, it is much easier to
annotate data by clicks, which costs only several seconds for an image.
However, applying clicks to learn video semantic segmentation model has not
been explored before. In this work, we propose an effective weakly-supervised
video semantic segmentation pipeline with click annotations, called WeClick,
for saving laborious annotating effort by segmenting an instance of the
semantic class with only a single click. Since detailed semantic information is
not captured by clicks, directly training with click labels leads to poor
segmentation predictions. To mitigate this problem, we design a novel memory
flow knowledge distillation strategy to exploit temporal information (named
memory flow) in abundant unlabeled video frames, by distilling the neighboring
predictions to the target frame via estimated motion. Moreover, we adopt
vanilla knowledge distillation for model compression. In this case, WeClick
learns compact video semantic segmentation models with the low-cost click
annotations during the training phase yet achieves real-time and accurate
models during the inference period. Experimental results on Cityscapes and
Camvid show that WeClick outperforms the state-of-the-art methods, increases
performance by 10.24% mIoU than baseline, and achieves real-time execution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Odometry with an Event Camera Using Continuous Ray Warping and Volumetric Contrast Maximization. (arXiv:2107.03011v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiaqi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xin Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Peng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Ling Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaben Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kneip_L/0/1/0/all/0/1">Laurent Kneip</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03011">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new solution to tracking and mapping with an event camera. The
motion of the camera contains both rotation and translation, and the
displacements happen in an arbitrarily structured environment. As a result, the
image matching may no longer be represented by a low-dimensional homographic
warping, thus complicating an application of the commonly used Image of Warped
Events (IWE). We introduce a new solution to this problem by performing
contrast maximization in 3D. The 3D location of the rays cast for each event is
smoothly varied as a function of a continuous-time motion parametrization, and
the optimal parameters are found by maximizing the contrast in a volumetric ray
density field. Our method thus performs joint optimization over motion and
structure. The practical validity of our approach is supported by an
application to AGV motion estimation and 3D reconstruction with a single
vehicle-mounted event camera. The method approaches the performance obtained
with regular cameras, and eventually outperforms in challenging visual
conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XPDNet for MRI Reconstruction: an application to the 2020 fastMRI challenge. (arXiv:2010.07290v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ramzi_Z/0/1/0/all/0/1">Zaccharie Ramzi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ciuciu_P/0/1/0/all/0/1">Philippe Ciuciu</a>, <a href="http://arxiv.org/find/eess/1/au:+Starck_J/0/1/0/all/0/1">Jean-Luc Starck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07290">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new neural network, the XPDNet, for MRI reconstruction from
periodically under-sampled multi-coil data. We inform the design of this
network by taking best practices from MRI reconstruction and computer vision.
We show that this network can achieve state-of-the-art reconstruction results,
as shown by its ranking of second in the fastMRI 2020 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Invariant Representation with Consistency and Diversity for Semi-supervised Source Hypothesis Transfer. (arXiv:2107.03008v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaodong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuo_J/0/1/0/all/0/1">Junbao Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuhao Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuhui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03008">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised domain adaptation (SSDA) aims to solve tasks in target domain
by utilizing transferable information learned from the available source domain
and a few labeled target data. However, source data is not always accessible in
practical scenarios, which restricts the application of SSDA in real world
circumstances. In this paper, we propose a novel task named Semi-supervised
Source Hypothesis Transfer (SSHT), which performs domain adaptation based on
source trained model, to generalize well in target domain with a few
supervisions. In SSHT, we are facing two challenges: (1) The insufficient
labeled target data may result in target features near the decision boundary,
with the increased risk of mis-classification; (2) The data are usually
imbalanced in source domain, so the model trained with these data is biased.
The biased model is prone to categorize samples of minority categories into
majority ones, resulting in low prediction diversity. To tackle the above
issues, we propose Consistency and Diversity Learning (CDL), a simple but
effective framework for SSHT by facilitating prediction consistency between two
randomly augmented unlabeled data and maintaining the prediction diversity when
adapting model to target domain. Encouraging consistency regularization brings
difficulty to memorize the few labeled target data and thus enhances the
generalization ability of the learned model. We further integrate Batch
Nuclear-norm Maximization into our method to enhance the discriminability and
diversity. Experimental results show that our method outperforms existing SSDA
methods and unsupervised model adaptation methods on DomainNet, Office-Home and
Office-31 datasets. The code is available at
https://github.com/Wang-xd1899/SSHT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Learning by Integrating Spatial and Frequency Representation. (arXiv:2105.05348v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guanghui Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05348">
                                    <div class="article-summary-box-inner">
                                        <span>Human beings can recognize new objects with only a few labeled examples,
however, few-shot learning remains a challenging problem for machine learning
systems. Most previous algorithms in few-shot learning only utilize spatial
information of the images. In this paper, we propose to integrate the frequency
information into the learning model to boost the discrimination ability of the
system. We employ Discrete Cosine Transformation (DCT) to generate the
frequency representation, then, integrate the features from both the spatial
domain and frequency domain for classification. The proposed strategy and its
effectiveness are validated with different backbones, datasets, and algorithms.
Extensive experiments demonstrate that the frequency information is
complementary to the spatial representations in few-shot classification. The
classification accuracy is boosted significantly by integrating features from
both the spatial and frequency domains in different few-shot learning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FasterPose: A Faster Simple Baseline for Human Pose Estimation. (arXiv:2107.03215v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hanbin Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Hailin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Linfang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yinglu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03215">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of human pose estimation depends on the spatial accuracy of
keypoint localization. Most existing methods pursue the spatial accuracy
through learning the high-resolution (HR) representation from input images. By
the experimental analysis, we find that the HR representation leads to a sharp
increase of computational cost, while the accuracy improvement remains marginal
compared with the low-resolution (LR) representation. In this paper, we propose
a design paradigm for cost-effective network with LR representation for
efficient pose estimation, named FasterPose. Whereas the LR design largely
shrinks the model complexity, yet how to effectively train the network with
respect to the spatial accuracy is a concomitant challenge. We study the
training behavior of FasterPose, and formulate a novel regressive cross-entropy
(RCE) loss function for accelerating the convergence and promoting the
accuracy. The RCE loss generalizes the ordinary cross-entropy loss from the
binary supervision to a continuous range, thus the training of pose estimation
network is able to benefit from the sigmoid function. By doing so, the output
heatmap can be inferred from the LR features without loss of spatial accuracy,
while the computational cost and model size has been significantly reduced.
Compared with the previously dominant network of pose estimation, our method
reduces 58% of the FLOPs and simultaneously gains 1.3% improvement of accuracy.
Extensive experiments show that FasterPose yields promising results on the
common benchmarks, i.e., COCO and MPII, consistently validating the
effectiveness and efficiency for practical utilization, especially the
low-latency and low-energy-budget applications in the non-GPU scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MuVAM: A Multi-View Attention-based Model for Medical Visual Question Answering. (arXiv:2107.03216v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Haiwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shuning He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kejia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_B/0/1/0/all/0/1">Bo Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chunling Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_K/0/1/0/all/0/1">Kun Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03216">
                                    <div class="article-summary-box-inner">
                                        <span>Medical Visual Question Answering (VQA) is a multi-modal challenging task
widely considered by research communities of the computer vision and natural
language processing. Since most current medical VQA models focus on visual
content, ignoring the importance of text, this paper proposes a multi-view
attention-based model(MuVAM) for medical visual question answering which
integrates the high-level semantics of medical images on the basis of text
description. Firstly, different methods are utilized to extract the features of
the image and the question for the two modalities of vision and text. Secondly,
this paper proposes a multi-view attention mechanism that include
Image-to-Question (I2Q) attention and Word-to-Text (W2T) attention. Multi-view
attention can correlate the question with image and word in order to better
analyze the question and get an accurate answer. Thirdly, a composite loss is
presented to predict the answer accurately after multi-modal feature fusion and
improve the similarity between visual and textual cross-modal features. It
consists of classification loss and image-question complementary (IQC) loss.
Finally, for data errors and missing labels in the VQA-RAD dataset, we
collaborate with medical experts to correct and complete this dataset and then
construct an enhanced dataset, VQA-RADPh. The experiments on these two datasets
show that the effectiveness of MuVAM surpasses the state-of-the-art method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IntraLoss: Further Margin via Gradient-Enhancing Term for Deep Face Recognition. (arXiv:2107.03352v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Chengzhi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yanzhou Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Haiwei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haijun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jian Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03352">
                                    <div class="article-summary-box-inner">
                                        <span>Existing classification-based face recognition methods have achieved
remarkable progress, introducing large margin into hypersphere manifold to
learn discriminative facial representations. However, the feature distribution
is ignored. Poor feature distribution will wipe out the performance improvement
brought about by margin scheme. Recent studies focus on the unbalanced
inter-class distribution and form a equidistributed feature representations by
penalizing the angle between identity and its nearest neighbor. But the problem
is more than that, we also found the anisotropy of intra-class distribution. In
this paper, we propose the &#x60;gradient-enhancing term&#x27; that concentrates on the
distribution characteristics within the class. This method, named IntraLoss,
explicitly performs gradient enhancement in the anisotropic region so that the
intra-class distribution continues to shrink, resulting in isotropic and more
compact intra-class distribution and further margin between identities. The
experimental results on LFW, YTF and CFP-FP show that our outperforms
state-of-the-art methods by gradient enhancement, demonstrating the superiority
of our method. In addition, our method has intuitive geometric interpretation
and can be easily combined with existing methods to solve the previously
ignored problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangle Your Dense Object Detector. (arXiv:2107.02963v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zehui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chenhongyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiaofei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Feng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zhengjun Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02963">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based dense object detectors have achieved great success in the
past few years and have been applied to numerous multimedia applications such
as video understanding. However, the current training pipeline for dense
detectors is compromised to lots of conjunctions that may not hold. In this
paper, we investigate three such important conjunctions: 1) only samples
assigned as positive in classification head are used to train the regression
head; 2) classification and regression share the same input feature and
computational fields defined by the parallel head architecture; and 3) samples
distributed in different feature pyramid layers are treated equally when
computing the loss. We first carry out a series of pilot experiments to show
disentangling such conjunctions can lead to persistent performance improvement.
Then, based on these findings, we propose Disentangled Dense Object Detector
(DDOD), in which simple and effective disentanglement mechanisms are designed
and integrated into the current state-of-the-art dense object detectors.
Extensive experiments on MS COCO benchmark show that our approach can lead to
2.0 mAP, 2.4 mAP and 2.2 mAP absolute improvements on RetinaNet, FCOS, and ATSS
baselines with negligible extra overhead. Notably, our best model reaches 55.0
mAP on the COCO test-dev set and 93.5 AP on the hard subset of WIDER FACE,
achieving new state-of-the-art performance on these two competitive benchmarks.
Code is available at https://github.com/zehuichen123/DDOD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGD-Autoencoder: Attention Gated Deep Convolutional Autoencoder for Brain Tumor Segmentation. (arXiv:2107.03323v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cvetko_T/0/1/0/all/0/1">Tim Cvetko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03323">
                                    <div class="article-summary-box-inner">
                                        <span>Brain tumor segmentation is a challenging problem in medical image analysis.
The endpoint is to generate the salient masks that accurately identify brain
tumor regions in an fMRI screening. In this paper, we propose a novel attention
gate (AG model) for brain tumor segmentation that utilizes both the edge
detecting unit and the attention gated network to highlight and segment the
salient regions from fMRI images. This feature enables us to eliminate the
necessity of having to explicitly point towards the damaged area(external
tissue localization) and classify(classification) as per classical computer
vision techniques. AGs can easily be integrated within the deep convolutional
neural networks(CNNs). Minimal computional overhead is required while the AGs
increase the sensitivity scores significantly. We show that the edge detector
along with an attention gated mechanism provide a sufficient enough method for
brain segmentation reaching an IOU of 0.78</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Blind Image Super-Resolution: A Survey and Beyond. (arXiv:2107.03055v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Anran Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yihao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jinjin Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1">Chao Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03055">
                                    <div class="article-summary-box-inner">
                                        <span>Blind image super-resolution (SR), aiming to super-resolve low-resolution
images with unknown degradation, has attracted increasing attention due to its
significance in promoting real-world applications. Many novel and effective
solutions have been proposed recently, especially with the powerful deep
learning techniques. Despite years of efforts, it still remains as a
challenging research problem. This paper serves as a systematic review on
recent progress in blind image SR, and proposes a taxonomy to categorize
existing methods into three different classes according to their ways of
degradation modelling and the data used for solving the SR model. This taxonomy
helps summarize and distinguish among existing methods. We hope to provide
insights into current research states, as well as to reveal novel research
directions worth exploring. In addition, we make a summary on commonly used
datasets and previous competitions related to blind image SR. Last but not
least, a comparison among different methods is provided with detailed analysis
on their merits and demerits using both synthetic and real testing images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Urban Tree Species Classification Using Aerial Imagery. (arXiv:2107.03182v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Waters_E/0/1/0/all/0/1">Emily Waters</a>, <a href="http://arxiv.org/find/cs/1/au:+Oghaz_M/0/1/0/all/0/1">Mahdi Maktabdar Oghaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Saheer_L/0/1/0/all/0/1">Lakshmi Babu Saheer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03182">
                                    <div class="article-summary-box-inner">
                                        <span>Urban trees help regulate temperature, reduce energy consumption, improve
urban air quality, reduce wind speeds, and mitigating the urban heat island
effect. Urban trees also play a key role in climate change mitigation and
global warming by capturing and storing atmospheric carbon-dioxide which is the
largest contributor to greenhouse gases. Automated tree detection and species
classification using aerial imagery can be a powerful tool for sustainable
forest and urban tree management. Hence, This study first offers a pipeline for
generating labelled dataset of urban trees using Google Map&#x27;s aerial images and
then investigates how state of the art deep Convolutional Neural Network models
such as VGG and ResNet handle the classification problem of urban tree aerial
images under different parameters. Experimental results show our best model
achieves an average accuracy of 60% over 6 tree species.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bi-level Feature Alignment for Versatile Image Translation and Manipulation. (arXiv:2107.03021v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1">Fangneng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yingchen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Rongliang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_K/0/1/0/all/0/1">Kaiwen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">Aoran Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03021">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GANs) have achieved great success in image
translation and manipulation. However, high-fidelity image generation with
faithful style control remains a grand challenge in computer vision. This paper
presents a versatile image translation and manipulation framework that achieves
accurate semantic and style guidance in image generation by explicitly building
a correspondence. To handle the quadratic complexity incurred by building the
dense correspondences, we introduce a bi-level feature alignment strategy that
adopts a top-$k$ operation to rank block-wise features followed by dense
attention between block features which reduces memory cost substantially. As
the top-$k$ operation involves index swapping which precludes the gradient
propagation, we propose to approximate the non-differentiable top-$k$ operation
with a regularized earth mover&#x27;s problem so that its gradient can be
effectively back-propagated. In addition, we design a novel semantic position
encoding mechanism that builds up coordinate for each individual semantic
region to preserve texture structures while building correspondences. Further,
we design a novel confidence feature injection module which mitigates mismatch
problem by fusing features adaptively according to the reliability of built
correspondences. Extensive experiments show that our method achieves superior
performance qualitatively and quantitatively as compared with the
state-of-the-art. The code is available at
\href{https://github.com/fnzhan/RABIT}{https://github.com/fnzhan/RABIT}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bone Surface Reconstruction and Clinical Features Estimation from Sparse Landmarks and Statistical Shape Models: A feasibility study on the femur. (arXiv:2107.03292v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Asvadi_A/0/1/0/all/0/1">Alireza Asvadi</a>, <a href="http://arxiv.org/find/eess/1/au:+Dardenne_G/0/1/0/all/0/1">Guillaume Dardenne</a>, <a href="http://arxiv.org/find/eess/1/au:+Troccaz_J/0/1/0/all/0/1">Jocelyne Troccaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Burdin_V/0/1/0/all/0/1">Valerie Burdin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03292">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, we investigated a method allowing the determination of the
femur bone surface as well as its mechanical axis from some easy-to-identify
bony landmarks. The reconstruction of the whole femur is therefore performed
from these landmarks using a Statistical Shape Model (SSM). The aim of this
research is therefore to assess the impact of the number, the position, and the
accuracy of the landmarks for the reconstruction of the femur and the
determination of its related mechanical axis, an important clinical parameter
to consider for the lower limb analysis. Two statistical femur models were
created from our in-house dataset and a publicly available dataset. Both were
evaluated in terms of average point-to-point surface distance error and through
the mechanical axis of the femur. Furthermore, the clinical impact of using
landmarks on the skin in replacement of bony landmarks is investigated. The
predicted proximal femurs from bony landmarks were more accurate compared to
on-skin landmarks while both had less than 3.5 degrees mechanical axis angle
deviation error. The results regarding the non-invasive determination of the
mechanical axis are very encouraging and could open very interesting clinical
perspectives for the analysis of the lower limb either for orthopedics or
functional rehabilitation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Mesh Prior: Unsupervised Mesh Restoration using Graph Convolutional Networks. (arXiv:2107.02909v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hattori_S/0/1/0/all/0/1">Shota Hattori</a>, <a href="http://arxiv.org/find/cs/1/au:+Yatagawa_T/0/1/0/all/0/1">Tatsuya Yatagawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohtake_Y/0/1/0/all/0/1">Yutaka Ohtake</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_H/0/1/0/all/0/1">Hiromasa Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02909">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses mesh restoration problems, i.e., denoising and
completion, by learning self-similarity in an unsupervised manner. For this
purpose, the proposed method, which we refer to as Deep Mesh Prior, uses a
graph convolutional network on meshes to learn the self-similarity. The network
takes a single incomplete mesh as input data and directly outputs the
reconstructed mesh without being trained using large-scale datasets. Our method
does not use any intermediate representations such as an implicit field because
the whole process works on a mesh. We demonstrate that our unsupervised method
performs equally well or even better than the state-of-the-art methods using
large-scale datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RAM-VO: Less is more in Visual Odometry. (arXiv:2107.02974v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cleveston_I/0/1/0/all/0/1">Iury Cleveston</a>, <a href="http://arxiv.org/find/cs/1/au:+Colombini_E/0/1/0/all/0/1">Esther L. Colombini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02974">
                                    <div class="article-summary-box-inner">
                                        <span>Building vehicles capable of operating without human supervision requires the
determination of the agent&#x27;s pose. Visual Odometry (VO) algorithms estimate the
egomotion using only visual changes from the input images. The most recent VO
methods implement deep-learning techniques using convolutional neural networks
(CNN) extensively, which add a substantial cost when dealing with
high-resolution images. Furthermore, in VO tasks, more input data does not mean
a better prediction; on the contrary, the architecture may filter out useless
information. Therefore, the implementation of computationally efficient and
lightweight architectures is essential. In this work, we propose the RAM-VO, an
extension of the Recurrent Attention Model (RAM) for visual odometry tasks.
RAM-VO improves the visual and temporal representation of information and
implements the Proximal Policy Optimization (PPO) algorithm to learn robust
policies. The results indicate that RAM-VO can perform regressions with six
degrees of freedom from monocular input images using approximately 3 million
parameters. In addition, experiments on the KITTI dataset demonstrate that
RAM-VO achieves competitive results using only 5.7% of the available visual
information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Stixel-based Instance Segmentation. (arXiv:2107.03070v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Santarossa_M/0/1/0/all/0/1">Monty Santarossa</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_L/0/1/0/all/0/1">Lukas Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelenka_C/0/1/0/all/0/1">Claudius Zelenka</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmarje_L/0/1/0/all/0/1">Lars Schmarje</a>, <a href="http://arxiv.org/find/cs/1/au:+Koch_R/0/1/0/all/0/1">Reinhard Koch</a>, <a href="http://arxiv.org/find/cs/1/au:+Franke_U/0/1/0/all/0/1">Uwe Franke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03070">
                                    <div class="article-summary-box-inner">
                                        <span>Stixels have been successfully applied to a wide range of vision tasks in
autonomous driving, recently including instance segmentation. However, due to
their sparse occurrence in the image, until now Stixels seldomly served as
input for Deep Learning algorithms, restricting their utility for such
approaches. In this work we present StixelPointNet, a novel method to perform
fast instance segmentation directly on Stixels. By regarding the Stixel
representation as unstructured data similar to point clouds, architectures like
PointNet are able to learn features from Stixels. We use a bounding box
detector to propose candidate instances, for which the relevant Stixels are
extracted from the input image. On these Stixels, a PointNet models learns
binary segmentations, which we then unify throughout the whole image in a final
selection step. StixelPointNet achieves state-of-the-art performance on
Stixel-level, is considerably faster than pixel-based segmentation methods, and
shows that with our approach the Stixel domain can be introduced to many new 3D
Deep Learning tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer Network for Significant Stenosis Detection in CCTA of Coronary Arteries. (arXiv:2107.03035v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ma_X/0/1/0/all/0/1">Xinghua Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_G/0/1/0/all/0/1">Gongning Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_K/0/1/0/all/0/1">Kuanquan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03035">
                                    <div class="article-summary-box-inner">
                                        <span>Coronary artery disease (CAD) has posed a leading threat to the lives of
cardiovascular disease patients worldwide for a long time. Therefore, automated
diagnosis of CAD has indispensable significance in clinical medicine. However,
the complexity of coronary artery plaques that cause CAD makes the automatic
detection of coronary artery stenosis in Coronary CT angiography (CCTA) a
difficult task. In this paper, we propose a Transformer network (TR-Net) for
the automatic detection of significant stenosis (i.e. luminal narrowing &gt; 50%)
while practically completing the computer-assisted diagnosis of CAD. The
proposed TR-Net introduces a novel Transformer, and tightly combines
convolutional layers and Transformer encoders, allowing their advantages to be
demonstrated in the task. By analyzing semantic information sequences, TR-Net
can fully understand the relationship between image information in each
position of a multiplanar reformatted (MPR) image, and accurately detect
significant stenosis based on both local and global information. We evaluate
our TR-Net on a dataset of 76 patients from different patients annotated by
experienced radiologists. Experimental results illustrate that our TR-Net has
achieved better results in ACC (0.92), Spec (0.96), PPV (0.84), F1 (0.79) and
MCC (0.74) indicators compared with the state-of-the-art methods. The source
code is publicly available from the link (https://github.com/XinghuaMa/TR-Net).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Simultaneous Learning of Single-particle Orientation and 3D Map Reconstruction from Cryo-electron Microscopy Data. (arXiv:2107.02958v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nashed_Y/0/1/0/all/0/1">Youssef S. G. Nashed</a>, <a href="http://arxiv.org/find/eess/1/au:+Poitevin_F/0/1/0/all/0/1">Frederic Poitevin</a>, <a href="http://arxiv.org/find/eess/1/au:+Gupta_H/0/1/0/all/0/1">Harshit Gupta</a>, <a href="http://arxiv.org/find/eess/1/au:+Woollard_G/0/1/0/all/0/1">Geoffrey Woollard</a>, <a href="http://arxiv.org/find/eess/1/au:+Kagan_M/0/1/0/all/0/1">Michael Kagan</a>, <a href="http://arxiv.org/find/eess/1/au:+Yoon_C/0/1/0/all/0/1">Chuck Yoon</a>, <a href="http://arxiv.org/find/eess/1/au:+Ratner_D/0/1/0/all/0/1">Daniel Ratner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02958">
                                    <div class="article-summary-box-inner">
                                        <span>Cryogenic electron microscopy (cryo-EM) provides images from different copies
of the same biomolecule in arbitrary orientations. Here, we present an
end-to-end unsupervised approach that learns individual particle orientations
from cryo-EM data while reconstructing the average 3D map of the biomolecule,
starting from a random initialization. The approach relies on an auto-encoder
architecture where the latent space is explicitly interpreted as orientations
used by the decoder to form an image according to the linear projection model.
We evaluate our method on simulated data and show that it is able to
reconstruct 3D particle maps from noisy- and CTF-corrupted 2D projection images
of unknown particle orientations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Plot2Spectra: an Automatic Spectra Extraction Tool. (arXiv:2107.02827v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weixin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwenker_E/0/1/0/all/0/1">Eric Schwenker</a>, <a href="http://arxiv.org/find/cs/1/au:+Spreadbury_T/0/1/0/all/0/1">Trevor Spreadbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_M/0/1/0/all/0/1">Maria K.Y. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cossairt_O/0/1/0/all/0/1">Oliver Cossairt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02827">
                                    <div class="article-summary-box-inner">
                                        <span>Different types of spectroscopies, such as X-ray absorption near edge
structure (XANES) and Raman spectroscopy, play a very important role in
analyzing the characteristics of different materials. In scientific literature,
XANES/Raman data are usually plotted in line graphs which is a visually
appropriate way to represent the information when the end-user is a human
reader. However, such graphs are not conducive to direct programmatic analysis
due to the lack of automatic tools. In this paper, we develop a plot digitizer,
named Plot2Spectra, to extract data points from spectroscopy graph images in an
automatic fashion, which makes it possible for large scale data acquisition and
analysis. Specifically, the plot digitizer is a two-stage framework. In the
first axis alignment stage, we adopt an anchor-free detector to detect the plot
region and then refine the detected bounding boxes with an edge-based
constraint to locate the position of two axes. We also apply scene text
detector to extract and interpret all tick information below the x-axis. In the
second plot data extraction stage, we first employ semantic segmentation to
separate pixels belonging to plot lines from the background, and from there,
incorporate optical flow constraints to the plot line pixels to assign them to
the appropriate line (data instance) they encode. Extensive experiments are
conducted to validate the effectiveness of the proposed plot digitizer, which
shows that such a tool could help accelerate the discovery and machine learning
of materials properties.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A convolutional neural network for teeth margin detection on 3-dimensional dental meshes. (arXiv:2107.03030v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bifu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kenan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuchun Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03030">
                                    <div class="article-summary-box-inner">
                                        <span>We proposed a convolutional neural network for vertex classification on
3-dimensional dental meshes, and used it to detect teeth margins. An expanding
layer was constructed to collect statistic values of neighbor vertex features
and compute new features for each vertex with convolutional neural networks. An
end-to-end neural network was proposed to take vertex features, including
coordinates, curvatures and distance, as input and output each vertex
classification label. Several network structures with different parameters of
expanding layers and a base line network without expanding layers were designed
and trained by 1156 dental meshes. The accuracy, recall and precision were
validated on 145 dental meshes to rate the best network structures, which were
finally tested on another 144 dental meshes. All networks with our expanding
layers performed better than baseline, and the best one achieved an accuracy of
0.877 both on validation dataset and test dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Outdoor Scene Relighting. (arXiv:2107.03106v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Ye Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meka_A/0/1/0/all/0/1">Abhimitra Meka</a>, <a href="http://arxiv.org/find/cs/1/au:+Elgharib_M/0/1/0/all/0/1">Mohamed Elgharib</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidel_H/0/1/0/all/0/1">Hans-Peter Seidel</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_W/0/1/0/all/0/1">William A. P. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03106">
                                    <div class="article-summary-box-inner">
                                        <span>Outdoor scene relighting is a challenging problem that requires good
understanding of the scene geometry, illumination and albedo. Current
techniques are completely supervised, requiring high quality synthetic
renderings to train a solution. Such renderings are synthesized using priors
learned from limited data. In contrast, we propose a self-supervised approach
for relighting. Our approach is trained only on corpora of images collected
from the internet without any user-supervision. This virtually endless source
of training data allows training a general relighting solution. Our approach
first decomposes an image into its albedo, geometry and illumination. A novel
relighting is then produced by modifying the illumination parameters. Our
solution capture shadow using a dedicated shadow prediction map, and does not
rely on accurate geometry estimation. We evaluate our technique subjectively
and objectively using a new dataset with ground-truth relighting. Results show
the ability of our technique to produce photo-realistic and physically
plausible results, that generalizes to unseen scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Convolutional Correlation Iterative Particle Filter for Visual Tracking. (arXiv:2107.02984v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mozhdehi_R/0/1/0/all/0/1">Reza Jalil Mozhdehi</a>, <a href="http://arxiv.org/find/cs/1/au:+Medeiros_H/0/1/0/all/0/1">Henry Medeiros</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02984">
                                    <div class="article-summary-box-inner">
                                        <span>This work proposes a novel framework for visual tracking based on the
integration of an iterative particle filter, a deep convolutional neural
network, and a correlation filter. The iterative particle filter enables the
particles to correct themselves and converge to the correct target position. We
employ a novel strategy to assess the likelihood of the particles after the
iterations by applying K-means clustering. Our approach ensures a consistent
support for the posterior distribution. Thus, we do not need to perform
resampling at every video frame, improving the utilization of prior
distribution information. Experimental results on two different benchmark
datasets show that our tracker performs favorably against state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Poly-NL: Linear Complexity Non-local Layers with Polynomials. (arXiv:2107.02859v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Babiloni_F/0/1/0/all/0/1">Francesca Babiloni</a>, <a href="http://arxiv.org/find/cs/1/au:+Marras_I/0/1/0/all/0/1">Ioannis Marras</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokkinos_F/0/1/0/all/0/1">Filippos Kokkinos</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiankang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1">Grigorios Chrysos</a>, <a href="http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1">Stefanos Zafeiriou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02859">
                                    <div class="article-summary-box-inner">
                                        <span>Spatial self-attention layers, in the form of Non-Local blocks, introduce
long-range dependencies in Convolutional Neural Networks by computing pairwise
similarities among all possible positions. Such pairwise functions underpin the
effectiveness of non-local layers, but also determine a complexity that scales
quadratically with respect to the input size both in space and time. This is a
severely limiting factor that practically hinders the applicability of
non-local blocks to even moderately sized inputs. Previous works focused on
reducing the complexity by modifying the underlying matrix operations, however
in this work we aim to retain full expressiveness of non-local layers while
keeping complexity linear. We overcome the efficiency limitation of non-local
blocks by framing them as special cases of 3rd order polynomial functions. This
fact enables us to formulate novel fast Non-Local blocks, capable of reducing
the complexity from quadratic to linear with no loss in performance, by
replacing any direct computation of pairwise similarities with element-wise
multiplications. The proposed method, which we dub as &quot;Poly-NL&quot;, is competitive
with state-of-the-art performance across image recognition, instance
segmentation, and face detection tasks, while having considerably less
computational overhead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Greedy Offset-Guided Keypoint Grouping for Human Pose Estimation. (arXiv:2107.03098v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_L/0/1/0/all/0/1">Linhua Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zengfu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03098">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a simple yet reliable bottom-up approach with a good trade-off
between accuracy and efficiency for the problem of multi-person pose
estimation. Given an image, we employ an Hourglass Network to infer all the
keypoints from different persons indiscriminately as well as the guiding
offsets connecting the adjacent keypoints belonging to the same persons. Then,
we greedily group the candidate keypoints into multiple human poses (if any),
utilizing the predicted guiding offsets. And we refer to this process as greedy
offset-guided keypoint grouping (GOG). Moreover, we revisit the
encoding-decoding method for the multi-person keypoint coordinates and reveal
some important facts affecting accuracy. Experiments have demonstrated the
obvious performance improvements brought by the introduced components. Our
approach is comparable to the state of the art on the challenging COCO dataset
under fair conditions. The source code and our pre-trained model are publicly
available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GA-NET: Global Attention Network for Point Cloud Semantic Segmentation. (arXiv:2107.03101v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shuang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Q/0/1/0/all/0/1">Qiulei Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03101">
                                    <div class="article-summary-box-inner">
                                        <span>How to learn long-range dependencies from 3D point clouds is a challenging
problem in 3D point cloud analysis. Addressing this problem, we propose a
global attention network for point cloud semantic segmentation, named as
GA-Net, consisting of a point-independent global attention module and a
point-dependent global attention module for obtaining contextual information of
3D point clouds in this paper. The point-independent global attention module
simply shares a global attention map for all 3D points. In the point-dependent
global attention module, for each point, a novel random cross attention block
using only two randomly sampled subsets is exploited to learn the contextual
information of all the points. Additionally, we design a novel point-adaptive
aggregation block to replace linear skip connection for aggregating more
discriminate features. Extensive experimental results on three 3D public
datasets demonstrate that our method outperforms state-of-the-art methods in
most cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal Affect Analysis using standardized data within subjects in the Wild. (arXiv:2107.03009v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Youoku_S/0/1/0/all/0/1">Sachihiro Youoku</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamamoto_T/0/1/0/all/0/1">Takahisa Yamamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_J/0/1/0/all/0/1">Junya Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Uchida_A/0/1/0/all/0/1">Akiyoshi Uchida</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_X/0/1/0/all/0/1">Xiaoyu Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Ziqiang Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Liu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhongling Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03009">
                                    <div class="article-summary-box-inner">
                                        <span>Human affective recognition is an important factor in human-computer
interaction. However, the method development with in-the-wild data is not yet
accurate enough for practical usage. In this paper, we introduce the affective
recognition method focusing on facial expression (EXP) and valence-arousal
calculation that was submitted to the Affective Behavior Analysis in-the-wild
(ABAW) 2021 Contest.

When annotating facial expressions from a video, we thought that it would be
judged not only from the features common to all people, but also from the
relative changes in the time series of individuals. Therefore, after learning
the common features for each frame, we constructed a facial expression
estimation model and valence-arousal model using time-series data after
combining the common features and the standardized features for each video.
Furthermore, the above features were learned using multi-modal data such as
image features, AU, Head pose, and Gaze. In the validation set, our model
achieved a facial expression score of 0.546. These verification results reveal
that our proposed framework can improve estimation accuracy and robustness
effectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Denoising Diffusion Models in Discrete State-Spaces. (arXiv:2107.03006v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1">Jacob Austin</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_D/0/1/0/all/0/1">Daniel Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarlow_D/0/1/0/all/0/1">Danny Tarlow</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1">Rianne van den Berg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03006">
                                    <div class="article-summary-box-inner">
                                        <span>Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown
impressive results on image and waveform generation in continuous state spaces.
Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),
diffusion-like generative models for discrete data that generalize the
multinomial diffusion model of Hoogeboom et al. 2021, by going beyond
corruption processes with uniform transition probabilities. This includes
corruption with transition matrices that mimic Gaussian kernels in continuous
space, matrices based on nearest neighbors in embedding space, and matrices
that introduce absorbing states. The third allows us to draw a connection
between diffusion models and autoregressive and mask-based generative models.
We show that the choice of transition matrix is an important design decision
that leads to improved results in image and text domains. We also introduce a
new loss function that combines the variational lower bound with an auxiliary
cross entropy loss. For text, this model class achieves strong results on
character-level text generation while scaling to large vocabularies on LM1B. On
the image dataset CIFAR-10, our models approach the sample quality and exceed
the log-likelihood of the continuous-space DDPM model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maintaining a Reliable World Model using Action-aware Perceptual Anchoring. (arXiv:2107.03038v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Ying Siu Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_D/0/1/0/all/0/1">Dongkyu Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwok_K/0/1/0/all/0/1">Kenneth Kwok</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03038">
                                    <div class="article-summary-box-inner">
                                        <span>Reliable perception is essential for robots that interact with the world. But
sensors alone are often insufficient to provide this capability, and they are
prone to errors due to various conditions in the environment. Furthermore,
there is a need for robots to maintain a model of its surroundings even when
objects go out of view and are no longer visible. This requires anchoring
perceptual information onto symbols that represent the objects in the
environment. In this paper, we present a model for action-aware perceptual
anchoring that enables robots to track objects in a persistent manner. Our
rule-based approach considers inductive biases to perform high-level reasoning
over the results from low-level object detection, and it improves the robot&#x27;s
perceptual capability for complex tasks. We evaluate our model against existing
baseline models for object permanence and show that it outperforms these on a
snitch localisation task using a dataset of 1,371 videos. We also integrate our
action-aware perceptual anchoring in the context of a cognitive architecture
and demonstrate its benefits in a realistic gearbox assembly task on a
Universal Robot.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video-Based Camera Localization Using Anchor View Detection and Recursive 3D Reconstruction. (arXiv:2107.03068v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taira_H/0/1/0/all/0/1">Hajime Taira</a>, <a href="http://arxiv.org/find/cs/1/au:+Onbe_K/0/1/0/all/0/1">Koki Onbe</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyashita_N/0/1/0/all/0/1">Naoyuki Miyashita</a>, <a href="http://arxiv.org/find/cs/1/au:+Okutomi_M/0/1/0/all/0/1">Masatoshi Okutomi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03068">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we introduce a new camera localization strategy designed for
image sequences captured in challenging industrial situations such as
industrial parts inspection. To deal with peculiar appearances that hurt
standard 3D reconstruction pipeline, we exploit pre-knowledge of the scene by
selecting key frames in the sequence (called as anchors) which are roughly
connected to a certain location. Our method then seek the location of each
frame in time-order, while recursively updating an augmented 3D model which can
provide current camera location and surrounding 3D structure. In an experiment
on a practical industrial situation, our method can localize over 99% frames in
the input sequence, whereas standard localization methods fail to reconstruct a
complete camera trajectory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Vision Transformer with Squeeze and Excitation for Facial Expression Recognition. (arXiv:2107.03107v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aouayeb_M/0/1/0/all/0/1">Mouath Aouayeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamidouche_W/0/1/0/all/0/1">Wassim Hamidouche</a>, <a href="http://arxiv.org/find/cs/1/au:+Soladie_C/0/1/0/all/0/1">Catherine Soladie</a>, <a href="http://arxiv.org/find/cs/1/au:+Kpalma_K/0/1/0/all/0/1">Kidiyo Kpalma</a>, <a href="http://arxiv.org/find/cs/1/au:+Seguier_R/0/1/0/all/0/1">Renaud Seguier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03107">
                                    <div class="article-summary-box-inner">
                                        <span>As various databases of facial expressions have been made accessible over the
last few decades, the Facial Expression Recognition (FER) task has gotten a lot
of interest. The multiple sources of the available databases raised several
challenges for facial recognition task. These challenges are usually addressed
by Convolution Neural Network (CNN) architectures. Different from CNN models, a
Transformer model based on attention mechanism has been presented recently to
address vision tasks. One of the major issue with Transformers is the need of a
large data for training, while most FER databases are limited compared to other
vision applications. Therefore, we propose in this paper to learn a vision
Transformer jointly with a Squeeze and Excitation (SE) block for FER task. The
proposed method is evaluated on different publicly available FER databases
including CK+, JAFFE,RAF-DB and SFEW. Experiments demonstrate that our model
outperforms state-of-the-art methods on CK+ and SFEW and achieves competitive
results on JAFFE and RAF-DB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VIN: Voxel-based Implicit Network for Joint 3D Object Detection and Segmentation for Lidars. (arXiv:2107.02980v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1">Yuanxin Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Minghan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Huei Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02980">
                                    <div class="article-summary-box-inner">
                                        <span>A unified neural network structure is presented for joint 3D object detection
and point cloud segmentation in this paper. We leverage rich supervision from
both detection and segmentation labels rather than using just one of them. In
addition, an extension based on single-stage object detectors is proposed based
on the implicit function widely used in 3D scene and object understanding. The
extension branch takes the final feature map from the object detection module
as input, and produces an implicit function that generates semantic
distribution for each point for its corresponding voxel center. We demonstrated
the performance of our structure on nuScenes-lidarseg, a large-scale outdoor
dataset. Our solution achieves competitive results against state-of-the-art
methods in both 3D object detection and point cloud segmentation with little
additional computation load compared with object detection solutions. The
capability of efficient weakly supervision semantic segmentation of the
proposed method is also validated by experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpectralFormer: Rethinking Hyperspectral Image Classification with Transformers. (arXiv:2107.02988v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1">Danfeng Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jing Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Lianru Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Plaza_A/0/1/0/all/0/1">Antonio Plaza</a>, <a href="http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1">Jocelyn Chanussot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02988">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperspectral (HS) images are characterized by approximately contiguous
spectral information, enabling the fine identification of materials by
capturing subtle spectral discrepancies. Owing to their excellent locally
contextual modeling ability, convolutional neural networks (CNNs) have been
proven to be a powerful feature extractor in HS image classification. However,
CNNs fail to mine and represent the sequence attributes of spectral signatures
well due to the limitations of their inherent network backbone. To solve this
issue, we rethink HS image classification from a sequential perspective with
transformers, and propose a novel backbone network called \ul{SpectralFormer}.
Beyond band-wise representations in classic transformers, SpectralFormer is
capable of learning spectrally local sequence information from neighboring
bands of HS images, yielding group-wise spectral embeddings. More
significantly, to reduce the possibility of losing valuable information in the
layer-wise propagation process, we devise a cross-layer skip connection to
convey memory-like components from shallow to deep layers by adaptively
learning to fuse &quot;soft&quot; residuals across layers. It is worth noting that the
proposed SpectralFormer is a highly flexible backbone network, which can be
applicable to both pixel- and patch-wise inputs. We evaluate the classification
performance of the proposed SpectralFormer on three HS datasets by conducting
extensive experiments, showing the superiority over classic transformers and
achieving a significant improvement in comparison with state-of-the-art
backbone networks. The codes of this work will be available at
\url{https://sites.google.com/view/danfeng-hong} for the sake of
reproducibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learn to Learn Metric Space for Few-Shot Segmentation of 3D Shapes. (arXiv:2107.02972v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lingjing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yi Fang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02972">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research has seen numerous supervised learning-based methods for 3D
shape segmentation and remarkable performance has been achieved on various
benchmark datasets. These supervised methods require a large amount of
annotated data to train deep neural networks to ensure the generalization
ability on the unseen test set. In this paper, we introduce a
meta-learning-based method for few-shot 3D shape segmentation where only a few
labeled samples are provided for the unseen classes. To achieve this, we treat
the shape segmentation as a point labeling problem in the metric space.
Specifically, we first design a meta-metric learner to transform input shapes
into embedding space and our model learns to learn a proper metric space for
each object class based on point embeddings. Then, for each class, we design a
metric learner to extract part-specific prototype representations from a few
support shapes and our model performs per-point segmentation over the query
shapes by matching each point to its nearest prototype in the learned metric
space. A metric-based loss function is used to dynamically modify distances
between point embeddings thus maximizes in-part similarity while minimizing
inter-part similarity. A dual segmentation branch is adopted to make full use
of the support information and implicitly encourages consistency between the
support and query prototypes. We demonstrate the superior performance of our
proposed on the ShapeNet part dataset under the few-shot scenario, compared
with well-established baseline and state-of-the-art semi-supervised methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edge-aware Bidirectional Diffusion for Dense Depth Estimation from Light Fields. (arXiv:2107.02967v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Numair Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Min H. Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tompkin_J/0/1/0/all/0/1">James Tompkin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02967">
                                    <div class="article-summary-box-inner">
                                        <span>We present an algorithm to estimate fast and accurate depth maps from light
fields via a sparse set of depth edges and gradients. Our proposed approach is
based around the idea that true depth edges are more sensitive than texture
edges to local constraints, and so they can be reliably disambiguated through a
bidirectional diffusion process. First, we use epipolar-plane images to
estimate sub-pixel disparity at a sparse set of pixels. To find sparse points
efficiently, we propose an entropy-based refinement approach to a line estimate
from a limited set of oriented filter banks. Next, to estimate the diffusion
direction away from sparse points, we optimize constraints at these points via
our bidirectional diffusion method. This resolves the ambiguity of which
surface the edge belongs to and reliably separates depth from texture edges,
allowing us to diffuse the sparse set in a depth-edge and occlusion-aware
manner to obtain accurate dense depth maps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN-based Data Augmentation for Chest X-ray Classification. (arXiv:2107.02970v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sundaram_S/0/1/0/all/0/1">Shobhita Sundaram</a>, <a href="http://arxiv.org/find/eess/1/au:+Hulkund_N/0/1/0/all/0/1">Neha Hulkund</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02970">
                                    <div class="article-summary-box-inner">
                                        <span>A common problem in computer vision -- particularly in medical applications
-- is a lack of sufficiently diverse, large sets of training data. These
datasets often suffer from severe class imbalance. As a result, networks often
overfit and are unable to generalize to novel examples. Generative Adversarial
Networks (GANs) offer a novel method of synthetic data augmentation. In this
work, we evaluate the use of GAN- based data augmentation to artificially
expand the CheXpert dataset of chest radiographs. We compare performance to
traditional augmentation and find that GAN-based augmentation leads to higher
downstream performance for underrepresented classes. Furthermore, we see that
this result is pronounced in low data regimens. This suggests that GAN-based
augmentation a promising area of research to improve network performance when
data collection is prohibitively expensive.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PoseRN: A 2D pose refinement network for bias-free multi-view 3D human pose estimation. (arXiv:2107.03000v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sayo_A/0/1/0/all/0/1">Akihiko Sayo</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_D/0/1/0/all/0/1">Diego Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawasaki_H/0/1/0/all/0/1">Hiroshi Kawasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakashima_Y/0/1/0/all/0/1">Yuta Nakashima</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikeuchi_K/0/1/0/all/0/1">Katsushi Ikeuchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03000">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new 2D pose refinement network that learns to predict the human
bias in the estimated 2D pose. There are biases in 2D pose estimations that are
due to differences between annotations of 2D joint locations based on
annotators&#x27; perception and those defined by motion capture (MoCap) systems.
These biases are crafted into publicly available 2D pose datasets and cannot be
removed with existing error reduction approaches. Our proposed pose refinement
network allows us to efficiently remove the human bias in the estimated 2D
poses and achieve highly accurate multi-view 3D human pose estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLiT: Neural Architecture Search for Global and Local Image Transformer. (arXiv:2107.02960v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Boyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peixia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chuming Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baopu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1">Lei Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Ming Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+yan_J/0/1/0/all/0/1">Junjie yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02960">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the first Neural Architecture Search (NAS) method to find a
better transformer architecture for image recognition. Recently, transformers
without CNN-based backbones are found to achieve impressive performance for
image recognition. However, the transformer is designed for NLP tasks and thus
could be sub-optimal when directly used for image recognition. In order to
improve the visual representation ability for transformers, we propose a new
search space and searching algorithm. Specifically, we introduce a locality
module that models the local correlations in images explicitly with fewer
computational cost. With the locality module, our search space is defined to
let the search algorithm freely trade off between global and local information
as well as optimizing the low-level design choice in each module. To tackle the
problem caused by huge search space, a hierarchical neural architecture search
method is proposed to search the optimal vision transformer from two levels
separately with the evolutionary algorithm. Extensive experiments on the
ImageNet dataset demonstrate that our method can find more discriminative and
efficient transformer variants than the ResNet family (e.g., ResNet101) and the
baseline ViT for image classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group Sampling for Unsupervised Person Re-identification. (arXiv:2107.03024v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xumeng Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xuehui Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guorong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qixiang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhenjun Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03024">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised person re-identification (re-ID) remains a challenging task,
where the classifier and feature representation could be easily misled by the
noisy pseudo labels towards deteriorated over-fitting. In this paper, we
propose a simple yet effective approach, termed Group Sampling, to alleviate
the negative impact of noisy pseudo labels within unsupervised person re-ID
models. The idea behind Group Sampling is that it can gather a group of samples
from the same class in the same mini-batch, such that the model is trained upon
group normalized samples while alleviating the effect of a single sample. Group
sampling updates the pipeline of pseudo label generation by guaranteeing the
samples to be better divided into the correct classes. Group Sampling
regularizes classifier training and representation learning, leading to the
statistical stability of feature representation in a progressive fashion.
Qualitative and quantitative experiments on Market-1501, DukeMTMC-reID, and
MSMT17 show that Grouping Sampling improves the state-of-the-arts by up to
2.2%~6.1%. Code is available at https://github.com/wavinflaghxm/GroupSampling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">E-PixelHop: An Enhanced PixelHop Method for Object Classification. (arXiv:2107.02966v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yijing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Magoulianitis_V/0/1/0/all/0/1">Vasileios Magoulianitis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02966">
                                    <div class="article-summary-box-inner">
                                        <span>Based on PixelHop and PixelHop++, which are recently developed using the
successive subspace learning (SSL) framework, we propose an enhanced solution
for object classification, called E-PixelHop, in this work. E-PixelHop consists
of the following steps. First, to decouple the color channels for a color
image, we apply principle component analysis and project RGB three color
channels onto two principle subspaces which are processed separately for
classification. Second, to address the importance of multi-scale features, we
conduct pixel-level classification at each hop with various receptive fields.
Third, to further improve pixel-level classification accuracy, we develop a
supervised label smoothing (SLS) scheme to ensure prediction consistency.
Forth, pixel-level decisions from each hop and from each color subspace are
fused together for image-level decision. Fifth, to resolve confusing classes
for further performance boosting, we formulate E-PixelHop as a two-stage
pipeline. In the first stage, multi-class classification is performed to get a
soft decision for each class, where the top 2 classes with the highest
probabilities are called confusing classes. Then,we conduct a binary
classification in the second stage. The main contributions lie in Steps 1, 3
and 5.We use the classification of the CIFAR-10 dataset as an example to
demonstrate the effectiveness of the above-mentioned key components of
E-PixelHop.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SelfCF: A Simple Framework for Self-supervised Collaborative Filtering. (arXiv:2107.03019v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1">Aixin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03019">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering (CF) is widely used to learn an informative latent
representation of a user or item from observed interactions. Existing CF-based
methods commonly adopt negative sampling to discriminate different items. That
is, observed user-item pairs are treated as positive instances; unobserved
pairs are considered as negative instances and are sampled under a defined
distribution for training. Training with negative sampling on large datasets is
computationally expensive. Further, negative items should be carefully sampled
under the defined distribution, in order to avoid selecting an observed
positive item in the training dataset. Unavoidably, some negative items sampled
from the training dataset could be positive in the test set. Recently,
self-supervised learning (SSL) has emerged as a powerful tool to learn a model
without negative samples. In this paper, we propose a self-supervised
collaborative filtering framework (SelfCF), that is specially designed for
recommender scenario with implicit feedback. The main idea of SelfCF is to
augment the output embeddings generated by backbone networks, because it is
infeasible to augment raw input of user/item ids. We propose and study three
output perturbation techniques that can be applied to different types of
backbone networks including both traditional CF models and graph-based models.
By encapsulating two popular recommendation models into the framework, our
experiments on three datasets show that the best performance of our framework
is comparable or better than the supervised counterpart. We also show that
SelfCF can boost up the performance by up to 8.93\% on average, compared with
another self-supervised framework as the baseline. Source codes are available
at: https://github.com/enoche/SelfCF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Are you sure?&quot;: Preliminary Insights from Scaling Product Comparisons to Multiple Shops. (arXiv:2107.03256v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chia_P/0/1/0/all/0/1">Patrick John Chia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bingqing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliabue_J/0/1/0/all/0/1">Jacopo Tagliabue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03256">
                                    <div class="article-summary-box-inner">
                                        <span>Large eCommerce players introduced comparison tables as a new type of
recommendations. However, building comparisons at scale without pre-existing
training/taxonomy data remains an open challenge, especially within the
operational constraints of shops in the long tail. We present preliminary
results from building a comparison pipeline designed to scale in a multi-shop
scenario: we describe our design choices and run extensive benchmarks on
multiple shops to stress-test it. Finally, we run a small user study on
property selection and conclude by discussing potential improvements and
highlighting the questions that remain to be addressed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graphing else matters: exploiting aspect opinions and ratings in explainable graph-based recommendations. (arXiv:2107.03226v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cantador_I/0/1/0/all/0/1">Iv&#xe1;n Cantador</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvallo_A/0/1/0/all/0/1">Andr&#xe9;s Carvallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Diez_F/0/1/0/all/0/1">Fernando Diez</a>, <a href="http://arxiv.org/find/cs/1/au:+Parra_D/0/1/0/all/0/1">Denis Parra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03226">
                                    <div class="article-summary-box-inner">
                                        <span>The success of neural network embeddings has entailed a renewed interest in
using knowledge graphs for a wide variety of machine learning and information
retrieval tasks. In particular, current recommendation methods based on graph
embeddings have shown state-of-the-art performance. These methods commonly
encode latent rating patterns and content features. Different from previous
work, in this paper, we propose to exploit embeddings extracted from graphs
that combine information from ratings and aspect-based opinions expressed in
textual reviews. We then adapt and evaluate state-of-the-art graph embedding
techniques over graphs generated from Amazon and Yelp reviews on six domains,
outperforming baseline recommenders. Our approach has the advantage of
providing explanations which leverage aspect-based opinions given by users
about recommended items. Furthermore, we also provide examples of the
applicability of recommendations utilizing aspect opinions as explanations in a
visualization dashboard, which allows obtaining information about the most and
least liked aspects of similar users obtained from the embeddings of an input
graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoDebias: Learning to Debias for Recommendation. (arXiv:2105.04170v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiawei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hande Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1">Xin Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guli Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Keping Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04170">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems rely on user behavior data like ratings and clicks to
build personalization model. However, the collected data is observational
rather than experimental, causing various biases in the data which
significantly affect the learned model. Most existing work for recommendation
debiasing, such as the inverse propensity scoring and imputation approaches,
focuses on one or two specific biases, lacking the universal capacity that can
account for mixed or even unknown biases in the data.

Towards this research gap, we first analyze the origin of biases from the
perspective of \textit{risk discrepancy} that represents the difference between
the expectation empirical risk and the true risk. Remarkably, we derive a
general learning framework that well summarizes most existing debiasing
strategies by specifying some parameters of the general framework. This
provides a valuable opportunity to develop a universal solution for debiasing,
e.g., by learning the debiasing parameters from data. However, the training
data lacks important signal of how the data is biased and what the unbiased
data looks like. To move this idea forward, we propose \textit{AotoDebias} that
leverages another (small) set of uniform data to optimize the debiasing
parameters by solving the bi-level optimization problem with meta-learning.
Through theoretical analyses, we derive the generalization bound for AutoDebias
and prove its ability to acquire the appropriate debiasing strategy. Extensive
experiments on two real datasets and a simulated dataset demonstrated
effectiveness of AutoDebias. The code is available at
\url{https://github.com/DongHande/AutoDebias}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Computationally Efficient Optimization of Plackett-Luce Ranking Models for Relevance and Fairness. (arXiv:2105.00855v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oosterhuis_H/0/1/0/all/0/1">Harrie Oosterhuis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00855">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has proposed stochastic Plackett-Luce (PL) ranking models as a
robust choice for optimizing relevance and fairness metrics. Unlike their
deterministic counterparts that require heuristic optimization algorithms, PL
models are fully differentiable. Theoretically, they can be used to optimize
ranking metrics via stochastic gradient descent. However, in practice, the
computation of the gradient is infeasible because it requires one to iterate
over all possible permutations of items. Consequently, actual applications rely
on approximating the gradient via sampling techniques. In this paper, we
introduce a novel algorithm: PL-Rank, that estimates the gradient of a PL
ranking model w.r.t. both relevance and fairness metrics. Unlike existing
approaches that are based on policy gradients, PL-Rank makes use of the
specific structure of PL models and ranking metrics. Our experimental analysis
shows that PL-Rank has a greater sample-efficiency and is computationally less
costly than existing policy gradients, resulting in faster convergence at
higher performance. PL-Rank further enables the industry to apply PL models for
more relevant and fairer real-world ranking systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Big Are Peoples&#x27; Computer Files? File Size Distributions Among User-managed Collections. (arXiv:2107.03272v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dinneen_J/0/1/0/all/0/1">Jesse David Dinneen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Ba Xuan Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03272">
                                    <div class="article-summary-box-inner">
                                        <span>Improving file management interfaces and optimising system performance
requires current data about users&#x27; digital collections and particularly about
the file size distributions of such collections. However, prior works have
examined only the sizes of system files and users&#x27; work files in varied
contexts, and there has been no such study since 2013; it therefore remains
unclear how today&#x27;s file sizes are distributed, particularly personal files,
and further if distributions differ among the major operating systems or common
occupations. Here we examine such differences among 49 million files in 348
user collections. We find that the average file size has grown more than
ten-fold since the mid-2000s, though most files are still under 8 MB, and that
there are demographic and technological influences in the size distributions.
We discuss the implications for user interfaces, system optimisation, and PIM
research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Episodic Bandits with Stochastic Experts. (arXiv:2107.03263v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1">Nihal Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_S/0/1/0/all/0/1">Soumya Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shanmugam_K/0/1/0/all/0/1">Karthikeyan Shanmugam</a>, <a href="http://arxiv.org/find/cs/1/au:+Shakkottai_S/0/1/0/all/0/1">Sanjay Shakkottai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03263">
                                    <div class="article-summary-box-inner">
                                        <span>We study a version of the contextual bandit problem where an agent is given
soft control of a node in a graph-structured environment through a set of
stochastic expert policies. The agent interacts with the environment over
episodes, with each episode having different context distributions; this
results in the &#x60;best expert&#x27; changing across episodes. Our goal is to develop
an agent that tracks the best expert over episodes. We introduce the Empirical
Divergence-based UCB (ED-UCB) algorithm in this setting where the agent does
not have any knowledge of the expert policies or changes in context
distributions. With mild assumptions, we show that bootstrapping from
$\tilde{O}(N\log(NT^2\sqrt{E}))$ samples results in a regret of
$\tilde{O}(E(N+1) + \frac{N\sqrt{E}}{T^2})$. If the expert policies are known
to the agent a priori, then we can improve the regret to $\tilde{O}(EN)$
without requiring any bootstrapping. Our analysis also tightens pre-existing
logarithmic regret bounds to a problem-dependent constant in the non-episodic
setting when expert policies are known. We finally empirically validate our
findings through simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KaFiStO: A Kalman Filtering Framework for Stochastic Optimization. (arXiv:2107.03331v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Davtyan_A/0/1/0/all/0/1">Aram Davtyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sameni_S/0/1/0/all/0/1">Sepehr Sameni</a>, <a href="http://arxiv.org/find/cs/1/au:+Cerkezi_L/0/1/0/all/0/1">Llukman Cerkezi</a>, <a href="http://arxiv.org/find/cs/1/au:+Meishvilli_G/0/1/0/all/0/1">Givi Meishvilli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielski_A/0/1/0/all/0/1">Adam Bielski</a>, <a href="http://arxiv.org/find/cs/1/au:+Favaro_P/0/1/0/all/0/1">Paolo Favaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03331">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization is often cast as a deterministic problem, where the solution is
found through some iterative procedure such as gradient descent. However, when
training neural networks the loss function changes over (iteration) time due to
the randomized selection of a subset of the samples. This randomization turns
the optimization problem into a stochastic one. We propose to consider the loss
as a noisy observation with respect to some reference optimum. This
interpretation of the loss allows us to adopt Kalman filtering as an optimizer,
as its recursive formulation is designed to estimate unknown parameters from
noisy measurements. Moreover, we show that the Kalman Filter dynamical model
for the evolution of the unknown parameters can be used to capture the gradient
dynamics of advanced methods such as Momentum and Adam. We call this stochastic
optimization method KaFiStO. KaFiStO is an easy to implement, scalable, and
efficient method to train neural networks. We show that it also yields
parameter estimates that are on par with or better than existing optimization
algorithms across several neural network architectures and machine learning
tasks, such as computer vision and language modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularization-based Continual Learning for Fault Prediction in Lithium-Ion Batteries. (arXiv:2107.03336v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maschler_B/0/1/0/all/0/1">Benjamin Maschler</a>, <a href="http://arxiv.org/find/cs/1/au:+Tatiyosyan_S/0/1/0/all/0/1">Sophia Tatiyosyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Weyrich_M/0/1/0/all/0/1">Michael Weyrich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03336">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the use of lithium-ion batteries has greatly expanded into
products from many industrial sectors, e.g. cars, power tools or medical
devices. An early prediction and robust understanding of battery faults could
therefore greatly increase product quality in those fields. While current
approaches for data-driven fault prediction provide good results on the exact
processes they were trained on, they often lack the ability to flexibly adapt
to changes, e.g. in operational or environmental parameters. Continual learning
promises such flexibility, allowing for an automatic adaption of previously
learnt knowledge to new tasks. Therefore, this article discusses different
continual learning approaches from the group of regularization strategies,
which are implemented, evaluated and compared based on a real battery wear
dataset. Online elastic weight consolidation delivers the best results, but, as
with all examined approaches, its performance appears to be strongly dependent
on task characteristics and task sequence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoupling Exploration and Exploitation for Meta-Reinforcement Learning without Sacrifices. (arXiv:2008.02790v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_E/0/1/0/all/0/1">Evan Zheran Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1">Aditi Raghunathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Percy Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02790">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of meta-reinforcement learning (meta-RL) is to build agents that can
quickly learn new tasks by leveraging prior experience on related tasks.
Learning a new task often requires both exploring to gather task-relevant
information and exploiting this information to solve the task. In principle,
optimal exploration and exploitation can be learned end-to-end by simply
maximizing task performance. However, such meta-RL approaches struggle with
local optima due to a chicken-and-egg problem: learning to explore requires
good exploitation to gauge the exploration&#x27;s utility, but learning to exploit
requires information gathered via exploration. Optimizing separate objectives
for exploration and exploitation can avoid this problem, but prior meta-RL
exploration objectives yield suboptimal policies that gather information
irrelevant to the task. We alleviate both concerns by constructing an
exploitation objective that automatically identifies task-relevant information
and an exploration objective to recover only this information. This avoids
local optima in end-to-end training, without sacrificing optimal exploration.
Empirically, DREAM substantially outperforms existing approaches on complex
meta-RL problems, such as sparse-reward 3D visual navigation. Videos of DREAM:
https://ezliu.github.io/dream/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Universal Approximation for Log-concave Distributions using Well-conditioned Normalizing Flows. (arXiv:2107.02951v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Holden Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pabbaraju_C/0/1/0/all/0/1">Chirag Pabbaraju</a>, <a href="http://arxiv.org/find/cs/1/au:+Sevekari_A/0/1/0/all/0/1">Anish Sevekari</a>, <a href="http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1">Andrej Risteski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02951">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows are a widely used class of latent-variable generative
models with a tractable likelihood. Affine-coupling (Dinh et al, 2014-16)
models are a particularly common type of normalizing flows, for which the
Jacobian of the latent-to-observable-variable transformation is triangular,
allowing the likelihood to be computed in linear time. Despite the widespread
usage of affine couplings, the special structure of the architecture makes
understanding their representational power challenging. The question of
universal approximation was only recently resolved by three parallel papers
(Huang et al.,2020;Zhang et al.,2020;Koehler et al.,2020) -- who showed
reasonably regular distributions can be approximated arbitrarily well using
affine couplings -- albeit with networks with a nearly-singular Jacobian. As
ill-conditioned Jacobians are an obstacle for likelihood-based training, the
fundamental question remains: which distributions can be approximated using
well-conditioned affine coupling flows?

In this paper, we show that any log-concave distribution can be approximated
using well-conditioned affine-coupling flows. In terms of proof techniques, we
uncover and leverage deep connections between affine coupling architectures,
underdamped Langevin dynamics (a stochastic differential equation often used to
sample from Gibbs measures) and H\&#x27;enon maps (a structured dynamical system
that appears in the study of symplectic diffeomorphisms). Our results also
inform the practice of training affine couplings: we approximate a padded
version of the input distribution with iid Gaussians -- a strategy which
Koehler et al.(2020) empirically observed to result in better-conditioned
flows, but had hitherto no theoretical grounding. Our proof can thus be seen as
providing theoretical evidence for the benefits of Gaussian padding when
training normalizing flows.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust learning under clean-label attack. (arXiv:2103.00671v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blum_A/0/1/0/all/0/1">Avrim Blum</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1">Steve Hanneke</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1">Jian Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_H/0/1/0/all/0/1">Han Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00671">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of robust learning under clean-label data-poisoning
attacks, where the attacker injects (an arbitrary set of) correctly-labeled
examples to the training set to fool the algorithm into making mistakes on
specific test instances at test time. The learning goal is to minimize the
attackable rate (the probability mass of attackable test instances), which is
more difficult than optimal PAC learning. As we show, any robust algorithm with
diminishing attackable rate can achieve the optimal dependence on $\epsilon$ in
its PAC sample complexity, i.e., $O(1/\epsilon)$. On the other hand, the
attackable rate might be large even for some optimal PAC learners, e.g., SVM
for linear classifiers. Furthermore, we show that the class of linear
hypotheses is not robustly learnable when the data distribution has zero margin
and is robustly learnable in the case of positive margin but requires sample
complexity exponential in the dimension. For a general hypothesis class with
bounded VC dimension, if the attacker is limited to add at most $t&gt;0$ poison
examples, the optimal robust learning sample complexity grows almost linearly
with $t$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SoundStream: An End-to-End Neural Audio Codec. (arXiv:2107.03312v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeghidour_N/0/1/0/all/0/1">Neil Zeghidour</a>, <a href="http://arxiv.org/find/cs/1/au:+Luebs_A/0/1/0/all/0/1">Alejandro Luebs</a>, <a href="http://arxiv.org/find/cs/1/au:+Omran_A/0/1/0/all/0/1">Ahmed Omran</a>, <a href="http://arxiv.org/find/cs/1/au:+Skoglund_J/0/1/0/all/0/1">Jan Skoglund</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliasacchi_M/0/1/0/all/0/1">Marco Tagliasacchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03312">
                                    <div class="article-summary-box-inner">
                                        <span>We present SoundStream, a novel neural audio codec that can efficiently
compress speech, music and general audio at bitrates normally targeted by
speech-tailored codecs. SoundStream relies on a model architecture composed by
a fully convolutional encoder/decoder network and a residual vector quantizer,
which are trained jointly end-to-end. Training leverages recent advances in
text-to-speech and speech enhancement, which combine adversarial and
reconstruction losses to allow the generation of high-quality audio content
from quantized embeddings. By training with structured dropout applied to
quantizer layers, a single model can operate across variable bitrates from
3kbps to 18kbps, with a negligible quality loss when compared with models
trained at fixed bitrates. In addition, the model is amenable to a low latency
implementation, which supports streamable inference and runs in real time on a
smartphone CPU. In subjective evaluations using audio at 24kHz sampling rate,
SoundStream at 3kbps outperforms Opus at 12kbps and approaches EVS at 9.6kbps.
Moreover, we are able to perform joint compression and enhancement either at
the encoder or at the decoder side with no additional latency, which we
demonstrate through background noise suppression for speech.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic semi-nonnegative matrix factorization: a Skellam-based framework. (arXiv:2107.03317v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fuentes_B/0/1/0/all/0/1">Benoit Fuentes</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1">Ga&#xeb;l Richard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03317">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new probabilistic model to address semi-nonnegative matrix
factorization (SNMF), called Skellam-SNMF. It is a hierarchical generative
model consisting of prior components, Skellam-distributed hidden variables and
observed data. Two inference algorithms are derived: Expectation-Maximization
(EM) algorithm for maximum \emph{a posteriori} estimation and Variational Bayes
EM (VBEM) for full Bayesian inference, including the estimation of parameters
prior distribution. From this Skellam-based model, we also introduce a new
divergence $\mathcal{D}$ between a real-valued target data $x$ and two
nonnegative parameters $\lambda_{0}$ and $\lambda_{1}$ such that
$\mathcal{D}\left(x\mid\lambda_{0},\lambda_{1}\right)&#x3D;0\Leftrightarrow
x&#x3D;\lambda_{0}-\lambda_{1}$, which is a generalization of the Kullback-Leibler
(KL) divergence. Finally, we conduct experimental studies on those new
algorithms in order to understand their behavior and prove that they can
outperform the classic SNMF approach on real data in a task of automatic
clustering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lossy Compression for Lossless Prediction. (arXiv:2106.10800v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dubois_Y/0/1/0/all/0/1">Yann Dubois</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloem_Reddy_B/0/1/0/all/0/1">Benjamin Bloem-Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullrich_K/0/1/0/all/0/1">Karen Ullrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1">Chris J. Maddison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10800">
                                    <div class="article-summary-box-inner">
                                        <span>Most data is automatically collected and only ever &quot;seen&quot; by algorithms. Yet,
data compressors preserve perceptual fidelity rather than just the information
needed by algorithms performing downstream tasks. In this paper, we
characterize the bit-rate required to ensure high performance on all predictive
tasks that are invariant under a set of transformations, such as data
augmentations. Based on our theory, we design unsupervised objectives for
training neural compressors. Using these objectives, we train a generic image
compressor that achieves substantial rate savings (more than $1000\times$ on
ImageNet) compared to JPEG on 8 datasets, without decreasing downstream
classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Monocular Depth Estimation via Listwise Ranking using the Plackett-Luce Model. (arXiv:2010.13118v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lienen_J/0/1/0/all/0/1">Julian Lienen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1">Eyke H&#xfc;llermeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ewerth_R/0/1/0/all/0/1">Ralph Ewerth</a>, <a href="http://arxiv.org/find/cs/1/au:+Nommensen_N/0/1/0/all/0/1">Nils Nommensen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13118">
                                    <div class="article-summary-box-inner">
                                        <span>In many real-world applications, the relative depth of objects in an image is
crucial for scene understanding. Recent approaches mainly tackle the problem of
depth prediction in monocular images by treating the problem as a regression
task. Yet, being interested in an order relation in the first place, ranking
methods suggest themselves as a natural alternative to regression, and indeed,
ranking approaches leveraging pairwise comparisons as training information
(&quot;object A is closer to the camera than B&quot;) have shown promising performance on
this problem. In this paper, we elaborate on the use of so-called listwise
ranking as a generalization of the pairwise approach. Our method is based on
the Plackett-Luce (PL) model, a probability distribution on rankings, which we
combine with a state-of-the-art neural network architecture and a simple
sampling strategy to reduce training complexity. Moreover, taking advantage of
the representation of PL as a random utility model, the proposed predictor
offers a natural way to recover (shift-invariant) metric depth information from
ranking-only data provided at training time. An empirical evaluation on several
benchmark datasets in a &quot;zero-shot&quot; setting demonstrates the effectiveness of
our approach compared to existing ranking and regression methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simulated Data Generation Through Algorithmic Force Coefficient Estimation for AI-Based Robotic Projectile Launch Modeling. (arXiv:2105.12833v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_S/0/1/0/all/0/1">Sajiv Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Haque_A/0/1/0/all/0/1">Ayaan Haque</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12833">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling of non-rigid object launching and manipulation is complex
considering the wide range of dynamics affecting trajectory, many of which may
be unknown. Using physics models can be inaccurate because they cannot account
for unknown factors and the effects of the deformation of the object as it is
launched; moreover, deriving force coefficients for these models is not
possible without extensive experimental testing. Recently, advancements in
data-powered artificial intelligence methods have allowed learnable models and
systems to emerge. It is desirable to train a model for launch prediction on a
robot, as deep neural networks can account for immeasurable dynamics. However,
the inability to collect large amounts of experimental data decreases
performance of deep neural networks. Through estimating force coefficients, the
accepted physics models can be leveraged to produce adequate supplemental data
to artificially increase the size of the training set, yielding improved neural
networks. In this paper, we introduce a new framework for algorithmic
estimation of force coefficients for non-rigid object launching, which can be
generalized to other domains, in order to generate large datasets. We implement
a novel training algorithm and objective for our deep neural network to
accurately model launch trajectory of non-rigid objects and predict whether
they will hit a series of targets. Our experimental results demonstrate the
effectiveness of using simulated data from force coefficient estimation and
shows the importance of simulated data for training an effective neural
network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Locally Private Graph Neural Networks. (arXiv:2006.05535v9 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sajadmanesh_S/0/1/0/all/0/1">Sina Sajadmanesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Gatica_Perez_D/0/1/0/all/0/1">Daniel Gatica-Perez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05535">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) have demonstrated superior performance in
learning node representations for various graph inference tasks. However,
learning over graph data can raise privacy concerns when nodes represent people
or human-related variables that involve sensitive or personal information.
While numerous techniques have been proposed for privacy-preserving deep
learning over non-relational data, there is less work addressing the privacy
issues pertained to applying deep learning algorithms on graphs. In this paper,
we study the problem of node data privacy, where graph nodes have potentially
sensitive data that is kept private, but they could be beneficial for a central
server for training a GNN over the graph. To address this problem, we develop a
privacy-preserving, architecture-agnostic GNN learning algorithm with formal
privacy guarantees based on Local Differential Privacy (LDP). Specifically, we
propose an LDP encoder and an unbiased rectifier, by which the server can
communicate with the graph nodes to privately collect their data and
approximate the GNN&#x27;s first layer. To further reduce the effect of the injected
noise, we propose to prepend a simple graph convolution layer, called KProp,
which is based on the multi-hop aggregation of the nodes&#x27; features acting as a
denoising mechanism. Finally, we propose a robust training framework, in which
we benefit from KProp&#x27;s denoising capability to increase the accuracy of
inference in the presence of noisy labels. Extensive experiments conducted over
real-world datasets demonstrate that our method can maintain a satisfying level
of accuracy with low privacy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparative Study of Using Spatial-Temporal Graph Convolutional Networks for Predicting Availability in Bike Sharing Schemes. (arXiv:2104.10644v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengyong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hongde Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+OConnor_N/0/1/0/all/0/1">Noel E. O&#x27;Connor</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10644">
                                    <div class="article-summary-box-inner">
                                        <span>Accurately forecasting transportation demand is crucial for efficient urban
traffic guidance, control and management. One solution to enhance the level of
prediction accuracy is to leverage graph convolutional networks (GCN), a neural
network based modelling approach with the ability to process data contained in
graph based structures. As a powerful extension of GCN, a spatial-temporal
graph convolutional network (ST-GCN) aims to capture the relationship of data
contained in the graphical nodes across both spatial and temporal dimensions,
which presents a novel deep learning paradigm for the analysis of complex
time-series data that also involves spatial information as present in
transportation use cases. In this paper, we present an Attention-based ST-GCN
(AST-GCN) for predicting the number of available bikes in bike-sharing systems
in cities, where the attention-based mechanism is introduced to further improve
the performance of an ST-GCN. Furthermore, we also discuss the impacts of
different modelling methods of adjacency matrices on the proposed architecture.
Our experimental results are presented using two real-world datasets,
Dublinbikes and NYC-Citi Bike, to illustrate the efficacy of our proposed model
which outperforms the majority of existing approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Convergence of Overlapping Schwarz Decomposition for Nonlinear Optimal Control. (arXiv:2005.06674v4 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Na_S/0/1/0/all/0/1">Sen Na</a>, <a href="http://arxiv.org/find/math/1/au:+Shin_S/0/1/0/all/0/1">Sungho Shin</a>, <a href="http://arxiv.org/find/math/1/au:+Anitescu_M/0/1/0/all/0/1">Mihai Anitescu</a>, <a href="http://arxiv.org/find/math/1/au:+Zavala_V/0/1/0/all/0/1">Victor M. Zavala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.06674">
                                    <div class="article-summary-box-inner">
                                        <span>We study the convergence properties of an overlapping Schwarz
decomposition~algorithm for solving nonlinear optimal control problems (OCPs).
The approach decomposes the time domain into a set of overlapping subdomains,
and solves subproblems defined over such subdomains in parallel. Convergence is
attained by updating primal-dual information at the boundaries of the
overlapping regions. We show that the algorithm exhibits local linear
convergence and that the convergence rate improves exponentially with the
overlap size. Our convergence results rely on a sensitivity result for OCPs
that we call &quot;exponential decay of sensitivity&quot; (EDS). Intuitively, EDS states
that the impact of parametric perturbations at the boundaries of the domain
(initial and final time) decays exponentially as one moves into the domain. We
show that EDS holds for nonlinear OCPs under a uniform second-order sufficient
condition, a controllability condition, and a uniform boundedness condition. We
conduct numerical experiments using a quadrotor motion planning problem and a
PDE control problem; and show that the approach is significantly more efficient
than ADMM and as efficient as the centralized solver Ipopt.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Faults in Deep Reinforcement Learning Programs: A Taxonomy and A Detection Approach. (arXiv:2101.00135v2 [cs.SE] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikanjam_A/0/1/0/all/0/1">Amin Nikanjam</a>, <a href="http://arxiv.org/find/cs/1/au:+Morovati_M/0/1/0/all/0/1">Mohammad Mehdi Morovati</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a>, <a href="http://arxiv.org/find/cs/1/au:+Braiek_H/0/1/0/all/0/1">Houssem Ben Braiek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00135">
                                    <div class="article-summary-box-inner">
                                        <span>A growing demand is witnessed in both industry and academia for employing
Deep Learning (DL) in various domains to solve real-world problems. Deep
Reinforcement Learning (DRL) is the application of DL in the domain of
Reinforcement Learning (RL). Like any software systems, DRL applications can
fail because of faults in their programs. In this paper, we present the first
attempt to categorize faults occurring in DRL programs. We manually analyzed
761 artifacts of DRL programs (from Stack Overflow posts and GitHub issues)
developed using well-known DRL frameworks (OpenAI Gym, Dopamine, Keras-rl,
Tensorforce) and identified faults reported by developers/users. We labeled and
taxonomized the identified faults through several rounds of discussions. The
resulting taxonomy is validated using an online survey with 19
developers/researchers. To allow for the automatic detection of faults in DRL
programs, we have defined a meta-model of DRL programs and developed DRLinter,
a model-based fault detection approach that leverages static analysis and graph
transformations. The execution flow of DRLinter consists in parsing a DRL
program to generate a model conforming to our meta-model and applying detection
rules on the model to identify faults occurrences. The effectiveness of
DRLinter is evaluated using 15 synthetic DRLprograms in which we injected
faults observed in the analyzed artifacts of the taxonomy. The results show
that DRLinter can successfully detect faults in all synthetic faulty programs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Test for non-negligible adverse shifts. (arXiv:2107.02990v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kamulete_V/0/1/0/all/0/1">Vathy M. Kamulete</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02990">
                                    <div class="article-summary-box-inner">
                                        <span>Statistical tests for dataset shift are susceptible to false alarms: they are
sensitive to minor differences where there is in fact adequate sample coverage
and predictive performance. We propose instead a robust framework for tests of
dataset shift based on outlier scores, D-SOS for short. D-SOS detects adverse
shifts and can identify false alarms caused by benign ones. It posits that a
new (test) sample is not substantively worse than an old (training) sample, and
not that the two are equal. The key idea is to reduce observations to outlier
scores and compare contamination rates. Beyond comparing distributions, users
can define what worse means in terms of predictive performance and other
relevant notions. We show how versatile and practical D-SOS is for a wide range
of real and simulated datasets. Unlike tests of equal distribution and of
goodness-of-fit, the D-SOS tests are uniquely tailored to serve as robust
performance metrics to monitor model drift and dataset shift.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RoFL: Attestable Robustness for Secure Federated Learning. (arXiv:2107.03311v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Burkhalter_L/0/1/0/all/0/1">Lukas Burkhalter</a>, <a href="http://arxiv.org/find/cs/1/au:+Nijeholt_H/0/1/0/all/0/1">Hidde Lycklama &#xe0; Nijeholt</a>, <a href="http://arxiv.org/find/cs/1/au:+Viand_A/0/1/0/all/0/1">Alexander Viand</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuchler_N/0/1/0/all/0/1">Nicolas K&#xfc;chler</a>, <a href="http://arxiv.org/find/cs/1/au:+Hithnawi_A/0/1/0/all/0/1">Anwar Hithnawi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03311">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning is an emerging decentralized machine learning paradigm
that allows a large number of clients to train a joint model without the need
to share their private data. Participants instead only share ephemeral updates
necessary to train the model. To ensure the confidentiality of the client
updates, Federated Learning systems employ secure aggregation; clients encrypt
their gradient updates, and only the aggregated model is revealed to the
server. Achieving this level of data protection, however, presents new
challenges to the robustness of Federated Learning, i.e., the ability to
tolerate failures and attacks. Unfortunately, in this setting, a malicious
client can now easily exert influence on the model behavior without being
detected. As Federated Learning is being deployed in practice in a range of
sensitive applications, its robustness is growing in importance. In this paper,
we take a step towards understanding and improving the robustness of secure
Federated Learning. We start this paper with a systematic study that evaluates
and analyzes existing attack vectors and discusses potential defenses and
assesses their effectiveness. We then present RoFL, a secure Federated Learning
system that improves robustness against malicious clients through input checks
on the encrypted model updates. RoFL extends Federated Learning&#x27;s secure
aggregation protocol to allow expressing a variety of properties and
constraints on model updates using zero-knowledge proofs. To enable RoFL to
scale to typical Federated Learning settings, we introduce several ML and
cryptographic optimizations specific to Federated Learning. We implement and
evaluate a prototype of RoFL and show that realistic ML models can be trained
in a reasonable time while improving robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A data-driven approach to the forecasting of ground-level ozone concentration. (arXiv:2012.00685v4 [physics.ao-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Marvin_D/0/1/0/all/0/1">Dario Marvin</a>, <a href="http://arxiv.org/find/physics/1/au:+Nespoli_L/0/1/0/all/0/1">Lorenzo Nespoli</a>, <a href="http://arxiv.org/find/physics/1/au:+Strepparava_D/0/1/0/all/0/1">Davide Strepparava</a>, <a href="http://arxiv.org/find/physics/1/au:+Medici_V/0/1/0/all/0/1">Vasco Medici</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00685">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to forecast the concentration of air pollutants in an urban
region is crucial for decision-makers wishing to reduce the impact of pollution
on public health through active measures (e.g. temporary traffic closures). In
this study, we present a machine learning approach applied to the forecast of
the day-ahead maximum value of the ozone concentration for several geographical
locations in southern Switzerland. Due to the low density of measurement
stations and to the complex orography of the use case terrain, we adopted
feature selection methods instead of explicitly restricting relevant features
to a neighbourhood of the prediction sites, as common in spatio-temporal
forecasting methods. We then used Shapley values to assess the explainability
of the learned models in terms of feature importance and feature interactions
in relation to ozone predictions; our analysis suggests that the trained models
effectively learned explanatory cross-dependencies among atmospheric variables.
Finally, we show how weighting observations helps in increasing the accuracy of
the forecasts for specific ranges of ozone&#x27;s daily peak values.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MD-split+: Practical Local Conformal Inference in High Dimensions. (arXiv:2107.03280v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+LeRoy_B/0/1/0/all/0/1">Benjamin LeRoy</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhao_D/0/1/0/all/0/1">David Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03280">
                                    <div class="article-summary-box-inner">
                                        <span>Quantifying uncertainty in model predictions is a common goal for
practitioners seeking more than just point predictions. One tool for
uncertainty quantification that requires minimal assumptions is conformal
inference, which can help create probabilistically valid prediction regions for
black box models. Classical conformal prediction only provides marginal
validity, whereas in many situations locally valid prediction regions are
desirable. Deciding how best to partition the feature space X when applying
localized conformal prediction is still an open question. We present MD-split+,
a practical local conformal approach that creates X partitions based on
localized model performance of conditional density estimation models. Our
method handles complex real-world data settings where such models may be
misspecified, and scales to high-dimensional inputs. We discuss how our local
partitions philosophically align with expected behavior from an unattainable
conditional conformal inference approach. We also empirically compare our
method against other local conformal approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A comparative study of various Deep Learning techniques for spatio-temporal Super-Resolution reconstruction of Forced Isotropic Turbulent flows. (arXiv:2107.03361v1 [physics.flu-dyn])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Venkatesh_T/0/1/0/all/0/1">T.S.Sachin Venkatesh</a>, <a href="http://arxiv.org/find/physics/1/au:+Srivastava_R/0/1/0/all/0/1">Rajat Srivastava</a>, <a href="http://arxiv.org/find/physics/1/au:+Bhatt_P/0/1/0/all/0/1">Pratyush Bhatt</a>, <a href="http://arxiv.org/find/physics/1/au:+Tyagi_P/0/1/0/all/0/1">Prince Tyagi</a>, <a href="http://arxiv.org/find/physics/1/au:+Singh_R/0/1/0/all/0/1">Raj Kumar Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03361">
                                    <div class="article-summary-box-inner">
                                        <span>Super-resolution is an innovative technique that upscales the resolution of
an image or a video and thus enables us to reconstruct high-fidelity images
from low-resolution data. This study performs super-resolution analysis on
turbulent flow fields spatially and temporally using various state-of-the-art
machine learning techniques like ESPCN, ESRGAN and TecoGAN to reconstruct
high-resolution flow fields from low-resolution flow field data, especially
keeping in mind the need for low resource consumption and rapid results
production/verification. The dataset used for this study is extracted from the
&#x27;isotropic 1024 coarse&#x27; dataset which is a part of Johns Hopkins Turbulence
Databases (JHTDB). We have utilized pre-trained models and fine tuned them to
our needs, so as to minimize the computational resources and the time required
for the implementation of the super-resolution models. The advantages presented
by this method far exceed the expectations and the outcomes of regular single
structure models. The results obtained through these models are then compared
using MSE, PSNR, SAM, VIF and SCC metrics in order to evaluate the upscaled
results, find the balance between computational power and output quality, and
then identify the most accurate and efficient model for spatial and temporal
super-resolution of turbulent flow fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution. (arXiv:2106.02295v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhaoyang_Z/0/1/0/all/0/1">Zhang Zhaoyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wenqi_S/0/1/0/all/0/1">Shao Wenqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jinwei_G/0/1/0/all/0/1">Gu Jinwei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiaogang_W/0/1/0/all/0/1">Wang Xiaogang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_L/0/1/0/all/0/1">Luo Ping</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02295">
                                    <div class="article-summary-box-inner">
                                        <span>Model quantization is challenging due to many tedious hyper-parameters such
as precision (bitwidth), dynamic range (minimum and maximum discrete values)
and stepsize (interval between discrete values). Unlike prior arts that
carefully tune these values, we present a fully differentiable approach to
learn all of them, named Differentiable Dynamic Quantization (DDQ), which has
several benefits. (1) DDQ is able to quantize challenging lightweight
architectures like MobileNets, where different layers prefer different
quantization parameters. (2) DDQ is hardware-friendly and can be easily
implemented using low-precision matrix-vector multiplication, making it capable
in many hardware such as ARM. (3) Extensive experiments show that DDQ
outperforms prior arts on many networks and benchmarks, especially when models
are already efficient and compact. e.g., DDQ is the first approach that
achieves lossless 4-bit quantization for MobileNetV2 on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GRIMGEP: Learning Progress for Robust Goal Sampling in Visual Deep Reinforcement Learning. (arXiv:2008.04388v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovac_G/0/1/0/all/0/1">Grgur Kova&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Laversanne_Finot_A/0/1/0/all/0/1">Adrien Laversanne-Finot</a>, <a href="http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1">Pierre-Yves Oudeyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.04388">
                                    <div class="article-summary-box-inner">
                                        <span>Designing agents, capable of learning autonomously a wide range of skills is
critical in order to increase the scope of reinforcement learning. It will both
increase the diversity of learned skills and reduce the burden of manually
designing reward functions for each skill. Self-supervised agents, setting
their own goals, and trying to maximize the diversity of those goals have shown
great promise towards this end. However, a currently known limitation of agents
trying to maximize the diversity of sampled goals is that they tend to get
attracted to noise or more generally to parts of the environments that cannot
be controlled (distractors). When agents have access to predefined goal
features or expert knowledge, absolute Learning Progress (ALP) provides a way
to distinguish between regions that can be controlled and those that cannot.
However, those methods often fall short when the agents are only provided with
raw sensory inputs such as images. In this work we extend those concepts to
unsupervised image-based goal exploration. We propose a framework that allows
agents to autonomously identify and ignore noisy distracting regions while
searching for novelty in the learnable regions to both improve overall
performance and avoid catastrophic forgetting. Our framework can be combined
with any state-of-the-art novelty seeking goal exploration approaches. We
construct a rich 3D image based environment with distractors. Experiments on
this environment show that agents using our framework successfully identify
interesting regions of the environment, resulting in drastically improved
performances. The source code is available at
https://sites.google.com/view/grimgep.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Samplets: A new paradigm for data compression. (arXiv:2107.03337v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Harbrecht_H/0/1/0/all/0/1">Helmut Harbrecht</a>, <a href="http://arxiv.org/find/math/1/au:+Multerer_M/0/1/0/all/0/1">Michael Multerer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03337">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we introduce the novel concept of samplets by transferring
the construction of Tausch-White wavelets to the realm of data. This way we
obtain a multilevel representation of discrete data which directly enables data
compression, detection of singularities and adaptivity. Applying samplets to
represent kernel matrices, as they arise in kernel based learning or Gaussian
process regression, we end up with quasi-sparse matrices. By thresholding small
entries, these matrices are compressible to O(N log N) relevant entries, where
N is the number of data points. This feature allows for the use of fill-in
reducing reorderings to obtain a sparse factorization of the compressed
matrices. Besides the comprehensive introduction to samplets and their
properties, we present extensive numerical studies to benchmark the approach.
Our results demonstrate that samplets mark a considerable step in the direction
of making large data sets accessible for analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UAV-assisted Online Machine Learning over Multi-Tiered Networks: A Hierarchical Nested Personalized Federated Learning Approach. (arXiv:2106.15734v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Su Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseinalipour_S/0/1/0/all/0/1">Seyyedali Hosseinalipour</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorlatova_M/0/1/0/all/0/1">Maria Gorlatova</a>, <a href="http://arxiv.org/find/cs/1/au:+Brinton_C/0/1/0/all/0/1">Christopher G. Brinton</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_M/0/1/0/all/0/1">Mung Chiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15734">
                                    <div class="article-summary-box-inner">
                                        <span>We consider distributed machine learning (ML) through unmanned aerial
vehicles (UAVs) for geo-distributed device clusters. We propose five new
technologies/techniques: (i) stratified UAV swarms with leader, worker, and
coordinator UAVs, (ii) hierarchical nested personalized federated learning
(HN-PFL): a holistic distributed ML framework for personalized model training
across the worker-leader-core network hierarchy, (iii) cooperative UAV resource
pooling for distributed ML using the UAVs&#x27; local computational capabilities,
(iv) aerial data caching and relaying for efficient data relaying to conduct
ML, and (v) concept/model drift, capturing online data variations at the
devices. We split the UAV-enabled model training problem as two parts. (a)
Network-aware HN-PFL, where we optimize a tradeoff between energy consumption
and ML model performance by configuring data offloading among devices-UAVs and
UAV-UAVs, UAVs&#x27; CPU frequencies, and mini-batch sizes subject to
communication/computation network heterogeneity. We tackle this optimization
problem via the method of posynomial condensation and propose a distributed
algorithm with a performance guarantee. (b) Macro-trajectory and learning
duration design, which we formulate as a sequential decision making problem,
tackled via deep reinforcement learning. Our simulations demonstrate the
superiority of our methodology with regards to the distributed ML performance,
the optimization of network resources, and the swarm trajectory efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Jitter: Random Jittering Loss Function. (arXiv:2106.13749v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhicheng Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_C/0/1/0/all/0/1">Chenglei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Sidan Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13749">
                                    <div class="article-summary-box-inner">
                                        <span>Regularization plays a vital role in machine learning optimization. One novel
regularization method called flooding makes the training loss fluctuate around
the flooding level. It intends to make the model continue to random walk until
it comes to a flat loss landscape to enhance generalization. However, the
hyper-parameter flooding level of the flooding method fails to be selected
properly and uniformly. We propose a novel method called Jitter to improve it.
Jitter is essentially a kind of random loss function. Before training, we
randomly sample the Jitter Point from a specific probability distribution. The
flooding level should be replaced by Jitter point to obtain a new target
function and train the model accordingly. As Jitter point acting as a random
factor, we actually add some randomness to the loss function, which is
consistent with the fact that there exists innumerable random behaviors in the
learning process of the machine learning model and is supposed to make the
model more robust. In addition, Jitter performs random walk randomly which
divides the loss curve into small intervals and then flipping them over,
ideally making the loss curve much flatter and enhancing generalization
ability. Moreover, Jitter can be a domain-, task-, and model-independent
regularization method and train the model effectively after the training error
reduces to zero. Our experimental results show that Jitter method can improve
model performance more significantly than the previous flooding method and make
the test loss curve descend twice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Pseudo-Metric between Probability Distributions based on Depth-Trimmed Regions. (arXiv:2103.12711v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Staerman_G/0/1/0/all/0/1">Guillaume Staerman</a>, <a href="http://arxiv.org/find/stat/1/au:+Mozharovskyi_P/0/1/0/all/0/1">Pavlo Mozharovskyi</a>, <a href="http://arxiv.org/find/stat/1/au:+Clemencon_S/0/1/0/all/0/1">St&#xe9;phan Cl&#xe9;men&#xe7;on</a>, <a href="http://arxiv.org/find/stat/1/au:+dAlche_Buc_F/0/1/0/all/0/1">Florence d&#x27;Alch&#xe9;-Buc</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12711">
                                    <div class="article-summary-box-inner">
                                        <span>Data depth is a non parametric statistical tool that measures centrality of
any element $x\in\mathbb{R}^d$ with respect to (w.r.t.) a probability
distribution or a data set. It is a natural median-oriented extension of the
cumulative distribution function (cdf) to the multivariate case. Consequently,
its upper level sets -- the depth-trimmed regions -- give rise to a definition
of multivariate quantiles. In this work, we propose two new pseudo-metrics
between continuous probability measures based on data depth and its associated
central regions. The first one is constructed as the Lp-distance between data
depth w.r.t. each distribution while the second one relies on the Hausdorff
distance between their quantile regions. It can further be seen as an original
way to extend the one-dimensional formulae of the Wasserstein distance, which
involves quantiles and cdfs, to the multivariate space. After discussing the
properties of these pseudo-metrics and providing conditions under which they
define a distance, we highlight similarities with the Wasserstein distance.
Interestingly, the derived non-asymptotic bounds show that in contrast to the
Wasserstein distance, the proposed pseudo-metrics do not suffer from the curse
of dimensionality. Moreover, based on the support function of a convex body, we
propose an efficient approximation possessing linear time complexity w.r.t. the
size of the data set and its dimension. The quality of this approximation as
well as the performance of the proposed approach are illustrated in
experiments. Furthermore, by construction the regions-based pseudo-metric
appears to be robust w.r.t. both outliers and heavy tails, a behavior witnessed
in the numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How and Why to Use Experimental Data to Evaluate Methods for Observational Causal Inference. (arXiv:2010.03051v2 [stat.ME] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gentzel_A/0/1/0/all/0/1">Amanda Gentzel</a>, <a href="http://arxiv.org/find/stat/1/au:+Pruthi_P/0/1/0/all/0/1">Purva Pruthi</a>, <a href="http://arxiv.org/find/stat/1/au:+Jensen_D/0/1/0/all/0/1">David Jensen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03051">
                                    <div class="article-summary-box-inner">
                                        <span>Methods that infer causal dependence from observational data are central to
many areas of science, including medicine, economics, and the social sciences.
A variety of theoretical properties of these methods have been proven, but
empirical evaluation remains a challenge, largely due to the lack of
observational data sets for which treatment effect is known. We describe and
analyze observational sampling from randomized controlled trials (OSRCT), a
method for evaluating causal inference methods using data from randomized
controlled trials (RCTs). This method can be used to create constructed
observational data sets with corresponding unbiased estimates of treatment
effect, substantially increasing the number of data sets available for
empirical evaluation of causal inference methods. We show that, in expectation,
OSRCT creates data sets that are equivalent to those produced by randomly
sampling from empirical data sets in which all potential outcomes are
available. We then perform a large-scale evaluation of seven causal inference
methods over 37 data sets, drawn from RCTs, as well as simulators, real-world
computational systems, and observational data sets augmented with a synthetic
response variable. We find notable performance differences when comparing
across data from different sources, demonstrating the importance of using data
from a variety of sources when evaluating any causal inference method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey of Uncertainty in Deep Neural Networks. (arXiv:2107.03342v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gawlikowski_J/0/1/0/all/0/1">Jakob Gawlikowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Tassi_C/0/1/0/all/0/1">Cedrique Rovile Njieutcheu Tassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_M/0/1/0/all/0/1">Mohsin Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jongseok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Humt_M/0/1/0/all/0/1">Matthias Humt</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianxiang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kruspe_A/0/1/0/all/0/1">Anna Kruspe</a>, <a href="http://arxiv.org/find/cs/1/au:+Triebel_R/0/1/0/all/0/1">Rudolph Triebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_P/0/1/0/all/0/1">Peter Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Roscher_R/0/1/0/all/0/1">Ribana Roscher</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahzad_M/0/1/0/all/0/1">Muhammad Shahzad</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bamler_R/0/1/0/all/0/1">Richard Bamler</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiao Xiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03342">
                                    <div class="article-summary-box-inner">
                                        <span>Due to their increasing spread, confidence in neural network predictions
became more and more important. However, basic neural networks do not deliver
certainty estimates or suffer from over or under confidence. Many researchers
have been working on understanding and quantifying uncertainty in a neural
network&#x27;s prediction. As a result, different types and sources of uncertainty
have been identified and a variety of approaches to measure and quantify
uncertainty in neural networks have been proposed. This work gives a
comprehensive overview of uncertainty estimation in neural networks, reviews
recent advances in the field, highlights current challenges, and identifies
potential research opportunities. It is intended to give anyone interested in
uncertainty estimation in neural networks a broad overview and introduction,
without presupposing prior knowledge in this field. A comprehensive
introduction to the most crucial sources of uncertainty is given and their
separation into reducible model uncertainty and not reducible data uncertainty
is presented. The modeling of these uncertainties based on deterministic neural
networks, Bayesian neural networks, ensemble of neural networks, and test-time
data augmentation approaches is introduced and different branches of these
fields as well as the latest developments are discussed. For a practical
application, we discuss different measures of uncertainty, approaches for the
calibration of neural networks and give an overview of existing baselines and
implementations. Different examples from the wide spectrum of challenges in
different fields give an idea of the needs and challenges regarding
uncertainties in practical applications. Additionally, the practical
limitations of current methods for mission- and safety-critical real world
applications are discussed and an outlook on the next steps towards a broader
usage of such methods is given.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying Training Stop Point with Noisy Labeled Data. (arXiv:2012.13435v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamabattula_S/0/1/0/all/0/1">Sree Ram Kamabattula</a>, <a href="http://arxiv.org/find/cs/1/au:+Devarajan_V/0/1/0/all/0/1">Venkat Devarajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Namazi_B/0/1/0/all/0/1">Babak Namazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sankaranarayanan_G/0/1/0/all/0/1">Ganesh Sankaranarayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13435">
                                    <div class="article-summary-box-inner">
                                        <span>Training deep neural networks (DNNs) with noisy labels is a challenging
problem due to over-parameterization. DNNs tend to essentially fit on clean
samples at a higher rate in the initial stages, and later fit on the noisy
samples at a relatively lower rate. Thus, with a noisy dataset, the test
accuracy increases initially and drops in the later stages. To find an early
stopping point at the maximum obtainable test accuracy (MOTA), recent studies
assume either that i) a clean validation set is available or ii) the noise
ratio is known, or, both. However, often a clean validation set is unavailable,
and the noise estimation can be inaccurate. To overcome these issues, we
provide a novel training solution, free of these conditions. We analyze the
rate of change of the training accuracy for different noise ratios under
different conditions to identify a training stop region. We further develop a
heuristic algorithm based on a small-learning assumption to find a training
stop point (TSP) at or close to MOTA. To the best of our knowledge, our method
is the first to rely solely on the \textit{training behavior}, while utilizing
the entire training set, to automatically find a TSP. We validated the
robustness of our algorithm (AutoTSP) through several experiments on CIFAR-10,
CIFAR-100, and a real-world noisy dataset for different noise ratios, noise
types, and architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Convolution for Semi-Supervised Classification: Improved Linear Separability and Out-of-Distribution Generalization. (arXiv:2102.06966v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baranwal_A/0/1/0/all/0/1">Aseem Baranwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Fountoulakis_K/0/1/0/all/0/1">Kimon Fountoulakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Jagannath_A/0/1/0/all/0/1">Aukosh Jagannath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06966">
                                    <div class="article-summary-box-inner">
                                        <span>Recently there has been increased interest in semi-supervised classification
in the presence of graphical information. A new class of learning models has
emerged that relies, at its most basic level, on classifying the data after
first applying a graph convolution. To understand the merits of this approach,
we study the classification of a mixture of Gaussians, where the data
corresponds to the node attributes of a stochastic block model. We show that
graph convolution extends the regime in which the data is linearly separable by
a factor of roughly $1/\sqrt{D}$, where $D$ is the expected degree of a node,
as compared to the mixture model data on its own. Furthermore, we find that the
linear classifier obtained by minimizing the cross-entropy loss after the graph
convolution generalizes to out-of-distribution data where the unseen data can
have different intra- and inter-class edge probabilities from the training
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGD-Autoencoder: Attention Gated Deep Convolutional Autoencoder for Brain Tumor Segmentation. (arXiv:2107.03323v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cvetko_T/0/1/0/all/0/1">Tim Cvetko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03323">
                                    <div class="article-summary-box-inner">
                                        <span>Brain tumor segmentation is a challenging problem in medical image analysis.
The endpoint is to generate the salient masks that accurately identify brain
tumor regions in an fMRI screening. In this paper, we propose a novel attention
gate (AG model) for brain tumor segmentation that utilizes both the edge
detecting unit and the attention gated network to highlight and segment the
salient regions from fMRI images. This feature enables us to eliminate the
necessity of having to explicitly point towards the damaged area(external
tissue localization) and classify(classification) as per classical computer
vision techniques. AGs can easily be integrated within the deep convolutional
neural networks(CNNs). Minimal computional overhead is required while the AGs
increase the sensitivity scores significantly. We show that the edge detector
along with an attention gated mechanism provide a sufficient enough method for
brain segmentation reaching an IOU of 0.78</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoDebias: Learning to Debias for Recommendation. (arXiv:2105.04170v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiawei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hande Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1">Xin Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guli Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Keping Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04170">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems rely on user behavior data like ratings and clicks to
build personalization model. However, the collected data is observational
rather than experimental, causing various biases in the data which
significantly affect the learned model. Most existing work for recommendation
debiasing, such as the inverse propensity scoring and imputation approaches,
focuses on one or two specific biases, lacking the universal capacity that can
account for mixed or even unknown biases in the data.

Towards this research gap, we first analyze the origin of biases from the
perspective of \textit{risk discrepancy} that represents the difference between
the expectation empirical risk and the true risk. Remarkably, we derive a
general learning framework that well summarizes most existing debiasing
strategies by specifying some parameters of the general framework. This
provides a valuable opportunity to develop a universal solution for debiasing,
e.g., by learning the debiasing parameters from data. However, the training
data lacks important signal of how the data is biased and what the unbiased
data looks like. To move this idea forward, we propose \textit{AotoDebias} that
leverages another (small) set of uniform data to optimize the debiasing
parameters by solving the bi-level optimization problem with meta-learning.
Through theoretical analyses, we derive the generalization bound for AutoDebias
and prove its ability to acquire the appropriate debiasing strategy. Extensive
experiments on two real datasets and a simulated dataset demonstrated
effectiveness of AutoDebias. The code is available at
\url{https://github.com/DongHande/AutoDebias}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Dynamic Multi-Modal Data Fusion: A Model Uncertainty Perspective. (arXiv:2105.06018v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06018">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is concerned with multi-modal data fusion (MMDF) under unexpected
modality failures in nonlinear non-Gaussian dynamic processes. An efficient
framework to tackle this problem is proposed. In particular, a notion termed
modality &quot;\emph{usefulness}&quot;, which takes a value of 1 or 0, is used for
indicating whether the observation of this modality is useful or not. For $n$
modalities involved, $2^n$ combinations of their &quot;\emph{usefulness}&quot; values
exist. Each combination defines one hypothetical model of the true data
generative process. Then the problem of concern is formalized as a task of
nonlinear non-Gaussian state filtering under model uncertainty, which is
addressed by a dynamic model averaging (DMA) based particle filter (PF)
algorithm. This DMA algorithm employs $2^n$ models, while all models share the
same state-transition function and a unique set of particle values. That makes
the computational complexity of this algorithm only slightly larger than a
single model based PF algorithm, especially for scenarios in which $n$ is
small. Experimental results show that the proposed solution outperforms
remarkably state-of-the-art methods. Code and data are available at
https://github.com/robinlau1981/fusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing the Spatio-temporal Observability of Grid-Edge Resources in Distribution Grids. (arXiv:2102.07801v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lin_S/0/1/0/all/0/1">Shanny Lin</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07801">
                                    <div class="article-summary-box-inner">
                                        <span>Enhancing the spatio-temporal observability of distributed energy resources
(DERs) is crucial for achieving secure and efficient operations in distribution
grids. This paper puts forth a joint recovery framework for residential loads
by leveraging the complimentary strengths of heterogeneous types of
measurements. The proposed approaches integrate the low-resolution smart meter
data collected for every load node with the fast-sampled feeder-level
measurements provided by limited number of phasor measurement units. To address
the lack of data, we exploit two key characteristics for the loads and DERs,
namely the sparse changes due to infrequent activities of appliances and
electric vehicles (EVs) and the locational dependence of solar photovoltaic
(PV) generation. Accordingly, meaningful regularization terms are introduced to
cast a convex load recovery problem, which will be further simplified to reduce
computational complexity. The load recovery solutions can be utilized to
identify the EV charging events at each load node and to infer the total
behind-the-meter PV output. Numerical tests using real-world data have
demonstrated the effectiveness of the proposed approaches in enhancing the
visibility of these grid-edge DERs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">POLAR: A Polynomial Arithmetic Framework for Verifying Neural-Network Controlled Systems. (arXiv:2106.13867v3 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Huang_C/0/1/0/all/0/1">Chao Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Fan_J/0/1/0/all/0/1">Jiameng Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1">Xin Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_W/0/1/0/all/0/1">Wenchao Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_Q/0/1/0/all/0/1">Qi Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13867">
                                    <div class="article-summary-box-inner">
                                        <span>We propose POLAR, a \textbf{pol}ynomial \textbf{ar}ithmetic framework that
leverages polynomial overapproximations with interval remainders for
bounded-time reachability analysis of neural network-controlled systems
(NNCSs). Compared with existing arithmetic approaches that use standard Taylor
models, our framework uses a novel approach to iteratively overapproximate the
neuron output ranges layer-by-layer with a combination of Bernstein polynomial
interpolation for continuous activation functions and Taylor model arithmetic
for the other operations. This approach can overcome the main drawback in the
standard Taylor model arithmetic, i.e. its inability to handle functions that
cannot be well approximated by Taylor polynomials, and significantly improve
the accuracy and efficiency of reachable states computation for NNCSs. To
further tighten the overapproximation, our method keeps the Taylor model
remainders symbolic under the linear mappings when estimating the output range
of a neural network. We show that POLAR can be seamlessly integrated with
existing Taylor model flowpipe construction techniques, and demonstrate that
POLAR significantly outperforms the current state-of-the-art techniques on a
suite of benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Neural Nets in Chemical Engineering: Foundations, Computations, and Applications. (arXiv:2101.04869v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shengli Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zavala_V/0/1/0/all/0/1">Victor M. Zavala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04869">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we review the mathematical foundations of convolutional neural
nets (CNNs) with the goals of: i) highlighting connections with techniques from
statistics, signal processing, linear algebra, differential equations, and
optimization, ii) demystifying underlying computations, and iii) identifying
new types of applications. CNNs are powerful machine learning models that
highlight features from grid data to make predictions (regression and
classification). The grid data object can be represented as vectors (in 1D),
matrices (in 2D), or tensors (in 3D or higher dimensions) and can incorporate
multiple channels (thus providing high flexibility in the input data
representation). CNNs highlight features from the grid data by performing
convolution operations with different types of operators. The operators
highlight different types of features (e.g., patterns, gradients, geometrical
features) and are learned by using optimization techniques. In other words,
CNNs seek to identify optimal operators that best map the input data to the
output data. A common misconception is that CNNs are only capable of processing
image or video data but their application scope is much wider; specifically,
datasets encountered in diverse applications can be expressed as grid data.
Here, we show how to apply CNNs to new types of applications such as optimal
control, flow cytometry, multivariate process monitoring, and molecular
simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Up Exact Neural Network Compression by ReLU Stability. (arXiv:2102.07804v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Serra_T/0/1/0/all/0/1">Thiago Serra</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Abhinav Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramalingam_S/0/1/0/all/0/1">Srikumar Ramalingam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07804">
                                    <div class="article-summary-box-inner">
                                        <span>We can compress a neural network while exactly preserving its underlying
functionality with respect to a given input domain if some of its neurons are
stable. However, current approaches to determine the stability of neurons with
Rectified Linear Unit (ReLU) activations require solving or finding a good
approximation to multiple discrete optimization problems. In this work, we
introduce an algorithm based on solving a single optimization problem to
identify all stable neurons. Our approach is on median 100 times faster than
the state-of-art method, which allows us to explore exact compression on deeper
(5 x 100) and wider (2 x 800) networks within minutes. For classifiers trained
under an amount of L1 regularization that does not worsen accuracy, we can
remove up to 40% of the connections</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable Prediction of Text Complexity: The Missing Preliminaries for Text Simplification. (arXiv:2007.15823v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garbacea_C/0/1/0/all/0/1">Cristina Garbacea</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mengtian Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Carton_S/0/1/0/all/0/1">Samuel Carton</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_Q/0/1/0/all/0/1">Qiaozhu Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.15823">
                                    <div class="article-summary-box-inner">
                                        <span>Text simplification reduces the language complexity of professional content
for accessibility purposes. End-to-end neural network models have been widely
adopted to directly generate the simplified version of input text, usually
functioning as a blackbox. We show that text simplification can be decomposed
into a compact pipeline of tasks to ensure the transparency and explainability
of the process. The first two steps in this pipeline are often neglected: 1) to
predict whether a given piece of text needs to be simplified, and 2) if yes, to
identify complex parts of the text. The two tasks can be solved separately
using either lexical or deep learning methods, or solved jointly. Simply
applying explainable complexity prediction as a preliminary step, the
out-of-sample text simplification performance of the state-of-the-art,
black-box simplification models can be improved by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Codomain Separability and Label Inference from (Noisy) Loss Functions. (arXiv:2107.03022v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1">Abhinav Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasiviswanathan_S/0/1/0/all/0/1">Shiva Prasad Kasiviswanathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zekun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feyisetan_O/0/1/0/all/0/1">Oluwaseyi Feyisetan</a>, <a href="http://arxiv.org/find/cs/1/au:+Teissier_N/0/1/0/all/0/1">Nathanael Teissier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03022">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning classifiers rely on loss functions for performance
evaluation, often on a private (hidden) dataset. Label inference was recently
introduced as the problem of reconstructing the ground truth labels of this
private dataset from just the (possibly perturbed) loss function values
evaluated at chosen prediction vectors, without any other access to the hidden
dataset. Existing results have demonstrated this inference is possible on
specific loss functions like the cross-entropy loss. In this paper, we
introduce the notion of codomain separability to formally study the necessary
and sufficient conditions under which label inference is possible from any
(noisy) loss function values. Using this notion, we show that for many commonly
used loss functions, including multiclass cross-entropy with common activation
functions and some Bregman divergence-based losses, it is possible to design
label inference attacks for arbitrary noise levels. We demonstrate that these
attacks can also be carried out through actual neural network models, and
argue, both formally and empirically, the role of finite precision arithmetic
in this setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Residual Star Generative Adversarial Network for multi-domain Image Super-Resolution. (arXiv:2107.03145v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Umer_R/0/1/0/all/0/1">Rao Muhammad Umer</a>, <a href="http://arxiv.org/find/eess/1/au:+Munir_A/0/1/0/all/0/1">Asad Munir</a>, <a href="http://arxiv.org/find/eess/1/au:+Micheloni_C/0/1/0/all/0/1">Christian Micheloni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03145">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, most of state-of-the-art single image super-resolution (SISR)
methods have attained impressive performance by using deep convolutional neural
networks (DCNNs). The existing SR methods have limited performance due to a
fixed degradation settings, i.e. usually a bicubic downscaling of
low-resolution (LR) image. However, in real-world settings, the LR degradation
process is unknown which can be bicubic LR, bilinear LR, nearest-neighbor LR,
or real LR. Therefore, most SR methods are ineffective and inefficient in
handling more than one degradation settings within a single network. To handle
the multiple degradation, i.e. refers to multi-domain image super-resolution,
we propose a deep Super-Resolution Residual StarGAN (SR2*GAN), a novel and
scalable approach that super-resolves the LR images for the multiple LR domains
using only a single model. The proposed scheme is trained in a StarGAN like
network topology with a single generator and discriminator networks. We
demonstrate the effectiveness of our proposed approach in quantitative and
qualitative experiments compared to other state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Promises and Pitfalls of Deep Kernel Learning. (arXiv:2102.12108v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ober_S/0/1/0/all/0/1">Sebastian W. Ober</a>, <a href="http://arxiv.org/find/stat/1/au:+Rasmussen_C/0/1/0/all/0/1">Carl E. Rasmussen</a>, <a href="http://arxiv.org/find/stat/1/au:+Wilk_M/0/1/0/all/0/1">Mark van der Wilk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12108">
                                    <div class="article-summary-box-inner">
                                        <span>Deep kernel learning (DKL) and related techniques aim to combine the
representational power of neural networks with the reliable uncertainty
estimates of Gaussian processes. One crucial aspect of these models is an
expectation that, because they are treated as Gaussian process models optimized
using the marginal likelihood, they are protected from overfitting. However, we
identify situations where this is not the case. We explore this behavior,
explain its origins and consider how it applies to real datasets. Through
careful experimentation on the UCI, CIFAR-10, and the UTKFace datasets, we find
that the overfitting from overparameterized maximum marginal likelihood, in
which the model is &quot;somewhat Bayesian&quot;, can in certain scenarios be worse than
that from not being Bayesian at all. We explain how and when DKL can still be
successful by investigating optimization dynamics. We also find that failures
of DKL can be rectified by a fully Bayesian treatment, which leads to the
desired performance improvements over standard neural networks and Gaussian
processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Path Planning using Neural A* Search. (arXiv:2009.07476v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yonetani_R/0/1/0/all/0/1">Ryo Yonetani</a>, <a href="http://arxiv.org/find/cs/1/au:+Taniai_T/0/1/0/all/0/1">Tatsunori Taniai</a>, <a href="http://arxiv.org/find/cs/1/au:+Barekatain_M/0/1/0/all/0/1">Mohammadamin Barekatain</a>, <a href="http://arxiv.org/find/cs/1/au:+Nishimura_M/0/1/0/all/0/1">Mai Nishimura</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanezaki_A/0/1/0/all/0/1">Asako Kanezaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07476">
                                    <div class="article-summary-box-inner">
                                        <span>We present Neural A*, a novel data-driven search method for path planning
problems. Despite the recent increasing attention to data-driven path planning,
machine learning approaches to search-based planning are still challenging due
to the discrete nature of search algorithms. In this work, we reformulate a
canonical A* search algorithm to be differentiable and couple it with a
convolutional encoder to form an end-to-end trainable neural network planner.
Neural A* solves a path planning problem by encoding a problem instance to a
guidance map and then performing the differentiable A* search with the guidance
map. By learning to match the search results with ground-truth paths provided
by experts, Neural A* can produce a path consistent with the ground truth
accurately and efficiently. Our extensive experiments confirmed that Neural A*
outperformed state-of-the-art data-driven planners in terms of the search
optimality and efficiency trade-off. Furthermore, Neural A* successfully
predicted realistic human trajectories by directly performing search-based
planning on natural image inputs. Project page:
https://omron-sinicx.github.io/neural-astar/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distribution-free uncertainty quantification for classification under label shift. (arXiv:2103.03323v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Podkopaev_A/0/1/0/all/0/1">Aleksandr Podkopaev</a>, <a href="http://arxiv.org/find/stat/1/au:+Ramdas_A/0/1/0/all/0/1">Aaditya Ramdas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03323">
                                    <div class="article-summary-box-inner">
                                        <span>Trustworthy deployment of ML models requires a proper measure of uncertainty,
especially in safety-critical applications. We focus on uncertainty
quantification (UQ) for classification problems via two avenues -- prediction
sets using conformal prediction and calibration of probabilistic predictors by
post-hoc binning -- since these possess distribution-free guarantees for i.i.d.
data. Two common ways of generalizing beyond the i.i.d. setting include
handling covariate and label shift. Within the context of distribution-free UQ,
the former has already received attention, but not the latter. It is known that
label shift hurts prediction, and we first argue that it also hurts UQ, by
showing degradation in coverage and calibration. Piggybacking on recent
progress in addressing label shift (for better prediction), we examine the
right way to achieve UQ by reweighting the aforementioned conformal and
calibration procedures whenever some unlabeled data from the target
distribution is available. We examine these techniques theoretically in a
distribution-free framework and demonstrate their excellent practical
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incorporating Label Uncertainty in Understanding Adversarial Robustness. (arXiv:2107.03250v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_D/0/1/0/all/0/1">David Evans</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03250">
                                    <div class="article-summary-box-inner">
                                        <span>A fundamental question in adversarial machine learning is whether a robust
classifier exists for a given task. A line of research has made progress
towards this goal by studying concentration of measure, but without considering
data labels. We argue that the standard concentration fails to fully
characterize the intrinsic robustness of a classification problem, since it
ignores data labels which are essential to any classification task. Building on
a novel definition of label uncertainty, we empirically demonstrate that error
regions induced by state-of-the-art models tend to have much higher label
uncertainty compared with randomly-selected subsets. This observation motivates
us to adapt a concentration estimation algorithm to account for label
uncertainty, resulting in more accurate intrinsic robustness measures for
benchmark image classification problems. We further provide empirical evidence
showing that adding an abstain option for classifiers based on label
uncertainty can help improve both the clean and robust accuracies of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization Error Analysis of Neural networks with Gradient Based Regularization. (arXiv:2107.02797v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lingfeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_X/0/1/0/all/0/1">Xue-Cheng Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jiang Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02797">
                                    <div class="article-summary-box-inner">
                                        <span>We study gradient-based regularization methods for neural networks. We mainly
focus on two regularization methods: the total variation and the Tikhonov
regularization. Applying these methods is equivalent to using neural networks
to solve some partial differential equations, mostly in high dimensions in
practical applications. In this work, we introduce a general framework to
analyze the generalization error of regularized networks. The error estimate
relies on two assumptions on the approximation error and the quadrature error.
Moreover, we conduct some experiments on the image classification tasks to show
that gradient-based methods can significantly improve the generalization
ability and adversarial robustness of neural networks. A graphical extension of
the gradient-based methods are also considered in the experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Deterministic Annealing for Classification and Clustering. (arXiv:2102.05836v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mavridis_C/0/1/0/all/0/1">Christos Mavridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Baras_J/0/1/0/all/0/1">John Baras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05836">
                                    <div class="article-summary-box-inner">
                                        <span>Inherent in virtually every iterative machine learning algorithm is the
problem of hyper-parameter tuning, which includes three major design
parameters: (a) the complexity of the model, e.g., the number of neurons in a
neural network, (b) the initial conditions, which heavily affect the behavior
of the algorithm, and (c) the dissimilarity measure used to quantify its
performance. We introduce an online prototype-based learning algorithm that can
be viewed as a progressively growing competitive-learning neural network
architecture for classification and clustering. The learning rule of the
proposed approach is formulated as an online gradient-free stochastic
approximation algorithm that solves a sequence of appropriately defined
optimization problems, simulating an annealing process. The annealing nature of
the algorithm contributes to avoiding poor local minima, offers robustness with
respect to the initial conditions, and provides a means to progressively
increase the complexity of the learning model, through an intuitive bifurcation
phenomenon. The proposed approach is interpretable, requires minimal
hyper-parameter tuning, and allows online control over the
performance-complexity trade-off. Finally, we show that Bregman divergences
appear naturally as a family of dissimilarity measures that play a central role
in both the performance and the computational complexity of the learning
algorithm. Experimental results illustrate the properties and evaluate the
performance of the proposed learning algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Your GAN is Secretly an Energy-based Model and You Should use Discriminator Driven Latent Sampling. (arXiv:2003.06060v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Che_T/0/1/0/all/0/1">Tong Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruixiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1">Jascha Sohl-Dickstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Larochelle_H/0/1/0/all/0/1">Hugo Larochelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Paull_L/0/1/0/all/0/1">Liam Paull</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yuan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.06060">
                                    <div class="article-summary-box-inner">
                                        <span>We show that the sum of the implicit generator log-density $\log p_g$ of a
GAN with the logit score of the discriminator defines an energy function which
yields the true data density when the generator is imperfect but the
discriminator is optimal, thus making it possible to improve on the typical
generator (with implicit density $p_g$). To make that practical, we show that
sampling from this modified density can be achieved by sampling in latent space
according to an energy-based model induced by the sum of the latent prior
log-density and the discriminator output score. This can be achieved by running
a Langevin MCMC in latent space and then applying the generator function, which
we call Discriminator Driven Latent Sampling~(DDLS). We show that DDLS is
highly efficient compared to previous methods which work in the
high-dimensional pixel space and can be applied to improve on previously
trained GANs of many types. We evaluate DDLS on both synthetic and real-world
datasets qualitatively and quantitatively. On CIFAR-10, DDLS substantially
improves the Inception Score of an off-the-shelf pre-trained
SN-GAN~\citep{sngan} from $8.22$ to $9.09$ which is even comparable to the
class-conditional BigGAN~\citep{biggan} model. This achieves a new
state-of-the-art in unconditional image synthesis setting without introducing
extra parameters or additional training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intensity Prediction of Tropical Cyclones using Long Short-Term Memory Network. (arXiv:2107.03187v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_K/0/1/0/all/0/1">Koushik Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sandeep Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Ashish Kumar Pandey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03187">
                                    <div class="article-summary-box-inner">
                                        <span>Tropical cyclones can be of varied intensity and cause a huge loss of lives
and property if the intensity is high enough. Therefore, the prediction of the
intensity of tropical cyclones advance in time is of utmost importance. We
propose a novel stacked bidirectional long short-term memory network (BiLSTM)
based model architecture to predict the intensity of a tropical cyclone in
terms of Maximum surface sustained wind speed (MSWS). The proposed model can
predict MSWS well advance in time (up to 72 h) with very high accuracy. We have
applied the model on tropical cyclones in the North Indian Ocean from 1982 to
2018 and checked its performance on two recent tropical cyclones, namely, Fani
and Vayu. The model predicts MSWS (in knots) for the next 3, 12, 24, 36, 48,
60, and 72 hours with a mean absolute error of 1.52, 3.66, 5.88, 7.42, 8.96,
10.15, and 11.92, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Fault Detection for Deep Learning Programs Using Graph Transformations. (arXiv:2105.08095v2 [cs.SE] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikanjam_A/0/1/0/all/0/1">Amin Nikanjam</a>, <a href="http://arxiv.org/find/cs/1/au:+Braiek_H/0/1/0/all/0/1">Houssem Ben Braiek</a>, <a href="http://arxiv.org/find/cs/1/au:+Morovati_M/0/1/0/all/0/1">Mohammad Mehdi Morovati</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08095">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, we are witnessing an increasing demand in both corporates and
academia for exploiting Deep Learning (DL) to solve complex real-world
problems. A DL program encodes the network structure of a desirable DL model
and the process by which the model learns from the training dataset. Like any
software, a DL program can be faulty, which implies substantial challenges of
software quality assurance, especially in safety-critical domains. It is
therefore crucial to equip DL development teams with efficient fault detection
techniques and tools. In this paper, we propose NeuraLint, a model-based fault
detection approach for DL programs, using meta-modelling and graph
transformations. First, we design a meta-model for DL programs that includes
their base skeleton and fundamental properties. Then, we construct a
graph-based verification process that covers 23 rules defined on top of the
meta-model and implemented as graph transformations to detect faults and design
inefficiencies in the generated models (i.e., instances of the meta-model).
First, the proposed approach is evaluated by finding faults and design
inefficiencies in 28 synthesized examples built from common problems reported
in the literature. Then NeuraLint successfully finds 64 faults and design
inefficiencies in 34 real-world DL programs extracted from Stack Overflow posts
and GitHub repositories. The results show that NeuraLint effectively detects
faults and design issues in both synthesized and real-world examples with a
recall of 70.5 % and a precision of 100 %. Although the proposed meta-model is
designed for feedforward neural networks, it can be extended to support other
neural network architectures such as recurrent neural networks. Researchers can
also expand our set of verification rules to cover more types of issues in DL
programs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Opioid Use Disorder from Longitudinal Healthcare Data using Multi-stream Transformer. (arXiv:2103.08800v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fouladvand_S/0/1/0/all/0/1">Sajjad Fouladvand</a>, <a href="http://arxiv.org/find/cs/1/au:+Talbert_J/0/1/0/all/0/1">Jeffery Talbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Dwoskin_L/0/1/0/all/0/1">Linda P. Dwoskin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bush_H/0/1/0/all/0/1">Heather Bush</a>, <a href="http://arxiv.org/find/cs/1/au:+Meadows_A/0/1/0/all/0/1">Amy Lynn Meadows</a>, <a href="http://arxiv.org/find/cs/1/au:+Peterson_L/0/1/0/all/0/1">Lars E. Peterson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kavuluru_R/0/1/0/all/0/1">Ramakanth Kavuluru</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08800">
                                    <div class="article-summary-box-inner">
                                        <span>Opioid Use Disorder (OUD) is a public health crisis costing the US billions
of dollars annually in healthcare, lost workplace productivity, and crime.
Analyzing longitudinal healthcare data is critical in addressing many
real-world problems in healthcare. Leveraging the real-world longitudinal
healthcare data, we propose a novel multi-stream transformer model called MUPOD
for OUD identification. MUPOD is designed to simultaneously analyze multiple
types of healthcare data streams, such as medications and diagnoses, by
attending to segments within and across these data streams. Our model tested on
the data from 392,492 patients with long-term back pain problems showed
significantly better performance than the traditional models and recently
developed deep learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graphing else matters: exploiting aspect opinions and ratings in explainable graph-based recommendations. (arXiv:2107.03226v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cantador_I/0/1/0/all/0/1">Iv&#xe1;n Cantador</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvallo_A/0/1/0/all/0/1">Andr&#xe9;s Carvallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Diez_F/0/1/0/all/0/1">Fernando Diez</a>, <a href="http://arxiv.org/find/cs/1/au:+Parra_D/0/1/0/all/0/1">Denis Parra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03226">
                                    <div class="article-summary-box-inner">
                                        <span>The success of neural network embeddings has entailed a renewed interest in
using knowledge graphs for a wide variety of machine learning and information
retrieval tasks. In particular, current recommendation methods based on graph
embeddings have shown state-of-the-art performance. These methods commonly
encode latent rating patterns and content features. Different from previous
work, in this paper, we propose to exploit embeddings extracted from graphs
that combine information from ratings and aspect-based opinions expressed in
textual reviews. We then adapt and evaluate state-of-the-art graph embedding
techniques over graphs generated from Amazon and Yelp reviews on six domains,
outperforming baseline recommenders. Our approach has the advantage of
providing explanations which leverage aspect-based opinions given by users
about recommended items. Furthermore, we also provide examples of the
applicability of recommendations utilizing aspect opinions as explanations in a
visualization dashboard, which allows obtaining information about the most and
least liked aspects of similar users obtained from the embeddings of an input
graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simple Agent, Complex Environment: Efficient Reinforcement Learning with Agent States. (arXiv:2102.05261v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1">Shi Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1">Benjamin Van Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05261">
                                    <div class="article-summary-box-inner">
                                        <span>We design a simple reinforcement learning (RL) agent that implements an
optimistic version of $Q$-learning and establish through regret analysis that
this agent can operate with some level of competence in any environment. While
we leverage concepts from the literature on provably efficient RL, we consider
a general agent-environment interface and provide a novel agent design and
analysis. This level of generality positions our results to inform the design
of future agents for operation in complex real environments. We establish that,
as time progresses, our agent performs competitively relative to policies that
require longer times to evaluate. The time it takes to approach asymptotic
performance is polynomial in the complexity of the agent&#x27;s state representation
and the time required to evaluate the best policy that the agent can represent.
Notably, there is no dependence on the complexity of the environment. The
ultimate per-period performance loss of the agent is bounded by a constant
multiple of a measure of distortion introduced by the agent&#x27;s state
representation. This work is the first to establish that an algorithm
approaches this asymptotic condition within a tractable time frame.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed stochastic optimization with large delays. (arXiv:2107.02919v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Zhou_Z/0/1/0/all/0/1">Zhengyuan Zhou</a>, <a href="http://arxiv.org/find/math/1/au:+Mertikopoulos_P/0/1/0/all/0/1">Panayotis Mertikopoulos</a>, <a href="http://arxiv.org/find/math/1/au:+Bambos_N/0/1/0/all/0/1">Nicholas Bambos</a>, <a href="http://arxiv.org/find/math/1/au:+Glynn_P/0/1/0/all/0/1">Peter W. Glynn</a>, <a href="http://arxiv.org/find/math/1/au:+Ye_Y/0/1/0/all/0/1">Yinyu Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02919">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most widely used methods for solving large-scale stochastic
optimization problems is distributed asynchronous stochastic gradient descent
(DASGD), a family of algorithms that result from parallelizing stochastic
gradient descent on distributed computing architectures (possibly)
asychronously. However, a key obstacle in the efficient implementation of DASGD
is the issue of delays: when a computing node contributes a gradient update,
the global model parameter may have already been updated by other nodes several
times over, thereby rendering this gradient information stale. These delays can
quickly add up if the computational throughput of a node is saturated, so the
convergence of DASGD may be compromised in the presence of large delays. Our
first contribution is that, by carefully tuning the algorithm&#x27;s step-size,
convergence to the critical set is still achieved in mean square, even if the
delays grow unbounded at a polynomial rate. We also establish finer results in
a broad class of structured optimization problems (called variationally
coherent), where we show that DASGD converges to a global optimum with
probability $1$ under the same delay assumptions. Together, these results
contribute to the broad landscape of large-scale non-convex stochastic
optimization by offering state-of-the-art theoretical guarantees and providing
insights for algorithm design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DER Forecast using Privacy Preserving Federated Learning. (arXiv:2107.03248v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Venkataramanan_V/0/1/0/all/0/1">Venkatesh Venkataramanan</a>, <a href="http://arxiv.org/find/eess/1/au:+Kaza_S/0/1/0/all/0/1">Sridevi Kaza</a>, <a href="http://arxiv.org/find/eess/1/au:+Annaswamy_A/0/1/0/all/0/1">Anuradha M. Annaswamy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03248">
                                    <div class="article-summary-box-inner">
                                        <span>With increasing penetration of Distributed Energy Resources (DERs) in grid
edge including renewable generation, flexible loads, and storage, accurate
prediction of distributed generation and consumption at the consumer level
becomes important. However, DER prediction based on the transmission of
customer level data, either repeatedly or in large amounts, is not feasible due
to privacy concerns. In this paper, a distributed machine learning approach,
Federated Learning, is proposed to carry out DER forecasting using a network of
IoT nodes, each of which transmits a model of the consumption and generation
patterns without revealing consumer data. We consider a simulation study which
includes 1000 DERs, and show that our method leads to an accurate prediction of
preserve consumer privacy, while still leading to an accurate forecast. We also
evaluate grid-specific performance metrics such as load swings and load
curtailment and show that our FL algorithm leads to satisfactory performance.
Simulations are also performed on the Pecan street dataset to demonstrate the
validity of the proposed approach on real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Large Language Models Trained on Code. (arXiv:2107.03374v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mark Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tworek_J/0/1/0/all/0/1">Jerry Tworek</a>, <a href="http://arxiv.org/find/cs/1/au:+Jun_H/0/1/0/all/0/1">Heewoo Jun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Q/0/1/0/all/0/1">Qiming Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponde_H/0/1/0/all/0/1">Henrique Ponde</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_J/0/1/0/all/0/1">Jared Kaplan</a>, <a href="http://arxiv.org/find/cs/1/au:+Edwards_H/0/1/0/all/0/1">Harri Edwards</a>, <a href="http://arxiv.org/find/cs/1/au:+Burda_Y/0/1/0/all/0/1">Yura Burda</a>, <a href="http://arxiv.org/find/cs/1/au:+Joseph_N/0/1/0/all/0/1">Nicholas Joseph</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockman_G/0/1/0/all/0/1">Greg Brockman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1">Alex Ray</a>, <a href="http://arxiv.org/find/cs/1/au:+Puri_R/0/1/0/all/0/1">Raul Puri</a>, <a href="http://arxiv.org/find/cs/1/au:+Krueger_G/0/1/0/all/0/1">Gretchen Krueger</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrov_M/0/1/0/all/0/1">Michael Petrov</a>, <a href="http://arxiv.org/find/cs/1/au:+Khlaaf_H/0/1/0/all/0/1">Heidy Khlaaf</a>, <a href="http://arxiv.org/find/cs/1/au:+Sastry_G/0/1/0/all/0/1">Girish Sastry</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishkin_P/0/1/0/all/0/1">Pamela Mishkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_B/0/1/0/all/0/1">Brooke Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gray_S/0/1/0/all/0/1">Scott Gray</a>, <a href="http://arxiv.org/find/cs/1/au:+Ryder_N/0/1/0/all/0/1">Nick Ryder</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavlov_M/0/1/0/all/0/1">Mikhail Pavlov</a>, <a href="http://arxiv.org/find/cs/1/au:+Power_A/0/1/0/all/0/1">Alethea Power</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaiser_L/0/1/0/all/0/1">Lukasz Kaiser</a>, <a href="http://arxiv.org/find/cs/1/au:+Bavarian_M/0/1/0/all/0/1">Mohammad Bavarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Winter_C/0/1/0/all/0/1">Clemens Winter</a>, <a href="http://arxiv.org/find/cs/1/au:+Tillet_P/0/1/0/all/0/1">Philippe Tillet</a>, <a href="http://arxiv.org/find/cs/1/au:+Such_F/0/1/0/all/0/1">Felipe Such</a>, <a href="http://arxiv.org/find/cs/1/au:+Cummings_D/0/1/0/all/0/1">Dave Cummings</a>, <a href="http://arxiv.org/find/cs/1/au:+Plappert_M/0/1/0/all/0/1">Matthias Plappert</a>, <a href="http://arxiv.org/find/cs/1/au:+Chantzis_F/0/1/0/all/0/1">Fotios Chantzis</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_E/0/1/0/all/0/1">Elizabeth Barnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Herbert_Voss_A/0/1/0/all/0/1">Ariel Herbert-Voss</a>, <a href="http://arxiv.org/find/cs/1/au:+Guss_W/0/1/0/all/0/1">Will Guss</a>, <a href="http://arxiv.org/find/cs/1/au:+Nichol_A/0/1/0/all/0/1">Alex Nichol</a>, <a href="http://arxiv.org/find/cs/1/au:+Babuschkin_I/0/1/0/all/0/1">Igor Babuschkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Balaji_S/0/1/0/all/0/1">Suchir Balaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Shantanu Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Carr_A/0/1/0/all/0/1">Andrew Carr</a>, <a href="http://arxiv.org/find/cs/1/au:+Leike_J/0/1/0/all/0/1">Jan Leike</a>, <a href="http://arxiv.org/find/cs/1/au:+Achiam_J/0/1/0/all/0/1">Josh Achiam</a>, <a href="http://arxiv.org/find/cs/1/au:+Misra_V/0/1/0/all/0/1">Vedant Misra</a>, <a href="http://arxiv.org/find/cs/1/au:+Morikawa_E/0/1/0/all/0/1">Evan Morikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Radford_A/0/1/0/all/0/1">Alec Radford</a>, <a href="http://arxiv.org/find/cs/1/au:+Knight_M/0/1/0/all/0/1">Matthew Knight</a>, <a href="http://arxiv.org/find/cs/1/au:+Brundage_M/0/1/0/all/0/1">Miles Brundage</a>, <a href="http://arxiv.org/find/cs/1/au:+Murati_M/0/1/0/all/0/1">Mira Murati</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayer_K/0/1/0/all/0/1">Katie Mayer</a>, <a href="http://arxiv.org/find/cs/1/au:+Welinder_P/0/1/0/all/0/1">Peter Welinder</a>, <a href="http://arxiv.org/find/cs/1/au:+McGrew_B/0/1/0/all/0/1">Bob McGrew</a>, <a href="http://arxiv.org/find/cs/1/au:+Amodei_D/0/1/0/all/0/1">Dario Amodei</a>, <a href="http://arxiv.org/find/cs/1/au:+McCandlish_S/0/1/0/all/0/1">Sam McCandlish</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutskever_I/0/1/0/all/0/1">Ilya Sutskever</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1">Wojciech Zaremba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03374">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Codex, a GPT language model fine-tuned on publicly available
code from GitHub, and study its Python code-writing capabilities. A distinct
production version of Codex powers GitHub Copilot. On HumanEval, a new
evaluation set we release to measure functional correctness for synthesizing
programs from docstrings, our model solves 28.8% of the problems, while GPT-3
solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling
from the model is a surprisingly effective strategy for producing working
solutions to difficult prompts. Using this method, we solve 70.2% of our
problems with 100 samples per problem. Careful investigation of our model
reveals its limitations, including difficulty with docstrings describing long
chains of operations and with binding operations to variables. Finally, we
discuss the potential broader impacts of deploying powerful code generation
technologies, covering safety, security, and economics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An empirical evaluation of active inference in multi-armed bandits. (arXiv:2101.08699v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Markovic_D/0/1/0/all/0/1">Dimitrije Markovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Stojic_H/0/1/0/all/0/1">Hrvoje Stojic</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwoebel_S/0/1/0/all/0/1">Sarah Schwoebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiebel_S/0/1/0/all/0/1">Stefan J. Kiebel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08699">
                                    <div class="article-summary-box-inner">
                                        <span>A key feature of sequential decision making under uncertainty is a need to
balance between exploiting--choosing the best action according to the current
knowledge, and exploring--obtaining information about values of other actions.
The multi-armed bandit problem, a classical task that captures this trade-off,
served as a vehicle in machine learning for developing bandit algorithms that
proved to be useful in numerous industrial applications. The active inference
framework, an approach to sequential decision making recently developed in
neuroscience for understanding human and animal behaviour, is distinguished by
its sophisticated strategy for resolving the exploration-exploitation
trade-off. This makes active inference an exciting alternative to already
established bandit algorithms. Here we derive an efficient and scalable
approximate active inference algorithm and compare it to two state-of-the-art
bandit algorithms: Bayesian upper confidence bound and optimistic Thompson
sampling. This comparison is done on two types of bandit problems: a stationary
and a dynamic switching bandit. Our empirical evaluation shows that the active
inference algorithm does not produce efficient long-term behaviour in
stationary bandits. However, in the more challenging switching bandit problem
active inference performs substantially better than the two state-of-the-art
bandit algorithms. The results open exciting venues for further research in
theoretical and applied machine learning, as well as lend additional
credibility to active inference as a general framework for studying human and
animal behaviour.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XPDNet for MRI Reconstruction: an application to the 2020 fastMRI challenge. (arXiv:2010.07290v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ramzi_Z/0/1/0/all/0/1">Zaccharie Ramzi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ciuciu_P/0/1/0/all/0/1">Philippe Ciuciu</a>, <a href="http://arxiv.org/find/eess/1/au:+Starck_J/0/1/0/all/0/1">Jean-Luc Starck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07290">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new neural network, the XPDNet, for MRI reconstruction from
periodically under-sampled multi-coil data. We inform the design of this
network by taking best practices from MRI reconstruction and computer vision.
We show that this network can achieve state-of-the-art reconstruction results,
as shown by its ranking of second in the fastMRI 2020 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hub and Spoke Logistics Network Design for Urban Region with Clustering-Based Approach. (arXiv:2107.03080v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duong_Q/0/1/0/all/0/1">Quan Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dang Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quoc Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03080">
                                    <div class="article-summary-box-inner">
                                        <span>This study aims to propose effective modeling and approach for designing a
logistics network in the urban area in order to offer an efficient flow
distribution network as a competitive strategy in the logistics industry where
demand is sensitive to both price and time. A multi-stage approach is
introduced to select the number of hubs and allocate spokes to the hubs for
flow distribution and hubs&#x27; location detection. Specifically, a fuzzy
clustering model with the objective function is to minimize the approximate
transportation cost is employed, in the next phase is to focus on balancing the
demand capacity among the hubs with the help of domain experts, afterward, the
facility location vehicle routing problems within the network is introduced. To
demonstrate the approach&#x27;s advantages, an experiment was performed on the
designed network and its actual transportation cost for the real operational
data in which specific to the Ho Chi Minh city infrastructure conditions.
Additionally, we show the flexibility of the designed network in the flow
distribution and its computational experiments to develop the managerial
insights which contribute to the network design decision-making process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection and Mitigation of Rare Subclasses in Deep Neural Network Classifiers. (arXiv:1911.12780v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paterson_C/0/1/0/all/0/1">Colin Paterson</a>, <a href="http://arxiv.org/find/cs/1/au:+Calinescu_R/0/1/0/all/0/1">Radu Calinescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Picardi_C/0/1/0/all/0/1">Chiara Picardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.12780">
                                    <div class="article-summary-box-inner">
                                        <span>Regions of high-dimensional input spaces that are underrepresented in
training datasets reduce machine-learnt classifier performance, and may lead to
corner cases and unwanted bias for classifiers used in decision making systems.
When these regions belong to otherwise well-represented classes, their presence
and negative impact are very hard to identify. We propose an approach for the
detection and mitigation of such rare subclasses in deep neural network
classifiers. The new approach is underpinned by an easy-to-compute commonality
metric that supports the detection of rare subclasses, and comprises methods
for reducing the impact of these subclasses during both model training and
model exploitation. We demonstrate our approach using two well-known datasets,
MNIST&#x27;s handwritten digits and Kaggle&#x27;s cats/dogs, identifying rare subclasses
and producing models which compensate for subclass rarity. In addition we
demonstrate how our run-time approach increases the ability of users to
identify samples likely to be misclassified at run-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coastal water quality prediction based on machine learning with feature interpretation and spatio-temporal analysis. (arXiv:2107.03230v1 [stat.AP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Grbcic_L/0/1/0/all/0/1">Luka Grb&#x10d;i&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Druzeta_S/0/1/0/all/0/1">Sini&#x161;a Dru&#x17e;eta</a>, <a href="http://arxiv.org/find/stat/1/au:+Mausa_G/0/1/0/all/0/1">Goran Mau&#x161;a</a>, <a href="http://arxiv.org/find/stat/1/au:+Lipic_T/0/1/0/all/0/1">Tomislav Lipi&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Lusic_D/0/1/0/all/0/1">Darija Vuki&#x107; Lu&#x161;i&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Alvir_M/0/1/0/all/0/1">Marta Alvir</a>, <a href="http://arxiv.org/find/stat/1/au:+Lucin_I/0/1/0/all/0/1">Ivana Lu&#x10d;in</a>, <a href="http://arxiv.org/find/stat/1/au:+Sikirica_A/0/1/0/all/0/1">Ante Sikirica</a>, <a href="http://arxiv.org/find/stat/1/au:+Davidovic_D/0/1/0/all/0/1">Davor Davidovi&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Travas_V/0/1/0/all/0/1">Vanja Trava&#x161;</a>, <a href="http://arxiv.org/find/stat/1/au:+Kalafatovic_D/0/1/0/all/0/1">Daniela Kalafatovi&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Pikelj_K/0/1/0/all/0/1">Kristina Pikelj</a>, <a href="http://arxiv.org/find/stat/1/au:+Fajkovic_H/0/1/0/all/0/1">Hana Fajkovi&#x107;</a>, <a href="http://arxiv.org/find/stat/1/au:+Kranjcevic_L/0/1/0/all/0/1">Lado Kranj&#x10d;evi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03230">
                                    <div class="article-summary-box-inner">
                                        <span>Coastal water quality management is a public health concern, as poor coastal
water quality can harbor pathogens that are dangerous to human health.
Tourism-oriented countries need to actively monitor the condition of coastal
water at tourist popular sites during the summer season. In this study, routine
monitoring data of $Escherichia\ Coli$ and enterococci across 15 public beaches
in the city of Rijeka, Croatia, were used to build machine learning models for
predicting their levels based on environmental parameters as well as to
investigate their relationships with environmental stressors. Gradient Boosting
(Catboost, Xgboost), Random Forests, Support Vector Regression and Artificial
Neural Networks were trained with measurements from all sampling sites and used
to predict $E.\ Coli$ and enterococci values based on environmental features.
The evaluation of stability and generalizability with 10-fold cross validation
analysis of the machine learning models, showed that the Catboost algorithm
performed best with R$^2$ values of 0.71 and 0.68 for predicting $E.\ Coli$ and
enterococci, respectively, compared to other evaluated ML algorithms including
Xgboost, Random Forests, Support Vector Regression and Artificial Neural
Networks. We also use the SHapley Additive exPlanations technique to identify
and interpret which features have the most predictive power. The results show
that site salinity measured is the most important feature for forecasting both
$E.\ Coli$ and enterococci levels. Finally, the spatial and temporal accuracy
of both ML models were examined at sites with the lowest coastal water quality.
The spatial $E. Coli$ and enterococci models achieved strong R$^2$ values of
0.85 and 0.83, while the temporal models achieved R$^2$ values of 0.74 and
0.67. The temporal model also achieved moderate R$^2$ values of 0.44 and 0.46
at a site with high coastal water quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Closed-Form Approximation to the Conjugate Prior of the Dirichlet and Beta Distributions. (arXiv:2107.03183v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Thommen_K/0/1/0/all/0/1">Kaspar Thommen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03183">
                                    <div class="article-summary-box-inner">
                                        <span>We derive the conjugate prior of the Dirichlet and beta distributions and
explore it with numerical examples to gain an intuitive understanding of the
distribution itself, its hyperparameters, and conditions concerning its
convergence. Due to the prior&#x27;s intractability, we proceed to define and
analyze a closed-form approximation. Finally, we provide an algorithm
implementing this approximation that enables fully tractable Bayesian conjugate
treatment of Dirichlet and beta likelihoods without the need for Monte Carlo
simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impulse data models for the inverse problem of electrocardiography. (arXiv:2102.00570v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Peng_T/0/1/0/all/0/1">Tommy Peng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Malik_A/0/1/0/all/0/1">Avinash Malik</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bear_L/0/1/0/all/0/1">Laura Bear</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Trew_M/0/1/0/all/0/1">Mark L. Trew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00570">
                                    <div class="article-summary-box-inner">
                                        <span>The proposed method re-frames traditional inverse problems of
electrocardiography into regression problems, constraining the solution space
by decomposing signals with multidimensional Gaussian impulse basis functions.
Impulse HSPs were generated with single Gaussian basis functions at discrete
heart surface locations and projected to corresponding BSPs using a volume
conductor torso model. Both BSP (inputs) and HSP (outputs) were mapped to
regular 2D surface meshes and used to train a neural network. Predictive
capabilities of the network were tested with unseen synthetic and experimental
data. A dense full connected single hidden layer neural network was trained to
map body surface impulses to heart surface Gaussian basis functions for
reconstructing HSP. Synthetic pulses moving across the heart surface were
predicted from the neural network with root mean squared error of $9.1\pm1.4$%.
Predicted signals were robust to noise up to 20 dB and errors due to
displacement and rotation of the heart within the torso were bounded and
predictable. A shift of the heart 40 mm toward the spine resulted in a 4\%
increase in signal feature localization error. The set of training impulse
function data could be reduced and prediction error remained bounded. Recorded
HSPs from in-vitro pig hearts were reliably decomposed using space-time
Gaussian basis functions. Predicted HSPs for left-ventricular pacing had a mean
absolute error of $10.4\pm11.4$ ms. Other pacing scenarios were analyzed with
similar success. Conclusion: Impulses from Gaussian basis functions are
potentially an effective and robust way to train simple neural network data
models for reconstructing HSPs from decomposed BSPs. The HSPs predicted by the
neural network can be used to generate activation maps that non-invasively
identify features of cardiac electrical dysfunction and can guide subsequent
treatment options.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing an Intelligent Digital Twin with a Self-organized Reconfiguration Management based on Adaptive Process Models. (arXiv:2107.03324v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1">Timo M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindemann_B/0/1/0/all/0/1">Benjamin Lindemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_T/0/1/0/all/0/1">Tobias Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Jazdi_N/0/1/0/all/0/1">Nasser Jazdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Weyrich_M/0/1/0/all/0/1">Michael Weyrich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03324">
                                    <div class="article-summary-box-inner">
                                        <span>Shorter product life cycles and increasing individualization of production
leads to an increased reconfiguration demand in the domain of industrial
automation systems, which will be dominated by cyber-physical production
systems in the future. In constantly changing systems, however, not all
configuration alternatives of the almost infinite state space are fully
understood. Thus, certain configurations can lead to process instability, a
reduction in quality or machine failures. Therefore, this paper presents an
approach that enhances an intelligent Digital Twin with a self-organized
reconfiguration management based on adaptive process models in order to find
optimized configurations more comprehensively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PHOTONAI -- A Python API for Rapid Machine Learning Model Development. (arXiv:2002.05426v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leenings_R/0/1/0/all/0/1">Ramona Leenings</a>, <a href="http://arxiv.org/find/cs/1/au:+Winter_N/0/1/0/all/0/1">Nils Ralf Winter</a>, <a href="http://arxiv.org/find/cs/1/au:+Plagwitz_L/0/1/0/all/0/1">Lucas Plagwitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Holstein_V/0/1/0/all/0/1">Vincent Holstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Ernsting_J/0/1/0/all/0/1">Jan Ernsting</a>, <a href="http://arxiv.org/find/cs/1/au:+Steenweg_J/0/1/0/all/0/1">Jakob Steenweg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gebker_J/0/1/0/all/0/1">Julian Gebker</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarink_K/0/1/0/all/0/1">Kelvin Sarink</a>, <a href="http://arxiv.org/find/cs/1/au:+Emden_D/0/1/0/all/0/1">Daniel Emden</a>, <a href="http://arxiv.org/find/cs/1/au:+Grotegerd_D/0/1/0/all/0/1">Dominik Grotegerd</a>, <a href="http://arxiv.org/find/cs/1/au:+Opel_N/0/1/0/all/0/1">Nils Opel</a>, <a href="http://arxiv.org/find/cs/1/au:+Risse_B/0/1/0/all/0/1">Benjamin Risse</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xiaoyi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dannlowski_U/0/1/0/all/0/1">Udo Dannlowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Hahn_T/0/1/0/all/0/1">Tim Hahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05426">
                                    <div class="article-summary-box-inner">
                                        <span>PHOTONAI is a high-level Python API designed to simplify and accelerate
machine learning model development. It functions as a unifying framework
allowing the user to easily access and combine algorithms from different
toolboxes into custom algorithm sequences. It is especially designed to support
the iterative model development process and automates the repetitive training,
hyperparameter optimization and evaluation tasks. Importantly, the workflow
ensures unbiased performance estimates while still allowing the user to fully
customize the machine learning analysis. PHOTONAI extends existing solutions
with a novel pipeline implementation supporting more complex data streams,
feature combinations, and algorithm selection. Metrics and results can be
conveniently visualized using the PHOTONAI Explorer and predictive models are
shareable in a standardized format for further external validation or
application. A growing add-on ecosystem allows researchers to offer data
modality specific algorithms to the community and enhance machine learning in
the areas of the life sciences. Its practical utility is demonstrated on an
exemplary medical machine learning problem, achieving a state-of-the-art
solution in few lines of code. Source code is publicly available on Github,
while examples and documentation can be found at www.photon-ai.com.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mitigating Performance Saturation in Neural Marked Point Processes: Architectures and Loss Functions. (arXiv:2107.03354v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianbo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_T/0/1/0/all/0/1">Tianze Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_Y/0/1/0/all/0/1">Yiping Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Sinno Jialin Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03354">
                                    <div class="article-summary-box-inner">
                                        <span>Attributed event sequences are commonly encountered in practice. A recent
research line focuses on incorporating neural networks with the statistical
model -- marked point processes, which is the conventional tool for dealing
with attributed event sequences. Neural marked point processes possess good
interpretability of probabilistic models as well as the representational power
of neural networks. However, we find that performance of neural marked point
processes is not always increasing as the network architecture becomes more
complicated and larger, which is what we call the performance saturation
phenomenon. This is due to the fact that the generalization error of neural
marked point processes is determined by both the network representational
ability and the model specification at the same time. Therefore we can draw two
major conclusions: first, simple network structures can perform no worse than
complicated ones for some cases; second, using a proper probabilistic
assumption is as equally, if not more, important as improving the complexity of
the network. Based on this observation, we propose a simple graph-based network
structure called GCHP, which utilizes only graph convolutional layers, thus it
can be easily accelerated by the parallel mechanism. We directly consider the
distribution of interarrival times instead of imposing a specific assumption on
the conditional intensity function, and propose to use a likelihood ratio loss
with a moment matching mechanism for optimization and model selection.
Experimental results show that GCHP can significantly reduce training time and
the likelihood ratio loss with interarrival time probability assumptions can
greatly improve the model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">L2P: An Algorithm for Estimating Heavy-tailed Outcomes. (arXiv:1908.04628v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xindi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Varol_O/0/1/0/all/0/1">Onur Varol</a>, <a href="http://arxiv.org/find/cs/1/au:+Eliassi_Rad_T/0/1/0/all/0/1">Tina Eliassi-Rad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.04628">
                                    <div class="article-summary-box-inner">
                                        <span>Many real-world prediction tasks have outcome variables that have
characteristic heavy-tail distributions. Examples include copies of books sold,
auction prices of art pieces, demand for commodities in warehouses, etc. By
learning heavy-tailed distributions, &quot;big and rare&quot; instances (e.g., the
best-sellers) will have accurate predictions. Most existing approaches are not
dedicated to learning heavy-tailed distribution; thus, they heavily
under-predict such instances. To tackle this problem, we introduce Learning to
Place (L2P), which exploits the pairwise relationships between instances for
learning. In its training phase, L2P learns a pairwise preference classifier:
is instance A &gt; instance B? In its placing phase, L2P obtains a prediction by
placing the new instance among the known instances. Based on its placement, the
new instance is then assigned a value for its outcome variable. Experiments on
real data show that L2P outperforms competing approaches in terms of accuracy
and ability to reproduce heavy-tailed outcome distribution. In addition, L2P
provides an interpretable model by placing each predicted instance in relation
to its comparable neighbors. Interpretable models are highly desirable when
lives and treasure are at stake.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Last-iterate Convergence of Decentralized Optimistic Gradient Descent/Ascent in Infinite-horizon Competitive Markov Games. (arXiv:2102.04540v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Chen-Yu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chung-Wei Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mengxiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Haipeng Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04540">
                                    <div class="article-summary-box-inner">
                                        <span>We study infinite-horizon discounted two-player zero-sum Markov games, and
develop a decentralized algorithm that provably converges to the set of Nash
equilibria under self-play. Our algorithm is based on running an Optimistic
Gradient Descent Ascent algorithm on each state to learn the policies, with a
critic that slowly learns the value of each state. To the best of our
knowledge, this is the first algorithm in this setting that is simultaneously
rational (converging to the opponent&#x27;s best response when it uses a stationary
policy), convergent (converging to the set of Nash equilibria under self-play),
agnostic (no need to know the actions played by the opponent), symmetric
(players taking symmetric roles in the algorithm), and enjoying a finite-time
last-iterate convergence guarantee, all of which are desirable properties of
decentralized algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A case for new neural network smoothness constraints. (arXiv:2012.07969v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1">Mihaela Rosca</a>, <a href="http://arxiv.org/find/stat/1/au:+Weber_T/0/1/0/all/0/1">Theophane Weber</a>, <a href="http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a>, <a href="http://arxiv.org/find/stat/1/au:+Mohamed_S/0/1/0/all/0/1">Shakir Mohamed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07969">
                                    <div class="article-summary-box-inner">
                                        <span>How sensitive should machine learning models be to input changes? We tackle
the question of model smoothness and show that it is a useful inductive bias
which aids generalization, adversarial robustness, generative modeling and
reinforcement learning. We explore current methods of imposing smoothness
constraints and observe they lack the flexibility to adapt to new tasks, they
don&#x27;t account for data modalities, they interact with losses, architectures and
optimization in ways not yet fully understood. We conclude that new advances in
the field are hinging on finding ways to incorporate data, tasks and learning
into our definitions of smoothness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning 1-Dimensional Submanifolds for Subsequent Inference on Random Dot Product Graphs. (arXiv:2004.07348v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Trosset_M/0/1/0/all/0/1">Michael W. Trosset</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_M/0/1/0/all/0/1">Mingyue Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Tang_M/0/1/0/all/0/1">Minh Tang</a>, <a href="http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1">Carey E. Priebe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.07348">
                                    <div class="article-summary-box-inner">
                                        <span>A random dot product graph (RDPG) is a generative model for networks in which
vertices correspond to positions in a latent Euclidean space and edge
probabilities are determined by the dot products of the latent positions. We
consider RDPGs for which the latent positions are randomly sampled from an
unknown $1$-dimensional submanifold of the latent space. In principle,
restricted inference, i.e., procedures that exploit the structure of the
submanifold, should be more effective than unrestricted inference; however, it
is not clear how to conduct restricted inference when the submanifold is
unknown. We submit that techniques for manifold learning can be used to learn
the unknown submanifold well enough to realize benefit from restricted
inference. To illustrate, we test $1$- and $2$-sample hypotheses about the
Fr\&#x27;{e}chet means of small communities of vertices, using the complete set of
vertices to infer latent structure. We propose test statistics that deploy the
Isomap procedure for manifold learning, using shortest path distances on
neighborhood graphs constructed from estimated latent positions to estimate arc
lengths on the unknown $1$-dimensional submanifold. Unlike conventional
applications of Isomap, the estimated latent positions do not lie on the
submanifold of interest. We extend existing convergence results for Isomap to
this setting and use them to demonstrate that, as the number of auxiliary
vertices increases, the power of our test converges to the power of the
corresponding test when the submanifold is known.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RAM-VO: Less is more in Visual Odometry. (arXiv:2107.02974v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cleveston_I/0/1/0/all/0/1">Iury Cleveston</a>, <a href="http://arxiv.org/find/cs/1/au:+Colombini_E/0/1/0/all/0/1">Esther L. Colombini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02974">
                                    <div class="article-summary-box-inner">
                                        <span>Building vehicles capable of operating without human supervision requires the
determination of the agent&#x27;s pose. Visual Odometry (VO) algorithms estimate the
egomotion using only visual changes from the input images. The most recent VO
methods implement deep-learning techniques using convolutional neural networks
(CNN) extensively, which add a substantial cost when dealing with
high-resolution images. Furthermore, in VO tasks, more input data does not mean
a better prediction; on the contrary, the architecture may filter out useless
information. Therefore, the implementation of computationally efficient and
lightweight architectures is essential. In this work, we propose the RAM-VO, an
extension of the Recurrent Attention Model (RAM) for visual odometry tasks.
RAM-VO improves the visual and temporal representation of information and
implements the Proximal Policy Optimization (PPO) algorithm to learn robust
policies. The results indicate that RAM-VO can perform regressions with six
degrees of freedom from monocular input images using approximately 3 million
parameters. In addition, experiments on the KITTI dataset demonstrate that
RAM-VO achieves competitive results using only 5.7% of the available visual
information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Keiki: Towards Realistic Danmaku Generation via Sequential GANs. (arXiv:2107.02991v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Ziqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yannakakis_G/0/1/0/all/0/1">Georgios N. Yannakakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02991">
                                    <div class="article-summary-box-inner">
                                        <span>Search-based procedural content generation methods have recently been
introduced for the autonomous creation of bullet hell games. Search-based
methods, however, can hardly model patterns of danmakus -- the bullet hell
shooting entity -- explicitly and the resulting levels often look
non-realistic. In this paper, we present a novel bullet hell game platform
named Keiki, which allows the representation of danmakus as a parametric
sequence which, in turn, can model the sequential behaviours of danmakus. We
employ three types of generative adversarial networks (GANs) and test Keiki
across three metrics designed to quantify the quality of the generated
danmakus. The time-series GAN and periodic spatial GAN show different yet
competitive performance in terms of the evaluation metrics adopted, their
deviation from human-designed danmakus, and the diversity of generated
danmakus. The preliminary experimental studies presented here showcase that
potential of time-series GANs for sequential content generation in games.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Are you sure?&quot;: Preliminary Insights from Scaling Product Comparisons to Multiple Shops. (arXiv:2107.03256v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chia_P/0/1/0/all/0/1">Patrick John Chia</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bingqing Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tagliabue_J/0/1/0/all/0/1">Jacopo Tagliabue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03256">
                                    <div class="article-summary-box-inner">
                                        <span>Large eCommerce players introduced comparison tables as a new type of
recommendations. However, building comparisons at scale without pre-existing
training/taxonomy data remains an open challenge, especially within the
operational constraints of shops in the long tail. We present preliminary
results from building a comparison pipeline designed to scale in a multi-shop
scenario: we describe our design choices and run extensive benchmarks on
multiple shops to stress-test it. Finally, we run a small user study on
property selection and conclude by discussing potential improvements and
highlighting the questions that remain to be addressed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diametrical Risk Minimization: Theory and Computations. (arXiv:1910.10844v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Norton_M/0/1/0/all/0/1">Matthew Norton</a>, <a href="http://arxiv.org/find/math/1/au:+Royset_J/0/1/0/all/0/1">Johannes O. Royset</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.10844">
                                    <div class="article-summary-box-inner">
                                        <span>The theoretical and empirical performance of Empirical Risk Minimization
(ERM) often suffers when loss functions are poorly behaved with large Lipschitz
moduli and spurious sharp minimizers. We propose and analyze a counterpart to
ERM called Diametrical Risk Minimization (DRM), which accounts for worst-case
empirical risks within neighborhoods in parameter space. DRM has generalization
bounds that are independent of Lipschitz moduli for convex as well as nonconvex
problems and it can be implemented using a practical algorithm based on
stochastic gradient descent. Numerical results illustrate the ability of DRM to
find quality solutions with low generalization error in sharp empirical risk
landscapes from benchmark neural network classification problems with corrupted
labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting with Confidence on Unseen Distributions. (arXiv:2107.03315v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guillory_D/0/1/0/all/0/1">Devin Guillory</a>, <a href="http://arxiv.org/find/cs/1/au:+Shankar_V/0/1/0/all/0/1">Vaishaal Shankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ebrahimi_S/0/1/0/all/0/1">Sayna Ebrahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1">Trevor Darrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1">Ludwig Schmidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03315">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that the performance of machine learning models can
vary substantially when models are evaluated on data drawn from a distribution
that is close to but different from the training distribution. As a result,
predicting model performance on unseen distributions is an important challenge.
Our work connects techniques from domain adaptation and predictive uncertainty
literature, and allows us to predict model accuracy on challenging unseen
distributions without access to labeled data. In the context of distribution
shift, distributional distances are often used to adapt models and improve
their performance on new domains, however accuracy estimation, or other forms
of predictive uncertainty, are often neglected in these investigations. Through
investigating a wide range of established distributional distances, such as
Frechet distance or Maximum Mean Discrepancy, we determine that they fail to
induce reliable estimates of performance under distribution shift. On the other
hand, we find that the difference of confidences (DoC) of a classifier&#x27;s
predictions successfully estimates the classifier&#x27;s performance change over a
variety of shifts. We specifically investigate the distinction between
synthetic and natural distribution shifts and observe that despite its
simplicity DoC consistently outperforms other quantifications of distributional
difference. $DoC$ reduces predictive error by almost half ($46\%$) on several
realistic and challenging distribution shifts, e.g., on the ImageNet-Vid-Robust
and ImageNet-Rendition datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Extrapolation for Attribute-Enhanced Generation. (arXiv:2107.02968v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1">Alvin Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Madani_A/0/1/0/all/0/1">Ali Madani</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_B/0/1/0/all/0/1">Ben Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Naik_N/0/1/0/all/0/1">Nikhil Naik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02968">
                                    <div class="article-summary-box-inner">
                                        <span>Attribute extrapolation in sample generation is challenging for deep neural
networks operating beyond the training distribution. We formulate a new task
for extrapolation in sequence generation, focusing on natural language and
proteins, and propose GENhance, a generative framework that enhances attributes
through a learned latent space. Trained on movie reviews and a computed protein
stability dataset, GENhance can generate strongly-positive text reviews and
highly stable protein sequences without being exposed to similar data during
training. We release our benchmark tasks and models to contribute to the study
of generative modeling extrapolation and data-driven design in biology and
chemistry.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SelfCF: A Simple Framework for Self-supervised Collaborative Filtering. (arXiv:2107.03019v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_A/0/1/0/all/0/1">Aixin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03019">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering (CF) is widely used to learn an informative latent
representation of a user or item from observed interactions. Existing CF-based
methods commonly adopt negative sampling to discriminate different items. That
is, observed user-item pairs are treated as positive instances; unobserved
pairs are considered as negative instances and are sampled under a defined
distribution for training. Training with negative sampling on large datasets is
computationally expensive. Further, negative items should be carefully sampled
under the defined distribution, in order to avoid selecting an observed
positive item in the training dataset. Unavoidably, some negative items sampled
from the training dataset could be positive in the test set. Recently,
self-supervised learning (SSL) has emerged as a powerful tool to learn a model
without negative samples. In this paper, we propose a self-supervised
collaborative filtering framework (SelfCF), that is specially designed for
recommender scenario with implicit feedback. The main idea of SelfCF is to
augment the output embeddings generated by backbone networks, because it is
infeasible to augment raw input of user/item ids. We propose and study three
output perturbation techniques that can be applied to different types of
backbone networks including both traditional CF models and graph-based models.
By encapsulating two popular recommendation models into the framework, our
experiments on three datasets show that the best performance of our framework
is comparable or better than the supervised counterpart. We also show that
SelfCF can boost up the performance by up to 8.93\% on average, compared with
another self-supervised framework as the baseline. Source codes are available
at: https://github.com/enoche/SelfCF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Modified Drake Equation for Assessing Adversarial Risk to Machine Learning Models. (arXiv:2103.02718v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalin_J/0/1/0/all/0/1">Josh Kalin</a>, <a href="http://arxiv.org/find/cs/1/au:+Noever_D/0/1/0/all/0/1">David Noever</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciolino_M/0/1/0/all/0/1">Matthew Ciolino</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02718">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models present a risk of adversarial attack when deployed in
production. Quantifying the contributing factors and uncertainties using
empirical measures could assist the industry with assessing the risk of
downloading and deploying common model types. This work proposes modifying the
traditional Drake Equation&#x27;s formalism to estimate the number of potentially
successful adversarial attacks on a deployed model. The Drake Equation is
famously used for parameterizing uncertainties and it has been used in many
research fields outside of its original intentions to estimate the number of
radio-capable extra-terrestrial civilizations. While previous work has outlined
methods for discovering vulnerabilities in public model architectures, the
proposed equation seeks to provide a semi-quantitative benchmark for evaluating
and estimating the potential risk factors for adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Bayesian Specification Inference from Demonstrations. (arXiv:2107.02912v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1">Ankit Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1">Pritish Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Craven_P/0/1/0/all/0/1">Patrick Craven</a>, <a href="http://arxiv.org/find/cs/1/au:+Landers_K/0/1/0/all/0/1">Kevin Landers</a>, <a href="http://arxiv.org/find/cs/1/au:+Oden_K/0/1/0/all/0/1">Kevin Oden</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_J/0/1/0/all/0/1">Julie Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02912">
                                    <div class="article-summary-box-inner">
                                        <span>When observing task demonstrations, human apprentices are able to identify
whether a given task is executed correctly long before they gain expertise in
actually performing that task. Prior research into learning from demonstrations
(LfD) has failed to capture this notion of the acceptability of a task&#x27;s
execution; meanwhile, temporal logics provide a flexible language for
expressing task specifications. Inspired by this, we present Bayesian
specification inference, a probabilistic model for inferring task specification
as a temporal logic formula. We incorporate methods from probabilistic
programming to define our priors, along with a domain-independent likelihood
function to enable sampling-based inference. We demonstrate the efficacy of our
model for inferring specifications, with over 90% similarity observed between
the inferred specification and the ground truth, both within a synthetic domain
and during a real-world table setting task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving the scalarization issues of Advantage-based Reinforcement Learning Algorithms. (arXiv:2004.04120v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Galatolo_F/0/1/0/all/0/1">Federico A. Galatolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cimino_M/0/1/0/all/0/1">Mario G.C.A. Cimino</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaglini_G/0/1/0/all/0/1">Gigliola Vaglini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.04120">
                                    <div class="article-summary-box-inner">
                                        <span>In this research, some of the issues that arise from the scalarization of the
multi-objective optimization problem in the Advantage Actor Critic (A2C)
reinforcement learning algorithm are investigated. The paper shows how a naive
scalarization can lead to gradients overlapping. Furthermore, the possibility
that the entropy regularization term can be a source of uncontrolled noise is
discussed. With respect to the above issues, a technique to avoid gradient
overlapping is proposed, while keeping the same loss formulation. Moreover, a
method to avoid the uncontrolled noise, by sampling the actions from
distributions with a desired minimum entropy, is investigated. Pilot
experiments have been carried out to show how the proposed method speeds up the
training. The proposed approach can be applied to any Advantage-based
Reinforcement Learning algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Matrix-Free Approximations of Second-Order Information, with Applications to Pruning and Optimization. (arXiv:2107.03356v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Frantar_E/0/1/0/all/0/1">Elias Frantar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurtic_E/0/1/0/all/0/1">Eldar Kurtic</a>, <a href="http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1">Dan Alistarh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03356">
                                    <div class="article-summary-box-inner">
                                        <span>Efficiently approximating local curvature information of the loss function is
a key tool for optimization and compression of deep neural networks. Yet, most
existing methods to approximate second-order information have high
computational or storage costs, which can limit their practicality. In this
work, we investigate matrix-free, linear-time approaches for estimating
Inverse-Hessian Vector Products (IHVPs) for the case when the Hessian can be
approximated as a sum of rank-one matrices, as in the classic approximation of
the Hessian by the empirical Fisher matrix. We propose two new algorithms as
part of a framework called M-FAC: the first algorithm is tailored towards
network compression and can compute the IHVP for dimension $d$, if the Hessian
is given as a sum of $m$ rank-one matrices, using $O(dm^2)$ precomputation,
$O(dm)$ cost for computing the IHVP, and query cost $O(m)$ for any single
element of the inverse Hessian. The second algorithm targets an optimization
setting, where we wish to compute the product between the inverse Hessian,
estimated over a sliding window of optimization steps, and a given gradient
direction, as required for preconditioned SGD. We give an algorithm with cost
$O(dm + m^2)$ for computing the IHVP and $O(dm + m^3)$ for adding or removing
any gradient from the sliding window. These two algorithms yield
state-of-the-art results for network pruning and optimization with lower
computational overhead relative to existing second-order methods.
Implementations are available at [10] and [18].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discriminative Mutual Information Estimators for Channel Capacity Learning. (arXiv:2107.03084v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Letizia_N/0/1/0/all/0/1">Nunzio A. Letizia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonello_A/0/1/0/all/0/1">Andrea M. Tonello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03084">
                                    <div class="article-summary-box-inner">
                                        <span>Channel capacity plays a crucial role in the development of modern
communication systems as it represents the maximum rate at which information
can be reliably transmitted over a communication channel. Nevertheless, for the
majority of channels, finding a closed-form capacity expression remains an open
challenge. This is because it requires to carry out two formidable tasks a) the
computation of the mutual information between the channel input and output, and
b) its maximization with respect to the signal distribution at the channel
input. In this paper, we address both tasks. Inspired by implicit generative
models, we propose a novel cooperative framework to automatically learn the
channel capacity, for any type of memory-less channel. In particular, we
firstly develop a new methodology to estimate the mutual information directly
from a discriminator typically deployed to train adversarial networks, referred
to as discriminative mutual information estimator (DIME). Secondly, we include
the discriminator in a cooperative channel capacity learning framework,
referred to as CORTICAL, where a discriminator learns to distinguish between
dependent and independent channel input-output samples while a generator learns
to produce the optimal channel input distribution for which the discriminator
exhibits the best performance. Lastly, we prove that a particular choice of the
cooperative value function solves the channel capacity estimation problem.
Simulation results demonstrate that the proposed method offers high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-VAE: Learning Disentangled View-common and View-peculiar Visual Representations for Multi-view Clustering. (arXiv:2106.11232v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yazhou Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Huayi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_X/0/1/0/all/0/1">Xiaorong Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaofeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Ming Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lifang He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11232">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-view clustering, a long-standing and important research problem,
focuses on mining complementary information from diverse views. However,
existing works often fuse multiple views&#x27; representations or handle clustering
in a common feature space, which may result in their entanglement especially
for visual representations. To address this issue, we present a novel VAE-based
multi-view clustering framework (Multi-VAE) by learning disentangled visual
representations. Concretely, we define a view-common variable and multiple
view-peculiar variables in the generative model. The prior of view-common
variable obeys approximately discrete Gumbel Softmax distribution, which is
introduced to extract the common cluster factor of multiple views. Meanwhile,
the prior of view-peculiar variable follows continuous Gaussian distribution,
which is used to represent each view&#x27;s peculiar visual factors. By controlling
the mutual information capacity to disentangle the view-common and
view-peculiar representations, continuous visual information of multiple views
can be separated so that their common discrete cluster information can be
effectively mined. Experimental results demonstrate that Multi-VAE enjoys the
disentangled and explainable visual representations, while obtaining superior
clustering performance compared with state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly detection and automatic labeling for solar cell quality inspection based on Generative Adversarial Network. (arXiv:2103.03518v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balzategui_J/0/1/0/all/0/1">Julen Balzategui</a>, <a href="http://arxiv.org/find/cs/1/au:+Eciolaza_L/0/1/0/all/0/1">Luka Eciolaza</a>, <a href="http://arxiv.org/find/cs/1/au:+Maestro_Watson_D/0/1/0/all/0/1">Daniel Maestro-Watson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03518">
                                    <div class="article-summary-box-inner">
                                        <span>Quality inspection applications in industry are required to move towards a
zero-defect manufacturing scenario, withnon-destructive inspection and
traceability of 100 % of produced parts. Developing robust fault detection and
classification modelsfrom the start-up of the lines is challenging due to the
difficulty in getting enough representative samples of the faulty patternsand
the need to manually label them. This work presents a methodology to develop a
robust inspection system, targeting thesepeculiarities, in the context of solar
cell manufacturing. The methodology is divided into two phases: In the first
phase, an anomalydetection model based on a Generative Adversarial Network
(GAN) is employed. This model enables the detection and localizationof
anomalous patterns within the solar cells from the beginning, using only
non-defective samples for training and without anymanual labeling involved. In
a second stage, as defective samples arise, the detected anomalies will be used
as automaticallygenerated annotations for the supervised training of a Fully
Convolutional Network that is capable of detecting multiple types offaults. The
experimental results using 1873 EL images of monocrystalline cells show that
(a) the anomaly detection scheme can beused to start detecting features with
very little available data, (b) the anomaly detection may serve as automatic
labeling in order totrain a supervised model, and (c) segmentation and
classification results of supervised models trained with automatic labels
arecomparable to the ones obtained from the models trained with manual labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Auxiliary Diagnosing Coronary Stenosis Using Machine Learning. (arXiv:2007.10316v3 [q-bio.TO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_W/0/1/0/all/0/1">Weijun Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+LU_F/0/1/0/all/0/1">Fengyuan LU</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_X/0/1/0/all/0/1">Xiaoyu Yang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+LI_E/0/1/0/all/0/1">En LI</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.10316">
                                    <div class="article-summary-box-inner">
                                        <span>How to accurately classify and diagnose whether an individual has Coronary
Stenosis (CS) without invasive physical examination? This problem has not been
solved satisfactorily. To this end, the four machine learning (ML) algorithms,
i.e., Boosted Tree (BT), Decision Tree (DT), Logistic Regression (LR) and
Random Forest (RF) are employed in this paper. First, eleven features including
basic information of an individual, symptoms and results of routine physical
examination are selected, as well as one label is specified, indicating whether
an individual suffers from different severity of coronary artery stenosis or
not. On the basis of it, a sample set is constructed. Second, each of these
four ML algorithms learns from the sample set to obtain the corresponding
optimal classified results, respectively. The experimental results show that:
RF performs better than other three algorithms, and the former algorithm
classifies whether an individual has CS with an accuracy of 95.7% (&#x3D;90/94).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Atmospheric Data and Identifying Dynamics: Temporal Data-Driven Modeling of Air Pollutants. (arXiv:2010.06538v2 [stat.AP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rubio_Herrero_J/0/1/0/all/0/1">Javier Rubio-Herrero</a>, <a href="http://arxiv.org/find/stat/1/au:+Marrero_C/0/1/0/all/0/1">Carlos Ortiz Marrero</a>, <a href="http://arxiv.org/find/stat/1/au:+Fan_W/0/1/0/all/0/1">Wai-Tong Louis Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06538">
                                    <div class="article-summary-box-inner">
                                        <span>Atmospheric modeling has recently experienced a surge with the advent of deep
learning. Most of these models, however, predict concentrations of pollutants
following a data-driven approach in which the physical laws that govern their
behaviors and relationships remain hidden. With the aid of real-world air
quality data collected hourly in different stations throughout Madrid, we
present an empirical approach using data-driven techniques with the following
goals: (1) Find parsimonious systems of ordinary differential equations via
sparse identification of nonlinear dynamics (SINDy) that model the
concentration of pollutants and their changes over time; (2) assess the
performance and limitations of our models using stability analysis; (3)
reconstruct the time series of chemical pollutants not measured in certain
stations using delay coordinate embedding results. Our results show that
Akaike&#x27;s Information Criterion can work well in conjunction with best subset
regression as to find an equilibrium between sparsity and goodness of fit. We
also find that, due to the complexity of the chemical system under study,
identifying the dynamics of this system over longer periods of time require
higher levels of data filtering and smoothing. Stability analysis for the
reconstructed ordinary differential equations (ODEs) reveals that more than
half of the physically relevant critical points are saddle points, suggesting
that the system is unstable even under the idealized assumption that all
environmental conditions are constant over time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Architecture Pruning for Transfer Learning. (arXiv:2107.03375v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Colombo_N/0/1/0/all/0/1">Nicolo Colombo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03375">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new gradient-based approach for extracting sub-architectures
from a given large model. Contrarily to existing pruning methods, which are
unable to disentangle the network architecture and the corresponding weights,
our architecture-pruning scheme produces transferable new structures that can
be successfully retrained to solve different tasks. We focus on a
transfer-learning setup where architectures can be trained on a large data set
but very few data points are available for fine-tuning them on new tasks. We
define a new gradient-based algorithm that trains architectures of arbitrarily
low complexity independently from the attached weights. Given a search space
defined by an existing large neural model, we reformulate the architecture
search task as a complexity-penalized subset-selection problem and solve it
through a two-temperature relaxation scheme. We provide theoretical convergence
guarantees and validate the proposed transfer-learning strategy on real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation of Representation Models for Text Classification with AutoML Tools. (arXiv:2106.12798v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brandle_S/0/1/0/all/0/1">Sebastian Br&#xe4;ndle</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanussek_M/0/1/0/all/0/1">Marc Hanussek</a>, <a href="http://arxiv.org/find/cs/1/au:+Blohm_M/0/1/0/all/0/1">Matthias Blohm</a>, <a href="http://arxiv.org/find/cs/1/au:+Kintz_M/0/1/0/all/0/1">Maximilien Kintz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12798">
                                    <div class="article-summary-box-inner">
                                        <span>Automated Machine Learning (AutoML) has gained increasing success on tabular
data in recent years. However, processing unstructured data like text is a
challenge and not widely supported by open-source AutoML tools. This work
compares three manually created text representations and text embeddings
automatically created by AutoML tools. Our benchmark includes four popular
open-source AutoML tools and eight datasets for text classification purposes.
The results show that straightforward text representations perform better than
AutoML tools with automatically created text embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An algorithmic view of $\ell_2$ regularization and some path-following algorithms. (arXiv:2107.03322v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1">Yunzhang Zhu</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_R/0/1/0/all/0/1">Renxiong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03322">
                                    <div class="article-summary-box-inner">
                                        <span>We establish an equivalence between the $\ell_2$-regularized solution path
for a convex loss function, and the solution of an ordinary differentiable
equation (ODE). Importantly, this equivalence reveals that the solution path
can be viewed as the flow of a hybrid of gradient descent and Newton method
applying to the empirical loss, which is similar to a widely used optimization
technique called trust region method. This provides an interesting algorithmic
view of $\ell_2$ regularization, and is in contrast to the conventional view
that the $\ell_2$ regularization solution path is similar to the gradient flow
of the empirical loss.New path-following algorithms based on homotopy methods
and numerical ODE solvers are proposed to numerically approximate the solution
path. In particular, we consider respectively Newton method and gradient
descent method as the basis algorithm for the homotopy method, and establish
their approximation error rates over the solution path. Importantly, our theory
suggests novel schemes to choose grid points that guarantee an arbitrarily
small suboptimality for the solution path. In terms of computational cost, we
prove that in order to achieve an $\epsilon$-suboptimality for the entire
solution path, the number of Newton steps required for the Newton method is
$\mathcal O(\epsilon^{-1/2})$, while the number of gradient steps required for
the gradient descent method is $\mathcal O\left(\epsilon^{-1}
\ln(\epsilon^{-1})\right)$. Finally, we use $\ell_2$-regularized logistic
regression as an illustrating example to demonstrate the effectiveness of the
proposed path-following algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RISAN: Robust Instance Specific Abstention Network. (arXiv:2107.03090v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalra_B/0/1/0/all/0/1">Bhavya Kalra</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_K/0/1/0/all/0/1">Kulin Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Manwani_N/0/1/0/all/0/1">Naresh Manwani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03090">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose deep architectures for learning instance specific
abstain (reject option) binary classifiers. The proposed approach uses double
sigmoid loss function as described by Kulin Shah and Naresh Manwani in (&quot;Online
Active Learning of Reject Option Classifiers&quot;, AAAI, 2020), as a performance
measure. We show that the double sigmoid loss is classification calibrated. We
also show that the excess risk of 0-d-1 loss is upper bounded by the excess
risk of double sigmoid loss. We derive the generalization error bounds for the
proposed architecture for reject option classifiers. To show the effectiveness
of the proposed approach, we experiment with several real world datasets. We
observe that the proposed approach not only performs comparable to the
state-of-the-art approaches, it is also robust against label noise. We also
provide visualizations to observe the important features learned by the network
corresponding to the abstaining decision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combined Global and Local Search for Optimization with Gaussian Process Models. (arXiv:2107.03217v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Meng_Q/0/1/0/all/0/1">Qun Meng</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1">Songhao Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Ng_S/0/1/0/all/0/1">Szu Hui Ng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03217">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian process (GP) model based optimization is widely applied in
simulation and machine learning. In general, it first estimates a GP model
based on a few observations from the true response and then employs this model
to guide the search, aiming to quickly locate the global optimum. Despite its
successful applications, it has several limitations that may hinder its broader
usage. First, building an accurate GP model can be difficult and
computationally expensive, especially when the response function is multi-modal
or varies significantly over the design space. Second, even with an appropriate
model, the search process can be trapped in suboptimal regions before moving to
the global optimum due to the excessive effort spent around the current best
solution. In this work, we adopt the Additive Global and Local GP (AGLGP) model
in the optimization framework. The model is rooted in the inducing-points-based
GP sparse approximations and is combined with independent local models in
different regions. With these properties, the AGLGP model is suitable for
multi-modal responses with relatively large data sizes. Based on this AGLGP
model, we propose a Combined Global and Local search for Optimization (CGLO)
algorithm. It first divides the whole design space into disjoint local regions
and identifies a promising region with the global model. Next, a local model in
the selected region is fit to guide detailed search within this region. The
algorithm then switches back to the global step when a good local solution is
found. The global and local natures of CGLO enable it to enjoy the benefits of
both global and local search to efficiently locate the global optimum.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Predict Error for MRI Reconstruction. (arXiv:2002.05582v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pezzotti_N/0/1/0/all/0/1">Nicola Pezzotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05582">
                                    <div class="article-summary-box-inner">
                                        <span>In healthcare applications, predictive uncertainty has been used to assess
predictive accuracy. In this paper, we demonstrate that predictive uncertainty
estimated by the current methods does not highly correlate with prediction
error by decomposing the latter into random and systematic errors, and showing
that the former is equivalent to the variance of the random error. In addition,
we observe that current methods unnecessarily compromise performance by
modifying the model and training loss to estimate the target and uncertainty
jointly. We show that estimating them separately without modifications improves
performance. Following this, we propose a novel method that estimates the
target labels and magnitude of the prediction error in two steps. We
demonstrate this method on a large-scale MRI reconstruction task, and achieve
significantly better results than the state-of-the-art uncertainty estimation
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ICDAR 2021 Competition on Components Segmentation Task of Document Photos. (arXiv:2106.08499v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Junior_C/0/1/0/all/0/1">Celso A. M. Lopes Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Junior_R/0/1/0/all/0/1">Ricardo B. das Neves Junior</a>, <a href="http://arxiv.org/find/cs/1/au:+Bezerra_B/0/1/0/all/0/1">Byron L. D. Bezerra</a>, <a href="http://arxiv.org/find/cs/1/au:+Toselli_A/0/1/0/all/0/1">Alejandro H. Toselli</a>, <a href="http://arxiv.org/find/cs/1/au:+Impedovo_D/0/1/0/all/0/1">Donato Impedovo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.08499">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the short-term competition on Components Segmentation
Task of Document Photos that was prepared in the context of the 16th
International Conference on Document Analysis and Recognition (ICDAR 2021).
This competition aims to bring together researchers working on the filed of
identification document image processing and provides them a suitable benchmark
to compare their techniques on the component segmentation task of document
images. Three challenge tasks were proposed entailing different segmentation
assignments to be performed on a provided dataset. The collected data are from
several types of Brazilian ID documents, whose personal information was
conveniently replaced. There were 16 participants whose results obtained for
some or all the three tasks show different rates for the adopted metrics, like
Dice Similarity Coefficient ranging from 0.06 to 0.99. Different Deep Learning
models were applied by the entrants with diverse strategies to achieve the best
results in each of the tasks. Obtained results show that the current applied
methods for solving one of the proposed tasks (document boundary detection) are
already well stablished. However, for the other two challenge tasks (text zone
and handwritten sign detection) research and development of more robust
approaches are still required to achieve acceptable results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Big Data Information and Nowcasting: Consumption and Investment from Bank Transactions in Turkey. (arXiv:2107.03299v1 [econ.EM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/econ/1/au:+Barlas_A/0/1/0/all/0/1">Ali B. Barlas</a> (BBVA Research), <a href="http://arxiv.org/find/econ/1/au:+Mert_S/0/1/0/all/0/1">Seda Guler Mert</a> (BBVA Research), <a href="http://arxiv.org/find/econ/1/au:+Isa_B/0/1/0/all/0/1">Berk Orkun Isa</a> (BBVA Research) <a href="http://arxiv.org/find/econ/1/au:+Ortiz_A/0/1/0/all/0/1">Alvaro Ortiz</a> (BBVA Research), <a href="http://arxiv.org/find/econ/1/au:+Rodrigo_T/0/1/0/all/0/1">Tomasa Rodrigo</a> (BBVA Research), <a href="http://arxiv.org/find/econ/1/au:+Soybilgen_B/0/1/0/all/0/1">Baris Soybilgen</a> (Bilgi University), <a href="http://arxiv.org/find/econ/1/au:+Yazgan_E/0/1/0/all/0/1">Ege Yazgan</a> (Bilgi University)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03299">
                                    <div class="article-summary-box-inner">
                                        <span>We use the aggregate information from individual-to-firm and firm-to-firm in
Garanti BBVA Bank transactions to mimic domestic private demand. Particularly,
we replicate the quarterly national accounts aggregate consumption and
investment (gross fixed capital formation) and its bigger components (Machinery
and Equipment and Construction) in real time for the case of Turkey. In order
to validate the usefulness of the information derived from these indicators we
test the nowcasting ability of both indicators to nowcast the Turkish GDP using
different nowcasting models. The results are successful and confirm the
usefulness of Consumption and Investment Banking transactions for nowcasting
purposes. The value of the Big data information is more relevant at the
beginning of the nowcasting process, when the traditional hard data information
is scarce. This makes this information specially relevant for those countries
where statistical release lags are longer like the Emerging Markets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate Multi-Agent Fitted Q Iteration. (arXiv:2104.09343v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lesage_Landry_A/0/1/0/all/0/1">Antoine Lesage-Landry</a>, <a href="http://arxiv.org/find/cs/1/au:+Callaway_D/0/1/0/all/0/1">Duncan S. Callaway</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09343">
                                    <div class="article-summary-box-inner">
                                        <span>We formulate an efficient approximation for multi-agent batch reinforcement
learning, the approximate multi-agent fitted Q iteration (AMAFQI). We present a
detailed derivation of our approach. We propose an iterative policy search and
show that it yields a greedy policy with respect to multiple approximations of
the centralized, standard Q-function. In each iteration and policy evaluation,
AMAFQI requires a number of computations that scales linearly with the number
of agents whereas the analogous number of computations increase exponentially
for the fitted Q iteration (FQI), one of the most commonly used approaches in
batch reinforcement learning. This property of AMAFQI is fundamental for the
design of a tractable multi-agent approach. We evaluate the performance of
AMAFQI and compare it to FQI in numerical simulations. Numerical examples
illustrate the significant computation time reduction when using AMAFQI instead
of FQI in multi-agent problems and corroborate the similar decision-making
performance of both approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Security of Deepfake Detection. (arXiv:2107.02045v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiaoyu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1">Neil Zhenqiang Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02045">
                                    <div class="article-summary-box-inner">
                                        <span>Deepfakes pose growing challenges to the trust of information on the
Internet. Thus, detecting deepfakes has attracted increasing attentions from
both academia and industry. State-of-the-art deepfake detection methods consist
of two key components, i.e., face extractor and face classifier, which extract
the face region in an image and classify it to be real/fake, respectively.
Existing studies mainly focused on improving the detection performance in
non-adversarial settings, leaving security of deepfake detection in adversarial
settings largely unexplored. In this work, we aim to bridge the gap. In
particular, we perform a systematic measurement study to understand the
security of the state-of-the-art deepfake detection methods in adversarial
settings. We use two large-scale public deepfakes data sources including
FaceForensics++ and Facebook Deepfake Detection Challenge, where the deepfakes
are fake face images; and we train state-of-the-art deepfake detection methods.
These detection methods can achieve 0.94--0.99 accuracies in non-adversarial
settings on these datasets. However, our measurement results uncover multiple
security limitations of the deepfake detection methods in adversarial settings.
First, we find that an attacker can evade a face extractor, i.e., the face
extractor fails to extract the correct face regions, via adding small Gaussian
noise to its deepfake images. Second, we find that a face classifier trained
using deepfakes generated by one method cannot detect deepfakes generated by
another method, i.e., an attacker can evade detection via generating deepfakes
using a new method. Third, we find that an attacker can leverage backdoor
attacks developed by the adversarial machine learning community to evade a face
classifier. Our results highlight that deepfake detection should consider the
adversarial nature of the problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Formal derivation of Mesh Neural Networks with their Forward-Only gradient Propagation. (arXiv:1905.06684v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Galatolo_F/0/1/0/all/0/1">Federico A. Galatolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cimino_M/0/1/0/all/0/1">Mario G.C.A. Cimino</a>, <a href="http://arxiv.org/find/cs/1/au:+Vaglini_G/0/1/0/all/0/1">Gigliola Vaglini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.06684">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes the Mesh Neural Network (MNN), a novel architecture which
allows neurons to be connected in any topology, to efficiently route
information. In MNNs, information is propagated between neurons throughout a
state transition function. State and error gradients are then directly computed
from state updates without backward computation. The MNN architecture and the
error propagation schema is formalized and derived in tensor algebra. The
proposed computational model can fully supply a gradient descent process, and
is potentially suitable for very large scale sparse NNs, due to its
expressivity and training efficiency, with respect to NNs based on
back-propagation and computational graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the performance of EEG decoding using anchored-STFT in conjunction with gradient norm adversarial augmentation. (arXiv:2011.14694v3 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Ali_O/0/1/0/all/0/1">Omair Ali</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Saif_ur_Rehman_M/0/1/0/all/0/1">Muhammad Saif-ur-Rehman</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Dyck_S/0/1/0/all/0/1">Susanne Dyck</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Glasmachers_T/0/1/0/all/0/1">Tobias Glasmachers</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Iossifidis_I/0/1/0/all/0/1">Ioannis Iossifidis</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Klaes_C/0/1/0/all/0/1">Christian Klaes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14694">
                                    <div class="article-summary-box-inner">
                                        <span>Brain-computer interfaces (BCIs) enable direct communication between humans
and machines by translating brain activity into control commands. EEG is one of
the most common sources of neural signals because of its inexpensive and
non-invasive nature. However, interpretation of EEG signals is non-trivial
because EEG signals have a low spatial resolution and are often distorted with
noise and artifacts. Therefore, it is possible that meaningful patterns for
classifying EEG signals are deeply hidden. Nowadays, state-of-the-art
deep-learning algorithms have proven to be quite efficient in learning hidden,
meaningful patterns. However, the performance of the deep learning algorithms
depends upon the quality and the amount of the provided training data. Hence, a
better input formation (feature extraction) technique and a generative model to
produce high-quality data can enable the deep learning algorithms to adapt high
generalization quality. In this study, we proposed a novel input formation
(feature extraction) method in conjunction with a novel deep learning based
generative model to harness new training examples. The feature vectors are
extracted using a modified Short Time Fourier Transform (STFT) called
anchored-STFT. Anchored-STFT, inspired by wavelet transform, tries to minimize
the tradeoff between time and frequency resolution. As a result, it extracts
the inputs (feature vectors) with better time and frequency resolution compared
to the standard STFT. Secondly, we introduced a novel generative adversarial
data augmentation technique called gradient norm adversarial augmentation
(GNAA) for generating more training data. Thirdly, we investigated the
existence and significance of adversarial inputs in EEG data. Our approach
obtained the kappa value of 0.814 for BCI competition II dataset III and 0.755
for BCI competition IV dataset 2b for session-to-session transfer on test data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transfer Learning in Information Criteria-based Feature Selection. (arXiv:2107.02847v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_S/0/1/0/all/0/1">Shaohan Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Sahinidis_N/0/1/0/all/0/1">Nikolaos V. Sahinidis</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_C/0/1/0/all/0/1">Chuanhou Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02847">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the effectiveness of transfer learning based on
Mallows&#x27; Cp. We propose a procedure that combines transfer learning with
Mallows&#x27; Cp (TLCp) and prove that it outperforms the conventional Mallows&#x27; Cp
criterion in terms of accuracy and stability. Our theoretical results indicate
that, for any sample size in the target domain, the proposed TLCp estimator
performs better than the Cp estimator by the mean squared error (MSE) metric in
the case of orthogonal predictors, provided that i) the dissimilarity between
the tasks from source domain and target domain is small, and ii) the procedure
parameters (complexity penalties) are tuned according to certain explicit
rules. Moreover, we show that our transfer learning framework can be extended
to other feature selection criteria, such as the Bayesian information
criterion. By analyzing the solution of the orthogonalized Cp, we identify an
estimator that asymptotically approximates the solution of the Cp criterion in
the case of non-orthogonal predictors. Similar results are obtained for the
non-orthogonal TLCp. Finally, simulation studies and applications with real
data demonstrate the usefulness of the TLCp scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solution of Physics-based Bayesian Inverse Problems with Deep Generative Priors. (arXiv:2107.02926v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Patel_D/0/1/0/all/0/1">Dhruv V Patel</a>, <a href="http://arxiv.org/find/stat/1/au:+Ray_D/0/1/0/all/0/1">Deep Ray</a>, <a href="http://arxiv.org/find/stat/1/au:+Oberai_A/0/1/0/all/0/1">Assad A Oberai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02926">
                                    <div class="article-summary-box-inner">
                                        <span>Inverse problems are notoriously difficult to solve because they can have no
solutions, multiple solutions, or have solutions that vary significantly in
response to small perturbations in measurements. Bayesian inference, which
poses an inverse problem as a stochastic inference problem, addresses these
difficulties and provides quantitative estimates of the inferred field and the
associated uncertainty. However, it is difficult to employ when inferring
vectors of large dimensions, and/or when prior information is available through
previously acquired samples. In this paper, we describe how deep generative
adversarial networks can be used to represent the prior distribution in
Bayesian inference and overcome these challenges. We apply these ideas to
inverse problems that are diverse in terms of the governing physical
principles, sources of prior knowledge, type of measurement, and the extent of
available information about measurement noise. In each case we apply the
proposed approach to infer the most likely solution and quantitative estimates
of uncertainty.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Harnessing Heterogeneity: Learning from Decomposed Feedback in Bayesian Modeling. (arXiv:2107.03003v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilder_B/0/1/0/all/0/1">Bryan Wilder</a>, <a href="http://arxiv.org/find/cs/1/au:+Suen_S/0/1/0/all/0/1">Sze-chuan Suen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1">Bistra Dilkina</a>, <a href="http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1">Milind Tambe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03003">
                                    <div class="article-summary-box-inner">
                                        <span>There is significant interest in learning and optimizing a complex system
composed of multiple sub-components, where these components may be agents or
autonomous sensors. Among the rich literature on this topic, agent-based and
domain-specific simulations can capture complex dynamics and subgroup
interaction, but optimizing over such simulations can be computationally and
algorithmically challenging. Bayesian approaches, such as Gaussian processes
(GPs), can be used to learn a computationally tractable approximation to the
underlying dynamics but typically neglect the detailed information about
subgroups in the complicated system. We attempt to find the best of both worlds
by proposing the idea of decomposed feedback, which captures group-based
heterogeneity and dynamics. We introduce a novel decomposed GP regression to
incorporate the subgroup decomposed feedback. Our modified regression has
provably lower variance -- and thus a more accurate posterior -- compared to
previous approaches; it also allows us to introduce a decomposed GP-UCB
optimization algorithm that leverages subgroup feedback. The Bayesian nature of
our method makes the optimization algorithm trackable with a theoretical
guarantee on convergence and no-regret property. To demonstrate the wide
applicability of this work, we execute our algorithm on two disparate social
problems: infectious disease control in a heterogeneous population and
allocation of distributed weather sensors. Experimental results show that our
new method provides significant improvement compared to the state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic partition of unity networks: clustering based deep approximation. (arXiv:2107.03066v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trask_N/0/1/0/all/0/1">Nat Trask</a>, <a href="http://arxiv.org/find/cs/1/au:+Gulian_M/0/1/0/all/0/1">Mamikon Gulian</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_A/0/1/0/all/0/1">Andy Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kookjin Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03066">
                                    <div class="article-summary-box-inner">
                                        <span>Partition of unity networks (POU-Nets) have been shown capable of realizing
algebraic convergence rates for regression and solution of PDEs, but require
empirical tuning of training parameters. We enrich POU-Nets with a Gaussian
noise model to obtain a probabilistic generalization amenable to gradient-based
minimization of a maximum likelihood loss. The resulting architecture provides
spatial representations of both noiseless and noisy data as Gaussian mixtures
with closed form expressions for variance which provides an estimator of local
error. The training process yields remarkably sharp partitions of input space
based upon correlation of function values. This classification of training
points is amenable to a hierarchical refinement strategy that significantly
improves the localization of the regression, allowing for higher-order
polynomial approximation to be utilized. The framework scales more favorably to
large data sets as compared to Gaussian process regression and allows for
spatially varying uncertainty, leveraging the expressive power of deep neural
networks while bypassing expensive training associated with other probabilistic
deep learning methods. Compared to standard deep neural networks, the framework
demonstrates hp-convergence without the use of regularizers to tune the
localization of partitions. We provide benchmarks quantifying performance in
high/low-dimensions, demonstrating that convergence rates depend only on the
latent dimension of data within high-dimensional space. Finally, we introduce a
new open-source data set of PDE-based simulations of a semiconductor device and
perform unsupervised extraction of a physically interpretable reduced-order
basis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Machine Learning for Cybersecurity and Computer Vision: Current Developments and Challenges. (arXiv:2107.02894v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xi_B/0/1/0/all/0/1">Bowei Xi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02894">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a comprehensive overview of adversarial machine learning focusing
on two application domains, i.e., cybersecurity and computer vision. Research
in adversarial machine learning addresses a significant threat to the wide
application of machine learning techniques -- they are vulnerable to carefully
crafted attacks from malicious adversaries. For example, deep neural networks
fail to correctly classify adversarial images, which are generated by adding
imperceptible perturbations to clean images.We first discuss three main
categories of attacks against machine learning techniques -- poisoning attacks,
evasion attacks, and privacy attacks. Then the corresponding defense approaches
are introduced along with the weakness and limitations of the existing defense
approaches. We notice adversarial samples in cybersecurity and computer vision
are fundamentally different. While adversarial samples in cybersecurity often
have different properties/distributions compared with training data,
adversarial images in computer vision are created with minor input
perturbations. This further complicates the development of robust learning
techniques, because a robust learning technique must withstand different types
of attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling up Continuous-Time Markov Chains Helps Resolve Underspecification. (arXiv:2107.02911v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gotovos_A/0/1/0/all/0/1">Alkis Gotovos</a>, <a href="http://arxiv.org/find/cs/1/au:+Burkholz_R/0/1/0/all/0/1">Rebekka Burkholz</a>, <a href="http://arxiv.org/find/cs/1/au:+Quackenbush_J/0/1/0/all/0/1">John Quackenbush</a>, <a href="http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1">Stefanie Jegelka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02911">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling the time evolution of discrete sets of items (e.g., genetic
mutations) is a fundamental problem in many biomedical applications. We
approach this problem through the lens of continuous-time Markov chains, and
show that the resulting learning task is generally underspecified in the usual
setting of cross-sectional data. We explore a perhaps surprising remedy:
including a number of additional independent items can help determine time
order, and hence resolve underspecification. This is in sharp contrast to the
common practice of limiting the analysis to a small subset of relevant items,
which is followed largely due to poor scaling of existing methods. To put our
theoretical insight into practice, we develop an approximate likelihood
maximization method for learning continuous-time Markov chains, which can scale
to hundreds of items and is orders of magnitude faster than previous methods.
We demonstrate the effectiveness of our approach on synthetic and real cancer
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trans4E: Link Prediction on Scholarly Knowledge Graphs. (arXiv:2107.03297v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nayyeri_M/0/1/0/all/0/1">Mojtaba Nayyeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Cil_G/0/1/0/all/0/1">Gokce Muge Cil</a>, <a href="http://arxiv.org/find/cs/1/au:+Vahdati_S/0/1/0/all/0/1">Sahar Vahdati</a>, <a href="http://arxiv.org/find/cs/1/au:+Osborne_F/0/1/0/all/0/1">Francesco Osborne</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mahfuzur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Angioni_S/0/1/0/all/0/1">Simone Angioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Salatino_A/0/1/0/all/0/1">Angelo Salatino</a>, <a href="http://arxiv.org/find/cs/1/au:+Recupero_D/0/1/0/all/0/1">Diego Reforgiato Recupero</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilyeva_N/0/1/0/all/0/1">Nadezhda Vassilyeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Motta_E/0/1/0/all/0/1">Enrico Motta</a>, <a href="http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1">Jens Lehmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03297">
                                    <div class="article-summary-box-inner">
                                        <span>The incompleteness of Knowledge Graphs (KGs) is a crucial issue affecting the
quality of AI-based services. In the scholarly domain, KGs describing research
publications typically lack important information, hindering our ability to
analyse and predict research dynamics. In recent years, link prediction
approaches based on Knowledge Graph Embedding models became the first aid for
this issue. In this work, we present Trans4E, a novel embedding model that is
particularly fit for KGs which include N to M relations with N$\gg$M. This is
typical for KGs that categorize a large number of entities (e.g., research
articles, patents, persons) according to a relatively small set of categories.
Trans4E was applied on two large-scale knowledge graphs, the Academia/Industry
DynAmics (AIDA) and Microsoft Academic Graph (MAG), for completing the
information about Fields of Study (e.g., &#x27;neural networks&#x27;, &#x27;machine learning&#x27;,
&#x27;artificial intelligence&#x27;), and affiliation types (e.g., &#x27;education&#x27;,
&#x27;company&#x27;, &#x27;government&#x27;), improving the scope and accuracy of the resulting
data. We evaluated our approach against alternative solutions on AIDA, MAG, and
four other benchmarks (FB15k, FB15k-237, WN18, and WN18RR). Trans4E outperforms
the other models when using low embedding dimensions and obtains competitive
results in high dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Urban Tree Species Classification Using Aerial Imagery. (arXiv:2107.03182v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Waters_E/0/1/0/all/0/1">Emily Waters</a>, <a href="http://arxiv.org/find/cs/1/au:+Oghaz_M/0/1/0/all/0/1">Mahdi Maktabdar Oghaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Saheer_L/0/1/0/all/0/1">Lakshmi Babu Saheer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03182">
                                    <div class="article-summary-box-inner">
                                        <span>Urban trees help regulate temperature, reduce energy consumption, improve
urban air quality, reduce wind speeds, and mitigating the urban heat island
effect. Urban trees also play a key role in climate change mitigation and
global warming by capturing and storing atmospheric carbon-dioxide which is the
largest contributor to greenhouse gases. Automated tree detection and species
classification using aerial imagery can be a powerful tool for sustainable
forest and urban tree management. Hence, This study first offers a pipeline for
generating labelled dataset of urban trees using Google Map&#x27;s aerial images and
then investigates how state of the art deep Convolutional Neural Network models
such as VGG and ResNet handle the classification problem of urban tree aerial
images under different parameters. Experimental results show our best model
achieves an average accuracy of 60% over 6 tree species.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cognitive Learning-Aided Multi-Antenna Communications. (arXiv:2010.03131v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Elbir_A/0/1/0/all/0/1">Ahmet M. Elbir</a>, <a href="http://arxiv.org/find/eess/1/au:+Mishra_K/0/1/0/all/0/1">Kumar Vijay Mishra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03131">
                                    <div class="article-summary-box-inner">
                                        <span>Cognitive communications have emerged as a promising solution to enhance,
adapt, and invent new tools and capabilities that transcend conventional
wireless networks. Deep learning (DL) is critical in enabling essential
features of cognitive systems because of its fast prediction performance,
adaptive behavior, and model-free structure. These features are especially
significant for multi-antenna wireless communications systems, which generate
and handle massive data. Multiple antennas may provide multiplexing, diversity,
or antenna gains that, respectively, improve the capacity, bit error rate, or
the signal-to-interference-plus-noise ratio. In practice, multi-antenna
cognitive communications encounter challenges in terms of data complexity and
diversity, hardware complexity, and wireless channel dynamics. The DL-based
solutions tackle these problems at the various stages of communications
processing such as channel estimation, hybrid beamforming, user localization,
and sparse array design. There are research opportunities to address
significant design challenges arising from insufficient data coverage, learning
model complexity, and data transmission overheads. This article provides
synopses of various DL-based methods to impart cognitive behavior to
multi-antenna wireless communications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ADAPT : Awesome Domain Adaptation Python Toolbox. (arXiv:2107.03049v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mathelin_A/0/1/0/all/0/1">Antoine de Mathelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Deheeger_F/0/1/0/all/0/1">Fran&#xe7;ois Deheeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1">Guillaume Richard</a>, <a href="http://arxiv.org/find/cs/1/au:+Mougeot_M/0/1/0/all/0/1">Mathilde Mougeot</a>, <a href="http://arxiv.org/find/cs/1/au:+Vayatis_N/0/1/0/all/0/1">Nicolas Vayatis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03049">
                                    <div class="article-summary-box-inner">
                                        <span>ADAPT is an open-source python library providing the implementation of
several domain adaptation methods. The library is suited for scikit-learn
estimator object (object which implement fit and predict methods) and
tensorflow models. Most of the implemented methods are developed in an
estimator agnostic fashion, offering various possibilities adapted to multiple
usage. The library offers three modules corresponding to the three principal
strategies of domain adaptation: (i) feature-based containing methods
performing feature transformation; (ii) instance-based with the implementation
of reweighting techniques and (iii) parameter-based proposing methods to adapt
pre-trained models to novel observations. A full documentation is proposed
online https://adapt-python.github.io/adapt/ with gallery of examples. Besides,
the library presents an high test coverage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonmyopic Multifidelity Active Search. (arXiv:2106.06356v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Modiri_A/0/1/0/all/0/1">Arghavan Modiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1">Roman Garnett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06356">
                                    <div class="article-summary-box-inner">
                                        <span>Active search is a learning paradigm where we seek to identify as many
members of a rare, valuable class as possible given a labeling budget. Previous
work on active search has assumed access to a faithful (and expensive) oracle
reporting experimental results. However, some settings offer access to cheaper
surrogates such as computational simulation that may aid in the search. We
propose a model of multifidelity active search, as well as a novel,
computationally efficient policy for this setting that is motivated by
state-of-the-art classical policies. Our policy is nonmyopic and budget aware,
allowing for a dynamic tradeoff between exploration and exploitation. We
evaluate the performance of our solution on real-world datasets and demonstrate
significantly better performance than natural benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Training Instance Selection for Few-Shot Neural Text Generation. (arXiv:2107.03176v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1">Ernie Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1">Xiaoyu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeh_H/0/1/0/all/0/1">Hui-Syuan Yeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1">Vera Demberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03176">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale pretrained language models have led to dramatic improvements in
text generation. Impressive performance can be achieved by finetuning only on a
small number of instances (few-shot setting). Nonetheless, almost all previous
work simply applies random sampling to select the few-shot training instances.
Little to no attention has been paid to the selection strategies and how they
would affect model performance. In this work, we present a study on training
instance selection in few-shot neural text generation. The selection decision
is made based only on the unlabeled data so as to identify the most worthwhile
data points that should be annotated under some budget of labeling cost. Based
on the intuition that the few-shot training instances should be diverse and
representative of the entire data distribution, we propose a simple selection
strategy with K-means clustering. We show that even with the naive
clustering-based approach, the generation models consistently outperform random
sampling on three text generation tasks: data-to-text generation, document
summarization and question generation. We hope that this work will call for
more attention on this largely unexplored area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Detection of Botnet Traffic by features selection and Decision Trees. (arXiv:2107.02896v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Velasco_Mata_J/0/1/0/all/0/1">Javier Velasco-Mata</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Castro_V/0/1/0/all/0/1">V&#xed;ctor Gonz&#xe1;lez-Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Fidalgo_E/0/1/0/all/0/1">Eduardo Fidalgo</a>, <a href="http://arxiv.org/find/cs/1/au:+Alegre_E/0/1/0/all/0/1">Enrique Alegre</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02896">
                                    <div class="article-summary-box-inner">
                                        <span>Botnets are one of the online threats with the biggest presence, causing
billionaire losses to global economies. Nowadays, the increasing number of
devices connected to the Internet makes it necessary to analyze large amounts
of network traffic data. In this work, we focus on increasing the performance
on botnet traffic classification by selecting those features that further
increase the detection rate. For this purpose we use two feature selection
techniques, Information Gain and Gini Importance, which led to three
pre-selected subsets of five, six and seven features. Then, we evaluate the
three feature subsets along with three models, Decision Tree, Random Forest and
k-Nearest Neighbors. To test the performance of the three feature vectors and
the three models we generate two datasets based on the CTU-13 dataset, namely
QB-CTU13 and EQB-CTU13. We measure the performance as the macro averaged F1
score over the computational time required to classify a sample. The results
show that the highest performance is achieved by Decision Trees using a five
feature set which obtained a mean F1 score of 85% classifying each sample in an
average time of 0.78 microseconds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">New Methods and Datasets for Group Anomaly Detection From Fundamental Physics. (arXiv:2107.02821v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kasieczka_G/0/1/0/all/0/1">Gregor Kasieczka</a>, <a href="http://arxiv.org/find/stat/1/au:+Nachman_B/0/1/0/all/0/1">Benjamin Nachman</a>, <a href="http://arxiv.org/find/stat/1/au:+Shih_D/0/1/0/all/0/1">David Shih</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02821">
                                    <div class="article-summary-box-inner">
                                        <span>The identification of anomalous overdensities in data - group or collective
anomaly detection - is a rich problem with a large number of real world
applications. However, it has received relatively little attention in the
broader ML community, as compared to point anomalies or other types of single
instance outliers. One reason for this is the lack of powerful benchmark
datasets. In this paper, we first explain how, after the Nobel-prize winning
discovery of the Higgs boson, unsupervised group anomaly detection has become a
new frontier of fundamental physics (where the motivation is to find new
particles and forces). Then we propose a realistic synthetic benchmark dataset
(LHCO2020) for the development of group anomaly detection algorithms. Finally,
we compare several existing statistically-sound techniques for unsupervised
group anomaly detection, and demonstrate their performance on the LHCO2020
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bio-Inspired Adversarial Attack Against Deep Neural Networks. (arXiv:2107.02895v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xi_B/0/1/0/all/0/1">Bowei Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yujie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_F/0/1/0/all/0/1">Fan Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhan Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_X/0/1/0/all/0/1">Xinyan Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02895">
                                    <div class="article-summary-box-inner">
                                        <span>The paper develops a new adversarial attack against deep neural networks
(DNN), based on applying bio-inspired design to moving physical objects. To the
best of our knowledge, this is the first work to introduce physical attacks
with a moving object. Instead of following the dominating attack strategy in
the existing literature, i.e., to introduce minor perturbations to a digital
input or a stationary physical object, we show two new successful attack
strategies in this paper. We show by superimposing several patterns onto one
physical object, a DNN becomes confused and picks one of the patterns to assign
a class label. Our experiment with three flapping wing robots demonstrates the
possibility of developing an adversarial camouflage to cause a targeted mistake
by DNN. We also show certain motion can reduce the dependency among consecutive
frames in a video and make an object detector &quot;blind&quot;, i.e., not able to detect
an object exists in the video. Hence in a successful physical attack against
DNN, targeted motion against the system should also be considered.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Data Balancing for Unlabeled Satellite Imagery. (arXiv:2107.03227v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Deep Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_E/0/1/0/all/0/1">Erin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1">Anirudh Koul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1">Siddha Ganju</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasam_M/0/1/0/all/0/1">Meher Anand Kasam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03227">
                                    <div class="article-summary-box-inner">
                                        <span>Data imbalance is a ubiquitous problem in machine learning. In large scale
collected and annotated datasets, data imbalance is either mitigated manually
by undersampling frequent classes and oversampling rare classes, or planned for
with imputation and augmentation techniques. In both cases balancing data
requires labels. In other words, only annotated data can be balanced.
Collecting fully annotated datasets is challenging, especially for large scale
satellite systems such as the unlabeled NASA&#x27;s 35 PB Earth Imagery dataset.
Although the NASA Earth Imagery dataset is unlabeled, there are implicit
properties of the data source that we can rely on to hypothesize about its
imbalance, such as distribution of land and water in the case of the Earth&#x27;s
imagery. We present a new iterative method to balance unlabeled data. Our
method utilizes image embeddings as a proxy for image labels that can be used
to balance data, and ultimately when trained increases overall accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAN-based Data Augmentation for Chest X-ray Classification. (arXiv:2107.02970v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sundaram_S/0/1/0/all/0/1">Shobhita Sundaram</a>, <a href="http://arxiv.org/find/eess/1/au:+Hulkund_N/0/1/0/all/0/1">Neha Hulkund</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02970">
                                    <div class="article-summary-box-inner">
                                        <span>A common problem in computer vision -- particularly in medical applications
-- is a lack of sufficiently diverse, large sets of training data. These
datasets often suffer from severe class imbalance. As a result, networks often
overfit and are unable to generalize to novel examples. Generative Adversarial
Networks (GANs) offer a novel method of synthetic data augmentation. In this
work, we evaluate the use of GAN- based data augmentation to artificially
expand the CheXpert dataset of chest radiographs. We compare performance to
traditional augmentation and find that GAN-based augmentation leads to higher
downstream performance for underrepresented classes. Furthermore, we see that
this result is pronounced in low data regimens. This suggests that GAN-based
augmentation a promising area of research to improve network performance when
data collection is prohibitively expensive.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlled Caption Generation for Images Through Adversarial Attacks. (arXiv:2107.03050v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aafaq_N/0/1/0/all/0/1">Nayyer Aafaq</a>, <a href="http://arxiv.org/find/cs/1/au:+Akhtar_N/0/1/0/all/0/1">Naveed Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mubarak Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1">Ajmal Mian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03050">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is found to be vulnerable to adversarial examples. However, its
adversarial susceptibility in image caption generation is under-explored. We
study adversarial examples for vision and language models, which typically
adopt an encoder-decoder framework consisting of two major components: a
Convolutional Neural Network (i.e., CNN) for image feature extraction and a
Recurrent Neural Network (RNN) for caption generation. In particular, we
investigate attacks on the visual encoder&#x27;s hidden layer that is fed to the
subsequent recurrent network. The existing methods either attack the
classification layer of the visual encoder or they back-propagate the gradients
from the language model. In contrast, we propose a GAN-based algorithm for
crafting adversarial examples for neural image captioning that mimics the
internal representation of the CNN such that the resulting deep features of the
input image enable a controlled incorrect caption generation through the
recurrent network. Our contribution provides new insights for understanding
adversarial attacks on vision systems with language component. The proposed
method employs two strategies for a comprehensive evaluation. The first
examines if a neural image captioning system can be misled to output targeted
image captions. The second analyzes the possibility of keywords into the
predicted captions. Experiments show that our algorithm can craft effective
adversarial images based on the CNN hidden layers to fool captioning framework.
Moreover, we discover the proposed attack to be highly transferable. Our work
leads to new robustness implications for neural image captioning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RAILS: A Robust Adversarial Immune-inspired Learning System. (arXiv:2107.02840v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ren Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindsly_S/0/1/0/all/0/1">Stephen Lindsly</a>, <a href="http://arxiv.org/find/cs/1/au:+Stansbury_C/0/1/0/all/0/1">Cooper Stansbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehemtulla_A/0/1/0/all/0/1">Alnawaz Rehemtulla</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajapakse_I/0/1/0/all/0/1">Indika Rajapakse</a>, <a href="http://arxiv.org/find/cs/1/au:+Hero_A/0/1/0/all/0/1">Alfred Hero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02840">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial attacks against deep neural networks (DNNs) are continuously
evolving, requiring increasingly powerful defense strategies. We develop a
novel adversarial defense framework inspired by the adaptive immune system: the
Robust Adversarial Immune-inspired Learning System (RAILS). Initializing a
population of exemplars that is balanced across classes, RAILS starts from a
uniform label distribution that encourages diversity and debiases a potentially
corrupted initial condition. RAILS implements an evolutionary optimization
process to adjust the label distribution and achieve specificity towards ground
truth. RAILS displays a tradeoff between robustness (diversity) and accuracy
(specificity), providing a new immune-inspired perspective on adversarial
learning. We empirically validate the benefits of RAILS through several
adversarial image classification experiments on MNIST, SVHN, and CIFAR-10
datasets. For the PGD attack, RAILS is found to improve the robustness over
existing methods by &gt;&#x3D; 5.62%, 12.5% and 10.32%, respectively, without
appreciable loss of standard accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nested Counterfactual Identification from Arbitrary Surrogate Experiments. (arXiv:2107.03190v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Correa_J/0/1/0/all/0/1">Juan D Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sanghack Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Bareinboim_E/0/1/0/all/0/1">Elias Bareinboim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03190">
                                    <div class="article-summary-box-inner">
                                        <span>The Ladder of Causation describes three qualitatively different types of
activities an agent may be interested in engaging in, namely, seeing
(observational), doing (interventional), and imagining (counterfactual) (Pearl
and Mackenzie, 2018). The inferential challenge imposed by the causal hierarchy
is that data is collected by an agent observing or intervening in a system
(layers 1 and 2), while its goal may be to understand what would have happened
had it taken a different course of action, contrary to what factually ended up
happening (layer 3). While there exists a solid understanding of the conditions
under which cross-layer inferences are allowed from observations to
interventions, the results are somewhat scarcer when targeting counterfactual
quantities. In this paper, we study the identification of nested
counterfactuals from an arbitrary combination of observations and experiments.
Specifically, building on a more explicit definition of nested counterfactuals,
we prove the counterfactual unnesting theorem (CUT), which allows one to map
arbitrary nested counterfactuals to unnested ones. For instance, applications
in mediation and fairness analysis usually evoke notions of direct, indirect,
and spurious effects, which naturally require nesting. Second, we introduce a
sufficient and necessary graphical condition for counterfactual identification
from an arbitrary combination of observational and experimental distributions.
Lastly, we develop an efficient and complete algorithm for identifying nested
counterfactuals; failure of the algorithm returning an expression for a query
implies it is not identifiable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Contextual Bandits without Regret. (arXiv:2107.03144v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kassraie_P/0/1/0/all/0/1">Parnian Kassraie</a>, <a href="http://arxiv.org/find/stat/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03144">
                                    <div class="article-summary-box-inner">
                                        <span>Contextual bandits are a rich model for sequential decision making given side
information, with important applications, e.g., in recommender systems. We
propose novel algorithms for contextual bandits harnessing neural networks to
approximate the unknown reward function. We resolve the open problem of proving
sublinear regret bounds in this setting for general context sequences,
considering both fully-connected and convolutional networks. To this end, we
first analyze NTK-UCB, a kernelized bandit optimization algorithm employing the
Neural Tangent Kernel (NTK), and bound its regret in terms of the NTK maximum
information gain $\gamma_T$, a complexity parameter capturing the difficulty of
learning. Our bounds on $\gamma_T$ for the NTK may be of independent interest.
We then introduce our neural network based algorithm NN-UCB, and show that its
regret closely tracks that of NTK-UCB. Under broad non-parametric assumptions
about the reward function, our approach converges to the optimal policy at a
$\tilde{\mathcal{O}}(T^{-1/2d})$ rate, where $d$ is the dimension of the
context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias-Tolerant Fair Classification. (arXiv:2107.03207v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Feng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhidong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03207">
                                    <div class="article-summary-box-inner">
                                        <span>The label bias and selection bias are acknowledged as two reasons in data
that will hinder the fairness of machine-learning outcomes. The label bias
occurs when the labeling decision is disturbed by sensitive features, while the
selection bias occurs when subjective bias exists during the data sampling.
Even worse, models trained on such data can inherit or even intensify the
discrimination. Most algorithmic fairness approaches perform an empirical risk
minimization with predefined fairness constraints, which tends to trade-off
accuracy for fairness. However, such methods would achieve the desired fairness
level with the sacrifice of the benefits (receive positive outcomes) for
individuals affected by the bias. Therefore, we propose a
Bias-TolerantFAirRegularizedLoss (B-FARL), which tries to regain the benefits
using data affected by label bias and selection bias. B-FARL takes the biased
data as input, calls a model that approximates the one trained with fair but
latent data, and thus prevents discrimination without constraints required. In
addition, we show the effective components by decomposing B-FARL, and we
utilize the meta-learning framework for the B-FARL optimization. The
experimental results on real-world datasets show that our method is empirically
effective in improving fairness towards the direction of true but latent
labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Particle Convolution for High Energy Physics. (arXiv:2107.02908v1 [hep-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-ph/1/au:+Shimmin_C/0/1/0/all/0/1">Chase Shimmin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02908">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the Particle Convolution Network (PCN), a new type of
equivariant neural network layer suitable for many tasks in jet physics. The
particle convolution layer can be viewed as an extension of Deep Sets and
Energy Flow network architectures, in which the permutation-invariant operator
is promoted to a group convolution. While the PCN can be implemented for
various kinds of symmetries, we consider the specific case of rotation about
the jet axis the $\eta - \phi$ plane. In two standard benchmark tasks, q/g
tagging and top tagging, we show that the rotational PCN (rPCN) achieves
performance comparable to graph networks such as ParticleNet. Moreover, we show
that it is possible to implement an IRC-safe rPCN, which significantly
outperforms existing IRC-safe tagging methods on both tasks. We speculate that
by generalizing the PCN to include additional convolutional symmetries relevant
to jet physics, it may outperform the current state-of-the-art set by graph
networks, while offering a new degree of control over physically-motivated
inductive biases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Immuno-mimetic Deep Neural Networks (Immuno-Net). (arXiv:2107.02842v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ren Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lindsly_S/0/1/0/all/0/1">Stephen Lindsly</a>, <a href="http://arxiv.org/find/cs/1/au:+Stansbury_C/0/1/0/all/0/1">Cooper Stansbury</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajapakse_I/0/1/0/all/0/1">Indika Rajapakse</a>, <a href="http://arxiv.org/find/cs/1/au:+Hero_A/0/1/0/all/0/1">Alfred Hero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02842">
                                    <div class="article-summary-box-inner">
                                        <span>Biomimetics has played a key role in the evolution of artificial neural
networks. Thus far, in silico metaphors have been dominated by concepts from
neuroscience and cognitive psychology. In this paper we introduce a different
type of biomimetic model, one that borrows concepts from the immune system, for
designing robust deep neural networks. This immuno-mimetic model leads to a new
computational biology framework for robustification of deep neural networks
against adversarial attacks. Within this Immuno-Net framework we define a
robust adaptive immune-inspired learning system (Immuno-Net RAILS) that
emulates, in silico, the adaptive biological mechanisms of B-cells that are
used to defend a mammalian host against pathogenic attacks. When applied to
image classification tasks on benchmark datasets, we demonstrate that
Immuno-net RAILS results in improvement of as much as 12.5% in adversarial
accuracy of a baseline method, the DkNN-robustified CNN, without appreciable
loss of accuracy on clean data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principles for Evaluation of AI/ML Model Performance and Robustness. (arXiv:2107.02868v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brown_O/0/1/0/all/0/1">Olivia Brown</a>, <a href="http://arxiv.org/find/cs/1/au:+Curtis_A/0/1/0/all/0/1">Andrew Curtis</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodwin_J/0/1/0/all/0/1">Justin Goodwin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02868">
                                    <div class="article-summary-box-inner">
                                        <span>The Department of Defense (DoD) has significantly increased its investment in
the design, evaluation, and deployment of Artificial Intelligence and Machine
Learning (AI/ML) capabilities to address national security needs. While there
are numerous AI/ML successes in the academic and commercial sectors, many of
these systems have also been shown to be brittle and nonrobust. In a complex
and ever-changing national security environment, it is vital that the DoD
establish a sound and methodical process to evaluate the performance and
robustness of AI/ML models before these new capabilities are deployed to the
field. This paper reviews the AI/ML development process, highlights common best
practices for AI/ML model evaluation, and makes recommendations to DoD
evaluators to ensure the deployment of robust AI/ML capabilities for national
security needs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed adaptive algorithm based on the asymmetric cost of error functions. (arXiv:2107.03067v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_S/0/1/0/all/0/1">Sihai Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1">Qing Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yong Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03067">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, a family of novel diffusion adaptive estimation algorithm is
proposed from the asymmetric cost function perspective by combining diffusion
strategy and the linear-linear cost (LLC), quadratic-quadratic cost (QQC), and
linear-exponential cost (LEC), at all distributed network nodes, and named
diffusion LLCLMS (DLLCLMS), diffusion QQCLMS (DQQCLMS), and diffusion LECLMS
(DLECLMS), respectively. Then the stability of mean estimation error and
computational complexity of those three diffusion algorithms are analyzed
theoretically. Finally, several experiment simulation results are designed to
verify the superiority of those three proposed diffusion algorithms.
Experimental simulation results show that DLLCLMS, DQQCLMS, and DLECLMS
algorithms are more robust to the input signal and impulsive noise than the
DSELMS, DRVSSLMS, and DLLAD algorithms. In brief, theoretical analysis and
experiment results show that those proposed DLLCLMS, DQQCLMS, and DLECLMS
algorithms have superior performance when estimating the unknown linear system
under the changeable impulsive noise environments and different types of input
signals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Teacher Forcing Network for Semi-Supervised Large Scale Data Streams. (arXiv:2107.02943v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pratama_M/0/1/0/all/0/1">Mahardhika Pratama</a>, <a href="http://arxiv.org/find/cs/1/au:+Zain_C/0/1/0/all/0/1">Choiru Za&#x27;in</a>, <a href="http://arxiv.org/find/cs/1/au:+Lughofer_E/0/1/0/all/0/1">Edwin Lughofer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pardede_E/0/1/0/all/0/1">Eric Pardede</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahayu_D/0/1/0/all/0/1">Dwi A. P. Rahayu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02943">
                                    <div class="article-summary-box-inner">
                                        <span>The large-scale data stream problem refers to high-speed information flow
which cannot be processed in scalable manner under a traditional computing
platform. This problem also imposes expensive labelling cost making the
deployment of fully supervised algorithms unfeasible. On the other hand, the
problem of semi-supervised large-scale data streams is little explored in the
literature because most works are designed in the traditional single-node
computing environments while also being fully supervised approaches. This paper
offers Weakly Supervised Scalable Teacher Forcing Network (WeScatterNet) to
cope with the scarcity of labelled samples and the large-scale data streams
simultaneously. WeScatterNet is crafted under distributed computing platform of
Apache Spark with a data-free model fusion strategy for model compression after
parallel computing stage. It features an open network structure to address the
global and local drift problems while integrating a data augmentation,
annotation and auto-correction ($DA^3$) method for handling partially labelled
data streams. The performance of WeScatterNet is numerically evaluated in the
six large-scale data stream problems with only $25\%$ label proportions. It
shows highly competitive performance even if compared with fully supervised
learners with $100\%$ label proportions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Denoising Diffusion Models in Discrete State-Spaces. (arXiv:2107.03006v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Austin_J/0/1/0/all/0/1">Jacob Austin</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_D/0/1/0/all/0/1">Daniel Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1">Jonathan Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarlow_D/0/1/0/all/0/1">Danny Tarlow</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_R/0/1/0/all/0/1">Rianne van den Berg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03006">
                                    <div class="article-summary-box-inner">
                                        <span>Denoising diffusion probabilistic models (DDPMs) (Ho et al. 2020) have shown
impressive results on image and waveform generation in continuous state spaces.
Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs),
diffusion-like generative models for discrete data that generalize the
multinomial diffusion model of Hoogeboom et al. 2021, by going beyond
corruption processes with uniform transition probabilities. This includes
corruption with transition matrices that mimic Gaussian kernels in continuous
space, matrices based on nearest neighbors in embedding space, and matrices
that introduce absorbing states. The third allows us to draw a connection
between diffusion models and autoregressive and mask-based generative models.
We show that the choice of transition matrix is an important design decision
that leads to improved results in image and text domains. We also introduce a
new loss function that combines the variational lower bound with an auxiliary
cross entropy loss. For text, this model class achieves strong results on
character-level text generation while scaling to large vocabularies on LM1B. On
the image dataset CIFAR-10, our models approach the sample quality and exceed
the log-likelihood of the continuous-space DDPM model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bi-Level Poisoning Attack Model and Countermeasure for Appliance Consumption Data of Smart Homes. (arXiv:2107.02897v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Billah_M/0/1/0/all/0/1">Mustain Billah</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1">Adnan Anwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_Z/0/1/0/all/0/1">Ziaur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Galib_S/0/1/0/all/0/1">Syed Md. Galib</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02897">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate building energy prediction is useful in various applications
starting from building energy automation and management to optimal storage
control. However, vulnerabilities should be considered when designing building
energy prediction models, as intelligent attackers can deliberately influence
the model performance using sophisticated attack models. These may consequently
degrade the prediction accuracy, which may affect the efficiency and
performance of the building energy management systems. In this paper, we
investigate the impact of bi-level poisoning attacks on regression models of
energy usage obtained from household appliances. Furthermore, an effective
countermeasure against the poisoning attacks on the prediction model is
proposed in this paper. Attacks and defenses are evaluated on a benchmark
dataset. Experimental results show that an intelligent cyber-attacker can
poison the prediction model to manipulate the decision. However, our proposed
solution successfully ensures defense against such poisoning attacks
effectively compared to other benchmark techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Embedding of Structural and Functional Brain Networks with Graph Neural Networks for Mental Illness Diagnosis. (arXiv:2107.03220v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_Y/0/1/0/all/0/1">Yanqiao Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cui_H/0/1/0/all/0/1">Hejie Cui</a>, <a href="http://arxiv.org/find/q-bio/1/au:+He_L/0/1/0/all/0/1">Lifang He</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sun_L/0/1/0/all/0/1">Lichao Sun</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03220">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal brain networks characterize complex connectivities among different
brain regions from both structural and functional aspects and provide a new
means for mental disease analysis. Recently, Graph Neural Networks (GNNs) have
become a de facto model for analyzing graph-structured data. However, how to
employ GNNs to extract effective representations from brain networks in
multiple modalities remains rarely explored. Moreover, as brain networks
provide no initial node features, how to design informative node attributes and
leverage edge weights for GNNs to learn is left unsolved. To this end, we
develop a novel multiview GNN for multimodal brain networks. In particular, we
regard each modality as a view for brain networks and employ contrastive
learning for multimodal fusion. Then, we propose a GNN model which takes
advantage of the message passing scheme by propagating messages based on degree
statistics and brain region connectivities. Extensive experiments on two
real-world disease datasets (HIV and Bipolar) demonstrate the effectiveness of
our proposed method over state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Immunization of Pruning Attack in DNN Watermarking Using Constant Weight Code. (arXiv:2107.02961v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuribayashi_M/0/1/0/all/0/1">Minoru Kuribayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yasui_T/0/1/0/all/0/1">Tatsuya Yasui</a>, <a href="http://arxiv.org/find/cs/1/au:+Malik_A/0/1/0/all/0/1">Asad Malik</a>, <a href="http://arxiv.org/find/cs/1/au:+Funabiki_N/0/1/0/all/0/1">Nobuo Funabiki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02961">
                                    <div class="article-summary-box-inner">
                                        <span>To ensure protection of the intellectual property rights of DNN models,
watermarking techniques have been investigated to insert side-information into
the models without seriously degrading the performance of original task. One of
the threats for the DNN watermarking is the pruning attack such that less
important neurons in the model are pruned to make it faster and more compact as
well as to remove the watermark. In this study, we investigate a channel coding
approach to resist the pruning attack. As the channel model is completely
different from conventional models like digital images, it has been an open
problem what kind of encoding method is suitable for DNN watermarking. A novel
encoding approach by using constant weight codes to immunize the effects of
pruning attacks is presented. To the best of our knowledge, this is the first
study that introduces an encoding technique for DNN watermarking to make it
robust against pruning attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the progress of Deep Reinforcement Learning in the real world: aligning domain-agnostic and domain-specific research. (arXiv:2107.03015v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garau_Luis_J/0/1/0/all/0/1">Juan Jose Garau-Luis</a>, <a href="http://arxiv.org/find/cs/1/au:+Crawley_E/0/1/0/all/0/1">Edward Crawley</a>, <a href="http://arxiv.org/find/cs/1/au:+Cameron_B/0/1/0/all/0/1">Bruce Cameron</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03015">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Reinforcement Learning (DRL) is considered a potential framework to
improve many real-world autonomous systems; it has attracted the attention of
multiple and diverse fields. Nevertheless, the successful deployment in the
real world is a test most of DRL models still need to pass. In this work we
focus on this issue by reviewing and evaluating the research efforts from both
domain-agnostic and domain-specific communities. On one hand, we offer a
comprehensive summary of DRL challenges and summarize the different proposals
to mitigate them; this helps identifying five gaps of domain-agnostic research.
On the other hand, from the domain-specific perspective, we discuss different
success stories and argue why other models might fail to be deployed. Finally,
we take up on ways to move forward accounting for both perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Zero to The Hero: A Collaborative Market Aware Recommendation System for Crowd Workers. (arXiv:2107.02890v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shamszare_H/0/1/0/all/0/1">Hamid Shamszare</a>, <a href="http://arxiv.org/find/cs/1/au:+Saremi_R/0/1/0/all/0/1">Razieh Saremi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jena_S/0/1/0/all/0/1">Sanam Jena</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02890">
                                    <div class="article-summary-box-inner">
                                        <span>The success of software crowdsourcing depends on active and trustworthy pool
of worker supply. The uncertainty of crowd workers&#x27; behaviors makes it
challenging to predict workers&#x27; success and plan accordingly. In a competitive
crowdsourcing marketplace, competition for success over shared tasks adds
another layer of uncertainty in crowd workers&#x27; decision-making process.
Preliminary analysis on software worker behaviors reveals an alarming task
dropping rate of 82.9%. These factors lead to the need for an automated
recommendation system for CSD workers to improve the visibility and
predictability of their success in the competition. To that end, this paper
proposes a collaborative recommendation system for crowd workers. The proposed
recommendation system method uses five input metrics based on workers&#x27;
collaboration history in the pool, workers&#x27; preferences in taking tasks in
terms of monetary prize and duration, workers&#x27; specialty, and workers&#x27;
proficiency. The proposed method then recommends the most suitable tasks for a
worker to compete on based on workers&#x27; probability of success in the task.
Experimental results on 260 active crowd workers demonstrate that just
following the top three success probabilities of task recommendations, workers
can achieve success up to 86%</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logit-based Uncertainty Measure in Classification. (arXiv:2107.02845v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Huiyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Klabjan_D/0/1/0/all/0/1">Diego Klabjan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02845">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new, reliable, and agnostic uncertainty measure for
classification tasks called logit uncertainty. It is based on logit outputs of
neural networks. We in particular show that this new uncertainty measure yields
a superior performance compared to existing uncertainty measures on different
tasks, including out of sample detection and finding erroneous predictions. We
analyze theoretical foundations of the measure and explore a relationship with
high density regions. We also demonstrate how to test uncertainty using
intermediate outputs in training of generative adversarial networks. We propose
two potential ways to utilize logit-based uncertainty in real world
applications, and show that the uncertainty measure outperforms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exact Learning Augmented Naive Bayes Classifier. (arXiv:2107.03018v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sugahara_S/0/1/0/all/0/1">Shouta Sugahara</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueno_M/0/1/0/all/0/1">Maomi Ueno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03018">
                                    <div class="article-summary-box-inner">
                                        <span>Earlier studies have shown that classification accuracies of Bayesian
networks (BNs) obtained by maximizing the conditional log likelihood (CLL) of a
class variable, given the feature variables, were higher than those obtained by
maximizing the marginal likelihood (ML). However, differences between the
performances of the two scores in the earlier studies may be attributed to the
fact that they used approximate learning algorithms, not exact ones. This paper
compares the classification accuracies of BNs with approximate learning using
CLL to those with exact learning using ML. The results demonstrate that the
classification accuracies of BNs obtained by maximizing the ML are higher than
those obtained by maximizing the CLL for large data. However, the results also
demonstrate that the classification accuracies of exact learning BNs using the
ML are much worse than those of other methods when the sample size is small and
the class variable has numerous parents. To resolve the problem, we propose an
exact learning augmented naive Bayes classifier (ANB), which ensures a class
variable with no parents. The proposed method is guaranteed to asymptotically
estimate the identical class posterior to that of the exactly learned BN.
Comparison experiments demonstrated the superior performance of the proposed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DSANet: Dynamic Segment Aggregation Network for Video-Level Representation Learning. (arXiv:2105.12085v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yanwu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_M/0/1/0/all/0/1">Mingde Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zichao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yifeng Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12085">
                                    <div class="article-summary-box-inner">
                                        <span>Long-range and short-range temporal modeling are two complementary and
crucial aspects of video recognition. Most of the state-of-the-arts focus on
short-range spatio-temporal modeling and then average multiple snippet-level
predictions to yield the final video-level prediction. Thus, their video-level
prediction does not consider spatio-temporal features of how video evolves
along the temporal dimension. In this paper, we introduce a novel Dynamic
Segment Aggregation (DSA) module to capture relationship among snippets. To be
more specific, we attempt to generate a dynamic kernel for a convolutional
operation to aggregate long-range temporal information among adjacent snippets
adaptively. The DSA module is an efficient plug-and-play module and can be
combined with the off-the-shelf clip-based models (i.e., TSM, I3D) to perform
powerful long-range modeling with minimal overhead. The final video
architecture, coined as DSANet. We conduct extensive experiments on several
video recognition benchmarks (i.e., Mini-Kinetics-200, Kinetics-400,
Something-Something V1 and ActivityNet) to show its superiority. Our proposed
DSA module is shown to benefit various video recognition models significantly.
For example, equipped with DSA modules, the top-1 accuracy of I3D ResNet-50 is
improved from 74.9% to 78.2% on Kinetics-400. Codes are available at
https://github.com/whwu95/DSANet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VAENAR-TTS: Variational Auto-Encoder based Non-AutoRegressive Text-to-Speech Synthesis. (arXiv:2107.03298v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Hui Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiyong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xixin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1">Shiyin Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xunying Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1">Helen Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03298">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes a variational auto-encoder based non-autoregressive
text-to-speech (VAENAR-TTS) model. The autoregressive TTS (AR-TTS) models based
on the sequence-to-sequence architecture can generate high-quality speech, but
their sequential decoding process can be time-consuming. Recently,
non-autoregressive TTS (NAR-TTS) models have been shown to be more efficient
with the parallel decoding process. However, these NAR-TTS models rely on
phoneme-level durations to generate a hard alignment between the text and the
spectrogram. Obtaining duration labels, either through forced alignment or
knowledge distillation, is cumbersome. Furthermore, hard alignment based on
phoneme expansion can degrade the naturalness of the synthesized speech. In
contrast, the proposed model of VAENAR-TTS is an end-to-end approach that does
not require phoneme-level durations. The VAENAR-TTS model does not contain
recurrent structures and is completely non-autoregressive in both the training
and inference phases. Based on the VAE architecture, the alignment information
is encoded in the latent variable, and attention-based soft alignment between
the text and the latent variable is used in the decoder to reconstruct the
spectrogram. Experiments show that VAENAR-TTS achieves state-of-the-art
synthesis quality, while the synthesis speed is comparable with other NAR-TTS
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-View Exocentric to Egocentric Video Synthesis. (arXiv:2107.03120v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Gaowen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Latapie_H/0/1/0/all/0/1">Hugo Latapie</a>, <a href="http://arxiv.org/find/cs/1/au:+Corso_J/0/1/0/all/0/1">Jason Corso</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yan Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03120">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-view video synthesis task seeks to generate video sequences of one view
from another dramatically different view. In this paper, we investigate the
exocentric (third-person) view to egocentric (first-person) view video
generation task. This is challenging because egocentric view sometimes is
remarkably different from the exocentric view. Thus, transforming the
appearances across the two different views is a non-trivial task. Particularly,
we propose a novel Bi-directional Spatial Temporal Attention Fusion Generative
Adversarial Network (STA-GAN) to learn both spatial and temporal information to
generate egocentric video sequences from the exocentric view. The proposed
STA-GAN consists of three parts: temporal branch, spatial branch, and attention
fusion. First, the temporal and spatial branches generate a sequence of fake
frames and their corresponding features. The fake frames are generated in both
downstream and upstream directions for both temporal and spatial branches.
Next, the generated four different fake frames and their corresponding features
(spatial and temporal branches in two directions) are fed into a novel
multi-generation attention fusion module to produce the final video sequence.
Meanwhile, we also propose a novel temporal and spatial dual-discriminator for
more robust network optimization. Extensive experiments on the Side2Ego and
Top2Ego datasets show that the proposed STA-GAN significantly outperforms the
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WeClick: Weakly-Supervised Video Semantic Segmentation with Click Annotations. (arXiv:2107.03088v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peidong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zibin He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xiyu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1">Shutao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Maowei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03088">
                                    <div class="article-summary-box-inner">
                                        <span>Compared with tedious per-pixel mask annotating, it is much easier to
annotate data by clicks, which costs only several seconds for an image.
However, applying clicks to learn video semantic segmentation model has not
been explored before. In this work, we propose an effective weakly-supervised
video semantic segmentation pipeline with click annotations, called WeClick,
for saving laborious annotating effort by segmenting an instance of the
semantic class with only a single click. Since detailed semantic information is
not captured by clicks, directly training with click labels leads to poor
segmentation predictions. To mitigate this problem, we design a novel memory
flow knowledge distillation strategy to exploit temporal information (named
memory flow) in abundant unlabeled video frames, by distilling the neighboring
predictions to the target frame via estimated motion. Moreover, we adopt
vanilla knowledge distillation for model compression. In this case, WeClick
learns compact video semantic segmentation models with the low-cost click
annotations during the training phase yet achieves real-time and accurate
models during the inference period. Experimental results on Cityscapes and
Camvid show that WeClick outperforms the state-of-the-art methods, increases
performance by 10.24% mIoU than baseline, and achieves real-time execution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-07">2021-07-07</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gender Recognition in Informal and Formal Language Scenarios via Transfer Learning. (arXiv:2107.02759v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Escobar_Grisales_D/0/1/0/all/0/1">Daniel Escobar-Grisales</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasquez_Correa_J/0/1/0/all/0/1">Juan Camilo Vasquez-Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Orozco_Arroyave_J/0/1/0/all/0/1">Juan Rafael Orozco-Arroyave</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02759">
                                    <div class="article-summary-box-inner">
                                        <span>The interest in demographic information retrieval based on text data has
increased in the research community because applications have shown success in
different sectors such as security, marketing, heath-care, and others.
Recognition and identification of demographic traits such as gender, age,
location, or personality based on text data can help to improve different
marketing strategies. For instance it makes it possible to segment and to
personalize offers, thus products and services are exposed to the group of
greatest interest. This type of technology has been discussed widely in
documents from social media. However, the methods have been poorly studied in
data with a more formal structure, where there is no access to emoticons,
mentions, and other linguistic phenomena that are only present in social media.
This paper proposes the use of recurrent and convolutional neural networks, and
a transfer learning strategy for gender recognition in documents that are
written in informal and formal languages. Models are tested in two different
databases consisting of Tweets and call-center conversations. Accuracies of up
to 75\% are achieved for both databases. The results also indicate that it is
possible to transfer the knowledge from a system trained on a specific type of
expressions or idioms such as those typically used in social media into a more
formal type of text data, where the amount of data is more scarce and its
structure is completely different.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An NLG pipeline for a legal expert system: a work in progress. (arXiv:2107.02421v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Listenmaa_I/0/1/0/all/0/1">Inari Listenmaa</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_J/0/1/0/all/0/1">Jason Morris</a>, <a href="http://arxiv.org/find/cs/1/au:+Ang_A/0/1/0/all/0/1">Alfred Ang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanafiah_M/0/1/0/all/0/1">Maryam Hanafiah</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheong_R/0/1/0/all/0/1">Regina Cheong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02421">
                                    <div class="article-summary-box-inner">
                                        <span>We present the NLG component for L4, a prototype domain-specific language
(DSL) for drafting laws and contracts. As a concrete use case, we describe a
pipeline for a legal expert system created from L4 code. The NLG component is
used in two steps. The first step is to create an interview, whose answers are
processed into a query for an automated reasoner. The second step is to render
the answers of the reasoner in natural language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Graph Reasoning for Natural Proof Generation. (arXiv:2107.02418v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changzhi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiangjie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chun Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuanbin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiaze Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02418">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate the problem of reasoning over natural language
statements. Prior neural based approaches do not explicitly consider the
inter-dependency among answers and their proofs. In this paper, we propose
PRobr, a novel approach for joint answer prediction and proof generation. PRobr
defines a joint probabilistic distribution over all possible proof graphs and
answers via an induced graphical model. We then optimize the model using
variational approximation on top of neural textual representation. Experiments
on multiple datasets under diverse settings (fully supervised, few-shot and
zero-shot evaluation) verify the effectiveness of PRobr, e.g., achieving
10%-30% improvement on QA accuracy in few/zero-shot evaluation. Our codes and
models can be found at https://github.com/changzhisun/PRobr/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Named Entity Tagging with Learnable Logical Rules. (arXiv:2107.02282v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiacheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Haibo Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1">Jingbo Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1">Julian McAuley</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zhe Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02282">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of building entity tagging systems by using a few rules
as weak supervision. Previous methods mostly focus on disambiguation entity
types based on contexts and expert-provided rules, while assuming entity spans
are given. In this work, we propose a novel method TALLOR that bootstraps
high-quality logical rules to train a neural tagger in a fully automated
manner. Specifically, we introduce compound rules that are composed from simple
rules to increase the precision of boundary detection and generate more diverse
pseudo labels. We further design a dynamic label selection strategy to ensure
pseudo label quality and therefore avoid overfitting the neural tagger.
Experiments on three datasets demonstrate that our method outperforms other
weakly supervised methods and even rivals a state-of-the-art distantly
supervised tagger with a lexicon of over 2,000 terms when starting from only 20
simple rules. Our method can serve as a tool for rapidly building taggers in
emerging domains and tasks. Case studies show that learned rules can
potentially explain the predicted entities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When Does Pretraining Help? Assessing Self-Supervised Learning for Law and the CaseHOLD Dataset. (arXiv:2104.08671v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lucia Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guha_N/0/1/0/all/0/1">Neel Guha</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_B/0/1/0/all/0/1">Brandon R. Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1">Peter Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_D/0/1/0/all/0/1">Daniel E. Ho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08671">
                                    <div class="article-summary-box-inner">
                                        <span>While self-supervised learning has made rapid advances in natural language
processing, it remains unclear when researchers should engage in
resource-intensive domain-specific pretraining (domain pretraining). The law,
puzzlingly, has yielded few documented instances of substantial gains to domain
pretraining in spite of the fact that legal language is widely seen to be
unique. We hypothesize that these existing results stem from the fact that
existing legal NLP tasks are too easy and fail to meet conditions for when
domain pretraining can help. To address this, we first present CaseHOLD (Case
Holdings On Legal Decisions), a new dataset comprised of over 53,000+ multiple
choice questions to identify the relevant holding of a cited case. This dataset
presents a fundamental task to lawyers and is both legally meaningful and
difficult from an NLP perspective (F1 of 0.4 with a BiLSTM baseline). Second,
we assess performance gains on CaseHOLD and existing legal NLP datasets. While
a Transformer architecture (BERT) pretrained on a general corpus (Google Books
and Wikipedia) improves performance, domain pretraining (using corpus of
approximately 3.5M decisions across all courts in the U.S. that is larger than
BERT&#x27;s) with a custom legal vocabulary exhibits the most substantial
performance gains with CaseHOLD (gain of 7.2% on F1, representing a 12%
improvement on BERT) and consistent performance gains across two other legal
tasks. Third, we show that domain pretraining may be warranted when the task
exhibits sufficient similarity to the pretraining corpus: the level of
performance increase in three legal tasks was directly tied to the domain
specificity of the task. Our findings inform when researchers should engage
resource-intensive pretraining and show that Transformer-based architectures,
too, learn embeddings suggestive of distinct legal language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Talk to Action with Accountability: Monitoring the Public Discussion of Policy Makers with Deep Neural Networks and Topic Modelling. (arXiv:2010.08346v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hatonen_V/0/1/0/all/0/1">Vili H&#xe4;t&#xf6;nen</a>, <a href="http://arxiv.org/find/cs/1/au:+Melzer_F/0/1/0/all/0/1">Fiona Melzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08346">
                                    <div class="article-summary-box-inner">
                                        <span>Decades of research on climate have provided a consensus that human activity
has changed the climate and we are currently heading into a climate crisis.
While public discussion and research efforts on climate change mitigation have
increased, potential solutions need to not only be discussed but also
effectively deployed. For preventing mismanagement and holding policy makers
accountable, transparency and degree of information about government processes
have been shown to be crucial. However, currently the quantity of information
about climate change discussions and the range of sources make it increasingly
difficult for the public and civil society to maintain an overview to hold
politicians accountable.

In response, we propose a multi-source topic aggregation system (MuSTAS)
which processes policy makers speech and rhetoric from several publicly
available sources into an easily digestible topic summary. MuSTAS uses novel
multi-source hybrid latent Dirichlet allocation to model topics from a variety
of documents. This topic digest will serve the general public and civil society
in assessing where, how, and when politicians talk about climate and climate
policies, enabling them to hold politicians accountable for their actions to
mitigate climate change and lack thereof.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention over learned object embeddings enables complex visual reasoning. (arXiv:2012.08508v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1">David Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1">Adam Santoro</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynolds_M/0/1/0/all/0/1">Malcolm Reynolds</a>, <a href="http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1">Matt Botvinick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08508">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have achieved success in a wide array of perceptual tasks but
often fail at tasks involving both perception and higher-level reasoning. On
these more challenging tasks, bespoke approaches (such as modular symbolic
components, independent dynamics models or semantic parsers) targeted towards
that specific type of task have typically performed better. The downside to
these targeted approaches, however, is that they can be more brittle than
general-purpose neural networks, requiring significant modification or even
redesign according to the particular task at hand. Here, we propose a more
general neural-network-based approach to dynamic visual reasoning problems that
obtains state-of-the-art performance on three different domains, in each case
outperforming bespoke modular approaches tailored specifically to the task. Our
method relies on learned object-centric representations, self-attention and
self-supervised dynamics learning, and all three elements together are required
for strong performance to emerge. The success of this combination suggests that
there may be no need to trade off flexibility for performance on problems
involving spatio-temporal or causal-style reasoning. With the right soft biases
and learning objectives in a neural network we may be able to attain the best
of both worlds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Schema-based Event Extraction: Literature Review and Current Trends. (arXiv:2107.02126v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hei_Y/0/1/0/all/0/1">Yiming Hei</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1">Rui Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_J/0/1/0/all/0/1">Jiawei Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lihong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Philip S. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02126">
                                    <div class="article-summary-box-inner">
                                        <span>Schema-based event extraction is a critical technique to apprehend the
essential content of events promptly. With the rapid development of deep
learning technology, event extraction technology based on deep learning has
become a research hotspot. Numerous methods, datasets, and evaluation metrics
have been proposed in the literature, raising the need for a comprehensive and
updated survey. This paper fills the gap by reviewing the state-of-the-art
approaches, focusing on deep learning-based models. We summarize the task
definition, paradigm, and models of schema-based event extraction and then
discuss each of these in detail. We introduce benchmark datasets that support
tests of predictions and evaluation metrics. A comprehensive comparison between
different techniques is also provided in this survey. Finally, we conclude by
summarizing future research directions facing the research area.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ETHOS: an Online Hate Speech Detection Dataset. (arXiv:2006.08328v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mollas_I/0/1/0/all/0/1">Ioannis Mollas</a>, <a href="http://arxiv.org/find/cs/1/au:+Chrysopoulou_Z/0/1/0/all/0/1">Zoe Chrysopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlos_S/0/1/0/all/0/1">Stamatis Karlos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1">Grigorios Tsoumakas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08328">
                                    <div class="article-summary-box-inner">
                                        <span>Online hate speech is a recent problem in our society that is rising at a
steady pace by leveraging the vulnerabilities of the corresponding regimes that
characterise most social media platforms. This phenomenon is primarily fostered
by offensive comments, either during user interaction or in the form of a
posted multimedia context. Nowadays, giant corporations own platforms where
millions of users log in every day, and protection from exposure to similar
phenomena appears to be necessary in order to comply with the corresponding
legislation and maintain a high level of service quality. A robust and reliable
system for detecting and preventing the uploading of relevant content will have
a significant impact on our digitally interconnected society. Several aspects
of our daily lives are undeniably linked to our social profiles, making us
vulnerable to abusive behaviours. As a result, the lack of accurate hate speech
detection mechanisms would severely degrade the overall user experience,
although its erroneous operation would pose many ethical concerns. In this
paper, we present &#x27;ETHOS&#x27;, a textual dataset with two variants: binary and
multi-label, based on YouTube and Reddit comments validated using the
Figure-Eight crowdsourcing platform. Furthermore, we present the annotation
protocol used to create this dataset: an active sampling procedure for
balancing our data in relation to the various aspects defined. Our key
assumption is that, even gaining a small amount of labelled data from such a
time-consuming process, we can guarantee hate speech occurrences in the
examined material.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP Contributions for a Research Knowledge Graph. (arXiv:2106.07385v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1">Jennifer D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1">S&#xf6;ren Auer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersen_T/0/1/0/all/0/1">Ted Pedersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07385">
                                    <div class="article-summary-box-inner">
                                        <span>There is currently a gap between the natural language expression of scholarly
publications and their structured semantic content modeling to enable
intelligent content search. With the volume of research growing exponentially
every year, a search feature operating over semantically structured content is
compelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. &#x27;the NCG
task&#x27;) tasks participants to develop automated systems that structure
contributions from NLP scholarly articles in the English language. Being the
first-of-its-kind in the SemEval series, the task released structured data from
NLP scholarly articles at three levels of information granularity, i.e. at
sentence-level, phrase-level, and phrases organized as triples toward Knowledge
Graph (KG) building. The sentence-level annotations comprised the few sentences
about the article&#x27;s contribution. The phrase-level annotations were scientific
term and predicate phrases from the contribution sentences. Finally, the
triples constituted the research overview KG. For the Shared Task,
participating systems were then expected to automatically classify contribution
sentences, extract scientific terms and relations from the sentences, and
organize them as KG triples.

Overall, the task drew a strong participation demographic of seven teams and
27 participants. The best end-to-end task system classified contribution
sentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While
the absolute performance to generate triples remains low, in the conclusion of
this article, the difficulty of producing such data and as a consequence of
modeling it is highlighted.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Order in the Court: Explainable AI Methods Prone to Disagreement. (arXiv:2105.03287v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neely_M/0/1/0/all/0/1">Michael Neely</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouten_S/0/1/0/all/0/1">Stefan F. Schouten</a>, <a href="http://arxiv.org/find/cs/1/au:+Bleeker_M/0/1/0/all/0/1">Maurits J. R. Bleeker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_A/0/1/0/all/0/1">Ana Lucic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03287">
                                    <div class="article-summary-box-inner">
                                        <span>By computing the rank correlation between attention weights and
feature-additive explanation methods, previous analyses either invalidate or
support the role of attention-based explanations as a faithful and plausible
measure of salience. To investigate whether this approach is appropriate, we
compare LIME, Integrated Gradients, DeepLIFT, Grad-SHAP, Deep-SHAP, and
attention-based explanations, applied to two neural architectures trained on
single- and pair-sequence language tasks. In most cases, we find that none of
our chosen methods agree. Based on our empirical observations and theoretical
objections, we conclude that rank correlation does not measure the quality of
feature-additive methods. Practitioners should instead use the numerous and
rigorous diagnostic methods proposed by the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VidLanKD: Improving Language Understanding via Video-Distilled Knowledge Transfer. (arXiv:2107.02681v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zineng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jaemin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02681">
                                    <div class="article-summary-box-inner">
                                        <span>Since visual perception can give rich information beyond text descriptions
for world understanding, there has been increasing interest in leveraging
visual grounding for language learning. Recently, vokenization has attracted
attention by using the predictions of a text-to-image retrieval model as labels
for language model supervision. Despite its success, the method suffers from
approximation error of using finite image labels and the lack of vocabulary
diversity of a small image-text dataset. To overcome these limitations, we
present VidLanKD, a video-language knowledge distillation method for improving
language understanding. We train a multi-modal teacher model on a video-text
dataset, and then transfer its knowledge to a student language model with a
text dataset. To avoid approximation error, we propose to use different
knowledge distillation objectives. In addition, the use of a large-scale
video-text dataset helps learn diverse and richer vocabularies. In our
experiments, VidLanKD achieves consistent improvements over text-only language
models and vokenization models, on several downstream language understanding
tasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world
knowledge, physical reasoning, and temporal reasoning capabilities of our model
by evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we
present comprehensive ablation studies as well as visualizations of the learned
text-to-video grounding results of our teacher and student language models. Our
code and models are available at: https://github.com/zinengtang/VidLanKD</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style. (arXiv:2107.02530v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yuzi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bohan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guangyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei-Qiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02530">
                                    <div class="article-summary-box-inner">
                                        <span>While recent text to speech (TTS) models perform very well in synthesizing
reading-style (e.g., audiobook) speech, it is still challenging to synthesize
spontaneous-style speech (e.g., podcast or conversation), mainly because of two
reasons: 1) the lack of training data for spontaneous speech; 2) the difficulty
in modeling the filled pauses (um and uh) and diverse rhythms in spontaneous
speech. In this paper, we develop AdaSpeech 3, an adaptive TTS system that
fine-tunes a well-trained reading-style TTS model for spontaneous-style speech.
Specifically, 1) to insert filled pauses (FP) in the text sequence
appropriately, we introduce an FP predictor to the TTS model; 2) to model the
varying rhythms, we introduce a duration predictor based on mixture of experts
(MoE), which contains three experts responsible for the generation of fast,
medium and slow speech respectively, and fine-tune it as well as the pitch
predictor for rhythm adaptation; 3) to adapt to other speaker timbre, we
fine-tune some parameters in the decoder with few speech data. To address the
challenge of lack of training data, we mine a spontaneous speech dataset to
support our research this work and facilitate future research on spontaneous
TTS. Experiments show that AdaSpeech 3 synthesizes speech with natural FP and
rhythms in spontaneous styles, and achieves much better MOS and SMOS scores
than previous adaptive TTS systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Location, Location: Enhancing the Evaluation of Text-to-Speech Synthesis Using the Rapid Prosody Transcription Paradigm. (arXiv:2107.02527v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gutierrez_E/0/1/0/all/0/1">Elijah Gutierrez</a>, <a href="http://arxiv.org/find/eess/1/au:+Oplustil_Gallegos_P/0/1/0/all/0/1">Pilar Oplustil-Gallegos</a>, <a href="http://arxiv.org/find/eess/1/au:+Lai_C/0/1/0/all/0/1">Catherine Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02527">
                                    <div class="article-summary-box-inner">
                                        <span>Text-to-Speech synthesis systems are generally evaluated using Mean Opinion
Score (MOS) tests, where listeners score samples of synthetic speech on a
Likert scale. A major drawback of MOS tests is that they only offer a general
measure of overall quality-i.e., the naturalness of an utterance-and so cannot
tell us where exactly synthesis errors occur. This can make evaluation of the
appropriateness of prosodic variation within utterances inconclusive. To
address this, we propose a novel evaluation method based on the Rapid Prosody
Transcription paradigm. This allows listeners to mark the locations of errors
in an utterance in real-time, providing a probabilistic representation of the
perceptual errors that occur in the synthetic signal. We conduct experiments
that confirm that the fine-grained evaluation can be mapped to system rankings
of standard MOS tests, but the error marking gives a much more comprehensive
assessment of synthesized prosody. In particular, for standard audiobook test
set samples, we see that error marks consistently cluster around words at major
prosodic boundaries indicated by punctuation. However, for question-answer
based stimuli, where we control information structure, we see differences
emerge in the ability of neural TTS systems to generate context-appropriate
prosodic prominence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transfer Learning for Improving Results on Russian Sentiment Datasets. (arXiv:2107.02499v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Golubev_A/0/1/0/all/0/1">Anton Golubev</a>, <a href="http://arxiv.org/find/cs/1/au:+Loukachevitch_N/0/1/0/all/0/1">Natalia Loukachevitch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02499">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, we test transfer learning approach on Russian sentiment
benchmark datasets using additional train sample created with distant
supervision technique. We compare several variants of combining additional data
with benchmark train samples. The best results were achieved using three-step
approach of sequential training on general, thematic and original train
samples. For most datasets, the results were improved by more than 3% to the
current state-of-the-art methods. The BERT-NLI model treating sentiment
classification problem as a natural language inference task reached the human
level of sentiment analysis on one of the datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lexical Access Model for Italian -- Modeling human speech processing: identification of words in running speech toward lexical access based on the detection of landmarks and other acoustic cues to features. (arXiv:2107.02720v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Benedetto_M/0/1/0/all/0/1">Maria-Gabriella Di Benedetto</a>, <a href="http://arxiv.org/find/eess/1/au:+Shattuck_Hufnagel_S/0/1/0/all/0/1">Stefanie Shattuck-Hufnagel</a>, <a href="http://arxiv.org/find/eess/1/au:+Choi_J/0/1/0/all/0/1">Jeung-Yoon Choi</a>, <a href="http://arxiv.org/find/eess/1/au:+Nardis_L/0/1/0/all/0/1">Luca De Nardis</a>, <a href="http://arxiv.org/find/eess/1/au:+Arango_J/0/1/0/all/0/1">Javier Arango</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_I/0/1/0/all/0/1">Ian Chan</a>, <a href="http://arxiv.org/find/eess/1/au:+DeCaprio_A/0/1/0/all/0/1">Alec DeCaprio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02720">
                                    <div class="article-summary-box-inner">
                                        <span>Modelling the process that a listener actuates in deriving the words intended
by a speaker requires setting a hypothesis on how lexical items are stored in
memory. This work aims at developing a system that imitates humans when
identifying words in running speech and, in this way, provide a framework to
better understand human speech processing. We build a speech recognizer for
Italian based on the principles of Stevens&#x27; model of Lexical Access in which
words are stored as hierarchical arrangements of distinctive features (Stevens,
K. N. (2002). &quot;Toward a model for lexical access based on acoustic landmarks
and distinctive features,&quot; J. Acoust. Soc. Am., 111(4):1872-1891). Over the
past few decades, the Speech Communication Group at the Massachusetts Institute
of Technology (MIT) developed a speech recognition system for English based on
this approach. Italian will be the first language beyond English to be
explored; the extension to another language provides the opportunity to test
the hypothesis that words are represented in memory as a set of
hierarchically-arranged distinctive features, and reveal which of the
underlying mechanisms may have a language-independent nature. This paper also
introduces a new Lexical Access corpus, the LaMIT database, created and labeled
specifically for this work, that will be provided freely to the speech research
community. Future developments will test the hypothesis that specific acoustic
discontinuities - called landmarks - that serve as cues to features, are
language independent, while other cues may be language-dependent, with powerful
implications for understanding how the human brain recognizes speech.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Empowering NGOs in Countering Online Hate Messages. (arXiv:2107.02472v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chung_Y/0/1/0/all/0/1">Yi-Ling Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Tekiroglu_S/0/1/0/all/0/1">Serra Sinem Tekiroglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tonelli_S/0/1/0/all/0/1">Sara Tonelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerini_M/0/1/0/all/0/1">Marco Guerini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02472">
                                    <div class="article-summary-box-inner">
                                        <span>Studies on online hate speech have mostly focused on the automated detection
of harmful messages. Little attention has been devoted so far to the
development of effective strategies to fight hate speech, in particular through
the creation of counter-messages. While existing manual scrutiny and
intervention strategies are time-consuming and not scalable, advances in
natural language processing have the potential to provide a systematic approach
to hatred management. In this paper, we introduce a novel ICT platform that NGO
operators can use to monitor and analyze social media data, along with a
counter-narrative suggestion tool. Our platform aims at increasing the
efficiency and effectiveness of operators&#x27; activities against islamophobia. We
test the platform with more than one hundred NGO operators in three countries
through qualitative and quantitative evaluation. Results show that NGOs favor
the platform solution with the suggestion tool, and that the time required to
produce counter-narratives significantly decreases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network. (arXiv:2107.02757v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhibin Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dongsheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chaojie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenchao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yewen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02757">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical topic models such as the gamma belief network (GBN) have
delivered promising results in mining multi-layer document representations and
discovering interpretable topic taxonomies. However, they often assume in the
prior that the topics at each layer are independently drawn from the Dirichlet
distribution, ignoring the dependencies between the topics both at the same
layer and across different layers. To relax this assumption, we propose
sawtooth factorial topic embedding guided GBN, a deep generative model of
documents that captures the dependencies and semantic similarities between the
topics in the embedding space. Specifically, both the words and topics are
represented as embedding vectors of the same dimension. The topic matrix at a
layer is factorized into the product of a factor loading matrix and a topic
embedding matrix, the transpose of which is set as the factor loading matrix of
the layer above. Repeating this particular type of factorization, which shares
components between adjacent layers, leads to a structure referred to as
sawtooth factorization. An auto-encoding variational inference network is
constructed to optimize the model parameter via stochastic gradient descent.
Experiments on big corpora show that our models outperform other neural topic
models on extracting deeper interpretable topics and deriving better document
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning. (arXiv:2107.02794v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nye_M/0/1/0/all/0/1">Maxwell Nye</a>, <a href="http://arxiv.org/find/cs/1/au:+Tessler_M/0/1/0/all/0/1">Michael Henry Tessler</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1">Brenden M. Lake</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02794">
                                    <div class="article-summary-box-inner">
                                        <span>Human reasoning can often be understood as an interplay between two systems:
the intuitive and associative (&quot;System 1&quot;) and the deliberative and logical
(&quot;System 2&quot;). Neural sequence models -- which have been increasingly successful
at performing complex, structured tasks -- exhibit the advantages and failure
modes of System 1: they are fast and learn patterns from data, but are often
inconsistent and incoherent. In this work, we seek a lightweight, training-free
means of improving existing System 1-like sequence models by adding System
2-inspired logical reasoning. We explore several variations on this theme in
which candidate generations from a neural sequence model are examined for
logical consistency by a symbolic reasoning module, which can either accept or
reject the generations. Our approach uses neural inference to mediate between
the neural System 1 and the logical System 2. Results in robust story
generation and grounded instruction-following show that this approach can
increase the coherence and accuracy of neurally-based generations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The NiuTrans End-to-End Speech Translation System \\for IWSLT 2021 Offline Task. (arXiv:2107.02444v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoqian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaowen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Laohu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Canan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_T/0/1/0/all/0/1">Tong Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jingbo Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02444">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the submission of the NiuTrans end-to-end speech
translation system for the IWSLT 2021 offline task, which translates from the
English audio to German text directly without intermediate transcription. We
use the Transformer-based model architecture and enhance it by Conformer,
relative position encoding, and stacked acoustic and textual encoding. To
augment the training data, the English transcriptions are translated to German
translations. Finally, we employ ensemble decoding to integrate the predictions
from several models trained with the different datasets. Combining these
techniques, we achieve 33.84 BLEU points on the MuST-C En-De test set, which
shows the enormous potential of the end-to-end model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhanced Universal Dependency Parsing with Automated Concatenation of Embeddings. (arXiv:2107.02416v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zixia Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02416">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the system used in submission from SHANGHAITECH team to
the IWPT 2021 Shared Task. Our system is a graph-based parser with the
technique of Automated Concatenation of Embeddings (ACE). Because recent work
found that better word representations can be obtained by concatenating
different types of embeddings, we use ACE to automatically find the better
concatenation of embeddings for the task of enhanced universal dependencies.
According to official results averaged on 17 languages, our system ranks 2nd
over 9 teams.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Helps Transformers Recognize Conversational Structure? Importance of Context, Punctuation, and Labels in Dialog Act Recognition. (arXiv:2107.02294v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zelasko_P/0/1/0/all/0/1">Piotr &#x17b;elasko</a>, <a href="http://arxiv.org/find/cs/1/au:+Pappagari_R/0/1/0/all/0/1">Raghavendra Pappagari</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehak_N/0/1/0/all/0/1">Najim Dehak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02294">
                                    <div class="article-summary-box-inner">
                                        <span>Dialog acts can be interpreted as the atomic units of a conversation, more
fine-grained than utterances, characterized by a specific communicative
function. The ability to structure a conversational transcript as a sequence of
dialog acts -- dialog act recognition, including the segmentation -- is
critical for understanding dialog. We apply two pre-trained transformer models,
XLNet and Longformer, to this task in English and achieve strong results on
Switchboard Dialog Act and Meeting Recorder Dialog Act corpora with dialog act
segmentation error rates (DSER) of 8.4% and 14.2%. To understand the key
factors affecting dialog act recognition, we perform a comparative analysis of
models trained under different conditions. We find that the inclusion of a
broader conversational context helps disambiguate many dialog act classes,
especially those infrequent in the training data. The presence of punctuation
in the transcripts has a massive effect on the models&#x27; performance, and a
detailed analysis reveals specific segmentation patterns observed in its
absence. Finally, we find that the label set specificity does not affect dialog
act segmentation performance. These findings have significant practical
implications for spoken language understanding applications that depend heavily
on a good-quality segmentation being available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3$\times$ as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results~(e.g., Top-1 accuracy 84.1% trained on 224$\times$224
ImageNet-1K only), while being more scalable on high-resolution images. The
models and source code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mind Your Outliers! Investigating the Negative Impact of Outliers on Active Learning for Visual Question Answering. (arXiv:2107.02331v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karamcheti_S/0/1/0/all/0/1">Siddharth Karamcheti</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1">Ranjay Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1">Christopher D. Manning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02331">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning promises to alleviate the massive data needs of supervised
machine learning: it has successfully improved sample efficiency by an order of
magnitude on traditional tasks like topic classification and object
recognition. However, we uncover a striking contrast to this promise: across 5
models and 4 datasets on the task of visual question answering, a wide variety
of active learning approaches fail to outperform random selection. To
understand this discrepancy, we profile 8 active learning methods on a
per-example basis, and identify the problem as collective outliers -- groups of
examples that active learning methods prefer to acquire but models fail to
learn (e.g., questions that ask about text in images or require external
knowledge). Through systematic ablation experiments and qualitative
visualizations, we verify that collective outliers are a general phenomenon
responsible for degrading pool-based active learning. Notably, we show that
active learning sample efficiency increases significantly as the number of
collective outliers in the active learning pool decreases. We conclude with a
discussion and prescriptive recommendations for mitigating the effects of these
outliers in future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sarcasm Detection: A Comparative Study. (arXiv:2107.02276v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yaghoobian_H/0/1/0/all/0/1">Hamed Yaghoobian</a>, <a href="http://arxiv.org/find/cs/1/au:+Arabnia_H/0/1/0/all/0/1">Hamid R. Arabnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasheed_K/0/1/0/all/0/1">Khaled Rasheed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02276">
                                    <div class="article-summary-box-inner">
                                        <span>Sarcasm detection is the task of identifying irony containing utterances in
sentiment-bearing text. However, the figurative and creative nature of sarcasm
poses a great challenge for affective computing systems performing sentiment
analysis. This article compiles and reviews the salient work in the literature
of automatic sarcasm detection. Thus far, three main paradigm shifts have
occurred in the way researchers have approached this task: 1) semi-supervised
pattern extraction to identify implicit sentiment, 2) use of hashtag-based
supervision, and 3) incorporation of context beyond target text. In this
article, we provide a comprehensive review of the datasets, approaches, trends,
and issues in sarcasm and irony detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instant One-Shot Word-Learning for Context-Specific Neural Sequence-to-Sequence Speech Recognition. (arXiv:2107.02268v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huber_C/0/1/0/all/0/1">Christian Huber</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_J/0/1/0/all/0/1">Juan Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Stuker_S/0/1/0/all/0/1">Sebastian St&#xfc;ker</a>, <a href="http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1">Alexander Waibel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02268">
                                    <div class="article-summary-box-inner">
                                        <span>Neural sequence-to-sequence systems deliver state-of-the-art performance for
automatic speech recognition (ASR). When using appropriate modeling units,
e.g., byte-pair encoded characters, these systems are in principal open
vocabulary systems. In practice, however, they often fail to recognize words
not seen during training, e.g., named entities, numbers or technical terms. To
alleviate this problem we supplement an end-to-end ASR system with a
word/phrase memory and a mechanism to access this memory to recognize the words
and phrases correctly. After the training of the ASR system, and when it has
already been deployed, a relevant word can be added or subtracted instantly
without the need for further training. In this paper we demonstrate that
through this mechanism our system is able to recognize more than 85% of newly
added words that it previously failed to recognize compared to a strong
baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Injecting Knowledge Base Information into End-to-End Joint Entity and Relation Extraction and Coreference Resolution. (arXiv:2107.02286v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Verlinden_S/0/1/0/all/0/1">Severine Verlinden</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaporojets_K/0/1/0/all/0/1">Klim Zaporojets</a>, <a href="http://arxiv.org/find/cs/1/au:+Deleu_J/0/1/0/all/0/1">Johannes Deleu</a>, <a href="http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1">Thomas Demeester</a>, <a href="http://arxiv.org/find/cs/1/au:+Develder_C/0/1/0/all/0/1">Chris Develder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02286">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a joint information extraction (IE) model, solving named entity
recognition, coreference resolution and relation extraction jointly over the
whole document. In particular, we study how to inject information from a
knowledge base (KB) in such IE model, based on unsupervised entity linking. The
used KB entity representations are learned from either (i) hyperlinked text
documents (Wikipedia), or (ii) a knowledge graph (Wikidata), and appear
complementary in raising IE performance. Representations of corresponding
entity linking (EL) candidates are added to text span representations of the
input document, and we experiment with (i) taking a weighted average of the EL
candidate representations based on their prior (in Wikipedia), and (ii) using
an attention scheme over the EL candidate list. Results demonstrate an increase
of up to 5% F1-score for the evaluated IE tasks on two datasets. Despite a
strong performance of the prior-based model, our quantitative and qualitative
analysis reveals the advantage of using the attention-based approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Experiments with adversarial attacks on text genres. (arXiv:2107.02246v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lepekhin_M/0/1/0/all/0/1">Mikhail Lepekhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharoff_S/0/1/0/all/0/1">Serge Sharoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02246">
                                    <div class="article-summary-box-inner">
                                        <span>Neural models based on pre-trained transformers, such as BERT or XLM-RoBERTa,
demonstrate SOTA results in many NLP tasks, including non-topical
classification, such as genre identification. However, often these approaches
exhibit low reliability to minor alterations of the test texts. A related
probelm concerns topical biases in the training corpus, for example, the
prevalence of words on a specific topic in a specific genre can trick the genre
classifier to recognise any text on this topic in this genre. In order to
mitigate the reliability problem, this paper investigates techniques for
attacking genre classifiers to understand the limitations of the transformer
models and to improve their performance. While simple text attacks, such as
those based on word replacement using keywords extracted by tf-idf, are not
capable of deceiving powerful models like XLM-RoBERTa, we show that
embedding-based algorithms which can replace some of the most &#x60;&#x60;significant&#x27;&#x27;
words with words similar to them, for example, TextFooler, have the ability to
influence model predictions in a significant proportion of cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying negativity factors from social media text corpus using sentiment analysis method. (arXiv:2107.02175v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aimal_M/0/1/0/all/0/1">Mohammad Aimal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakhtyar_M/0/1/0/all/0/1">Maheen Bakhtyar</a>, <a href="http://arxiv.org/find/cs/1/au:+Baber_J/0/1/0/all/0/1">Junaid Baber</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakho_S/0/1/0/all/0/1">Sadia Lakho</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammad_U/0/1/0/all/0/1">Umar Mohammad</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_W/0/1/0/all/0/1">Warda Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Karim_J/0/1/0/all/0/1">Jahanvash Karim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02175">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic sentiment analysis play vital role in decision making. Many
organizations spend a lot of budget to understand their customer satisfaction
by manually going over their feedback/comments or tweets. Automatic sentiment
analysis can give overall picture of the comments received against any event,
product, or activity. Usually, the comments/tweets are classified into two main
classes that are negative or positive. However, the negative comments are too
abstract to understand the basic reason or the context. organizations are
interested to identify the exact reason for the negativity. In this research
study, we hierarchically goes down into negative comments, and link them with
more classes. Tweets are extracted from social media sites such as Twitter and
Facebook. If the sentiment analysis classifies any tweet into negative class,
then we further try to associates that negative comments with more possible
negative classes. Based on expert opinions, the negative comments/tweets are
further classified into 8 classes. Different machine learning algorithms are
evaluated and their accuracy are reported.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalizing Nucleus Recognition Model in Multi-source Images via Pruning. (arXiv:2107.02500v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jiatong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chenglu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_C/0/1/0/all/0/1">Can Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Honglin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shichuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02500">
                                    <div class="article-summary-box-inner">
                                        <span>Ki67 is a significant biomarker in the diagnosis and prognosis of cancer,
whose index can be evaluated by quantifying its expression in Ki67
immunohistochemistry (IHC) stained images. However, quantitative analysis on
multi-source Ki67 images is yet a challenging task in practice due to
cross-domain distribution differences, which result from imaging variation,
staining styles, and lesion types. Many recent studies have made some efforts
on domain generalization (DG), whereas there are still some noteworthy
limitations. Specifically in the case of Ki67 images, learning invariant
representation is at the mercy of the insufficient number of domains and the
cell categories mismatching in different domains. In this paper, we propose a
novel method to improve DG by searching the domain-agnostic subnetwork in a
domain merging scenario. Partial model parameters are iteratively pruned
according to the domain gap, which is caused by the data converting from a
single domain into merged domains during training. In addition, the model is
optimized by fine-tuning on merged domains to eliminate the interference of
class mismatching among various domains. Furthermore, an appropriate
implementation is attained by applying the pruning method to different parts of
the framework. Compared with known DG methods, our method yields excellent
performance in multiclass nucleus recognition of Ki67 IHC images, especially in
the lost category cases. Moreover, our competitive results are also evaluated
on the public dataset over the state-of-the-art DG methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From General to Specific: Online Updating for Blind Super-Resolution. (arXiv:2107.02398v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guixuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhengxiong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_Z/0/1/0/all/0/1">Zhi Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuwu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02398">
                                    <div class="article-summary-box-inner">
                                        <span>Most deep learning-based super-resolution (SR) methods are not
image-specific: 1) They are exhaustively trained on datasets synthesized by
predefined blur kernels (\eg bicubic), regardless of the domain gap with test
images. 2) Their model weights are fixed during testing, which means that test
images with various degradations are super-resolved by the same set of weights.
However, degradations of real images are various and unknown (\ie blind SR). It
is hard for a single model to perform well in all cases. To address these
issues, we propose an online super-resolution (ONSR) method. It does not rely
on predefined blur kernels and allows the model weights to be updated according
to the degradation of the test image. Specifically, ONSR consists of two
branches, namely internal branch (IB) and external branch (EB). IB could learn
the specific degradation of the given test LR image, and EB could learn to
super resolve images degraded by the learned degradation. In this way, ONSR
could customize a specific model for each test image, and thus could be more
tolerant with various degradations in real applications. Extensive experiments
on both synthesized and real-world images show that ONSR can generate more
visually favorable SR results and achieve state-of-the-art performance in blind
SR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Segmentation Alternative Technique: Segmentation Domain Generation. (arXiv:2107.02525v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rogoz_A/0/1/0/all/0/1">Ana-Cristina Rogoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Muntean_R/0/1/0/all/0/1">Radu Muntean</a>, <a href="http://arxiv.org/find/cs/1/au:+Cobeli_S/0/1/0/all/0/1">Stefan Cobeli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02525">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting objects of interest in images was always a compelling task to
automate. In recent years this task was more and more explored using deep
learning techniques, mostly using region-based convolutional networks. In this
project we propose an alternative semantic segmentation technique making use of
Generative Adversarial Networks. We consider semantic segmentation to be a
domain transfer problem. Thus, we train a feed forward network (FFNN) to
receive as input a seed real image and generate as output its segmentation
mask.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Integrating Circle Kernels into Convolutional Neural Networks. (arXiv:2107.02451v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1">Kun He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yixiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hopcroft_J/0/1/0/all/0/1">John E. Hopcroft</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02451">
                                    <div class="article-summary-box-inner">
                                        <span>The square kernel is a standard unit for contemporary Convolutional Neural
Networks (CNNs), as it fits well on the tensor computation for the convolution
operation. However, the receptive field in the human visual system is actually
isotropic like a circle. Motivated by this observation, we propose using circle
kernels with isotropic receptive fields for the convolution, and our training
takes approximately equivalent amount of calculation when compared with the
corresponding CNN with square kernels. Our preliminary experiments demonstrate
the rationality of circle kernels. We then propose a kernel boosting strategy
that integrates the circle kernels with square kernels for the training and
inference, and we further let the kernel size/radius be learnable during the
training. Note that we reparameterize the circle kernels or integrated kernels
before the inference, thus taking no extra computation as well as the number of
parameter overhead for the testing. Extensive experiments on several standard
datasets, ImageNet, CIFAR-10 and CIFAR-100, using the circle kernels or
integrated kernels on typical existing CNNs, show that our approach exhibits
highly competitive performance. Specifically, on ImageNet with standard data
augmentation, our approach dramatically boosts the performance of
MobileNetV3-Small by 5.20% top-1 accuracy and 3.39% top-5 accuracy, and boosts
the performance of MobileNetV3-Large by 2.16% top-1 accuracy and 1.18% top-5
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hear Me Out: Fusional Approaches for Audio Augmented Temporal Action Localization. (arXiv:2106.14118v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bagchi_A/0/1/0/all/0/1">Anurag Bagchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_J/0/1/0/all/0/1">Jazib Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_D/0/1/0/all/0/1">Dolton Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarvadevabhatla_R/0/1/0/all/0/1">Ravi Kiran Sarvadevabhatla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14118">
                                    <div class="article-summary-box-inner">
                                        <span>State of the art architectures for untrimmed video Temporal Action
Localization (TAL) have only considered RGB and Flow modalities, leaving the
information-rich audio modality totally unexploited. Audio fusion has been
explored for the related but arguably easier problem of trimmed (clip-level)
action recognition. However, TAL poses a unique set of challenges. In this
paper, we propose simple but effective fusion-based approaches for TAL. To the
best of our knowledge, our work is the first to jointly consider audio and
video modalities for supervised TAL. We experimentally show that our schemes
consistently improve performance for state of the art video-only TAL
approaches. Specifically, they help achieve new state of the art performance on
large-scale benchmark datasets - ActivityNet-1.3 (54.34 mAP@0.5) and THUMOS14
(57.18 mAP@0.5). Our experiments include ablations involving multiple fusion
schemes, modality combinations and TAL architectures. Our code, models and
associated data will be made available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimizing L1 over L2 norms on the gradient. (arXiv:2101.00809v2 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Wang_C/0/1/0/all/0/1">Chao Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Tao_M/0/1/0/all/0/1">Min Tao</a>, <a href="http://arxiv.org/find/math/1/au:+Chuah_C/0/1/0/all/0/1">Chen-Nee Chuah</a>, <a href="http://arxiv.org/find/math/1/au:+Nagy_J/0/1/0/all/0/1">James Nagy</a>, <a href="http://arxiv.org/find/math/1/au:+Lou_Y/0/1/0/all/0/1">Yifei Lou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00809">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the L1/L2 minimization on the gradient for imaging
applications. Several recent works have demonstrated that L1/L2 is better than
the L1 norm when approximating the L0 norm to promote sparsity. Consequently,
we postulate that applying L1/L2 on the gradient is better than the classic
total variation (the L1 norm on the gradient) to enforce the sparsity of the
image gradient. To verify our hypothesis, we consider a constrained formulation
to reveal empirical evidence on the superiority of L1/L2 over L1 when
recovering piecewise constant signals from low-frequency measurements.
Numerically, we design a specific splitting scheme, under which we can prove
subsequential and global convergence for the alternating direction method of
multipliers (ADMM) under certain conditions. Experimentally, we demonstrate
visible improvements of L1/L2 over L1 and other nonconvex regularizations for
image recovery from low-frequency measurements and two medical applications of
MRI and CT reconstruction. All the numerical results show the efficiency of our
proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Hypo-plastic Left Heart Syndrome in Fetal Ultrasound via Disease-specific Atlas Maps. (arXiv:2107.02643v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Budd_S/0/1/0/all/0/1">Samuel Budd</a>, <a href="http://arxiv.org/find/eess/1/au:+Sinclair_M/0/1/0/all/0/1">Matthew Sinclair</a>, <a href="http://arxiv.org/find/eess/1/au:+Day_T/0/1/0/all/0/1">Thomas Day</a>, <a href="http://arxiv.org/find/eess/1/au:+Vlontzos_A/0/1/0/all/0/1">Athanasios Vlontzos</a>, <a href="http://arxiv.org/find/eess/1/au:+Tan_J/0/1/0/all/0/1">Jeremy Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tianrui Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Matthew_J/0/1/0/all/0/1">Jaqueline Matthew</a>, <a href="http://arxiv.org/find/eess/1/au:+Skelton_E/0/1/0/all/0/1">Emily Skelton</a>, <a href="http://arxiv.org/find/eess/1/au:+Simpson_J/0/1/0/all/0/1">John Simpson</a>, <a href="http://arxiv.org/find/eess/1/au:+Razavi_R/0/1/0/all/0/1">Reza Razavi</a>, <a href="http://arxiv.org/find/eess/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Robinson_E/0/1/0/all/0/1">Emma C. Robinson</a>, <a href="http://arxiv.org/find/eess/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02643">
                                    <div class="article-summary-box-inner">
                                        <span>Fetal ultrasound screening during pregnancy plays a vital role in the early
detection of fetal malformations which have potential long-term health impacts.
The level of skill required to diagnose such malformations from live ultrasound
during examination is high and resources for screening are often limited. We
present an interpretable, atlas-learning segmentation method for automatic
diagnosis of Hypo-plastic Left Heart Syndrome (HLHS) from a single &#x60;4 Chamber
Heart&#x27; view image. We propose to extend the recently introduced
Image-and-Spatial Transformer Networks (Atlas-ISTN) into a framework that
enables sensitising atlas generation to disease. In this framework we can
jointly learn image segmentation, registration, atlas construction and disease
prediction while providing a maximum level of clinical interpretability
compared to direct image classification methods. As a result our segmentation
allows diagnoses competitive with expert-derived manual diagnosis and yields an
AUC-ROC of 0.978 (1043 cases for training, 260 for validation and 325 for
testing).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Contrast MRI Super-Resolution via a Multi-Stage Integration Network. (arXiv:2105.08949v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Feng_C/0/1/0/all/0/1">Chun-Mei Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_H/0/1/0/all/0/1">Huazhu Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuan_S/0/1/0/all/0/1">Shuhao Yuan</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08949">
                                    <div class="article-summary-box-inner">
                                        <span>Super-resolution (SR) plays a crucial role in improving the image quality of
magnetic resonance imaging (MRI). MRI produces multi-contrast images and can
provide a clear display of soft tissues. However, current super-resolution
methods only employ a single contrast, or use a simple multi-contrast fusion
mechanism, ignoring the rich relations among different contrasts, which are
valuable for improving SR. In this work, we propose a multi-stage integration
network (i.e., MINet) for multi-contrast MRI SR, which explicitly models the
dependencies between multi-contrast images at different stages to guide image
SR. In particular, our MINet first learns a hierarchical feature representation
from multiple convolutional stages for each of different-contrast image.
Subsequently, we introduce a multi-stage integration module to mine the
comprehensive relations between the representations of the multi-contrast
images. Specifically, the module matches each representation with all other
features, which are integrated in terms of their similarities to obtain an
enriched representation. Extensive experiments on fastMRI and real-world
clinical datasets demonstrate that 1) our MINet outperforms state-of-the-art
multi-contrast SR methods in terms of various metrics and 2) our multi-stage
integration module is able to excavate complex interactions among
multi-contrast features at different stages, leading to improved target-image
quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Confidence-based Out-of-Distribution Detection: A Comparative Study and Analysis. (arXiv:2107.02568v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Berger_C/0/1/0/all/0/1">Christoph Berger</a>, <a href="http://arxiv.org/find/cs/1/au:+Paschali_M/0/1/0/all/0/1">Magdalini Paschali</a>, <a href="http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamnitsas_K/0/1/0/all/0/1">Konstantinos Kamnitsas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02568">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification models deployed in the real world may receive inputs
outside the intended data distribution. For critical applications such as
clinical decision making, it is important that a model can detect such
out-of-distribution (OOD) inputs and express its uncertainty. In this work, we
assess the capability of various state-of-the-art approaches for
confidence-based OOD detection through a comparative study and in-depth
analysis. First, we leverage a computer vision benchmark to reproduce and
compare multiple OOD detection methods. We then evaluate their capabilities on
the challenging task of disease classification using chest X-rays. Our study
shows that high performance in a computer vision task does not directly
translate to accuracy in a medical imaging task. We analyse factors that affect
performance of the methods between the two tasks. Our results provide useful
insights for developing the next generation of OOD detection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepOPG: Improving Orthopantomogram Finding Summarization with Weak Supervision. (arXiv:2103.08290v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_T/0/1/0/all/0/1">Tzu-Ming Harry Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yin-Chih Chelsea Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08290">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical finding summaries from an orthopantomogram, or a dental panoramic
radiograph, have significant potential to improve patient communication and
speed up clinical judgments. While orthopantomogram is a first-line tool for
dental examinations, no existing work has explored the summarization of
findings from it. A finding summary has to find teeth in the imaging study and
label the teeth with several types of past treatments. To tackle the problem,
we developDeepOPG that breaks the summarization process into functional
segmentation and tooth localization, the latter of which is further refined by
a novel dental coherence module. We also leverage weak supervision labels to
improve detection results in a reinforcement learning scenario. Experiments
show high efficacy of DeepOPG on finding summarization, achieving an overall
AUC of 88.2% in detecting six types of findings. The proposed dental coherence
and weak supervision both are shown to improve DeepOPG by adding 5.9% and 0.4%
to AP@IoU&#x3D;0.5.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learned Visual Navigation for Under-Canopy Agricultural Robots. (arXiv:2107.02792v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sivakumar_A/0/1/0/all/0/1">Arun Narenthiran Sivakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Modi_S/0/1/0/all/0/1">Sahil Modi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasparino_M/0/1/0/all/0/1">Mateus Valverde Gasparino</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_C/0/1/0/all/0/1">Che Ellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Velasquez_A/0/1/0/all/0/1">Andres Eduardo Baquero Velasquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhary_G/0/1/0/all/0/1">Girish Chowdhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Saurabh Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02792">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a system for visually guided autonomous navigation of
under-canopy farm robots. Low-cost under-canopy robots can drive between crop
rows under the plant canopy and accomplish tasks that are infeasible for
over-the-canopy drones or larger agricultural equipment. However, autonomously
navigating them under the canopy presents a number of challenges: unreliable
GPS and LiDAR, high cost of sensing, challenging farm terrain, clutter due to
leaves and weeds, and large variability in appearance over the season and
across crop types. We address these challenges by building a modular system
that leverages machine learning for robust and generalizable perception from
monocular RGB images from low-cost cameras, and model predictive control for
accurate control in challenging terrain. Our system, CropFollow, is able to
autonomously drive 485 meters per intervention on average, outperforming a
state-of-the-art LiDAR based system (286 meters per intervention) in extensive
field testing spanning over 25 km.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicate correlation learning for scene graph generation. (arXiv:2107.02713v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tao_L/0/1/0/all/0/1">Leitian Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_L/0/1/0/all/0/1">Li Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1">Nannan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xianhang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yaosi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhenzhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02713">
                                    <div class="article-summary-box-inner">
                                        <span>For a typical Scene Graph Generation (SGG) method, there is often a large gap
in the performance of the predicates&#x27; head classes and tail classes. This
phenomenon is mainly caused by the semantic overlap between different
predicates as well as the long-tailed data distribution. In this paper, a
Predicate Correlation Learning (PCL) method for SGG is proposed to address the
above two problems by taking the correlation between predicates into
consideration. To describe the semantic overlap between strong-correlated
predicate classes, a Predicate Correlation Matrix (PCM) is defined to quantify
the relationship between predicate pairs, which is dynamically updated to
remove the matrix&#x27;s long-tailed bias. In addition, PCM is integrated into a
Predicate Correlation Loss function ($L_{PC}$) to reduce discouraging gradients
of unannotated classes. The proposed method is evaluated on Visual Genome
benchmark, where the performance of the tail classes is significantly improved
when built on the existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-based Adversarial Appearance Learning of Augmented Pedestrians. (arXiv:2107.02673v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Strauss_K/0/1/0/all/0/1">Kevin Strauss</a>, <a href="http://arxiv.org/find/cs/1/au:+Savkin_A/0/1/0/all/0/1">Artem Savkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tombari_F/0/1/0/all/0/1">Federico Tombari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02673">
                                    <div class="article-summary-box-inner">
                                        <span>Synthetic data became already an essential component of machine
learning-based perception in the field of autonomous driving. Yet it still
cannot replace real data completely due to the sim2real domain shift. In this
work, we propose a method that leverages the advantages of the augmentation
process and adversarial training to synthesize realistic data for the
pedestrian recognition task. Our approach utilizes an attention mechanism
driven by an adversarial loss to learn domain discrepancies and improve
sim2real adaptation. Our experiments confirm that the proposed adaptation
method is robust to such discrepancies and reveals both visual realism and
semantic consistency. Furthermore, we evaluate our data generation pipeline on
the task of pedestrian recognition and demonstrate that generated data resemble
properties of the real domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Disentangled Representation Implicitly via Transformer for Occluded Person Re-Identification. (arXiv:2107.02380v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1">Mengxi Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xinhua Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jian Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02380">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification (re-ID) under various occlusions has been a
long-standing challenge as person images with different types of occlusions
often suffer from misalignment in image matching and ranking. Most existing
methods tackle this challenge by aligning spatial features of body parts
according to external semantic cues or feature similarities but this alignment
approach is complicated and sensitive to noises. We design DRL-Net, a
disentangled representation learning network that handles occluded re-ID
without requiring strict person image alignment or any additional supervision.
Leveraging transformer architectures, DRL-Net achieves alignment-free re-ID via
global reasoning of local features of occluded person images. It measures image
similarity by automatically disentangling the representation of undefined
semantic components, e.g., human body parts or obstacles, under the guidance of
semantic preference object queries in the transformer. In addition, we design a
decorrelation constraint in the transformer decoder and impose it over object
queries for better focus on different semantic components. To better eliminate
interference from occlusions, we design a contrast feature learning technique
(CFL) for better separation of occlusion features and discriminative ID
features. Extensive experiments over occluded and holistic re-ID benchmarks
(Occluded-DukeMTMC, Market1501 and DukeMTMC) show that the DRL-Net achieves
superior re-ID performance consistently and outperforms the state-of-the-art by
large margins for Occluded-DukeMTMC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining EfficientNet and Vision Transformers for Video Deepfake Detection. (arXiv:2107.02612v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Coccomini_D/0/1/0/all/0/1">Davide Coccomini</a>, <a href="http://arxiv.org/find/cs/1/au:+Messina_N/0/1/0/all/0/1">Nicola Messina</a>, <a href="http://arxiv.org/find/cs/1/au:+Gennaro_C/0/1/0/all/0/1">Claudio Gennaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Falchi_F/0/1/0/all/0/1">Fabrizio Falchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02612">
                                    <div class="article-summary-box-inner">
                                        <span>Deepfakes are the result of digital manipulation to obtain credible videos in
order to deceive the viewer. This is done through deep learning techniques
based on autoencoders or GANs that become more accessible and accurate year
after year, resulting in fake videos that are very difficult to distinguish
from real ones. Traditionally, CNN networks have been used to perform deepfake
detection, with the best results obtained using methods based on EfficientNet
B7. In this study, we combine various types of Vision Transformers with a
convolutional EfficientNet B0 used as a feature extractor, obtaining comparable
results with some very recent methods that use Vision Transformers. Differently
from the state-of-the-art approaches, we use neither distillation nor ensemble
methods. The best model achieved an AUC of 0.951 and an F1 score of 88.0%, very
close to the state-of-the-art on the DeepFake Detection Challenge (DFDC).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DocSynth: A Layout Guided Approach for Controllable Document Image Synthesis. (arXiv:2107.02638v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1">Sanket Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Riba_P/0/1/0/all/0/1">Pau Riba</a>, <a href="http://arxiv.org/find/cs/1/au:+Llados_J/0/1/0/all/0/1">Josep Llad&#xf3;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_U/0/1/0/all/0/1">Umapada Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02638">
                                    <div class="article-summary-box-inner">
                                        <span>Despite significant progress on current state-of-the-art image generation
models, synthesis of document images containing multiple and complex object
layouts is a challenging task. This paper presents a novel approach, called
DocSynth, to automatically synthesize document images based on a given layout.
In this work, given a spatial layout (bounding boxes with object categories) as
a reference by the user, our proposed DocSynth model learns to generate a set
of realistic document images consistent with the defined layout. Also, this
framework has been adapted to this work as a superior baseline model for
creating synthetic document image datasets for augmenting real data during
training for document layout analysis tasks. Different sets of learning
objectives have been also used to improve the model performance.
Quantitatively, we also compare the generated results of our model with real
data using standard evaluation metrics. The results highlight that our model
can successfully generate realistic and diverse document images with multiple
objects. We also present a comprehensive qualitative analysis summary of the
different scopes of synthetic image generation tasks. Lastly, to our knowledge
this is the first work of its kind.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-based Jitter: Improving Visual Recognition on Long-tailed Data with Diversity In Memory. (arXiv:2008.09809v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+yang_Y/0/1/0/all/0/1">Yi yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenhui Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yifan Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.09809">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers deep visual recognition on long-tailed data. To be
general, we consider two applied scenarios, \ie, deep classification and deep
metric learning. Under the long-tailed data distribution, the majority classes
(\ie, tail classes) only occupy relatively few samples and are prone to lack of
within-class diversity. A radical solution is to augment the tail classes with
higher diversity. To this end, we introduce a simple and reliable method named
Memory-based Jitter (MBJ). We observe that during training, the deep model
constantly changes its parameters after every iteration, yielding the
phenomenon of \emph{weight jitters}. Consequentially, given a same image as the
input, two historical editions of the model generate two different features in
the deeply-embedded space, resulting in \emph{feature jitters}. Using a memory
bank, we collect these (model or feature) jitters across multiple training
iterations and get the so-called Memory-based Jitter. The accumulated jitters
enhance the within-class diversity for the tail classes and consequentially
improves long-tailed visual recognition. With slight modifications, MBJ is
applicable for two fundamental visual recognition tasks, \emph{i.e.}, deep
image classification and deep metric learning (on long-tailed data). Extensive
experiments on five long-tailed classification benchmarks and two deep metric
learning benchmarks demonstrate significant improvement. Moreover, the achieved
performance are on par with the state of the art on both tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PillarSegNet: Pillar-based Semantic Grid Map Estimation using Sparse LiDAR Data. (arXiv:2105.04169v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fei_J/0/1/0/all/0/1">Juncong Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1">Kunyu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Heidenreich_P/0/1/0/all/0/1">Philipp Heidenreich</a>, <a href="http://arxiv.org/find/cs/1/au:+Bieder_F/0/1/0/all/0/1">Frank Bieder</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiller_C/0/1/0/all/0/1">Christoph Stiller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04169">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic understanding of the surrounding environment is essential for
automated vehicles. The recent publication of the SemanticKITTI dataset
stimulates the research on semantic segmentation of LiDAR point clouds in urban
scenarios. While most existing approaches predict sparse pointwise semantic
classes for the sparse input LiDAR scan, we propose PillarSegNet to be able to
output a dense semantic grid map. In contrast to a previously proposed grid map
method, PillarSegNet uses PointNet to learn features directly from the 3D point
cloud and then conducts 2D semantic segmentation in the top view. To train and
evaluate our approach, we use both sparse and dense ground truth, where the
dense ground truth is obtained from multiple superimposed scans. Experimental
results on the SemanticKITTI dataset show that PillarSegNet achieves a
performance gain of about 10% mIoU over the state-of-the-art grid map method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Multimodal Fusion with TupleInfoNCE. (arXiv:2107.02575v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yunze Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Q/0/1/0/all/0/1">Qingnan Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanghang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Funkhouser_T/0/1/0/all/0/1">Thomas Funkhouser</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_L/0/1/0/all/0/1">Li Yi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02575">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a method for representation learning of multimodal data
using contrastive losses. A traditional approach is to contrast different
modalities to learn the information shared between them. However, that approach
could fail to learn the complementary synergies between modalities that might
be useful for downstream tasks. Another approach is to concatenate all the
modalities into a tuple and then contrast positive and negative tuple
correspondences. However, that approach could consider only the stronger
modalities while ignoring the weaker ones. To address these issues, we propose
a novel contrastive learning objective, TupleInfoNCE. It contrasts tuples based
not only on positive and negative correspondences but also by composing new
negative tuples using modalities describing different scenes. Training with
these additional negatives encourages the learning model to examine the
correspondences among modalities in the same tuple, ensuring that weak
modalities are not ignored. We provide a theoretical justification based on
mutual information for why this approach works, and we propose a sample
optimization algorithm to generate positive and negative samples to maximize
training efficacy. We find that TupleInfoNCE significantly outperforms the
previous state of the arts on three different downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision Xformers: Efficient Attention for Image Classification. (arXiv:2107.02239v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeevan_P/0/1/0/all/0/1">Pranav Jeevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethi_A/0/1/0/all/0/1">Amit Sethi</a> (Indian Institute of Technology Bombay)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02239">
                                    <div class="article-summary-box-inner">
                                        <span>Linear attention mechanisms provide hope for overcoming the bottleneck of
quadratic complexity which restricts application of transformer models in
vision tasks. We modify the ViT architecture to work on longer sequence data by
replacing the quadratic attention with efficient transformers like Performer,
Linformer and Nystr\&quot;omformer of linear complexity creating Vision X-formers
(ViX). We show that ViX performs better than ViT in image classification
consuming lesser computing resources. We further show that replacing the
embedding linear layer by convolutional layers in ViX further increases their
performance. Our test on recent visions transformer models like LeViT and
Compact Convolutional Transformer (CCT) show that replacing the attention with
Nystr\&quot;omformer or Performer saves GPU usage and memory without deteriorating
performance. Incorporating these changes can democratize transformers by making
them accessible to those with limited data and computing resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Feature Information Extraction for Interest Point Detection: A Comprehensive Review. (arXiv:2106.07929v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jing_J/0/1/0/all/0/1">Junfeng Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1">Tian Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weichuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yongsheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changming Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07929">
                                    <div class="article-summary-box-inner">
                                        <span>Interest point detection is one of the most fundamental and critical problems
in computer vision and image processing. In this paper, we carry out a
comprehensive review on image feature information (IFI) extraction techniques
for interest point detection. To systematically introduce how the existing
interest point detection methods extract IFI from an input image, we propose a
taxonomy of the IFI extraction techniques for interest point detection.
According to this taxonomy, we discuss different types of IFI extraction
techniques for interest point detection. Furthermore, we identify the main
unresolved issues related to the existing IFI extraction techniques for
interest point detection and any interest point detection methods that have not
been discussed before. The existing popular datasets and evaluation standards
are provided and the performances for eighteen state-of-the-art approaches are
evaluated and discussed. Moreover, future research directions on IFI extraction
techniques for interest point detection are elaborated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-To-End Data-Dependent Routing in Multi-Path Neural Networks. (arXiv:2107.02450v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tissera_D/0/1/0/all/0/1">Dumindu Tissera</a>, <a href="http://arxiv.org/find/cs/1/au:+Vithanage_K/0/1/0/all/0/1">Kasun Vithanage</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijessinghe_R/0/1/0/all/0/1">Rukshan Wijessinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_S/0/1/0/all/0/1">Subha Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigo_R/0/1/0/all/0/1">Ranga Rodrigo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02450">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are known to give better performance with increased depth due
to their ability to learn more abstract features. Although the deepening of
networks has been well established, there is still room for efficient feature
extraction within a layer which would reduce the need for mere parameter
increment. The conventional widening of networks by having more filters in each
layer introduces a quadratic increment of parameters. Having multiple parallel
convolutional/dense operations in each layer solves this problem, but without
any context-dependent allocation of resources among these operations: the
parallel computations tend to learn similar features making the widening
process less effective. Therefore, we propose the use of multi-path neural
networks with data-dependent resource allocation among parallel computations
within layers, which also lets an input to be routed end-to-end through these
parallel paths. To do this, we first introduce a cross-prediction based
algorithm between parallel tensors of subsequent layers. Second, we further
reduce the routing overhead by introducing feature-dependent cross-connections
between parallel tensors of successive layers. Our multi-path networks show
superior performance to existing widening and adaptive feature extraction, and
even ensembles, and deeper networks at similar complexity in the image
recognition task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label noise in segmentation networks : mitigation must deal with bias. (arXiv:2107.02189v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1">Eugene Vorontsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadoury_S/0/1/0/all/0/1">Samuel Kadoury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02189">
                                    <div class="article-summary-box-inner">
                                        <span>Imperfect labels limit the quality of predictions learned by deep neural
networks. This is particularly relevant in medical image segmentation, where
reference annotations are difficult to collect and vary significantly even
across expert annotators. Prior work on mitigating label noise focused on
simple models of mostly uniform noise. In this work, we explore biased and
unbiased errors artificially introduced to brain tumour annotations on MRI
data. We found that supervised and semi-supervised segmentation methods are
robust or fairly robust to unbiased errors but sensitive to biased errors. It
is therefore important to identify the sorts of errors expected in medical
image labels and especially mitigate the biased errors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Cervical Whole Slide Image Analysis Framework Based on Multi-scale Semantic and Spatial Deep Features. (arXiv:2106.15113v2 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Ziquan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Shenghua Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiuli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1">Shaoqun Zeng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15113">
                                    <div class="article-summary-box-inner">
                                        <span>Digital gigapixel whole slide image (WSI) is widely used in clinical
diagnosis, and automated WSI analysis is key for computer-aided diagnosis.
Currently, analyzing the integrated descriptor of probabilities or feature maps
from massive local patches encoded by ResNet classifier is the main manner for
WSI-level prediction. Feature representations of the sparse and tiny lesion
cells in cervical slides, however, are still challengeable for the
under-promoted upstream encoders, while the unused spatial representations of
cervical cells are the available features to supply the semantics analysis. As
well as patches sampling with overlap and repetitive processing incur the
inefficiency and the unpredictable side effect. This study designs a novel
inline connection network (InCNet) by enriching the multi-scale connectivity to
build the lightweight model named You Only Look Cytopathology Once (YOLCO) with
the additional supervision of spatial information. The proposed model allows
the input size enlarged to megapixel that can stitch the WSI without any
overlap by the average repeats decreased from $10^3\sim10^4$ to $10^1\sim10^2$
for collecting features and predictions at two scales. Based on Transformer for
classifying the integrated multi-scale multi-task features, the experimental
results appear $0.872$ AUC score better and $2.51\times$ faster than the best
conventional method in WSI classification on multicohort datasets of 2,019
slides from four scanning devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Hierarchical Dual Model of Environment- and Place-Specific Utility for Visual Place Recognition. (arXiv:2107.02440v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keetha_N/0/1/0/all/0/1">Nikhil Varma Keetha</a>, <a href="http://arxiv.org/find/cs/1/au:+Milford_M/0/1/0/all/0/1">Michael Milford</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Sourav Garg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02440">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Place Recognition (VPR) approaches have typically attempted to match
places by identifying visual cues, image regions or landmarks that have high
&#x60;&#x60;utility&#x27;&#x27; in identifying a specific place. But this concept of utility is not
singular - rather it can take a range of forms. In this paper, we present a
novel approach to deduce two key types of utility for VPR: the utility of
visual cues &#x60;specific&#x27; to an environment, and to a particular place. We employ
contrastive learning principles to estimate both the environment- and
place-specific utility of Vector of Locally Aggregated Descriptors (VLAD)
clusters in an unsupervised manner, which is then used to guide local feature
matching through keypoint selection. By combining these two utility measures,
our approach achieves state-of-the-art performance on three challenging
benchmark datasets, while simultaneously reducing the required storage and
compute time. We provide further analysis demonstrating that unsupervised
cluster selection results in semantically meaningful results, that finer
grained categorization often has higher utility for VPR than high level
semantic categorization (e.g. building, road), and characterise how these two
utility measures vary across different places and environments. Source code is
made publicly available at https://github.com/Nik-V9/HEAPUtil.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatiotemporal Fusion in Remote Sensing. (arXiv:2107.02701v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Albanwan_H/0/1/0/all/0/1">Hessah Albanwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Rongjun Qin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02701">
                                    <div class="article-summary-box-inner">
                                        <span>Remote sensing images and techniques are powerful tools to investigate earth
surface. Data quality is the key to enhance remote sensing applications and
obtaining a clear and noise-free set of data is very difficult in most
situations due to the varying acquisition (e.g., atmosphere and season),
sensor, and platform (e.g., satellite angles and sensor characteristics)
conditions. With the increasing development of satellites, nowadays Terabytes
of remote sensing images can be acquired every day. Therefore, information and
data fusion can be particularly important in the remote sensing community. The
fusion integrates data from various sources acquired asynchronously for
information extraction, analysis, and quality improvement. In this chapter, we
aim to discuss the theory of spatiotemporal fusion by investigating previous
works, in addition to describing the basic concepts and some of its
applications by summarizing our prior and ongoing works.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Knowledge-Transfer for Learned Image Reconstruction. (arXiv:2107.02572v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Barbano_R/0/1/0/all/0/1">Riccardo Barbano</a>, <a href="http://arxiv.org/find/eess/1/au:+Kereta_Z/0/1/0/all/0/1">Zeljko Kereta</a>, <a href="http://arxiv.org/find/eess/1/au:+Hauptmann_A/0/1/0/all/0/1">Andreas Hauptmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Arridge_S/0/1/0/all/0/1">Simon R. Arridge</a>, <a href="http://arxiv.org/find/eess/1/au:+Jin_B/0/1/0/all/0/1">Bangti Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02572">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based image reconstruction approaches have demonstrated
impressive empirical performance in many imaging modalities. These approaches
generally require a large amount of high-quality training data, which is often
not available. To circumvent this issue, we develop a novel unsupervised
knowledge-transfer paradigm for learned iterative reconstruction within a
Bayesian framework. The proposed approach learns an iterative reconstruction
network in two phases. The first phase trains a reconstruction network with a
set of ordered pairs comprising of ground truth images and measurement data.
The second phase fine-tunes the pretrained network to the measurement data
without supervision. Furthermore, the framework delivers uncertainty
information over the reconstructed image. We present extensive experimental
results on low-dose and sparse-view computed tomography, showing that the
proposed framework significantly improves reconstruction quality not only
visually, but also quantitatively in terms of PSNR and SSIM, and is competitive
with several state-of-the-art supervised and unsupervised reconstruction
techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">General Purpose (GenP) Bioimage Ensemble of Handcrafted and Learned Features with Data Augmentation. (arXiv:1904.08084v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nanni_L/0/1/0/all/0/1">L. Nanni</a>, <a href="http://arxiv.org/find/cs/1/au:+Brahnam_S/0/1/0/all/0/1">S. Brahnam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghidoni_S/0/1/0/all/0/1">S. Ghidoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Maguolo_G/0/1/0/all/0/1">G. Maguolo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.08084">
                                    <div class="article-summary-box-inner">
                                        <span>Bioimage classification plays a crucial role in many biological problems. In
this work, we present a new General Purpose (GenP) ensemble that boosts
performance by combining local features, dense sampling features, and deep
learning approaches. First, we introduce three new methods for data
augmentation based on PCA/DCT; second, we show that different data augmentation
approaches can boost the performance of an ensemble of CNNs; and, finally, we
propose a set of handcrafted/learned descriptors that are highly generalizable.
Each handcrafted descriptor is used to train a different Support Vector Machine
(SVM), and the different SVMs are combined with the ensemble of CNNs. Our
method is evaluated on a diverse set of bioimage classification problems.
Results demonstrate that the proposed GenP bioimage ensemble obtains
state-of-the-art performance without any ad-hoc dataset tuning of parameters
(thus avoiding the risk of overfitting/overtraining).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A new smart-cropping pipeline for prostate segmentation using deep learning networks. (arXiv:2107.02476v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zaridis_D/0/1/0/all/0/1">Dimitrios G. Zaridis</a>, <a href="http://arxiv.org/find/eess/1/au:+Mylona_E/0/1/0/all/0/1">Eugenia Mylona</a>, <a href="http://arxiv.org/find/eess/1/au:+Marias_K/0/1/0/all/0/1">Kostas Marias</a>, <a href="http://arxiv.org/find/eess/1/au:+Papanikolaou_N/0/1/0/all/0/1">Nikolaos Papanikolaou</a>, <a href="http://arxiv.org/find/eess/1/au:+Tachos_N/0/1/0/all/0/1">Nikolaos S. Tachos</a>, <a href="http://arxiv.org/find/eess/1/au:+Fotiadis_D/0/1/0/all/0/1">Dimitrios I. Fotiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02476">
                                    <div class="article-summary-box-inner">
                                        <span>Prostate segmentation from magnetic resonance imaging (MRI) is a challenging
task. In recent years, several network architectures have been proposed to
automate this process and alleviate the burden of manual annotation. Although
the performance of these models has achieved promising results, there is still
room for improvement before these models can be used safely and effectively in
clinical practice. One of the major challenges in prostate MR image
segmentation is the presence of class imbalance in the image labels where the
background pixels dominate over the prostate. In the present work we propose a
DL-based pipeline for cropping the region around the prostate from MRI images
to produce a more balanced distribution of the foreground pixels (prostate) and
the background pixels and improve segmentation accuracy. The effect of
DL-cropping for improving the segmentation performance compared to standard
center-cropping is assessed using five popular DL networks for prostate
segmentation, namely U-net, U-net+, Res Unet++, Bridge U-net and Dense U-net.
The proposed smart-cropping outperformed the standard center cropping in terms
of segmentation accuracy for all the evaluated prostate segmentation networks.
In terms of Dice score, the highest improvement was achieved for the U-net+ and
ResU-net++ architectures corresponding to 8.9% and 8%, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Semantic Segmentation of Large-Scale Point Clouds with Random Sampling. (arXiv:2107.02389v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1">Qingyong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Bo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Linhai Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosa_S/0/1/0/all/0/1">Stefano Rosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yulan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhihua Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Trigoni_N/0/1/0/all/0/1">Niki Trigoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Markham_A/0/1/0/all/0/1">Andrew Markham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02389">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of efficient semantic segmentation of large-scale 3D
point clouds. By relying on expensive sampling techniques or computationally
heavy pre/post-processing steps, most existing approaches are only able to be
trained and operate over small-scale point clouds. In this paper, we introduce
RandLA-Net, an efficient and lightweight neural architecture to directly infer
per-point semantics for large-scale point clouds. The key to our approach is to
use random point sampling instead of more complex point selection approaches.
Although remarkably computation and memory efficient, random sampling can
discard key features by chance. To overcome this, we introduce a novel local
feature aggregation module to progressively increase the receptive field for
each 3D point, thereby effectively preserving geometric details. Comparative
experiments show that our RandLA-Net can process 1 million points in a single
pass up to 200x faster than existing approaches. Moreover, extensive
experiments on five large-scale point cloud datasets, including Semantic3D,
SemanticKITTI, Toronto3D, NPM3D and S3DIS, demonstrate the state-of-the-art
semantic segmentation performance of our RandLA-Net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Deep Learning Methods for Real-Time Surgical Instrument Segmentation in Laparoscopy. (arXiv:2107.02319v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Jha_D/0/1/0/all/0/1">Debesh Jha</a>, <a href="http://arxiv.org/find/eess/1/au:+Ali_S/0/1/0/all/0/1">Sharib Ali</a>, <a href="http://arxiv.org/find/eess/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>, <a href="http://arxiv.org/find/eess/1/au:+Johansen_D/0/1/0/all/0/1">Dag Johansen</a>, <a href="http://arxiv.org/find/eess/1/au:+Johansen_H/0/1/0/all/0/1">H&#xe5;vard D. Johansen</a>, <a href="http://arxiv.org/find/eess/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02319">
                                    <div class="article-summary-box-inner">
                                        <span>Minimally invasive surgery is a surgical intervention used to examine the
organs inside the abdomen and has been widely used due to its effectiveness
over open surgery. Due to the hardware improvements such as high definition
cameras, this procedure has significantly improved and new software methods
have demonstrated potential for computer-assisted procedures. However, there
exists challenges and requirements to improve detection and tracking of the
position of the instruments during these surgical procedures. To this end, we
evaluate and compare some popular deep learning methods that can be explored
for the automated segmentation of surgical instruments in laparoscopy, an
important step towards tool tracking. Our experimental results exhibit that the
Dual decoder attention network (DDANet) produces a superior result compared to
other recent deep learning methods. DDANet yields a Dice coefficient of 0.8739
and mean intersection-over-union of 0.8183 for the Robust Medical Instrument
Segmentation (ROBUST-MIS) Challenge 2019 dataset, at a real-time speed of
101.36 frames-per-second that is critical for such procedures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">S2FGAN: Semantically Aware Interactive Sketch-to-Face Translation. (arXiv:2011.14785v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md Zakir Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Gedeon_T/0/1/0/all/0/1">Tom Gedeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_S/0/1/0/all/0/1">Shafin Rahman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14785">
                                    <div class="article-summary-box-inner">
                                        <span>Interactive facial image manipulation attempts to edit single and multiple
face attributes using a photo-realistic face and/or semantic mask as input. In
the absence of the photo-realistic image (only sketch/mask available), previous
methods only retrieve the original face but ignore the potential of aiding
model controllability and diversity in the translation process. This paper
proposes a sketch-to-image generation framework called S2FGAN, aiming to
improve users&#x27; ability to interpret and flexibility of face attribute editing
from a simple sketch. The proposed framework modifies the constrained latent
space semantics trained on Generative Adversarial Networks (GANs). We employ
two latent spaces to control the face appearance and adjust the desired
attributes of the generated face. Instead of constraining the translation
process by using a reference image, the users can command the model to retouch
the generated images by involving the semantic information in the generation
process. In this way, our method can manipulate single or multiple face
attributes by only specifying attributes to be changed. Extensive experimental
results on CelebAMask-HQ dataset empirically shows our superior performance and
effectiveness on this task. Our method successfully outperforms
state-of-the-art methods on attribute manipulation by exploiting greater
control of attribute intensity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training. (arXiv:2104.14129v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianfei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lianmin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhewei Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dequan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14129">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing size of neural network models has been critical for
improvements in their accuracy, but device memory is not growing at the same
rate. This creates fundamental challenges for training neural networks within
limited memory environments. In this work, we propose ActNN, a memory-efficient
training framework that stores randomly quantized activations for back
propagation. We prove the convergence of ActNN for general network
architectures, and we characterize the impact of quantization on the
convergence via an exact expression for the gradient variance. Using our
theory, we propose novel mixed-precision quantization strategies that exploit
the activation&#x27;s heterogeneity across feature dimensions, samples, and layers.
These techniques can be readily applied to existing dynamic graph frameworks,
such as PyTorch, simply by substituting the layers. We evaluate ActNN on
mainstream computer vision models for classification, detection, and
segmentation tasks. On all these tasks, ActNN compresses the activation to 2
bits on average, with negligible accuracy loss. ActNN reduces the memory
footprint of the activation by 12x, and it enables training with a 6.6x to 14x
larger batch size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VTGAN: Semi-supervised Retinal Image Synthesis and Disease Prediction using Vision Transformers. (arXiv:2104.06757v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kamran_S/0/1/0/all/0/1">Sharif Amit Kamran</a>, <a href="http://arxiv.org/find/eess/1/au:+Hossain_K/0/1/0/all/0/1">Khondker Fariha Hossain</a>, <a href="http://arxiv.org/find/eess/1/au:+Tavakkoli_A/0/1/0/all/0/1">Alireza Tavakkoli</a>, <a href="http://arxiv.org/find/eess/1/au:+Zuckerbrod_S/0/1/0/all/0/1">Stewart Lee Zuckerbrod</a>, <a href="http://arxiv.org/find/eess/1/au:+Baker_S/0/1/0/all/0/1">Salah A. Baker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06757">
                                    <div class="article-summary-box-inner">
                                        <span>In Fluorescein Angiography (FA), an exogenous dye is injected in the
bloodstream to image the vascular structure of the retina. The injected dye can
cause adverse reactions such as nausea, vomiting, anaphylactic shock, and even
death. In contrast, color fundus imaging is a non-invasive technique used for
photographing the retina but does not have sufficient fidelity for capturing
its vascular structure. The only non-invasive method for capturing retinal
vasculature is optical coherence tomography-angiography (OCTA). However, OCTA
equipment is quite expensive, and stable imaging is limited to small areas on
the retina. In this paper, we propose a novel conditional generative
adversarial network (GAN) capable of simultaneously synthesizing FA images from
fundus photographs while predicting retinal degeneration. The proposed system
has the benefit of addressing the problem of imaging retinal vasculature in a
non-invasive manner as well as predicting the existence of retinal
abnormalities. We use a semi-supervised approach to train our GAN using
multiple weighted losses on different modalities of data. Our experiments
validate that the proposed architecture exceeds recent state-of-the-art
generative networks for fundus-to-angiography synthesis. Moreover, our vision
transformer-based discriminators generalize quite well on out-of-distribution
data sets for retinal disease prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAN++: Towards Efficient and Accurate End-to-End Spotting of Arbitrarily-Shaped Text. (arXiv:2105.00405v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuebo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Ding Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhibo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00405">
                                    <div class="article-summary-box-inner">
                                        <span>Scene text detection and recognition have been well explored in the past few
years. Despite the progress, efficient and accurate end-to-end spotting of
arbitrarily-shaped text remains challenging. In this work, we propose an
end-to-end text spotting framework, termed PAN++, which can efficiently detect
and recognize text of arbitrary shapes in natural scenes. PAN++ is based on the
kernel representation that reformulates a text line as a text kernel (central
region) surrounded by peripheral pixels. By systematically comparing with
existing scene text representations, we show that our kernel representation can
not only describe arbitrarily-shaped text but also well distinguish adjacent
text. Moreover, as a pixel-based representation, the kernel representation can
be predicted by a single fully convolutional network, which is very friendly to
real-time applications. Taking the advantages of the kernel representation, we
design a series of components as follows: 1) a computationally efficient
feature enhancement network composed of stacked Feature Pyramid Enhancement
Modules (FPEMs); 2) a lightweight detection head cooperating with Pixel
Aggregation (PA); and 3) an efficient attention-based recognition head with
Masked RoI. Benefiting from the kernel representation and the tailored
components, our method achieves high inference speed while maintaining
competitive accuracy. Extensive experiments show the superiority of our method.
For example, the proposed PAN++ achieves an end-to-end text spotting F-measure
of 64.9 at 29.2 FPS on the Total-Text dataset, which significantly outperforms
the previous best method. Code will be available at: https://git.io/PAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task Transformer Network for Joint MRI Reconstruction and Super-Resolution. (arXiv:2106.06742v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Feng_C/0/1/0/all/0/1">Chun-Mei Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_Y/0/1/0/all/0/1">Yunlu Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_H/0/1/0/all/0/1">Huazhu Fu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Y/0/1/0/all/0/1">Yong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06742">
                                    <div class="article-summary-box-inner">
                                        <span>The core problem of Magnetic Resonance Imaging (MRI) is the trade off between
acceleration and image quality. Image reconstruction and super-resolution are
two crucial techniques in Magnetic Resonance Imaging (MRI). Current methods are
designed to perform these tasks separately, ignoring the correlations between
them. In this work, we propose an end-to-end task transformer network
(T$^2$Net) for joint MRI reconstruction and super-resolution, which allows
representations and feature transmission to be shared between multiple task to
achieve higher-quality, super-resolved and motion-artifacts-free images from
highly undersampled and degenerated MRI data. Our framework combines both
reconstruction and super-resolution, divided into two sub-branches, whose
features are expressed as queries and keys. Specifically, we encourage joint
feature learning between the two tasks, thereby transferring accurate task
information. We first use two separate CNN branches to extract task-specific
features. Then, a task transformer module is designed to embed and synthesize
the relevance between the two tasks. Experimental results show that our
multi-task model significantly outperforms advanced sequential methods, both
quantitatively and qualitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SUTD-TrafficQA: A Question Answering Benchmark and an Efficient Network for Video Reasoning over Traffic Events. (arXiv:2103.15538v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Li Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">He Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15538">
                                    <div class="article-summary-box-inner">
                                        <span>Traffic event cognition and reasoning in videos is an important task that has
a wide range of applications in intelligent transportation, assisted driving,
and autonomous vehicles. In this paper, we create a novel dataset,
SUTD-TrafficQA (Traffic Question Answering), which takes the form of video QA
based on the collected 10,080 in-the-wild videos and annotated 62,535 QA pairs,
for benchmarking the cognitive capability of causal inference and event
understanding models in complex traffic scenarios. Specifically, we propose 6
challenging reasoning tasks corresponding to various traffic scenarios, so as
to evaluate the reasoning capability over different kinds of complex yet
practical traffic events. Moreover, we propose Eclipse, a novel Efficient
glimpse network via dynamic inference, in order to achieve
computation-efficient and reliable video reasoning. The experiments show that
our method achieves superior performance while reducing the computation cost
significantly. The project page: https://github.com/SUTDCV/SUTD-TrafficQA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Red Blood Cell Segmentation with Overlapping Cell Separation and Classification on Imbalanced Dataset. (arXiv:2012.01321v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Naruenatthanaset_K/0/1/0/all/0/1">Korranat Naruenatthanaset</a>, <a href="http://arxiv.org/find/eess/1/au:+Chalidabhongse_T/0/1/0/all/0/1">Thanarat H. Chalidabhongse</a>, <a href="http://arxiv.org/find/eess/1/au:+Palasuwan_D/0/1/0/all/0/1">Duangdao Palasuwan</a>, <a href="http://arxiv.org/find/eess/1/au:+Anantrasirichai_N/0/1/0/all/0/1">Nantheera Anantrasirichai</a>, <a href="http://arxiv.org/find/eess/1/au:+Palasuwan_A/0/1/0/all/0/1">Attakorn Palasuwan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01321">
                                    <div class="article-summary-box-inner">
                                        <span>Automated red blood cell (RBC) classification on blood smear images helps
hematologists to analyze RBC lab results in a reduced time and cost. However,
overlapping cells can cause incorrect predicted results, and so they have to be
separated into multiple single RBCs before classifying. To classify multiple
classes with deep learning, imbalance problems are common in medical imaging
because normal samples are always higher than rare disease samples. This paper
presents a new method to segment and classify RBCs from blood smear images,
specifically to tackle cell overlapping and data imbalance problems. Focusing
on overlapping cell separation, our segmentation process first estimates
ellipses to represent RBCs. The method detects the concave points and then
finds the ellipses using directed ellipse fitting. The accuracy from 20 blood
smear images was 0.889. Classification requires balanced training datasets.
However, some RBC types are rare. The imbalance ratio of this dataset was
34.538 for 12 RBC classes from 20,875 individual RBC samples. The use of
machine learning for RBC classification with an imbalanced dataset is hence
more challenging than many other applications. We analyzed techniques to deal
with this problem. The best accuracy and F1-score were 0.921 and 0.8679,
respectively, using EfficientNet-B1 with augmentation. Experimental results
showed that the weight balancing technique with augmentation had the potential
to deal with imbalance problems by improving the F1-score on minority classes,
while data augmentation significantly improved the overall classification
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-Local Representation based Mutual Affine-Transfer Network for Photorealistic Stylization. (arXiv:1907.10274v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1">Ying Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhenzhou Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1">Hairong Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.10274">
                                    <div class="article-summary-box-inner">
                                        <span>Photorealistic stylization aims to transfer the style of a reference photo
onto a content photo in a natural fashion, such that the stylized image looks
like a real photo taken by a camera. State-of-the-art methods stylize the image
locally within each matched semantic region and are prone to global color
inconsistency across semantic objects/parts, making the stylized image less
photorealistic. To tackle the challenging issues, we propose a non-local
representation scheme, constrained with a mutual affine-transfer network
(NL-MAT). Through a dictionary-based decomposition, NL-MAT is able to
successfully decouple matched non-local representations and color information
of the image pair, such that the context correspondence between the image pair
is incorporated naturally, which largely facilitates local style transfer in a
global-consistent fashion. To the best of our knowledge, this is the first
attempt to address the photorealistic stylization problem with a non-local
representation scheme, such that no additional models or steps for semantic
matching are required during stylization. Experimental results demonstrate that
the proposed method is able to generate photorealistic results with local style
transfer while preserving both the spatial structure and global color
consistency of the content image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The GIST and RIST of Iterative Self-Training for Semi-Supervised Segmentation. (arXiv:2103.17105v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Teh_E/0/1/0/all/0/1">Eu Wern Teh</a>, <a href="http://arxiv.org/find/cs/1/au:+DeVries_T/0/1/0/all/0/1">Terrance DeVries</a>, <a href="http://arxiv.org/find/cs/1/au:+Duke_B/0/1/0/all/0/1">Brendan Duke</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1">Ruowei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Aarabi_P/0/1/0/all/0/1">Parham Aarabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1">Graham W. Taylor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17105">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the task of semi-supervised semantic segmentation, where we aim
to produce pixel-wise semantic object masks given only a small number of
human-labeled training examples. We focus on iterative self-training methods in
which we explore the behavior of self-training over multiple refinement stages.
We show that iterative self-training leads to performance degradation if done
na\&quot;ively with a fixed ratio of human-labeled to pseudo-labeled training
examples. We propose Greedy Iterative Self-Training (GIST) and Random Iterative
Self-Training (RIST) strategies that alternate between training on either
human-labeled data or pseudo-labeled data at each refinement stage, resulting
in a performance boost rather than degradation. We further show that GIST and
RIST can be combined with existing semi-supervised learning methods to boost
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection. (arXiv:2012.04355v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">He Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_Y/0/1/0/all/0/1">Yezhen Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Litany_O/0/1/0/all/0/1">Or Litany</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yue Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas J. Guibas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04355">
                                    <div class="article-summary-box-inner">
                                        <span>3D object detection is an important yet demanding task that heavily relies on
difficult to obtain 3D annotations. To reduce the required amount of
supervision, we propose 3DIoUMatch, a novel semi-supervised method for 3D
object detection applicable to both indoor and outdoor scenes. We leverage a
teacher-student mutual learning framework to propagate information from the
labeled to the unlabeled train set in the form of pseudo-labels. However, due
to the high task complexity, we observe that the pseudo-labels suffer from
significant noise and are thus not directly usable. To that end, we introduce a
confidence-based filtering mechanism, inspired by FixMatch. We set confidence
thresholds based upon the predicted objectness and class probability to filter
low-quality pseudo-labels. While effective, we observe that these two measures
do not sufficiently capture localization quality. We therefore propose to use
the estimated 3D IoU as a localization metric and set category-aware
self-adjusted thresholds to filter poorly localized proposals. We adopt VoteNet
as our backbone detector on indoor datasets while we use PV-RCNN on the
autonomous driving dataset, KITTI. Our method consistently improves
state-of-the-art methods on both ScanNet and SUN-RGBD benchmarks by significant
margins under all label ratios (including fully labeled setting). For example,
when training using only 10\% labeled data on ScanNet, 3DIoUMatch achieves 7.7%
absolute improvement on mAP@0.25 and 8.5% absolute improvement on mAP@0.5 upon
the prior art. On KITTI, we are the first to demonstrate semi-supervised 3D
object detection and our method surpasses a fully supervised baseline from 1.8%
to 7.6% under different label ratios and categories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AE TextSpotter: Learning Visual and Linguistic Representation for Ambiguous Text Spotting. (arXiv:2008.00714v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuebo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1">Xiaozhong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_D/0/1/0/all/0/1">Ding Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhibo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00714">
                                    <div class="article-summary-box-inner">
                                        <span>Scene text spotting aims to detect and recognize the entire word or sentence
with multiple characters in natural images. It is still challenging because
ambiguity often occurs when the spacing between characters is large or the
characters are evenly spread in multiple rows and columns, making many visually
plausible groupings of the characters (e.g. &quot;BERLIN&quot; is incorrectly detected as
&quot;BERL&quot; and &quot;IN&quot; in Fig. 1(c)). Unlike previous works that merely employed
visual features for text detection, this work proposes a novel text spotter,
named Ambiguity Eliminating Text Spotter (AE TextSpotter), which learns both
visual and linguistic features to significantly reduce ambiguity in text
detection. The proposed AE TextSpotter has three important benefits. 1) The
linguistic representation is learned together with the visual representation in
a framework. To our knowledge, it is the first time to improve text detection
by using a language model. 2) A carefully designed language module is utilized
to reduce the detection confidence of incorrect text lines, making them easily
pruned in the detection stage. 3) Extensive experiments show that AE
TextSpotter outperforms other state-of-the-art methods by a large margin. For
example, we carefully select a validation set of extremely ambiguous samples
from the IC19-ReCTS dataset, where our approach surpasses other methods by more
than 4%. The code has been released at
https://github.com/whai362/AE_TextSpotter. The image list and evaluation
scripts of the validation set have been released at
https://github.com/whai362/TDA-ReCTS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient-CapsNet: Capsule Network with Self-Attention Routing. (arXiv:2101.12491v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazzia_V/0/1/0/all/0/1">Vittorio Mazzia</a>, <a href="http://arxiv.org/find/cs/1/au:+Salvetti_F/0/1/0/all/0/1">Francesco Salvetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiaberge_M/0/1/0/all/0/1">Marcello Chiaberge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12491">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks, assisted by architectural design
strategies, make extensive use of data augmentation techniques and layers with
a high number of feature maps to embed object transformations. That is highly
inefficient and for large datasets implies a massive redundancy of features
detectors. Even though capsules networks are still in their infancy, they
constitute a promising solution to extend current convolutional networks and
endow artificial visual perception with a process to encode more efficiently
all feature affine transformations. Indeed, a properly working capsule network
should theoretically achieve higher results with a considerably lower number of
parameters count due to intrinsic capability to generalize to novel viewpoints.
Nevertheless, little attention has been given to this relevant aspect. In this
paper, we investigate the efficiency of capsule networks and, pushing their
capacity to the limits with an extreme architecture with barely 160K
parameters, we prove that the proposed architecture is still able to achieve
state-of-the-art results on three different datasets with only 2% of the
original CapsNet parameters. Moreover, we replace dynamic routing with a novel
non-iterative, highly parallelizable routing algorithm that can easily cope
with a reduced number of capsules. Extensive experimentation with other capsule
implementations has proved the effectiveness of our methodology and the
capability of capsule networks to efficiently embed visual representations more
prone to generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fractional order graph neural network. (arXiv:2001.04026v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zijian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Chunbo Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Peng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_G/0/1/0/all/0/1">Geyong Min</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04026">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes fractional order graph neural networks (FGNNs), optimized
by the approximation strategy to address the challenges of local optimum of
classic and fractional graph neural networks which are specialised at
aggregating information from the feature and adjacent matrices of connected
nodes and their neighbours to solve learning tasks on non-Euclidean data such
as graphs. Meanwhile the approximate calculation of fractional order gradients
also overcomes the high computational complexity of fractional order
derivations. We further prove that such an approximation is feasible and the
FGNN is unbiased towards global optimization solution. Extensive experiments on
citation networks show that FGNN achieves great advantage over baseline models
when selected appropriate fractional order.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised learning of MRI tissue properties using MRI physics models. (arXiv:2107.02704v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Varadarajan_D/0/1/0/all/0/1">Divya Varadarajan</a>, <a href="http://arxiv.org/find/eess/1/au:+Bouman_K/0/1/0/all/0/1">Katherine L. Bouman</a>, <a href="http://arxiv.org/find/eess/1/au:+Kouwe_A/0/1/0/all/0/1">Andre van der Kouwe</a>, <a href="http://arxiv.org/find/eess/1/au:+Fischl_B/0/1/0/all/0/1">Bruce Fischl</a>, <a href="http://arxiv.org/find/eess/1/au:+Dalca_A/0/1/0/all/0/1">Adrian V. Dalca</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02704">
                                    <div class="article-summary-box-inner">
                                        <span>In neuroimaging, MRI tissue properties characterize underlying neurobiology,
provide quantitative biomarkers for neurological disease detection and
analysis, and can be used to synthesize arbitrary MRI contrasts. Estimating
tissue properties from a single scan session using a protocol available on all
clinical scanners promises to reduce scan time and cost, enable quantitative
analysis in routine clinical scans and provide scan-independent biomarkers of
disease. However, existing tissue properties estimation methods - most often
$\mathbf{T_1}$ relaxation, $\mathbf{T_2^*}$ relaxation, and proton density
($\mathbf{PD}$) - require data from multiple scan sessions and cannot estimate
all properties from a single clinically available MRI protocol such as the
multiecho MRI scan. In addition, the widespread use of non-standard acquisition
parameters across clinical imaging sites require estimation methods that can
generalize across varying scanner parameters. However, existing learning
methods are acquisition protocol specific and cannot estimate from heterogenous
clinical data from different imaging sites. In this work we propose an
unsupervised deep-learning strategy that employs MRI physics to estimate all
three tissue properties from a single multiecho MRI scan session, and
generalizes across varying acquisition parameters. The proposed strategy
optimizes accurate synthesis of new MRI contrasts from estimated latent tissue
properties, enabling unsupervised training, we also employ random acquisition
parameters during training to achieve acquisition generalization. We provide
the first demonstration of estimating all tissue properties from a single
multiecho scan session. We demonstrate improved accuracy and generalizability
for tissue property estimation and MRI synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention over learned object embeddings enables complex visual reasoning. (arXiv:2012.08508v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1">David Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1">Adam Santoro</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynolds_M/0/1/0/all/0/1">Malcolm Reynolds</a>, <a href="http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1">Matt Botvinick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08508">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have achieved success in a wide array of perceptual tasks but
often fail at tasks involving both perception and higher-level reasoning. On
these more challenging tasks, bespoke approaches (such as modular symbolic
components, independent dynamics models or semantic parsers) targeted towards
that specific type of task have typically performed better. The downside to
these targeted approaches, however, is that they can be more brittle than
general-purpose neural networks, requiring significant modification or even
redesign according to the particular task at hand. Here, we propose a more
general neural-network-based approach to dynamic visual reasoning problems that
obtains state-of-the-art performance on three different domains, in each case
outperforming bespoke modular approaches tailored specifically to the task. Our
method relies on learned object-centric representations, self-attention and
self-supervised dynamics learning, and all three elements together are required
for strong performance to emerge. The success of this combination suggests that
there may be no need to trade off flexibility for performance on problems
involving spatio-temporal or causal-style reasoning. With the right soft biases
and learning objectives in a neural network we may be able to attain the best
of both worlds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the Best Pooling Strategy for Visual Semantic Embedding. (arXiv:2011.04305v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiacheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hexiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuning Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04305">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Semantic Embedding (VSE) is a dominant approach for vision-language
retrieval, which aims at learning a deep embedding space such that visual data
are embedded close to their semantic text labels or descriptions. Recent VSE
models use complex methods to better contextualize and aggregate multi-modal
features into holistic embeddings. However, we discover that surprisingly
simple (but carefully selected) global pooling functions (e.g., max pooling)
outperform those complex models, across different feature extractors. Despite
its simplicity and effectiveness, seeking the best pooling function for
different data modality and feature extractor is costly and tedious, especially
when the size of features varies (e.g., text, video). Therefore, we propose a
Generalized Pooling Operator (GPO), which learns to automatically adapt itself
to the best pooling strategy for different features, requiring no manual tuning
while staying effective and efficient. We extend the VSE model using this
proposed GPO and denote it as VSE$\infty$.

Without bells and whistles, VSE$\infty$ outperforms previous VSE methods
significantly on image-text retrieval benchmarks across popular feature
extractors. With a simple adaptation, variants of VSE$\infty$ further
demonstrate its strength by achieving the new state of the art on two
video-text retrieval datasets. Comprehensive experiments and visualizations
confirm that GPO always discovers the best pooling strategy and can be a
plug-and-play feature aggregation module for standard VSE models. Code and
pre-trained models are available at https://vse-infty.github.io.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Human Video Rendering by Learning Dynamic Textures and Rendering-to-Video Translation. (arXiv:2001.04947v3 [cs.GR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weipeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1">Marc Habermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Zollhoefer_M/0/1/0/all/0/1">Michael Zollhoefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernard_F/0/1/0/all/0/1">Florian Bernard</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyeongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04947">
                                    <div class="article-summary-box-inner">
                                        <span>Synthesizing realistic videos of humans using neural networks has been a
popular alternative to the conventional graphics-based rendering pipeline due
to its high efficiency. Existing works typically formulate this as an
image-to-image translation problem in 2D screen space, which leads to artifacts
such as over-smoothing, missing body parts, and temporal instability of
fine-scale detail, such as pose-dependent wrinkles in the clothing. In this
paper, we propose a novel human video synthesis method that approaches these
limiting factors by explicitly disentangling the learning of time-coherent
fine-scale details from the embedding of the human in 2D screen space. More
specifically, our method relies on the combination of two convolutional neural
networks (CNNs). Given the pose information, the first CNN predicts a dynamic
texture map that contains time-coherent high-frequency details, and the second
CNN conditions the generation of the final video on the temporally coherent
output of the first CNN. We demonstrate several applications of our approach,
such as human reenactment and novel view synthesis from monocular video, where
we show significant improvement over the state of the art both qualitatively
and quantitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-time Pose Estimation from Images for Multiple Humanoid Robots. (arXiv:2107.02675v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1">Arash Amini</a>, <a href="http://arxiv.org/find/cs/1/au:+Farazi_H/0/1/0/all/0/1">Hafez Farazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_S/0/1/0/all/0/1">Sven Behnke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02675">
                                    <div class="article-summary-box-inner">
                                        <span>Pose estimation commonly refers to computer vision methods that recognize
people&#x27;s body postures in images or videos. With recent advancements in deep
learning, we now have compelling models to tackle the problem in real-time.
Since these models are usually designed for human images, one needs to adapt
existing models to work on other creatures, including robots. This paper
examines different state-of-the-art pose estimation models and proposes a
lightweight model that can work in real-time on humanoid robots in the RoboCup
Humanoid League environment. Additionally, we present a novel dataset called
the HumanoidRobotPose dataset. The results of this work have the potential to
enable many advanced behaviors for soccer-playing robots.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Representation Theoretic Patterns in Multi-Frequency Class Averaging for Three-Dimensional Cryo-Electron Microscopy. (arXiv:1906.01082v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fan_Y/0/1/0/all/0/1">Yifeng Fan</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_T/0/1/0/all/0/1">Tingran Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Z/0/1/0/all/0/1">Zhizhen Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.01082">
                                    <div class="article-summary-box-inner">
                                        <span>We develop in this paper a novel intrinsic classification algorithm --
multi-frequency class averaging (MFCA) -- for classifying noisy projection
images obtained from three-dimensional cryo-electron microscopy (cryo-EM) by
the similarity among their viewing directions. This new algorithm leverages
multiple irreducible representations of the unitary group to introduce
additional redundancy into the representation of the optimal in-plane
rotational alignment, extending and outperforming the existing class averaging
algorithm that uses only a single representation. The formal algebraic model
and representation theoretic patterns of the proposed MFCA algorithm extend the
framework of Hadani and Singer to arbitrary irreducible representations of the
unitary group. We conceptually establish the consistency and stability of MFCA
by inspecting the spectral properties of a generalized local parallel transport
operator through the lens of Wigner $D$-matrices. We demonstrate the efficacy
of the proposed algorithm with numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COVID-19 Pneumonia Severity Prediction using Hybrid Convolution-Attention Neural Architectures. (arXiv:2107.02672v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nguyen_N/0/1/0/all/0/1">Nam Nguyen</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_J/0/1/0/all/0/1">J. Morris Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02672">
                                    <div class="article-summary-box-inner">
                                        <span>This study proposed a novel framework for COVID-19 severity prediction, which
is a combination of data-centric and model-centric approaches. First, we
propose a data-centric pre-training for extremely scare data scenarios of the
investigating dataset. Second, we propose two hybrid convolution-attention
neural architectures that leverage the self-attention from Transformer and
Hopfield networks. Our proposed approach achieves significant improvement from
the conventional baseline approach. The best model from our proposed approach
achieves $R^2 &#x3D; 0.85 \pm 0.05$ and Pearson correlation coefficient $\rho &#x3D; 0.92
\pm 0.02$ in geographic extend and $R^2 &#x3D; 0.72 \pm 0.09, \rho &#x3D; 0.85\pm 0.06$
in opacity prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VidLanKD: Improving Language Understanding via Video-Distilled Knowledge Transfer. (arXiv:2107.02681v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zineng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jaemin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02681">
                                    <div class="article-summary-box-inner">
                                        <span>Since visual perception can give rich information beyond text descriptions
for world understanding, there has been increasing interest in leveraging
visual grounding for language learning. Recently, vokenization has attracted
attention by using the predictions of a text-to-image retrieval model as labels
for language model supervision. Despite its success, the method suffers from
approximation error of using finite image labels and the lack of vocabulary
diversity of a small image-text dataset. To overcome these limitations, we
present VidLanKD, a video-language knowledge distillation method for improving
language understanding. We train a multi-modal teacher model on a video-text
dataset, and then transfer its knowledge to a student language model with a
text dataset. To avoid approximation error, we propose to use different
knowledge distillation objectives. In addition, the use of a large-scale
video-text dataset helps learn diverse and richer vocabularies. In our
experiments, VidLanKD achieves consistent improvements over text-only language
models and vokenization models, on several downstream language understanding
tasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world
knowledge, physical reasoning, and temporal reasoning capabilities of our model
by evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we
present comprehensive ablation studies as well as visualizations of the learned
text-to-video grounding results of our teacher and student language models. Our
code and models are available at: https://github.com/zinengtang/VidLanKD</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially private federated deep learning for multi-site medical image segmentation. (arXiv:2107.02586v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ziller_A/0/1/0/all/0/1">Alexander Ziller</a>, <a href="http://arxiv.org/find/eess/1/au:+Usynin_D/0/1/0/all/0/1">Dmitrii Usynin</a>, <a href="http://arxiv.org/find/eess/1/au:+Remerscheid_N/0/1/0/all/0/1">Nicolas Remerscheid</a>, <a href="http://arxiv.org/find/eess/1/au:+Knolle_M/0/1/0/all/0/1">Moritz Knolle</a>, <a href="http://arxiv.org/find/eess/1/au:+Makowski_M/0/1/0/all/0/1">Marcus Makowski</a>, <a href="http://arxiv.org/find/eess/1/au:+Braren_R/0/1/0/all/0/1">Rickmer Braren</a>, <a href="http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02586">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative machine learning techniques such as federated learning (FL)
enable the training of models on effectively larger datasets without data
transfer. Recent initiatives have demonstrated that segmentation models trained
with FL can achieve performance similar to locally trained models. However, FL
is not a fully privacy-preserving technique and privacy-centred attacks can
disclose confidential patient data. Thus, supplementing FL with
privacy-enhancing technologies (PTs) such as differential privacy (DP) is a
requirement for clinical applications in a multi-institutional setting. The
application of PTs to FL in medical imaging and the trade-offs between privacy
guarantees and model utility, the ramifications on training performance and the
susceptibility of the final models to attacks have not yet been conclusively
investigated. Here we demonstrate the first application of differentially
private gradient descent-based FL on the task of semantic segmentation in
computed tomography. We find that high segmentation performance is possible
under strong privacy guarantees with an acceptable training time penalty. We
furthermore demonstrate the first successful gradient-based model inversion
attack on a semantic segmentation model and show that the application of DP
prevents it from divulging sensitive image features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Outliers with Poisson Image Interpolation. (arXiv:2107.02622v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Jeremy Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1">Benjamin Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Day_T/0/1/0/all/0/1">Thomas Day</a>, <a href="http://arxiv.org/find/cs/1/au:+Simpson_J/0/1/0/all/0/1">John Simpson</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02622">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised learning of every possible pathology is unrealistic for many
primary care applications like health screening. Image anomaly detection
methods that learn normal appearance from only healthy data have shown
promising results recently. We propose an alternative to image
reconstruction-based and image embedding-based methods and propose a new
self-supervised method to tackle pathological anomaly detection. Our approach
originates in the foreign patch interpolation (FPI) strategy that has shown
superior performance on brain MRI and abdominal CT data. We propose to use a
better patch interpolation strategy, Poisson image interpolation (PII), which
makes our method suitable for applications in challenging data regimes. PII
outperforms state-of-the-art methods by a good margin when tested on surrogate
tasks like identifying common lung anomalies in chest X-rays or hypo-plastic
left heart syndrome in prenatal, fetal cardiac ultrasound images. Code
available at https://github.com/jemtan/PII.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomaly Detection using Edge Computing in Video Surveillance System: Review. (arXiv:2107.02778v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patrikar_D/0/1/0/all/0/1">Devashree R. Patrikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Parate_M/0/1/0/all/0/1">Mayur Rajram Parate</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02778">
                                    <div class="article-summary-box-inner">
                                        <span>The current concept of Smart Cities influences urban planners and researchers
to provide modern, secured and sustainable infrastructure and give a decent
quality of life to its residents. To fulfill this need video surveillance
cameras have been deployed to enhance the safety and well-being of the
citizens. Despite technical developments in modern science, abnormal event
detection in surveillance video systems is challenging and requires exhaustive
human efforts. In this paper, we surveyed various methodologies developed to
detect anomalies in intelligent video surveillance. Firstly, we revisit the
surveys on anomaly detection in the last decade. We then present a systematic
categorization of methodologies developed for ease of understanding.
Considering the notion of anomaly depends on context, we identify different
objects-of-interest and publicly available datasets in anomaly detection. Since
anomaly detection is considered a time-critical application of computer vision,
our emphasis is on anomaly detection using edge devices and approaches
explicitly designed for them. Further, we discuss the challenges and
opportunities involved in anomaly detection at the edge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">iPOKE: Poking a Still Image for Controlled Stochastic Video Synthesis. (arXiv:2107.02790v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blattmann_A/0/1/0/all/0/1">Andreas Blattmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Milbich_T/0/1/0/all/0/1">Timo Milbich</a>, <a href="http://arxiv.org/find/cs/1/au:+Dorkenwald_M/0/1/0/all/0/1">Michael Dorkenwald</a>, <a href="http://arxiv.org/find/cs/1/au:+Ommer_B/0/1/0/all/0/1">Bj&#xf6;rn Ommer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02790">
                                    <div class="article-summary-box-inner">
                                        <span>How would a static scene react to a local poke? What are the effects on other
parts of an object if you could locally push it? There will be distinctive
movement, despite evident variations caused by the stochastic nature of our
world. These outcomes are governed by the characteristic kinematics of objects
that dictate their overall motion caused by a local interaction. Conversely,
the movement of an object provides crucial information about its underlying
distinctive kinematics and the interdependencies between its parts. This
two-way relation motivates learning a bijective mapping between object
kinematics and plausible future image sequences. Therefore, we propose iPOKE -
invertible Prediction of Object Kinematics - that, conditioned on an initial
frame and a local poke, allows to sample object kinematics and establishes a
one-to-one correspondence to the corresponding plausible videos, thereby
providing a controlled stochastic video synthesis. In contrast to previous
works, we do not generate arbitrary realistic videos, but provide efficient
control of movements, while still capturing the stochastic nature of our
environment and the diversity of plausible outcomes it entails. Moreover, our
approach can transfer kinematics onto novel object instances and is not
confined to particular object classes. Project page is available at
https://bit.ly/3dJN4Lf</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Foreground-Aware Stylization and Consensus Pseudo-Labeling for Domain Adaptation of First-Person Hand Segmentation. (arXiv:2107.02718v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ohkawa_T/0/1/0/all/0/1">Takehiko Ohkawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Yagi_T/0/1/0/all/0/1">Takuma Yagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashimoto_A/0/1/0/all/0/1">Atsushi Hashimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ushiku_Y/0/1/0/all/0/1">Yoshitaka Ushiku</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_Y/0/1/0/all/0/1">Yoichi Sato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02718">
                                    <div class="article-summary-box-inner">
                                        <span>Hand segmentation is a crucial task in first-person vision. Since
first-person images exhibit strong bias in appearance among different
environments, adapting a pre-trained segmentation model to a new domain is
required in hand segmentation. Here, we focus on appearance gaps for hand
regions and backgrounds separately. We propose (i) foreground-aware image
stylization and (ii) consensus pseudo-labeling for domain adaptation of hand
segmentation. We stylize source images independently for the foreground and
background using target images as style. To resolve the domain shift that the
stylization has not addressed, we apply careful pseudo-labeling by taking a
consensus between the models trained on the source and stylized source images.
We validated our method on domain adaptation of hand segmentation from real and
simulation images. Our method achieved state-of-the-art performance in both
settings. We also demonstrated promising results in challenging multi-target
domain adaptation and domain generalization settings. Code is available at
https://github.com/ut-vision/FgSty-CPL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A deep-learning--based multimodal depth-aware dynamic hand gesture recognition system. (arXiv:2107.02543v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmud_H/0/1/0/all/0/1">Hasan Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Morshed_M/0/1/0/all/0/1">Mashrur Mahmud Morshed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Md. Kamrul Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02543">
                                    <div class="article-summary-box-inner">
                                        <span>Any spatio-temporal movement or reorientation of the hand, done with the
intention of conveying a specific meaning, can be considered as a hand gesture.
Inputs to hand gesture recognition systems can be in several forms, such as
depth images, monocular RGB, or skeleton joint points. We observe that raw
depth images possess low contrasts in the hand regions of interest (ROI). They
do not highlight important details to learn, such as finger bending information
(whether a finger is overlapping the palm, or another finger). Recently, in
deep-learning--based dynamic hand gesture recognition, researchers are tying to
fuse different input modalities (e.g. RGB or depth images and hand skeleton
joint points) to improve the recognition accuracy. In this paper, we focus on
dynamic hand gesture (DHG) recognition using depth quantized image features and
hand skeleton joint points. In particular, we explore the effect of using
depth-quantized features in Convolutional Neural Network (CNN) and Recurrent
Neural Network (RNN) based multi-modal fusion networks. We find that our method
improves existing results on the SHREC-DHG-14 dataset. Furthermore, using our
method, we show that it is possible to reduce the resolution of the input
images by more than four times and still obtain comparable or better accuracy
to that of the resolutions used in previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth-supervised NeRF: Fewer Views and Faster Training for Free. (arXiv:2107.02791v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1">Kangle Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Andrew Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun-Yan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1">Deva Ramanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02791">
                                    <div class="article-summary-box-inner">
                                        <span>One common failure mode of Neural Radiance Field (NeRF) models is fitting
incorrect geometries when given an insufficient number of input views. We
propose DS-NeRF (Depth-supervised Neural Radiance Fields), a loss for learning
neural radiance fields that takes advantage of readily-available depth
supervision. Our key insight is that sparse depth supervision can be used to
regularize the learned geometry, a crucial component for effectively rendering
novel views using NeRF. We exploit the fact that current NeRF pipelines require
images with known camera poses that are typically estimated by running
structure-from-motion (SFM). Crucially, SFM also produces sparse 3D points that
can be used as &#x60;&#x60;free&quot; depth supervision during training: we simply add a loss
to ensure that depth rendered along rays that intersect these 3D points is
close to the observed depth. We find that DS-NeRF can render more accurate
images given fewer training views while training 2-6x faster. With only two
training views on real-world images, DS-NeRF significantly outperforms NeRF as
well as other sparse-view variants. We show that our loss is compatible with
these NeRF models, demonstrating that depth is a cheap and easily digestible
supervisory signal. Finally, we show that DS-NeRF supports other types of depth
supervision such as scanned depth sensors and RGBD reconstruction outputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-fine Semantic Localization with HD Map for Autonomous Driving in Structural Scenes. (arXiv:2107.02557v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1">Chengcheng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1">Minjie Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Heyang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1">Pengpeng Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_E/0/1/0/all/0/1">Erkang Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02557">
                                    <div class="article-summary-box-inner">
                                        <span>Robust and accurate localization is an essential component for robotic
navigation and autonomous driving. The use of cameras for localization with
high definition map (HD Map) provides an affordable localization sensor set.
Existing methods suffer from pose estimation failure due to error prone data
association or initialization with accurate initial pose requirement. In this
paper, we propose a cost-effective vehicle localization system with HD map for
autonomous driving that uses cameras as primary sensors. To this end, we
formulate vision-based localization as a data association problem that maps
visual semantics to landmarks in HD map. Specifically, system initialization is
finished in a coarse to fine manner by combining coarse GPS (Global Positioning
System) measurement and fine pose searching. In tracking stage, vehicle pose is
refined by implicitly aligning the semantic segmentation result between image
and landmarks in HD maps with photometric consistency. Finally, vehicle pose is
computed by pose graph optimization in a sliding window fashion. We evaluate
our method on two datasets and demonstrate that the proposed approach yields
promising localization results in different driving scenarios. Additionally,
our approach is suitable for both monocular camera and multi-cameras that
provides flexibility and improves robustness for the localization system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HybrUR: A Hybrid Physical-Neural Solution for Unsupervised Underwater Image Restoration. (arXiv:2107.02660v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1">Shuaizheng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhengxing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yue Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Min Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Junzhi Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02660">
                                    <div class="article-summary-box-inner">
                                        <span>Robust vision restoration for an underwater image remains a challenging
problem. For the lack of aligned underwater-terrestrial image pairs, the
unsupervised method is more suited to this task. However, the pure data-driven
unsupervised method usually has difficulty in achieving realistic color
correction for lack of optical constraint. In this paper, we propose a data-
and physics-driven unsupervised architecture that learns underwater vision
restoration from unpaired underwater-terrestrial images. For sufficient domain
transformation and detail preservation, the underwater degeneration needs to be
explicitly constructed based on the optically unambiguous physics law. Thus, we
employ the Jaffe-McGlamery degradation theory to design the generation models,
and use neural networks to describe the process of underwater degradation.
Furthermore, to overcome the problem of invalid gradient when optimizing the
hybrid physical-neural model, we fully investigate the intrinsic correlation
between the scene depth and the degradation factors for the backscattering
estimation, to improve the restoration performance through physical
constraints. Our experimental results show that the proposed method is able to
perform high-quality restoration for unconstrained underwater images without
any supervision. On multiple benchmarks, we outperform several state-of-the-art
supervised and unsupervised approaches. We also demonstrate that our methods
yield encouraging results on real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation. (arXiv:2107.02655v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbera_G/0/1/0/all/0/1">Giammarco La Barbera</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Boussaid_H/0/1/0/all/0/1">Haithem Boussaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Belucci_B/0/1/0/all/0/1">Bruno Belucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Delmonte_A/0/1/0/all/0/1">Alessandro Delmonte</a>, <a href="http://arxiv.org/find/cs/1/au:+Goulin_J/0/1/0/all/0/1">Jeanne Goulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarnacki_S/0/1/0/all/0/1">Sabine Sarnacki</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouet_L/0/1/0/all/0/1">Laurence Rouet</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloch_I/0/1/0/all/0/1">Isabelle Bloch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02655">
                                    <div class="article-summary-box-inner">
                                        <span>Due to a high heterogeneity in pose and size and to a limited number of
available data, segmentation of pediatric images is challenging for deep
learning methods. In this work, we propose a new CNN architecture that is pose
and scale invariant thanks to the use of Spatial Transformer Network (STN). Our
architecture is composed of three sequential modules that are estimated
together during training: (i) a regression module to estimate a similarity
matrix to normalize the input image to a reference one; (ii) a differentiable
module to find the region of interest to segment; (iii) a segmentation module,
based on the popular UNet architecture, to delineate the object. Unlike the
original UNet, which strives to learn a complex mapping, including pose and
scale variations, from a finite training dataset, our segmentation module
learns a simpler mapping focusing on images with normalized pose and size.
Furthermore, the use of an automatic bounding box detection through STN allows
saving time and especially memory, while keeping similar performance. We test
the proposed method in kidney and renal tumor segmentation on abdominal
pediatric CT scanners. Results indicate that the estimated STN homogenization
of size and pose accelerates the segmentation (25h), compared to standard
data-augmentation (33h), while obtaining a similar quality for the kidney
(88.01\% of Dice score) and improving the renal tumor delineation (from 85.52\%
to 87.12\%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperspectral Pansharpening Based on Improved Deep Image Prior and Residual Reconstruction. (arXiv:2107.02630v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bandara_W/0/1/0/all/0/1">Wele Gedara Chaminda Bandara</a>, <a href="http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1">Jeya Maria Jose Valanarasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02630">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperspectral pansharpening aims to synthesize a low-resolution hyperspectral
image (LR-HSI) with a registered panchromatic image (PAN) to generate an
enhanced HSI with high spectral and spatial resolution. Recently proposed HS
pansharpening methods have obtained remarkable results using deep convolutional
networks (ConvNets), which typically consist of three steps: (1) up-sampling
the LR-HSI, (2) predicting the residual image via a ConvNet, and (3) obtaining
the final fused HSI by adding the outputs from first and second steps. Recent
methods have leveraged Deep Image Prior (DIP) to up-sample the LR-HSI due to
its excellent ability to preserve both spatial and spectral information,
without learning from large data sets. However, we observed that the quality of
up-sampled HSIs can be further improved by introducing an additional
spatial-domain constraint to the conventional spectral-domain energy function.
We define our spatial-domain constraint as the $L_1$ distance between the
predicted PAN image and the actual PAN image. To estimate the PAN image of the
up-sampled HSI, we also propose a learnable spectral response function (SRF).
Moreover, we noticed that the residual image between the up-sampled HSI and the
reference HSI mainly consists of edge information and very fine structures. In
order to accurately estimate fine information, we propose a novel over-complete
network, called HyperKite, which focuses on learning high-level features by
constraining the receptive from increasing in the deep layers. We perform
experiments on three HSI datasets to demonstrate the superiority of our
DIP-HyperKite over the state-of-the-art pansharpening methods. The deployment
codes, pre-trained models, and final fusion outputs of our DIP-HyperKite and
the methods used for the comparisons will be publicly made available at
https://github.com/wgcban/DIP-HyperKite.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth-Aware Multi-Grid Deep Homography Estimation with Contextual Correlation. (arXiv:2107.02524v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nie_L/0/1/0/all/0/1">Lang Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chunyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_K/0/1/0/all/0/1">Kang Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuaicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02524">
                                    <div class="article-summary-box-inner">
                                        <span>Homography estimation is an important task in computer vision, such as image
stitching, video stabilization, and camera calibration. Traditional homography
estimation methods heavily depend on the quantity and distribution of feature
points, leading to poor robustness in textureless scenes. The learning
solutions, on the contrary, try to learn robust deep features but demonstrate
unsatisfying performance in the scenes of low overlap rates. In this paper, we
address the two problems simultaneously, by designing a contextual correlation
layer, which can capture the long-range correlation on feature maps and
flexibly be bridged in a learning framework. In addition, considering that a
single homography can not represent the complex spatial transformation in
depth-varying images with parallax, we propose to predict multi-grid homography
from global to local. Moreover, we equip our network with depth perception
capability, by introducing a novel depth-aware shape-preserved loss. Extensive
experiments demonstrate the superiority of our method over other
state-of-the-art solutions in the synthetic benchmark dataset and real-world
dataset. The codes and models will be available at
https://github.com/nie-lang/Multi-Grid-Deep-Homogarphy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-aware curriculum federated learning for breast cancer classification. (arXiv:2107.02504v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jimenez_Sanchez_A/0/1/0/all/0/1">Amelia Jim&#xe9;nez-S&#xe1;nchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Tardy_M/0/1/0/all/0/1">Mickael Tardy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballester_M/0/1/0/all/0/1">Miguel A. Gonz&#xe1;lez Ballester</a>, <a href="http://arxiv.org/find/cs/1/au:+Mateus_D/0/1/0/all/0/1">Diana Mateus</a>, <a href="http://arxiv.org/find/cs/1/au:+Piella_G/0/1/0/all/0/1">Gemma Piella</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02504">
                                    <div class="article-summary-box-inner">
                                        <span>For early breast cancer detection, regular screening with mammography imaging
is recommended. Routinary examinations result in datasets with a predominant
amount of negative samples. A potential solution to such class-imbalance is
joining forces across multiple institutions. Developing a collaborative
computer-aided diagnosis system is challenging in different ways. Patient
privacy and regulations need to be carefully respected. Data across
institutions may be acquired from different devices or imaging protocols,
leading to heterogeneous non-IID data. Also, for learning-based methods, new
optimization strategies working on distributed data are required. Recently,
federated learning has emerged as an effective tool for collaborative learning.
In this setting, local models perform computation on their private data to
update the global model. The order and the frequency of local updates influence
the final global model. Hence, the order in which samples are locally presented
to the optimizers plays an important role. In this work, we define a
memory-aware curriculum learning method for the federated setting. Our
curriculum controls the order of the training samples paying special attention
to those that are forgotten after the deployment of the global model. Our
approach is combined with unsupervised domain adaptation to deal with domain
shift while preserving data privacy. We evaluate our method with three clinical
datasets from different vendors. Our results verify the effectiveness of
federated adversarial learning for the multi-site breast cancer classification.
Moreover, we show that our proposed memory-aware curriculum method is
beneficial to further improve classification performance. Our code is publicly
available at: https://github.com/ameliajimenez/curriculum-federated-learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stateless actor-critic for instance segmentation with high-level priors. (arXiv:2107.02600v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hilt_P/0/1/0/all/0/1">Paul Hilt</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaziakhmedov_E/0/1/0/all/0/1">Edgar Kaziakhmedov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhide_S/0/1/0/all/0/1">Sourabh Bhide</a>, <a href="http://arxiv.org/find/cs/1/au:+Leptin_M/0/1/0/all/0/1">Maria Leptin</a>, <a href="http://arxiv.org/find/cs/1/au:+Pape_C/0/1/0/all/0/1">Constantin Pape</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreshuk_A/0/1/0/all/0/1">Anna Kreshuk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02600">
                                    <div class="article-summary-box-inner">
                                        <span>Instance segmentation is an important computer vision problem which remains
challenging despite impressive recent advances due to deep learning-based
methods. Given sufficient training data, fully supervised methods can yield
excellent performance, but annotation of ground-truth data remains a major
bottleneck, especially for biomedical applications where it has to be performed
by domain experts. The amount of labels required can be drastically reduced by
using rules derived from prior knowledge to guide the segmentation. However,
these rules are in general not differentiable and thus cannot be used with
existing methods. Here, we relax this requirement by using stateless actor
critic reinforcement learning, which enables non-differentiable rewards. We
formulate the instance segmentation problem as graph partitioning and the actor
critic predicts the edge weights driven by the rewards, which are based on the
conformity of segmented instances to high-level priors on object shape,
position or size. The experiments on toy and real datasets demonstrate that we
can achieve excellent performance without any direct supervision based only on
a rich set of priors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Positional Encoding. (arXiv:2107.02561v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jianqiao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramasinghe_S/0/1/0/all/0/1">Sameera Ramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucey_S/0/1/0/all/0/1">Simon Lucey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02561">
                                    <div class="article-summary-box-inner">
                                        <span>It is well noted that coordinate based MLPs benefit greatly -- in terms of
preserving high-frequency information -- through the encoding of coordinate
positions as an array of Fourier features. Hitherto, the rationale for the
effectiveness of these positional encodings has been solely studied through a
Fourier lens. In this paper, we strive to broaden this understanding by showing
that alternative non-Fourier embedding functions can indeed be used for
positional encoding. Moreover, we show that their performance is entirely
determined by a trade-off between the stable rank of the embedded matrix and
the distance preservation between embedded coordinates. We further establish
that the now ubiquitous Fourier feature mapping of position is a special case
that fulfills these conditions. Consequently, we present a more general theory
to analyze positional encoding in terms of shifted basis functions. To this
end, we develop the necessary theoretical formulae and empirically verify that
our theoretical claims hold in practice. Codes available at
https://github.com/osiriszjq/Rethinking-positional-encoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Theory of the Distortion-Perception Tradeoff in Wasserstein Space. (arXiv:2107.02555v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Freirich_D/0/1/0/all/0/1">Dror Freirich</a>, <a href="http://arxiv.org/find/eess/1/au:+Michaeli_T/0/1/0/all/0/1">Tomer Michaeli</a>, <a href="http://arxiv.org/find/eess/1/au:+Meir_R/0/1/0/all/0/1">Ron Meir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02555">
                                    <div class="article-summary-box-inner">
                                        <span>The lower the distortion of an estimator, the more the distribution of its
outputs generally deviates from the distribution of the signals it attempts to
estimate. This phenomenon, known as the perception-distortion tradeoff, has
captured significant attention in image restoration, where it implies that
fidelity to ground truth images comes at the expense of perceptual quality
(deviation from statistics of natural images). However, despite the increasing
popularity of performing comparisons on the perception-distortion plane, there
remains an important open question: what is the minimal distortion that can be
achieved under a given perception constraint? In this paper, we derive a closed
form expression for this distortion-perception (DP) function for the mean
squared-error (MSE) distortion and the Wasserstein-2 perception index. We prove
that the DP function is always quadratic, regardless of the underlying
distribution. This stems from the fact that estimators on the DP curve form a
geodesic in Wasserstein space. In the Gaussian setting, we further provide a
closed form expression for such estimators. For general distributions, we show
how these estimators can be constructed from the estimators at the two extremes
of the tradeoff: The global MSE minimizer, and a minimizer of the MSE under a
perfect perceptual quality constraint. The latter can be obtained as a
stochastic transformation of the former.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point Cloud Registration using Representative Overlapping Points. (arXiv:2107.02583v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lifa Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dongrui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Changwei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_R/0/1/0/all/0/1">Rui Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_Fernandez_F/0/1/0/all/0/1">Francisco G&#xf3;mez-Fern&#xe1;ndez</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_N/0/1/0/all/0/1">Ninghua Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Ziyong Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02583">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud registration is a fundamental task in robotics and computer
vision. Recently, many learning-based point cloud registration methods based on
correspondences have emerged. However, these methods heavily rely on such
correspondences and meet great challenges with partial overlap. In this paper,
we propose ROPNet, a new deep learning model using Representative Overlapping
Points with discriminative features for registration that transforms
partial-to-partial registration into partial-to-complete registration.
Specifically, we propose a context-guided module which uses an encoder to
extract global features for predicting point overlap score. To better find
representative overlapping points, we use the extracted global features for
coarse alignment. Then, we introduce a Transformer to enrich point features and
remove non-representative points based on point overlap score and feature
matching. A similarity matrix is built in a partial-to-complete mode, and
finally, weighted SVD is adopted to estimate a transformation matrix. Extensive
experiments over ModelNet40 using noisy and partially overlapping point clouds
show that the proposed method outperforms traditional and learning-based
methods, achieving state-of-the-art performance. The code is available at
https://github.com/zhulf0804/ROPNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neighbor-Vote: Improving Monocular 3D Object Detection through Neighbor Distance Voting. (arXiv:2107.02493v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiaomeng Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1">Jiajun Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhenxun Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanyong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jianmin Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02493">
                                    <div class="article-summary-box-inner">
                                        <span>As cameras are increasingly deployed in new application domains such as
autonomous driving, performing 3D object detection on monocular images becomes
an important task for visual scene understanding. Recent advances on monocular
3D object detection mainly rely on the &#x60;&#x60;pseudo-LiDAR&#x27;&#x27; generation, which
performs monocular depth estimation and lifts the 2D pixels to pseudo 3D
points. However, depth estimation from monocular images, due to its poor
accuracy, leads to inevitable position shift of pseudo-LiDAR points within the
object. Therefore, the predicted bounding boxes may suffer from inaccurate
location and deformed shape. In this paper, we present a novel neighbor-voting
method that incorporates neighbor predictions to ameliorate object detection
from severely deformed pseudo-LiDAR point clouds. Specifically, each feature
point around the object forms their own predictions, and then the &#x60;&#x60;consensus&#x27;&#x27;
is achieved through voting. In this way, we can effectively combine the
neighbors&#x27; predictions with local prediction and achieve more accurate 3D
detection. To further enlarge the difference between the foreground region of
interest (ROI) pseudo-LiDAR points and the background points, we also encode
the ROI prediction scores of 2D foreground pixels into the corresponding
pseudo-LiDAR points. We conduct extensive experiments on the KITTI benchmark to
validate the merits of our proposed method. Our results on the bird&#x27;s eye view
detection outperform the state-of-the-art performance by a large margin,
especially for the &#x60;&#x60;hard&#x27;&#x27; level detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FloorLevel-Net: Recognizing Floor-Level Lines with Height-Attention-Guided Multi-task Learning. (arXiv:2107.02462v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Mengyang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wei Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chi-Wing Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02462">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to recognize the position and order of the floor-level lines that
divide adjacent building floors can benefit many applications, for example,
urban augmented reality (AR). This work tackles the problem of locating
floor-level lines in street-view images, using a supervised deep learning
approach. Unfortunately, very little data is available for training such a
network $-$ current street-view datasets contain either semantic annotations
that lack geometric attributes, or rectified facades without perspective
priors. To address this issue, we first compile a new dataset and develop a new
data augmentation scheme to synthesize training samples by harassing (i) the
rich semantics of existing rectified facades and (ii) perspective priors of
buildings in diverse street views. Next, we design FloorLevel-Net, a multi-task
learning network that associates explicit features of building facades and
implicit floor-level lines, along with a height-attention mechanism to help
enforce a vertical ordering of floor-level lines. The generated segmentations
are then passed to a second-stage geometry post-processing to exploit
self-constrained geometric priors for plausible and consistent reconstruction
of floor-level lines. Quantitative and qualitative evaluations conducted on
assorted facades in existing datasets and street views from Google demonstrate
the effectiveness of our approach. Also, we present context-aware image overlay
results and show the potentials of our approach in enriching AR-related
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Robustness of Lane Detection Models to Physical-World Adversarial Attacks in Autonomous Driving. (arXiv:2107.02488v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sato_T/0/1/0/all/0/1">Takami Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qi Alfred Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02488">
                                    <div class="article-summary-box-inner">
                                        <span>After the 2017 TuSimple Lane Detection Challenge, its evaluation based on
accuracy and F1 score has become the de facto standard to measure the
performance of lane detection methods. In this work, we conduct the first
large-scale empirical study to evaluate the robustness of state-of-the-art lane
detection methods under physical-world adversarial attacks in autonomous
driving. We evaluate 4 major types of lane detection approaches with the
conventional evaluation and end-to-end evaluation in autonomous driving
scenarios and then discuss the security proprieties of each lane detection
model. We demonstrate that the conventional evaluation fails to reflect the
robustness in end-to-end autonomous driving scenarios. Our results show that
the most robust model on the conventional metrics is the least robust in the
end-to-end evaluation. Although the competition dataset and its metrics have
played a substantial role in developing performant lane detection methods along
with the rapid development of deep neural networks, the conventional evaluation
is becoming obsolete and the gap between the metrics and practicality is
critical. We hope that our study will help the community make further progress
in building a more comprehensive framework to evaluate lane detection models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embracing the Dark Knowledge: Domain Generalization Using Regularized Knowledge Distillation. (arXiv:2107.02629v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yufei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_L/0/1/0/all/0/1">Lap-pui Chau</a>, <a href="http://arxiv.org/find/cs/1/au:+Kot_A/0/1/0/all/0/1">Alex C. Kot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02629">
                                    <div class="article-summary-box-inner">
                                        <span>Though convolutional neural networks are widely used in different tasks, lack
of generalization capability in the absence of sufficient and representative
data is one of the challenges that hinder their practical application. In this
paper, we propose a simple, effective, and plug-and-play training strategy
named Knowledge Distillation for Domain Generalization (KDDG) which is built
upon a knowledge distillation framework with the gradient filter as a novel
regularization term. We find that both the &#x60;&#x60;richer dark knowledge&quot; from the
teacher network, as well as the gradient filter we proposed, can reduce the
difficulty of learning the mapping which further improves the generalization
ability of the model. We also conduct experiments extensively to show that our
framework can significantly improve the generalization capability of deep
neural networks in different tasks including image classification,
segmentation, reinforcement learning by comparing our method with existing
state-of-the-art domain generalization techniques. Last but not the least, we
propose to adopt two metrics to analyze our proposed method in order to better
understand how our proposed method benefits the generalization capability of
deep neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GCN-Based Linkage Prediction for Face Clusteringon Imbalanced Datasets: An Empirical Study. (arXiv:2107.02477v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Huafeng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xingjian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fangyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hei_G/0/1/0/all/0/1">Guangyue Hei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_R/0/1/0/all/0/1">Rong Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02477">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, benefiting from the expressivepower of Graph Convolutional
Networks (GCNs),significant breakthroughs have been made in faceclustering.
However, rare attention has been paidto GCN-based clustering on imbalanced
data. Al-though imbalance problem has been extensivelystudied, the impact of
imbalanced data on GCN-based linkage prediction task is quite different,which
would cause problems in two aspects: im-balanced linkage labels and biased
graph represen-tations. The problem of imbalanced linkage labelsis similar to
that in image classification task, but thelatter is a particular problem in
GCN-based clus-tering via linkage prediction. Significantly biasedgraph
representations in training can cause catas-trophic overfitting of a GCN model.
To tacklethese problems, we evaluate the feasibility of thoseexisting methods
for imbalanced image classifica-tion problem on graphs with extensive
experiments,and present a new method to alleviate the imbal-anced labels and
also augment graph representa-tions using a Reverse-Imbalance Weighted
Sam-pling (RIWS) strategy, followed with insightfulanalyses and discussions. A
series of imbalancedbenchmark datasets synthesized from MS-Celeb-1M and
DeepFashion will be openly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Independent Encoder for Deep Hierarchical Unsupervised Image-to-Image Translation. (arXiv:2107.02494v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_K/0/1/0/all/0/1">Kai Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yinru Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Minqiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bin Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02494">
                                    <div class="article-summary-box-inner">
                                        <span>The main challenges of image-to-image (I2I) translation are to make the
translated image realistic and retain as much information from the source
domain as possible. To address this issue, we propose a novel architecture,
termed as IEGAN, which removes the encoder of each network and introduces an
encoder that is independent of other networks. Compared with previous models,
it embodies three advantages of our model: Firstly, it is more directly and
comprehensively to grasp image information since the encoder no longer receives
loss from generator and discriminator. Secondly, the independent encoder allows
each network to focus more on its own goal which makes the translated image
more realistic. Thirdly, the reduction in the number of encoders performs more
unified image representation. However, when the independent encoder applies two
down-sampling blocks, it&#x27;s hard to extract semantic information. To tackle this
problem, we propose deep and shallow information space containing
characteristic and semantic information, which can guide the model to translate
high-quality images under the task with significant shape or texture change. We
compare IEGAN with other previous models, and conduct researches on semantic
information consistency and component ablation at the same time. These
experiments show the superiority and effectiveness of our architecture. Our
code is published on: https://github.com/Elvinky/IEGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VolNet: Estimating Human Body Part Volumes from a Single RGB Image. (arXiv:2107.02259v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leinen_F/0/1/0/all/0/1">Fabian Leinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cozzolino_V/0/1/0/all/0/1">Vittorio Cozzolino</a>, <a href="http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1">Torsten Sch&#xf6;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02259">
                                    <div class="article-summary-box-inner">
                                        <span>Human body volume estimation from a single RGB image is a challenging problem
despite minimal attention from the research community. However VolNet, an
architecture leveraging 2D and 3D pose estimation, body part segmentation and
volume regression extracted from a single 2D RGB image combined with the
subject&#x27;s body height can be used to estimate the total body volume. VolNet is
designed to predict the 2D and 3D pose as well as the body part segmentation in
intermediate tasks. We generated a synthetic, large-scale dataset of
photo-realistic images of human bodies with a wide range of body shapes and
realistic poses called SURREALvols. By using Volnet and combining multiple
stacked hourglass networks together with ResNeXt, our model correctly predicted
the volume in ~82% of cases with a 10% tolerance threshold. This is a
considerable improvement compared to state-of-the-art solutions such as BodyNet
with only a ~38% success rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Connectivity Matters: Neural Network Pruning Through the Lens of Effective Sparsity. (arXiv:2107.02306v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vysogorets_A/0/1/0/all/0/1">Artem Vysogorets</a>, <a href="http://arxiv.org/find/cs/1/au:+Kempe_J/0/1/0/all/0/1">Julia Kempe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02306">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network pruning is a fruitful area of research with surging interest
in high sparsity regimes. Benchmarking in this domain heavily relies on
faithful representation of the sparsity of subnetworks, which has been
traditionally computed as the fraction of removed connections (direct
sparsity). This definition, however, fails to recognize unpruned parameters
that detached from input or output layers of underlying subnetworks,
potentially underestimating actual effective sparsity: the fraction of
inactivated connections. While this effect might be negligible for moderately
pruned networks (up to 10-100 compression rates), we find that it plays an
increasing role for thinner subnetworks, greatly distorting comparison between
different pruning algorithms. For example, we show that effective compression
of a randomly pruned LeNet-300-100 can be orders of magnitude larger than its
direct counterpart, while no discrepancy is ever observed when using SynFlow
for pruning [Tanaka et al., 2020]. In this work, we adopt the lens of effective
sparsity to reevaluate several recent pruning algorithms on common benchmark
architectures (e.g., LeNet-300-100, VGG-19, ResNet-18) and discover that their
absolute and relative performance changes dramatically in this new and more
appropriate framework. To aim for effective, rather than direct, sparsity, we
develop a low-cost extension to most pruning algorithms. Further, equipped with
effective sparsity as a reference frame, we partially reconfirm that random
pruning with appropriate sparsity allocation across layers performs as well or
better than more sophisticated algorithms for pruning at initialization [Su et
al., 2020]. In response to this observation, using a simple analogy of pressure
distribution in coupled cylinders from physics, we design novel layerwise
sparsity quotas that outperform all existing baselines in the context of random
pruning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A visual introduction to Gaussian Belief Propagation. (arXiv:2107.02308v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ortiz_J/0/1/0/all/0/1">Joseph Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_T/0/1/0/all/0/1">Talfan Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Davison_A/0/1/0/all/0/1">Andrew J. Davison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02308">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we present a visual introduction to Gaussian Belief
Propagation (GBP), an approximate probabilistic inference algorithm that
operates by passing messages between the nodes of arbitrarily structured factor
graphs. A special case of loopy belief propagation, GBP updates rely only on
local information and will converge independently of the message schedule. Our
key argument is that, given recent trends in computing hardware, GBP has the
right computational properties to act as a scalable distributed probabilistic
inference framework for future machine learning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoReD: Generalizing Fake Media Detection with Continual Representation using Distillation. (arXiv:2107.02408v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minha Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tariq_S/0/1/0/all/0/1">Shahroz Tariq</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Simon S. Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02408">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few decades, artificial intelligence research has made
tremendous strides, but it still heavily relies on fixed datasets in stationary
environments. Continual learning is a growing field of research that examines
how AI systems can learn sequentially from a continuous stream of linked data
in the same way that biological systems do. Simultaneously, fake media such as
deepfakes and synthetic face images have emerged as significant to current
multimedia technologies. Recently, numerous method has been proposed which can
detect deepfakes with high accuracy. However, they suffer significantly due to
their reliance on fixed datasets in limited evaluation settings. Therefore, in
this work, we apply continuous learning to neural networks&#x27; learning dynamics,
emphasizing its potential to increase data efficiency significantly. We propose
Continual Representation using Distillation (CoReD) method that employs the
concept of Continual Learning (CoL), Representation Learning (ReL), and
Knowledge Distillation (KD). We design CoReD to perform sequential domain
adaptation tasks on new deepfake and GAN-generated synthetic face datasets,
while effectively minimizing the catastrophic forgetting in a teacher-student
model setting. Our extensive experimental results demonstrate that our method
is efficient at domain adaptation to detect low-quality deepfakes videos and
GAN-generated images from several datasets, outperforming the-state-of-art
baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Adversarial Training incorporating Forgery Attention for Image Forgery Localization. (arXiv:2107.02434v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuo_L/0/1/0/all/0/1">Long Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shunquan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02434">
                                    <div class="article-summary-box-inner">
                                        <span>Image editing techniques enable people to modify the content of an image
without leaving visual traces and thus may cause serious security risks. Hence
the detection and localization of these forgeries become quite necessary and
challenging. Furthermore, unlike other tasks with extensive data, there is
usually a lack of annotated forged images for training due to annotation
difficulties. In this paper, we propose a self-adversarial training strategy
and a reliable coarse-to-fine network that utilizes a self-attention mechanism
to localize forged regions in forgery images. The self-attention module is
based on a Channel-Wise High Pass Filter block (CW-HPF). CW-HPF leverages
inter-channel relationships of features and extracts noise features by high
pass filters. Based on the CW-HPF, a self-attention mechanism, called forgery
attention, is proposed to capture rich contextual dependencies of intrinsic
inconsistency extracted from tampered regions. Specifically, we append two
types of attention modules on top of CW-HPF respectively to model internal
interdependencies in spatial dimension and external dependencies among
channels. We exploit a coarse-to-fine network to enhance the noise
inconsistency between original and tampered regions. More importantly, to
address the issue of insufficient training data, we design a self-adversarial
training strategy that expands training data dynamically to achieve more robust
performance. Specifically, in each training iteration, we perform adversarial
attacks against our network to generate adversarial examples and train our
model on them. Extensive experimental results demonstrate that our proposed
algorithm steadily outperforms state-of-the-art methods by a clear margin in
different benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UACANet: Uncertainty Augmented Context Attention for Polyp Semgnetaion. (arXiv:2107.02368v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1">Taehun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hyemin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Daijin Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02368">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Uncertainty Augmented Context Attention network (UACANet) for
polyp segmentation which consider a uncertain area of the saliency map. We
construct a modified version of U-Net shape network with additional encoder and
decoder and compute a saliency map in each bottom-up stream prediction module
and propagate to the next prediction module. In each prediction module,
previously predicted saliency map is utilized to compute foreground, background
and uncertain area map and we aggregate the feature map with three area maps
for each representation. Then we compute the relation between each
representation and each pixel in the feature map. We conduct experiments on
five popular polyp segmentation benchmarks, Kvasir, CVC-ClinicDB, ETIS,
CVC-ColonDB and CVC-300, and achieve state-of-the-art performance. Especially,
we achieve 76.6% mean Dice on ETIS dataset which is 13.8% improvement compared
to the previous state-of-the-art method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impact of deep learning-based image super-resolution on binary signal detection. (arXiv:2107.02338v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_X/0/1/0/all/0/1">Xiaohui Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Kelkar_V/0/1/0/all/0/1">Varun A. Kelkar</a>, <a href="http://arxiv.org/find/eess/1/au:+Granstedt_J/0/1/0/all/0/1">Jason Granstedt</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Hua Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Anastasio_M/0/1/0/all/0/1">Mark A. Anastasio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02338">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based image super-resolution (DL-SR) has shown great promise in
medical imaging applications. To date, most of the proposed methods for DL-SR
have only been assessed by use of traditional measures of image quality (IQ)
that are commonly employed in the field of computer vision. However, the impact
of these methods on objective measures of image quality that are relevant to
medical imaging tasks remains largely unexplored. In this study, we investigate
the impact of DL-SR methods on binary signal detection performance. Two popular
DL-SR methods, the super-resolution convolutional neural network (SRCNN) and
the super-resolution generative adversarial network (SRGAN), were trained by
use of simulated medical image data. Binary signal-known-exactly with
background-known-statistically (SKE/BKS) and signal-known-statistically with
background-known-statistically (SKS/BKS) detection tasks were formulated.
Numerical observers, which included a neural network-approximated ideal
observer and common linear numerical observers, were employed to assess the
impact of DL-SR on task performance. The impact of the complexity of the DL-SR
network architectures on task-performance was quantified. In addition, the
utility of DL-SR for improving the task-performance of sub-optimal observers
was investigated. Our numerical experiments confirmed that, as expected, DL-SR
could improve traditional measures of IQ. However, for many of the study
designs considered, the DL-SR methods provided little or no improvement in task
performance and could even degrade it. It was observed that DL-SR could improve
the task-performance of sub-optimal observers under certain conditions. The
presented study highlights the urgent need for the objective assessment of
DL-SR methods and suggests avenues for improving their efficacy in medical
imaging applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Mixture Models with Expectation-Maximization for End-to-end Deep Clustering. (arXiv:2107.02453v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tissera_D/0/1/0/all/0/1">Dumindu Tissera</a>, <a href="http://arxiv.org/find/cs/1/au:+Vithanage_K/0/1/0/all/0/1">Kasun Vithanage</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijesinghe_R/0/1/0/all/0/1">Rukshan Wijesinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Xavier_A/0/1/0/all/0/1">Alex Xavier</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayasena_S/0/1/0/all/0/1">Sanath Jayasena</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_S/0/1/0/all/0/1">Subha Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigo_R/0/1/0/all/0/1">Ranga Rodrigo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02453">
                                    <div class="article-summary-box-inner">
                                        <span>Any clustering algorithm must synchronously learn to model the clusters and
allocate data to those clusters in the absence of labels. Mixture model-based
methods model clusters with pre-defined statistical distributions and allocate
data to those clusters based on the cluster likelihoods. They iteratively
refine those distribution parameters and member assignments following the
Expectation-Maximization (EM) algorithm. However, the cluster representability
of such hand-designed distributions that employ a limited amount of parameters
is not adequate for most real-world clustering tasks. In this paper, we realize
mixture model-based clustering with a neural network where the final layer
neurons, with the aid of an additional transformation, approximate cluster
distribution outputs. The network parameters pose as the parameters of those
distributions. The result is an elegant, much-generalized representation of
clusters than a restricted mixture of hand-designed distributions. We train the
network end-to-end via batch-wise EM iterations where the forward pass acts as
the E-step and the backward pass acts as the M-step. In image clustering, the
mixture-based EM objective can be used as the clustering objective along with
existing representation learning methods. In particular, we show that when
mixture-EM optimization is fused with consistency optimization, it improves the
sole consistency optimization performance in clustering. Our trained networks
outperform single-stage deep clustering methods that still depend on k-means,
with unsupervised classification accuracy of 63.8% in STL10, 58% in CIFAR10,
25.9% in CIFAR100, and 98.9% in MNIST.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Double-Uncertainty Assisted Spatial and Temporal Regularization Weighting for Learning-based Registration. (arXiv:2107.02433v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jie Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1">Donghuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jiangpeng Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jagadeesan_J/0/1/0/all/0/1">Jayender Jagadeesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wells_W/0/1/0/all/0/1">William Wells III</a>, <a href="http://arxiv.org/find/cs/1/au:+Frisken_S/0/1/0/all/0/1">Sarah Frisken</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kai Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_R/0/1/0/all/0/1">Raymond Kai-yu Tong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02433">
                                    <div class="article-summary-box-inner">
                                        <span>In order to tackle the difficulty associated with the ill-posed nature of the
image registration problem, researchers use regularization to constrain the
solution space. For most learning-based registration approaches, the
regularization usually has a fixed weight and only constrains the spatial
transformation. Such convention has two limitations: (1) The regularization
strength of a specific image pair should be associated with the content of the
images, thus the &#x60;&#x60;one value fits all&#x27;&#x27; scheme is not ideal; (2) Only spatially
regularizing the transformation (but overlooking the temporal consistency of
different estimations) may not be the best strategy to cope with the
ill-posedness. In this study, we propose a mean-teacher based registration
framework. This framework incorporates an additional \textit{temporal
regularization} term by encouraging the teacher model&#x27;s temporal ensemble
prediction to be consistent with that of the student model. At each training
step, it also automatically adjusts the weights of the \textit{spatial
regularization} and the \textit{temporal regularization} by taking account of
the transformation uncertainty and appearance uncertainty derived from the
perturbed teacher model. We perform experiments on multi- and uni-modal
registration tasks, and the results show that our strategy outperforms the
traditional and learning-based benchmark methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NRST: Non-rigid Surface Tracking from Monocular Video. (arXiv:2107.02407v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1">Marc Habermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weipeng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rhodin_H/0/1/0/all/0/1">Helge Rhodin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zollhoefer_M/0/1/0/all/0/1">Michael Zollhoefer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pons_Moll_G/0/1/0/all/0/1">Gerard Pons-Moll</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02407">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an efficient method for non-rigid surface tracking from monocular
RGB videos. Given a video and a template mesh, our algorithm sequentially
registers the template non-rigidly to each frame. We formulate the per-frame
registration as an optimization problem that includes a novel texture term
specifically tailored towards tracking objects with uniform texture but
fine-scale structure, such as the regular micro-structural patterns of fabric.
Our texture term exploits the orientation information in the micro-structures
of the objects, e.g., the yarn patterns of fabrics. This enables us to
accurately track uniformly colored materials that have these high frequency
micro-structures, for which traditional photometric terms are usually less
effective. The results demonstrate the effectiveness of our method on both
general textured non-rigid objects and monochromatic fabrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adapting Vehicle Detector to Target Domain by Adversarial Prediction Alignment. (arXiv:2107.02411v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koga_Y/0/1/0/all/0/1">Yohei Koga</a>, <a href="http://arxiv.org/find/cs/1/au:+Miyazaki_H/0/1/0/all/0/1">Hiroyuki Miyazaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Shibasaki_R/0/1/0/all/0/1">Ryosuke Shibasaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02411">
                                    <div class="article-summary-box-inner">
                                        <span>While recent advancement of domain adaptation techniques is significant, most
of methods only align a feature extractor and do not adapt a classifier to
target domain, which would be a cause of performance degradation. We propose
novel domain adaptation technique for object detection that aligns prediction
output space. In addition to feature alignment, we aligned predictions of
locations and class confidences of our vehicle detector for satellite images by
adversarial training. The proposed method significantly improved AP score by
over 5%, which shows effectivity of our method for object detection tasks in
satellite images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LightFuse: Lightweight CNN based Dual-exposure Fusion. (arXiv:2107.02299v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadid_Pecht_O/0/1/0/all/0/1">Orly Yadid-Pecht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02299">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks (DCNN) aided high dynamic range (HDR)
imaging recently received a lot of attention. The quality of DCNN generated HDR
images have overperformed the traditional counterparts. However, DCNN is prone
to be computationally intensive and power-hungry. To address the challenge, we
propose LightFuse, a light-weight CNN-based algorithm for extreme dual-exposure
image fusion, which can be implemented on various embedded computing platforms
with limited power and hardware resources. Two sub-networks are utilized: a
GlobalNet (G) and a DetailNet (D). The goal of G is to learn the global
illumination information on the spatial dimension, whereas D aims to enhance
local details on the channel dimension. Both G and D are based solely on
depthwise convolution (D Conv) and pointwise convolution (P Conv) to reduce
required parameters and computations. Experimental results display that the
proposed technique could generate HDR images with plausible details in
extremely exposed regions. Our PSNR score exceeds the other state-of-the-art
approaches by 1.2 to 1.6 times and achieves 1.4 to 20 times FLOP and parameter
reduction compared with others.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Ensemble Noise-Robust K-fold Cross-Validation Selection Method for Noisy Labels. (arXiv:2107.02347v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalander_M/0/1/0/all/0/1">Marcus Kalander</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chanfei Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1">Lujia Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02347">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of training robust and accurate deep neural networks
(DNNs) when subject to various proportions of noisy labels. Large-scale
datasets tend to contain mislabeled samples that can be memorized by DNNs,
impeding the performance. With appropriate handling, this degradation can be
alleviated. There are two problems to consider: how to distinguish clean
samples and how to deal with noisy samples. In this paper, we present Ensemble
Noise-robust K-fold Cross-Validation Selection (E-NKCVS) to effectively select
clean samples from noisy data, solving the first problem. For the second
problem, we create a new pseudo label for any sample determined to have an
uncertain or likely corrupt label. E-NKCVS obtains multiple predicted labels
for each sample and the entropy of these labels is used to tune the weight
given to the pseudo label and the given label. Theoretical analysis and
extensive verification of the algorithms in the noisy label setting are
provided. We evaluate our approach on various image and text classification
tasks where the labels have been manually corrupted with different noise
ratios. Additionally, two large real-world noisy datasets are also used,
Clothing-1M and WebVision. E-NKCVS is empirically shown to be highly tolerant
to considerable proportions of label noise and has a consistent improvement
over state-of-the-art methods. Especially on more difficult datasets with
higher noise ratios, we can achieve a significant improvement over the
second-best model. Moreover, our proposed approach can easily be integrated
into existing DNN methods to improve their robustness against label noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3$\times$ as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results~(e.g., Top-1 accuracy 84.1% trained on 224$\times$224
ImageNet-1K only), while being more scalable on high-resolution images. The
models and source code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Polarized skylight orientation determination artificial neural network. (arXiv:2107.02328v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_H/0/1/0/all/0/1">Huaju Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Hongyang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1">Ke Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1">Xinbo Lv</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02328">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes an artificial neural network to determine orientation
using polarized skylight. This neural network has specific dilated convolution,
which can extract light intensity information of different polarization
directions. Then, the degree of polarization (DOP) and angle of polarization
(AOP) are directly extracted in the network. In addition, the exponential
function encoding of orientation is designed as the network output, which can
better reflect the insect&#x27;s encoding of polarization information, and improve
the accuracy of orientation determination. Finally, training and testing were
conducted on a public polarized skylight navigation dataset, and the
experimental results proved the stability and effectiveness of the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MSE Loss with Outlying Label for Imbalanced Classification. (arXiv:2107.02393v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kato_S/0/1/0/all/0/1">Sota Kato</a>, <a href="http://arxiv.org/find/cs/1/au:+Hotta_K/0/1/0/all/0/1">Kazuhiro Hotta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02393">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose mean squared error (MSE) loss with outlying label
for class imbalanced classification. Cross entropy (CE) loss, which is widely
used for image recognition, is learned so that the probability value of true
class is closer to one by back propagation. However, for imbalanced datasets,
the learning is insufficient for the classes with a small number of samples.
Therefore, we propose a novel classification method using the MSE loss that can
be learned the relationships of all classes no matter which image is input.
Unlike CE loss, MSE loss is possible to equalize the number of back propagation
for all classes and to learn the feature space considering the relationships
between classes as metric learning. Furthermore, instead of the usual one-hot
teacher label, we use a novel teacher label that takes the number of class
samples into account. This induces the outlying label which depends on the
number of samples in each class, and the class with a small number of samples
has outlying margin in a feature space. It is possible to create the feature
space for separating high-difficulty classes and low-difficulty classes. By the
experiments on imbalanced classification and semantic segmentation, we
confirmed that the proposed method was much improved in comparison with
standard CE loss and conventional methods, even though only the loss and
teacher labels were changed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mind Your Outliers! Investigating the Negative Impact of Outliers on Active Learning for Visual Question Answering. (arXiv:2107.02331v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karamcheti_S/0/1/0/all/0/1">Siddharth Karamcheti</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1">Ranjay Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1">Christopher D. Manning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02331">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning promises to alleviate the massive data needs of supervised
machine learning: it has successfully improved sample efficiency by an order of
magnitude on traditional tasks like topic classification and object
recognition. However, we uncover a striking contrast to this promise: across 5
models and 4 datasets on the task of visual question answering, a wide variety
of active learning approaches fail to outperform random selection. To
understand this discrepancy, we profile 8 active learning methods on a
per-example basis, and identify the problem as collective outliers -- groups of
examples that active learning methods prefer to acquire but models fail to
learn (e.g., questions that ask about text in images or require external
knowledge). Through systematic ablation experiments and qualitative
visualizations, we verify that collective outliers are a general phenomenon
responsible for degrading pool-based active learning. Notably, we show that
active learning sample efficiency increases significantly as the number of
collective outliers in the active learning pool decreases. We conclude with a
discussion and prescriptive recommendations for mitigating the effects of these
outliers in future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Morphological Classification of Galaxies in S-PLUS using an Ensemble of Convolutional Networks. (arXiv:2107.02287v1 [astro-ph.GA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Cardoso_N/0/1/0/all/0/1">N. M. Cardoso</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Schwarz_G/0/1/0/all/0/1">G. B. O. Schwarz</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Dias_L/0/1/0/all/0/1">L. O. Dias</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bom_C/0/1/0/all/0/1">C. R. Bom</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sodre_L/0/1/0/all/0/1">L. Sodr&#xe9; Jr.</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Oliveira_C/0/1/0/all/0/1">C. Mendes de Oliveira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02287">
                                    <div class="article-summary-box-inner">
                                        <span>The universe is composed of galaxies that have diverse shapes. Once the
structure of a galaxy is determined, it is possible to obtain important
information about its formation and evolution. Morphologically classifying
galaxies means cataloging them according to their visual appearance and the
classification is linked to the physical properties of the galaxy. A
morphological classification made through visual inspection is subject to
biases introduced by subjective observations made by human volunteers. For this
reason, systematic, objective and easily reproducible classification of
galaxies has been gaining importance since the astronomer Edwin Hubble created
his famous classification method. In this work, we combine accurate visual
classifications of the Galaxy Zoo project with \emph {Deep Learning} methods.
The goal is to find an efficient technique at human performance level
classification, but in a systematic and automatic way, for classification of
elliptical and spiral galaxies. For this, a neural network model was created
through an Ensemble of four other convolutional models, allowing a greater
accuracy in the classification than what would be obtained with any one
individual. Details of the individual models and improvements made are also
described. The present work is entirely based on the analysis of images (not
parameter tables) from DR1 (www.datalab.noao.edu) of the Southern Photometric
Local Universe Survey (S-PLUS). In terms of classification, we achieved, with
the Ensemble, an accuracy of $\approx 99 \%$ in the test sample (using
pre-trained networks).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-TCL: Semi-Supervised Track Contrastive Representation Learning. (arXiv:2107.02396v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuo Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingze Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongxin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wei Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02396">
                                    <div class="article-summary-box-inner">
                                        <span>Online tracking of multiple objects in videos requires strong capacity of
modeling and matching object appearances. Previous methods for learning
appearance embedding mostly rely on instance-level matching without considering
the temporal continuity provided by videos. We design a new instance-to-track
matching objective to learn appearance embedding that compares a candidate
detection to the embedding of the tracks persisted in the tracker. It enables
us to learn not only from videos labeled with complete tracks, but also
unlabeled or partially labeled videos. We implement this learning objective in
a unified form following the spirit of constrastive loss. Experiments on
multiple object tracking datasets demonstrate that our method can effectively
learning discriminative appearance embeddings in a semi-supervised fashion and
outperform state of the art methods on representative benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptation via CycleGAN for Retina Segmentation in Optical Coherence Tomography. (arXiv:2107.02345v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_R/0/1/0/all/0/1">Ricky Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_T/0/1/0/all/0/1">Timothy T. Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_G/0/1/0/all/0/1">Gavin Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_D/0/1/0/all/0/1">Da Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarunic_M/0/1/0/all/0/1">Marinko V. Sarunic</a>, <a href="http://arxiv.org/find/eess/1/au:+Beg_M/0/1/0/all/0/1">Mirza Faisal Beg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02345">
                                    <div class="article-summary-box-inner">
                                        <span>With the FDA approval of Artificial Intelligence (AI) for point-of-care
clinical diagnoses, model generalizability is of the utmost importance as
clinical decision-making must be domain-agnostic. A method of tackling the
problem is to increase the dataset to include images from a multitude of
domains; while this technique is ideal, the security requirements of medical
data is a major limitation. Additionally, researchers with developed tools
benefit from the addition of open-sourced data, but are limited by the
difference in domains. Herewith, we investigated the implementation of a
Cycle-Consistent Generative Adversarial Networks (CycleGAN) for the domain
adaptation of Optical Coherence Tomography (OCT) volumes. This study was done
in collaboration with the Biomedical Optics Research Group and Functional &amp;
Anatomical Imaging &amp; Shape Analysis Lab at Simon Fraser University. In this
study, we investigated a learning-based approach of adapting the domain of a
publicly available dataset, UK Biobank dataset (UKB). To evaluate the
performance of domain adaptation, we utilized pre-existing retinal layer
segmentation tools developed on a different set of RETOUCH OCT data. This study
provides insight on state-of-the-art tools for domain adaptation compared to
traditional processing techniques as well as a pipeline for adapting publicly
available retinal data to the domains previously used by our collaborators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated age-related macular degeneration area estimation -- first results. (arXiv:2107.02211v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Peciulis_R/0/1/0/all/0/1">Rokas Pe&#x10d;iulis</a>, <a href="http://arxiv.org/find/eess/1/au:+Lukosevicius_M/0/1/0/all/0/1">Mantas Luko&#x161;evi&#x10d;ius</a>, <a href="http://arxiv.org/find/eess/1/au:+Krisciukaitis_A/0/1/0/all/0/1">Algimantas Kri&#x161;&#x10d;iukaitis</a>, <a href="http://arxiv.org/find/eess/1/au:+Petrolis_R/0/1/0/all/0/1">Robertas Petrolis</a>, <a href="http://arxiv.org/find/eess/1/au:+Buteikiene_D/0/1/0/all/0/1">Dovil&#x117; Buteikien&#x117;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02211">
                                    <div class="article-summary-box-inner">
                                        <span>This work aims to research an automatic method for detecting Age-related
Macular Degeneration (AMD) lesions in RGB eye fundus images. For this, we align
invasively obtained eye fundus contrast images (the &quot;golden standard&quot;
diagnostic) to the RGB ones and use them to hand-annotate the lesions. This is
done using our custom-made tool. Using the data, we train and test five
different convolutional neural networks: a custom one to classify healthy and
AMD-affected eye fundi, and four well-known networks: ResNet50, ResNet101,
MobileNetV3, and UNet to segment (localize) the AMD lesions in the affected eye
fundus images. We achieve 93.55% accuracy or 69.71% Dice index as the
preliminary best results in segmentation with MobileNetV3.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Convolution for Re-ranking in Person Re-identification. (arXiv:2107.02220v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qian Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weihua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Rong Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02220">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, deep learning is widely applied to extract features for similarity
computation in person re-identification (re-ID) and have achieved great
success. However, due to the non-overlapping between training and testing IDs,
the difference between the data used for model training and the testing data
makes the performance of learned feature degraded during testing. Hence,
re-ranking is proposed to mitigate this issue and various algorithms have been
developed. However, most of existing re-ranking methods focus on replacing the
Euclidean distance with sophisticated distance metrics, which are not friendly
to downstream tasks and hard to be used for fast retrieval of massive data in
real applications. In this work, we propose a graph-based re-ranking method to
improve learned features while still keeping Euclidean distance as the
similarity metric. Inspired by graph convolution networks, we develop an
operator to propagate features over an appropriate graph. Since graph is the
essential key for the propagation, two important criteria are considered for
designing the graph, and three different graphs are explored accordingly.
Furthermore, a simple yet effective method is proposed to generate a profile
vector for each tracklet in videos, which helps extend our method to video
re-ID. Extensive experiments on three benchmark data sets, e.g., Market-1501,
Duke, and MARS, demonstrate the effectiveness of our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Histogram of Cell Types: Deep Learning for Automated Bone Marrow Cytology. (arXiv:2107.02293v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tayebi_R/0/1/0/all/0/1">Rohollah Moosavi Tayebi</a>, <a href="http://arxiv.org/find/eess/1/au:+Mu_Y/0/1/0/all/0/1">Youqing Mu</a>, <a href="http://arxiv.org/find/eess/1/au:+Dehkharghanian_T/0/1/0/all/0/1">Taher Dehkharghanian</a>, <a href="http://arxiv.org/find/eess/1/au:+Ross_C/0/1/0/all/0/1">Catherine Ross</a>, <a href="http://arxiv.org/find/eess/1/au:+Sur_M/0/1/0/all/0/1">Monalisa Sur</a>, <a href="http://arxiv.org/find/eess/1/au:+Foley_R/0/1/0/all/0/1">Ronan Foley</a>, <a href="http://arxiv.org/find/eess/1/au:+Tizhoosh_H/0/1/0/all/0/1">Hamid R. Tizhoosh</a>, <a href="http://arxiv.org/find/eess/1/au:+Campbell_C/0/1/0/all/0/1">Clinton JV Campbell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02293">
                                    <div class="article-summary-box-inner">
                                        <span>Bone marrow cytology is required to make a hematological diagnosis,
influencing critical clinical decision points in hematology. However, bone
marrow cytology is tedious, limited to experienced reference centers and
associated with high inter-observer variability. This may lead to a delayed or
incorrect diagnosis, leaving an unmet need for innovative supporting
technologies. We have developed the first ever end-to-end deep learning-based
technology for automated bone marrow cytology. Starting with a bone marrow
aspirate digital whole slide image, our technology rapidly and automatically
detects suitable regions for cytology, and subsequently identifies and
classifies all bone marrow cells in each region. This collective
cytomorphological information is captured in a novel representation called
Histogram of Cell Types (HCT) quantifying bone marrow cell class probability
distribution and acting as a cytological &quot;patient fingerprint&quot;. The approach
achieves high accuracy in region detection (0.97 accuracy and 0.99 ROC AUC),
and cell detection and cell classification (0.75 mAP, 0.78 F1-score,
Log-average miss rate of 0.31). HCT has potential to revolutionize
hematopathology diagnostic workflows, leading to more cost-effective, accurate
diagnosis and opening the door to precision medicine.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransformerFusion: Monocular RGB Scene Reconstruction using Transformers. (arXiv:2107.02191v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bozic_A/0/1/0/all/0/1">Alja&#x17e; Bo&#x17e;i&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Palafox_P/0/1/0/all/0/1">Pablo Palafox</a>, <a href="http://arxiv.org/find/cs/1/au:+Thies_J/0/1/0/all/0/1">Justus Thies</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1">Angela Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Niessner_M/0/1/0/all/0/1">Matthias Nie&#xdf;ner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02191">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce TransformerFusion, a transformer-based 3D scene reconstruction
approach. From an input monocular RGB video, the video frames are processed by
a transformer network that fuses the observations into a volumetric feature
grid representing the scene; this feature grid is then decoded into an implicit
3D scene representation. Key to our approach is the transformer architecture
that enables the network to learn to attend to the most relevant image frames
for each 3D location in the scene, supervised only by the scene reconstruction
task. Features are fused in a coarse-to-fine fashion, storing fine-level
features only where needed, requiring lower memory storage and enabling fusion
at interactive rates. The feature grid is then decoded to a higher-resolution
scene reconstruction, using an MLP-based surface occupancy prediction from
interpolated coarse-to-fine 3D features. Our approach results in an accurate
surface reconstruction, outperforming state-of-the-art multi-view stereo depth
estimation methods, fully-convolutional 3D reconstruction approaches, and
approaches using LSTM- or GRU-based recurrent networks for video sequence
fusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Fusion Vision Transformer Fine-Grained Visual Categorization. (arXiv:2107.02341v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xiaohan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yongsheng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02341">
                                    <div class="article-summary-box-inner">
                                        <span>The core for tackling the fine-grained visual categorization (FGVC) is to
learn subtleyet discriminative features. Most previous works achieve this by
explicitly selecting thediscriminative parts or integrating the attention
mechanism via CNN-based approaches.However, these methods enhance the
computational complexity and make the modeldominated by the regions containing
the most of the objects. Recently, vision trans-former (ViT) has achieved SOTA
performance on general image recognition tasks. Theself-attention mechanism
aggregates and weights the information from all patches to theclassification
token, making it perfectly suitable for FGVC. Nonetheless, the classifi-cation
token in the deep layer pays more attention to the global information,
lackingthe local and low-level features that are essential for FGVC. In this
work, we proposea novel pure transformer-based framework Feature Fusion Vision
Transformer (FFVT)where we aggregate the important tokens from each transformer
layer to compensate thelocal, low-level and middle-level information. We design
a novel token selection mod-ule called mutual attention weight selection (MAWS)
to guide the network effectivelyand efficiently towards selecting
discriminative tokens without introducing extra param-eters. We verify the
effectiveness of FFVT on three benchmarks where FFVT achievesthe
state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The RSNA-ASNR-MICCAI BraTS 2021 Benchmark on Brain Tumor Segmentation and Radiogenomic Classification. (arXiv:2107.02314v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baid_U/0/1/0/all/0/1">Ujjwal Baid</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghodasara_S/0/1/0/all/0/1">Satyam Ghodasara</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilello_M/0/1/0/all/0/1">Michel Bilello</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_S/0/1/0/all/0/1">Suyash Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Calabrese_E/0/1/0/all/0/1">Evan Calabrese</a>, <a href="http://arxiv.org/find/cs/1/au:+Colak_E/0/1/0/all/0/1">Errol Colak</a>, <a href="http://arxiv.org/find/cs/1/au:+Farahani_K/0/1/0/all/0/1">Keyvan Farahani</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1">Jayashree Kalpathy-Cramer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitamura_F/0/1/0/all/0/1">Felipe C. Kitamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Pati_S/0/1/0/all/0/1">Sarthak Pati</a>, <a href="http://arxiv.org/find/cs/1/au:+Prevedello_L/0/1/0/all/0/1">Luciano M. Prevedello</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudie_J/0/1/0/all/0/1">Jeffrey D. Rudie</a>, <a href="http://arxiv.org/find/cs/1/au:+Sako_C/0/1/0/all/0/1">Chiharu Sako</a>, <a href="http://arxiv.org/find/cs/1/au:+Shinohara_R/0/1/0/all/0/1">Russell T. Shinohara</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergquist_T/0/1/0/all/0/1">Timothy Bergquist</a>, <a href="http://arxiv.org/find/cs/1/au:+Chai_R/0/1/0/all/0/1">Rong Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Eddy_J/0/1/0/all/0/1">James Eddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Elliott_J/0/1/0/all/0/1">Julia Elliott</a>, <a href="http://arxiv.org/find/cs/1/au:+Reade_W/0/1/0/all/0/1">Walter Reade</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaffter_T/0/1/0/all/0/1">Thomas Schaffter</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1">Thomas Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jiaxin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Annotators_B/0/1/0/all/0/1">BraTS Annotators</a>, <a href="http://arxiv.org/find/cs/1/au:+Davatzikos_C/0/1/0/all/0/1">Christos Davatzikos</a>, <a href="http://arxiv.org/find/cs/1/au:+Mongan_J/0/1/0/all/0/1">John Mongan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hess_C/0/1/0/all/0/1">Christopher Hess</a>, <a href="http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1">Soonmee Cha</a>, <a href="http://arxiv.org/find/cs/1/au:+Villanueva_Meyer_J/0/1/0/all/0/1">Javier Villanueva-Meyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Freymann_J/0/1/0/all/0/1">John B. Freymann</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirby_J/0/1/0/all/0/1">Justin S. Kirby</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiestler_B/0/1/0/all/0/1">Benedikt Wiestler</a>, <a href="http://arxiv.org/find/cs/1/au:+Crivellaro_P/0/1/0/all/0/1">Priscila Crivellaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Colen_R/0/1/0/all/0/1">Rivka R.Colen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotrotsou_A/0/1/0/all/0/1">Aikaterini Kotrotsou</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcus_D/0/1/0/all/0/1">Daniel Marcus</a>, <a href="http://arxiv.org/find/cs/1/au:+Milchenko_M/0/1/0/all/0/1">Mikhail Milchenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Nazeri_A/0/1/0/all/0/1">Arash Nazeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Fathallah_Shaykh_H/0/1/0/all/0/1">Hassan Fathallah-Shaykh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiest_R/0/1/0/all/0/1">Roland Wiest</a>, <a href="http://arxiv.org/find/cs/1/au:+Jakab_A/0/1/0/all/0/1">Andras Jakab</a>, <a href="http://arxiv.org/find/cs/1/au:+Weber_M/0/1/0/all/0/1">Marc-Andre Weber</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_A/0/1/0/all/0/1">Abhishek Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Menze_B/0/1/0/all/0/1">Bjoern Menze</a>, <a href="http://arxiv.org/find/cs/1/au:+Flanders_A/0/1/0/all/0/1">Adam E. Flanders</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakas_S/0/1/0/all/0/1">Spyridon Bakas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02314">
                                    <div class="article-summary-box-inner">
                                        <span>The BraTS 2021 challenge celebrates its 10th anniversary and is jointly
organized by the Radiological Society of North America (RSNA), the American
Society of Neuroradiology (ASNR), and the Medical Image Computing and Computer
Assisted Interventions (MICCAI) society. Since its inception, BraTS has been
focusing on being a common benchmarking venue for brain glioma segmentation
algorithms, with well-curated multi-institutional multi-parametric magnetic
resonance imaging (mpMRI) data. Gliomas are the most common primary
malignancies of the central nervous system, with varying degrees of
aggressiveness and prognosis. The RSNA-ASNR-MICCAI BraTS 2021 challenge targets
the evaluation of computational algorithms assessing the same tumor
compartmentalization, as well as the underlying tumor&#x27;s molecular
characterization, in pre-operative baseline mpMRI data from 2,000 patients.
Specifically, the two tasks that BraTS 2021 focuses on are: a) the segmentation
of the histologically distinct brain tumor sub-regions, and b) the
classification of the tumor&#x27;s O[6]-methylguanine-DNA methyltransferase (MGMT)
promoter methylation status. The performance evaluation of all participating
algorithms in BraTS 2021 will be conducted through the Sage Bionetworks Synapse
platform (Task 1) and Kaggle (Task 2), concluding in distributing to the top
ranked participants monetary awards of $60,000 collectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overlapping Spaces for Compact Graph Representations. (arXiv:2007.02445v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shevkunov_K/0/1/0/all/0/1">Kirill Shevkunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1">Liudmila Prokhorenkova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.02445">
                                    <div class="article-summary-box-inner">
                                        <span>Various non-trivial spaces are becoming popular for embedding structured data
such as graphs, texts, or images. Following spherical and hyperbolic spaces,
more general product spaces have been proposed. However, searching for the best
configuration of product space is a resource-intensive procedure, which reduces
the practical applicability of the idea. We generalize the concept of product
space and introduce an overlapping space that does not have the configuration
search problem. The main idea is to allow subsets of coordinates to be shared
between spaces of different types (Euclidean, hyperbolic, spherical). As a
result, parameter optimization automatically learns the optimal configuration.
Additionally, overlapping spaces allow for more compact representations since
their geometry is more complex. Our experiments confirm that overlapping spaces
outperform the competitors in graph embedding tasks. Here, we consider both
distortion setup, where the aim is to preserve distances, and ranking setup,
where the relative order should be preserved. The proposed method effectively
solves the problem and outperforms the competitors in both settings. We also
perform an empirical analysis in a realistic information retrieval task, where
we compare all spaces by incorporating them into DSSM. In this case, the
proposed overlapping space consistently achieves nearly optimal results without
any configuration tuning. This allows for reducing training time, which can be
significant in large-scale applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KATRec: Knowledge Aware aTtentive Sequential Recommendations. (arXiv:2012.03323v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Amjadi_M/0/1/0/all/0/1">Mehrnaz Amjadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Taheri_S/0/1/0/all/0/1">Seyed Danial Mohseni Taheri</a>, <a href="http://arxiv.org/find/cs/1/au:+Tulabandhula_T/0/1/0/all/0/1">Theja Tulabandhula</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03323">
                                    <div class="article-summary-box-inner">
                                        <span>Sequential recommendation systems model dynamic preferences of users based on
their historical interactions with platforms. Despite recent progress, modeling
short-term and long-term behavior of users in such systems is nontrivial and
challenging. To address this, we present a solution enhanced by a knowledge
graph called KATRec (Knowledge Aware aTtentive sequential Recommendations).
KATRec learns the short and long-term interests of users by modeling their
sequence of interacted items and leveraging pre-existing side information
through a knowledge graph attention network. Our novel knowledge graph-enhanced
sequential recommender contains item multi-relations at the entity-level and
users&#x27; dynamic sequences at the item-level. KATRec improves item representation
learning by considering higher-order connections and incorporating them in user
preference representation while recommending the next item. Experiments on
three public datasets show that KATRec outperforms state-of-the-art
recommendation models and demonstrates the importance of modeling both temporal
and side information to achieve high-quality recommendations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP Contributions for a Research Knowledge Graph. (arXiv:2106.07385v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1">Jennifer D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1">S&#xf6;ren Auer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersen_T/0/1/0/all/0/1">Ted Pedersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07385">
                                    <div class="article-summary-box-inner">
                                        <span>There is currently a gap between the natural language expression of scholarly
publications and their structured semantic content modeling to enable
intelligent content search. With the volume of research growing exponentially
every year, a search feature operating over semantically structured content is
compelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. &#x27;the NCG
task&#x27;) tasks participants to develop automated systems that structure
contributions from NLP scholarly articles in the English language. Being the
first-of-its-kind in the SemEval series, the task released structured data from
NLP scholarly articles at three levels of information granularity, i.e. at
sentence-level, phrase-level, and phrases organized as triples toward Knowledge
Graph (KG) building. The sentence-level annotations comprised the few sentences
about the article&#x27;s contribution. The phrase-level annotations were scientific
term and predicate phrases from the contribution sentences. Finally, the
triples constituted the research overview KG. For the Shared Task,
participating systems were then expected to automatically classify contribution
sentences, extract scientific terms and relations from the sentences, and
organize them as KG triples.

Overall, the task drew a strong participation demographic of seven teams and
27 participants. The best end-to-end task system classified contribution
sentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While
the absolute performance to generate triples remains low, in the conclusion of
this article, the difficulty of producing such data and as a consequence of
modeling it is highlighted.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CausalRec: Causal Inference for Visual Debiasing in Visually-Aware Recommendation. (arXiv:2107.02390v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruihong_Q/0/1/0/all/0/1">Qiu Ruihong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_W/0/1/0/all/0/1">Wang Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhi_C/0/1/0/all/0/1">Chen Zhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hongzhi_Y/0/1/0/all/0/1">Yin Hongzhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zi_H/0/1/0/all/0/1">Huang Zi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02390">
                                    <div class="article-summary-box-inner">
                                        <span>Visually-aware recommendation on E-commerce platforms aims to leverage visual
information of items to predict a user&#x27;s preference. It is commonly observed
that user&#x27;s attention to visual features does not always reflect the real
preference. Although a user may click and view an item in light of a visual
satisfaction of their expectations, a real purchase does not always occur due
to the unsatisfaction of other essential features (e.g., brand, material,
price). We refer to the reason for such a visually related interaction
deviating from the real preference as a visual bias. Existing visually-aware
models make use of the visual features as a separate collaborative signal
similarly to other features to directly predict the user&#x27;s preference without
considering a potential bias, which gives rise to a visually biased
recommendation. In this paper, we derive a causal graph to identify and analyze
the visual bias of these existing methods. In this causal graph, the visual
feature of an item acts as a mediator, which could introduce a spurious
relationship between the user and the item. To eliminate this spurious
relationship that misleads the prediction of the user&#x27;s real preference, an
intervention and a counterfactual inference are developed over the mediator.
Particularly, the Total Indirect Effect is applied for a debiased prediction
during the testing phase of the model. This causal inference framework is model
agnostic such that it can be integrated into the existing methods. Furthermore,
we propose a debiased visually-aware recommender system, denoted as CausalRec
to effectively retain the supportive significance of the visual information and
remove the visual bias. Extensive experiments are conducted on eight benchmark
datasets, which shows the state-of-the-art performance of CausalRec and the
efficacy of debiasing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network. (arXiv:2107.02757v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhibin Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dongsheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chaojie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenchao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yewen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02757">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical topic models such as the gamma belief network (GBN) have
delivered promising results in mining multi-layer document representations and
discovering interpretable topic taxonomies. However, they often assume in the
prior that the topics at each layer are independently drawn from the Dirichlet
distribution, ignoring the dependencies between the topics both at the same
layer and across different layers. To relax this assumption, we propose
sawtooth factorial topic embedding guided GBN, a deep generative model of
documents that captures the dependencies and semantic similarities between the
topics in the embedding space. Specifically, both the words and topics are
represented as embedding vectors of the same dimension. The topic matrix at a
layer is factorized into the product of a factor loading matrix and a topic
embedding matrix, the transpose of which is set as the factor loading matrix of
the layer above. Repeating this particular type of factorization, which shares
components between adjacent layers, leads to a structure referred to as
sawtooth factorization. An auto-encoding variational inference network is
constructed to optimize the model parameter via stochastic gradient descent.
Experiments on big corpora show that our models outperform other neural topic
models on extracting deeper interpretable topics and deriving better document
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring the Scope of Using News Articles to Understand Development Patterns of Districts in India. (arXiv:2107.02765v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1">Mehak Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Saifi_S/0/1/0/all/0/1">Shayan Saifi</a>, <a href="http://arxiv.org/find/cs/1/au:+Verma_K/0/1/0/all/0/1">Konark Verma</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekha_K/0/1/0/all/0/1">Kumari Rekha</a>, <a href="http://arxiv.org/find/cs/1/au:+Seth_A/0/1/0/all/0/1">Aaditeshwar Seth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02765">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding what factors bring about socio-economic development may often
suffer from the streetlight effect, of analyzing the effect of only those
variables that have been measured and are therefore available for analysis. How
do we check whether all worthwhile variables have been instrumented and
considered when building an econometric development model? We attempt to
address this question by building unsupervised learning methods to identify and
rank news articles about diverse events occurring in different districts of
India, that can provide insights about what may have transpired in the
districts. This can help determine whether variables related to these events
are indeed available or not to model the development of these districts. We
also describe several other applications that emerge from this approach, such
as to use news articles to understand why pairs of districts that may have had
similar socio-economic indicators approximately ten years back ended up at
different levels of development currently, and another application that
generates a newsfeed of unusual news articles that do not conform to news
articles about typical districts with a similar socio-economic profile. These
applications outline the need for qualitative data to augment models based on
quantitative data, and are meant to open up research on new ways to mine
information from unstructured qualitative data to understand development.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gender Recognition in Informal and Formal Language Scenarios via Transfer Learning. (arXiv:2107.02759v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Escobar_Grisales_D/0/1/0/all/0/1">Daniel Escobar-Grisales</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasquez_Correa_J/0/1/0/all/0/1">Juan Camilo Vasquez-Correa</a>, <a href="http://arxiv.org/find/cs/1/au:+Orozco_Arroyave_J/0/1/0/all/0/1">Juan Rafael Orozco-Arroyave</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02759">
                                    <div class="article-summary-box-inner">
                                        <span>The interest in demographic information retrieval based on text data has
increased in the research community because applications have shown success in
different sectors such as security, marketing, heath-care, and others.
Recognition and identification of demographic traits such as gender, age,
location, or personality based on text data can help to improve different
marketing strategies. For instance it makes it possible to segment and to
personalize offers, thus products and services are exposed to the group of
greatest interest. This type of technology has been discussed widely in
documents from social media. However, the methods have been poorly studied in
data with a more formal structure, where there is no access to emoticons,
mentions, and other linguistic phenomena that are only present in social media.
This paper proposes the use of recurrent and convolutional neural networks, and
a transfer learning strategy for gender recognition in documents that are
written in informal and formal languages. Models are tested in two different
databases consisting of Tweets and call-center conversations. Accuracies of up
to 75\% are achieved for both databases. The results also indicate that it is
possible to transfer the knowledge from a system trained on a specific type of
expressions or idioms such as those typically used in social media into a more
formal type of text data, where the amount of data is more scarce and its
structure is completely different.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EVARS-GPR: EVent-triggered Augmented Refitting of Gaussian Process Regression for Seasonal Data. (arXiv:2107.02463v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Haselbeck_F/0/1/0/all/0/1">Florian Haselbeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Grimm_D/0/1/0/all/0/1">Dominik G. Grimm</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02463">
                                    <div class="article-summary-box-inner">
                                        <span>Time series forecasting is a growing domain with diverse applications.
However, changes of the system behavior over time due to internal or external
influences are challenging. Therefore, predictions of a previously learned
fore-casting model might not be useful anymore. In this paper, we present
EVent-triggered Augmented Refitting of Gaussian Process Regression for Seasonal
Data (EVARS-GPR), a novel online algorithm that is able to handle sudden shifts
in the target variable scale of seasonal data. For this purpose, EVARS-GPR
com-bines online change point detection with a refitting of the prediction
model using data augmentation for samples prior to a change point. Our
experiments on sim-ulated data show that EVARS-GPR is applicable for a wide
range of output scale changes. EVARS-GPR has on average a 20.8 % lower RMSE on
different real-world datasets compared to methods with a similar computational
resource con-sumption. Furthermore, we show that our algorithm leads to a
six-fold reduction of the averaged runtime in relation to all comparison
partners with a periodical refitting strategy. In summary, we present a
computationally efficient online fore-casting algorithm for seasonal time
series with changes of the target variable scale and demonstrate its
functionality on simulated as well as real-world data. All code is publicly
available on GitHub: https://github.com/grimmlab/evars-gpr.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Visual Attention-Based Transfer Clustering. (arXiv:2107.02415v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gunari_A/0/1/0/all/0/1">Akshaykumar Gunari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kudari_S/0/1/0/all/0/1">Shashidhar Veerappa Kudari</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadagadalli_S/0/1/0/all/0/1">Sukanya Nadagadalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Goudnaik_K/0/1/0/all/0/1">Keerthi Goudnaik</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabib_R/0/1/0/all/0/1">Ramesh Ashok Tabib</a>, <a href="http://arxiv.org/find/cs/1/au:+Mudenagudi_U/0/1/0/all/0/1">Uma Mudenagudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jamadandi_A/0/1/0/all/0/1">Adarsh Jamadandi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02415">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a methodology to improvise the technique of deep
transfer clustering (DTC) when applied to the less variant data distribution.
Clustering can be considered as the most important unsupervised learning
problem. A simple definition of clustering can be stated as &quot;the process of
organizing objects into groups, whose members are similar in some way&quot;. Image
clustering is a crucial but challenging task in the domain machine learning and
computer vision. We have discussed the clustering of the data collection where
the data is less variant. We have discussed the improvement by using
attention-based classifiers rather than regular classifiers as the initial
feature extractors in the deep transfer clustering. We have enforced the model
to learn only the required region of interest in the images to get the
differentiable and robust features that do not take into account the
background. This paper is the improvement of the existing deep transfer
clustering for less variant data distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NP-DRAW: A Non-Parametric Structured Latent Variable Model for Image Generation. (arXiv:2106.13435v2 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_X/0/1/0/all/0/1">Xiaohui Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1">Raquel Urtasun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1">Richard Zemel</a>, <a href="http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1">Sanja Fidler</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1">Renjie Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13435">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a non-parametric structured latent variable model
for image generation, called NP-DRAW, which sequentially draws on a latent
canvas in a part-by-part fashion and then decodes the image from the canvas.
Our key contributions are as follows. 1) We propose a non-parametric prior
distribution over the appearance of image parts so that the latent variable
&#x60;&#x60;what-to-draw&#x27;&#x27; per step becomes a categorical random variable. This improves
the expressiveness and greatly eases the learning compared to Gaussians used in
the literature. 2) We model the sequential dependency structure of parts via a
Transformer, which is more powerful and easier to train compared to RNNs used
in the literature. 3) We propose an effective heuristic parsing algorithm to
pre-train the prior. Experiments on MNIST, Omniglot, CIFAR-10, and CelebA show
that our method significantly outperforms previous structured image models like
DRAW and AIR and is competitive to other generic generative models. Moreover,
we show that our model&#x27;s inherent compositionality and interpretability bring
significant benefits in the low-data learning regime and latent space editing.
Code is available at https://github.com/ZENGXH/NPDRAW.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Morphological Classification of Galaxies in S-PLUS using an Ensemble of Convolutional Networks. (arXiv:2107.02287v1 [astro-ph.GA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Cardoso_N/0/1/0/all/0/1">N. M. Cardoso</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Schwarz_G/0/1/0/all/0/1">G. B. O. Schwarz</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Dias_L/0/1/0/all/0/1">L. O. Dias</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bom_C/0/1/0/all/0/1">C. R. Bom</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sodre_L/0/1/0/all/0/1">L. Sodr&#xe9; Jr.</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Oliveira_C/0/1/0/all/0/1">C. Mendes de Oliveira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02287">
                                    <div class="article-summary-box-inner">
                                        <span>The universe is composed of galaxies that have diverse shapes. Once the
structure of a galaxy is determined, it is possible to obtain important
information about its formation and evolution. Morphologically classifying
galaxies means cataloging them according to their visual appearance and the
classification is linked to the physical properties of the galaxy. A
morphological classification made through visual inspection is subject to
biases introduced by subjective observations made by human volunteers. For this
reason, systematic, objective and easily reproducible classification of
galaxies has been gaining importance since the astronomer Edwin Hubble created
his famous classification method. In this work, we combine accurate visual
classifications of the Galaxy Zoo project with \emph {Deep Learning} methods.
The goal is to find an efficient technique at human performance level
classification, but in a systematic and automatic way, for classification of
elliptical and spiral galaxies. For this, a neural network model was created
through an Ensemble of four other convolutional models, allowing a greater
accuracy in the classification than what would be obtained with any one
individual. Details of the individual models and improvements made are also
described. The present work is entirely based on the analysis of images (not
parameter tables) from DR1 (www.datalab.noao.edu) of the Southern Photometric
Local Universe Survey (S-PLUS). In terms of classification, we achieved, with
the Ensemble, an accuracy of $\approx 99 \%$ in the test sample (using
pre-trained networks).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory-Sample Lower Bounds for Learning Parity with Noise. (arXiv:2107.02320v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1">Sumegha Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1">Pravesh K. Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengda Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Raz_R/0/1/0/all/0/1">Ran Raz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02320">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we show, for the well-studied problem of learning parity under
noise, where a learner tries to learn $x&#x3D;(x_1,\ldots,x_n) \in \{0,1\}^n$ from a
stream of random linear equations over $\mathrm{F}_2$ that are correct with
probability $\frac{1}{2}+\varepsilon$ and flipped with probability
$\frac{1}{2}-\varepsilon$, that any learning algorithm requires either a memory
of size $\Omega(n^2/\varepsilon)$ or an exponential number of samples.

In fact, we study memory-sample lower bounds for a large class of learning
problems, as characterized by [GRT&#x27;18], when the samples are noisy. A matrix
$M: A \times X \rightarrow \{-1,1\}$ corresponds to the following learning
problem with error parameter $\varepsilon$: an unknown element $x \in X$ is
chosen uniformly at random. A learner tries to learn $x$ from a stream of
samples, $(a_1, b_1), (a_2, b_2) \ldots$, where for every $i$, $a_i \in A$ is
chosen uniformly at random and $b_i &#x3D; M(a_i,x)$ with probability
$1/2+\varepsilon$ and $b_i &#x3D; -M(a_i,x)$ with probability $1/2-\varepsilon$
($0&lt;\varepsilon&lt; \frac{1}{2}$). Assume that $k,\ell, r$ are such that any
submatrix of $M$ of at least $2^{-k} \cdot |A|$ rows and at least $2^{-\ell}
\cdot |X|$ columns, has a bias of at most $2^{-r}$. We show that any learning
algorithm for the learning problem corresponding to $M$, with error, requires
either a memory of size at least $\Omega\left(\frac{k \cdot \ell}{\varepsilon}
\right)$, or at least $2^{\Omega(r)}$ samples. In particular, this shows that
for a large class of learning problems, same as those in [GRT&#x27;18], any learning
algorithm requires either a memory of size at least $\Omega\left(\frac{(\log
|X|) \cdot (\log |A|)}{\varepsilon}\right)$ or an exponential number of noisy
samples.

Our proof is based on adapting the arguments in [Raz&#x27;17,GRT&#x27;18] to the noisy
case.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Mixture Models with Expectation-Maximization for End-to-end Deep Clustering. (arXiv:2107.02453v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tissera_D/0/1/0/all/0/1">Dumindu Tissera</a>, <a href="http://arxiv.org/find/cs/1/au:+Vithanage_K/0/1/0/all/0/1">Kasun Vithanage</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijesinghe_R/0/1/0/all/0/1">Rukshan Wijesinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Xavier_A/0/1/0/all/0/1">Alex Xavier</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayasena_S/0/1/0/all/0/1">Sanath Jayasena</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernando_S/0/1/0/all/0/1">Subha Fernando</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigo_R/0/1/0/all/0/1">Ranga Rodrigo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02453">
                                    <div class="article-summary-box-inner">
                                        <span>Any clustering algorithm must synchronously learn to model the clusters and
allocate data to those clusters in the absence of labels. Mixture model-based
methods model clusters with pre-defined statistical distributions and allocate
data to those clusters based on the cluster likelihoods. They iteratively
refine those distribution parameters and member assignments following the
Expectation-Maximization (EM) algorithm. However, the cluster representability
of such hand-designed distributions that employ a limited amount of parameters
is not adequate for most real-world clustering tasks. In this paper, we realize
mixture model-based clustering with a neural network where the final layer
neurons, with the aid of an additional transformation, approximate cluster
distribution outputs. The network parameters pose as the parameters of those
distributions. The result is an elegant, much-generalized representation of
clusters than a restricted mixture of hand-designed distributions. We train the
network end-to-end via batch-wise EM iterations where the forward pass acts as
the E-step and the backward pass acts as the M-step. In image clustering, the
mixture-based EM objective can be used as the clustering objective along with
existing representation learning methods. In particular, we show that when
mixture-EM optimization is fused with consistency optimization, it improves the
sole consistency optimization performance in clustering. Our trained networks
outperform single-stage deep clustering methods that still depend on k-means,
with unsupervised classification accuracy of 63.8% in STL10, 58% in CIFAR10,
25.9% in CIFAR100, and 98.9% in MNIST.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LipBaB: Computing exact Lipschitz constant of ReLU networks. (arXiv:2105.05495v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhowmick_A/0/1/0/all/0/1">Aritra Bhowmick</a>, <a href="http://arxiv.org/find/cs/1/au:+DSouza_M/0/1/0/all/0/1">Meenakshi D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghavan_G/0/1/0/all/0/1">G. Srinivasa Raghavan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05495">
                                    <div class="article-summary-box-inner">
                                        <span>The Lipschitz constant of neural networks plays an important role in several
contexts of deep learning ranging from robustness certification and
regularization to stability analysis of systems with neural network
controllers. Obtaining tight bounds of the Lipschitz constant is therefore
important. We introduce LipBaB, a branch and bound framework to compute
certified bounds of the local Lipschitz constant of deep neural networks with
ReLU activation functions up to any desired precision. We achieve this by
bounding the norm of the Jacobians, corresponding to different activation
patterns of the network caused within the input domain. Our algorithm can
provide provably exact computation of the Lipschitz constant for any p-norm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymptotics of Network Embeddings Learned via Subsampling. (arXiv:2107.02363v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Davison_A/0/1/0/all/0/1">Andrew Davison</a>, <a href="http://arxiv.org/find/stat/1/au:+Austern_M/0/1/0/all/0/1">Morgane Austern</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02363">
                                    <div class="article-summary-box-inner">
                                        <span>Network data are ubiquitous in modern machine learning, with tasks of
interest including node classification, node clustering and link prediction. A
frequent approach begins by learning an Euclidean embedding of the network, to
which algorithms developed for vector-valued data are applied. For large
networks, embeddings are learned using stochastic gradient methods where the
sub-sampling scheme can be freely chosen. Despite the strong empirical
performance of such methods, they are not well understood theoretically. Our
work encapsulates representation methods using a subsampling approach, such as
node2vec, into a single unifying framework. We prove, under the assumption that
the graph is exchangeable, that the distribution of the learned embedding
vectors asymptotically decouples. Moreover, we characterize the asymptotic
distribution and provided rates of convergence, in terms of the latent
parameters, which includes the choice of loss function and the embedding
dimension. This provides a theoretical foundation to understand what the
embedding vectors represent and how well these methods perform on downstream
tasks. Notably, we observe that typically used loss functions may lead to
shortcomings, such as a lack of Fisher consistency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SplitAVG: A heterogeneity-aware federated deep learning method for medical imaging. (arXiv:2107.02375v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Miao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Liangqiong Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Praveer Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1">Jayashree Kalpathy-Cramer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1">Daniel L. Rubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02375">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning is an emerging research paradigm for enabling
collaboratively training deep learning models without sharing patient data.
However, the data from different institutions are usually heterogeneous across
institutions, which may reduce the performance of models trained using
federated learning. In this study, we propose a novel heterogeneity-aware
federated learning method, SplitAVG, to overcome the performance drops from
data heterogeneity in federated learning. Unlike previous federated methods
that require complex heuristic training or hyper parameter tuning, our SplitAVG
leverages the simple network split and feature map concatenation strategies to
encourage the federated model training an unbiased estimator of the target data
distribution. We compare SplitAVG with seven state-of-the-art federated
learning methods, using centrally hosted training data as the baseline on a
suite of both synthetic and real-world federated datasets. We find that the
performance of models trained using all the comparison federated learning
methods degraded significantly with the increasing degrees of data
heterogeneity. In contrast, SplitAVG method achieves comparable results to the
baseline method under all heterogeneous settings, that it achieves 96.2% of the
accuracy and 110.4% of the mean absolute error obtained by the baseline in a
diabetic retinopathy binary classification dataset and a bone age prediction
dataset, respectively, on highly heterogeneous data partitions. We conclude
that SplitAVG method can effectively overcome the performance drops from
variability in data distributions across institutions. Experimental results
also show that SplitAVG can be adapted to different base networks and
generalized to various types of medical imaging tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fractional order graph neural network. (arXiv:2001.04026v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zijian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1">Chunbo Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Peng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_G/0/1/0/all/0/1">Geyong Min</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.04026">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes fractional order graph neural networks (FGNNs), optimized
by the approximation strategy to address the challenges of local optimum of
classic and fractional graph neural networks which are specialised at
aggregating information from the feature and adjacent matrices of connected
nodes and their neighbours to solve learning tasks on non-Euclidean data such
as graphs. Meanwhile the approximate calculation of fractional order gradients
also overcomes the high computational complexity of fractional order
derivations. We further prove that such an approximation is feasible and the
FGNN is unbiased towards global optimization solution. Extensive experiments on
citation networks show that FGNN achieves great advantage over baseline models
when selected appropriate fractional order.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variance Reduction for Matrix Computations with Applications to Gaussian Processes. (arXiv:2106.14565v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mathur_A/0/1/0/all/0/1">Anant Mathur</a>, <a href="http://arxiv.org/find/stat/1/au:+Moka_S/0/1/0/all/0/1">Sarat Moka</a>, <a href="http://arxiv.org/find/stat/1/au:+Botev_Z/0/1/0/all/0/1">Zdravko Botev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14565">
                                    <div class="article-summary-box-inner">
                                        <span>In addition to recent developments in computing speed and memory,
methodological advances have contributed to significant gains in the
performance of stochastic simulation. In this paper, we focus on variance
reduction for matrix computations via matrix factorization. We provide insights
into existing variance reduction methods for estimating the entries of large
matrices. Popular methods do not exploit the reduction in variance that is
possible when the matrix is factorized. We show how computing the square root
factorization of the matrix can achieve in some important cases arbitrarily
better stochastic performance. In addition, we propose a factorized estimator
for the trace of a product of matrices and numerically demonstrate that the
estimator can be up to 1,000 times more efficient on certain problems of
estimating the log-likelihood of a Gaussian process. Additionally, we provide a
new estimator of the log-determinant of a positive semi-definite matrix where
the log-determinant is treated as a normalizing constant of a probability
density.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ADMM for Efficient Deep Learning with Global Convergence. (arXiv:1905.13611v4 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Wang_J/0/1/0/all/0/1">Junxiang Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Yu_F/0/1/0/all/0/1">Fuxun Yu</a>, <a href="http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1">Xiang Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.13611">
                                    <div class="article-summary-box-inner">
                                        <span>Alternating Direction Method of Multipliers (ADMM) has been used successfully
in many conventional machine learning applications and is considered to be a
useful alternative to Stochastic Gradient Descent (SGD) as a deep learning
optimizer. However, as an emerging domain, several challenges remain, including
1) The lack of global convergence guarantees, 2) Slow convergence towards
solutions, and 3) Cubic time complexity with regard to feature dimensions. In
this paper, we propose a novel optimization framework for deep learning via
ADMM (dlADMM) to address these challenges simultaneously. The parameters in
each layer are updated backward and then forward so that the parameter
information in each layer is exchanged efficiently. The time complexity is
reduced from cubic to quadratic in (latent) feature dimensions via a dedicated
algorithm design for subproblems that enhances them utilizing iterative
quadratic approximations and backtracking. Finally, we provide the first proof
of global convergence for an ADMM-based method (dlADMM) in a deep neural
network problem under mild conditions. Experiments on benchmark datasets
demonstrated that our proposed dlADMM algorithm outperforms most of the
comparison methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Algorithm Execution: Estimating Computable Properties of Black-box Functions Using Mutual Information. (arXiv:2104.09460v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Neiswanger_W/0/1/0/all/0/1">Willie Neiswanger</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_K/0/1/0/all/0/1">Ke Alexander Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09460">
                                    <div class="article-summary-box-inner">
                                        <span>In many real-world problems, we want to infer some property of an expensive
black-box function $f$, given a budget of $T$ function evaluations. One example
is budget constrained global optimization of $f$, for which Bayesian
optimization is a popular method. Other properties of interest include local
optima, level sets, integrals, or graph-structured information induced by $f$.
Often, we can find an algorithm $\mathcal{A}$ to compute the desired property,
but it may require far more than $T$ queries to execute. Given such an
$\mathcal{A}$, and a prior distribution over $f$, we refer to the problem of
inferring the output of $\mathcal{A}$ using $T$ evaluations as Bayesian
Algorithm Execution (BAX). To tackle this problem, we present a procedure,
InfoBAX, that sequentially chooses queries that maximize mutual information
with respect to the algorithm&#x27;s output. Applying this to Dijkstra&#x27;s algorithm,
for instance, we infer shortest paths in synthetic and real-world graphs with
black-box edge costs. Using evolution strategies, we yield variants of Bayesian
optimization that target local, rather than global, optima. On these problems,
InfoBAX uses up to 500 times fewer queries to $f$ than required by the original
algorithm. Our method is closely connected to other Bayesian optimal
experimental design procedures such as entropy search methods and optimal
sensor placement using Gaussian processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning optimal multigrid smoothers via neural networks. (arXiv:2102.12071v2 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Huang_R/0/1/0/all/0/1">Ru Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Li_R/0/1/0/all/0/1">Ruipeng Li</a>, <a href="http://arxiv.org/find/math/1/au:+Xi_Y/0/1/0/all/0/1">Yuanzhe Xi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12071">
                                    <div class="article-summary-box-inner">
                                        <span>Multigrid methods are one of the most efficient techniques for solving linear
systems arising from Partial Differential Equations (PDEs) and graph Laplacians
from machine learning applications. One of the key components of multigrid is
smoothing, which aims at reducing high-frequency errors on each grid level.
However, finding optimal smoothing algorithms is problem-dependent and can
impose challenges for many problems. In this paper, we propose an efficient
adaptive framework for learning optimized smoothers from operator stencils in
the form of convolutional neural networks (CNNs). The CNNs are trained on
small-scale problems from a given type of PDEs based on a supervised loss
function derived from multigrid convergence theories, and can be applied to
large-scale problems of the same class of PDEs. Numerical results on
anisotropic rotated Laplacian problems demonstrate improved convergence rates
and solution time compared with classical hand-crafted relaxation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Order in the Court: Explainable AI Methods Prone to Disagreement. (arXiv:2105.03287v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neely_M/0/1/0/all/0/1">Michael Neely</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouten_S/0/1/0/all/0/1">Stefan F. Schouten</a>, <a href="http://arxiv.org/find/cs/1/au:+Bleeker_M/0/1/0/all/0/1">Maurits J. R. Bleeker</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_A/0/1/0/all/0/1">Ana Lucic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03287">
                                    <div class="article-summary-box-inner">
                                        <span>By computing the rank correlation between attention weights and
feature-additive explanation methods, previous analyses either invalidate or
support the role of attention-based explanations as a faithful and plausible
measure of salience. To investigate whether this approach is appropriate, we
compare LIME, Integrated Gradients, DeepLIFT, Grad-SHAP, Deep-SHAP, and
attention-based explanations, applied to two neural architectures trained on
single- and pair-sequence language tasks. In most cases, we find that none of
our chosen methods agree. Based on our empirical observations and theoretical
objections, we conclude that rank correlation does not measure the quality of
feature-additive methods. Practitioners should instead use the numerous and
rigorous diagnostic methods proposed by the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Fusion for Deep Learning on Transport Mode Detection: A Case Study. (arXiv:2106.05876v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moreau_H/0/1/0/all/0/1">Hugues Moreau</a>, <a href="http://arxiv.org/find/cs/1/au:+Vassilev_A/0/1/0/all/0/1">Andr&#xe9;a Vassilev</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liming Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05876">
                                    <div class="article-summary-box-inner">
                                        <span>In Transport Mode Detection, a great diversity of methodologies exist
according to the choice made on sensors, preprocessing, model used, etc. In
this domain, the comparisons between each option are not always complete.
Experiments on a public, real-life dataset are led here to evaluate carefully
each of the choices that were made, with a specific emphasis on data fusion
methods. Our most surprising finding is that none of the methods we implemented
from the literature is better than a simple late fusion. Two important
decisions are the choice of a sensor and the choice of a representation for the
data: we found that using 2D convolutions on spectrograms with a logarithmic
axis for the frequencies was better than 1-dimensional temporal
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Computing. (arXiv:2107.02744v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gangal_A/0/1/0/all/0/1">Ayushe Gangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">Peeyush Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumari_S/0/1/0/all/0/1">Sunita Kumari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Aditya Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02744">
                                    <div class="article-summary-box-inner">
                                        <span>This chapter aims to provide next-level understanding of the problems of the
world and the solutions available to those problems, which lie very well within
the domain of neural computing, and at the same time are intelligent in their
approach, to invoke a sense of innovation among the educationalists,
researchers, academic professionals, students and people concerned, by
highlighting the work done by major researchers and innovators in this field
and thus, encouraging the readers to develop newer and more advanced techniques
for the same. By means of this chapter, the societal problems are discussed and
various solutions are also given by means of the theories presented and
researches done so far. Different types of neural networks discovered so far
and applications of some of those neural networks are focused on, apart from
their theoretical understanding, the working and core concepts involved in the
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overlapping Spaces for Compact Graph Representations. (arXiv:2007.02445v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shevkunov_K/0/1/0/all/0/1">Kirill Shevkunov</a>, <a href="http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1">Liudmila Prokhorenkova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.02445">
                                    <div class="article-summary-box-inner">
                                        <span>Various non-trivial spaces are becoming popular for embedding structured data
such as graphs, texts, or images. Following spherical and hyperbolic spaces,
more general product spaces have been proposed. However, searching for the best
configuration of product space is a resource-intensive procedure, which reduces
the practical applicability of the idea. We generalize the concept of product
space and introduce an overlapping space that does not have the configuration
search problem. The main idea is to allow subsets of coordinates to be shared
between spaces of different types (Euclidean, hyperbolic, spherical). As a
result, parameter optimization automatically learns the optimal configuration.
Additionally, overlapping spaces allow for more compact representations since
their geometry is more complex. Our experiments confirm that overlapping spaces
outperform the competitors in graph embedding tasks. Here, we consider both
distortion setup, where the aim is to preserve distances, and ranking setup,
where the relative order should be preserved. The proposed method effectively
solves the problem and outperforms the competitors in both settings. We also
perform an empirical analysis in a realistic information retrieval task, where
we compare all spaces by incorporating them into DSSM. In this case, the
proposed overlapping space consistently achieves nearly optimal results without
any configuration tuning. This allows for reducing training time, which can be
significant in large-scale applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning-based vs Model-free Adaptive Control of a MAV under Wind Gust. (arXiv:2101.12501v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chaffre_T/0/1/0/all/0/1">Thomas Chaffre</a>, <a href="http://arxiv.org/find/cs/1/au:+Moras_J/0/1/0/all/0/1">Julien Moras</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_Hon_Tong_A/0/1/0/all/0/1">Adrien Chan-Hon-Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Marzat_J/0/1/0/all/0/1">Julien Marzat</a>, <a href="http://arxiv.org/find/cs/1/au:+Sammut_K/0/1/0/all/0/1">Karl Sammut</a>, <a href="http://arxiv.org/find/cs/1/au:+Chenadec_G/0/1/0/all/0/1">Gilles Le Chenadec</a>, <a href="http://arxiv.org/find/cs/1/au:+Clement_B/0/1/0/all/0/1">Benoit Clement</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.12501">
                                    <div class="article-summary-box-inner">
                                        <span>Navigation problems under unknown varying conditions are among the most
important and well-studied problems in the control field. Classic model-based
adaptive control methods can be applied only when a convenient model of the
plant or environment is provided. Recent model-free adaptive control methods
aim at removing this dependency by learning the physical characteristics of the
plant and/or process directly from sensor feedback. Although there have been
prior attempts at improving these techniques, it remains an open question as to
whether it is possible to cope with real-world uncertainties in a control
system that is fully based on either paradigm. We propose a conceptually simple
learning-based approach composed of a full state feedback controller, tuned
robustly by a deep reinforcement learning framework based on the Soft
Actor-Critic algorithm. We compare it, in realistic simulations, to a
model-free controller that uses the same deep reinforcement learning framework
for the control of a micro aerial vehicle under wind gust. The results indicate
the great potential of learning-based adaptive control methods in modern
dynamical systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Losses and Solution Caching for Predict-and-Optimize. (arXiv:2011.05354v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mulamba_M/0/1/0/all/0/1">Maxime Mulamba</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandi_J/0/1/0/all/0/1">Jayanta Mandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Diligenti_M/0/1/0/all/0/1">Michelangelo Diligenti</a>, <a href="http://arxiv.org/find/cs/1/au:+Lombardi_M/0/1/0/all/0/1">Michele Lombardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bucarey_V/0/1/0/all/0/1">Victor Bucarey</a>, <a href="http://arxiv.org/find/cs/1/au:+Guns_T/0/1/0/all/0/1">Tias Guns</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05354">
                                    <div class="article-summary-box-inner">
                                        <span>Many decision-making processes involve solving a combinatorial optimization
problem with uncertain input that can be estimated from historic data.
Recently, problems in this class have been successfully addressed via
end-to-end learning approaches, which rely on solving one optimization problem
for each training instance at every epoch. In this context, we provide two
distinct contributions. First, we use a Noise Contrastive approach to motivate
a family of surrogate loss functions, based on viewing non-optimal solutions as
negative examples. Second, we address a major bottleneck of all
predict-and-optimize approaches, i.e. the need to frequently recompute optimal
solutions at training time. This is done via a solver-agnostic solution caching
scheme, and by replacing optimization calls with a lookup in the solution
cache. The method is formally based on an inner approximation of the feasible
space and, combined with a cache lookup strategy, provides a controllable
trade-off between training time and accuracy of the loss approximation. We
empirically show that even a very slow growth rate is enough to match the
quality of state-of-the-art methods, at a fraction of the computational cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Advanced Graph and Sequence Neural Networks for Molecular Property Prediction and Drug Discovery. (arXiv:2012.01981v3 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Wang_Z/0/1/0/all/0/1">Zhengyang Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Liu_M/0/1/0/all/0/1">Meng Liu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Luo_Y/0/1/0/all/0/1">Youzhi Luo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xu_Z/0/1/0/all/0/1">Zhao Xu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xie_Y/0/1/0/all/0/1">Yaochen Xie</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_L/0/1/0/all/0/1">Limei Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cai_L/0/1/0/all/0/1">Lei Cai</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Qi_Q/0/1/0/all/0/1">Qi Qi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yuan_Z/0/1/0/all/0/1">Zhuoning Yuan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_T/0/1/0/all/0/1">Tianbao Yang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01981">
                                    <div class="article-summary-box-inner">
                                        <span>Properties of molecules are indicative of their functions and thus are useful
in many applications. With the advances of deep learning methods, computational
approaches for predicting molecular properties are gaining increasing momentum.
However, there lacks customized and advanced methods and comprehensive tools
for this task currently. Here we develop a suite of comprehensive machine
learning methods and tools spanning different computational models, molecular
representations, and loss functions for molecular property prediction and drug
discovery. Specifically, we represent molecules as both graphs and sequences.
Built on these representations, we develop novel deep models for learning from
molecular graphs and sequences. In order to learn effectively from highly
imbalanced datasets, we develop advanced loss functions that optimize areas
under precision-recall curves. Altogether, our work not only serves as a
comprehensive tool, but also contributes towards developing novel and advanced
graph and sequence learning methodologies. Results on both online and offline
antibiotics discovery and molecular property prediction tasks show that our
methods achieve consistent improvements over prior methods. In particular, our
methods achieve #1 ranking in terms of both ROC-AUC and PRC-AUC on the AI Cures
Open Challenge for drug discovery related to COVID-19. Our software is released
as part of the MoleculeX library under AdvProp.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classification with Rejection Based on Cost-sensitive Classification. (arXiv:2010.11748v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Charoenphakdee_N/0/1/0/all/0/1">Nontawat Charoenphakdee</a>, <a href="http://arxiv.org/find/stat/1/au:+Cui_Z/0/1/0/all/0/1">Zhenghang Cui</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1">Yivan Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11748">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of classification with rejection is to avoid risky misclassification
in error-critical applications such as medical diagnosis and product
inspection. In this paper, based on the relationship between classification
with rejection and cost-sensitive classification, we propose a novel method of
classification with rejection by learning an ensemble of cost-sensitive
classifiers, which satisfies all the following properties: (i) it can avoid
estimating class-posterior probabilities, resulting in improved classification
accuracy, (ii) it allows a flexible choice of losses including non-convex ones,
(iii) it does not require complicated modifications when using different
losses, (iv) it is applicable to both binary and multiclass cases, and (v) it
is theoretically justifiable for any classification-calibrated loss.
Experimental results demonstrate the usefulness of our proposed approach in
clean-labeled, noisy-labeled, and positive-unlabeled classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Formalism, Method and Open Issues for Zero-Shot Coordination. (arXiv:2106.06613v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Treutlein_J/0/1/0/all/0/1">Johannes Treutlein</a>, <a href="http://arxiv.org/find/cs/1/au:+Dennis_M/0/1/0/all/0/1">Michael Dennis</a>, <a href="http://arxiv.org/find/cs/1/au:+Oesterheld_C/0/1/0/all/0/1">Caspar Oesterheld</a>, <a href="http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1">Jakob Foerster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06613">
                                    <div class="article-summary-box-inner">
                                        <span>In many coordination problems, independently reasoning humans are able to
discover mutually compatible policies. In contrast, independently trained
self-play policies are often mutually incompatible. Zero-shot coordination
(ZSC) has recently been proposed as a new frontier in multi-agent reinforcement
learning to address this fundamental issue. Prior work approaches the ZSC
problem by assuming players can agree on a shared learning algorithm but not on
labels for actions and observations, and proposes other-play as an optimal
solution. However, until now, this &quot;label-free&quot; problem has only been
informally defined. We formalize this setting as the label-free coordination
(LFC) problem by defining the label-free coordination game. We show that
other-play is not an optimal solution to the LFC problem as it fails to
consistently break ties between incompatible maximizers of the other-play
objective. We introduce an extension of the algorithm, other-play with
tie-breaking, and prove that it is optimal in the LFC problem and an
equilibrium in the LFC game. Since arbitrary tie-breaking is precisely what the
ZSC setting aims to prevent, we conclude that the LFC problem does not reflect
the aims of ZSC. To address this, we introduce an alternative informal
operationalization of ZSC as a starting point for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SemEval-2021 Task 11: NLPContributionGraph -- Structuring Scholarly NLP Contributions for a Research Knowledge Graph. (arXiv:2106.07385v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DSouza_J/0/1/0/all/0/1">Jennifer D&#x27;Souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Auer_S/0/1/0/all/0/1">S&#xf6;ren Auer</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersen_T/0/1/0/all/0/1">Ted Pedersen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07385">
                                    <div class="article-summary-box-inner">
                                        <span>There is currently a gap between the natural language expression of scholarly
publications and their structured semantic content modeling to enable
intelligent content search. With the volume of research growing exponentially
every year, a search feature operating over semantically structured content is
compelling. The SemEval-2021 Shared Task NLPContributionGraph (a.k.a. &#x27;the NCG
task&#x27;) tasks participants to develop automated systems that structure
contributions from NLP scholarly articles in the English language. Being the
first-of-its-kind in the SemEval series, the task released structured data from
NLP scholarly articles at three levels of information granularity, i.e. at
sentence-level, phrase-level, and phrases organized as triples toward Knowledge
Graph (KG) building. The sentence-level annotations comprised the few sentences
about the article&#x27;s contribution. The phrase-level annotations were scientific
term and predicate phrases from the contribution sentences. Finally, the
triples constituted the research overview KG. For the Shared Task,
participating systems were then expected to automatically classify contribution
sentences, extract scientific terms and relations from the sentences, and
organize them as KG triples.

Overall, the task drew a strong participation demographic of seven teams and
27 participants. The best end-to-end task system classified contribution
sentences at 57.27% F1, phrases at 46.41% F1, and triples at 22.28% F1. While
the absolute performance to generate triples remains low, in the conclusion of
this article, the difficulty of producing such data and as a consequence of
modeling it is highlighted.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepOPG: Improving Orthopantomogram Finding Summarization with Weak Supervision. (arXiv:2103.08290v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_T/0/1/0/all/0/1">Tzu-Ming Harry Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yin-Chih Chelsea Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08290">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical finding summaries from an orthopantomogram, or a dental panoramic
radiograph, have significant potential to improve patient communication and
speed up clinical judgments. While orthopantomogram is a first-line tool for
dental examinations, no existing work has explored the summarization of
findings from it. A finding summary has to find teeth in the imaging study and
label the teeth with several types of past treatments. To tackle the problem,
we developDeepOPG that breaks the summarization process into functional
segmentation and tooth localization, the latter of which is further refined by
a novel dental coherence module. We also leverage weak supervision labels to
improve detection results in a reinforcement learning scenario. Experiments
show high efficacy of DeepOPG on finding summarization, achieving an overall
AUC of 88.2% in detecting six types of findings. The proposed dental coherence
and weak supervision both are shown to improve DeepOPG by adding 5.9% and 0.4%
to AP@IoU&#x3D;0.5.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive machine learning for protein engineering. (arXiv:2106.05466v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Hie_B/0/1/0/all/0/1">Brian L. Hie</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yang_K/0/1/0/all/0/1">Kevin K. Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05466">
                                    <div class="article-summary-box-inner">
                                        <span>Machine-learning models that learn from data to predict how protein sequence
encodes function are emerging as a useful protein engineering tool. However,
when using these models to suggest new protein designs, one must deal with the
vast combinatorial complexity of protein sequences. Here, we review how to use
a sequence-to-function machine-learning surrogate model to select sequences for
experimental measurement. First, we discuss how to select sequences through a
single round of machine-learning optimization. Then, we discuss sequential
optimization, where the goal is to discover optimized sequences and improve the
model across multiple rounds of training, optimization, and experimental
measurement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Size-Invariant Graph Representations for Graph Classification Extrapolations. (arXiv:2103.05045v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bevilacqua_B/0/1/0/all/0/1">Beatrice Bevilacqua</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yangze Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1">Bruno Ribeiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05045">
                                    <div class="article-summary-box-inner">
                                        <span>In general, graph representation learning methods assume that the train and
test data come from the same distribution. In this work we consider an
underexplored area of an otherwise rapidly developing field of graph
representation learning: The task of out-of-distribution (OOD) graph
classification, where train and test data have different distributions, with
test data unavailable during training. Our work shows it is possible to use a
causal model to learn approximately invariant representations that better
extrapolate between train and test data. Finally, we conclude with synthetic
and real-world dataset experiments showcasing the benefits of representations
that are invariant to train/test distribution shifts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Surrogate Model Based Hyperparameter Tuning for Deep Learning with SPOT. (arXiv:2105.14625v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bartz_Beielstein_T/0/1/0/all/0/1">Thomas Bartz-Beielstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehbach_F/0/1/0/all/0/1">Frederik Rehbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_A/0/1/0/all/0/1">Amrita Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaefferer_M/0/1/0/all/0/1">Martin Zaefferer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14625">
                                    <div class="article-summary-box-inner">
                                        <span>A surrogate model based hyperparameter tuning approach for deep learning is
presented. This article demonstrates how the architecture-level parameters
(hyperparameters) of deep learning models that were implemented in
Keras/tensorflow can be optimized. The implementation of the tuning procedure
is 100% accessible from R, the software environment for statistical computing.
With a few lines of code, existing R packages (tfruns and SPOT) can be combined
to perform hyperparameter tuning. An elementary hyperparameter tuning task
(neural network and the MNIST data) is used to exemplify this approach</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maximizing Ensemble Diversity in Deep Q-Learning. (arXiv:2006.13823v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheikh_H/0/1/0/all/0/1">Hassam Ullah Sheikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Phielipp_M/0/1/0/all/0/1">Mariano Phielipp</a>, <a href="http://arxiv.org/find/cs/1/au:+Boloni_L/0/1/0/all/0/1">Ladislau B&#xf6;l&#xf6;ni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.13823">
                                    <div class="article-summary-box-inner">
                                        <span>The classic DQN algorithm is limited by the overestimation bias of the
learned Q-function. Subsequent algorithms have proposed techniques to reduce
this problem, without fully eliminating it. Recently, the Maxmin and Ensemble
Q-learning algorithms have used different estimates provided by the ensembles
of learners to reduce the overestimation bias. Unfortunately, these learners
can converge to the same point in the parametric or representation space,
falling back to the classic single neural network DQN. In this paper, we
describe a regularization technique to maximize ensemble diversity in these
algorithms. We propose and compare five regularization functions inspired from
economics theory and consensus optimization. We show that the regularized
approach significantly outperforms the Maxmin and Ensemble Q-learning
algorithms as well as non-ensemble baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Graph Disentanglement. (arXiv:2103.07295v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuai Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenfeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhizhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1">Jian Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07295">
                                    <div class="article-summary-box-inner">
                                        <span>A real-world graph has a complex topological structure, which is often formed
by the interaction of different latent factors. Disentanglement of these latent
factors can effectively improve the robustness and expressiveness of node
representation of graph. However, most existing methods lack consideration of
the intrinsic differences in relations between nodes caused by factor
entanglement. In this paper, we propose an Adversarial Disentangled Graph
Convolutional Network (ADGCN) for disentangled graph representation learning.
Specifically, a component-specific aggregation approach is proposed to achieve
micro-disentanglement by inferring latent components that caused the links
between nodes. On the basis of micro-disentanglement, we further propose a
macro-disentanglement adversarial regularizer to improve the separability among
component distributions, thus restricting the interdependence among components.
Additionally, to reveal the topological graph structure, a diversity-preserving
node sampling approach is proposed, by which the graph structure can be
progressively refined in a way of local structure awareness. The experimental
results on various real-world graph data verify that our ADGCN obtains more
favorable performance over currently available alternatives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LeadCache: Regret-Optimal Caching in Networks. (arXiv:2009.08228v3 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paria_D/0/1/0/all/0/1">Debjit Paria</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1">Abhishek Sinha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08228">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a set-valued online prediction problem in the context of network
caching. Assume that multiple users are connected to several caches via a
bipartite network. At any time slot, each user requests an arbitrary file
chosen from a large catalog. A user&#x27;s request at a slot is met if the requested
file is cached in at least one of the caches connected to the user. Our
objective is to predict, prefetch, and optimally distribute the files on the
caches to maximize the total number of cache hits in an online setting. The
problem is non-trivial due to the non-convex and non-smooth nature of the
objective function. In this paper, we propose $\texttt{LeadCache}$ - an online
caching policy based on the Follow-the-Perturbed-Leader paradigm. We show that
the policy is regret-optimal up to a factor of $\tilde{O}(n^{3/8}),$ where $n$
is the number of users. We design two efficient implementations of the
$\texttt{LeadCache}$ policy, one based on Pipage rounding and the other based
on Madow&#x27;s sampling, each of which makes precisely one call to an LP-solver per
iteration. With a Strong-Law-type assumption, we show that the total number of
file fetches under $\texttt{LeadCache}$ remains almost surely finite over an
infinite horizon. Finally, we derive a tight regret lower bound using results
from graph coloring. We conclude that the learning-based $\texttt{LeadCache}$
policy decisively outperforms the known caching policies both theoretically and
empirically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention over learned object embeddings enables complex visual reasoning. (arXiv:2012.08508v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1">David Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1">Felix Hill</a>, <a href="http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1">Adam Santoro</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynolds_M/0/1/0/all/0/1">Malcolm Reynolds</a>, <a href="http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1">Matt Botvinick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08508">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks have achieved success in a wide array of perceptual tasks but
often fail at tasks involving both perception and higher-level reasoning. On
these more challenging tasks, bespoke approaches (such as modular symbolic
components, independent dynamics models or semantic parsers) targeted towards
that specific type of task have typically performed better. The downside to
these targeted approaches, however, is that they can be more brittle than
general-purpose neural networks, requiring significant modification or even
redesign according to the particular task at hand. Here, we propose a more
general neural-network-based approach to dynamic visual reasoning problems that
obtains state-of-the-art performance on three different domains, in each case
outperforming bespoke modular approaches tailored specifically to the task. Our
method relies on learned object-centric representations, self-attention and
self-supervised dynamics learning, and all three elements together are required
for strong performance to emerge. The success of this combination suggests that
there may be no need to trade off flexibility for performance on problems
involving spatio-temporal or causal-style reasoning. With the right soft biases
and learning objectives in a neural network we may be able to attain the best
of both worlds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Surprising Effectiveness of PPO in Cooperative, Multi-Agent Games. (arXiv:2103.01955v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Chao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Velu_A/0/1/0/all/0/1">Akash Velu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinitsky_E/0/1/0/all/0/1">Eugene Vinitsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bayen_A/0/1/0/all/0/1">Alexandre Bayen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yi Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01955">
                                    <div class="article-summary-box-inner">
                                        <span>Proximal Policy Optimization (PPO) is a popular on-policy reinforcement
learning algorithm but is significantly less utilized than off-policy learning
algorithms in multi-agent settings. This is often due the belief that on-policy
methods are significantly less sample efficient than their off-policy
counterparts in multi-agent problems. In this work, we investigate Multi-Agent
PPO (MAPPO), a variant of PPO which is specialized for multi-agent settings.
Using a 1-GPU desktop, we show that MAPPO achieves surprisingly strong
performance in three popular multi-agent testbeds: the particle-world
environments, the Starcraft multi-agent challenge, and the Hanabi challenge,
with minimal hyperparameter tuning and without any domain-specific algorithmic
modifications or architectures. In the majority of environments, we find that
compared to off-policy baselines, MAPPO achieves strong results while
exhibiting comparable sample efficiency. Finally, through ablation studies, we
present the implementation and algorithmic factors which are most influential
to MAPPO&#x27;s practical performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy Forecasting in Smart Grid Systems: A Review of the State-of-the-art Techniques. (arXiv:2011.12598v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaur_D/0/1/0/all/0/1">Devinder Kaur</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_S/0/1/0/all/0/1">Shama Naz Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmud_M/0/1/0/all/0/1">Md. Apel Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">ZhaoYang Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12598">
                                    <div class="article-summary-box-inner">
                                        <span>Energy forecasting has a vital role to play in smart grid (SG) systems
involving various applications such as demand-side management, load shedding,
and optimum dispatch. Managing efficient forecasting while ensuring the least
possible prediction error is one of the main challenges posed in the grid
today, considering the uncertainty and granularity in SG data. This paper
presents a comprehensive and application-oriented review of state-of-the-art
forecasting methods for SG systems along with recent developments in
probabilistic deep learning (PDL) considering different models and
architectures. Traditional point forecasting methods including statistical,
machine learning (ML), and deep learning (DL) are extensively investigated in
terms of their applicability to energy forecasting. In addition, the
significance of hybrid and data pre-processing techniques to support
forecasting performance is also studied. A comparative case study using the
Victorian electricity consumption and American electric power (AEP) datasets is
conducted to analyze the performance of point and probabilistic forecasting
methods. The analysis demonstrates higher accuracy of the long-short term
memory (LSTM) models with appropriate hyper-parameter tuning among point
forecasting methods especially when sample sizes are larger and involve
nonlinear patterns with long sequences. Furthermore, Bayesian bidirectional
LSTM (BLSTM) as a probabilistic method exhibit the highest accuracy in terms of
least pinball score and root mean square error (RMSE).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Inference with Corrupted Data: Measurement Error, Missing Values, Discretization, and Differential Privacy. (arXiv:2107.02780v1 [econ.EM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/econ/1/au:+Agarwal_A/0/1/0/all/0/1">Anish Agarwal</a>, <a href="http://arxiv.org/find/econ/1/au:+Singh_R/0/1/0/all/0/1">Rahul Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02780">
                                    <div class="article-summary-box-inner">
                                        <span>Even the most carefully curated economic data sets have variables that are
noisy, missing, discretized, or privatized. The standard workflow for empirical
research involves data cleaning followed by data analysis that typically
ignores the bias and variance consequences of data cleaning. We formulate a
semiparametric model for causal inference with corrupted data to encompass both
data cleaning and data analysis. We propose a new end-to-end procedure for data
cleaning, estimation, and inference with data cleaning-adjusted confidence
intervals. We prove root-n consistency, Gaussian approximation, and
semiparametric efficiency for our estimator of the causal parameter by finite
sample arguments. Our key assumption is that the true covariates are
approximately low rank. In our analysis, we provide nonasymptotic theoretical
contributions to matrix completion, statistical learning, and semiparametric
statistics. We verify the coverage of the data cleaning-adjusted confidence
intervals in simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-informed regularization and structure preservation for learning stable reduced models from data with operator inference. (arXiv:2107.02597v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Sawant_N/0/1/0/all/0/1">Nihar Sawant</a>, <a href="http://arxiv.org/find/math/1/au:+Kramer_B/0/1/0/all/0/1">Boris Kramer</a>, <a href="http://arxiv.org/find/math/1/au:+Peherstorfer_B/0/1/0/all/0/1">Benjamin Peherstorfer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02597">
                                    <div class="article-summary-box-inner">
                                        <span>Operator inference learns low-dimensional dynamical-system models with
polynomial nonlinear terms from trajectories of high-dimensional physical
systems (non-intrusive model reduction). This work focuses on the large class
of physical systems that can be well described by models with quadratic
nonlinear terms and proposes a regularizer for operator inference that induces
a stability bias onto quadratic models. The proposed regularizer is physics
informed in the sense that it penalizes quadratic terms with large norms and so
explicitly leverages the quadratic model form that is given by the underlying
physics. This means that the proposed approach judiciously learns from data and
physical insights combined, rather than from either data or physics alone.
Additionally, a formulation of operator inference is proposed that enforces
model constraints for preserving structure such as symmetry and definiteness in
the linear terms. Numerical results demonstrate that models learned with
operator inference and the proposed regularizer and structure preservation are
accurate and stable even in cases where using no regularization or Tikhonov
regularization leads to models that are unstable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Counterfactual Explanations in Sequential Decision Making Under Uncertainty. (arXiv:2107.02776v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsirtsis_S/0/1/0/all/0/1">Stratis Tsirtsis</a>, <a href="http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1">Abir De</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_M/0/1/0/all/0/1">Manuel Gomez-Rodriguez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02776">
                                    <div class="article-summary-box-inner">
                                        <span>Methods to find counterfactual explanations have predominantly focused on one
step decision making processes. In this work, we initiate the development of
methods to find counterfactual explanations for decision making processes in
which multiple, dependent actions are taken sequentially over time. We start by
formally characterizing a sequence of actions and states using finite horizon
Markov decision processes and the Gumbel-Max structural causal model. Building
upon this characterization, we formally state the problem of finding
counterfactual explanations for sequential decision making processes. In our
problem formulation, the counterfactual explanation specifies an alternative
sequence of actions differing in at most k actions from the observed sequence
that could have led the observed process realization to a better outcome. Then,
we introduce a polynomial time algorithm based on dynamic programming to build
a counterfactual policy that is guaranteed to always provide the optimal
counterfactual explanation on every possible realization of the counterfactual
environment dynamics. We validate our algorithm using both synthetic and real
data from cognitive behavioral therapy and show that the counterfactual
explanations our algorithm finds can provide valuable insights to enhance
sequential decision making under uncertainty.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A deep-learning--based multimodal depth-aware dynamic hand gesture recognition system. (arXiv:2107.02543v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmud_H/0/1/0/all/0/1">Hasan Mahmud</a>, <a href="http://arxiv.org/find/cs/1/au:+Morshed_M/0/1/0/all/0/1">Mashrur Mahmud Morshed</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1">Md. Kamrul Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02543">
                                    <div class="article-summary-box-inner">
                                        <span>Any spatio-temporal movement or reorientation of the hand, done with the
intention of conveying a specific meaning, can be considered as a hand gesture.
Inputs to hand gesture recognition systems can be in several forms, such as
depth images, monocular RGB, or skeleton joint points. We observe that raw
depth images possess low contrasts in the hand regions of interest (ROI). They
do not highlight important details to learn, such as finger bending information
(whether a finger is overlapping the palm, or another finger). Recently, in
deep-learning--based dynamic hand gesture recognition, researchers are tying to
fuse different input modalities (e.g. RGB or depth images and hand skeleton
joint points) to improve the recognition accuracy. In this paper, we focus on
dynamic hand gesture (DHG) recognition using depth quantized image features and
hand skeleton joint points. In particular, we explore the effect of using
depth-quantized features in Convolutional Neural Network (CNN) and Recurrent
Neural Network (RNN) based multi-modal fusion networks. We find that our method
improves existing results on the SHREC-DHG-14 dataset. Furthermore, using our
method, we show that it is possible to reduce the resolution of the input
images by more than four times and still obtain comparable or better accuracy
to that of the resolutions used in previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VidLanKD: Improving Language Understanding via Video-Distilled Knowledge Transfer. (arXiv:2107.02681v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zineng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jaemin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02681">
                                    <div class="article-summary-box-inner">
                                        <span>Since visual perception can give rich information beyond text descriptions
for world understanding, there has been increasing interest in leveraging
visual grounding for language learning. Recently, vokenization has attracted
attention by using the predictions of a text-to-image retrieval model as labels
for language model supervision. Despite its success, the method suffers from
approximation error of using finite image labels and the lack of vocabulary
diversity of a small image-text dataset. To overcome these limitations, we
present VidLanKD, a video-language knowledge distillation method for improving
language understanding. We train a multi-modal teacher model on a video-text
dataset, and then transfer its knowledge to a student language model with a
text dataset. To avoid approximation error, we propose to use different
knowledge distillation objectives. In addition, the use of a large-scale
video-text dataset helps learn diverse and richer vocabularies. In our
experiments, VidLanKD achieves consistent improvements over text-only language
models and vokenization models, on several downstream language understanding
tasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world
knowledge, physical reasoning, and temporal reasoning capabilities of our model
by evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we
present comprehensive ablation studies as well as visualizations of the learned
text-to-video grounding results of our teacher and student language models. Our
code and models are available at: https://github.com/zinengtang/VidLanKD</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperspectral Pansharpening Based on Improved Deep Image Prior and Residual Reconstruction. (arXiv:2107.02630v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bandara_W/0/1/0/all/0/1">Wele Gedara Chaminda Bandara</a>, <a href="http://arxiv.org/find/cs/1/au:+Valanarasu_J/0/1/0/all/0/1">Jeya Maria Jose Valanarasu</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02630">
                                    <div class="article-summary-box-inner">
                                        <span>Hyperspectral pansharpening aims to synthesize a low-resolution hyperspectral
image (LR-HSI) with a registered panchromatic image (PAN) to generate an
enhanced HSI with high spectral and spatial resolution. Recently proposed HS
pansharpening methods have obtained remarkable results using deep convolutional
networks (ConvNets), which typically consist of three steps: (1) up-sampling
the LR-HSI, (2) predicting the residual image via a ConvNet, and (3) obtaining
the final fused HSI by adding the outputs from first and second steps. Recent
methods have leveraged Deep Image Prior (DIP) to up-sample the LR-HSI due to
its excellent ability to preserve both spatial and spectral information,
without learning from large data sets. However, we observed that the quality of
up-sampled HSIs can be further improved by introducing an additional
spatial-domain constraint to the conventional spectral-domain energy function.
We define our spatial-domain constraint as the $L_1$ distance between the
predicted PAN image and the actual PAN image. To estimate the PAN image of the
up-sampled HSI, we also propose a learnable spectral response function (SRF).
Moreover, we noticed that the residual image between the up-sampled HSI and the
reference HSI mainly consists of edge information and very fine structures. In
order to accurately estimate fine information, we propose a novel over-complete
network, called HyperKite, which focuses on learning high-level features by
constraining the receptive from increasing in the deep layers. We perform
experiments on three HSI datasets to demonstrate the superiority of our
DIP-HyperKite over the state-of-the-art pansharpening methods. The deployment
codes, pre-trained models, and final fusion outputs of our DIP-HyperKite and
the methods used for the comparisons will be publicly made available at
https://github.com/wgcban/DIP-HyperKite.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Total Nitrogen Estimation in Agricultural Soils via Aerial Multispectral Imaging and LIBS. (arXiv:2107.02355v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hossen_M/0/1/0/all/0/1">Md Abir Hossen</a>, <a href="http://arxiv.org/find/eess/1/au:+Diwaka_P/0/1/0/all/0/1">Prasoon K Diwaka</a>, <a href="http://arxiv.org/find/eess/1/au:+Ragi_S/0/1/0/all/0/1">Shankarachary Ragi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02355">
                                    <div class="article-summary-box-inner">
                                        <span>Measuring soil health indicators is an important and challenging task that
affects farmers&#x27; decisions on timing, placement, and quantity of fertilizers
applied in the farms. Most existing methods to measure soil health indicators
(SHIs) are in-lab wet chemistry or spectroscopy-based methods, which require
significant human input and effort, time-consuming, costly, and are
low-throughput in nature. To address this challenge, we develop an artificial
intelligence (AI)-driven near real-time unmanned aerial vehicle (UAV)-based
multispectral sensing (UMS) solution to estimate total nitrogen (TN) of the
soil, an important macro-nutrient or SHI that directly affects the crop health.
Accurate prediction of soil TN can significantly increase crop yield through
informed decision making on the timing of seed planting, and fertilizer
quantity and timing. We train two machine learning models including multi-layer
perceptron and support vector machine to predict the soil nitrogen using a
suite of data classes including multispectral characteristics of the soil and
crops in red, near-infrared, and green spectral bands, computed vegetation
indices, and environmental variables including air temperature and relative
humidity. To generate the ground-truth data or the training data for the
machine learning models, we measure the total nitrogen of the soil samples
(collected from a farm) using laser-induced breakdown spectroscopy (LIBS).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Risk bounds when learning infinitely many response functions by ordinary linear regression. (arXiv:2006.09223v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Plassier_V/0/1/0/all/0/1">Vincent Plassier</a>, <a href="http://arxiv.org/find/stat/1/au:+Portier_F/0/1/0/all/0/1">Fran&#xe7;ois Portier</a>, <a href="http://arxiv.org/find/stat/1/au:+Segers_J/0/1/0/all/0/1">Johan Segers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09223">
                                    <div class="article-summary-box-inner">
                                        <span>Consider the problem of learning a large number of response functions
simultaneously based on the same input variables. The training data consist of
a single independent random sample of the input variables drawn from a common
distribution together with the associated responses. The input variables are
mapped into a high-dimensional linear space, called the feature space, and the
response functions are modelled as linear functionals of the mapped features,
with coefficients calibrated via ordinary least squares. We provide convergence
guarantees on the worst-case excess prediction risk by controlling the
convergence rate of the excess risk uniformly in the response function. The
dimension of the feature map is allowed to tend to infinity with the sample
size. The collection of response functions, although potentially infinite, is
supposed to have a finite Vapnik-Chervonenkis dimension. The bound derived can
be applied when building multiple surrogate models in a reasonable computing
time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Testing With Reusable Adversarial Agents. (arXiv:1910.13645v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1">Xin Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Arechiga_N/0/1/0/all/0/1">Nikos Ar&#xe9;chiga</a>, <a href="http://arxiv.org/find/cs/1/au:+Best_A/0/1/0/all/0/1">Andrew Best</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshmukh_J/0/1/0/all/0/1">Jyotirmoy Deshmukh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.13645">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous systems such as self-driving cars and general-purpose robots are
safety-critical systems that operate in highly uncertain and dynamic
environments. We propose an interactive multi-agent framework where the
system-under-design is modeled as an ego agent and its environment is modeled
by a number of adversarial (ado) agents. For example, a self-driving car is an
ego agent whose behavior is influenced by ado agents such as pedestrians,
bicyclists, traffic lights, road geometry etc. Given a logical specification of
the correct behavior of the ego agent, and a set of constraints that encode
reasonable adversarial behavior, our framework reduces the adversarial testing
problem to the problem of synthesizing controllers for (constrained) ado agents
that cause the ego agent to violate its specifications. Specifically, we
explore the use of tabular and deep reinforcement learning approaches for
synthesizing adversarial agents. We show that ado agents trained in this
fashion are better than traditional falsification or testing techniques because
they can generalize to ego agents and environments that differ from the
original ego agent. We demonstrate the efficacy of our technique on two
real-world case studies from the domain of self-driving cars.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ActNN: Reducing Training Memory Footprint via 2-Bit Activation Compressed Training. (arXiv:2104.14129v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianfei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lianmin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhewei Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dequan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14129">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing size of neural network models has been critical for
improvements in their accuracy, but device memory is not growing at the same
rate. This creates fundamental challenges for training neural networks within
limited memory environments. In this work, we propose ActNN, a memory-efficient
training framework that stores randomly quantized activations for back
propagation. We prove the convergence of ActNN for general network
architectures, and we characterize the impact of quantization on the
convergence via an exact expression for the gradient variance. Using our
theory, we propose novel mixed-precision quantization strategies that exploit
the activation&#x27;s heterogeneity across feature dimensions, samples, and layers.
These techniques can be readily applied to existing dynamic graph frameworks,
such as PyTorch, simply by substituting the layers. We evaluate ActNN on
mainstream computer vision models for classification, detection, and
segmentation tasks. On all these tasks, ActNN compresses the activation to 2
bits on average, with negligible accuracy loss. ActNN reduces the memory
footprint of the activation by 12x, and it enables training with a 6.6x to 14x
larger batch size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably Strict Generalisation Benefit for Equivariant Models. (arXiv:2102.10333v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Elesedy_B/0/1/0/all/0/1">Bryn Elesedy</a>, <a href="http://arxiv.org/find/stat/1/au:+Zaidi_S/0/1/0/all/0/1">Sheheryar Zaidi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10333">
                                    <div class="article-summary-box-inner">
                                        <span>It is widely believed that engineering a model to be invariant/equivariant
improves generalisation. Despite the growing popularity of this approach, a
precise characterisation of the generalisation benefit is lacking. By
considering the simplest case of linear models, this paper provides the first
provably non-zero improvement in generalisation for invariant/equivariant
models when the target distribution is invariant/equivariant with respect to a
compact group. Moreover, our work reveals an interesting relationship between
generalisation, the number of training examples and properties of the group
action. Our results rest on an observation of the structure of function spaces
under averaging operators which, along with its consequences for feature
averaging, may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven reduced order modeling of environmental hydrodynamics using deep autoencoders and neural ODEs. (arXiv:2107.02784v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dutta_S/0/1/0/all/0/1">Sourav Dutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivera_Casillas_P/0/1/0/all/0/1">Peter Rivera-Casillas</a>, <a href="http://arxiv.org/find/cs/1/au:+Cecil_O/0/1/0/all/0/1">Orie M. Cecil</a>, <a href="http://arxiv.org/find/cs/1/au:+Farthing_M/0/1/0/all/0/1">Matthew W. Farthing</a>, <a href="http://arxiv.org/find/cs/1/au:+Perracchione_E/0/1/0/all/0/1">Emma Perracchione</a>, <a href="http://arxiv.org/find/cs/1/au:+Putti_M/0/1/0/all/0/1">Mario Putti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02784">
                                    <div class="article-summary-box-inner">
                                        <span>Model reduction for fluid flow simulation continues to be of great interest
across a number of scientific and engineering fields. In a previous work
[arXiv:2104.13962], we explored the use of Neural Ordinary Differential
Equations (NODE) as a non-intrusive method for propagating the latent-space
dynamics in reduced order models. Here, we investigate employing deep
autoencoders for discovering the reduced basis representation, the dynamics of
which are then approximated by NODE. The ability of deep autoencoders to
represent the latent-space is compared to the traditional proper orthogonal
decomposition (POD) approach, again in conjunction with NODE for capturing the
dynamics. Additionally, we compare their behavior with two classical
non-intrusive methods based on POD and radial basis function interpolation as
well as dynamic mode decomposition. The test problems we consider include
incompressible flow around a cylinder as well as a real-world application of
shallow water hydrodynamics in an estuarine system. Our findings indicate that
deep autoencoders can leverage nonlinear manifold learning to achieve a highly
efficient compression of spatial information and define a latent-space that
appears to be more suitable for capturing the temporal dynamics through the
NODE framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An $\ell_p$ theory of PCA and spectral clustering. (arXiv:2006.14062v2 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Abbe_E/0/1/0/all/0/1">Emmanuel Abbe</a>, <a href="http://arxiv.org/find/math/1/au:+Fan_J/0/1/0/all/0/1">Jianqing Fan</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_K/0/1/0/all/0/1">Kaizheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.14062">
                                    <div class="article-summary-box-inner">
                                        <span>Principal Component Analysis (PCA) is a powerful tool in statistics and
machine learning. While existing study of PCA focuses on the recovery of
principal components and their associated eigenvalues, there are few precise
characterizations of individual principal component scores that yield
low-dimensional embedding of samples. That hinders the analysis of various
spectral methods. In this paper, we first develop an $\ell_p$ perturbation
theory for a hollowed version of PCA in Hilbert spaces which provably improves
upon the vanilla PCA in the presence of heteroscedastic noises. Through a novel
$\ell_p$ analysis of eigenvectors, we investigate entrywise behaviors of
principal component score vectors and show that they can be approximated by
linear functionals of the Gram matrix in $\ell_p$ norm, which includes $\ell_2$
and $\ell_\infty$ as special examples. For sub-Gaussian mixture models, the
choice of $p$ giving optimal bounds depends on the signal-to-noise ratio, which
further yields optimality guarantees for spectral clustering. For contextual
community detection, the $\ell_p$ theory leads to a simple spectral algorithm
that achieves the information threshold for exact recovery. These also provide
optimal recovery results for Gaussian mixture and stochastic block models as
special cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Experts&#x27; Opinions in Machine Learning Tasks. (arXiv:2008.04216v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Habibi_J/0/1/0/all/0/1">Jafar Habibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazelinia_A/0/1/0/all/0/1">Amir Fazelinia</a>, <a href="http://arxiv.org/find/cs/1/au:+Annamoradnejad_I/0/1/0/all/0/1">Issa Annamoradnejad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.04216">
                                    <div class="article-summary-box-inner">
                                        <span>In machine learning tasks, especially in the tasks of prediction, scientists
tend to rely solely on available historical data and disregard unproven
insights, such as experts&#x27; opinions, polls, and betting odds. In this paper, we
propose a general three-step framework for utilizing experts&#x27; insights in
machine learning tasks and build four concrete models for a sports game
prediction case study. For the case study, we have chosen the task of
predicting NCAA Men&#x27;s Basketball games, which has been the focus of a group of
Kaggle competitions in recent years. Results highly suggest that the good
performance and high scores of the past models are a result of chance, and not
because of a good-performing and stable model. Furthermore, our proposed models
can achieve more steady results with lower log loss average (best at 0.489)
compared to the top solutions of the 2019 competition (&gt;0.503), and reach the
top 1%, 10% and 1% in the 2017, 2018 and 2019 leaderboards, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Model-Driven Engineering Approach to Machine Learning and Software Modeling. (arXiv:2107.02689v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moin_A/0/1/0/all/0/1">Armin Moin</a>, <a href="http://arxiv.org/find/cs/1/au:+Badii_A/0/1/0/all/0/1">Atta Badii</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02689">
                                    <div class="article-summary-box-inner">
                                        <span>Models are used in both the Software Engineering (SE) and the Artificial
Intelligence (AI) communities. In the former case, models of software, which
may specify the software system architecture on different levels of abstraction
could be used in various stages of the Software Development Life-Cycle (SDLC),
from early conceptualization and design, to verification, implementation,
testing and evolution. However, in the latter case, i.e., AI, models may
provide smart capabilities, such as prediction and decision making support. For
instance, in Machine Learning (ML), which is the most popular sub-discipline of
AI at the present time, mathematical models may learn useful patterns in the
observed data instances and can become capable of making better predictions or
recommendations in the future. The goal of this work is to create synergy by
bringing models in the said communities together and proposing a holistic
approach. We illustrate how software models can become capable of producing or
dealing with data analytics and ML models. The main focus is on the Internet of
Things (IoT) and smart Cyber-Physical Systems (CPS) use cases, where both ML
and model-driven (model-based) SE play a key role. In particular, we implement
the proposed approach in an open source prototype and validate it using two use
cases from the IoT/CPS domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LTL2Action: Generalizing LTL Instructions for Multi-Task RL. (arXiv:2102.06858v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vaezipoor_P/0/1/0/all/0/1">Pashootan Vaezipoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Andrew Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Icarte_R/0/1/0/all/0/1">Rodrigo Toro Icarte</a>, <a href="http://arxiv.org/find/cs/1/au:+McIlraith_S/0/1/0/all/0/1">Sheila McIlraith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06858">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of teaching a deep reinforcement learning (RL) agent
to follow instructions in multi-task environments. Instructions are expressed
in a well-known formal language -- linear temporal logic (LTL) -- and can
specify a diversity of complex, temporally extended behaviours, including
conditionals and alternative realizations. Our proposed learning approach
exploits the compositional syntax and the semantics of LTL, enabling our RL
agent to learn task-conditioned policies that generalize to new instructions,
not observed during training. To reduce the overhead of learning LTL semantics,
we introduce an environment-agnostic LTL pretraining scheme which improves
sample-efficiency in downstream environments. Experiments on discrete and
continuous domains target combinatorial task sets of up to $\sim10^{39}$ unique
tasks and demonstrate the strength of our approach in learning to solve
(unseen) tasks, given LTL instructions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic size and pose homogenization with spatial transformer network to improve and accelerate pediatric segmentation. (arXiv:2107.02655v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbera_G/0/1/0/all/0/1">Giammarco La Barbera</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Boussaid_H/0/1/0/all/0/1">Haithem Boussaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Belucci_B/0/1/0/all/0/1">Bruno Belucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Delmonte_A/0/1/0/all/0/1">Alessandro Delmonte</a>, <a href="http://arxiv.org/find/cs/1/au:+Goulin_J/0/1/0/all/0/1">Jeanne Goulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarnacki_S/0/1/0/all/0/1">Sabine Sarnacki</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouet_L/0/1/0/all/0/1">Laurence Rouet</a>, <a href="http://arxiv.org/find/cs/1/au:+Bloch_I/0/1/0/all/0/1">Isabelle Bloch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02655">
                                    <div class="article-summary-box-inner">
                                        <span>Due to a high heterogeneity in pose and size and to a limited number of
available data, segmentation of pediatric images is challenging for deep
learning methods. In this work, we propose a new CNN architecture that is pose
and scale invariant thanks to the use of Spatial Transformer Network (STN). Our
architecture is composed of three sequential modules that are estimated
together during training: (i) a regression module to estimate a similarity
matrix to normalize the input image to a reference one; (ii) a differentiable
module to find the region of interest to segment; (iii) a segmentation module,
based on the popular UNet architecture, to delineate the object. Unlike the
original UNet, which strives to learn a complex mapping, including pose and
scale variations, from a finite training dataset, our segmentation module
learns a simpler mapping focusing on images with normalized pose and size.
Furthermore, the use of an automatic bounding box detection through STN allows
saving time and especially memory, while keeping similar performance. We test
the proposed method in kidney and renal tumor segmentation on abdominal
pediatric CT scanners. Results indicate that the estimated STN homogenization
of size and pose accelerates the segmentation (25h), compared to standard
data-augmentation (33h), while obtaining a similar quality for the kidney
(88.01\% of Dice score) and improving the renal tumor delineation (from 85.52\%
to 87.12\%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamical System Parameter Identification using Deep Recurrent Cell Networks. (arXiv:2107.02427v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akagunduz_E/0/1/0/all/0/1">Erdem Akag&#xfc;nd&#xfc;z</a>, <a href="http://arxiv.org/find/cs/1/au:+Cifdaloz_O/0/1/0/all/0/1">Oguzhan Cifdaloz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02427">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate the parameter identification problem in
dynamical systems through a deep learning approach. Focusing mainly on
second-order, linear time-invariant dynamical systems, the topic of damping
factor identification is studied. By utilizing a six-layer deep neural network
with different recurrent cells, namely GRUs, LSTMs or BiLSTMs; and by feeding
input-output sequence pairs captured from a dynamical system simulator, we
search for an effective deep recurrent architecture in order to resolve damping
factor identification problem. Our study results show that, although previously
not utilized for this task in the literature, bidirectional gated recurrent
cells (BiLSTMs) provide better parameter identification results when compared
to unidirectional gated recurrent memory cells such as GRUs and LSTM. Thus,
indicating that an input-output sequence pair of finite length, collected from
a dynamical system and when observed anachronistically, may carry information
in both time directions for prediction of a dynamical systems parameter.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DriveML: An R Package for Driverless Machine Learning. (arXiv:2005.00478v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Putatunda_S/0/1/0/all/0/1">Sayan Putatunda</a>, <a href="http://arxiv.org/find/cs/1/au:+Ubrangala_D/0/1/0/all/0/1">Dayananda Ubrangala</a>, <a href="http://arxiv.org/find/cs/1/au:+Rama_K/0/1/0/all/0/1">Kiran Rama</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondapalli_R/0/1/0/all/0/1">Ravi Kondapalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00478">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the concept of automated machine learning has become very
popular. Automated Machine Learning (AutoML) mainly refers to the automated
methods for model selection and hyper-parameter optimization of various
algorithms such as random forests, gradient boosting, neural networks, etc. In
this paper, we introduce a new package i.e. DriveML for automated machine
learning. DriveML helps in implementing some of the pillars of an automated
machine learning pipeline such as automated data preparation, feature
engineering, model building and model explanation by running the function
instead of writing lengthy R codes. The DriveML package is available in CRAN.
We compare the DriveML package with other relevant packages in CRAN/Github and
find that DriveML performs the best across different parameters. We also
provide an illustration by applying the DriveML package with default
configuration on a real world dataset. Overall, the main benefits of DriveML
are in development time savings, reduce developer&#x27;s errors, optimal tuning of
machine learning models and reproducibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dirichlet Energy Constrained Learning for Deep Graph Neural Networks. (arXiv:2107.02392v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaixiong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_D/0/1/0/all/0/1">Daochen Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Rui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Li Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Soo-Hyun Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xia Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02392">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) integrate deep architectures and topological
structure modeling in an effective way. However, the performance of existing
GNNs would decrease significantly when they stack many layers, because of the
over-smoothing issue. Node embeddings tend to converge to similar vectors when
GNNs keep recursively aggregating the representations of neighbors. To enable
deep GNNs, several methods have been explored recently. But they are developed
from either techniques in convolutional neural networks or heuristic
strategies. There is no generalizable and theoretical principle to guide the
design of deep GNNs. To this end, we analyze the bottleneck of deep GNNs by
leveraging the Dirichlet energy of node embeddings, and propose a generalizable
principle to guide the training of deep GNNs. Based on it, a novel deep GNN
framework -- EGNN is designed. It could provide lower and upper constraints in
terms of Dirichlet energy at each layer to avoid over-smoothing. Experimental
results demonstrate that EGNN achieves state-of-the-art performance by using
deep layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum Annealing Formulation for Binary Neural Networks. (arXiv:2107.02751v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Sasdelli_M/0/1/0/all/0/1">Michele Sasdelli</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Chin_T/0/1/0/all/0/1">Tat-Jun Chin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02751">
                                    <div class="article-summary-box-inner">
                                        <span>Quantum annealing is a promising paradigm for building practical quantum
computers. Compared to other approaches, quantum annealing technology has been
scaled up to a larger number of qubits. On the other hand, deep learning has
been profoundly successful in pushing the boundaries of AI. It is thus natural
to investigate potentially game changing technologies such as quantum annealers
to augment the capabilities of deep learning. In this work, we explore binary
neural networks, which are lightweight yet powerful models typically intended
for resource constrained devices. Departing from current training regimes for
binary networks that smooth/approximate the activation functions to make the
network differentiable, we devise a quadratic unconstrained binary optimization
formulation for the training problem. While the problem is intractable, i.e.,
the cost to estimate the binary weights scales exponentially with network size,
we show how the problem can be optimized directly on a quantum annealer,
thereby opening up to the potential gains of quantum computing. We
experimentally validated our formulation via simulation and testing on an
actual quantum annealer (D-Wave Advantage), the latter to the extent allowable
by the capacity of current technology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Off-Policy Evaluation Approach for General Value Function. (arXiv:2107.02711v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tengyu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuoran Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaoran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yingbin Liang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02711">
                                    <div class="article-summary-box-inner">
                                        <span>General Value Function (GVF) is a powerful tool to represent both the {\em
predictive} and {\em retrospective} knowledge in reinforcement learning (RL).
In practice, often multiple interrelated GVFs need to be evaluated jointly with
pre-collected off-policy samples. In the literature, the gradient temporal
difference (GTD) learning method has been adopted to evaluate GVFs in the
off-policy setting, but such an approach may suffer from a large estimation
error even if the function approximation class is sufficiently expressive.
Moreover, none of the previous work have formally established the convergence
guarantee to the ground truth GVFs under the function approximation settings.
In this paper, we address both issues through the lens of a class of GVFs with
causal filtering, which cover a wide range of RL applications such as reward
variance, value gradient, cost in anomaly detection, stationary distribution
gradient, etc. We propose a new algorithm called GenTD for off-policy GVFs
evaluation and show that GenTD learns multiple interrelated multi-dimensional
GVFs as efficiently as a single canonical scalar value function. We further
show that unlike GTD, the learned GVFs by GenTD are guaranteed to converge to
the ground truth GVFs as long as the function approximation power is
sufficiently large. To our best knowledge, GenTD is the first off-policy GVF
evaluation algorithm that has global optimality guarantee.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ML-Quadrat &amp; DriotData: A Model-Driven Engineering Tool and a Low-Code Platform for Smart IoT Services. (arXiv:2107.02692v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moin_A/0/1/0/all/0/1">Armin Moin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mituca_A/0/1/0/all/0/1">Andrei Mituca</a>, <a href="http://arxiv.org/find/cs/1/au:+Badii_A/0/1/0/all/0/1">Atta Badii</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02692">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present the novel early tool prototype of ML-Quadrat, which
is an open source research prototype, based on the Eclipse Modeling Framework
(EMF) and the state of the art in the literature of Model-Driven Software
Engineering (MDSE) for smart Cyber-Physical Systems (CPS) and the Internet of
Things (IoT). Its envisioned users are mostly software developers, who might
not have deep knowledge and skills in the heterogeneous IoT platforms and the
diverse Artificial Intelligence (AI) technologies, specifically regarding Data
Analytics and Machine Learning (DAML). ML-Quadrat is released under the terms
of the Apache 2.0 license on Github: https://github.com/arminmoin/ML-Quadrat.
Additionally, the novel early tool prototype of DriotData, a Low-Code platform
targeting citizen data scientists and citizen/end-user software developers is
demonstrated. DriotData exploits and adopts ML-Quadrat and offers an extended
version of it as a web-based service to companies, especially Small- and
Medium-Sized Enterprises (SME). A basic web-based demo of the Minimum Viable
Product (MVP) of DriotData is already available. Finally, a short video
demonstrating the tools is available on YouTube: https://youtu.be/YCNFfhmy_JY.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prioritized training on points that are learnable, worth learning, and not yet learned. (arXiv:2107.02565v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1">S&#xf6;ren Mindermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Razzak_M/0/1/0/all/0/1">Muhammed Razzak</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Winnie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirsch_A/0/1/0/all/0/1">Andreas Kirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_M/0/1/0/all/0/1">Mrinank Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Morisot_A/0/1/0/all/0/1">Adrien Morisot</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1">Aidan N. Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1">Sebastian Farquhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Brauner_J/0/1/0/all/0/1">Jan Brauner</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02565">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Goldilocks Selection, a technique for faster model training
which selects a sequence of training points that are &quot;just right&quot;. We propose
an information-theoretic acquisition function -- the reducible validation loss
-- and compute it with a small proxy model -- GoldiProx -- to efficiently
choose training points that maximize information about a validation set. We
show that the &quot;hard&quot; (e.g. high loss) points usually selected in the
optimization literature are typically noisy, while the &quot;easy&quot; (e.g. low noise)
samples often prioritized for curriculum learning confer less information.
Further, points with uncertain labels, typically targeted by active learning,
tend to be less relevant to the task. In contrast, Goldilocks Selection chooses
points that are &quot;just right&quot; and empirically outperforms the above approaches.
Moreover, the selected sequence can transfer to other architectures;
practitioners can share and reuse it without the need to recreate it.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedFog: Network-Aware Optimization of Federated Learning over Wireless Fog-Cloud Systems. (arXiv:2107.02755v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Van-Dinh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatzinotas_S/0/1/0/all/0/1">Symeon Chatzinotas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ottersten_B/0/1/0/all/0/1">Bjorn Ottersten</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_T/0/1/0/all/0/1">Trung Q. Duong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02755">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) is capable of performing large distributed machine
learning tasks across multiple edge users by periodically aggregating trained
local parameters. To address key challenges of enabling FL over a wireless
fog-cloud system (e.g., non-i.i.d. data, users&#x27; heterogeneity), we first
propose an efficient FL algorithm (called FedFog) to perform the local
aggregation of gradient parameters at fog servers and global training update at
the cloud. Next, we employ FedFog in wireless fog-cloud systems by
investigating a novel network-aware FL optimization problem that strikes the
balance between the global loss and completion time. An iterative algorithm is
then developed to obtain a precise measurement of the system performance, which
helps design an efficient stopping criteria to output an appropriate number of
global rounds. To mitigate the straggler effect, we propose a flexible user
aggregation strategy that trains fast users first to obtain a certain level of
accuracy before allowing slow users to join the global training updates.
Extensive numerical results using several real-world FL tasks are provided to
verify the theoretical convergence of FedFog. We also show that the proposed
co-design of FL and communication is essential to substantially improve
resource utilization while achieving comparable accuracy of the learning model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DTGAN: Differential Private Training for Tabular GANs. (arXiv:2107.02521v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kunar_A/0/1/0/all/0/1">Aditya Kunar</a>, <a href="http://arxiv.org/find/cs/1/au:+Birke_R/0/1/0/all/0/1">Robert Birke</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lydia Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zilong Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02521">
                                    <div class="article-summary-box-inner">
                                        <span>Tabular generative adversarial networks (TGAN) have recently emerged to cater
to the need of synthesizing tabular data -- the most widely used data format.
While synthetic tabular data offers the advantage of complying with privacy
regulations, there still exists a risk of privacy leakage via inference attacks
due to interpolating the properties of real data during training. Differential
private (DP) training algorithms provide theoretical guarantees for training
machine learning models by injecting statistical noise to prevent privacy
leaks. However, the challenges of applying DP on TGAN are to determine the most
optimal framework (i.e., PATE/DP-SGD) and neural network (i.e.,
Generator/Discriminator)to inject noise such that the data utility is well
maintained under a given privacy guarantee. In this paper, we propose DTGAN, a
novel conditional Wasserstein tabular GAN that comes in two variants DTGAN_G
and DTGAN_D, for providing a detailed comparison of tabular GANs trained using
DP-SGD for the generator vs discriminator, respectively. We elicit the privacy
analysis associated with training the generator with complex loss functions
(i.e., classification and information losses) needed for high quality tabular
data synthesis. Additionally, we rigorously evaluate the theoretical privacy
guarantees offered by DP empirically against membership and attribute inference
attacks. Our results on 3 datasets show that the DP-SGD framework is superior
to PATE and that a DP discriminator is more optimal for training convergence.
Thus, we find (i) DTGAN_D is capable of maintaining the highest data utility
across 4 ML models by up to 18% in terms of the average precision score for a
strict privacy budget, epsilon &#x3D; 1, as compared to the prior studies and (ii)
DP effectively prevents privacy loss against inference attacks by restricting
the success probability of membership attacks to be close to 50%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Generalization of Graph Autoencoders with Adversarial Training. (arXiv:2107.02658v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+huang_T/0/1/0/all/0/1">Tianjin huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pei_Y/0/1/0/all/0/1">Yulong Pei</a>, <a href="http://arxiv.org/find/cs/1/au:+Menkovski_V/0/1/0/all/0/1">Vlado Menkovski</a>, <a href="http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1">Mykola Pechenizkiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02658">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training is an approach for increasing model&#x27;s resilience against
adversarial perturbations. Such approaches have been demonstrated to result in
models with feature representations that generalize better. However, limited
works have been done on adversarial training of models on graph data. In this
paper, we raise such a question { does adversarial training improve the
generalization of graph representations. We formulate L2 and L1 versions of
adversarial training in two powerful node embedding methods: graph autoencoder
(GAE) and variational graph autoencoder (VGAE). We conduct extensive
experiments on three main applications, i.e. link prediction, node clustering,
graph anomaly detection of GAE and VGAE, and demonstrate that both L2 and L1
adversarial training boost the generalization of GAE and VGAE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Does Dataset Complexity Matters for Model Explainers?. (arXiv:2107.02661v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_J/0/1/0/all/0/1">Jos&#xe9; Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1">Ra&#xed;ssa Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Alves_R/0/1/0/all/0/1">Ronnie Alves</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02661">
                                    <div class="article-summary-box-inner">
                                        <span>Strategies based on Explainable Artificial Intelligence - XAI have emerged in
computing to promote a better understanding of predictions made by black box
models. Most XAI-based tools used today explain these types of models,
generating attribute rankings aimed at explaining the same, that is, the
analysis of Attribute Importance. There is no consensus on which XAI tool
generates a general rank of explainability, for this reason, several proposals
for tools have emerged (Ciu, Dalex, Eli5, Lofo, Shap and Skater). Here, we
present an experimental benchmark of explainable AI techniques capable of
producing model-agnostic global explainability ranks based on tabular data
related to different problems. Seeking to answer questions such as &quot;Are the
explanations generated by the different tools the same, similar or different?&quot;
and &quot;How does data complexity play along model explainability?&quot;. The results
from the construction of 82 computational models and 592 ranks give us some
light on the other side of the problem of explainability: dataset complexity!</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaRL: What, Where, and How to Adapt in Transfer Reinforcement Learning. (arXiv:2107.02729v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1">Biwei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chaochao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Magliacane_S/0/1/0/all/0/1">Sara Magliacane</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02729">
                                    <div class="article-summary-box-inner">
                                        <span>Most approaches in reinforcement learning (RL) are data-hungry and specific
to fixed environments. In this paper, we propose a principled framework for
adaptive RL, called AdaRL, that adapts reliably to changes across domains.
Specifically, we construct a generative environment model for the structural
relationships among variables in the system and embed the changes in a compact
way, which provides a clear and interpretable picture for locating what and
where the changes are and how to adapt. Based on the environment model, we
characterize a minimal set of representations, including both domain-specific
factors and domain-shared state representations, that suffice for reliable and
low-cost transfer. Moreover, we show that by explicitly leveraging a compact
representation to encode changes, we can adapt the policy with only a few
samples without further policy optimization in the target domain. We illustrate
the efficacy of AdaRL through a series of experiments that allow for changes in
different components of Cartpole and Atari games.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Early Recognition of Ball Catching Success in Clinical Trials with RNN-Based Predictive Classification. (arXiv:2107.02442v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lang_J/0/1/0/all/0/1">Jana Lang</a>, <a href="http://arxiv.org/find/cs/1/au:+Giese_M/0/1/0/all/0/1">Martin A. Giese</a>, <a href="http://arxiv.org/find/cs/1/au:+Synofzik_M/0/1/0/all/0/1">Matthis Synofzik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilg_W/0/1/0/all/0/1">Winfried Ilg</a>, <a href="http://arxiv.org/find/cs/1/au:+Otte_S/0/1/0/all/0/1">Sebastian Otte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02442">
                                    <div class="article-summary-box-inner">
                                        <span>Motor disturbances can affect the interaction with dynamic objects, such as
catching a ball. A classification of clinical catching trials might give
insight into the existence of pathological alterations in the relation of arm
and ball movements. Accurate, but also early decisions are required to classify
a catching attempt before the catcher&#x27;s first ball contact. To obtain
clinically valuable results, a significant decision confidence of at least 75%
is required. Hence, three competing objectives have to be optimized at the same
time: accuracy, earliness and decision-making confidence. Here we propose a
coupled classification and prediction approach for early time series
classification: a predictive, generative recurrent neural network (RNN)
forecasts the next data points of ball trajectories based on already available
observations; a discriminative RNN continuously generates classification
guesses based on the available data points and the unrolled sequence
predictions. We compare our approach, which we refer to as predictive
sequential classification (PSC), to state-of-the-art sequence learners,
including various RNN and temporal convolutional network (TCN) architectures.
On this hard real-world task we can consistently demonstrate the superiority of
PSC over all other models in terms of accuracy and confidence with respect to
earliness of recognition. Specifically, PSC is able to confidently classify the
success of catching trials as early as 123 milliseconds before the first ball
contact. We conclude that PSC is a promising approach for early time series
classification, when accurate and confident decisions are required.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Informed Graph Learning for Robust Fault Location in Distribution Systems. (arXiv:2107.02275v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenting Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deka_D/0/1/0/all/0/1">Deepjyoti Deka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02275">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid growth of distributed energy resources potentially increases power
grid instability. One promising strategy is to employ data in power grids to
efficiently respond to abnormal events (e.g., faults) by detection and
location. Unfortunately, most existing works lack physical interpretation and
are vulnerable to the practical challenges: sparse observation, insufficient
labeled datasets, and stochastic environment. We propose a physics-informed
graph learning framework of two stages to handle these challenges when locating
faults. Stage- I focuses on informing a graph neural network (GNN) with the
geometrical structure of power grids; stage-II employs the physical similarity
of labeled and unlabeled data samples to improve the location accuracy. We
provide a random walk-based the underpinning of designing our GNNs to address
the challenge of sparse observation and augment the correct prediction
probability. We compare our approach with three baselines in the IEEE 123-node
benchmark system, showing that the proposed method outperforms the others by
significant margins, especially when label rates are low. Also, we validate the
robustness of our algorithms to out-of-distribution-data (ODD) due to topology
changes and load variations. Additionally, we adapt our graph learning
framework to the IEEE 37-node test feeder and show high location performance
with the proposed training strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Bandits on General Graphs. (arXiv:2107.02772v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maiti_A/0/1/0/all/0/1">Aurghya Maiti</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1">Vineet Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_G/0/1/0/all/0/1">Gaurav Sinha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02772">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of determining the best intervention in a Causal
Bayesian Network (CBN) specified only by its causal graph. We model this as a
stochastic multi-armed bandit (MAB) problem with side-information, where the
interventions correspond to the arms of the bandit instance. First, we propose
a simple regret minimization algorithm that takes as input a semi-Markovian
causal graph with atomic interventions and possibly unobservable variables, and
achieves $\tilde{O}(\sqrt{M/T})$ expected simple regret, where $M$ is dependent
on the input CBN and could be very small compared to the number of arms. We
also show that this is almost optimal for CBNs described by causal graphs
having an $n$-ary tree structure. Our simple regret minimization results, both
upper and lower bound, subsume previous results in the literature, which
assumed additional structural restrictions on the input causal graph. In
particular, our results indicate that the simple regret guarantee of our
proposed algorithm can only be improved by considering more nuanced structural
restrictions on the causal graph. Next, we propose a cumulative regret
minimization algorithm that takes as input a general causal graph with all
observable nodes and atomic interventions and performs better than the optimal
MAB algorithm that does not take causal side-information into account. We also
experimentally compare both our algorithms with the best known algorithms in
the literature. To the best of our knowledge, this work gives the first simple
and cumulative regret minimization algorithms for CBNs with general causal
graphs under atomic interventions and having unobserved confounders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Methods for Joint Optimization of Beamforming and Fronthaul Quantization in Cloud Radio Access Networks. (arXiv:2107.02520v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yu_D/0/1/0/all/0/1">Daesung Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1">Hoon Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Park_S/0/1/0/all/0/1">Seok-Hwan Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Hong_S/0/1/0/all/0/1">Seung-Eun Hong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02520">
                                    <div class="article-summary-box-inner">
                                        <span>Cooperative beamforming across access points (APs) and fronthaul quantization
strategies are essential for cloud radio access network (C-RAN) systems. The
nonconvexity of the C-RAN optimization problems, which is stemmed from per-AP
power and fronthaul capacity constraints, requires high computational
complexity for executing iterative algorithms. To resolve this issue, we
investigate a deep learning approach where the optimization module is replaced
with a well-trained deep neural network (DNN). An efficient learning solution
is proposed which constructs a DNN to produce a low-dimensional representation
of optimal beamforming and quantization strategies. Numerical results validate
the advantages of the proposed learning solution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DEANN: Speeding up Kernel-Density Estimation using Approximate Nearest Neighbor Search. (arXiv:2107.02736v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karppa_M/0/1/0/all/0/1">Matti Karppa</a>, <a href="http://arxiv.org/find/cs/1/au:+Aumuller_M/0/1/0/all/0/1">Martin Aum&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Pagh_R/0/1/0/all/0/1">Rasmus Pagh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02736">
                                    <div class="article-summary-box-inner">
                                        <span>Kernel Density Estimation (KDE) is a nonparametric method for estimating the
shape of a density function, given a set of samples from the distribution.
Recently, locality-sensitive hashing, originally proposed as a tool for nearest
neighbor search, has been shown to enable fast KDE data structures. However,
these approaches do not take advantage of the many other advances that have
been made in algorithms for nearest neighbor algorithms. We present an
algorithm called Density Estimation from Approximate Nearest Neighbors (DEANN)
where we apply Approximate Nearest Neighbor (ANN) algorithms as a black box
subroutine to compute an unbiased KDE. The idea is to find points that have a
large contribution to the KDE using ANN, compute their contribution exactly,
and approximate the remainder with Random Sampling (RS). We present a
theoretical argument that supports the idea that an ANN subroutine can speed up
the evaluation. Furthermore, we provide a C++ implementation with a Python
interface that can make use of an arbitrary ANN implementation as a subroutine
for KDE evaluation. We show empirically that our implementation outperforms
state of the art implementations in all high dimensional datasets we
considered, and matches the performance of RS in cases where the ANN yield no
gains in performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The QR decomposition for radial neural networks. (arXiv:2107.02550v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganev_I/0/1/0/all/0/1">Iordan Ganev</a>, <a href="http://arxiv.org/find/cs/1/au:+Walters_R/0/1/0/all/0/1">Robin Walters</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02550">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a theoretical framework for neural networks in terms of the
representation theory of quivers, thus revealing symmetries of the parameter
space of neural networks. An exploitation of these symmetries leads to a model
compression algorithm for radial neural networks based on an analogue of the QR
decomposition. A projected version of backpropogation on the original model
matches usual backpropogation on the compressed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy and Thermal-aware Resource Management of Cloud Data Centres: A Taxonomy and Future Directions. (arXiv:2107.02342v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ilager_S/0/1/0/all/0/1">Shashikant Ilager</a>, <a href="http://arxiv.org/find/cs/1/au:+Buyya_R/0/1/0/all/0/1">Rajkumar Buyya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02342">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the existing resource management approaches in Cloud
Data Centres for energy and thermal efficiency. It identifies the need for
integrated computing and cooling systems management and learning-based
solutions in resource management systems. A taxonomy on energy and thermal
efficient resource management in data centres is proposed based on an in-depth
analysis of the literature. Furthermore, a detailed survey on existing
approaches is conducted according to the taxonomy and recent advancements
including machine learning-based resource management approaches and cooling
management technologies are discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhanced Universal Dependency Parsing with Automated Concatenation of Embeddings. (arXiv:2107.02416v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1">Zixia Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02416">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the system used in submission from SHANGHAITECH team to
the IWPT 2021 Shared Task. Our system is a graph-based parser with the
technique of Automated Concatenation of Embeddings (ACE). Because recent work
found that better word representations can be obtained by concatenating
different types of embeddings, we use ACE to automatically find the better
concatenation of embeddings for the task of enhanced universal dependencies.
According to official results averaged on 17 languages, our system ranks 2nd
over 9 teams.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaSpeech 3: Adaptive Text to Speech for Spontaneous Style. (arXiv:2107.02530v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yuzi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bohan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guangyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Sheng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei-Qiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02530">
                                    <div class="article-summary-box-inner">
                                        <span>While recent text to speech (TTS) models perform very well in synthesizing
reading-style (e.g., audiobook) speech, it is still challenging to synthesize
spontaneous-style speech (e.g., podcast or conversation), mainly because of two
reasons: 1) the lack of training data for spontaneous speech; 2) the difficulty
in modeling the filled pauses (um and uh) and diverse rhythms in spontaneous
speech. In this paper, we develop AdaSpeech 3, an adaptive TTS system that
fine-tunes a well-trained reading-style TTS model for spontaneous-style speech.
Specifically, 1) to insert filled pauses (FP) in the text sequence
appropriately, we introduce an FP predictor to the TTS model; 2) to model the
varying rhythms, we introduce a duration predictor based on mixture of experts
(MoE), which contains three experts responsible for the generation of fast,
medium and slow speech respectively, and fine-tune it as well as the pitch
predictor for rhythm adaptation; 3) to adapt to other speaker timbre, we
fine-tune some parameters in the decoder with few speech data. To address the
challenge of lack of training data, we mine a spontaneous speech dataset to
support our research this work and facilitate future research on spontaneous
TTS. Experiments show that AdaSpeech 3 synthesizes speech with natural FP and
rhythms in spontaneous styles, and achieves much better MOS and SMOS scores
than previous adaptive TTS systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Connectivity Matters: Neural Network Pruning Through the Lens of Effective Sparsity. (arXiv:2107.02306v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vysogorets_A/0/1/0/all/0/1">Artem Vysogorets</a>, <a href="http://arxiv.org/find/cs/1/au:+Kempe_J/0/1/0/all/0/1">Julia Kempe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02306">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network pruning is a fruitful area of research with surging interest
in high sparsity regimes. Benchmarking in this domain heavily relies on
faithful representation of the sparsity of subnetworks, which has been
traditionally computed as the fraction of removed connections (direct
sparsity). This definition, however, fails to recognize unpruned parameters
that detached from input or output layers of underlying subnetworks,
potentially underestimating actual effective sparsity: the fraction of
inactivated connections. While this effect might be negligible for moderately
pruned networks (up to 10-100 compression rates), we find that it plays an
increasing role for thinner subnetworks, greatly distorting comparison between
different pruning algorithms. For example, we show that effective compression
of a randomly pruned LeNet-300-100 can be orders of magnitude larger than its
direct counterpart, while no discrepancy is ever observed when using SynFlow
for pruning [Tanaka et al., 2020]. In this work, we adopt the lens of effective
sparsity to reevaluate several recent pruning algorithms on common benchmark
architectures (e.g., LeNet-300-100, VGG-19, ResNet-18) and discover that their
absolute and relative performance changes dramatically in this new and more
appropriate framework. To aim for effective, rather than direct, sparsity, we
develop a low-cost extension to most pruning algorithms. Further, equipped with
effective sparsity as a reference frame, we partially reconfirm that random
pruning with appropriate sparsity allocation across layers performs as well or
better than more sophisticated algorithms for pruning at initialization [Su et
al., 2020]. In response to this observation, using a simple analogy of pressure
distribution in coupled cylinders from physics, we design novel layerwise
sparsity quotas that outperform all existing baselines in the context of random
pruning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Evaluation of Machine Learning and Deep Learning Models for Drought Prediction using Weather Data. (arXiv:2107.02517v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weiwei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiayun Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02517">
                                    <div class="article-summary-box-inner">
                                        <span>Drought is a serious natural disaster that has a long duration and a wide
range of influence. To decrease the drought-caused losses, drought prediction
is the basis of making the corresponding drought prevention and disaster
reduction measures. While this problem has been studied in the literature, it
remains unknown whether drought can be precisely predicted or not with machine
learning models using weather data. To answer this question, a real-world
public dataset is leveraged in this study and different drought levels are
predicted using the last 90 days of 18 meteorological indicators as the
predictors. In a comprehensive approach, 16 machine learning models and 16 deep
learning models are evaluated and compared. The results show no single model
can achieve the best performance for all evaluation metrics simultaneously,
which indicates the drought prediction problem is still challenging. As
benchmarks for further studies, the code and results are publicly available in
a Github repository.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Equivariant bifurcation, quadratic equivariants, and symmetry breaking for the standard representation of $S_n$. (arXiv:2107.02422v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arjevani_Y/0/1/0/all/0/1">Yossi Arjevani</a>, <a href="http://arxiv.org/find/cs/1/au:+Field_M/0/1/0/all/0/1">Michael Field</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02422">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by questions originating from the study of a class of shallow
student-teacher neural networks, methods are developed for the analysis of
spurious minima in classes of gradient equivariant dynamics related to neural
nets. In the symmetric case, methods depend on the generic equivariant
bifurcation theory of irreducible representations of the symmetric group on $n$
symbols, $S_n$; in particular, the standard representation of $S_n$. It is
shown that spurious minima do not arise from spontaneous symmetry breaking but
rather through a complex deformation of the landscape geometry that can be
encoded by a generic $S_n$-equivariant bifurcation. We describe minimal models
for forced symmetry breaking that give a lower bound on the dynamic complexity
involved in the creation of spurious minima when there is no symmetry. Results
on generic bifurcation when there are quadratic equivariants are also proved;
this work extends and clarifies results of Ihrig &amp; Golubitsky and Chossat,
Lauterback &amp; Melbourne on the instability of solutions when there are quadratic
equivariants.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating subgroup disparity using epistemic uncertainty in mammography. (arXiv:2107.02716v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Charles Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lemay_A/0/1/0/all/0/1">Andreanne Lemay</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoebel_K/0/1/0/all/0/1">Katharina Hoebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalpathy_Cramer_J/0/1/0/all/0/1">Jayashree Kalpathy-Cramer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02716">
                                    <div class="article-summary-box-inner">
                                        <span>As machine learning (ML) continue to be integrated into healthcare systems
that affect clinical decision making, new strategies will need to be
incorporated in order to effectively detect and evaluate subgroup disparities
to ensure accountability and generalizability in clinical workflows. In this
paper, we explore how epistemic uncertainty can be used to evaluate disparity
in patient demographics (race) and data acquisition (scanner) subgroups for
breast density assessment on a dataset of 108,190 mammograms collected from 33
clinical sites. Our results show that even if aggregate performance is
comparable, the choice of uncertainty quantification metric can significantly
the subgroup level. We hope this analysis can promote further work on how
uncertainty can be leveraged to increase transparency of machine learning
applications for clinical deployment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weighted Gaussian Process Bandits for Non-stationary Environments. (arXiv:2107.02371v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yuntian Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xingyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Baekjin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1">Ambuj Tewari</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Abhishek Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Shroff_N/0/1/0/all/0/1">Ness Shroff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02371">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we consider the Gaussian process (GP) bandit optimization
problem in a non-stationary environment. To capture external changes, the
black-box function is allowed to be time-varying within a reproducing kernel
Hilbert space (RKHS). To this end, we develop WGP-UCB, a novel UCB-type
algorithm based on weighted Gaussian process regression. A key challenge is how
to cope with infinite-dimensional feature maps. To that end, we leverage kernel
approximation techniques to prove a sublinear regret bound, which is the first
(frequentist) sublinear regret guarantee on weighted time-varying bandits with
general nonlinear rewards. This result generalizes both non-stationary linear
bandits and standard GP-UCB algorithms. Further, a novel concentration
inequality is achieved for weighted Gaussian process regression with general
weights. We also provide universal upper bounds and weight-dependent upper
bounds for weighted maximum information gains. These results are potentially of
independent interest for applications such as news ranking and adaptive
pricing, where weights can be adopted to capture the importance or quality of
data. Finally, we conduct experiments to highlight the favorable gains of the
proposed algorithm in many cases when compared to existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially private federated deep learning for multi-site medical image segmentation. (arXiv:2107.02586v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ziller_A/0/1/0/all/0/1">Alexander Ziller</a>, <a href="http://arxiv.org/find/eess/1/au:+Usynin_D/0/1/0/all/0/1">Dmitrii Usynin</a>, <a href="http://arxiv.org/find/eess/1/au:+Remerscheid_N/0/1/0/all/0/1">Nicolas Remerscheid</a>, <a href="http://arxiv.org/find/eess/1/au:+Knolle_M/0/1/0/all/0/1">Moritz Knolle</a>, <a href="http://arxiv.org/find/eess/1/au:+Makowski_M/0/1/0/all/0/1">Marcus Makowski</a>, <a href="http://arxiv.org/find/eess/1/au:+Braren_R/0/1/0/all/0/1">Rickmer Braren</a>, <a href="http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Kaissis_G/0/1/0/all/0/1">Georgios Kaissis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02586">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative machine learning techniques such as federated learning (FL)
enable the training of models on effectively larger datasets without data
transfer. Recent initiatives have demonstrated that segmentation models trained
with FL can achieve performance similar to locally trained models. However, FL
is not a fully privacy-preserving technique and privacy-centred attacks can
disclose confidential patient data. Thus, supplementing FL with
privacy-enhancing technologies (PTs) such as differential privacy (DP) is a
requirement for clinical applications in a multi-institutional setting. The
application of PTs to FL in medical imaging and the trade-offs between privacy
guarantees and model utility, the ramifications on training performance and the
susceptibility of the final models to attacks have not yet been conclusively
investigated. Here we demonstrate the first application of differentially
private gradient descent-based FL on the task of semantic segmentation in
computed tomography. We find that high segmentation performance is possible
under strong privacy guarantees with an acceptable training time penalty. We
furthermore demonstrate the first successful gradient-based model inversion
attack on a semantic segmentation model and show that the application of DP
prevents it from divulging sensitive image features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Text-to-Image Synthesis Using Contrastive Learning. (arXiv:2107.02423v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hui Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiulong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Takac_M/0/1/0/all/0/1">Martin Takac</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunderraman_R/0/1/0/all/0/1">Rajshekhar Sunderraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shihao Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02423">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of text-to-image synthesis is to generate a visually realistic image
that matches a given text description. In practice, the captions annotated by
humans for the same image have large variance in terms of contents and the
choice of words. The linguistic discrepancy between the captions of the
identical image leads to the synthetic images deviating from the ground truth.
To address this issue, we propose a contrastive learning approach to improve
the quality and enhance the semantic consistency of synthetic images. In the
pre-training stage, we utilize the contrastive learning approach to learn the
consistent textual representations for the captions corresponding to the same
image. Furthermore, in the following stage of GAN training, we employ the
contrastive learning method to enhance the consistency between the generated
images from the captions related to the same image. We evaluate our approach
over two popular text-to-image synthesis models, AttnGAN and DM-GAN, on
datasets CUB and COCO, respectively. Experimental results have shown that our
approach can effectively improve the quality of synthetic images in terms of
three metrics: IS, FID and R-precision. Especially, on the challenging COCO
dataset, our approach boosts the FID significantly by 29.60% over AttnGAn and
by 21.96% over DM-GAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Level Graph Contrastive Learning. (arXiv:2107.02639v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_P/0/1/0/all/0/1">Pengpeng Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dawei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_J/0/1/0/all/0/1">Jianhua Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_F/0/1/0/all/0/1">Feihu Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guohua Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02639">
                                    <div class="article-summary-box-inner">
                                        <span>Graph representation learning has attracted a surge of interest recently,
whose target at learning discriminant embedding for each node in the graph.
Most of these representation methods focus on supervised learning and heavily
depend on label information. However, annotating graphs are expensive to obtain
in the real world, especially in specialized domains (i.e. biology), as it
needs the annotator to have the domain knowledge to label the graph. To
approach this problem, self-supervised learning provides a feasible solution
for graph representation learning. In this paper, we propose a Multi-Level
Graph Contrastive Learning (MLGCL) framework for learning robust representation
of graph data by contrasting space views of graphs. Specifically, we introduce
a novel contrastive view - topological and feature space views. The original
graph is first-order approximation structure and contains uncertainty or error,
while the $k$NN graph generated by encoding features preserves high-order
proximity. Thus $k$NN graph generated by encoding features not only provide a
complementary view, but is more suitable to GNN encoder to extract discriminant
representation. Furthermore, we develop a multi-level contrastive mode to
preserve the local similarity and semantic similarity of graph-structured data
simultaneously. Extensive experiments indicate MLGCL achieves promising results
compared with the existing state-of-the-art graph representation learning
methods on seven datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Reinforcement Learning for Heuristic Planning. (arXiv:2107.02603v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_R/0/1/0/all/0/1">Ricardo Luna Gutierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonetti_M/0/1/0/all/0/1">Matteo Leonetti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02603">
                                    <div class="article-summary-box-inner">
                                        <span>In Meta-Reinforcement Learning (meta-RL) an agent is trained on a set of
tasks to prepare for and learn faster in new, unseen, but related tasks. The
training tasks are usually hand-crafted to be representative of the expected
distribution of test tasks and hence all used in training. We show that given a
set of training tasks, learning can be both faster and more effective (leading
to better performance in the test tasks), if the training tasks are
appropriately selected. We propose a task selection algorithm,
Information-Theoretic Task Selection (ITTS), based on information theory, which
optimizes the set of tasks used for training in meta-RL, irrespectively of how
they are generated. The algorithm establishes which training tasks are both
sufficiently relevant for the test tasks, and different enough from one
another. We reproduce different meta-RL experiments from the literature and
show that ITTS improves the final performance in all of them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Histogram of Cell Types: Deep Learning for Automated Bone Marrow Cytology. (arXiv:2107.02293v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tayebi_R/0/1/0/all/0/1">Rohollah Moosavi Tayebi</a>, <a href="http://arxiv.org/find/eess/1/au:+Mu_Y/0/1/0/all/0/1">Youqing Mu</a>, <a href="http://arxiv.org/find/eess/1/au:+Dehkharghanian_T/0/1/0/all/0/1">Taher Dehkharghanian</a>, <a href="http://arxiv.org/find/eess/1/au:+Ross_C/0/1/0/all/0/1">Catherine Ross</a>, <a href="http://arxiv.org/find/eess/1/au:+Sur_M/0/1/0/all/0/1">Monalisa Sur</a>, <a href="http://arxiv.org/find/eess/1/au:+Foley_R/0/1/0/all/0/1">Ronan Foley</a>, <a href="http://arxiv.org/find/eess/1/au:+Tizhoosh_H/0/1/0/all/0/1">Hamid R. Tizhoosh</a>, <a href="http://arxiv.org/find/eess/1/au:+Campbell_C/0/1/0/all/0/1">Clinton JV Campbell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02293">
                                    <div class="article-summary-box-inner">
                                        <span>Bone marrow cytology is required to make a hematological diagnosis,
influencing critical clinical decision points in hematology. However, bone
marrow cytology is tedious, limited to experienced reference centers and
associated with high inter-observer variability. This may lead to a delayed or
incorrect diagnosis, leaving an unmet need for innovative supporting
technologies. We have developed the first ever end-to-end deep learning-based
technology for automated bone marrow cytology. Starting with a bone marrow
aspirate digital whole slide image, our technology rapidly and automatically
detects suitable regions for cytology, and subsequently identifies and
classifies all bone marrow cells in each region. This collective
cytomorphological information is captured in a novel representation called
Histogram of Cell Types (HCT) quantifying bone marrow cell class probability
distribution and acting as a cytological &quot;patient fingerprint&quot;. The approach
achieves high accuracy in region detection (0.97 accuracy and 0.99 ROC AUC),
and cell detection and cell classification (0.75 mAP, 0.78 F1-score,
Log-average miss rate of 0.31). HCT has potential to revolutionize
hematopathology diagnostic workflows, leading to more cost-effective, accurate
diagnosis and opening the door to precision medicine.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Remote sensing, AI and innovative prediction methods for adapting cities to the impacts of the climate change. (arXiv:2107.02693v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sirmacek_B/0/1/0/all/0/1">Beril Sirmacek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02693">
                                    <div class="article-summary-box-inner">
                                        <span>Urban areas are not only one of the biggest contributors to climate change,
but also they are one of the most vulnerable areas with high populations who
would together experience the negative impacts. In this paper, I address some
of the opportunities brought by satellite remote sensing imaging and artificial
intelligence (AI) in order to measure climate adaptation of cities
automatically. I propose an AI-based framework which might be useful for
extracting indicators from remote sensing images and might help with predictive
estimation of future states of these climate adaptation related indicators.
When such models become more robust and used in real-life applications, they
might help decision makers and early responders to choose the best actions to
sustain the wellbeing of society, natural resources and biodiversity. I
underline that this is an open field and an ongoing research for many
scientists, therefore I offer an in depth discussion on the challenges and
limitations of AI-based methods and the predictive estimation models in
general.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label noise in segmentation networks : mitigation must deal with bias. (arXiv:2107.02189v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vorontsov_E/0/1/0/all/0/1">Eugene Vorontsov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadoury_S/0/1/0/all/0/1">Samuel Kadoury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02189">
                                    <div class="article-summary-box-inner">
                                        <span>Imperfect labels limit the quality of predictions learned by deep neural
networks. This is particularly relevant in medical image segmentation, where
reference annotations are difficult to collect and vary significantly even
across expert annotators. Prior work on mitigating label noise focused on
simple models of mostly uniform noise. In this work, we explore biased and
unbiased errors artificially introduced to brain tumour annotations on MRI
data. We found that supervised and semi-supervised segmentation methods are
robust or fairly robust to unbiased errors but sensitive to biased errors. It
is therefore important to identify the sorts of errors expected in medical
image labels and especially mitigate the biased errors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometric convergence of elliptical slice sampling. (arXiv:2105.03308v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Natarovskii_V/0/1/0/all/0/1">Viacheslav Natarovskii</a>, <a href="http://arxiv.org/find/stat/1/au:+Rudolf_D/0/1/0/all/0/1">Daniel Rudolf</a>, <a href="http://arxiv.org/find/stat/1/au:+Sprungk_B/0/1/0/all/0/1">Bj&#xf6;rn Sprungk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03308">
                                    <div class="article-summary-box-inner">
                                        <span>For Bayesian learning, given likelihood function and Gaussian prior, the
elliptical slice sampler, introduced by Murray, Adams and MacKay 2010, provides
a tool for the construction of a Markov chain for approximate sampling of the
underlying posterior distribution. Besides of its wide applicability and
simplicity its main feature is that no tuning is necessary. Under weak
regularity assumptions on the posterior density we show that the corresponding
Markov chain is geometrically ergodic and therefore yield qualitative
convergence guarantees. We illustrate our result for Gaussian posteriors as
they appear in Gaussian process regression, as well as in a setting of a
multi-modal distribution. Remarkably, our numerical experiments indicate a
dimension-independent performance of elliptical slice sampling even in
situations where our ergodicity result does not apply.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Hypo-plastic Left Heart Syndrome in Fetal Ultrasound via Disease-specific Atlas Maps. (arXiv:2107.02643v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Budd_S/0/1/0/all/0/1">Samuel Budd</a>, <a href="http://arxiv.org/find/eess/1/au:+Sinclair_M/0/1/0/all/0/1">Matthew Sinclair</a>, <a href="http://arxiv.org/find/eess/1/au:+Day_T/0/1/0/all/0/1">Thomas Day</a>, <a href="http://arxiv.org/find/eess/1/au:+Vlontzos_A/0/1/0/all/0/1">Athanasios Vlontzos</a>, <a href="http://arxiv.org/find/eess/1/au:+Tan_J/0/1/0/all/0/1">Jeremy Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tianrui Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Matthew_J/0/1/0/all/0/1">Jaqueline Matthew</a>, <a href="http://arxiv.org/find/eess/1/au:+Skelton_E/0/1/0/all/0/1">Emily Skelton</a>, <a href="http://arxiv.org/find/eess/1/au:+Simpson_J/0/1/0/all/0/1">John Simpson</a>, <a href="http://arxiv.org/find/eess/1/au:+Razavi_R/0/1/0/all/0/1">Reza Razavi</a>, <a href="http://arxiv.org/find/eess/1/au:+Glocker_B/0/1/0/all/0/1">Ben Glocker</a>, <a href="http://arxiv.org/find/eess/1/au:+Rueckert_D/0/1/0/all/0/1">Daniel Rueckert</a>, <a href="http://arxiv.org/find/eess/1/au:+Robinson_E/0/1/0/all/0/1">Emma C. Robinson</a>, <a href="http://arxiv.org/find/eess/1/au:+Kainz_B/0/1/0/all/0/1">Bernhard Kainz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02643">
                                    <div class="article-summary-box-inner">
                                        <span>Fetal ultrasound screening during pregnancy plays a vital role in the early
detection of fetal malformations which have potential long-term health impacts.
The level of skill required to diagnose such malformations from live ultrasound
during examination is high and resources for screening are often limited. We
present an interpretable, atlas-learning segmentation method for automatic
diagnosis of Hypo-plastic Left Heart Syndrome (HLHS) from a single &#x60;4 Chamber
Heart&#x27; view image. We propose to extend the recently introduced
Image-and-Spatial Transformer Networks (Atlas-ISTN) into a framework that
enables sensitising atlas generation to disease. In this framework we can
jointly learn image segmentation, registration, atlas construction and disease
prediction while providing a maximum level of clinical interpretability
compared to direct image classification methods. As a result our segmentation
allows diagnoses competitive with expert-derived manual diagnosis and yields an
AUC-ROC of 0.978 (1043 cases for training, 260 for validation and 325 for
testing).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A new smart-cropping pipeline for prostate segmentation using deep learning networks. (arXiv:2107.02476v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zaridis_D/0/1/0/all/0/1">Dimitrios G. Zaridis</a>, <a href="http://arxiv.org/find/eess/1/au:+Mylona_E/0/1/0/all/0/1">Eugenia Mylona</a>, <a href="http://arxiv.org/find/eess/1/au:+Marias_K/0/1/0/all/0/1">Kostas Marias</a>, <a href="http://arxiv.org/find/eess/1/au:+Papanikolaou_N/0/1/0/all/0/1">Nikolaos Papanikolaou</a>, <a href="http://arxiv.org/find/eess/1/au:+Tachos_N/0/1/0/all/0/1">Nikolaos S. Tachos</a>, <a href="http://arxiv.org/find/eess/1/au:+Fotiadis_D/0/1/0/all/0/1">Dimitrios I. Fotiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02476">
                                    <div class="article-summary-box-inner">
                                        <span>Prostate segmentation from magnetic resonance imaging (MRI) is a challenging
task. In recent years, several network architectures have been proposed to
automate this process and alleviate the burden of manual annotation. Although
the performance of these models has achieved promising results, there is still
room for improvement before these models can be used safely and effectively in
clinical practice. One of the major challenges in prostate MR image
segmentation is the presence of class imbalance in the image labels where the
background pixels dominate over the prostate. In the present work we propose a
DL-based pipeline for cropping the region around the prostate from MRI images
to produce a more balanced distribution of the foreground pixels (prostate) and
the background pixels and improve segmentation accuracy. The effect of
DL-cropping for improving the segmentation performance compared to standard
center-cropping is assessed using five popular DL networks for prostate
segmentation, namely U-net, U-net+, Res Unet++, Bridge U-net and Dense U-net.
The proposed smart-cropping outperformed the standard center cropping in terms
of segmentation accuracy for all the evaluated prostate segmentation networks.
In terms of Dice score, the highest improvement was achieved for the U-net+ and
ResU-net++ architectures corresponding to 8.9% and 8%, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Critical Nodes in Temporal Networks by Dynamic Graph Convolutional Networks. (arXiv:2106.10419v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_E/0/1/0/all/0/1">En-Yu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jun-Lin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hong-Liang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Duan-Bing Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10419">
                                    <div class="article-summary-box-inner">
                                        <span>Many real-world systems can be expressed in temporal networks with nodes
playing far different roles in structure and function and edges representing
the relationships between nodes. Identifying critical nodes can help us control
the spread of public opinions or epidemics, predict leading figures in
academia, conduct advertisements for various commodities, and so on. However,
it is rather difficult to identify critical nodes because the network structure
changes over time in temporal networks. In this paper, considering the sequence
topological information of temporal networks, a novel and effective learning
framework based on the combination of special GCNs and RNNs is proposed to
identify nodes with the best spreading ability. The effectiveness of the
approach is evaluated by weighted Susceptible-Infected-Recovered model.
Experimental results on four real-world temporal networks demonstrate that the
proposed method outperforms both traditional and deep learning benchmark
methods in terms of the Kendall $\tau$ coefficient and top $k$ hit rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parametric Complexity Bounds for Approximating PDEs with Neural Networks. (arXiv:2103.02138v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marwah_T/0/1/0/all/0/1">Tanya Marwah</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1">Andrej Risteski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02138">
                                    <div class="article-summary-box-inner">
                                        <span>Recent experiments have shown that deep networks can approximate solutions to
high-dimensional PDEs, seemingly escaping the curse of dimensionality. However,
questions regarding the theoretical basis for such approximations, including
the required network size, remain open. In this paper, we investigate the
representational power of neural networks for approximating solutions to linear
elliptic PDEs with Dirichlet boundary conditions. We prove that when a PDE&#x27;s
coefficients are representable by small neural networks, the parameters
required to approximate its solution scale polynomially with the input
dimension $d$ and proportionally to the parameter counts of the coefficient
networks. To this we end, we develop a proof technique that simulates gradient
descent (in an appropriate Hilbert space) by growing a neural network
architecture whose iterates each participate as sub-networks in their (slightly
larger) successors, and converge to the solution of the PDE. We bound the size
of the solution, showing a polynomial dependence on $d$ and no dependence on
the volume of the domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning an Explicit Hyperparameter Prediction Policy Conditioned on Tasks. (arXiv:2107.02378v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_J/0/1/0/all/0/1">Jun Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1">Deyu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zongben Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02378">
                                    <div class="article-summary-box-inner">
                                        <span>Meta learning has attracted much attention recently in machine learning
community. Contrary to conventional machine learning aiming to learn inherent
prediction rules to predict labels for new query data, meta learning aims to
learn the learning methodology for machine learning from observed tasks, so as
to generalize to new query tasks by leveraging the meta-learned learning
methodology. In this study, we interpret such learning methodology as learning
an explicit hyperparameter prediction policy shared by all training tasks.
Specifically, this policy is represented as a parameterized function called
meta-learner, mapping from a training/test task to its suitable hyperparameter
setting, extracted from a pre-specified function set called meta learning
machine. Such setting guarantees that the meta-learned learning methodology is
able to flexibly fit diverse query tasks, instead of only obtaining fixed
hyperparameters by many current meta learning methods, with less adaptability
to query task&#x27;s variations. Such understanding of meta learning also makes it
easily succeed from traditional learning theory for analyzing its
generalization bounds with general losses/tasks/models. The theory naturally
leads to some feasible controlling strategies for ameliorating the quality of
the extracted meta-learner, verified to be able to finely ameliorate its
generalization capability in some typical meta learning applications, including
few-shot regression, few-shot classification and domain generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network. (arXiv:2107.02757v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_Z/0/1/0/all/0/1">Zhibin Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dongsheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chaojie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenchao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yewen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02757">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical topic models such as the gamma belief network (GBN) have
delivered promising results in mining multi-layer document representations and
discovering interpretable topic taxonomies. However, they often assume in the
prior that the topics at each layer are independently drawn from the Dirichlet
distribution, ignoring the dependencies between the topics both at the same
layer and across different layers. To relax this assumption, we propose
sawtooth factorial topic embedding guided GBN, a deep generative model of
documents that captures the dependencies and semantic similarities between the
topics in the embedding space. Specifically, both the words and topics are
represented as embedding vectors of the same dimension. The topic matrix at a
layer is factorized into the product of a factor loading matrix and a topic
embedding matrix, the transpose of which is set as the factor loading matrix of
the layer above. Repeating this particular type of factorization, which shares
components between adjacent layers, leads to a structure referred to as
sawtooth factorization. An auto-encoding variational inference network is
constructed to optimize the model parameter via stochastic gradient descent.
Experiments on big corpora show that our models outperform other neural topic
models on extracting deeper interpretable topics and deriving better document
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-Objective Approach for Sustainable Generative Audio Models. (arXiv:2107.02621v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Douwes_C/0/1/0/all/0/1">Constance Douwes</a>, <a href="http://arxiv.org/find/cs/1/au:+Esling_P/0/1/0/all/0/1">Philippe Esling</a>, <a href="http://arxiv.org/find/cs/1/au:+Briot_J/0/1/0/all/0/1">Jean-Pierre Briot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02621">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the deep learning community has largely focused on the
accuracy of deep generative models, resulting in impressive improvements in
several research fields. However, this scientific race for quality comes at a
tremendous computational cost, which incurs vast energy consumption and
greenhouse gas emissions. If the current exponential growth of computational
consumption persists, Artificial Intelligence (AI) will sadly become a
considerable contributor to global warming.

At the heart of this problem are the measures that we use as a scientific
community to evaluate our work. Currently, researchers in the field of AI judge
scientific works mostly based on the improvement in accuracy, log-likelihood,
reconstruction or opinion scores, all of which entirely obliterates the actual
computational cost of generative models.

In this paper, we introduce the idea of relying on a multi-objective measure
based on Pareto optimality, which simultaneously integrates the models
accuracy, as well as the environmental impact of their training. By applying
this measure on the current state-of-the-art in generative audio models, we
show that this measure drastically changes the perceived significance of the
results in the field, encouraging optimal training techniques and resource
allocation. We hope that this type of measure will be widely adopted, in order
to help the community to better evaluate the significance of their work, while
bringing computational cost -- and in fine carbon emissions -- in the spotlight
of AI research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effectiveness of MPC-friendly Softmax Replacement. (arXiv:2011.11202v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keller_M/0/1/0/all/0/1">Marcel Keller</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1">Ke Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11202">
                                    <div class="article-summary-box-inner">
                                        <span>Softmax is widely used in deep learning to map some representation to a
probability distribution. As it is based on exp/log functions that are
relatively expensive in multi-party computation, Mohassel and Zhang (2017)
proposed a simpler replacement based on ReLU to be used in secure computation.
However, we could not reproduce the accuracy they reported for training on
MNIST with three fully connected layers. Later works (e.g., Wagh et al., 2019
and 2021) used the softmax replacement not for computing the output probability
distribution but for approximating the gradient in back-propagation. In this
work, we analyze the two uses of the replacement and compare them to softmax,
both in terms of accuracy and cost in multi-party computation. We found that
the replacement only provides a significant speed-up for a one-layer network
while it always reduces accuracy, sometimes significantly. Thus we conclude
that its usefulness is limited and one should use the original softmax function
instead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Impact of On-Chip Interconnect on In-Memory Acceleration of Deep Neural Networks. (arXiv:2107.02358v1 [cs.AR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krishnan_G/0/1/0/all/0/1">Gokul Krishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mandal_S/0/1/0/all/0/1">Sumit K. Mandal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_C/0/1/0/all/0/1">Chaitali Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1">Jae-sun Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogras_U/0/1/0/all/0/1">Umit Y. Ogras</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yu Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02358">
                                    <div class="article-summary-box-inner">
                                        <span>With the widespread use of Deep Neural Networks (DNNs), machine learning
algorithms have evolved in two diverse directions -- one with ever-increasing
connection density for better accuracy and the other with more compact sizing
for energy efficiency. The increase in connection density increases on-chip
data movement, which makes efficient on-chip communication a critical function
of the DNN accelerator. The contribution of this work is threefold. First, we
illustrate that the point-to-point (P2P)-based interconnect is incapable of
handling a high volume of on-chip data movement for DNNs. Second, we evaluate
P2P and network-on-chip (NoC) interconnect (with a regular topology such as a
mesh) for SRAM- and ReRAM-based in-memory computing (IMC) architectures for a
range of DNNs. This analysis shows the necessity for the optimal interconnect
choice for an IMC DNN accelerator. Finally, we perform an experimental
evaluation for different DNNs to empirically obtain the performance of the IMC
architecture with both NoC-tree and NoC-mesh. We conclude that, at the tile
level, NoC-tree is appropriate for compact DNNs employed at the edge, and
NoC-mesh is necessary to accelerate DNNs with high connection density.
Furthermore, we propose a technique to determine the optimal choice of
interconnect for any given DNN. In this technique, we use analytical models of
NoC to evaluate end-to-end communication latency of any given DNN. We
demonstrate that the interconnect optimization in the IMC architecture results
in up to 6$\times$ improvement in energy-delay-area product for VGG-19
inference compared to the state-of-the-art ReRAM-based IMC architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Midwifery Learning and Forecasting: Predicting Content Demand with User-Generated Logs. (arXiv:2107.02480v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Guitart_A/0/1/0/all/0/1">Anna Guitart</a>, <a href="http://arxiv.org/find/stat/1/au:+Rio_A/0/1/0/all/0/1">Ana Fern&#xe1;ndez del R&#xed;o</a>, <a href="http://arxiv.org/find/stat/1/au:+Perianez_A/0/1/0/all/0/1">&#xc1;frica Peri&#xe1;&#xf1;ez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02480">
                                    <div class="article-summary-box-inner">
                                        <span>Every day, 800 women and 6,700 newborns die from complications related to
pregnancy or childbirth. A well-trained midwife can prevent most of these
maternal and newborn deaths. Data science models together with logs generated
by users of online learning applications for midwives can help to improve their
learning competencies. The goal is to use these rich behavioral data to push
digital learning towards personalized content and to provide an adaptive
learning journey. In this work, we evaluate various forecasting methods to
determine the interest of future users on the different kind of contents
available in the app, broken down by profession and region.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study of COVID-19 Infodemic. (arXiv:2106.11702v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Ye Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xingyi Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Scarton_C/0/1/0/all/0/1">Carolina Scarton</a>, <a href="http://arxiv.org/find/cs/1/au:+Aker_A/0/1/0/all/0/1">Ahmet Aker</a>, <a href="http://arxiv.org/find/cs/1/au:+Bontcheva_K/0/1/0/all/0/1">Kalina Bontcheva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11702">
                                    <div class="article-summary-box-inner">
                                        <span>The spreading COVID-19 misinformation over social media already draws the
attention of many researchers. According to Google Scholar, about 26000
COVID-19 related misinformation studies have been published to date. Most of
these studies focusing on 1) detect and/or 2) analysing the characteristics of
COVID-19 related misinformation. However, the study of the social behaviours
related to misinformation is often neglected. In this paper, we introduce a
fine-grained annotated misinformation tweets dataset including social
behaviours annotation (e.g. comment or question to the misinformation). The
dataset not only allows social behaviours analysis but also suitable for both
evidence-based or non-evidence-based misinformation classification task. In
addition, we introduce leave claim out validation in our experiments and
demonstrate the misinformation classification performance could be
significantly different when applying to real-world unseen misinformation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAP-RAM: A Charge-Domain In-Memory Computing 6T-SRAM for Accurate and Precision-Programmable CNN Inference. (arXiv:2107.02388v1 [cs.AR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhanghao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Q/0/1/0/all/0/1">Qing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Sheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kaiyuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02388">
                                    <div class="article-summary-box-inner">
                                        <span>A compact, accurate, and bitwidth-programmable in-memory computing (IMC)
static random-access memory (SRAM) macro, named CAP-RAM, is presented for
energy-efficient convolutional neural network (CNN) inference. It leverages a
novel charge-domain multiply-and-accumulate (MAC) mechanism and circuitry to
achieve superior linearity under process variations compared to conventional
IMC designs. The adopted semi-parallel architecture efficiently stores filters
from multiple CNN layers by sharing eight standard 6T SRAM cells with one
charge-domain MAC circuit. Moreover, up to six levels of bit-width of weights
with two encoding schemes and eight levels of input activations are supported.
A 7-bit charge-injection SAR (ciSAR) analog-to-digital converter (ADC) getting
rid of sample and hold (S&amp;H) and input/reference buffers further improves the
overall energy efficiency and throughput. A 65-nm prototype validates the
excellent linearity and computing accuracy of CAP-RAM. A single 512x128 macro
stores a complete pruned and quantized CNN model to achieve 98.8% inference
accuracy on the MNIST data set and 89.0% on the CIFAR-10 data set, with a
573.4-giga operations per second (GOPS) peak throughput and a 49.4-tera
operations per second (TOPS)/W energy efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Talk to Action with Accountability: Monitoring the Public Discussion of Policy Makers with Deep Neural Networks and Topic Modelling. (arXiv:2010.08346v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hatonen_V/0/1/0/all/0/1">Vili H&#xe4;t&#xf6;nen</a>, <a href="http://arxiv.org/find/cs/1/au:+Melzer_F/0/1/0/all/0/1">Fiona Melzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08346">
                                    <div class="article-summary-box-inner">
                                        <span>Decades of research on climate have provided a consensus that human activity
has changed the climate and we are currently heading into a climate crisis.
While public discussion and research efforts on climate change mitigation have
increased, potential solutions need to not only be discussed but also
effectively deployed. For preventing mismanagement and holding policy makers
accountable, transparency and degree of information about government processes
have been shown to be crucial. However, currently the quantity of information
about climate change discussions and the range of sources make it increasingly
difficult for the public and civil society to maintain an overview to hold
politicians accountable.

In response, we propose a multi-source topic aggregation system (MuSTAS)
which processes policy makers speech and rhetoric from several publicly
available sources into an easily digestible topic summary. MuSTAS uses novel
multi-source hybrid latent Dirichlet allocation to model topics from a variety
of documents. This topic digest will serve the general public and civil society
in assessing where, how, and when politicians talk about climate and climate
policies, enabling them to hold politicians accountable for their actions to
mitigate climate change and lack thereof.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiating through the Fr\&#x27;echet Mean. (arXiv:2003.00335v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lou_A/0/1/0/all/0/1">Aaron Lou</a>, <a href="http://arxiv.org/find/stat/1/au:+Katsman_I/0/1/0/all/0/1">Isay Katsman</a>, <a href="http://arxiv.org/find/stat/1/au:+Jiang_Q/0/1/0/all/0/1">Qingxuan Jiang</a>, <a href="http://arxiv.org/find/stat/1/au:+Belongie_S/0/1/0/all/0/1">Serge Belongie</a>, <a href="http://arxiv.org/find/stat/1/au:+Lim_S/0/1/0/all/0/1">Ser-Nam Lim</a>, <a href="http://arxiv.org/find/stat/1/au:+Sa_C/0/1/0/all/0/1">Christopher De Sa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.00335">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep representation learning on Riemannian manifolds
extend classical deep learning operations to better capture the geometry of the
manifold. One possible extension is the Fr\&#x27;echet mean, the generalization of
the Euclidean mean; however, it has been difficult to apply because it lacks a
closed form with an easily computable derivative. In this paper, we show how to
differentiate through the Fr\&#x27;echet mean for arbitrary Riemannian manifolds.
Then, focusing on hyperbolic space, we derive explicit gradient expressions and
a fast, accurate, and hyperparameter-free Fr\&#x27;echet mean solver. This fully
integrates the Fr\&#x27;echet mean into the hyperbolic neural network pipeline. To
demonstrate this integration, we present two case studies. First, we apply our
Fr\&#x27;echet mean to the existing Hyperbolic Graph Convolutional Network,
replacing its projected aggregation to obtain state-of-the-art results on
datasets with high hyperbolicity. Second, to demonstrate the Fr\&#x27;echet mean&#x27;s
capacity to generalize Euclidean neural network operations, we develop a
hyperbolic batch normalization method that gives an improvement parallel to the
one observed in the Euclidean setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large Scale Model Predictive Control with Neural Networks and Primal Active Sets. (arXiv:1910.10835v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Steven W. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Atanasov_N/0/1/0/all/0/1">Nikolay Atanasov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vijay Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Morari_M/0/1/0/all/0/1">Manfred Morari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.10835">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents an explicit-implicit procedure to compute a model
predictive control (MPC) law with guarantees on recursive feasibility and
asymptotic stability. The approach combines an offline-trained fully-connected
neural network with an online primal active set solver. The neural network
provides a control input initialization while the primal active set method
ensures recursive feasibility and asymptotic stability. The neural network is
trained with a primal-dual loss function, aiming to generate control sequences
that are primal feasible and meet a desired level of suboptimality. Since the
neural network alone does not guarantee constraint satisfaction, its output is
used to warm start the primal active set method online. We demonstrate that
this approach scales to large problems with thousands of optimization
variables, which are challenging for current approaches. Our method achieves a
2x reduction in online inference time compared to the best method in a
benchmark suite of different solver and initialization strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provable Lipschitz Certification for Generative Models. (arXiv:2107.02732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Matt Jordan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1">Alexandros G. Dimakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02732">
                                    <div class="article-summary-box-inner">
                                        <span>We present a scalable technique for upper bounding the Lipschitz constant of
generative models. We relate this quantity to the maximal norm over the set of
attainable vector-Jacobian products of a given generative model. We approximate
this set by layerwise convex approximations using zonotopes. Our approach
generalizes and improves upon prior work using zonotope transformers and we
extend to Lipschitz estimation of neural networks with large output dimension.
This provides efficient and tight bounds on small networks and can scale to
generative models on VAE and DCGAN architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Inverse QSAR Method Based on Linear Regression and Integer Programming. (arXiv:2107.02381v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jianshen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Azam_N/0/1/0/all/0/1">Naveed Ahmed Azam</a>, <a href="http://arxiv.org/find/cs/1/au:+Haraguchi_K/0/1/0/all/0/1">Kazuya Haraguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagamochi_H/0/1/0/all/0/1">Hiroshi Nagamochi</a>, <a href="http://arxiv.org/find/cs/1/au:+Akutsu_T/0/1/0/all/0/1">Tatsuya Akutsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02381">
                                    <div class="article-summary-box-inner">
                                        <span>Recently a novel framework has been proposed for designing the molecular
structure of chemical compounds using both artificial neural networks (ANNs)
and mixed integer linear programming (MILP). In the framework, we first define
a feature vector $f(C)$ of a chemical graph $C$ and construct an ANN that maps
$x&#x3D;f(C)$ to a predicted value $\eta(x)$ of a chemical property $\pi$ to $C$.
After this, we formulate an MILP that simulates the computation process of
$f(C)$ from $C$ and that of $\eta(x)$ from $x$. Given a target value $y^*$ of
the chemical property $\pi$, we infer a chemical graph $C^\dagger$ such that
$\eta(f(C^\dagger))&#x3D;y^*$ by solving the MILP. In this paper, we use linear
regression to construct a prediction function $\eta$ instead of ANNs. For this,
we derive an MILP formulation that simulates the computation process of a
prediction function by linear regression. The results of computational
experiments suggest our method can infer chemical graphs with around up to 50
non-hydrogen atoms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A visual introduction to Gaussian Belief Propagation. (arXiv:2107.02308v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ortiz_J/0/1/0/all/0/1">Joseph Ortiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Evans_T/0/1/0/all/0/1">Talfan Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Davison_A/0/1/0/all/0/1">Andrew J. Davison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02308">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we present a visual introduction to Gaussian Belief
Propagation (GBP), an approximate probabilistic inference algorithm that
operates by passing messages between the nodes of arbitrarily structured factor
graphs. A special case of loopy belief propagation, GBP updates rely only on
local information and will converge independently of the message schedule. Our
key argument is that, given recent trends in computing hardware, GBP has the
right computational properties to act as a scalable distributed probabilistic
inference framework for future machine learning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intrinsic uncertainties and where to find them. (arXiv:2107.02526v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Farina_F/0/1/0/all/0/1">Francesco Farina</a>, <a href="http://arxiv.org/find/cs/1/au:+Phillips_L/0/1/0/all/0/1">Lawrence Phillips</a>, <a href="http://arxiv.org/find/cs/1/au:+Richmond_N/0/1/0/all/0/1">Nicola J Richmond</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02526">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a framework for uncertainty estimation that both describes and
extends many existing methods. We consider typical hyperparameters involved in
classical training as random variables and marginalise them out to capture
various sources of uncertainty in the parameter space. We investigate which
forms and combinations of marginalisation are most useful from a practical
point of view on standard benchmarking data sets. Moreover, we discuss how some
marginalisations may produce reliable estimates of uncertainty without the need
for extensive hyperparameter tuning and/or large-scale ensembling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Positional Encoding. (arXiv:2107.02561v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jianqiao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramasinghe_S/0/1/0/all/0/1">Sameera Ramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucey_S/0/1/0/all/0/1">Simon Lucey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02561">
                                    <div class="article-summary-box-inner">
                                        <span>It is well noted that coordinate based MLPs benefit greatly -- in terms of
preserving high-frequency information -- through the encoding of coordinate
positions as an array of Fourier features. Hitherto, the rationale for the
effectiveness of these positional encodings has been solely studied through a
Fourier lens. In this paper, we strive to broaden this understanding by showing
that alternative non-Fourier embedding functions can indeed be used for
positional encoding. Moreover, we show that their performance is entirely
determined by a trade-off between the stable rank of the embedded matrix and
the distance preservation between embedded coordinates. We further establish
that the now ubiquitous Fourier feature mapping of position is a special case
that fulfills these conditions. Consequently, we present a more general theory
to analyze positional encoding in terms of shifted basis functions. To this
end, we develop the necessary theoretical formulae and empirically verify that
our theoretical claims hold in practice. Codes available at
https://github.com/osiriszjq/Rethinking-positional-encoding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3$\times$ as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results~(e.g., Top-1 accuracy 84.1% trained on 224$\times$224
ImageNet-1K only), while being more scalable on high-resolution images. The
models and source code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering Structure of Microstructure Measures. (arXiv:2107.02283v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Zhu_L/0/1/0/all/0/1">Liao Zhu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Sun_N/0/1/0/all/0/1">Ningning Sun</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wells_M/0/1/0/all/0/1">Martin T. Wells</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02283">
                                    <div class="article-summary-box-inner">
                                        <span>This paper builds the clustering model of measures of market microstructure
features which are popular in predicting the stock returns. In a 10-second time
frequency, we study the clustering structure of different measures to find out
the best ones for predicting. In this way, we can predict more accurately with
a limited number of predictors, which removes the noise and makes the model
more interpretable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shell Language Processing: Unix command parsing for Machine Learning. (arXiv:2107.02438v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trizna_D/0/1/0/all/0/1">Dmitrijs Trizna</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02438">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we present a Shell Language Preprocessing (SLP) library,
which implements tokenization and encoding directed on the parsing of Unix and
Linux shell commands. We describe the rationale behind the need for a new
approach with specific examples when conventional Natural Language Processing
(NLP) pipelines fail. Furthermore, we evaluate our methodology on a security
classification task against widely accepted information and communications
technology (ICT) tokenization techniques and achieve significant improvement of
an F1-score from 0.392 to 0.874.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Garbage In, Garbage Out&quot; Revisited: What Do Machine Learning Application Papers Report About Human-Labeled Training Data?. (arXiv:2107.02278v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiger_R/0/1/0/all/0/1">R. Stuart Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Cope_D/0/1/0/all/0/1">Dominique Cope</a>, <a href="http://arxiv.org/find/cs/1/au:+Ip_J/0/1/0/all/0/1">Jamie Ip</a>, <a href="http://arxiv.org/find/cs/1/au:+Lotosh_M/0/1/0/all/0/1">Marsha Lotosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1">Aayush Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_J/0/1/0/all/0/1">Jenny Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1">Rebekah Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02278">
                                    <div class="article-summary-box-inner">
                                        <span>Supervised machine learning, in which models are automatically derived from
labeled training data, is only as good as the quality of that data. This study
builds on prior work that investigated to what extent &#x27;best practices&#x27; around
labeling training data were followed in applied ML publications within a single
domain (social media platforms). In this paper, we expand by studying
publications that apply supervised ML in a far broader spectrum of disciplines,
focusing on human-labeled data. We report to what extent a random sample of ML
application papers across disciplines give specific details about whether best
practices were followed, while acknowledging that a greater range of
application fields necessarily produces greater diversity of labeling and
annotation methods. Because much of machine learning research and education
only focuses on what is done once a &quot;ground truth&quot; or &quot;gold standard&quot; of
training data is available, it is especially relevant to discuss issues around
the equally-important aspect of whether such data is reliable in the first
place. This determination becomes increasingly complex when applied to a
variety of specialized fields, as labeling can range from a task requiring
little-to-no background knowledge to one that must be performed by someone with
career expertise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Agents that Listen: High-Throughput Reinforcement Learning with Multiple Sensory Systems. (arXiv:2107.02195v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hegde_S/0/1/0/all/0/1">Shashank Hegde</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanervisto_A/0/1/0/all/0/1">Anssi Kanervisto</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrenko_A/0/1/0/all/0/1">Aleksei Petrenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02195">
                                    <div class="article-summary-box-inner">
                                        <span>Humans and other intelligent animals evolved highly sophisticated perception
systems that combine multiple sensory modalities. On the other hand,
state-of-the-art artificial agents rely mostly on visual inputs or structured
low-dimensional observations provided by instrumented environments. Learning to
act based on combined visual and auditory inputs is still a new topic of
research that has not been explored beyond simple scenarios. To facilitate
progress in this area we introduce a new version of VizDoom simulator to create
a highly efficient learning environment that provides raw audio observations.
We study the performance of different model architectures in a series of tasks
that require the agent to recognize sounds and execute instructions given in
natural language. Finally, we train our agent to play the full game of Doom and
find that it can consistently defeat a traditional vision-based adversary. We
are currently in the process of merging the augmented simulator with the main
ViZDoom code repository. Video demonstrations and experiment code can be found
at https://sites.google.com/view/sound-rl.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangled Attention as Intrinsic Regularization for Bimanual Multi-Object Manipulation. (arXiv:2106.05907v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jian_P/0/1/0/all/0/1">Pingcheng Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Huazhe Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05907">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of solving complex bimanual robot manipulation tasks
on multiple objects with sparse rewards. Such complex tasks can be decomposed
into sub-tasks that are accomplishable by different robots concurrently or
sequentially for better efficiency. While previous reinforcement learning
approaches primarily focus on modeling the compositionality of sub-tasks, two
fundamental issues are largely ignored particularly when learning cooperative
strategies for two robots: (i) domination, i.e., one robot may try to solve a
task by itself and leaves the other idle; (ii) conflict, i.e., one robot can
easily interrupt another&#x27;s workspace when executing different sub-tasks
simultaneously. To tackle these two issues, we propose a novel technique called
disentangled attention, which provides an intrinsic regularization for two
robots to focus on separate sub-tasks and objects. We evaluate our method on
four bimanual manipulation tasks. Experimental results show that our proposed
intrinsic regularization successfully avoids domination and reduces conflicts
for the policies, which leads to significantly more effective cooperative
strategies than all the baselines. Our project page with videos is at
https://mehooz.github.io/bimanual-attention.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">New Benchmarks for Learning on Non-Homophilous Graphs. (arXiv:2104.01404v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lim_D/0/1/0/all/0/1">Derek Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiuyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hohne_F/0/1/0/all/0/1">Felix Hohne</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Ser-Nam Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01404">
                                    <div class="article-summary-box-inner">
                                        <span>Much data with graph structures satisfy the principle of homophily, meaning
that connected nodes tend to be similar with respect to a specific attribute.
As such, ubiquitous datasets for graph machine learning tasks have generally
been highly homophilous, rewarding methods that leverage homophily as an
inductive bias. Recent work has pointed out this particular focus, as new
non-homophilous datasets have been introduced and graph representation learning
models better suited for low-homophily settings have been developed. However,
these datasets are small and poorly suited to truly testing the effectiveness
of new methods in non-homophilous settings. We present a series of improved
graph datasets with node label relationships that do not satisfy the homophily
principle. Along with this, we introduce a new measure of the presence or
absence of homophily that is better suited than existing measures in different
regimes. We benchmark a range of simple methods and graph neural networks
across our proposed datasets, drawing new insights for further research. Data
and codes can be found at https://github.com/CUAI/Non-Homophily-Benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">InfoNCE is a variational autoencoder. (arXiv:2107.02495v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Aitchison_L/0/1/0/all/0/1">Laurence Aitchison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02495">
                                    <div class="article-summary-box-inner">
                                        <span>We show that a popular self-supervised learning method, InfoNCE, is a special
case of a new family of unsupervised learning methods, the self-supervised
variational autoencoder (SSVAE). SSVAEs circumvent the usual VAE requirement to
reconstruct the data by using a carefully chosen implicit decoder. The InfoNCE
objective was motivated as a simplified parametric mutual information
estimator. Under one choice of prior, the SSVAE objective (i.e. the ELBO) is
exactly equal to the mutual information (up to constants). Under an alternative
choice of prior, the SSVAE objective is exactly equal to the simplified
parametric mutual information estimator used in InfoNCE (up to constants).
Importantly, the use of simplified parametric mutual information estimators is
believed to be critical to obtain good high-level representations, and the
SSVAE framework naturally provides a principled justification for using prior
information to choose these estimators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learned Visual Navigation for Under-Canopy Agricultural Robots. (arXiv:2107.02792v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sivakumar_A/0/1/0/all/0/1">Arun Narenthiran Sivakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Modi_S/0/1/0/all/0/1">Sahil Modi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasparino_M/0/1/0/all/0/1">Mateus Valverde Gasparino</a>, <a href="http://arxiv.org/find/cs/1/au:+Ellis_C/0/1/0/all/0/1">Che Ellis</a>, <a href="http://arxiv.org/find/cs/1/au:+Velasquez_A/0/1/0/all/0/1">Andres Eduardo Baquero Velasquez</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhary_G/0/1/0/all/0/1">Girish Chowdhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Saurabh Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02792">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a system for visually guided autonomous navigation of
under-canopy farm robots. Low-cost under-canopy robots can drive between crop
rows under the plant canopy and accomplish tasks that are infeasible for
over-the-canopy drones or larger agricultural equipment. However, autonomously
navigating them under the canopy presents a number of challenges: unreliable
GPS and LiDAR, high cost of sensing, challenging farm terrain, clutter due to
leaves and weeds, and large variability in appearance over the season and
across crop types. We address these challenges by building a modular system
that leverages machine learning for robust and generalizable perception from
monocular RGB images from low-cost cameras, and model predictive control for
accurate control in challenging terrain. Our system, CropFollow, is able to
autonomously drive 485 meters per intervention on average, outperforming a
state-of-the-art LiDAR based system (286 meters per intervention) in extensive
field testing spanning over 25 km.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision Xformers: Efficient Attention for Image Classification. (arXiv:2107.02239v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeevan_P/0/1/0/all/0/1">Pranav Jeevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethi_A/0/1/0/all/0/1">Amit Sethi</a> (Indian Institute of Technology Bombay)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02239">
                                    <div class="article-summary-box-inner">
                                        <span>Linear attention mechanisms provide hope for overcoming the bottleneck of
quadratic complexity which restricts application of transformer models in
vision tasks. We modify the ViT architecture to work on longer sequence data by
replacing the quadratic attention with efficient transformers like Performer,
Linformer and Nystr\&quot;omformer of linear complexity creating Vision X-formers
(ViX). We show that ViX performs better than ViT in image classification
consuming lesser computing resources. We further show that replacing the
embedding linear layer by convolutional layers in ViX further increases their
performance. Our test on recent visions transformer models like LeViT and
Compact Convolutional Transformer (CCT) show that replacing the attention with
Nystr\&quot;omformer or Performer saves GPU usage and memory without deteriorating
performance. Incorporating these changes can democratize transformers by making
them accessible to those with limited data and computing resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ETHOS: an Online Hate Speech Detection Dataset. (arXiv:2006.08328v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mollas_I/0/1/0/all/0/1">Ioannis Mollas</a>, <a href="http://arxiv.org/find/cs/1/au:+Chrysopoulou_Z/0/1/0/all/0/1">Zoe Chrysopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlos_S/0/1/0/all/0/1">Stamatis Karlos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1">Grigorios Tsoumakas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08328">
                                    <div class="article-summary-box-inner">
                                        <span>Online hate speech is a recent problem in our society that is rising at a
steady pace by leveraging the vulnerabilities of the corresponding regimes that
characterise most social media platforms. This phenomenon is primarily fostered
by offensive comments, either during user interaction or in the form of a
posted multimedia context. Nowadays, giant corporations own platforms where
millions of users log in every day, and protection from exposure to similar
phenomena appears to be necessary in order to comply with the corresponding
legislation and maintain a high level of service quality. A robust and reliable
system for detecting and preventing the uploading of relevant content will have
a significant impact on our digitally interconnected society. Several aspects
of our daily lives are undeniably linked to our social profiles, making us
vulnerable to abusive behaviours. As a result, the lack of accurate hate speech
detection mechanisms would severely degrade the overall user experience,
although its erroneous operation would pose many ethical concerns. In this
paper, we present &#x27;ETHOS&#x27;, a textual dataset with two variants: binary and
multi-label, based on YouTube and Reddit comments validated using the
Figure-Eight crowdsourcing platform. Furthermore, we present the annotation
protocol used to create this dataset: an active sampling procedure for
balancing our data in relation to the various aspects defined. Our key
assumption is that, even gaining a small amount of labelled data from such a
time-consuming process, we can guarantee hate speech occurrences in the
examined material.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization by design: Shortcuts to Generalization in Deep Learning. (arXiv:2107.02253v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taborsky_P/0/1/0/all/0/1">Petr Taborsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansen_L/0/1/0/all/0/1">Lars Kai Hansen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02253">
                                    <div class="article-summary-box-inner">
                                        <span>We take a geometrical viewpoint and present a unifying view on supervised
deep learning with the Bregman divergence loss function - this entails frequent
classification and prediction tasks. Motivated by simulations we suggest that
there is principally no implicit bias of vanilla stochastic gradient descent
training of deep models towards &quot;simpler&quot; functions. Instead, we show that good
generalization may be instigated by bounded spectral products over layers
leading to a novel geometric regularizer. It is revealed that in deep enough
models such a regularizer enables both, extreme accuracy and generalization, to
be reached. We associate popular regularization techniques like weight decay,
drop out, batch normalization, and early stopping with this perspective. Backed
up by theory we further demonstrate that &quot;generalization by design&quot; is
practically possible and that good generalization may be encoded into the
structure of the network. We design two such easy-to-use structural
regularizers that insert an additional \textit{generalization layer} into a
model architecture, one with a skip connection and another one with drop-out.
We verify our theoretical results in experiments on various feedforward and
convolutional architectures, including ResNets, and datasets (MNIST, CIFAR10,
synthetic data). We believe this work opens up new avenues of research towards
better generalizing architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAGE: Intrusion Alert-driven Attack Graph Extractor. (arXiv:2107.02783v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nadeem_A/0/1/0/all/0/1">Azqa Nadeem</a>, <a href="http://arxiv.org/find/cs/1/au:+Verwer_S/0/1/0/all/0/1">Sicco Verwer</a>, <a href="http://arxiv.org/find/cs/1/au:+Moskal_S/0/1/0/all/0/1">Stephen Moskal</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shanchieh Jay Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02783">
                                    <div class="article-summary-box-inner">
                                        <span>Attack graphs (AG) are used to assess pathways availed by cyber adversaries
to penetrate a network. State-of-the-art approaches for AG generation focus
mostly on deriving dependencies between system vulnerabilities based on network
scans and expert knowledge. In real-world operations however, it is costly and
ineffective to rely on constant vulnerability scanning and expert-crafted AGs.
We propose to automatically learn AGs based on actions observed through
intrusion alerts, without prior expert knowledge. Specifically, we develop an
unsupervised sequence learning system, SAGE, that leverages the temporal and
probabilistic dependence between alerts in a suffix-based probabilistic
deterministic finite automaton (S-PDFA) -- a model that accentuates infrequent
severe alerts and summarizes paths leading to them. AGs are then derived from
the S-PDFA. Tested with intrusion alerts collected through Collegiate
Penetration Testing Competition, SAGE produces AGs that reflect the strategies
used by participating teams. The resulting AGs are succinct, interpretable, and
enable analysts to derive actionable insights, e.g., attackers tend to follow
shorter paths after they have discovered a longer one.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">General Purpose (GenP) Bioimage Ensemble of Handcrafted and Learned Features with Data Augmentation. (arXiv:1904.08084v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nanni_L/0/1/0/all/0/1">L. Nanni</a>, <a href="http://arxiv.org/find/cs/1/au:+Brahnam_S/0/1/0/all/0/1">S. Brahnam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghidoni_S/0/1/0/all/0/1">S. Ghidoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Maguolo_G/0/1/0/all/0/1">G. Maguolo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.08084">
                                    <div class="article-summary-box-inner">
                                        <span>Bioimage classification plays a crucial role in many biological problems. In
this work, we present a new General Purpose (GenP) ensemble that boosts
performance by combining local features, dense sampling features, and deep
learning approaches. First, we introduce three new methods for data
augmentation based on PCA/DCT; second, we show that different data augmentation
approaches can boost the performance of an ensemble of CNNs; and, finally, we
propose a set of handcrafted/learned descriptors that are highly generalizable.
Each handcrafted descriptor is used to train a different Support Vector Machine
(SVM), and the different SVMs are combined with the ensemble of CNNs. Our
method is evaluated on a diverse set of bioimage classification problems.
Results demonstrate that the proposed GenP bioimage ensemble obtains
state-of-the-art performance without any ad-hoc dataset tuning of parameters
(thus avoiding the risk of overfitting/overtraining).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dueling Bandits with Team Comparisons. (arXiv:2107.02738v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cohen_L/0/1/0/all/0/1">Lee Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_Kraepelin_U/0/1/0/all/0/1">Ulrike Schmidt-Kraepelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02738">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the dueling teams problem, a new online-learning setting in
which the learner observes noisy comparisons of disjoint pairs of $k$-sized
teams from a universe of $n$ players. The goal of the learner is to minimize
the number of duels required to identify, with high probability, a Condorcet
winning team, i.e., a team which wins against any other disjoint team (with
probability at least $1/2$). Noisy comparisons are linked to a total order on
the teams. We formalize our model by building upon the dueling bandits setting
(Yue et al.2012) and provide several algorithms, both for stochastic and
deterministic settings. For the stochastic setting, we provide a reduction to
the classical dueling bandits setting, yielding an algorithm that identifies a
Condorcet winning team within $\mathcal{O}((n + k \log (k)) \frac{\max(\log\log
n, \log k)}{\Delta^2})$ duels, where $\Delta$ is a gap parameter. For
deterministic feedback, we additionally present a gap-independent algorithm
that identifies a Condorcet winning team within $\mathcal{O}(nk\log(k)+k^5)$
duels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning. (arXiv:2107.02794v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nye_M/0/1/0/all/0/1">Maxwell Nye</a>, <a href="http://arxiv.org/find/cs/1/au:+Tessler_M/0/1/0/all/0/1">Michael Henry Tessler</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1">Brenden M. Lake</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02794">
                                    <div class="article-summary-box-inner">
                                        <span>Human reasoning can often be understood as an interplay between two systems:
the intuitive and associative (&quot;System 1&quot;) and the deliberative and logical
(&quot;System 2&quot;). Neural sequence models -- which have been increasingly successful
at performing complex, structured tasks -- exhibit the advantages and failure
modes of System 1: they are fast and learn patterns from data, but are often
inconsistent and incoherent. In this work, we seek a lightweight, training-free
means of improving existing System 1-like sequence models by adding System
2-inspired logical reasoning. We explore several variations on this theme in
which candidate generations from a neural sequence model are examined for
logical consistency by a symbolic reasoning module, which can either accept or
reject the generations. Our approach uses neural inference to mediate between
the neural System 1 and the logical System 2. Results in robust story
generation and grounded instruction-following show that this approach can
increase the coherence and accuracy of neurally-based generations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Ensemble Noise-Robust K-fold Cross-Validation Selection Method for Noisy Labels. (arXiv:2107.02347v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yong Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalander_M/0/1/0/all/0/1">Marcus Kalander</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chanfei Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1">Lujia Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02347">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of training robust and accurate deep neural networks
(DNNs) when subject to various proportions of noisy labels. Large-scale
datasets tend to contain mislabeled samples that can be memorized by DNNs,
impeding the performance. With appropriate handling, this degradation can be
alleviated. There are two problems to consider: how to distinguish clean
samples and how to deal with noisy samples. In this paper, we present Ensemble
Noise-robust K-fold Cross-Validation Selection (E-NKCVS) to effectively select
clean samples from noisy data, solving the first problem. For the second
problem, we create a new pseudo label for any sample determined to have an
uncertain or likely corrupt label. E-NKCVS obtains multiple predicted labels
for each sample and the entropy of these labels is used to tune the weight
given to the pseudo label and the given label. Theoretical analysis and
extensive verification of the algorithms in the noisy label setting are
provided. We evaluate our approach on various image and text classification
tasks where the labels have been manually corrupted with different noise
ratios. Additionally, two large real-world noisy datasets are also used,
Clothing-1M and WebVision. E-NKCVS is empirically shown to be highly tolerant
to considerable proportions of label noise and has a consistent improvement
over state-of-the-art methods. Especially on more difficult datasets with
higher noise ratios, we can achieve a significant improvement over the
second-best model. Moreover, our proposed approach can easily be integrated
into existing DNN methods to improve their robustness against label noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-training with noisy student model and semi-supervised loss function for dcase 2021 challenge task 4. (arXiv:2107.02569v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1">Nam Kyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hong Kook Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02569">
                                    <div class="article-summary-box-inner">
                                        <span>This report proposes a polyphonic sound event detection (SED) method for the
DCASE 2021 Challenge Task 4. The proposed SED model consists of two stages: a
mean-teacher model for providing target labels regarding weakly labeled or
unlabeled data and a self-training-based noisy student model for predicting
strong labels for sound events. The mean-teacher model, which is based on the
residual convolutional recurrent neural network (RCRNN) for the teacher and
student model, is first trained using all the training data from a weakly
labeled dataset, an unlabeled dataset, and a strongly labeled synthetic
dataset. Then, the trained mean-teacher model predicts the strong label to each
of the weakly labeled and unlabeled datasets, which is brought to the noisy
student model in the second stage of the proposed SED model. Here, the
structure of the noisy student model is identical to the RCRNN-based student
model of the mean-teacher model in the first stage. Then, it is self-trained by
adding feature noises, such as time-frequency shift, mixup, SpecAugment, and
dropout-based model noise. In addition, a semi-supervised loss function is
applied to train the noisy student model, which acts as label noise injection.
The performance of the proposed SED model is evaluated on the validation set of
the DCASE 2021 Challenge Task 4, and then, several ensemble models that combine
five-fold validation models with different hyperparameters of the
semi-supervised loss function are finally selected as our final models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enabling Un-/Semi-Supervised Machine Learning for MDSE of the Real-World CPS/IoT Applications. (arXiv:2107.02690v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moin_A/0/1/0/all/0/1">Armin Moin</a>, <a href="http://arxiv.org/find/cs/1/au:+Badii_A/0/1/0/all/0/1">Atta Badii</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1">Stephan G&#xfc;nnemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02690">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel approach to support domain-specific
Model-Driven Software Engineering (MDSE) for the real-world use-case scenarios
of smart Cyber-Physical Systems (CPS) and the Internet of Things (IoT). We
argue that the majority of available data in the nature for Artificial
Intelligence (AI), specifically Machine Learning (ML) are unlabeled. Hence,
unsupervised and/or semi-supervised ML approaches are the practical choices.
However, prior work in the literature of MDSE has considered supervised ML
approaches, which only work with labeled training data. Our proposed approach
is fully implemented and integrated with an existing state-of-the-art MDSE tool
to serve the CPS/IoT domain. Moreover, we validate the proposed approach using
a portion of the open data of the REFIT reference dataset for the smart energy
systems domain. Our model-to-code transformations (code generators) provide the
full source code of the desired IoT services out of the model instances in an
automated manner. Currently, we generate the source code in Java and Python.
The Python code is responsible for the ML functionalities and uses the APIs of
several ML libraries and frameworks, namely Scikit-Learn, Keras and TensorFlow.
For unsupervised and semi-supervised learning, the APIs of Scikit-Learn are
deployed. In addition to the pure MDSE approach, where certain ML methods,
e.g., K-Means, Mini-Batch K-Means, DB-SCAN, Spectral Clustering, Gaussian
Mixture Model, Self-Training, Label Propagation and Label Spreading are
supported, a more flexible, hybrid approach is also enabled to support the
practitioner in deploying a pre-trained ML model with any arbitrary
architecture and learning algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Network Approximation With Accuracy Independent of Number of Neurons. (arXiv:2107.02397v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zuowei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haizhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shijun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02397">
                                    <div class="article-summary-box-inner">
                                        <span>This paper develops simple feed-forward neural networks that achieve the
universal approximation property for all continuous functions with a fixed
finite number of neurons. These neural networks are simple because they are
designed with a simple and computable continuous activation function $\sigma$
leveraging a triangular-wave function and a softsign function. We prove that
$\sigma$-activated networks with width $36d(2d+1)$ and depth $11$ can
approximate any continuous function on a $d$-dimensioanl hypercube within an
arbitrarily small error. Hence, for supervised learning and its related
regression problems, the hypothesis space generated by these networks with a
size not smaller than $36d(2d+1)\times 11$ is dense in the space of continuous
functions. Furthermore, classification functions arising from image and signal
classification are in the hypothesis space generated by $\sigma$-activated
networks with width $36d(2d+1)$ and depth $12$, when there exist pairwise
disjoint closed bounded subsets of $\mathbb{R}^d$ such that the samples of the
same class are located in the same subset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Variational Conditional Sampling with Normalizing Flows. (arXiv:2107.02474v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Moens_V/0/1/0/all/0/1">Vincent Moens</a>, <a href="http://arxiv.org/find/stat/1/au:+Sootla_A/0/1/0/all/0/1">Aivar Sootla</a>, <a href="http://arxiv.org/find/stat/1/au:+Ammar_H/0/1/0/all/0/1">Haitham Bou Ammar</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02474">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for conditional sampling with normalizing flows when only
part of an observation is available. We rely on the following fact: if the
flow&#x27;s domain can be partitioned in such a way that the flow restrictions to
subdomains keep the bijectivity property, a lower bound to the conditioning
variable log-probability can be derived. Simulation from the variational
conditional flow then amends to solving an equality constraint. Our
contribution is three-fold: a) we provide detailed insights on the choice of
variational distributions; b) we propose how to partition the input space of
the flow to preserve bijectivity property; c) we propose a set of methods to
optimise the variational distribution in specific cases. Through extensive
experiments, we show that our sampling method can be applied with success to
invertible residual networks for inference and classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Segmentation Alternative Technique: Segmentation Domain Generation. (arXiv:2107.02525v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rogoz_A/0/1/0/all/0/1">Ana-Cristina Rogoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Muntean_R/0/1/0/all/0/1">Radu Muntean</a>, <a href="http://arxiv.org/find/cs/1/au:+Cobeli_S/0/1/0/all/0/1">Stefan Cobeli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02525">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting objects of interest in images was always a compelling task to
automate. In recent years this task was more and more explored using deep
learning techniques, mostly using region-based convolutional networks. In this
project we propose an alternative semantic segmentation technique making use of
Generative Adversarial Networks. We consider semantic segmentation to be a
domain transfer problem. Thus, we train a feed forward network (FFNN) to
receive as input a seed real image and generate as output its segmentation
mask.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mind Your Outliers! Investigating the Negative Impact of Outliers on Active Learning for Visual Question Answering. (arXiv:2107.02331v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karamcheti_S/0/1/0/all/0/1">Siddharth Karamcheti</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_R/0/1/0/all/0/1">Ranjay Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1">Li Fei-Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1">Christopher D. Manning</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02331">
                                    <div class="article-summary-box-inner">
                                        <span>Active learning promises to alleviate the massive data needs of supervised
machine learning: it has successfully improved sample efficiency by an order of
magnitude on traditional tasks like topic classification and object
recognition. However, we uncover a striking contrast to this promise: across 5
models and 4 datasets on the task of visual question answering, a wide variety
of active learning approaches fail to outperform random selection. To
understand this discrepancy, we profile 8 active learning methods on a
per-example basis, and identify the problem as collective outliers -- groups of
examples that active learning methods prefer to acquire but models fail to
learn (e.g., questions that ask about text in images or require external
knowledge). Through systematic ablation experiments and qualitative
visualizations, we verify that collective outliers are a general phenomenon
responsible for degrading pool-based active learning. Notably, we show that
active learning sample efficiency increases significantly as the number of
collective outliers in the active learning pool decreases. We conclude with a
discussion and prescriptive recommendations for mitigating the effects of these
outliers in future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete-Valued Neural Communication. (arXiv:2107.02367v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dianbo_Liu_D/0/1/0/all/0/1">Dianbo Liu Dianbo_Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamb_A/0/1/0/all/0/1">Alex Lamb</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawaguchi_K/0/1/0/all/0/1">Kenji Kawaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1">Anirudh Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1">Michael Curtis Mozer</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02367">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has advanced from fully connected architectures to structured
models organized into components, e.g., the transformer composed of positional
elements, modular architectures divided into slots, and graph neural nets made
up of nodes. In structured models, an interesting question is how to conduct
dynamic and possibly sparse communication among the separate components. Here,
we explore the hypothesis that restricting the transmitted information among
components to discrete representations is a beneficial bottleneck. The
motivating intuition is human language in which communication occurs through
discrete symbols. Even though individuals have different understandings of what
a &#x60;&#x60;&quot;cat&quot; is based on their specific experiences, the shared discrete token
makes it possible for communication among individuals to be unimpeded by
individual differences in internal representation. To discretize the values of
concepts dynamically communicated among specialist components, we extend the
quantization mechanism from the Vector-Quantized Variational Autoencoder to
multi-headed discretization with shared codebooks and use it for
discrete-valued neural communication (DVNC). Our experiments show that DVNC
substantially improves systematic generalization in a variety of architectures
-- transformers, modular architectures, and graph neural networks. We also show
that the DVNC is robust to the choice of hyperparameters, making the method
very useful in practice. Moreover, we establish a theoretical justification of
our discretization process, proving that it has the ability to increase noise
robustness and reduce the underlying dimensionality of the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth-supervised NeRF: Fewer Views and Faster Training for Free. (arXiv:2107.02791v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_K/0/1/0/all/0/1">Kangle Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Andrew Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun-Yan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanan_D/0/1/0/all/0/1">Deva Ramanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02791">
                                    <div class="article-summary-box-inner">
                                        <span>One common failure mode of Neural Radiance Field (NeRF) models is fitting
incorrect geometries when given an insufficient number of input views. We
propose DS-NeRF (Depth-supervised Neural Radiance Fields), a loss for learning
neural radiance fields that takes advantage of readily-available depth
supervision. Our key insight is that sparse depth supervision can be used to
regularize the learned geometry, a crucial component for effectively rendering
novel views using NeRF. We exploit the fact that current NeRF pipelines require
images with known camera poses that are typically estimated by running
structure-from-motion (SFM). Crucially, SFM also produces sparse 3D points that
can be used as &#x60;&#x60;free&quot; depth supervision during training: we simply add a loss
to ensure that depth rendered along rays that intersect these 3D points is
close to the observed depth. We find that DS-NeRF can render more accurate
images given fewer training views while training 2-6x faster. With only two
training views on real-world images, DS-NeRF significantly outperforms NeRF as
well as other sparse-view variants. We show that our loss is compatible with
these NeRF models, demonstrating that depth is a cheap and easily digestible
supervisory signal. Finally, we show that DS-NeRF supports other types of depth
supervision such as scanned depth sensors and RGBD reconstruction outputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GradDiv: Adversarial Robustness of Randomized Neural Networks via Gradient Diversity Regularization. (arXiv:2107.02425v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sungyoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hoki Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jaewook Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02425">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is vulnerable to adversarial examples. Many defenses based on
randomized neural networks have been proposed to solve the problem, but fail to
achieve robustness against attacks using proxy gradients such as the
Expectation over Transformation (EOT) attack. We investigate the effect of the
adversarial attacks using proxy gradients on randomized neural networks and
demonstrate that it highly relies on the directional distribution of the loss
gradients of the randomized neural network. We show in particular that proxy
gradients are less effective when the gradients are more scattered. To this
end, we propose Gradient Diversity (GradDiv) regularizations that minimize the
concentration of the gradients to build a robust randomized neural network. Our
experiments on MNIST, CIFAR10, and STL10 show that our proposed GradDiv
regularizations improve the adversarial robustness of randomized neural
networks against a variety of state-of-the-art attack methods. Moreover, our
method efficiently reduces the transferability among sample models of
randomized neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Clinical Context for User-Centered Explainability: A Diabetes Use Case. (arXiv:2107.02359v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chari_S/0/1/0/all/0/1">Shruthi Chari</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_P/0/1/0/all/0/1">Prithwish Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghalwash_M/0/1/0/all/0/1">Mohamed Ghalwash</a>, <a href="http://arxiv.org/find/cs/1/au:+Seneviratne_O/0/1/0/all/0/1">Oshani Seneviratne</a>, <a href="http://arxiv.org/find/cs/1/au:+Eyigoz_E/0/1/0/all/0/1">Elif K. Eyigoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Gruen_D/0/1/0/all/0/1">Daniel M. Gruen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Ching-Hua Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rojas_P/0/1/0/all/0/1">Pablo Meyer Rojas</a>, <a href="http://arxiv.org/find/cs/1/au:+McGuinness_D/0/1/0/all/0/1">Deborah L. McGuinness</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02359">
                                    <div class="article-summary-box-inner">
                                        <span>Academic advances of AI models in high-precision domains, like healthcare,
need to be made explainable in order to enhance real-world adoption. Our past
studies and ongoing interactions indicate that medical experts can use AI
systems with greater trust if there are ways to connect the model inferences
about patients to explanations that are tied back to the context of use.
Specifically, risk prediction is a complex problem of diagnostic and
interventional importance to clinicians wherein they consult different sources
to make decisions. To enable the adoption of the ever improving AI risk
prediction models in practice, we have begun to explore techniques to
contextualize such models along three dimensions of interest: the patients&#x27;
clinical state, AI predictions about their risk of complications, and
algorithmic explanations supporting the predictions. We validate the importance
of these dimensions by implementing a proof-of-concept (POC) in type-2 diabetes
(T2DM) use case where we assess the risk of chronic kidney disease (CKD) - a
common T2DM comorbidity. Within the POC, we include risk prediction models for
CKD, post-hoc explainers of the predictions, and other natural-language modules
which operationalize domain knowledge and CPGs to provide context. With primary
care physicians (PCP) as our end-users, we present our initial results and
clinician feedback in this paper. Our POC approach covers multiple knowledge
sources and clinical scenarios, blends knowledge to explain data and
predictions to PCPs, and received an enthusiastic response from our medical
expert.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Nonparametric Modelling for Model-Free Reinforcement Learning in LTE-LAA and Wi-Fi Coexistence. (arXiv:2107.02431v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shih_P/0/1/0/all/0/1">Po-Kan Shih</a>, <a href="http://arxiv.org/find/cs/1/au:+Moraffah_B/0/1/0/all/0/1">Bahman Moraffah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02431">
                                    <div class="article-summary-box-inner">
                                        <span>With the arrival of next generation wireless communication, a growing number
of new applications like internet of things, autonomous driving systems, and
drone are crowding the unlicensed spectrum. Licensed network such as the
long-term evolution (LTE) also comes to the unlicensed spectrum for better
providing high-capacity contents with low cost. However, LTE was not designed
to share resources with others. Previous solutions usually work on fixed
scenarios. This work features a Nonparametric Bayesian reinforcement learning
algorithm to cope with the coexistence between Wi-Fi and LTE licensed assisted
access (LTE-LAA) agents in 5 GHz unlicensed spectrum. The coexistence problem
is modeled as a decentralized partially-observable Markov decision process
(Dec-POMDP) and Bayesian inference is adopted for policy learning with
nonparametric prior to accommodate the uncertainty of policy for different
agents. A fairness measure is introduced in the reward function to encourage
fair sharing between agents. Variational inference for posterior model
approximation is considered to make the algorithm computationally efficient.
Simulation results demonstrate that this algorithm can reach high value with
compact policy representations in few learning iterations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal Mutual Information (MuMMI) Training for Robust Self-Supervised Deep Reinforcement Learning. (arXiv:2107.02339v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kaiqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yong Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Soh_H/0/1/0/all/0/1">Harold Soh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02339">
                                    <div class="article-summary-box-inner">
                                        <span>This work focuses on learning useful and robust deep world models using
multiple, possibly unreliable, sensors. We find that current methods do not
sufficiently encourage a shared representation between modalities; this can
cause poor performance on downstream tasks and over-reliance on specific
sensors. As a solution, we contribute a new multi-modal deep latent state-space
model, trained using a mutual information lower-bound. The key innovation is a
specially-designed density ratio estimator that encourages consistency between
the latent codes of each modality. We tasked our method to learn policies (in a
self-supervised manner) on multi-modal Natural MuJoCo benchmarks and a
challenging Table Wiping task. Experiments show our method significantly
outperforms state-of-the-art deep reinforcement learning methods, particularly
in the presence of missing observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physical Interaction as Communication: Learning Robot Objectives Online from Human Corrections. (arXiv:2107.02349v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Losey_D/0/1/0/all/0/1">Dylan P. Losey</a>, <a href="http://arxiv.org/find/cs/1/au:+Bajcsy_A/0/1/0/all/0/1">Andrea Bajcsy</a>, <a href="http://arxiv.org/find/cs/1/au:+OMalley_M/0/1/0/all/0/1">Marcia K. O&#x27;Malley</a>, <a href="http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1">Anca D. Dragan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02349">
                                    <div class="article-summary-box-inner">
                                        <span>When a robot performs a task next to a human, physical interaction is
inevitable: the human might push, pull, twist, or guide the robot. The
state-of-the-art treats these interactions as disturbances that the robot
should reject or avoid. At best, these robots respond safely while the human
interacts; but after the human lets go, these robots simply return to their
original behavior. We recognize that physical human-robot interaction (pHRI) is
often intentional -- the human intervenes on purpose because the robot is not
doing the task correctly. In this paper, we argue that when pHRI is intentional
it is also informative: the robot can leverage interactions to learn how it
should complete the rest of its current task even after the person lets go. We
formalize pHRI as a dynamical system, where the human has in mind an objective
function they want the robot to optimize, but the robot does not get direct
access to the parameters of this objective -- they are internal to the human.
Within our proposed framework human interactions become observations about the
true objective. We introduce approximations to learn from and respond to pHRI
in real-time. We recognize that not all human corrections are perfect: often
users interact with the robot noisily, and so we improve the efficiency of
robot learning from pHRI by reducing unintended learning. Finally, we conduct
simulations and user studies on a robotic manipulator to compare our proposed
approach to the state-of-the-art. Our results indicate that learning from pHRI
leads to better task performance and improved human satisfaction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoReD: Generalizing Fake Media Detection with Continual Representation using Distillation. (arXiv:2107.02408v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minha Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tariq_S/0/1/0/all/0/1">Shahroz Tariq</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Simon S. Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02408">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few decades, artificial intelligence research has made
tremendous strides, but it still heavily relies on fixed datasets in stationary
environments. Continual learning is a growing field of research that examines
how AI systems can learn sequentially from a continuous stream of linked data
in the same way that biological systems do. Simultaneously, fake media such as
deepfakes and synthetic face images have emerged as significant to current
multimedia technologies. Recently, numerous method has been proposed which can
detect deepfakes with high accuracy. However, they suffer significantly due to
their reliance on fixed datasets in limited evaluation settings. Therefore, in
this work, we apply continuous learning to neural networks&#x27; learning dynamics,
emphasizing its potential to increase data efficiency significantly. We propose
Continual Representation using Distillation (CoReD) method that employs the
concept of Continual Learning (CoL), Representation Learning (ReL), and
Knowledge Distillation (KD). We design CoReD to perform sequential domain
adaptation tasks on new deepfake and GAN-generated synthetic face datasets,
while effectively minimizing the catastrophic forgetting in a teacher-student
model setting. Our extensive experimental results demonstrate that our method
is efficient at domain adaptation to detect low-quality deepfakes videos and
GAN-generated images from several datasets, outperforming the-state-of-art
baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Short Note on the Relationship of Information Gain and Eluder Dimension. (arXiv:2107.02377v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaixuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham M. Kakade</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1">Qi Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02377">
                                    <div class="article-summary-box-inner">
                                        <span>Eluder dimension and information gain are two widely used methods of
complexity measures in bandit and reinforcement learning. Eluder dimension was
originally proposed as a general complexity measure of function classes, but
the common examples of where it is known to be small are function spaces
(vector spaces). In these cases, the primary tool to upper bound the eluder
dimension is the elliptic potential lemma. Interestingly, the elliptic
potential lemma also features prominently in the analysis of linear
bandits/reinforcement learning and their nonparametric generalization, the
information gain. We show that this is not a coincidence -- eluder dimension
and information gain are equivalent in a precise sense for reproducing kernel
Hilbert spaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepDDS: deep graph neural network with attention mechanism to predict synergistic drug combinations. (arXiv:2107.02467v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">J. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">X. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1">S. Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">L. Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu%2A_H/0/1/0/all/0/1">H. Liu*</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02467">
                                    <div class="article-summary-box-inner">
                                        <span>Drug combination therapy has become a increasingly promising method in the
treatment of cancer. However, the number of possible drug combinations is so
huge that it is hard to screen synergistic drug combinations through wet-lab
experiments. Therefore, computational screening has become an important way to
prioritize drug combinations. Graph neural network have recently shown
remarkable performance in the prediction of compound-protein interactions, but
it has not been applied to the screening of drug combinations. In this paper,
we proposed a deep learning model based on graph neural networks and attention
mechanism to identify drug combinations that can effectively inhibit the
viability of specific cancer cells. The feature embeddings of drug molecule
structure and gene expression profiles were taken as input to multi-layer
feedforward neural network to identify the synergistic drug combinations. We
compared DeepDDS with classical machine learning methods and other deep
learning-based methods on benchmark data set, and the leave-one-out
experimental results showed that DeepDDS achieved better performance than
competitive methods. Also, on an independent test set released by well-known
pharmaceutical enterprise AstraZeneca, DeepDDS was superior to competitive
methods by more than 16\% predictive precision. Furthermore, we explored the
interpretability of the graph attention network, and found the correlation
matrix of atomic features revealed important chemical substructures of drugs.
We believed that DeepDDS is an effective tool that prioritized synergistic drug
combinations for further wet-lab experiment validation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Instant One-Shot Word-Learning for Context-Specific Neural Sequence-to-Sequence Speech Recognition. (arXiv:2107.02268v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huber_C/0/1/0/all/0/1">Christian Huber</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_J/0/1/0/all/0/1">Juan Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Stuker_S/0/1/0/all/0/1">Sebastian St&#xfc;ker</a>, <a href="http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1">Alexander Waibel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02268">
                                    <div class="article-summary-box-inner">
                                        <span>Neural sequence-to-sequence systems deliver state-of-the-art performance for
automatic speech recognition (ASR). When using appropriate modeling units,
e.g., byte-pair encoded characters, these systems are in principal open
vocabulary systems. In practice, however, they often fail to recognize words
not seen during training, e.g., named entities, numbers or technical terms. To
alleviate this problem we supplement an end-to-end ASR system with a
word/phrase memory and a mechanism to access this memory to recognize the words
and phrases correctly. After the training of the ASR system, and when it has
already been deployed, a relevant word can be added or subtracted instantly
without the need for further training. In this paper we demonstrate that
through this mechanism our system is able to recognize more than 85% of newly
added words that it previously failed to recognize compared to a strong
baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VolNet: Estimating Human Body Part Volumes from a Single RGB Image. (arXiv:2107.02259v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leinen_F/0/1/0/all/0/1">Fabian Leinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cozzolino_V/0/1/0/all/0/1">Vittorio Cozzolino</a>, <a href="http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1">Torsten Sch&#xf6;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02259">
                                    <div class="article-summary-box-inner">
                                        <span>Human body volume estimation from a single RGB image is a challenging problem
despite minimal attention from the research community. However VolNet, an
architecture leveraging 2D and 3D pose estimation, body part segmentation and
volume regression extracted from a single 2D RGB image combined with the
subject&#x27;s body height can be used to estimate the total body volume. VolNet is
designed to predict the 2D and 3D pose as well as the body part segmentation in
intermediate tasks. We generated a synthetic, large-scale dataset of
photo-realistic images of human bodies with a wide range of body shapes and
realistic poses called SURREALvols. By using Volnet and combining multiple
stacked hourglass networks together with ResNeXt, our model correctly predicted
the volume in ~82% of cases with a 10% tolerance threshold. This is a
considerable improvement compared to state-of-the-art solutions such as BodyNet
with only a ~38% success rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptation via CycleGAN for Retina Segmentation in Optical Coherence Tomography. (arXiv:2107.02345v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_R/0/1/0/all/0/1">Ricky Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_T/0/1/0/all/0/1">Timothy T. Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_G/0/1/0/all/0/1">Gavin Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_D/0/1/0/all/0/1">Da Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarunic_M/0/1/0/all/0/1">Marinko V. Sarunic</a>, <a href="http://arxiv.org/find/eess/1/au:+Beg_M/0/1/0/all/0/1">Mirza Faisal Beg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02345">
                                    <div class="article-summary-box-inner">
                                        <span>With the FDA approval of Artificial Intelligence (AI) for point-of-care
clinical diagnoses, model generalizability is of the utmost importance as
clinical decision-making must be domain-agnostic. A method of tackling the
problem is to increase the dataset to include images from a multitude of
domains; while this technique is ideal, the security requirements of medical
data is a major limitation. Additionally, researchers with developed tools
benefit from the addition of open-sourced data, but are limited by the
difference in domains. Herewith, we investigated the implementation of a
Cycle-Consistent Generative Adversarial Networks (CycleGAN) for the domain
adaptation of Optical Coherence Tomography (OCT) volumes. This study was done
in collaboration with the Biomedical Optics Research Group and Functional &amp;
Anatomical Imaging &amp; Shape Analysis Lab at Simon Fraser University. In this
study, we investigated a learning-based approach of adapting the domain of a
publicly available dataset, UK Biobank dataset (UKB). To evaluate the
performance of domain adaptation, we utilized pre-existing retinal layer
segmentation tools developed on a different set of RETOUCH OCT data. This study
provides insight on state-of-the-art tools for domain adaptation compared to
traditional processing techniques as well as a pipeline for adapting publicly
available retinal data to the domains previously used by our collaborators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Explainable Artificial Intelligence in Manufacturing. (arXiv:2107.02295v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sofianidis_G/0/1/0/all/0/1">Georgios Sofianidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozanec_J/0/1/0/all/0/1">Jo&#x17e;e M. Ro&#x17e;anec</a>, <a href="http://arxiv.org/find/cs/1/au:+Mladenic_D/0/1/0/all/0/1">Dunja Mladeni&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Kyriazis_D/0/1/0/all/0/1">Dimosthenis Kyriazis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02295">
                                    <div class="article-summary-box-inner">
                                        <span>The implementation of Artificial Intelligence (AI) systems in the
manufacturing domain enables higher production efficiency, outstanding
performance, and safer operations, leveraging powerful tools such as deep
learning and reinforcement learning techniques. Despite the high accuracy of
these models, they are mostly considered black boxes: they are unintelligible
to the human. Opaqueness affects trust in the system, a factor that is critical
in the context of decision-making. We present an overview of Explainable
Artificial Intelligence (XAI) techniques as a means of boosting the
transparency of models. We analyze different metrics to evaluate these
techniques and describe several application scenarios in the manufacturing
domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient First-Order Contextual Bandits: Prediction, Allocation, and Triangular Discrimination. (arXiv:2107.02237v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1">Dylan J. Foster</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1">Akshay Krishnamurthy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02237">
                                    <div class="article-summary-box-inner">
                                        <span>A recurring theme in statistical learning, online learning, and beyond is
that faster convergence rates are possible for problems with low noise, often
quantified by the performance of the best hypothesis; such results are known as
first-order or small-loss guarantees. While first-order guarantees are
relatively well understood in statistical and online learning, adapting to low
noise in contextual bandits (and more broadly, decision making) presents major
algorithmic challenges. In a COLT 2017 open problem, Agarwal, Krishnamurthy,
Langford, Luo, and Schapire asked whether first-order guarantees are even
possible for contextual bandits and -- if so -- whether they can be attained by
efficient algorithms. We give a resolution to this question by providing an
optimal and efficient reduction from contextual bandits to online regression
with the logarithmic (or, cross-entropy) loss. Our algorithm is simple and
practical, readily accommodates rich function classes, and requires no
distributional assumptions beyond realizability. In a large-scale empirical
evaluation, we find that our approach typically outperforms comparable
non-first-order methods.

On the technical side, we show that the logarithmic loss and an
information-theoretic quantity called the triangular discrimination play a
fundamental role in obtaining first-order guarantees, and we combine this
observation with new refinements to the regression oracle reduction framework
of Foster and Rakhlin. The use of triangular discrimination yields novel
results even for the classical statistical learning model, and we anticipate
that it will find broader use.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effects of Smart Traffic Signal Control on Air Quality. (arXiv:2107.02361v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fazzini_P/0/1/0/all/0/1">Paolo Fazzini</a>, <a href="http://arxiv.org/find/cs/1/au:+Torre_M/0/1/0/all/0/1">Marco Torre</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizza_V/0/1/0/all/0/1">Valeria Rizza</a>, <a href="http://arxiv.org/find/cs/1/au:+Petracchini_F/0/1/0/all/0/1">Francesco Petracchini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02361">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptive traffic signal control (ATSC) in urban traffic networks poses a
challenging task due to the complicated dynamics arising in traffic systems. In
recent years, several approaches based on multi-agent deep reinforcement
learning (MARL) have been studied experimentally. These approaches propose
distributed techniques in which each signalized intersection is seen as an
agent in a stochastic game whose purpose is to optimize the flow of vehicles in
its vicinity. In this setting, the systems evolves towards an equilibrium among
the agents that shows beneficial for the whole traffic network. A recently
developed multi-agent variant of the well-established advantage actor-critic
(A2C) algorithm, called MA2C (multi-agent A2C) exploits the promising idea of
some communication among the agents. In this view,the agents share their
strategies with other neighbor agents, thereby stabilizing the learning process
even when the agents grow in number and variety. We experimented MA2C in two
traffic networks located in Bologna (Italy) and found that its action
translates into a significant decrease of the amount of pollutants released
into the environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Learning-Based Particle-in-Cell Method for Plasma Simulations. (arXiv:2107.02232v1 [physics.plasm-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Aguilar_X/0/1/0/all/0/1">Xavier Aguilar</a>, <a href="http://arxiv.org/find/physics/1/au:+Markidis_S/0/1/0/all/0/1">Stefano Markidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02232">
                                    <div class="article-summary-box-inner">
                                        <span>We design and develop a new Particle-in-Cell (PIC) method for plasma
simulations using Deep-Learning (DL) to calculate the electric field from the
electron phase space. We train a Multilayer Perceptron (MLP) and a
Convolutional Neural Network (CNN) to solve the two-stream instability test. We
verify that the DL-based MLP PIC method produces the correct results using the
two-stream instability: the DL-based PIC provides the expected growth rate of
the two-stream instability. The DL-based PIC does not conserve the total energy
and momentum. However, the DL-based PIC method is stable against the cold-beam
instability, affecting traditional PIC methods. This work shows that
integrating DL technologies into traditional computational methods is a viable
approach for developing next-generation PIC algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransformerFusion: Monocular RGB Scene Reconstruction using Transformers. (arXiv:2107.02191v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bozic_A/0/1/0/all/0/1">Alja&#x17e; Bo&#x17e;i&#x10d;</a>, <a href="http://arxiv.org/find/cs/1/au:+Palafox_P/0/1/0/all/0/1">Pablo Palafox</a>, <a href="http://arxiv.org/find/cs/1/au:+Thies_J/0/1/0/all/0/1">Justus Thies</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1">Angela Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Niessner_M/0/1/0/all/0/1">Matthias Nie&#xdf;ner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02191">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce TransformerFusion, a transformer-based 3D scene reconstruction
approach. From an input monocular RGB video, the video frames are processed by
a transformer network that fuses the observations into a volumetric feature
grid representing the scene; this feature grid is then decoded into an implicit
3D scene representation. Key to our approach is the transformer architecture
that enables the network to learn to attend to the most relevant image frames
for each 3D location in the scene, supervised only by the scene reconstruction
task. Features are fused in a coarse-to-fine fashion, storing fine-level
features only where needed, requiring lower memory storage and enabling fusion
at interactive rates. The feature grid is then decoded to a higher-resolution
scene reconstruction, using an MLP-based surface occupancy prediction from
interpolated coarse-to-fine 3D features. Our approach results in an accurate
surface reconstruction, outperforming state-of-the-art multi-view stereo depth
estimation methods, fully-convolutional 3D reconstruction approaches, and
approaches using LSTM- or GRU-based recurrent networks for video sequence
fusion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sarcasm Detection: A Comparative Study. (arXiv:2107.02276v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yaghoobian_H/0/1/0/all/0/1">Hamed Yaghoobian</a>, <a href="http://arxiv.org/find/cs/1/au:+Arabnia_H/0/1/0/all/0/1">Hamid R. Arabnia</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasheed_K/0/1/0/all/0/1">Khaled Rasheed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02276">
                                    <div class="article-summary-box-inner">
                                        <span>Sarcasm detection is the task of identifying irony containing utterances in
sentiment-bearing text. However, the figurative and creative nature of sarcasm
poses a great challenge for affective computing systems performing sentiment
analysis. This article compiles and reviews the salient work in the literature
of automatic sarcasm detection. Thus far, three main paradigm shifts have
occurred in the way researchers have approached this task: 1) semi-supervised
pattern extraction to identify implicit sentiment, 2) use of hashtag-based
supervision, and 3) incorporation of context beyond target text. In this
article, we provide a comprehensive review of the datasets, approaches, trends,
and issues in sarcasm and irony detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-optimal inference in adaptive linear regression. (arXiv:2107.02266v1 [math.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Khamaru_K/0/1/0/all/0/1">Koulik Khamaru</a>, <a href="http://arxiv.org/find/math/1/au:+Deshpande_Y/0/1/0/all/0/1">Yash Deshpande</a>, <a href="http://arxiv.org/find/math/1/au:+Mackey_L/0/1/0/all/0/1">Lester Mackey</a>, <a href="http://arxiv.org/find/math/1/au:+Wainwright_M/0/1/0/all/0/1">Martin J. Wainwright</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02266">
                                    <div class="article-summary-box-inner">
                                        <span>When data is collected in an adaptive manner, even simple methods like
ordinary least squares can exhibit non-normal asymptotic behavior. As an
undesirable consequence, hypothesis tests and confidence intervals based on
asymptotic normality can lead to erroneous results. We propose an online
debiasing estimator to correct these distributional anomalies in least squares
estimation. Our proposed method takes advantage of the covariance structure
present in the dataset and provides sharper estimates in directions for which
more information has accrued. We establish an asymptotic normality property for
our proposed online debiasing estimator under mild conditions on the data
collection process, and provide asymptotically exact confidence intervals. We
additionally prove a minimax lower bound for the adaptive linear regression
problem, thereby providing a baseline by which to compare estimators. There are
various conditions under which our proposed estimator achieves the minimax
lower bound up to logarithmic factors. We demonstrate the usefulness of our
theory via applications to multi-armed bandit, autoregressive time series
estimation, and active learning with exploration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Featurized Density Ratio Estimation. (arXiv:2107.02212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1">Kristy Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_M/0/1/0/all/0/1">Madeline Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02212">
                                    <div class="article-summary-box-inner">
                                        <span>Density ratio estimation serves as an important technique in the unsupervised
machine learning toolbox. However, such ratios are difficult to estimate for
complex, high-dimensional data, particularly when the densities of interest are
sufficiently different. In our work, we propose to leverage an invertible
generative model to map the two distributions into a common feature space prior
to estimation. This featurization brings the densities closer together in
latent space, sidestepping pathological scenarios where the learned density
ratios in input space can be arbitrarily inaccurate. At the same time, the
invertibility of our feature map guarantees that the ratios computed in feature
space are equivalent to those in input space. Empirically, we demonstrate the
efficacy of our approach in a variety of downstream tasks that require access
to accurate density ratios such as mutual information estimation, targeted
sampling in deep generative models, and classification with data augmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A comparison of LSTM and GRU networks for learning symbolic sequences. (arXiv:2107.02248v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cahuantzi_R/0/1/0/all/0/1">Roberto Cahuantzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinye Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guttel_S/0/1/0/all/0/1">Stefan G&#xfc;ttel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02248">
                                    <div class="article-summary-box-inner">
                                        <span>We explore relations between the hyper-parameters of a recurrent neural
network (RNN) and the complexity of string sequences it is able to memorize. We
compare long short-term memory (LSTM) networks and gated recurrent units
(GRUs). We find that an increase of RNN depth does not necessarily result in
better memorization capability when the training time is constrained. Our
results also indicate that the learning rate and the number of units per layer
are among the most important hyper-parameters to be tuned. Generally, GRUs
outperform LSTM networks on low complexity sequences while on high complexity
sequences LSTMs perform better.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dueling Bandits with Adversarial Sleeping. (arXiv:2107.02274v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1">Aadirupa Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaillard_P/0/1/0/all/0/1">Pierre Gaillard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02274">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the problem of sleeping dueling bandits with stochastic
preferences and adversarial availabilities (DB-SPAA). In almost all dueling
bandit applications, the decision space often changes over time; eg, retail
store management, online shopping, restaurant recommendation, search engine
optimization, etc. Surprisingly, this &#x60;sleeping aspect&#x27; of dueling bandits has
never been studied in the literature. Like dueling bandits, the goal is to
compete with the best arm by sequentially querying the preference feedback of
item pairs. The non-triviality however results due to the non-stationary item
spaces that allow any arbitrary subsets items to go unavailable every round.
The goal is to find an optimal &#x60;no-regret&#x27; policy that can identify the best
available item at each round, as opposed to the standard &#x60;fixed best-arm regret
objective&#x27; of dueling bandits. We first derive an instance-specific lower bound
for DB-SPAA $\Omega( \sum_{i &#x3D;1}^{K-1}\sum_{j&#x3D;i+1}^K \frac{\log
T}{\Delta(i,j)})$, where $K$ is the number of items and $\Delta(i,j)$ is the
gap between items $i$ and $j$. This indicates that the sleeping problem with
preference feedback is inherently more difficult than that for classical
multi-armed bandits (MAB). We then propose two algorithms, with near optimal
regret guarantees. Our results are corroborated empirically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-learning Amidst Heterogeneity and Ambiguity. (arXiv:2107.02228v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Go_K/0/1/0/all/0/1">Kyeongryeol Go</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Seyoung Yun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02228">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning aims to learn a model that can handle multiple tasks generated
from an unknown but shared distribution. However, typical meta-learning
algorithms have assumed the tasks to be similar such that a single meta-learner
is sufficient to aggregate the variations in all aspects. In addition, there
has been less consideration on uncertainty when limited information is given as
context. In this paper, we devise a novel meta-learning framework, called
Meta-learning Amidst Heterogeneity and Ambiguity (MAHA), that outperforms
previous works in terms of prediction based on its ability on task
identification. By extensively conducting several experiments in regression and
classification, we demonstrate the validity of our model, which turns out to be
robust to both task heterogeneity and ambiguity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepCEL0 for 2D Single Molecule Localization in Fluorescence Microscopy. (arXiv:2107.02281v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cascarano_P/0/1/0/all/0/1">Pasquale Cascarano</a>, <a href="http://arxiv.org/find/cs/1/au:+Comes_M/0/1/0/all/0/1">Maria Colomba Comes</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastiani_A/0/1/0/all/0/1">Andrea Sebastiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mencattini_A/0/1/0/all/0/1">Arianna Mencattini</a>, <a href="http://arxiv.org/find/cs/1/au:+Piccolomini_E/0/1/0/all/0/1">Elena Loli Piccolomini</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinelli_E/0/1/0/all/0/1">Eugenio Martinelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02281">
                                    <div class="article-summary-box-inner">
                                        <span>In fluorescence microscopy, Single Molecule Localization Microscopy (SMLM)
techniques aim at localizing with high precision high density fluorescent
molecules by stochastically activating and imaging small subsets of blinking
emitters. Super Resolution (SR) plays an important role in this field since it
allows to go beyond the intrinsic light diffraction limit. In this work, we
propose a deep learning-based algorithm for precise molecule localization of
high density frames acquired by SMLM techniques whose $\ell_{2}$-based loss
function is regularized by positivity and $\ell_{0}$-based constraints. The
$\ell_{0}$ is relaxed through its Continuous Exact $\ell_{0}$ (CEL0)
counterpart. The arising approach, named DeepCEL0, is parameter-free, more
flexible, faster and provides more precise molecule localization maps if
compared to the other state-of-the-art methods. We validate our approach on
both simulated and real fluorescence microscopy data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Weak Supervision. (arXiv:2107.02233v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cachay_S/0/1/0/all/0/1">Salva R&#xfc;hling Cachay</a>, <a href="http://arxiv.org/find/cs/1/au:+Boecking_B/0/1/0/all/0/1">Benedikt Boecking</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubrawski_A/0/1/0/all/0/1">Artur Dubrawski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02233">
                                    <div class="article-summary-box-inner">
                                        <span>Aggregating multiple sources of weak supervision (WS) can ease the
data-labeling bottleneck prevalent in many machine learning applications, by
replacing the tedious manual collection of ground truth labels. Current state
of the art approaches that do not use any labeled training data, however,
require two separate modeling steps: Learning a probabilistic latent variable
model based on the WS sources -- making assumptions that rarely hold in
practice -- followed by downstream model training. Importantly, the first step
of modeling does not consider the performance of the downstream model. To
address these caveats we propose an end-to-end approach for directly learning
the downstream model by maximizing its agreement with probabilistic labels
generated by reparameterizing previous probabilistic posteriors with a neural
network. Our results show improved performance over prior work in terms of end
model performance on downstream test sets, as well as in terms of improved
robustness to dependencies among weak supervision sources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated age-related macular degeneration area estimation -- first results. (arXiv:2107.02211v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Peciulis_R/0/1/0/all/0/1">Rokas Pe&#x10d;iulis</a>, <a href="http://arxiv.org/find/eess/1/au:+Lukosevicius_M/0/1/0/all/0/1">Mantas Luko&#x161;evi&#x10d;ius</a>, <a href="http://arxiv.org/find/eess/1/au:+Krisciukaitis_A/0/1/0/all/0/1">Algimantas Kri&#x161;&#x10d;iukaitis</a>, <a href="http://arxiv.org/find/eess/1/au:+Petrolis_R/0/1/0/all/0/1">Robertas Petrolis</a>, <a href="http://arxiv.org/find/eess/1/au:+Buteikiene_D/0/1/0/all/0/1">Dovil&#x117; Buteikien&#x117;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02211">
                                    <div class="article-summary-box-inner">
                                        <span>This work aims to research an automatic method for detecting Age-related
Macular Degeneration (AMD) lesions in RGB eye fundus images. For this, we align
invasively obtained eye fundus contrast images (the &quot;golden standard&quot;
diagnostic) to the RGB ones and use them to hand-annotate the lesions. This is
done using our custom-made tool. Using the data, we train and test five
different convolutional neural networks: a custom one to classify healthy and
AMD-affected eye fundi, and four well-known networks: ResNet50, ResNet101,
MobileNetV3, and UNet to segment (localize) the AMD lesions in the affected eye
fundus images. We achieve 93.55% accuracy or 69.71% Dice index as the
preliminary best results in segmentation with MobileNetV3.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoReD: Generalizing Fake Media Detection with Continual Representation using Distillation. (arXiv:2107.02408v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minha Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Tariq_S/0/1/0/all/0/1">Shahroz Tariq</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Simon S. Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02408">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few decades, artificial intelligence research has made
tremendous strides, but it still heavily relies on fixed datasets in stationary
environments. Continual learning is a growing field of research that examines
how AI systems can learn sequentially from a continuous stream of linked data
in the same way that biological systems do. Simultaneously, fake media such as
deepfakes and synthetic face images have emerged as significant to current
multimedia technologies. Recently, numerous method has been proposed which can
detect deepfakes with high accuracy. However, they suffer significantly due to
their reliance on fixed datasets in limited evaluation settings. Therefore, in
this work, we apply continuous learning to neural networks&#x27; learning dynamics,
emphasizing its potential to increase data efficiency significantly. We propose
Continual Representation using Distillation (CoReD) method that employs the
concept of Continual Learning (CoL), Representation Learning (ReL), and
Knowledge Distillation (KD). We design CoReD to perform sequential domain
adaptation tasks on new deepfake and GAN-generated synthetic face datasets,
while effectively minimizing the catastrophic forgetting in a teacher-student
model setting. Our extensive experimental results demonstrate that our method
is efficient at domain adaptation to detect low-quality deepfakes videos and
GAN-generated images from several datasets, outperforming the-state-of-art
baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3$\times$ as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results~(e.g., Top-1 accuracy 84.1% trained on 224$\times$224
ImageNet-1K only), while being more scalable on high-resolution images. The
models and source code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hear Me Out: Fusional Approaches for Audio Augmented Temporal Action Localization. (arXiv:2106.14118v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bagchi_A/0/1/0/all/0/1">Anurag Bagchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_J/0/1/0/all/0/1">Jazib Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandes_D/0/1/0/all/0/1">Dolton Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarvadevabhatla_R/0/1/0/all/0/1">Ravi Kiran Sarvadevabhatla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.14118">
                                    <div class="article-summary-box-inner">
                                        <span>State of the art architectures for untrimmed video Temporal Action
Localization (TAL) have only considered RGB and Flow modalities, leaving the
information-rich audio modality totally unexploited. Audio fusion has been
explored for the related but arguably easier problem of trimmed (clip-level)
action recognition. However, TAL poses a unique set of challenges. In this
paper, we propose simple but effective fusion-based approaches for TAL. To the
best of our knowledge, our work is the first to jointly consider audio and
video modalities for supervised TAL. We experimentally show that our schemes
consistently improve performance for state of the art video-only TAL
approaches. Specifically, they help achieve new state of the art performance on
large-scale benchmark datasets - ActivityNet-1.3 (54.34 mAP@0.5) and THUMOS14
(57.18 mAP@0.5). Our experiments include ablations involving multiple fusion
schemes, modality combinations and TAL architectures. Our code, models and
associated data will be made available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Adversarial Training incorporating Forgery Attention for Image Forgery Localization. (arXiv:2107.02434v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuo_L/0/1/0/all/0/1">Long Zhuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Shunquan Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiwu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02434">
                                    <div class="article-summary-box-inner">
                                        <span>Image editing techniques enable people to modify the content of an image
without leaving visual traces and thus may cause serious security risks. Hence
the detection and localization of these forgeries become quite necessary and
challenging. Furthermore, unlike other tasks with extensive data, there is
usually a lack of annotated forged images for training due to annotation
difficulties. In this paper, we propose a self-adversarial training strategy
and a reliable coarse-to-fine network that utilizes a self-attention mechanism
to localize forged regions in forgery images. The self-attention module is
based on a Channel-Wise High Pass Filter block (CW-HPF). CW-HPF leverages
inter-channel relationships of features and extracts noise features by high
pass filters. Based on the CW-HPF, a self-attention mechanism, called forgery
attention, is proposed to capture rich contextual dependencies of intrinsic
inconsistency extracted from tampered regions. Specifically, we append two
types of attention modules on top of CW-HPF respectively to model internal
interdependencies in spatial dimension and external dependencies among
channels. We exploit a coarse-to-fine network to enhance the noise
inconsistency between original and tampered regions. More importantly, to
address the issue of insufficient training data, we design a self-adversarial
training strategy that expands training data dynamically to achieve more robust
performance. Specifically, in each training iteration, we perform adversarial
attacks against our network to generate adversarial examples and train our
model on them. Extensive experimental results demonstrate that our proposed
algorithm steadily outperforms state-of-the-art methods by a clear margin in
different benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>

    <footer>
        <time id="build-timestamp" datetime="2021-07-13T00:49:42.549Z">2021-07-13T00:49:42.549Z</time>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.js"></script>
    <script src="highlightRegex.js"></script>
    <script src="index.js"></script>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=386&t=tt&d=sDvlbgmeTw_E_GoVDGdggVOFT21w54hFtP9VETatnEM&cmo=ff4242&cmn=3dd13d"></script>
    <!-- %before-body-end.html% -->
</body>

</html>