 
<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="ArxivDaily" href="feed.atom" />
    <link href="index.css" rel="stylesheet" />
    <!-- %before-head-end.html% -->
</head>

<body>
    <!-- %after-body-begin.html% -->
    <a href="https://github.com/LooperXX/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">LooperXX/ArxivDaily</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-30">2021-07-30</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Addressing Barriers to Reproducible Named Entity Recognition Evaluation. (arXiv:2107.14154v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Palen_Michel_C/0/1/0/all/0/1">Chester Palen-Michel</a>, <a href="http://arxiv.org/find/cs/1/au:+Holley_N/0/1/0/all/0/1">Nolan Holley</a>, <a href="http://arxiv.org/find/cs/1/au:+Lignos_C/0/1/0/all/0/1">Constantine Lignos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14154">
                                    <div class="article-summary-box-inner">
                                        <span>To address what we believe is a looming crisis of unreproducible evaluation
for named entity recognition tasks, we present guidelines for reproducible
evaluation. The guidelines we propose are extremely simple, focusing on
transparency regarding how chunks are encoded and scored, but very few papers
currently being published fully comply with them. We demonstrate that despite
the apparent simplicity of NER evaluation, unreported differences in the
scoring procedure can result in changes to scores that are both of noticeable
magnitude and are statistically significant. We provide SeqScore, an open
source toolkit that addresses many of the issues that cause replication
failures and makes following our guidelines easy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Easy and Efficient Transformer : Scalable Inference Solution For large NLP model. (arXiv:2104.12470v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gongzheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xi_Y/0/1/0/all/0/1">Yadong Xi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1">Jingzhen Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Duan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bai Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Changjie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xiaoxi Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zeng Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12470">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, large-scale transformer-based models have been proven to be
effective over a variety of tasks across many domains. Nevertheless, putting
them into production is very expensive, requiring comprehensive optimization
techniques to reduce inference costs. This paper introduces a series of
transformer inference optimization techniques that are both in algorithm level
and hardware level. These techniques include a pre-padding decoding mechanism
that improves token parallelism for text generation, and highly optimized
kernels designed for very long input length and large hidden size. On this
basis, we propose a transformer inference acceleration library -- Easy and
Efficient Transformer (EET), which has a significant performance improvement
over existing libraries. Compared to Faster Transformer v4.0&#x27;s implementation
for GPT-2 layer on A100, EET achieves a 1.5-4.5x state-of-art speedup varying
with different context lengths. EET is available at
https://github.com/NetEase-FuXi/EET. A demo video is available at
https://youtu.be/22UPcNGcErg.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Break, Perturb, Build: Automatic Perturbation of Reasoning Paths through Question Decomposition. (arXiv:2107.13935v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geva_M/0/1/0/all/0/1">Mor Geva</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfson_T/0/1/0/all/0/1">Tomer Wolfson</a>, <a href="http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1">Jonathan Berant</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13935">
                                    <div class="article-summary-box-inner">
                                        <span>Recent efforts to create challenge benchmarks that test the abilities of
natural language understanding models have largely depended on human
annotations. In this work, we introduce the &quot;Break, Perturb, Build&quot; (BPB)
framework for automatic reasoning-oriented perturbation of question-answer
pairs. BPB represents a question by decomposing it into the reasoning steps
that are required to answer it, symbolically perturbs the decomposition, and
then generates new question-answer pairs. We demonstrate the effectiveness of
BPB by creating evaluation sets for three reading comprehension (RC)
benchmarks, generating thousands of high-quality examples without human
intervention. We evaluate a range of RC models on our evaluation sets, which
reveals large performance gaps on generated examples compared to the original
data. Moreover, symbolic perturbations enable fine-grained analysis of the
strengths and limitations of models. Last, augmenting the training data with
examples generated by BPB helps close performance gaps, without any drop on the
original data distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Perturbed Length-aware Positional Encoding for Non-autoregressive Neural Machine Translation. (arXiv:2107.13689v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oka_Y/0/1/0/all/0/1">Yui Oka</a>, <a href="http://arxiv.org/find/cs/1/au:+Sudoh_K/0/1/0/all/0/1">Katsuhito Sudoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakamura_S/0/1/0/all/0/1">Satoshi Nakamura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13689">
                                    <div class="article-summary-box-inner">
                                        <span>Non-autoregressive neural machine translation (NAT) usually employs
sequence-level knowledge distillation using autoregressive neural machine
translation (AT) as its teacher model. However, a NAT model often outputs
shorter sentences than an AT model. In this work, we propose sequence-level
knowledge distillation (SKD) using perturbed length-aware positional encoding
and apply it to a student model, the Levenshtein Transformer. Our method
outperformed a standard Levenshtein Transformer by 2.5 points in bilingual
evaluation understudy (BLEU) at maximum in a WMT14 German to English
translation. The NAT model output longer sentences than the baseline NAT
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recognizing Emotion Cause in Conversations. (arXiv:2012.11820v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1">Navonil Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Hazarika_D/0/1/0/all/0/1">Devamanyu Hazarika</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosal_D/0/1/0/all/0/1">Deepanway Ghosal</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhardwaj_R/0/1/0/all/0/1">Rishabh Bhardwaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Jian_S/0/1/0/all/0/1">Samson Yu Bai Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_P/0/1/0/all/0/1">Pengfei Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1">Romila Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Abhinaba Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chhaya_N/0/1/0/all/0/1">Niyati Chhaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Gelbukh_A/0/1/0/all/0/1">Alexander Gelbukh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11820">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of recognizing emotion cause in conversations, define
two novel sub-tasks of this problem, and provide a corresponding dialogue-level
dataset, along with strong Transformer-based baselines. The dataset is
available at https://github.com/declare-lab/RECCON.

Introduction: Recognizing the cause behind emotions in text is a fundamental
yet under-explored area of research in NLP. Advances in this area hold the
potential to improve interpretability and performance in affect-based models.
Identifying emotion causes at the utterance level in conversations is
particularly challenging due to the intermingling dynamics among the
interlocutors.

Method: We introduce the task of Recognizing Emotion Cause in CONversations
with an accompanying dataset named RECCON, containing over 1,000 dialogues and
10,000 utterance cause-effect pairs. Furthermore, we define different cause
types based on the source of the causes, and establish strong Transformer-based
baselines to address two different sub-tasks on this dataset: causal span
extraction and causal emotion entailment.

Result: Our Transformer-based baselines, which leverage contextual
pre-trained embeddings, such as RoBERTa, outperform the state-of-the-art
emotion cause extraction approaches

Conclusion: We introduce a new task highly relevant for (explainable)
emotion-aware artificial intelligence: recognizing emotion cause in
conversations, provide a new highly challenging publicly available
dialogue-level dataset for this task, and give strong baseline results on this
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Applying Occam&#x27;s Razor to Transformer-Based Dependency Parsing: What Works, What Doesn&#x27;t, and What is Really Necessary. (arXiv:2010.12699v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grunewald_S/0/1/0/all/0/1">Stefan Gr&#xfc;newald</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrich_A/0/1/0/all/0/1">Annemarie Friedrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuhn_J/0/1/0/all/0/1">Jonas Kuhn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12699">
                                    <div class="article-summary-box-inner">
                                        <span>The introduction of pre-trained transformer-based contextualized word
embeddings has led to considerable improvements in the accuracy of graph-based
parsers for frameworks such as Universal Dependencies (UD). However, previous
works differ in various dimensions, including their choice of pre-trained
language models and whether they use LSTM layers. With the aims of
disentangling the effects of these choices and identifying a simple yet widely
applicable architecture, we introduce STEPS, a new modular graph-based
dependency parser. Using STEPS, we perform a series of analyses on the UD
corpora of a diverse set of languages. We find that the choice of pre-trained
embeddings has by far the greatest impact on parser performance and identify
XLM-R as a robust choice across the languages in our study. Adding LSTM layers
provides no benefits when using transformer-based embeddings. A multi-task
training setup outputting additional UD features may contort results. Taking
these insights together, we propose a simple but widely applicable parser
architecture and configuration, achieving new state-of-the-art results (in
terms of LAS) for 10 out of 12 diverse languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rare Disease Identification from Clinical Notes with Ontologies and Weak Supervision. (arXiv:2105.01995v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Hang Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Suarez_Paniagua_V/0/1/0/all/0/1">V&#xed;ctor Su&#xe1;rez-Paniagua</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huayu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Minhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitfield_E/0/1/0/all/0/1">Emma Whitfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Honghan Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01995">
                                    <div class="article-summary-box-inner">
                                        <span>The identification of rare diseases from clinical notes with Natural Language
Processing (NLP) is challenging due to the few cases available for machine
learning and the need of data annotation from clinical experts. We propose a
method using ontologies and weak supervision. The approach includes two steps:
(i) Text-to-UMLS, linking text mentions to concepts in Unified Medical Language
System (UMLS), with a named entity linking tool (e.g. SemEHR) and weak
supervision based on customised rules and Bidirectional Encoder Representations
from Transformers (BERT) based contextual representations, and (ii)
UMLS-to-ORDO, matching UMLS concepts to rare diseases in Orphanet Rare Disease
Ontology (ORDO). Using MIMIC-III US intensive care discharge summaries as a
case study, we show that the Text-to-UMLS process can be greatly improved with
weak supervision, without any annotated data from domain experts. Our analysis
shows that the overall pipeline processing discharge summaries can surface rare
disease cases, which are mostly uncaptured in manual ICD codes of the hospital
admissions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Translatotron 2: Robust direct speech-to-speech translation. (arXiv:2107.08661v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Ye Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanovich_M/0/1/0/all/0/1">Michelle Tadmor Ramanovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1">Tal Remez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pomerantz_R/0/1/0/all/0/1">Roi Pomerantz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08661">
                                    <div class="article-summary-box-inner">
                                        <span>We present Translatotron 2, a neural direct speech-to-speech translation
model that can be trained end-to-end. Translatotron 2 consists of a speech
encoder, a phoneme decoder, a mel-spectrogram synthesizer, and an attention
module that connects all the previous three components. Experimental results
suggest that Translatotron 2 outperforms the original Translatotron by a large
margin in terms of translation quality and predicted speech naturalness, and
drastically improves the robustness of the predicted speech by mitigating
over-generation, such as babbling or long pause. We also propose a new method
for retaining the source speaker&#x27;s voice in the translated speech. The trained
model is restricted to retain the source speaker&#x27;s voice, and unlike the
original Translatotron, it is not able to generate speech in a different
speaker&#x27;s voice, making the model more robust for production deployment, by
mitigating potential misuse for creating spoofing audio artifacts. When the new
method is used together with a simple concatenation-based data augmentation,
the trained Translatotron 2 model is able to retain each speaker&#x27;s voice for
input with speaker turns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demystifying Neural Language Models&#x27; Insensitivity to Word-Order. (arXiv:2107.13955v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Clouatre_L/0/1/0/all/0/1">Louis Clouatre</a>, <a href="http://arxiv.org/find/cs/1/au:+Parthasarathi_P/0/1/0/all/0/1">Prasanna Parthasarathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zouaq_A/0/1/0/all/0/1">Amal Zouaq</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1">Sarath Chandar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13955">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research analyzing the sensitivity of natural language understanding
models to word-order perturbations have shown that the state-of-the-art models
in several language tasks may have a unique way to understand the text that
could seldom be explained with conventional syntax and semantics. In this
paper, we investigate the insensitivity of natural language models to
word-order by quantifying perturbations and analysing their effect on neural
models&#x27; performance on language understanding tasks in GLUE benchmark. Towards
that end, we propose two metrics - the Direct Neighbour Displacement (DND) and
the Index Displacement Count (IDC) - that score the local and global ordering
of tokens in the perturbed texts and observe that perturbation functions found
in prior literature affect only the global ordering while the local ordering
remains relatively unperturbed. We propose perturbations at the granularity of
sub-words and characters to study the correlation between DND, IDC and the
performance of neural language models on natural language tasks. We find that
neural language models - pretrained and non-pretrained Transformers, LSTMs, and
Convolutional architectures - require local ordering more so than the global
ordering of tokens. The proposed metrics and the suite of perturbations allow a
systematic way to study the (in)sensitivity of neural language understanding
models to varying degree of perturbations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Term Expansion and FinBERT fine-tuning for Hypernym and Synonym Ranking of Financial Terms. (arXiv:2107.13764v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chopra_A/0/1/0/all/0/1">Ankush Chopra</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Sohom Ghosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13764">
                                    <div class="article-summary-box-inner">
                                        <span>Hypernym and synonym matching are one of the mainstream Natural Language
Processing (NLP) tasks. In this paper, we present systems that attempt to solve
this problem. We designed these systems to participate in the FinSim-3, a
shared task of FinNLP workshop at IJCAI-2021. The shared task is focused on
solving this problem for the financial domain. We experimented with various
transformer based pre-trained embeddings by fine-tuning these for either
classification or phrase similarity tasks. We also augmented the provided
dataset with abbreviations derived from prospectus provided by the organizers
and definitions of the financial terms from DBpedia [Auer et al., 2007],
Investopedia, and the Financial Industry Business Ontology (FIBO). Our best
performing system uses both FinBERT [Araci, 2019] and data augmentation from
the afore-mentioned sources. We observed that term expansion using data
augmentation in conjunction with semantic similarity is beneficial for this
task and could be useful for the other tasks that deal with short phrases. Our
best performing model (Accuracy: 0.917, Rank: 1.156) was developed by
fine-tuning SentenceBERT [Reimers et al., 2019] (with FinBERT at the backend)
over an extended labelled set created using the hierarchy of labels present in
FIBO.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Direct multimodal few-shot learning of speech and images. (arXiv:2012.05680v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nortje_L/0/1/0/all/0/1">Leanne Nortje</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1">Herman Kamper</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05680">
                                    <div class="article-summary-box-inner">
                                        <span>We propose direct multimodal few-shot models that learn a shared embedding
space of spoken words and images from only a few paired examples. Imagine an
agent is shown an image along with a spoken word describing the object in the
picture, e.g. pen, book and eraser. After observing a few paired examples of
each class, the model is asked to identify the &quot;book&quot; in a set of unseen
pictures. Previous work used a two-step indirect approach relying on learned
unimodal representations: speech-speech and image-image comparisons are
performed across the support set of given speech-image pairs. We propose two
direct models which instead learn a single multimodal space where inputs from
different modalities are directly comparable: a multimodal triplet network
(MTriplet) and a multimodal correspondence autoencoder (MCAE). To train these
direct models, we mine speech-image pairs: the support set is used to pair up
unlabelled in-domain speech and images. In a speech-to-image digit matching
task, direct models outperform indirect models, with the MTriplet achieving the
best multimodal five-shot accuracy. We show that the improvements are due to
the combination of unsupervised and transfer learning in the direct models, and
the absence of two-step compounding errors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CogniFNN: A Fuzzy Neural Network Framework for Cognitive Word Embedding Evaluation. (arXiv:2009.11485v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xinping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1">Zehong Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_S/0/1/0/all/0/1">Son Tran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.11485">
                                    <div class="article-summary-box-inner">
                                        <span>Word embeddings can reflect the semantic representations, and the embedding
qualities can be comprehensively evaluated with human natural reading-related
cognitive data sources. In this paper, we proposed the CogniFNN framework,
which is the first attempt at using fuzzy neural networks to extract non-linear
and non-stationary characteristics for evaluations of English word embeddings
against the corresponding cognitive datasets. In our experiment, we used 15
human cognitive datasets across three modalities: EEG, fMRI, and eye-tracking,
and selected the mean square error and multiple hypotheses testing as metrics
to evaluate our proposed CogniFNN framework. Compared to the recent pioneer
framework, our proposed CogniFNN showed smaller prediction errors of both
context-independent (GloVe) and context-sensitive (BERT) word embeddings, and
achieved higher significant ratios with randomly generated word embeddings. Our
findings suggested that the CogniFNN framework could provide a more accurate
and comprehensive evaluation of cognitive word embeddings. It will potentially
be beneficial to the further word embeddings evaluation on extrinsic natural
language processing tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. (arXiv:2107.13586v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Weizhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jinlan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhengbao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_H/0/1/0/all/0/1">Hiroaki Hayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13586">
                                    <div class="article-summary-box-inner">
                                        <span>This paper surveys and organizes research works in a new paradigm in natural
language processing, which we dub &quot;prompt-based learning&quot;. Unlike traditional
supervised learning, which trains a model to take in an input x and predict an
output y as P(y|x), prompt-based learning is based on language models that
model the probability of text directly. To use these models to perform
prediction tasks, the original input x is modified using a template into a
textual string prompt x&#x27; that has some unfilled slots, and then the language
model is used to probabilistically fill the unfilled information to obtain a
final string x, from which the final output y can be derived. This framework is
powerful and attractive for a number of reasons: it allows the language model
to be pre-trained on massive amounts of raw text, and by defining a new
prompting function the model is able to perform few-shot or even zero-shot
learning, adapting to new scenarios with few or no labeled data. In this paper
we introduce the basics of this promising paradigm, describe a unified set of
mathematical notations that can cover a wide variety of existing work, and
organize existing work along several dimensions, e.g.the choice of pre-trained
models, prompts, and tuning strategies. To make the field more accessible to
interested beginners, we not only make a systematic review of existing works
and a highly structured typology of prompt-based concepts, but also release
other resources, e.g., a website this http URL including
constantly-updated survey, and paperlist.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoTinyBERT: Automatic Hyper-parameter Optimization for Efficient Pre-trained Language Models. (arXiv:2107.13686v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yichun Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Cheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1">Lifeng Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13686">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained language models (PLMs) have achieved great success in natural
language processing. Most of PLMs follow the default setting of architecture
hyper-parameters (e.g., the hidden dimension is a quarter of the intermediate
dimension in feed-forward sub-networks) in BERT (Devlin et al., 2019). Few
studies have been conducted to explore the design of architecture
hyper-parameters in BERT, especially for the more efficient PLMs with tiny
sizes, which are essential for practical deployment on resource-constrained
devices. In this paper, we adopt the one-shot Neural Architecture Search (NAS)
to automatically search architecture hyper-parameters. Specifically, we
carefully design the techniques of one-shot learning and the search space to
provide an adaptive and efficient development way of tiny PLMs for various
latency constraints. We name our method AutoTinyBERT and evaluate its
effectiveness on the GLUE and SQuAD benchmarks. The extensive experiments show
that our method outperforms both the SOTA search-based baseline (NAS-BERT) and
the SOTA distillation-based methods (such as DistilBERT, TinyBERT, MiniLM and
MobileBERT). In addition, based on the obtained architectures, we propose a
more efficient development method that is even faster than the development of a
single PLM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain-matched Pre-training Tasks for Dense Retrieval. (arXiv:2107.13602v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1">Barlas O&#x11f;uz</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakhotia_K/0/1/0/all/0/1">Kushal Lakhotia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Anchit Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_P/0/1/0/all/0/1">Patrick Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Karpukhin_V/0/1/0/all/0/1">Vladimir Karpukhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Piktus_A/0/1/0/all/0/1">Aleksandra Piktus</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xilun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1">Sebastian Riedel</a>, <a href="http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1">Wen-tau Yih</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Sonal Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1">Yashar Mehdad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13602">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-training on larger datasets with ever increasing model size is now a
proven recipe for increased performance across almost all NLP tasks. A notable
exception is information retrieval, where additional pre-training has so far
failed to produce convincing results. We show that, with the right pre-training
setup, this barrier can be overcome. We demonstrate this by pre-training large
bi-encoder models on 1) a recently released set of 65 million synthetically
generated questions, and 2) 200 million post-comment pairs from a preexisting
dataset of Reddit conversations made available by pushshift.io. We evaluate on
a set of information retrieval and dialogue retrieval benchmarks, showing
substantial improvements over supervised baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating Text Simplification Evaluation. (arXiv:2107.13662v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vasquez_Rodriguez_L/0/1/0/all/0/1">Laura V&#xe1;squez-Rodr&#xed;guez</a>, <a href="http://arxiv.org/find/cs/1/au:+Shardlow_M/0/1/0/all/0/1">Matthew Shardlow</a>, <a href="http://arxiv.org/find/cs/1/au:+Przybyla_P/0/1/0/all/0/1">Piotr Przyby&#x142;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Ananiadou_S/0/1/0/all/0/1">Sophia Ananiadou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13662">
                                    <div class="article-summary-box-inner">
                                        <span>Modern text simplification (TS) heavily relies on the availability of gold
standard data to build machine learning models. However, existing studies show
that parallel TS corpora contain inaccurate simplifications and incorrect
alignments. Additionally, evaluation is usually performed by using metrics such
as BLEU or SARI to compare system output to the gold standard. A major
limitation is that these metrics do not match human judgements and the
performance on different datasets and linguistic phenomena vary greatly.
Furthermore, our research shows that the test and training subsets of parallel
datasets differ significantly. In this work, we investigate existing TS
corpora, providing new insights that will motivate the improvement of existing
state-of-the-art TS evaluation methods. Our contributions include the analysis
of TS corpora based on existing modifications used for simplification and an
empirical study on TS models performance by using better-distributed datasets.
We demonstrate that by improving the distribution of TS datasets, we can build
more robust TS models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Abusive Albanian. (arXiv:2107.13592v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nurce_E/0/1/0/all/0/1">Erida Nurce</a>, <a href="http://arxiv.org/find/cs/1/au:+Keci_J/0/1/0/all/0/1">Jorgel Keci</a>, <a href="http://arxiv.org/find/cs/1/au:+Derczynski_L/0/1/0/all/0/1">Leon Derczynski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13592">
                                    <div class="article-summary-box-inner">
                                        <span>The ever growing usage of social media in the recent years has had a direct
impact on the increased presence of hate speech and offensive speech in online
platforms. Research on effective detection of such content has mainly focused
on English and a few other widespread languages, while the leftover majority
fail to have the same work put into them and thus cannot benefit from the
steady advancements made in the field. In this paper we present \textsc{Shaj},
an annotated Albanian dataset for hate speech and offensive speech that has
been constructed from user-generated content on various social media platforms.
Its annotation follows the hierarchical schema introduced in OffensEval. The
dataset is tested using three different classification models, the best of
which achieves an F1 score of 0.77 for the identification of offensive
language, 0.64 F1 score for the automatic categorization of offensive types and
lastly, 0.52 F1 score for the offensive language target identification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Progressive Correspondence Pruning by Consensus Learning. (arXiv:2101.00591v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yixiao Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Feng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1">Rui Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1">Mathieu Salzmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00591">
                                    <div class="article-summary-box-inner">
                                        <span>Correspondence selection aims to correctly select the consistent matches
(inliers) from an initial set of putative correspondences. The selection is
challenging since putative matches are typically extremely unbalanced, largely
dominated by outliers, and the random distribution of such outliers further
complicates the learning process for learning-based methods. To address this
issue, we propose to progressively prune the correspondences via a
local-to-global consensus learning procedure. We introduce a &#x60;&#x60;pruning&#x27;&#x27; block
that lets us identify reliable candidates among the initial matches according
to consensus scores estimated using local-to-global dynamic graphs. We then
achieve progressive pruning by stacking multiple pruning blocks sequentially.
Our method outperforms state-of-the-arts on robust line fitting, camera pose
estimation and retrieval-based image localization benchmarks by significant
margins and shows promising generalization ability to different datasets and
detector/descriptor combinations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-Fine for Sim-to-Real: Sub-Millimetre Precision Across Wide Task Spaces. (arXiv:2105.11283v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Valassakis_E/0/1/0/all/0/1">Eugene Valassakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Palo_N/0/1/0/all/0/1">Norman Di Palo</a>, <a href="http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1">Edward Johns</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11283">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the problem of zero-shot sim-to-real when the task
requires both highly precise control with sub-millimetre error tolerance, and
wide task space generalisation. Our framework involves a coarse-to-fine
controller, where trajectories begin with classical motion planning using
ICP-based pose estimation, and transition to a learned end-to-end controller
which maps images to actions and is trained in simulation with domain
randomisation. In this way, we achieve precise control whilst also generalising
the controller across wide task spaces, and keeping the robustness of
vision-based, end-to-end control. Real-world experiments on a range of
different tasks show that, by exploiting the best of both worlds, our framework
significantly outperforms purely motion planning methods, and purely
learning-based methods. Furthermore, we answer a range of questions on best
practices for precise sim-to-real transfer, such as how different image sensor
modalities and image feature representations perform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning with Noisy Labels for Robust Point Cloud Segmentation. (arXiv:2107.14230v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1">Shuquan Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dongdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Songfang Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_J/0/1/0/all/0/1">Jing Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14230">
                                    <div class="article-summary-box-inner">
                                        <span>Point cloud segmentation is a fundamental task in 3D. Despite recent progress
on point cloud segmentation with the power of deep networks, current deep
learning methods based on the clean label assumptions may fail with noisy
labels. Yet, object class labels are often mislabeled in real-world point cloud
datasets. In this work, we take the lead in solving this issue by proposing a
novel Point Noise-Adaptive Learning (PNAL) framework. Compared to existing
noise-robust methods on image tasks, our PNAL is noise-rate blind, to cope with
the spatially variant noise rate problem specific to point clouds.
Specifically, we propose a novel point-wise confidence selection to obtain
reliable labels based on the historical predictions of each point. A novel
cluster-wise label correction is proposed with a voting strategy to generate
the best possible label taking the neighbor point correlations into
consideration. We conduct extensive experiments to demonstrate the
effectiveness of PNAL on both synthetic and real-world noisy datasets. In
particular, even with $60\%$ symmetric noisy labels, our proposed method
produces much better results than its baseline counterpart without PNAL and is
comparable to the ideal upper bound trained on a completely clean dataset.
Moreover, we fully re-labeled the test set of a popular but noisy real-world
scene dataset ScanNetV2 to make it clean, for rigorous experiment and future
research. Our code and data will be available at
\url{https://shuquanye.com/PNAL_website/}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Underwater inspection and intervention dataset. (arXiv:2107.13628v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luczynski_T/0/1/0/all/0/1">Tomasz Luczynski</a>, <a href="http://arxiv.org/find/cs/1/au:+Willners_J/0/1/0/all/0/1">Jonatan Scharff Willners</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_E/0/1/0/all/0/1">Elizabeth Vargas</a>, <a href="http://arxiv.org/find/cs/1/au:+Roe_J/0/1/0/all/0/1">Joshua Roe</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shida Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Petillot_Y/0/1/0/all/0/1">Yvan Petillot</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sen Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13628">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel dataset for the development of visual navigation
and simultaneous localisation and mapping (SLAM) algorithms as well as for
underwater intervention tasks. It differs from existing datasets as it contains
ground truth for the vehicle&#x27;s position captured by an underwater motion
tracking system. The dataset contains distortion-free and rectified stereo
images along with the calibration parameters of the stereo camera setup.
Furthermore, the experiments were performed and recorded in a controlled
environment, where current and waves could be generated allowing the dataset to
cover a wide range of conditions - from calm water to waves and currents of
significant strength.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">United We Learn Better: Harvesting Learning Improvements From Class Hierarchies Across Tasks. (arXiv:2107.13627v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shkodrani_S/0/1/0/all/0/1">Sindi Shkodrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Manfredi_M/0/1/0/all/0/1">Marco Manfredi</a>, <a href="http://arxiv.org/find/cs/1/au:+Baka_N/0/1/0/all/0/1">N&#xf3;ra Baka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13627">
                                    <div class="article-summary-box-inner">
                                        <span>Attempts of learning from hierarchical taxonomies in computer vision have
been mostly focusing on image classification. Though ways of best harvesting
learning improvements from hierarchies in classification are far from being
solved, there is a need to target these problems in other vision tasks such as
object detection. As progress on the classification side is often dependent on
hierarchical cross-entropy losses, novel detection architectures using sigmoid
as an output function instead of softmax cannot easily apply these advances,
requiring novel methods in detection. In this work we establish a theoretical
framework based on probability and set theory for extracting parent predictions
and a hierarchical loss that can be used across tasks, showing results across
classification and detection benchmarks and opening up the possibility of
hierarchical learning for sigmoid-based detection architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic and Geometric Depth: Detecting Objects in Perspective. (arXiv:2107.14160v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xinge Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jiangmiao Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14160">
                                    <div class="article-summary-box-inner">
                                        <span>3D object detection is an important capability needed in various practical
applications such as driver assistance systems. Monocular 3D detection, as an
economical solution compared to conventional settings relying on binocular
vision or LiDAR, has drawn increasing attention recently but still yields
unsatisfactory results. This paper first presents a systematic study on this
problem and observes that the current monocular 3D detection problem can be
simplified as an instance depth estimation problem: The inaccurate instance
depth blocks all the other 3D attribute predictions from improving the overall
detection performance. However, recent methods directly estimate the depth
based on isolated instances or pixels while ignoring the geometric relations
across different objects, which can be valuable constraints as the key
information about depth is not directly manifest in the monocular image.
Therefore, we construct geometric relation graphs across predicted objects and
use the graph to facilitate depth estimation. As the preliminary depth
estimation of each instance is usually inaccurate in this ill-posed setting, we
incorporate a probabilistic representation to capture the uncertainty. It
provides an important indicator to identify confident predictions and further
guide the depth propagation. Despite the simplicity of the basic idea, our
method obtains significant improvements on KITTI and nuScenes benchmarks,
achieving the 1st place out of all monocular vision-only methods while still
maintaining real-time efficiency. Code and models will be released at
https://github.com/open-mmlab/mmdetection3d.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-shot action recognition in challenging therapy scenarios. (arXiv:2102.08997v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sabater_A/0/1/0/all/0/1">Alberto Sabater</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_L/0/1/0/all/0/1">Laura Santos</a>, <a href="http://arxiv.org/find/cs/1/au:+Santos_Victor_J/0/1/0/all/0/1">Jose Santos-Victor</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernardino_A/0/1/0/all/0/1">Alexandre Bernardino</a>, <a href="http://arxiv.org/find/cs/1/au:+Montesano_L/0/1/0/all/0/1">Luis Montesano</a>, <a href="http://arxiv.org/find/cs/1/au:+Murillo_A/0/1/0/all/0/1">Ana C. Murillo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08997">
                                    <div class="article-summary-box-inner">
                                        <span>One-shot action recognition aims to recognize new action categories from a
single reference example, typically referred to as the anchor example. This
work presents a novel approach for one-shot action recognition in the wild that
computes motion representations robust to variable kinematic conditions.
One-shot action recognition is then performed by evaluating anchor and target
motion representations. We also develop a set of complementary steps that boost
the action recognition performance in the most challenging scenarios. Our
approach is evaluated on the public NTU-120 one-shot action recognition
benchmark, outperforming previous action recognition models. Besides, we
evaluate our framework on a real use-case of therapy with autistic people.
These recordings are particularly challenging due to high-level artifacts from
the patient motion. Our results provide not only quantitative but also online
qualitative measures, essential for the patient evaluation and monitoring
during the actual therapy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RigNet: Repetitive Image Guided Network for Depth Completion. (arXiv:2107.13802v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhiqiang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhenyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1">Baobei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jian Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13802">
                                    <div class="article-summary-box-inner">
                                        <span>Depth completion deals with the problem of recovering dense depth maps from
sparse ones, where color images are often used to facilitate this completion.
Recent approaches mainly focus on image guided learning to predict dense
results. However, blurry image guidance and object structures in depth still
impede the performance of image guided frameworks. To tackle these problems, we
explore a repetitive design in our image guided network to sufficiently and
gradually recover depth values. Specifically, the repetition is embodied in a
color image guidance branch and a depth generation branch. In the former
branch, we design a repetitive hourglass network to extract higher-level image
features of complex environments, which can provide powerful context guidance
for depth prediction. In the latter branch, we design a repetitive guidance
module based on dynamic convolution where the convolution factorization is
applied to simultaneously reduce its complexity and progressively model
high-frequency structures, e.g., boundaries. Further, in this module, we
propose an adaptive fusion mechanism to effectively aggregate multi-step depth
features. Extensive experiments show that our method achieves state-of-the-art
result on the NYUv2 dataset and ranks 1st on the KITTI benchmark at the time of
submission.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VMNet: Voxel-Mesh Network for Geodesic-Aware 3D Semantic Segmentation. (arXiv:2107.13824v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zeyu Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xuyang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1">Jiaxiang Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Runze Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jiayu Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_G/0/1/0/all/0/1">Guangyuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1">Hongbo Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_C/0/1/0/all/0/1">Chiew-Lan Tai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13824">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, sparse voxel-based methods have become the state-of-the-arts
for 3D semantic segmentation of indoor scenes, thanks to the powerful 3D CNNs.
Nevertheless, being oblivious to the underlying geometry, voxel-based methods
suffer from ambiguous features on spatially close objects and struggle with
handling complex and irregular geometries due to the lack of geodesic
information. In view of this, we present Voxel-Mesh Network (VMNet), a novel 3D
deep architecture that operates on the voxel and mesh representations
leveraging both the Euclidean and geodesic information. Intuitively, the
Euclidean information extracted from voxels can offer contextual cues
representing interactions between nearby objects, while the geodesic
information extracted from meshes can help separate objects that are spatially
close but have disconnected surfaces. To incorporate such information from the
two domains, we design an intra-domain attentive module for effective feature
aggregation and an inter-domain attentive module for adaptive feature fusion.
Experimental results validate the effectiveness of VMNet: specifically, on the
challenging ScanNet dataset for large-scale segmentation of indoor scenes, it
outperforms the state-of-the-art SparseConvNet and MinkowskiNet (74.6% vs 72.5%
and 73.6% in mIoU) with a simpler network structure (17M vs 30M and 38M
parameters). Code release: https://github.com/hzykent/VMNet</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FATNN: Fast and Accurate Ternary Neural Networks. (arXiv:2008.05101v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Peng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1">Bohan Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.05101">
                                    <div class="article-summary-box-inner">
                                        <span>Ternary Neural Networks (TNNs) have received much attention due to being
potentially orders of magnitude faster in inference, as well as more power
efficient, than full-precision counterparts. However, 2 bits are required to
encode the ternary representation with only 3 quantization levels leveraged. As
a result, conventional TNNs have similar memory consumption and speed compared
with the standard 2-bit models, but have worse representational capability.
Moreover, there is still a significant gap in accuracy between TNNs and
full-precision networks, hampering their deployment to real applications. To
tackle these two challenges, in this work, we first show that, under some mild
constraints, computational complexity of the ternary inner product can be
reduced by a factor of 2. Second, to mitigate the performance gap, we
elaborately design an implementation-dependent ternary quantization algorithm.
The proposed framework is termed Fast and Accurate Ternary Neural Networks
(FATNN). Experiments on image classification demonstrate that our FATNN
surpasses the state-of-the-arts by a significant margin in accuracy. More
importantly, speedup evaluation compared with various precisions is analyzed on
several platforms, which serves as a strong benchmark for further research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Object Recognition in Indoor Environments Using Topologically Persistent Features. (arXiv:2010.03196v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samani_E/0/1/0/all/0/1">Ekta U. Samani</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xingjian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1">Ashis G. Banerjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03196">
                                    <div class="article-summary-box-inner">
                                        <span>Object recognition in unseen indoor environments remains a challenging
problem for visual perception of mobile robots. In this letter, we propose the
use of topologically persistent features, which rely on the objects&#x27; shape
information, to address this challenge. In particular, we extract two kinds of
features, namely, sparse persistence image (PI) and amplitude, by applying
persistent homology to multi-directional height function-based filtrations of
the cubical complexes representing the object segmentation maps. The features
are then used to train a fully connected network for recognition. For
performance evaluation, in addition to a widely used shape dataset and a
benchmark indoor scenes dataset, we collect a new dataset, comprising scene
images from two different environments, namely, a living room and a mock
warehouse. The scenes are captured using varying camera poses under different
illumination conditions and include up to five different objects from a given
set of fourteen objects. On the benchmark indoor scenes dataset, sparse PI
features show better recognition performance in unseen environments than the
features learned using the widely used ResNetV2-56 and EfficientNet-B4 models.
Further, they provide slightly higher recall and accuracy values than Faster
R-CNN, an end-to-end object detection method, and its state-of-the-art variant,
Domain Adaptive Faster R-CNN. The performance of our methods also remains
relatively unchanged from the training environment (living room) to the unseen
environment (mock warehouse) in the new dataset. In contrast, the performance
of the object detection methods drops substantially. We also implement the
proposed method on a real-world robot to demonstrate its usefulness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">P2-Net: Joint Description and Detection of Local Features for Pixel and Point Matching. (arXiv:2103.01055v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Changhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zhaopeng Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jie Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chris Xiaoxuan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhengdi Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peijun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1">Zhen Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Fan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Trigoni_N/0/1/0/all/0/1">Niki Trigoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Markham_A/0/1/0/all/0/1">Andrew Markham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01055">
                                    <div class="article-summary-box-inner">
                                        <span>Accurately describing and detecting 2D and 3D keypoints is crucial to
establishing correspondences across images and point clouds. Despite a plethora
of learning-based 2D or 3D local feature descriptors and detectors having been
proposed, the derivation of a shared descriptor and joint keypoint detector
that directly matches pixels and points remains under-explored by the
community. This work takes the initiative to establish fine-grained
correspondences between 2D images and 3D point clouds. In order to directly
match pixels and points, a dual fully convolutional framework is presented that
maps 2D and 3D inputs into a shared latent representation space to
simultaneously describe and detect keypoints. Furthermore, an ultra-wide
reception mechanism in combination with a novel loss function are designed to
mitigate the intrinsic information variations between pixel and point local
regions. Extensive experimental results demonstrate that our framework shows
competitive performance in fine-grained matching between images and point
clouds and achieves state-of-the-art results for the task of indoor visual
localization. Our source code will be available at [no-name-for-blind-review].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Walk in the Cloud: Learning Curves for Point Clouds Shape Analysis. (arXiv:2105.01288v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tiange Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chaoyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jianhui Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Weidong Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01288">
                                    <div class="article-summary-box-inner">
                                        <span>Discrete point cloud objects lack sufficient shape descriptors of 3D
geometries. In this paper, we present a novel method for aggregating
hypothetical curves in point clouds. Sequences of connected points (curves) are
initially grouped by taking guided walks in the point clouds, and then
subsequently aggregated back to augment their point-wise features. We provide
an effective implementation of the proposed aggregation strategy including a
novel curve grouping operator followed by a curve aggregation operator. Our
method was benchmarked on several point cloud analysis tasks where we achieved
the state-of-the-art classification accuracy of 94.2% on the ModelNet40
classification task, instance IoU of 86.8 on the ShapeNetPart segmentation
task, and cosine error of 0.11 on the ModelNet40 normal estimation task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Monocular 3D Human Pose Estimation with Normalizing Flows. (arXiv:2107.13788v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wehrbein_T/0/1/0/all/0/1">Tom Wehrbein</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudolph_M/0/1/0/all/0/1">Marco Rudolph</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosenhahn_B/0/1/0/all/0/1">Bodo Rosenhahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Wandt_B/0/1/0/all/0/1">Bastian Wandt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13788">
                                    <div class="article-summary-box-inner">
                                        <span>3D human pose estimation from monocular images is a highly ill-posed problem
due to depth ambiguities and occlusions. Nonetheless, most existing works
ignore these ambiguities and only estimate a single solution. In contrast, we
generate a diverse set of hypotheses that represents the full posterior
distribution of feasible 3D poses. To this end, we propose a normalizing flow
based method that exploits the deterministic 3D-to-2D mapping to solve the
ambiguous inverse 2D-to-3D problem. Additionally, uncertain detections and
occlusions are effectively modeled by incorporating uncertainty information of
the 2D detector as condition. Further keys to success are a learned 3D pose
prior and a generalization of the best-of-M loss. We evaluate our approach on
the two benchmark datasets Human3.6M and MPI-INF-3DHP, outperforming all
comparable methods in most metrics. The implementation is available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CI-Net: Contextual Information for Joint Semantic Segmentation and Depth Estimation. (arXiv:2107.13800v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1">Tianxiao Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhongbin Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Z/0/1/0/all/0/1">Zhun Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Shane Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinmei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qiuda Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13800">
                                    <div class="article-summary-box-inner">
                                        <span>Monocular depth estimation and semantic segmentation are two fundamental
goals of scene understanding. Due to the advantages of task interaction, many
works study the joint task learning algorithm. However, most existing methods
fail to fully leverage the semantic labels, ignoring the provided context
structures and only using them to supervise the prediction of segmentation
split. In this paper, we propose a network injected with contextual information
(CI-Net) to solve the problem. Specifically, we introduce self-attention block
in the encoder to generate attention map. With supervision from the ground
truth created by semantic labels, the network is embedded with contextual
information so that it could understand the scene better, utilizing dependent
features to make accurate prediction. Besides, a feature sharing module is
constructed to make the task-specific features deeply fused and a consistency
loss is devised to make the features mutually guided. We evaluate the proposed
CI-Net on the NYU-Depth-v2 and SUN-RGBD datasets. The experimental results
validate that our proposed CI-Net is competitive with the state-of-the-arts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anchor-Based Spatio-Temporal Attention 3D Convolutional Networks for Dynamic 3D Point Cloud Sequences. (arXiv:2012.10860v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guangming Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Muyao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hanwen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yehui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hesheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10860">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of measurement technology, LiDAR and depth cameras
are widely used in the perception of the 3D environment. Recent learning based
methods for robot perception most focus on the image or video, but deep
learning methods for dynamic 3D point cloud sequences are underexplored.
Therefore, developing efficient and accurate perception method compatible with
these advanced instruments is pivotal to autonomous driving and service robots.
An Anchor-based Spatio-Temporal Attention 3D Convolution operation (ASTA3DConv)
is proposed in this paper to process dynamic 3D point cloud sequences. The
proposed convolution operation builds a regular receptive field around each
point by setting several virtual anchors around each point. The features of
neighborhood points are firstly aggregated to each anchor based on the
spatio-temporal attention mechanism. Then, anchor-based 3D convolution is
adopted to aggregate these anchors&#x27; features to the core points. The proposed
method makes better use of the structured information within the local region
and learns spatio-temporal embedding features from dynamic 3D point cloud
sequences. Anchor-based Spatio-Temporal Attention 3D Convolutional Neural
Networks (ASTA3DCNNs) are built for classification and segmentation tasks based
on the proposed ASTA3DConv and evaluated on action recognition and semantic
segmentation tasks. The experiments and ablation studies on MSRAction3D and
Synthia datasets demonstrate the superior performance and effectiveness of our
method for dynamic 3D point cloud sequences. Our method achieves the
state-of-the-art performance among the methods with dynamic 3D point cloud
sequences as input on MSRAction3D and Synthia datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">InstanceRefer: Cooperative Holistic Understanding for Visual Grounding on Point Clouds through Instance Multi-level Contextual Referring. (arXiv:2103.01128v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zhihao Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xu Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yinghong Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruimao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01128">
                                    <div class="article-summary-box-inner">
                                        <span>Compared with the visual grounding on 2D images, the natural-language-guided
3D object localization on point clouds is more challenging. In this paper, we
propose a new model, named InstanceRefer, to achieve a superior 3D visual
grounding through the grounding-by-matching strategy. In practice, our model
first predicts the target category from the language descriptions using a
simple language classification model. Then, based on the category, our model
sifts out a small number of instance candidates (usually less than 20) from the
panoptic segmentation of point clouds. Thus, the non-trivial 3D visual
grounding task has been effectively re-formulated as a simplified
instance-matching problem, considering that instance-level candidates are more
rational than the redundant 3D object proposals. Subsequently, for each
candidate, we perform the multi-level contextual inference, i.e., referring
from instance attribute perception, instance-to-instance relation perception,
and instance-to-background global localization perception, respectively.
Eventually, the most relevant candidate is selected and localized by ranking
confidence scores, which are obtained by the cooperative holistic
visual-language feature matching. Experiments confirm that our method
outperforms previous state-of-the-arts on ScanRefer online benchmark and
Nr3D/Sr3D datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RaidaR: A Rich Annotated Image Dataset of Rainy Street Scenes. (arXiv:2104.04606v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Jiongchao Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Fatemi_A/0/1/0/all/0/1">Arezou Fatemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lira_W/0/1/0/all/0/1">Wallace Lira</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fenggen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Leng_B/0/1/0/all/0/1">Biao Leng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1">Rui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahdavi_Amiri_A/0/1/0/all/0/1">Ali Mahdavi-Amiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04606">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce RaidaR, a rich annotated image dataset of rainy street scenes,
to support autonomous driving research. The new dataset contains the largest
number of rainy images (58,542) to date, 5,000 of which provide semantic
segmentations and 3,658 provide object instance segmentations. The RaidaR
images cover a wide range of realistic rain-induced artifacts, including fog,
droplets, and road reflections, which can effectively augment existing street
scene datasets to improve data-driven machine perception during rainy weather.
To facilitate efficient annotation of a large volume of images, we develop a
semi-automatic scheme combining manual segmentation and an automated processing
akin to cross validation, resulting in 10-20 fold reduction on annotation time.
We demonstrate the utility of our new dataset by showing how data augmentation
with RaidaR can elevate the accuracy of existing segmentation algorithms. We
also present a novel unpaired image-to-image translation algorithm for
adding/removing rain artifacts, which directly benefits from RaidaR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Embeddings for Few-Shot Open World Recognition. (arXiv:2107.13682v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Willes_J/0/1/0/all/0/1">John Willes</a>, <a href="http://arxiv.org/find/cs/1/au:+Harrison_J/0/1/0/all/0/1">James Harrison</a>, <a href="http://arxiv.org/find/cs/1/au:+Harakeh_A/0/1/0/all/0/1">Ali Harakeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1">Marco Pavone</a>, <a href="http://arxiv.org/find/cs/1/au:+Waslander_S/0/1/0/all/0/1">Steven Waslander</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13682">
                                    <div class="article-summary-box-inner">
                                        <span>As autonomous decision-making agents move from narrow operating environments
to unstructured worlds, learning systems must move from a closed-world
formulation to an open-world and few-shot setting in which agents continuously
learn new classes from small amounts of information. This stands in stark
contrast to modern machine learning systems that are typically designed with a
known set of classes and a large number of examples for each class. In this
work we extend embedding-based few-shot learning algorithms to the open-world
recognition setting. We combine Bayesian non-parametric class priors with an
embedding-based pre-training scheme to yield a highly flexible framework which
we refer to as few-shot learning for open world recognition (FLOWR). We
benchmark our framework on open-world extensions of the common MiniImageNet and
TieredImageNet few-shot learning datasets. Our results show, compared to prior
methods, strong classification accuracy performance and up to a 12% improvement
in H-measure (a measure of novel class detection) from our non-parametric
open-world few-shot learning scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">From Continuity to Editability: Inverting GANs with Consecutive Images. (arXiv:2107.13812v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yangyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yong Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Wenpeng Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xuemiao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shengfeng He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13812">
                                    <div class="article-summary-box-inner">
                                        <span>Existing GAN inversion methods are stuck in a paradox that the inverted codes
can either achieve high-fidelity reconstruction, or retain the editing
capability. Having only one of them clearly cannot realize real image editing.
In this paper, we resolve this paradox by introducing consecutive images (\eg,
video frames or the same person with different poses) into the inversion
process. The rationale behind our solution is that the continuity of
consecutive images leads to inherent editable directions. This inborn property
is used for two unique purposes: 1) regularizing the joint inversion process,
such that each of the inverted code is semantically accessible from one of the
other and fastened in a editable domain; 2) enforcing inter-image coherence,
such that the fidelity of each inverted code can be maximized with the
complement of other images. Extensive experiments demonstrate that our
alternative significantly outperforms state-of-the-art methods in terms of
reconstruction fidelity and editability on both the real image dataset and
synthesis dataset. Furthermore, our method provides the first support of
video-based GAN inversion, and an interesting application of unsupervised
semantic transfer from consecutive images. Source code can be found at:
\url{https://github.com/Qingyang-Xu/InvertingGANs_with_ConsecutiveImgs}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Social Processes: Self-Supervised Forecasting of Nonverbal Cues in Social Conversations. (arXiv:2107.13576v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raman_C/0/1/0/all/0/1">Chirag Raman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hung_H/0/1/0/all/0/1">Hayley Hung</a>, <a href="http://arxiv.org/find/cs/1/au:+Loog_M/0/1/0/all/0/1">Marco Loog</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13576">
                                    <div class="article-summary-box-inner">
                                        <span>The default paradigm for the forecasting of human behavior in social
conversations is characterized by top-down approaches. These involve
identifying predictive relationships between low level nonverbal cues and
future semantic events of interest (e.g. turn changes, group leaving). A common
hurdle however, is the limited availability of labeled data for supervised
learning. In this work, we take the first step in the direction of a bottom-up
self-supervised approach in the domain. We formulate the task of Social Cue
Forecasting to leverage the larger amount of unlabeled low-level behavior cues,
and characterize the modeling challenges involved. To address these, we take a
meta-learning approach and propose the Social Process (SP) models--socially
aware sequence-to-sequence (Seq2Seq) models within the Neural Process (NP)
family. SP models learn extractable representations of non-semantic future cues
for each participant, while capturing global uncertainty by jointly reasoning
about the future for all members of the group. Evaluation on synthesized and
real-world behavior data shows that our SP models achieve higher log-likelihood
than the NP baselines, and also highlights important considerations for
applying such techniques within the domain of social human interactions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">I2UV-HandNet: Image-to-UV Prediction Network for Accurate and High-fidelity 3D Hand Mesh Modeling. (arXiv:2102.03725v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Ping Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yujin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Dong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangyin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Q/0/1/0/all/0/1">Qingpei Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1">Yong Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03725">
                                    <div class="article-summary-box-inner">
                                        <span>Reconstructing a high-precision and high-fidelity 3D human hand from a color
image plays a central role in replicating a realistic virtual hand in
human-computer interaction and virtual reality applications. The results of
current methods are lacking in accuracy and fidelity due to various hand poses
and severe occlusions. In this study, we propose an I2UV-HandNet model for
accurate hand pose and shape estimation as well as 3D hand super-resolution
reconstruction. Specifically, we present the first UV-based 3D hand shape
representation. To recover a 3D hand mesh from an RGB image, we design an
AffineNet to predict a UV position map from the input in an image-to-image
translation fashion. To obtain a higher fidelity shape, we exploit an
additional SRNet to transform the low-resolution UV map outputted by AffineNet
into a high-resolution one. For the first time, we demonstrate the
characterization capability of the UV-based hand shape representation. Our
experiments show that the proposed method achieves state-of-the-art performance
on several challenging benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stereo Plane SLAM Based on Intersecting Lines. (arXiv:2008.08218v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xianyu Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Z/0/1/0/all/0/1">Ziwei Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08218">
                                    <div class="article-summary-box-inner">
                                        <span>Plane feature is a kind of stable landmark to reduce drift error in SLAM
system. It is easy and fast to extract planes from dense point cloud, which is
commonly acquired from RGB-D camera or lidar. But for stereo camera, it is hard
to compute dense point cloud accurately and efficiently. In this paper, we
propose a novel method to compute plane parameters using intersecting lines
which are extracted from the stereo image. The plane features commonly exist on
the surface of man-made objects and structure, which have regular shape and
straight edge lines. In 3D space, two intersecting lines can determine such a
plane. Thus we extract line segments from both stereo left and right image. By
stereo matching, we compute the endpoints and line directions in 3D space, and
then the planes from two intersecting lines. We discard those inaccurate plane
features in the frame tracking. Adding such plane features in stereo SLAM
system reduces the drift error and refines the performance. We test our
proposed system on public datasets and demonstrate its robust and accurate
estimation results, compared with state-of-the-art SLAM systems. To benefit the
research of plane-based SLAM, we release our codes at
https://github.com/fishmarch/Stereo-Plane-SLAM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Multi-View Stereo via Plane Sweep: A Survey. (arXiv:2106.15328v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Qingtian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_C/0/1/0/all/0/1">Chen Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zizhuang Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yisong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guoping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15328">
                                    <div class="article-summary-box-inner">
                                        <span>3D reconstruction has lately attracted increasing attention due to its wide
application in many areas, such as autonomous driving, robotics and virtual
reality. As a dominant technique in artificial intelligence, deep learning has
been successfully adopted to solve various computer vision problems. However,
deep learning for 3D reconstruction is still at its infancy due to its unique
challenges and varying pipelines. To stimulate future research, this paper
presents a review of recent progress in deep learning methods for Multi-view
Stereo (MVS), which is considered as a crucial task of image-based 3D
reconstruction. It also presents comparative results on several publicly
available datasets, with insightful observations and inspiring future research
directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Open-World Entity Segmentation. (arXiv:2107.14228v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lu Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuen_J/0/1/0/all/0/1">Jason Kuen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jiuxiang Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hengshuang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhe Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14228">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new image segmentation task, termed Entity Segmentation (ES)
with the aim to segment all visual entities in an image without considering
semantic category labels. It has many practical applications in image
manipulation/editing where the segmentation mask quality is typically crucial
but category labels are less important. In this setting, all
semantically-meaningful segments are equally treated as categoryless entities
and there is no thing-stuff distinction. Based on our unified entity
representation, we propose a center-based entity segmentation framework with
two novel modules to improve mask quality. Experimentally, both our new task
and framework demonstrate superior advantages as against existing work. In
particular, ES enables the following: (1) merging multiple datasets to form a
large training set without the need to resolve label conflicts; (2) any model
trained on one dataset can generalize exceptionally well to other datasets with
unseen domains. Our code is made publicly available at
https://github.com/dvlab-research/Entity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymmetric Loss For Multi-Label Classification. (arXiv:2009.14119v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1">Emanuel Ben-Baruch</a>, <a href="http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1">Tal Ridnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamir_N/0/1/0/all/0/1">Nadav Zamir</a>, <a href="http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1">Asaf Noy</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedman_I/0/1/0/all/0/1">Itamar Friedman</a>, <a href="http://arxiv.org/find/cs/1/au:+Protter_M/0/1/0/all/0/1">Matan Protter</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1">Lihi Zelnik-Manor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14119">
                                    <div class="article-summary-box-inner">
                                        <span>In a typical multi-label setting, a picture contains on average few positive
labels, and many negative ones. This positive-negative imbalance dominates the
optimization process, and can lead to under-emphasizing gradients from positive
labels during training, resulting in poor accuracy. In this paper, we introduce
a novel asymmetric loss (&quot;ASL&quot;), which operates differently on positive and
negative samples. The loss enables to dynamically down-weights and
hard-thresholds easy negative samples, while also discarding possibly
mislabeled samples. We demonstrate how ASL can balance the probabilities of
different samples, and how this balancing is translated to better mAP scores.
With ASL, we reach state-of-the-art results on multiple popular multi-label
datasets: MS-COCO, Pascal-VOC, NUS-WIDE and Open Images. We also demonstrate
ASL applicability for other tasks, such as single-label classification and
object detection. ASL is effective, easy to implement, and does not increase
the training time or complexity.

Implementation is available at: https://github.com/Alibaba-MIIL/ASL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guided Disentanglement in Generative Networks. (arXiv:2107.14229v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pizzati_F/0/1/0/all/0/1">Fabio Pizzati</a>, <a href="http://arxiv.org/find/cs/1/au:+Cerri_P/0/1/0/all/0/1">Pietro Cerri</a>, <a href="http://arxiv.org/find/cs/1/au:+Charette_R/0/1/0/all/0/1">Raoul de Charette</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14229">
                                    <div class="article-summary-box-inner">
                                        <span>Image-to-image translation (i2i) networks suffer from entanglement effects in
presence of physics-related phenomena in target domain (such as occlusions,
fog, etc), thus lowering the translation quality and variability. In this
paper, we present a comprehensive method for disentangling physics-based traits
in the translation, guiding the learning process with neural or physical
models. For the latter, we integrate adversarial estimation and genetic
algorithms to correctly achieve disentanglement. The results show our approach
dramatically increase performances in many challenging scenarios for image
translation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Trajectory Prediction via Distribution Discrimination. (arXiv:2107.14204v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guangyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junlong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_N/0/1/0/all/0/1">Nuoxing Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_L/0/1/0/all/0/1">Liangliang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14204">
                                    <div class="article-summary-box-inner">
                                        <span>Trajectory prediction is confronted with the dilemma to capture the
multi-modal nature of future dynamics with both diversity and accuracy. In this
paper, we present a distribution discrimination (DisDis) method to predict
personalized motion patterns by distinguishing the potential distributions.
Motivated by that the motion pattern of each person is personalized due to
his/her habit, our DisDis learns the latent distribution to represent different
motion patterns and optimize it by the contrastive discrimination. This
distribution discrimination encourages latent distributions to be more
discriminative. Our method can be integrated with existing multi-modal
stochastic predictive models as a plug-and-play module to learn the more
discriminative latent distribution. To evaluate the latent distribution, we
further propose a new metric, probability cumulative minimum distance (PCMD)
curve, which cumulatively calculates the minimum distance on the sorted
probabilities. Experimental results on the ETH and UCY datasets show the
effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do CNNs Encode Data Augmentations?. (arXiv:2003.08773v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_E/0/1/0/all/0/1">Eddie Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yanping Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.08773">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentations are important ingredients in the recipe for training
robust neural networks, especially in computer vision. A fundamental question
is whether neural network features encode data augmentation transformations. To
answer this question, we introduce a systematic approach to investigate which
layers of neural networks are the most predictive of augmentation
transformations. Our approach uses features in pre-trained vision models with
minimal additional processing to predict common properties transformed by
augmentation (scale, aspect ratio, hue, saturation, contrast, and brightness).
Surprisingly, neural network features not only predict data augmentation
transformations, but they predict many transformations with high accuracy.
After validating that neural networks encode features corresponding to
augmentation transformations, we show that these features are encoded in the
early layers of modern CNNs, though the augmentation signal fades in deeper
layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Visual Anomaly Detection for Task Execution Monitoring. (arXiv:2107.14206v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thoduka_S/0/1/0/all/0/1">Santosh Thoduka</a>, <a href="http://arxiv.org/find/cs/1/au:+Gall_J/0/1/0/all/0/1">Juergen Gall</a>, <a href="http://arxiv.org/find/cs/1/au:+Ploger_P/0/1/0/all/0/1">Paul G. Pl&#xf6;ger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14206">
                                    <div class="article-summary-box-inner">
                                        <span>Execution monitoring is essential for robots to detect and respond to
failures. Since it is impossible to enumerate all failures for a given task, we
learn from successful executions of the task to detect visual anomalies during
runtime. Our method learns to predict the motions that occur during the nominal
execution of a task, including camera and robot body motion. A probabilistic
U-Net architecture is used to learn to predict optical flow, and the robot&#x27;s
kinematics and 3D model are used to model camera and body motion. The errors
between the observed and predicted motion are used to calculate an anomaly
score. We evaluate our method on a dataset of a robot placing a book on a
shelf, which includes anomalies such as falling books, camera occlusions, and
robot disturbances. We find that modeling camera and body motion, in addition
to the learning-based optical flow prediction, results in an improvement of the
area under the receiver operating characteristic curve from 0.752 to 0.804, and
the area under the precision-recall curve from 0.467 to 0.549.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Selective Feature Compression for Efficient Activity Recognition Inference. (arXiv:2104.00179v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chunhui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Modolo_D/0/1/0/all/0/1">Davide Modolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tighe_J/0/1/0/all/0/1">Joseph Tighe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00179">
                                    <div class="article-summary-box-inner">
                                        <span>Most action recognition solutions rely on dense sampling to precisely cover
the informative temporal clip. Extensively searching temporal region is
expensive for a real-world application. In this work, we focus on improving the
inference efficiency of current action recognition backbones on trimmed videos,
and illustrate that one action model can also cover then informative region by
dropping non-informative features. We present Selective Feature Compression
(SFC), an action recognition inference strategy that greatly increase model
inference efficiency without any accuracy compromise. Differently from previous
works that compress kernel sizes and decrease the channel dimension, we propose
to compress feature flow at spatio-temporal dimension without changing any
backbone parameters. Our experiments on Kinetics-400, UCF101 and ActivityNet
show that SFC is able to reduce inference speed by 6-7x and memory usage by
5-6x compared with the commonly used 30 crops dense sampling procedure, while
also slightly improving Top1 Accuracy. We thoroughly quantitatively and
qualitatively evaluate SFC and all its components and show how does SFC learn
to attend to important video regions and to drop temporal features that are
uninformative for the task of action recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain and View-point Agnostic Hand Action Recognition. (arXiv:2103.02303v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sabater_A/0/1/0/all/0/1">Alberto Sabater</a>, <a href="http://arxiv.org/find/cs/1/au:+Alonso_I/0/1/0/all/0/1">I&#xf1;igo Alonso</a>, <a href="http://arxiv.org/find/cs/1/au:+Montesano_L/0/1/0/all/0/1">Luis Montesano</a>, <a href="http://arxiv.org/find/cs/1/au:+Murillo_A/0/1/0/all/0/1">Ana C. Murillo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02303">
                                    <div class="article-summary-box-inner">
                                        <span>Hand action recognition is a special case of action recognition with
applications in human-robot interaction, virtual reality or life-logging
systems. Building action classifiers able to work for such heterogeneous action
domains is very challenging. There are very subtle changes across different
actions from a given application but also large variations across domains (e.g.
virtual reality vs life-logging). This work introduces a novel skeleton-based
hand motion representation model that tackles this problem. The framework we
propose is agnostic to the application domain or camera recording view-point.
When working on a single domain (intra-domain action classification) our
approach performs better or similar to current state-of-the-art methods on
well-known hand action recognition benchmarks. And, more importantly, when
performing hand action recognition for action domains and camera perspectives
which our approach has not been trained for (cross-domain action
classification), our proposed framework achieves comparable performance to
intra-domain state-of-the-art methods. These experiments show the robustness
and generalization capabilities of our framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning Advances aiding Recognition and Classification of Indian Monuments and Landmarks. (arXiv:2107.14070v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1">Aditya Jyoti Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghose_S/0/1/0/all/0/1">Smaranjit Ghose</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_K/0/1/0/all/0/1">Kanishka Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nethaji_N/0/1/0/all/0/1">Niketha Nethaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1">Shivam Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Purkayastha_A/0/1/0/all/0/1">Arnab Dutta Purkayastha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14070">
                                    <div class="article-summary-box-inner">
                                        <span>Tourism in India plays a quintessential role in the country&#x27;s economy with an
estimated 9.2% GDP share for the year 2018. With a yearly growth rate of 6.2%,
the industry holds a huge potential for being the primary driver of the economy
as observed in the nations of the Middle East like the United Arab Emirates.
The historical and cultural diversity exhibited throughout the geography of the
nation is a unique spectacle for people around the world and therefore serves
to attract tourists in tens of millions in number every year. Traditionally,
tour guides or academic professionals who study these heritage monuments were
responsible for providing information to the visitors regarding their
architectural and historical significance. However, unfortunately this system
has several caveats when considered on a large scale such as unavailability of
sufficient trained people, lack of accurate information, failure to convey the
richness of details in an attractive format etc. Recently, machine learning
approaches revolving around the usage of monument pictures have been shown to
be useful for rudimentary analysis of heritage sights. This paper serves as a
survey of the research endeavors undertaken in this direction which would
eventually provide insights for building an automated decision system that
could be utilized to make the experience of tourism in India more modernized
for visitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReFormer: The Relational Transformer for Image Captioning. (arXiv:2107.14178v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xuewen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yingru Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14178">
                                    <div class="article-summary-box-inner">
                                        <span>Image captioning is shown to be able to achieve a better performance by using
scene graphs to represent the relations of objects in the image. The current
captioning encoders generally use a Graph Convolutional Net (GCN) to represent
the relation information and merge it with the object region features via
concatenation or convolution to get the final input for sentence decoding.
However, the GCN-based encoders in the existing methods are less effective for
captioning due to two reasons. First, using the image captioning as the
objective (i.e., Maximum Likelihood Estimation) rather than a relation-centric
loss cannot fully explore the potential of the encoder. Second, using a
pre-trained model instead of the encoder itself to extract the relationships is
not flexible and cannot contribute to the explainability of the model. To
improve the quality of image captioning, we propose a novel architecture
ReFormer -- a RElational transFORMER to generate features with relation
information embedded and to explicitly express the pair-wise relationships
between objects in the image. ReFormer incorporates the objective of scene
graph generation with that of image captioning using one modified Transformer
model. This design allows ReFormer to generate not only better image captions
with the bene-fit of extracting strong relational image features, but also
scene graphs to explicitly describe the pair-wise relation-ships. Experiments
on publicly available datasets show that our model significantly outperforms
state-of-the-art methods on image captioning and scene graph generation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot and Continual Learning with Attentive Independent Mechanisms. (arXiv:2107.14053v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1">Eugene Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Cheng-Han Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chen-Yi Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14053">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) are known to perform well when deployed to test
distributions that shares high similarity with the training distribution.
Feeding DNNs with new data sequentially that were unseen in the training
distribution has two major challenges -- fast adaptation to new tasks and
catastrophic forgetting of old tasks. Such difficulties paved way for the
on-going research on few-shot learning and continual learning. To tackle these
problems, we introduce Attentive Independent Mechanisms (AIM). We incorporate
the idea of learning using fast and slow weights in conjunction with the
decoupling of the feature extraction and higher-order conceptual learning of a
DNN. AIM is designed for higher-order conceptual learning, modeled by a mixture
of experts that compete to learn independent concepts to solve a new task. AIM
is a modular component that can be inserted into existing deep learning
frameworks. We demonstrate its capability for few-shot learning by adding it to
SIB and trained on MiniImageNet and CIFAR-FS, showing significant improvement.
AIM is also applied to ANML and OML trained on Omniglot, CIFAR-100 and
MiniImageNet to demonstrate its capability in continual learning. Code made
publicly available at https://github.com/huang50213/AIM-Fewshot-Continual.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Leakage and Rethinking the Kernel Size in CNNs. (arXiv:2101.10143v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tomen_N/0/1/0/all/0/1">Nergis Tomen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1">Jan van Gemert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10143">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional layers in CNNs implement linear filters which decompose the
input into different frequency bands. However, most modern architectures
neglect standard principles of filter design when optimizing their model
choices regarding the size and shape of the convolutional kernel. In this work,
we consider the well-known problem of spectral leakage caused by windowing
artifacts in filtering operations in the context of CNNs. We show that the
small size of CNN kernels make them susceptible to spectral leakage, which may
induce performance-degrading artifacts. To address this issue, we propose the
use of larger kernel sizes along with the Hamming window function to alleviate
leakage in CNN architectures. We demonstrate improved classification accuracy
on multiple benchmark datasets including Fashion-MNIST, CIFAR-10, CIFAR-100 and
ImageNet with the simple use of a standard window function in convolutional
layers. Finally, we show that CNNs employing the Hamming window display
increased robustness against various adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Adversarial Robustness via Test-time Transformation Ensembling. (arXiv:2107.14110v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perez_J/0/1/0/all/0/1">Juan C. P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1">Motasem Alfarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeanneret_G/0/1/0/all/0/1">Guillaume Jeanneret</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueda_L/0/1/0/all/0/1">Laura Rueda</a>, <a href="http://arxiv.org/find/cs/1/au:+Thabet_A/0/1/0/all/0/1">Ali Thabet</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbel&#xe1;ez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14110">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models are prone to being fooled by imperceptible perturbations
known as adversarial attacks. In this work, we study how equipping models with
Test-time Transformation Ensembling (TTE) can work as a reliable defense
against such attacks. While transforming the input data, both at train and test
times, is known to enhance model performance, its effects on adversarial
robustness have not been studied. Here, we present a comprehensive empirical
study of the impact of TTE, in the form of widely-used image transforms, on
adversarial robustness. We show that TTE consistently improves model robustness
against a variety of powerful attacks without any need for re-training, and
that this improvement comes at virtually no trade-off with accuracy on clean
samples. Finally, we show that the benefits of TTE transfer even to the
certified robustness domain, in which TTE provides sizable and consistent
improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking and Improving Relative Position Encoding for Vision Transformer. (arXiv:2107.14222v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Houwen Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Minghao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jianlong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_H/0/1/0/all/0/1">Hongyang Chao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14222">
                                    <div class="article-summary-box-inner">
                                        <span>Relative position encoding (RPE) is important for transformer to capture
sequence ordering of input tokens. General efficacy has been proven in natural
language processing. However, in computer vision, its efficacy is not well
studied and even remains controversial, e.g., whether relative position
encoding can work equally well as absolute position? In order to clarify this,
we first review existing relative position encoding methods and analyze their
pros and cons when applied in vision transformers. We then propose new relative
position encoding methods dedicated to 2D images, called image RPE (iRPE). Our
methods consider directional relative distance modeling as well as the
interactions between queries and relative position embeddings in self-attention
mechanism. The proposed iRPE methods are simple and lightweight. They can be
easily plugged into transformer blocks. Experiments demonstrate that solely due
to the proposed encoding methods, DeiT and DETR obtain up to 1.5% (top-1 Acc)
and 1.3% (mAP) stable improvements over their original versions on ImageNet and
COCO respectively, without tuning any extra hyperparameters such as learning
rate and weight decay. Our ablation and analysis also yield interesting
findings, some of which run counter to previous understanding. Code and models
are open-sourced at https://github.com/microsoft/Cream/tree/main/iRPE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fully-Automatic Pipeline for Document Signature Analysis to Detect Money Laundering Activities. (arXiv:2107.14091v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Woodruff_N/0/1/0/all/0/1">Nikhil Woodruff</a>, <a href="http://arxiv.org/find/cs/1/au:+Enshaei_A/0/1/0/all/0/1">Amir Enshaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_B/0/1/0/all/0/1">Bashar Awwad Shiekh Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14091">
                                    <div class="article-summary-box-inner">
                                        <span>Signatures present on corporate documents are often used in investigations of
relationships between persons of interest, and prior research into the task of
offline signature verification has evaluated a wide range of methods on
standard signature datasets. However, such tasks often benefit from prior human
supervision in the collection, adjustment and labelling of isolated signature
images from which all real-world context has been removed. Signatures found in
online document repositories such as the United Kingdom Companies House
regularly contain high variation in location, size, quality and degrees of
obfuscation under stamps. We propose an integrated pipeline of signature
extraction and curation, with no human assistance from the obtaining of company
documents to the clustering of individual signatures. We use a sequence of
heuristic methods, convolutional neural networks, generative adversarial
networks and convolutional Siamese networks for signature extraction,
filtering, cleaning and embedding respectively. We evaluate both the
effectiveness of the pipeline at matching obscured same-author signature pairs
and the effectiveness of the entire pipeline against a human baseline for
document signature analysis, as well as presenting uses for such a pipeline in
the field of real-world anti-money laundering investigation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Efficient Pyramid Transformer for Semantic Segmentation. (arXiv:2107.14209v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1">Fangrui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chongruo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14209">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation is a challenging problem due to difficulties in
modeling context in complex scenes and class confusions along boundaries. Most
literature either focuses on context modeling or boundary refinement, which is
less generalizable in open-world scenarios. In this work, we advocate a unified
framework(UN-EPT) to segment objects by considering both context information
and boundary artifacts. We first adapt a sparse sampling strategy to
incorporate the transformer-based attention mechanism for efficient context
modeling. In addition, a separate spatial branch is introduced to capture image
details for boundary refinement. The whole model can be trained in an
end-to-end manner. We demonstrate promising performance on three popular
benchmarks for semantic segmentation with low memory footprint. Code will be
released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-View Tracking for Multi-Human 3D Pose Estimation at over 100 FPS. (arXiv:2003.03972v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Long Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_H/0/1/0/all/0/1">Haizhou Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Rui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Z/0/1/0/all/0/1">Zijie Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.03972">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating 3D poses of multiple humans in real-time is a classic but still
challenging task in computer vision. Its major difficulty lies in the ambiguity
in cross-view association of 2D poses and the huge state space when there are
multiple people in multiple views. In this paper, we present a novel solution
for multi-human 3D pose estimation from multiple calibrated camera views. It
takes 2D poses in different camera coordinates as inputs and aims for the
accurate 3D poses in the global coordinate. Unlike previous methods that
associate 2D poses among all pairs of views from scratch at every frame, we
exploit the temporal consistency in videos to match the 2D inputs with 3D poses
directly in 3-space. More specifically, we propose to retain the 3D pose for
each person and update them iteratively via the cross-view multi-human
tracking. This novel formulation improves both accuracy and efficiency, as we
demonstrated on widely-used public datasets. To further verify the scalability
of our method, we propose a new large-scale multi-human dataset with 12 to 28
camera views. Without bells and whistles, our solution achieves 154 FPS on 12
cameras and 34 FPS on 28 cameras, indicating its ability to handle large-scale
real-world applications. The proposed dataset is released at
https://github.com/longcw/crossview_3d_pose_tracking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Swap-Free Fat-Water Separation in Dixon MRI using Conditional Generative Adversarial Networks. (arXiv:2107.14175v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Basty_N/0/1/0/all/0/1">Nicolas Basty</a>, <a href="http://arxiv.org/find/eess/1/au:+Thanaj_M/0/1/0/all/0/1">Marjola Thanaj</a>, <a href="http://arxiv.org/find/eess/1/au:+Cule_M/0/1/0/all/0/1">Madeleine Cule</a>, <a href="http://arxiv.org/find/eess/1/au:+Sorokin_E/0/1/0/all/0/1">Elena P. Sorokin</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yi Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Bell_J/0/1/0/all/0/1">Jimmy D. Bell</a>, <a href="http://arxiv.org/find/eess/1/au:+Thomas_E/0/1/0/all/0/1">E. Louise Thomas</a>, <a href="http://arxiv.org/find/eess/1/au:+Whitcher_B/0/1/0/all/0/1">Brandon Whitcher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14175">
                                    <div class="article-summary-box-inner">
                                        <span>Dixon MRI is widely used for body composition studies. Current processing
methods associated with large whole-body volumes are time intensive and prone
to artifacts during fat-water separation performed on the scanner, making the
data difficult to analyse. The most common artifact are fat-water swaps, where
the labels are inverted at the voxel level. It is common for researchers to
discard swapped data (generally around 10%), which can be wasteful and lead to
unintended biases. The UK Biobank is acquiring Dixon MRI for over 100,000
participants, and thousands of swaps will occur. If those go undetected, errors
will propagate into processes such as abdominal organ segmentation and dilute
the results in population-based analyses. There is a clear need for a fast and
robust method to accurately separate fat and water channels. In this work we
propose such a method based on style transfer using a conditional generative
adversarial network. We also introduce a new Dixon loss function for the
generator model. Using data from the UK Biobank Dixon MRI, our model is able to
predict highly accurate fat and water channels that are free from artifacts. We
show that the model separates fat and water channels using either single input
(in-phase) or dual input (in-phase and opposed-phase), with the latter
producing improved results. Our proposed method enables faster and more
accurate downstream analysis of body composition from Dixon MRI in population
studies by eliminating the need for visual inspection or discarding data due to
fat-water swaps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discovering 3D Parts from Image Collections. (arXiv:2107.13629v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_C/0/1/0/all/0/1">Chun-Han Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hung_W/0/1/0/all/0/1">Wei-Chih Hung</a>, <a href="http://arxiv.org/find/cs/1/au:+Jampani_V/0/1/0/all/0/1">Varun Jampani</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13629">
                                    <div class="article-summary-box-inner">
                                        <span>Reasoning 3D shapes from 2D images is an essential yet challenging task,
especially when only single-view images are at our disposal. While an object
can have a complicated shape, individual parts are usually close to geometric
primitives and thus are easier to model. Furthermore, parts provide a mid-level
representation that is robust to appearance variations across objects in a
particular category. In this work, we tackle the problem of 3D part discovery
from only 2D image collections. Instead of relying on manually annotated parts
for supervision, we propose a self-supervised approach, latent part discovery
(LPD). Our key insight is to learn a novel part shape prior that allows each
part to fit an object shape faithfully while constrained to have simple
geometry. Extensive experiments on the synthetic ShapeNet, PartNet, and
real-world Pascal 3D+ datasets show that our method discovers consistent object
parts and achieves favorable reconstruction accuracy compared to the existing
methods with the same level of supervision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FREE: Feature Refinement for Generalized Zero-Shot Learning. (arXiv:2107.13807v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shiming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_B/0/1/0/all/0/1">Beihao Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Q/0/1/0/all/0/1">Qinmu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+You_X/0/1/0/all/0/1">Xinge You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_F/0/1/0/all/0/1">Feng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13807">
                                    <div class="article-summary-box-inner">
                                        <span>Generalized zero-shot learning (GZSL) has achieved significant progress, with
many efforts dedicated to overcoming the problems of visual-semantic domain gap
and seen-unseen bias. However, most existing methods directly use feature
extraction models trained on ImageNet alone, ignoring the cross-dataset bias
between ImageNet and GZSL benchmarks. Such a bias inevitably results in
poor-quality visual features for GZSL tasks, which potentially limits the
recognition performance on both seen and unseen classes. In this paper, we
propose a simple yet effective GZSL method, termed feature refinement for
generalized zero-shot learning (FREE), to tackle the above problem. FREE
employs a feature refinement (FR) module that incorporates
\textit{semantic$\rightarrow$visual} mapping into a unified generative model to
refine the visual features of seen and unseen class samples. Furthermore, we
propose a self-adaptive margin center loss (SAMC-loss) that cooperates with a
semantic cycle-consistency loss to guide FR to learn class- and
semantically-relevant representations, and concatenate the features in FR to
extract the fully refined features. Extensive experiments on five benchmark
datasets demonstrate the significant performance gain of FREE over its baseline
and current state-of-the-art methods. Our codes are available at
https://github.com/shiming-chen/FREE .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Does TERRA-REF&#x27;s High Resolution, Multi Sensor Plant Sensing Public Domain Data Offer the Computer Vision Community?. (arXiv:2107.14072v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+LeBauer_D/0/1/0/all/0/1">David LeBauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnette_M/0/1/0/all/0/1">Max Burnette</a>, <a href="http://arxiv.org/find/cs/1/au:+Fahlgren_N/0/1/0/all/0/1">Noah Fahlgren</a>, <a href="http://arxiv.org/find/cs/1/au:+Kooper_R/0/1/0/all/0/1">Rob Kooper</a>, <a href="http://arxiv.org/find/cs/1/au:+McHenry_K/0/1/0/all/0/1">Kenton McHenry</a>, <a href="http://arxiv.org/find/cs/1/au:+Stylianou_A/0/1/0/all/0/1">Abby Stylianou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14072">
                                    <div class="article-summary-box-inner">
                                        <span>A core objective of the TERRA-REF project was to generate an open-access
reference dataset for the study of evaluation of sensing technology to study
plants under field conditions. The TERRA-REF program deployed a suite of high
resolution, cutting edge technology sensors on a gantry system with the aim of
scanning 1 hectare (~$10^4$ m) at around $1 mm^2$ spatial resolution multiple
times per week. The system contains co-located sensors including a stereo-pair
RGB camera, a thermal imager, a laser scanner to capture 3D structure, and two
hyperspectral cameras covering wavelengths of 300-2500nm. This sensor data is
provided alongside over sixty types of traditional plant measurements that can
be used to train new machine learning models. Associated weather and
environmental measurements, information about agronomic management and
experimental design, and the genomic sequences of hundreds of plant varieties
have been collected and are available alongside the sensor and plant trait
(phenotype) data.

Over the course of four years and ten growing seasons, the TERRA-REF system
generated over 1 PB of sensor data and almost 45 million files. The subset that
has been released to the public domain accounts for two seasons and about half
of the total data volume. This provides an unprecedented opportunity for
investigations far beyond the core biological scope of the project.

This focus of this paper is to provide the Computer Vision and Machine
Learning communities an overview of the available data and some potential
applications of this one of a kind data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Portrait Matting. (arXiv:2104.14222v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jizhizi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Sihan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14222">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been an increasing concern about the privacy issue raised
by using personally identifiable information in machine learning. However,
previous portrait matting methods were all based on identifiable portrait
images. To fill the gap, we present P3M-10k in this paper, which is the first
large-scale anonymized benchmark for Privacy-Preserving Portrait Matting.
P3M-10k consists of 10,000 high-resolution face-blurred portrait images along
with high-quality alpha mattes. We systematically evaluate both trimap-free and
trimap-based matting methods on P3M-10k and find that existing matting methods
show different generalization capabilities when following the
Privacy-Preserving Training (PPT) setting, i.e., training on face-blurred
images and testing on arbitrary images. To devise a better trimap-free portrait
matting model, we propose P3M-Net, which leverages the power of a unified
framework for both semantic perception and detail matting, and specifically
emphasizes the interaction between them and the encoder to facilitate the
matting process. Extensive experiments on P3M-10k demonstrate that P3M-Net
outperforms the state-of-the-art methods in terms of both objective metrics and
subjective visual quality. Besides, it shows good generalization capacity under
the PPT setting, confirming the value of P3M-10k for facilitating future
research and enabling potential real-world applications. The source code and
dataset are available at https://github.com/JizhiziLi/P3M</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PPT Fusion: Pyramid Patch Transformerfor a Case Study in Image Fusion. (arXiv:2107.13967v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yu Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">TianYang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">XiaoJun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kittler_J/0/1/0/all/0/1">Josef Kittler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13967">
                                    <div class="article-summary-box-inner">
                                        <span>The Transformer architecture has achieved rapiddevelopment in recent years,
outperforming the CNN archi-tectures in many computer vision tasks, such as the
VisionTransformers (ViT) for image classification. However, existingvisual
transformer models aim to extract semantic informationfor high-level tasks such
as classification and detection, distortingthe spatial resolution of the input
image, thus sacrificing thecapacity in reconstructing the input or generating
high-resolutionimages. In this paper, therefore, we propose a Patch
PyramidTransformer(PPT) to effectively address the above issues. Specif-ically,
we first design a Patch Transformer to transform theimage into a sequence of
patches, where transformer encodingis performed for each patch to extract local
representations.In addition, we construct a Pyramid Transformer to
effectivelyextract the non-local information from the entire image.
Afterobtaining a set of multi-scale, multi-dimensional, and multi-anglefeatures
of the original image, we design the image reconstructionnetwork to ensure that
the features can be reconstructed intothe original input. To validate the
effectiveness, we apply theproposed Patch Pyramid Transformer to the image
fusion task.The experimental results demonstrate its superior
performanceagainst the state-of-the-art fusion approaches, achieving the
bestresults on several evaluation indicators. The underlying capacityof the PPT
network is reflected by its universal power in featureextraction and image
reconstruction, which can be directlyapplied to different image fusion tasks
without redesigning orretraining the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascaded Residual Density Network for Crowd Counting. (arXiv:2107.13718v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1">Kun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Luchuan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_Q/0/1/0/all/0/1">Qi Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1">Nenghai Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13718">
                                    <div class="article-summary-box-inner">
                                        <span>Crowd counting is a challenging task due to the issues such as scale
variation and perspective variation in real crowd scenes. In this paper, we
propose a novel Cascaded Residual Density Network (CRDNet) in a coarse-to-fine
approach to generate the high-quality density map for crowd counting more
accurately. (1) We estimate the residual density maps by multi-scale pyramidal
features through cascaded residual density modules. It can improve the quality
of density map layer by layer effectively. (2) A novel additional local count
loss is presented to refine the accuracy of crowd counting, which reduces the
errors of pixel-wise Euclidean loss by restricting the number of people in the
local crowd areas. Experiments on two public benchmark datasets show that the
proposed method achieves effective improvement compared with the
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Image Semantic Segmentation. (arXiv:2107.13978v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chang-Bin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1">Peng-Tao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_F/0/1/0/all/0/1">Feng Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1">Ming-Ming Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13978">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation models trained on public datasets have achieved great
success in recent years. However, these models didn&#x27;t consider the
personalization issue of segmentation though it is important in practice. In
this paper, we address the problem of personalized image segmentation. The
objective is to generate more accurate segmentation results on unlabeled
personalized images by investigating the data&#x27;s personalized traits. To open up
future research in this area, we collect a large dataset containing various
users&#x27; personalized images called PIS (Personalized Image Semantic
Segmentation). We also survey some recent researches related to this problem
and report their performance on our dataset. Furthermore, by observing the
correlation among a user&#x27;s personalized images, we propose a baseline method
that incorporates the inter-image context when segmenting certain images.
Extensive experiments show that our method outperforms the existing methods on
the proposed dataset. The code and the PIS dataset will be made publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure and Performance of Fully Connected Neural Networks: Emerging Complex Network Properties. (arXiv:2107.14062v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scabini_L/0/1/0/all/0/1">Leonardo F. S. Scabini</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruno_O/0/1/0/all/0/1">Odemir M. Bruno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14062">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the behavior of Artificial Neural Networks is one of the main
topics in the field recently, as black-box approaches have become usual since
the widespread of deep learning. Such high-dimensional models may manifest
instabilities and weird properties that resemble complex systems. Therefore, we
propose Complex Network (CN) techniques to analyze the structure and
performance of fully connected neural networks. For that, we build a dataset
with 4 thousand models and their respective CN properties. They are employed in
a supervised classification setup considering four vision benchmarks. Each
neural network is approached as a weighted and undirected graph of neurons and
synapses, and centrality measures are computed after training. Results show
that these measures are highly related to the network classification
performance. We also propose the concept of Bag-Of-Neurons (BoN), a CN-based
approach for finding topological signatures linking similar neurons. Results
suggest that six neuronal types emerge in such networks, independently of the
target domain, and are distributed differently according to classification
accuracy. We also tackle specific CN properties related to performance, such as
higher subgraph centrality on lower-performing models. Our findings suggest
that CN properties play a critical role in the performance of fully connected
neural networks, with topological patterns emerging independently on a wide
range of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Importance-aware Transferable Adversarial Attacks. (arXiv:2107.14185v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhibo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hengchang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhifei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wenxin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhan Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_K/0/1/0/all/0/1">Kui Ren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14185">
                                    <div class="article-summary-box-inner">
                                        <span>Transferability of adversarial examples is of central importance for
attacking an unknown model, which facilitates adversarial attacks in more
practical scenarios, e.g., blackbox attacks. Existing transferable attacks tend
to craft adversarial examples by indiscriminately distorting features to
degrade prediction accuracy in a source model without aware of intrinsic
features of objects in the images. We argue that such brute-force degradation
would introduce model-specific local optimum into adversarial examples, thus
limiting the transferability. By contrast, we propose the Feature
Importance-aware Attack (FIA), which disrupts important object-aware features
that dominate model decisions consistently. More specifically, we obtain
feature importance by introducing the aggregate gradient, which averages the
gradients with respect to feature maps of the source model, computed on a batch
of random transforms of the original clean image. The gradients will be highly
correlated to objects of interest, and such correlation presents invariance
across different models. Besides, the random transforms will preserve intrinsic
features of objects and suppress model-specific information. Finally, the
feature importance guides to search for adversarial examples towards disrupting
critical features, achieving stronger transferability. Extensive experimental
evaluation demonstrates the effectiveness and superior performance of the
proposed FIA, i.e., improving the success rate by 8.4% against normally trained
models and 11.7% against defense models as compared to the state-of-the-art
transferable attacks. Code is available at: https://github.com/hcguoO0/FIA</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video Generation from Text Employing Latent Path Construction for Temporal Modeling. (arXiv:2107.13766v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazaheri_A/0/1/0/all/0/1">Amir Mazaheri</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mubarak Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13766">
                                    <div class="article-summary-box-inner">
                                        <span>Video generation is one of the most challenging tasks in Machine Learning and
Computer Vision fields of study. In this paper, we tackle the text to video
generation problem, which is a conditional form of video generation. Humans can
listen/read natural language sentences, and can imagine or visualize what is
being described; therefore, we believe that video generation from natural
language sentences will have an important impact on Artificial Intelligence.
Video generation is relatively a new field of study in Computer Vision, which
is far from being solved. The majority of recent works deal with synthetic
datasets or real datasets with very limited types of objects, scenes, and
emotions. To the best of our knowledge, this is the very first work on the text
(free-form sentences) to video generation on more realistic video datasets like
Actor and Action Dataset (A2D) or UCF101. We tackle the complicated problem of
video generation by regressing the latent representations of the first and last
frames and employing a context-aware interpolation method to build the latent
representations of in-between frames. We propose a stacking &#x60;&#x60;upPooling&#x27;&#x27; block
to sequentially generate RGB frames out of each latent representation and
progressively increase the resolution. Moreover, our proposed Discriminator
encodes videos based on single and multiple frames. We provide quantitative and
qualitative results to support our arguments and show the superiority of our
method over well-known baselines like Recurrent Neural Network (RNN) and
Deconvolution (as known as Convolutional Transpose) based video generation
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mapping Vulnerable Populations with AI. (arXiv:2107.14123v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kellenberger_B/0/1/0/all/0/1">Benjamin Kellenberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Vargas_Munoz_J/0/1/0/all/0/1">John E. Vargas-Mu&#xf1;oz</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuia_D/0/1/0/all/0/1">Devis Tuia</a>, <a href="http://arxiv.org/find/cs/1/au:+Daudt_R/0/1/0/all/0/1">Rodrigo C. Daudt</a>, <a href="http://arxiv.org/find/cs/1/au:+Schindler_K/0/1/0/all/0/1">Konrad Schindler</a>, <a href="http://arxiv.org/find/cs/1/au:+Whelan_T/0/1/0/all/0/1">Thao T-T Whelan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayo_B/0/1/0/all/0/1">Brenda Ayo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ofli_F/0/1/0/all/0/1">Ferda Ofli</a>, <a href="http://arxiv.org/find/cs/1/au:+Imran_M/0/1/0/all/0/1">Muhammad Imran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14123">
                                    <div class="article-summary-box-inner">
                                        <span>Humanitarian actions require accurate information to efficiently delegate
support operations. Such information can be maps of building footprints,
building functions, and population densities. While the access to this
information is comparably easy in industrialized countries thanks to reliable
census data and national geo-data infrastructures, this is not the case for
developing countries, where that data is often incomplete or outdated. Building
maps derived from remote sensing images may partially remedy this challenge in
such countries, but are not always accurate due to different landscape
configurations and lack of validation data. Even when they exist, building
footprint layers usually do not reveal more fine-grained building properties,
such as the number of stories or the building&#x27;s function (e.g., office,
residential, school, etc.). In this project we aim to automate building
footprint and function mapping using heterogeneous data sources. In a first
step, we intend to delineate buildings from satellite data, using deep learning
models for semantic image segmentation. Building functions shall be retrieved
by parsing social media data like for instance tweets, as well as ground-based
imagery, to automatically identify different buildings functions and retrieve
further information such as the number of building stories. Building maps
augmented with those additional attributes make it possible to derive more
accurate population density maps, needed to support the targeted provision of
humanitarian aid.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Camera Feature Prediction for Intra-Camera Supervised Person Re-identification across Distant Scenes. (arXiv:2107.13904v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1">Wenhang Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_C/0/1/0/all/0/1">Chunyan Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1">Ancong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hongwei Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Wei-Shi Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13904">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification (Re-ID) aims to match person images across
non-overlapping camera views. The majority of Re-ID methods focus on
small-scale surveillance systems in which each pedestrian is captured in
different camera views of adjacent scenes. However, in large-scale surveillance
systems that cover larger areas, it is required to track a pedestrian of
interest across distant scenes (e.g., a criminal suspect escapes from one city
to another). Since most pedestrians appear in limited local areas, it is
difficult to collect training data with cross-camera pairs of the same person.
In this work, we study intra-camera supervised person re-identification across
distant scenes (ICS-DS Re-ID), which uses cross-camera unpaired data with
intra-camera identity labels for training. It is challenging as cross-camera
paired data plays a crucial role for learning camera-invariant features in most
existing Re-ID methods. To learn camera-invariant representation from
cross-camera unpaired training data, we propose a cross-camera feature
prediction method to mine cross-camera self supervision information from
camera-specific feature distribution by transforming fake cross-camera positive
feature pairs and minimize the distances of the fake pairs. Furthermore, we
automatically localize and extract local-level feature by a transformer. Joint
learning of global-level and local-level features forms a global-local
cross-camera feature prediction scheme for mining fine-grained cross-camera
self supervision information. Finally, cross-camera self supervision and
intra-camera supervision are aggregated in a framework. The experiments are
conducted in the ICS-DS setting on Market-SCT, Duke-SCT and MSMT17-SCT
datasets. The evaluation results demonstrate the superiority of our method,
which gains significant improvements of 15.4 Rank-1 and 22.3 mAP on Market-SCT
as compared to the second best method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recurrent U-net for automatic pelvic floor muscle segmentation on 3D ultrasound. (arXiv:2107.13833v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Noort_F/0/1/0/all/0/1">Frieda van den Noort</a>, <a href="http://arxiv.org/find/eess/1/au:+Sirmacek_B/0/1/0/all/0/1">Beril Sirmacek</a>, <a href="http://arxiv.org/find/eess/1/au:+Slump_C/0/1/0/all/0/1">Cornelis H. Slump</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13833">
                                    <div class="article-summary-box-inner">
                                        <span>The prevalance of pelvic floor problems is high within the female population.
Transperineal ultrasound (TPUS) is the main imaging modality used to
investigate these problems. Automating the analysis of TPUS data will help in
growing our understanding of pelvic floor related problems. In this study we
present a U-net like neural network with some convolutional long short term
memory (CLSTM) layers to automate the 3D segmentation of the levator ani muscle
(LAM) in TPUS volumes. The CLSTM layers are added to preserve the inter-slice
3D information. We reach human level performance on this segmentation task.
Therefore, we conclude that we successfully automated the segmentation of the
LAM on 3D TPUS data. This paves the way towards automatic in-vivo analysis of
the LAM mechanics in the context of large study populations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Abnormal Behavior Detection Based on Target Analysis. (arXiv:2107.13706v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Luchuan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Huihui Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_Q/0/1/0/all/0/1">Qi Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1">Nenghai Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13706">
                                    <div class="article-summary-box-inner">
                                        <span>Abnormal behavior detection in surveillance video is a pivotal part of the
intelligent city. Most existing methods only consider how to detect anomalies,
with less considering to explain the reason of the anomalies. We investigate an
orthogonal perspective based on the reason of these abnormal behaviors. To this
end, we propose a multivariate fusion method that analyzes each target through
three branches: object, action and motion. The object branch focuses on the
appearance information, the motion branch focuses on the distribution of the
motion features, and the action branch focuses on the action category of the
target. The information that these branches focus on is different, and they can
complement each other and jointly detect abnormal behavior. The final abnormal
score can then be obtained by combining the abnormal scores of the three
branches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Excavating AI&quot; Re-excavated: Debunking a Fallacious Account of the JAFFE Dataset. (arXiv:2107.13998v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyons_M/0/1/0/all/0/1">Michael J. Lyons</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13998">
                                    <div class="article-summary-box-inner">
                                        <span>Twenty-five years ago, my colleagues Miyuki Kamachi and Jiro Gyoba and I
designed and photographed JAFFE, a set of facial expression images intended for
use in a study of face perception. In 2019, without seeking permission or
informing us, Kate Crawford and Trevor Paglen exhibited JAFFE in two widely
publicized art shows. In addition, they published a nonfactual account of the
images in the essay &quot;Excavating AI: The Politics of Images in Machine Learning
Training Sets.&quot; The present article recounts the creation of the JAFFE dataset
and unravels each of Crawford and Paglen&#x27;s fallacious statements. I also
discuss JAFFE more broadly in connection with research on facial expression,
affective computing, and human-computer interaction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why You Should Try the Real Data for the Scene Text Recognition. (arXiv:2107.13938v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Loginov_V/0/1/0/all/0/1">Vladimir Loginov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13938">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works in the text recognition area have pushed forward the recognition
results to the new horizons. But for a long time a lack of large human-labeled
natural text recognition datasets has been forcing researchers to use synthetic
data for training text recognition models. Even though synthetic datasets are
very large (MJSynth and SynthTest, two most famous synthetic datasets, have
several million images each), their diversity could be insufficient, compared
to natural datasets like ICDAR and others. Fortunately, the recently released
text-recognition annotation for OpenImages V5 dataset has comparable with
synthetic dataset number of instances and more diverse examples. We have used
this annotation with a Text Recognition head architecture from the Yet Another
Mask Text Spotter and got comparable to the SOTA results. On some datasets we
have even outperformed previous SOTA models. In this paper we also introduce a
text recognition model. The model&#x27;s code is available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Need and Status of Sea Turtle Conservation and Survey of Associated Computer Vision Advances. (arXiv:2107.14061v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1">Aditya Jyoti Paul</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14061">
                                    <div class="article-summary-box-inner">
                                        <span>For over hundreds of millions of years, sea turtles and their ancestors have
swum in the vast expanses of the ocean. They have undergone a number of
evolutionary changes, leading to speciation and sub-speciation. However, in the
past few decades, some of the most notable forces driving the genetic variance
and population decline have been global warming and anthropogenic impact
ranging from large-scale poaching, collecting turtle eggs for food, besides
dumping trash including plastic waste into the ocean. This leads to severe
detrimental effects in the sea turtle population, driving them to extinction.
This research focusses on the forces causing the decline in sea turtle
population, the necessity for the global conservation efforts along with its
successes and failures, followed by an in-depth analysis of the modern advances
in detection and recognition of sea turtles, involving Machine Learning and
Computer Vision systems, aiding the conservation efforts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Active Learning with Temporal Output Discrepancy. (arXiv:2107.14153v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Siyu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huan_J/0/1/0/all/0/1">Jun Huan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14153">
                                    <div class="article-summary-box-inner">
                                        <span>While deep learning succeeds in a wide range of tasks, it highly depends on
the massive collection of annotated data which is expensive and time-consuming.
To lower the cost of data annotation, active learning has been proposed to
interactively query an oracle to annotate a small proportion of informative
samples in an unlabeled dataset. Inspired by the fact that the samples with
higher loss are usually more informative to the model than the samples with
lower loss, in this paper we present a novel deep active learning approach that
queries the oracle for data annotation when the unlabeled sample is believed to
incorporate high loss. The core of our approach is a measurement Temporal
Output Discrepancy (TOD) that estimates the sample loss by evaluating the
discrepancy of outputs given by models at different optimization steps. Our
theoretical investigation shows that TOD lower-bounds the accumulated sample
loss thus it can be used to select informative unlabeled samples. On basis of
TOD, we further develop an effective unlabeled data sampling strategy as well
as an unsupervised learning criterion that enhances model performance by
incorporating the unlabeled data. Due to the simplicity of TOD, our active
learning approach is efficient, flexible, and task-agnostic. Extensive
experimental results demonstrate that our approach achieves superior
performances than the state-of-the-art active learning methods on image
classification and semantic segmentation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Paced Contrastive Learning for Semi-supervisedMedical Image Segmentation with Meta-labels. (arXiv:2107.13741v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1">Jizong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Ping Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1">Chrisitian Desrosiers</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedersoli_M/0/1/0/all/0/1">Marco Pedersoli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13741">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-training a recognition model with contrastive learning on a large dataset
of unlabeled data has shown great potential to boost the performance of a
downstream task, e.g., image classification. However, in domains such as
medical imaging, collecting unlabeled data can be challenging and expensive. In
this work, we propose to adapt contrastive learning to work with meta-label
annotations, for improving the model&#x27;s performance in medical image
segmentation even when no additional unlabeled data is available. Meta-labels
such as the location of a 2D slice in a 3D MRI scan or the type of device used,
often come for free during the acquisition process. We use the meta-labels for
pre-training the image encoder as well as to regularize a semi-supervised
training, in which a reduced set of annotated data is used for training.
Finally, to fully exploit the weak annotations, a self-paced learning approach
is used to help the learning and discriminate useful labels from noise. Results
on three different medical image segmentation datasets show that our approach:
i) highly boosts the performance of a model trained on a few scans, ii)
outperforms previous contrastive and semi-supervised approaches, and iii)
reaches close to the performance of a model trained on the full data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human Trajectory Prediction via Counterfactual Analysis. (arXiv:2107.14202v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guangyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junlong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14202">
                                    <div class="article-summary-box-inner">
                                        <span>Forecasting human trajectories in complex dynamic environments plays a
critical role in autonomous vehicles and intelligent robots. Most existing
methods learn to predict future trajectories by behavior clues from history
trajectories and interaction clues from environments. However, the inherent
bias between training and deployment environments is ignored. Hence, we propose
a counterfactual analysis method for human trajectory prediction to investigate
the causality between the predicted trajectories and input clues and alleviate
the negative effects brought by environment bias. We first build a causal graph
for trajectory forecasting with history trajectory, future trajectory, and the
environment interactions. Then, we cut off the inference from environment to
trajectory by constructing the counterfactual intervention on the trajectory
itself. Finally, we compare the factual and counterfactual trajectory clues to
alleviate the effects of environment bias and highlight the trajectory clues.
Our counterfactual analysis is a plug-and-play module that can be applied to
any baseline prediction methods including RNN- and CNN-based ones. We show that
our method achieves consistent improvement for different baselines and obtains
the state-of-the-art results on public pedestrian trajectory forecasting
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The interpretation of endobronchial ultrasound image using 3D convolutional neural network for differentiating malignant and benign mediastinal lesions. (arXiv:2107.13820v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ching/0/1/0/all/0/1">Ching</a>, <a href="http://arxiv.org/find/eess/1/au:+Lin_K/0/1/0/all/0/1">Kai Lin</a>, <a href="http://arxiv.org/find/eess/1/au:+Shao/0/1/0/all/0/1">Shao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_H/0/1/0/all/0/1">Hua Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chang_J/0/1/0/all/0/1">Jerry Chang</a>, Yun, <a href="http://arxiv.org/find/eess/1/au:+Cheng_C/0/1/0/all/0/1">Chien Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13820">
                                    <div class="article-summary-box-inner">
                                        <span>The purpose of this study is to differentiate malignant and benign
mediastinal lesions by using the three-dimensional convolutional neural network
through the endobronchial ultrasound (EBUS) image. Compared with previous
study, our proposed model is robust to noise and able to fuse various imaging
features and spatiotemporal features of EBUS videos. Endobronchial
ultrasound-guided transbronchial needle aspiration (EBUS-TBNA) is a diagnostic
tool for intrathoracic lymph nodes. Physician can observe the characteristics
of the lesion using grayscale mode, doppler mode, and elastography during the
procedure. To process the EBUS data in the form of a video and appropriately
integrate the features of multiple imaging modes, we used a time-series
three-dimensional convolutional neural network (3D CNN) to learn the
spatiotemporal features and design a variety of architectures to fuse each
imaging mode. Our model (Res3D_UDE) took grayscale mode, Doppler mode, and
elastography as training data and achieved an accuracy of 82.00% and area under
the curve (AUC) of 0.83 on the validation set. Compared with previous study, we
directly used videos recorded during procedure as training and validation data,
without additional manual selection, which might be easier for clinical
application. In addition, model designed with 3D CNN can also effectively learn
spatiotemporal features and improve accuracy. In the future, our model may be
used to guide physicians to quickly and correctly find the target lesions for
slice sampling during the inspection process, reduce the number of slices of
benign lesions, and shorten the inspection time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improvement of image classification by multiple optical scattering. (arXiv:2107.14051v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xinyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_Y/0/1/0/all/0/1">Yanqing Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_B/0/1/0/all/0/1">Bangning Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Miaogen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1">Yanlong Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chunliu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Juan Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Changyu Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14051">
                                    <div class="article-summary-box-inner">
                                        <span>Multiple optical scattering occurs when light propagates in a non-uniform
medium. During the multiple scattering, images were distorted and the spatial
information they carried became scrambled. However, the image information is
not lost but presents in the form of speckle patterns (SPs). In this study, we
built up an optical random scattering system based on an LCD and an RGB laser
source. We found that the image classification can be improved by the help of
random scattering which is considered as a feedforward neural network to
extracts features from image. Along with the ridge classification deployed on
computer, we achieved excellent classification accuracy higher than 94%, for a
variety of data sets covering medical, agricultural, environmental protection
and other fields. In addition, the proposed optical scattering system has the
advantages of high speed, low power consumption, and miniaturization, which is
suitable for deploying in edge computing applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry Uncertainty Projection Network for Monocular 3D Object Detection. (arXiv:2107.13774v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xinzhu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianzhu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yating Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_Q/0/1/0/all/0/1">Qi Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junjie Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13774">
                                    <div class="article-summary-box-inner">
                                        <span>Geometry Projection is a powerful depth estimation method in monocular 3D
object detection. It estimates depth dependent on heights, which introduces
mathematical priors into the deep model. But projection process also introduces
the error amplification problem, in which the error of the estimated height
will be amplified and reflected greatly at the output depth. This property
leads to uncontrollable depth inferences and also damages the training
efficiency. In this paper, we propose a Geometry Uncertainty Projection Network
(GUP Net) to tackle the error amplification problem at both inference and
training stages. Specifically, a GUP module is proposed to obtains the
geometry-guided uncertainty of the inferred depth, which not only provides high
reliable confidence for each depth but also benefits depth learning.
Furthermore, at the training stage, we propose a Hierarchical Task Learning
strategy to reduce the instability caused by error amplification. This learning
algorithm monitors the learning situation of each task by a proposed indicator
and adaptively assigns the proper loss weights for different tasks according to
their pre-tasks situation. Based on that, each task starts learning only when
its pre-tasks are learned well, which can significantly improve the stability
and efficiency of the training process. Extensive experiments demonstrate the
effectiveness of the proposed method. The overall model can infer more reliable
object depth than existing methods and outperforms the state-of-the-art
image-based monocular 3D detectors by 3.74% and 4.7% AP40 of the car and
pedestrian categories on the KITTI benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Egyptian Sign Language Recognition Using CNN and LSTM. (arXiv:2107.13647v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elhagry_A/0/1/0/all/0/1">Ahmed Elhagry</a>, <a href="http://arxiv.org/find/cs/1/au:+Gla_R/0/1/0/all/0/1">Rawan Gla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13647">
                                    <div class="article-summary-box-inner">
                                        <span>Sign language is a set of gestures that deaf people use to communicate.
Unfortunately, normal people don&#x27;t understand it, which creates a communication
gap that needs to be filled. Because of the variations in (Egyptian Sign
Language) ESL from one region to another, ESL provides a challenging research
problem. In this work, we are providing applied research with its video-based
Egyptian sign language recognition system that serves the local community of
deaf people in Egypt, with a moderate and reasonable accuracy. We present a
computer vision system with two different neural networks architectures. The
first is a Convolutional Neural Network (CNN) for extracting spatial features.
The CNN model was retrained on the inception mod. The second architecture is a
CNN followed by a Long Short-Term Memory (LSTM) for extracting both spatial and
temporal features. The two models achieved an accuracy of 90% and 72%,
respectively. We examined the power of these two architectures to distinguish
between 9 common words (with similar signs) among some deaf people community in
Egypt.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Similarity Measure of Histopathology Images by Deep Embeddings. (arXiv:2107.13703v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Afshari_M/0/1/0/all/0/1">Mehdi Afshari</a>, <a href="http://arxiv.org/find/eess/1/au:+Tizhoosh_H/0/1/0/all/0/1">H.R. Tizhoosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13703">
                                    <div class="article-summary-box-inner">
                                        <span>Histopathology digital scans are large-size images that contain valuable
information at the pixel level. Content-based comparison of these images is a
challenging task. This study proposes a content-based similarity measure for
high-resolution gigapixel histopathology images. The proposed similarity
measure is an expansion of cosine vector similarity to a matrix. Each image is
divided into same-size patches with a meaningful amount of information (i.e.,
contained enough tissue). The similarity is measured by the extraction of
patch-level deep embeddings of the last pooling layer of a pre-trained deep
model at four different magnification levels, namely, 1x, 2.5x, 5x, and 10x
magnifications. In addition, for faster measurement, embedding reduction is
investigated. Finally, to assess the proposed method, an image search method is
implemented. Results show that the similarity measure represents the slide
labels with a maximum accuracy of 93.18\% for top-5 search at 5x magnification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Robustness and Accuracy via Relative Information Encoding in 3D Human Pose Estimation. (arXiv:2107.13994v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shan_W/0/1/0/all/0/1">Wenkang Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Haopeng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shanshe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wen Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13994">
                                    <div class="article-summary-box-inner">
                                        <span>Most of the existing 3D human pose estimation approaches mainly focus on
predicting 3D positional relationships between the root joint and other human
joints (local motion) instead of the overall trajectory of the human body
(global motion). Despite the great progress achieved by these approaches, they
are not robust to global motion, and lack the ability to accurately predict
local motion with a small movement range. To alleviate these two problems, we
propose a relative information encoding method that yields positional and
temporal enhanced representations. Firstly, we encode positional information by
utilizing relative coordinates of 2D poses to enhance the consistency between
the input and output distribution. The same posture with different absolute 2D
positions can be mapped to a common representation. It is beneficial to resist
the interference of global motion on the prediction results. Second, we encode
temporal information by establishing the connection between the current pose
and other poses of the same person within a period of time. More attention will
be paid to the movement changes before and after the current pose, resulting in
better prediction performance on local motion with a small movement range. The
ablation studies validate the effectiveness of the proposed relative
information encoding method. Besides, we introduce a multi-stage optimization
method to the whole framework to further exploit the positional and temporal
enhanced representations. Our method outperforms state-of-the-art methods on
two public datasets. Code is available at
https://github.com/paTRICK-swk/Pose3D-RIE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalizing Gaze Estimation with Outlier-guided Collaborative Adaptation. (arXiv:2107.13780v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yunfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Ruicong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haofei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_F/0/1/0/all/0/1">Feng Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13780">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have significantly improved appearance-based gaze
estimation accuracy. However, it still suffers from unsatisfactory performance
when generalizing the trained model to new domains, e.g., unseen environments
or persons. In this paper, we propose a plug-and-play gaze adaptation framework
(PnP-GA), which is an ensemble of networks that learn collaboratively with the
guidance of outliers. Since our proposed framework does not require
ground-truth labels in the target domain, the existing gaze estimation networks
can be directly plugged into PnP-GA and generalize the algorithms to new
domains. We test PnP-GA on four gaze domain adaptation tasks, ETH-to-MPII,
ETH-to-EyeDiap, Gaze360-to-MPII, and Gaze360-to-EyeDiap. The experimental
results demonstrate that the PnP-GA framework achieves considerable performance
improvements of 36.9%, 31.6%, 19.4%, and 11.8% over the baseline system. The
proposed framework also outperforms the state-of-the-art domain adaptation
approaches on gaze domain adaptation tasks. Code has been released at
https://github.com/DreamtaleCore/PnP-GA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Self-supervised Augmented Knowledge Distillation. (arXiv:2107.13715v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chuanguang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+An_Z/0/1/0/all/0/1">Zhulin An</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1">Linhang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yongjun Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13715">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation often involves how to define and transfer knowledge
from teacher to student effectively. Although recent self-supervised
contrastive knowledge achieves the best performance, forcing the network to
learn such knowledge may damage the representation learning of the original
class recognition task. We therefore adopt an alternative self-supervised
augmented task to guide the network to learn the joint distribution of the
original recognition task and self-supervised auxiliary task. It is
demonstrated as a richer knowledge to improve the representation power without
losing the normal classification capability. Moreover, it is incomplete that
previous methods only transfer the probabilistic knowledge between the final
layers. We propose to append several auxiliary classifiers to hierarchical
intermediate feature maps to generate diverse self-supervised knowledge and
perform the one-to-one transfer to teach the student network thoroughly. Our
method significantly surpasses the previous SOTA SSKD with an average
improvement of 2.56\% on CIFAR-100 and an improvement of 0.77\% on ImageNet
across widely used network pairs. Codes are available at
https://github.com/winycg/HSAKD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Similarity and symmetry measures based on fuzzy descriptors of image objects&#x60; composition. (arXiv:2107.13651v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Iwanowski_M/0/1/0/all/0/1">Marcin Iwanowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Grzabka_M/0/1/0/all/0/1">Marcin Grzabka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13651">
                                    <div class="article-summary-box-inner">
                                        <span>The paper describes a method for measuring the similarity and symmetry of an
image annotated with bounding boxes indicating image objects. The latter
representation became popular recently due to the rapid development of fast and
efficient deep-learning-based object-detection methods. The proposed approach
allows for comparing sets of bounding boxes to estimate the degree of
similarity of their underlying images. It is based on the fuzzy approach that
uses the fuzzy mutual position (FMP) matrix to describe spatial composition and
relations between bounding boxes within an image. A method of computing the
similarity of two images described by their FMP matrices is proposed and the
algorithm of its computation. It outputs the single scalar value describing the
degree of content-based image similarity. By modifying the method&#x60;s parameters,
instead of similarity, the reflectional symmetry of object composition may also
be measured. The proposed approach allows for measuring differences in objects&#x60;
composition of various intensities. It is also invariant to translation and
scaling and - in case of symmetry detection - position and orientation of the
symmetry axis. A couple of examples illustrate the method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UIBert: Learning Generic Multimodal Representations for UI Understanding. (arXiv:2107.13731v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_C/0/1/0/all/0/1">Chongyang Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zang_X/0/1/0/all/0/1">Xiaoxue Zang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Ying Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunkara_S/0/1/0/all/0/1">Srinivas Sunkara</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1">Abhinav Rastogi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jindong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Arcas_B/0/1/0/all/0/1">Blaise Aguera y Arcas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13731">
                                    <div class="article-summary-box-inner">
                                        <span>To improve the accessibility of smart devices and to simplify their usage,
building models which understand user interfaces (UIs) and assist users to
complete their tasks is critical. However, unique challenges are proposed by
UI-specific characteristics, such as how to effectively leverage multimodal UI
features that involve image, text, and structural metadata and how to achieve
good performance when high-quality labeled data is unavailable. To address such
challenges we introduce UIBert, a transformer-based joint image-text model
trained through novel pre-training tasks on large-scale unlabeled UI data to
learn generic feature representations for a UI and its components. Our key
intuition is that the heterogeneous features in a UI are self-aligned, i.e.,
the image and text features of UI components, are predictive of each other. We
propose five pretraining tasks utilizing this self-alignment among different
features of a UI component and across various components in the same UI. We
evaluate our method on nine real-world downstream UI tasks where UIBert
outperforms strong multimodal baselines by up to 9.26% accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Profile to Frontal Face Recognition in the Wild Using Coupled Conditional GAN. (arXiv:2107.13742v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taherkhani_F/0/1/0/all/0/1">Fariborz Taherkhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Talreja_V/0/1/0/all/0/1">Veeru Talreja</a>, <a href="http://arxiv.org/find/cs/1/au:+Dawson_J/0/1/0/all/0/1">Jeremy Dawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Valenti_M/0/1/0/all/0/1">Matthew C. Valenti</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1">Nasser M. Nasrabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13742">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, with the advent of deep-learning, face recognition has
achieved exceptional success. However, many of these deep face recognition
models perform much better in handling frontal faces compared to profile faces.
The major reason for poor performance in handling of profile faces is that it
is inherently difficult to learn pose-invariant deep representations that are
useful for profile face recognition. In this paper, we hypothesize that the
profile face domain possesses a latent connection with the frontal face domain
in a latent feature subspace. We look to exploit this latent connection by
projecting the profile faces and frontal faces into a common latent subspace
and perform verification or retrieval in the latent domain. We leverage a
coupled conditional generative adversarial network (cpGAN) structure to find
the hidden relationship between the profile and frontal images in a latent
common embedding subspace. Specifically, the cpGAN framework consists of two
conditional GAN-based sub-networks, one dedicated to the frontal domain and the
other dedicated to the profile domain. Each sub-network tends to find a
projection that maximizes the pair-wise correlation between the two feature
domains in a common embedding feature subspace. The efficacy of our approach
compared with the state-of-the-art is demonstrated using the CFP, CMU
Multi-PIE, IJB-A, and IJB-C datasets. Additionally, we have also implemented a
coupled convolutional neural network (cpCNN) and an adversarial discriminative
domain adaptation network (ADDA) for profile to frontal face recognition. We
have evaluated the performance of cpCNN and ADDA and compared it with the
proposed cpGAN. Finally, we have also evaluated our cpGAN for reconstruction of
frontal faces from input profile faces contained in the VGGFace2 dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Corridor for new mobility Aachen-D\&quot;usseldorf: Methods and concepts of the research project ACCorD. (arXiv:2107.14048v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kloeker_L/0/1/0/all/0/1">Laurent Kloeker</a>, <a href="http://arxiv.org/find/cs/1/au:+Kloeker_A/0/1/0/all/0/1">Amarin Kloeker</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomsen_F/0/1/0/all/0/1">Fabian Thomsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Erraji_A/0/1/0/all/0/1">Armin Erraji</a>, <a href="http://arxiv.org/find/cs/1/au:+Eckstein_L/0/1/0/all/0/1">Lutz Eckstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamberty_S/0/1/0/all/0/1">Serge Lamberty</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazekas_A/0/1/0/all/0/1">Adrian Fazekas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kallo_E/0/1/0/all/0/1">Eszter Kall&#xf3;</a>, <a href="http://arxiv.org/find/cs/1/au:+Oeser_M/0/1/0/all/0/1">Markus Oeser</a>, <a href="http://arxiv.org/find/cs/1/au:+Flechon_C/0/1/0/all/0/1">Charlotte Fl&#xe9;chon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lohmiller_J/0/1/0/all/0/1">Jochen Lohmiller</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfeiffer_P/0/1/0/all/0/1">Pascal Pfeiffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sommer_M/0/1/0/all/0/1">Martin Sommer</a>, <a href="http://arxiv.org/find/cs/1/au:+Winter_H/0/1/0/all/0/1">Helen Winter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14048">
                                    <div class="article-summary-box-inner">
                                        <span>With the Corridor for New Mobility Aachen - D\&quot;usseldorf, an integrated
development environment is created, incorporating existing test capabilities,
to systematically test and validate automated vehicles in interaction with
connected Intelligent Transport Systems Stations (ITS-Ss). This is achieved
through a time- and cost-efficient toolchain and methodology, in which
simulation, closed test sites as well as test fields in public transport are
linked in the best possible way. By implementing a digital twin, the recorded
traffic events can be visualized in real-time and driving functions can be
tested in the simulation based on real data. In order to represent diverse
traffic scenarios, the corridor contains a highway section, a rural area, and
urban areas. First, this paper outlines the project goals before describing the
individual project contents in more detail. These include the concepts of
traffic detection, driving function development, digital twin development, and
public involvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Human Pose Estimation by Maximizing Fusion and High-Level Spatial Attention. (arXiv:2107.13693v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1">Zhiyuan Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yaohai Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yizhe Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1">Ruisong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yayu Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13693">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an efficient human pose estimation network -- SFM
(slender fusion model) by fusing multi-level features and adding lightweight
attention blocks -- HSA (High-Level Spatial Attention). Many existing methods
on efficient network have already taken feature fusion into consideration,
which largely boosts the performance. However, its performance is far inferior
to large network such as ResNet and HRNet due to its limited fusion operation
in the network. Specifically, we expand the number of fusion operation by
building bridges between two pyramid frameworks without adding layers.
Meanwhile, to capture long-range dependency, we propose a lightweight attention
block -- HSA, which computes second-order attention map. In summary, SFM
maximizes the number of feature fusion in a limited number of layers. HSA
learns high precise spatial information by computing the attention of spatial
attention map. With the help of SFM and HSA, our network is able to generate
multi-level feature and extract precise global spatial information with little
computing resource. Thus, our method achieve comparable or even better accuracy
with less parameters and computational cost. Our SFM achieve 89.0 in PCKh@0.5,
42.0 in PCKh@0.1 on MPII validation set and 71.7 in AP, 90.7 in AP@0.5 on COCO
validation with only 1.7G FLOPs and 1.5M parameters. The source code will be
public soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Viewpoint-Invariant Exercise Repetition Counting. (arXiv:2107.13760v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_Y/0/1/0/all/0/1">Yu Cheng Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingpeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsougenis_E/0/1/0/all/0/1">Efstratios Tsougenis</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsui_K/0/1/0/all/0/1">Kwok-Leung Tsui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13760">
                                    <div class="article-summary-box-inner">
                                        <span>Counting the repetition of human exercise and physical rehabilitation is a
common task in rehabilitation and exercise training. The existing vision-based
repetition counting methods less emphasize the concurrent motions in the same
video. This work presents a vision-based human motion repetition counting
applicable to counting concurrent motions through the skeleton location
extracted from various pose estimation methods. The presented method was
validated on the University of Idaho Physical Rehabilitation Movements Data Set
(UI-PRMD), and MM-fit dataset. The overall mean absolute error (MAE) for mm-fit
was 0.06 with off-by-one Accuracy (OBOA) 0.94. Overall MAE for UI-PRMD dataset
was 0.06 with OBOA 0.95. We have also tested the performance in a variety of
camera locations and concurrent motions with conveniently collected video with
overall MAE 0.06 and OBOA 0.88. The proposed method provides a view-angle and
motion agnostic concurrent motion counting. This method can potentially use in
large-scale remote rehabilitation and exercise training with only one camera.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lighter Stacked Hourglass Human Pose Estimation. (arXiv:2107.13643v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elhagry_A/0/1/0/all/0/1">Ahmed Elhagry</a>, <a href="http://arxiv.org/find/cs/1/au:+Saeed_M/0/1/0/all/0/1">Mohamed Saeed</a>, <a href="http://arxiv.org/find/cs/1/au:+Araia_M/0/1/0/all/0/1">Musie Araia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13643">
                                    <div class="article-summary-box-inner">
                                        <span>Human pose estimation (HPE) is one of the most challenging tasks in computer
vision as humans are deformable by nature and thus their pose has so much
variance. HPE aims to correctly identify the main joint locations of a single
person or multiple people in a given image or video. Locating joints of a
person in images or videos is an important task that can be applied in action
recognition and object tracking. As have many computer vision tasks, HPE has
advanced massively with the introduction of deep learning to the field. In this
paper, we focus on one of the deep learning-based approaches of HPE proposed by
Newell et al., which they named the stacked hourglass network. Their approach
is widely used in many applications and is regarded as one of the best works in
this area. The main focus of their approach is to capture as much information
as it can at all possible scales so that a coherent understanding of the local
features and full-body location is achieved. Their findings demonstrate that
important cues such as orientation of a person, arrangement of limbs, and
adjacent joints&#x27; relative location can be identified from multiple scales at
different resolutions. To do so, they makes use of a single pipeline to process
images in multiple resolutions, which comprises a skip layer to not lose
spatial information at each resolution. The resolution of the images stretches
as lower as 4x4 to make sure that a smaller spatial feature is included. In
this study, we study the effect of architectural modifications on the
computational speed and accuracy of the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Transformer based Dual Discriminator Generative Adversarial Networks for Video Anomaly Detection. (arXiv:2107.13720v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xinyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dongjin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuncong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengzhang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1">Jingchao Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13720">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting abnormal activities in real-world surveillance videos is an
important yet challenging task as the prior knowledge about video anomalies is
usually limited or unavailable. Despite that many approaches have been
developed to resolve this problem, few of them can capture the normal
spatio-temporal patterns effectively and efficiently. Moreover, existing works
seldom explicitly consider the local consistency at frame level and global
coherence of temporal dynamics in video sequences. To this end, we propose
Convolutional Transformer based Dual Discriminator Generative Adversarial
Networks (CT-D2GAN) to perform unsupervised video anomaly detection.
Specifically, we first present a convolutional transformer to perform future
frame prediction. It contains three key components, i.e., a convolutional
encoder to capture the spatial information of the input video clips, a temporal
self-attention module to encode the temporal dynamics, and a convolutional
decoder to integrate spatio-temporal features and predict the future frame.
Next, a dual discriminator based adversarial training procedure, which jointly
considers an image discriminator that can maintain the local consistency at
frame-level and a video discriminator that can enforce the global coherence of
temporal dynamics, is employed to enhance the future frame prediction. Finally,
the prediction error is used to identify abnormal video frames. Thoroughly
empirical studies on three public video anomaly detection datasets, i.e., UCSD
Ped2, CUHK Avenue, and Shanghai Tech Campus, demonstrate the effectiveness of
the proposed adversarial spatio-temporal modeling framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast and Scalable Image Search For Histology. (arXiv:2107.13587v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chengkuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_M/0/1/0/all/0/1">Ming Y. Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Williamson_D/0/1/0/all/0/1">Drew F. K. Williamson</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tiffany Y. Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaumberg_A/0/1/0/all/0/1">Andrew J. Schaumberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_F/0/1/0/all/0/1">Faisal Mahmood</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13587">
                                    <div class="article-summary-box-inner">
                                        <span>The expanding adoption of digital pathology has enabled the curation of large
repositories of histology whole slide images (WSIs), which contain a wealth of
information. Similar pathology image search offers the opportunity to comb
through large historical repositories of gigapixel WSIs to identify cases with
similar morphological features and can be particularly useful for diagnosing
rare diseases, identifying similar cases for predicting prognosis, treatment
outcomes, and potential clinical trial success. A critical challenge in
developing a WSI search and retrieval system is scalability, which is uniquely
challenging given the need to search a growing number of slides that each can
consist of billions of pixels and are several gigabytes in size. Such systems
are typically slow and retrieval speed often scales with the size of the
repository they search through, making their clinical adoption tedious and are
not feasible for repositories that are constantly growing. Here we present Fast
Image Search for Histopathology (FISH), a histology image search pipeline that
is infinitely scalable and achieves constant search speed that is independent
of the image database size while being interpretable and without requiring
detailed annotations. FISH uses self-supervised deep learning to encode
meaningful representations from WSIs and a Van Emde Boas tree for fast search,
followed by an uncertainty-based ranking algorithm to retrieve similar WSIs. We
evaluated FISH on multiple tasks and datasets with over 22,000 patient cases
spanning 56 disease subtypes. We additionally demonstrate that FISH can be used
to assist with the diagnosis of rare cancer types where sufficient cases may
not be available to train traditional supervised deep models. FISH is available
as an easy-to-use, open-source software package
(https://github.com/mahmoodlab/FISH).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sign and Search: Sign Search Functionality for Sign Language Lexica. (arXiv:2107.13637v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fragkiadakis_M/0/1/0/all/0/1">Manolis Fragkiadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Putten_P/0/1/0/all/0/1">Peter van der Putten</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13637">
                                    <div class="article-summary-box-inner">
                                        <span>Sign language lexica are a useful resource for researchers and people
learning sign languages. Current implementations allow a user to search a sign
either by its gloss or by selecting its primary features such as handshape and
location. This study focuses on exploring a reverse search functionality where
a user can sign a query sign in front of a webcam and retrieve a set of
matching signs. By extracting different body joints combinations (upper body,
dominant hand&#x27;s arm and wrist) using the pose estimation framework OpenPose, we
compare four techniques (PCA, UMAP, DTW and Euclidean distance) as distance
metrics between 20 query signs, each performed by eight participants on a 1200
sign lexicon. The results show that UMAP and DTW can predict a matching sign
with an 80\% and 71\% accuracy respectively at the top-20 retrieved signs using
the movement of the dominant hand arm. Using DTW and adding more sign instances
from other participants in the lexicon, the accuracy can be raised to 90\% at
the top-10 ranking. Our results suggest that our methodology can be used with
no training in any sign language lexicon regardless of its size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging Gap between Image Pixels and Semantics via Supervision: A Survey. (arXiv:2107.13757v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1">Jiali Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13757">
                                    <div class="article-summary-box-inner">
                                        <span>The fact that there exists a gap between low-level features and semantic
meanings of images, called the semantic gap, is known for decades. Resolution
of the semantic gap is a long standing problem. The semantic gap problem is
reviewed and a survey on recent efforts in bridging the gap is made in this
work. Most importantly, we claim that the semantic gap is primarily bridged
through supervised learning today. Experiences are drawn from two application
domains to illustrate this point: 1) object detection and 2) metric learning
for content-based image retrieval (CBIR). To begin with, this paper offers a
historical retrospective on supervision, makes a gradual transition to the
modern data-driven methodology and introduces commonly used datasets. Then, it
summarizes various supervision methods to bridge the semantic gap in the
context of object detection and metric learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Learning for Fine-Grained Image Classification. (arXiv:2107.13973v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Breiki_F/0/1/0/all/0/1">Farha Al Breiki</a>, <a href="http://arxiv.org/find/cs/1/au:+Ridzuan_M/0/1/0/all/0/1">Muhammad Ridzuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Grandhe_R/0/1/0/all/0/1">Rushali Grandhe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13973">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-grained image classification involves identifying different
subcategories of a class which possess very subtle discriminatory features.
Fine-grained datasets usually provide bounding box annotations along with class
labels to aid the process of classification. However, building large scale
datasets with such annotations is a mammoth task. Moreover, this extensive
annotation is time-consuming and often requires expertise, which is a huge
bottleneck in building large datasets. On the other hand, self-supervised
learning (SSL) exploits the freely available data to generate supervisory
signals which act as labels. The features learnt by performing some pretext
tasks on huge unlabelled data proves to be very helpful for multiple downstream
tasks.

Our idea is to leverage self-supervision such that the model learns useful
representations of fine-grained image classes. We experimented with 3 kinds of
models: Jigsaw solving as pretext task, adversarial learning (SRGAN) and
contrastive learning based (SimCLR) model. The learned features are used for
downstream tasks such as fine-grained image classification. Our code is
available at
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalizing Fairness: Discovery and Mitigation of Unknown Sensitive Attributes. (arXiv:2107.13625v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1">William Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1">Philippe Burlina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13625">
                                    <div class="article-summary-box-inner">
                                        <span>When deploying artificial intelligence (AI) in the real world, being able to
trust the operation of the AI by characterizing how it performs is an
ever-present and important topic. An important and still largely unexplored
task in this characterization is determining major factors within the real
world that affect the AI&#x27;s behavior, such as weather conditions or lighting,
and either a) being able to give justification for why it may have failed or b)
eliminating the influence the factor has. Determining these sensitive factors
heavily relies on collected data that is diverse enough to cover numerous
combinations of these factors, which becomes more onerous when having many
potential sensitive factors or operating in complex environments. This paper
investigates methods that discover and separate out individual semantic
sensitive factors from a given dataset to conduct this characterization as well
as addressing mitigation of these factors&#x27; sensitivity. We also broaden
remediation of fairness, which normally only addresses socially relevant
factors, and widen it to deal with the desensitization of AI with regard to all
possible aspects of variation in the domain. The proposed methods which
discover these major factors reduce the potentially onerous demands of
collecting a sufficiently diverse dataset. In experiments using the road sign
(GTSRB) and facial imagery (CelebA) datasets, we show the promise of using this
scheme to perform this characterization and remediation and demonstrate that
our approach outperforms state of the art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Geometry-Guided Depth via Projective Modeling for Monocular 3D Object Detection. (arXiv:2107.13931v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yinmin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xinzhu Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Shuai Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Jun Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhihui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dan Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13931">
                                    <div class="article-summary-box-inner">
                                        <span>As a crucial task of autonomous driving, 3D object detection has made great
progress in recent years. However, monocular 3D object detection remains a
challenging problem due to the unsatisfactory performance in depth estimation.
Most existing monocular methods typically directly regress the scene depth
while ignoring important relationships between the depth and various geometric
elements (e.g. bounding box sizes, 3D object dimensions, and object poses). In
this paper, we propose to learn geometry-guided depth estimation with
projective modeling to advance monocular 3D object detection. Specifically, a
principled geometry formula with projective modeling of 2D and 3D depth
predictions in the monocular 3D object detection network is devised. We further
implement and embed the proposed formula to enable geometry-aware deep
representation learning, allowing effective 2D and 3D interactions for boosting
the depth estimation. Moreover, we provide a strong baseline through addressing
substantial misalignment between 2D annotation and projected boxes to ensure
robust learning with the proposed geometric formula. Experiments on the KITTI
dataset show that our method remarkably improves the detection performance of
the state-of-the-art monocular-based method without extra data by 2.80% on the
moderate test setting. The model and code will be released at
https://github.com/YinminZhang/MonoGeo.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pitch-Informed Instrument Assignment Using a Deep Convolutional Network with Multiple Kernel Shapes. (arXiv:2107.13617v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lordelo_C/0/1/0/all/0/1">Carlos Lordelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Benetos_E/0/1/0/all/0/1">Emmanouil Benetos</a>, <a href="http://arxiv.org/find/cs/1/au:+Dixon_S/0/1/0/all/0/1">Simon Dixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahlback_S/0/1/0/all/0/1">Sven Ahlb&#xe4;ck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13617">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a deep convolutional neural network for performing
note-level instrument assignment. Given a polyphonic multi-instrumental music
signal along with its ground truth or predicted notes, the objective is to
assign an instrumental source for each note. This problem is addressed as a
pitch-informed classification task where each note is analysed individually. We
also propose to utilise several kernel shapes in the convolutional layers in
order to facilitate learning of efficient timbre-discriminative feature maps.
Experiments on the MusicNet dataset using 7 instrument classes show that our
approach is able to achieve an average F-score of 0.904 when the original
multi-pitch annotations are used as the pitch information for the system, and
that it also excels if the note information is provided using third-party
multi-pitch estimation algorithms. We also include ablation studies
investigating the effects of the use of multiple kernel shapes and comparing
different input representations for the audio and the note-related information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ranking Micro-Influencers: a Novel Multi-Task Learning and Interpretable Framework. (arXiv:2107.13943v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elwood_A/0/1/0/all/0/1">Adam Elwood</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasparin_A/0/1/0/all/0/1">Alberto Gasparin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozza_A/0/1/0/all/0/1">Alessandro Rozza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13943">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise in use of social media to promote branded products, the demand
for effective influencer marketing has increased. Brands are looking for
improved ways to identify valuable influencers among a vast catalogue; this is
even more challenging with &quot;micro-influencers&quot;, which are more affordable than
mainstream ones but difficult to discover. In this paper, we propose a novel
multi-task learning framework to improve the state of the art in
micro-influencer ranking based on multimedia content. Moreover, since the
visual congruence between a brand and influencer has been shown to be good
measure of compatibility, we provide an effective visual method for
interpreting our models&#x27; decisions, which can also be used to inform brands&#x27;
media strategies. We compare with the current state-of-the-art on a recently
constructed public dataset and we show significant improvement both in terms of
accuracy and model complexity. The techniques for ranking and interpretation
presented in this work can be generalised to arbitrary multimedia ranking tasks
that have datasets with a similar structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Effects of Adversarial Personalized Ranking Optimization Method on Recommendation Quality. (arXiv:2107.13876v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anelli_V/0/1/0/all/0/1">Vito Walter Anelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Deldjoo_Y/0/1/0/all/0/1">Yashar Deldjoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1">Tommaso Di Noia</a>, <a href="http://arxiv.org/find/cs/1/au:+Merra_F/0/1/0/all/0/1">Felice Antonio Merra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13876">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems (RSs) employ user-item feedback, e.g., ratings, to match
customers to personalized lists of products. Approaches to top-k recommendation
mainly rely on Learning-To-Rank algorithms and, among them, the most widely
adopted is Bayesian Personalized Ranking (BPR), which bases on a pair-wise
optimization approach. Recently, BPR has been found vulnerable against
adversarial perturbations of its model parameters. Adversarial Personalized
Ranking (APR) mitigates this issue by robustifying BPR via an adversarial
training procedure. The empirical improvements of APR&#x27;s accuracy performance on
BPR have led to its wide use in several recommender models. However, a key
overlooked aspect has been the beyond-accuracy performance of APR, i.e.,
novelty, coverage, and amplification of popularity bias, considering that
recent results suggest that BPR, the building block of APR, is sensitive to the
intensification of biases and reduction of recommendation novelty. In this
work, we model the learning characteristics of the BPR and APR optimization
frameworks to give mathematical evidence that, when the feedback data have a
tailed distribution, APR amplifies the popularity bias more than BPR due to an
unbalanced number of received positive updates from short-head items. Using
matrix factorization (MF), we empirically validate the theoretical results by
performing preliminary experiments on two public datasets to compare BPR-MF and
APR-MF performance on accuracy and beyond-accuracy metrics. The experimental
results consistently show the degradation of novelty and coverage measures and
a worrying amplification of bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PAD: a graphical and numerical enhancement of structural coding to facilitate thematic analysis of a literature corpus. (arXiv:2107.13983v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Depasquale_E/0/1/0/all/0/1">Etienne-Victor Depasquale</a>, <a href="http://arxiv.org/find/cs/1/au:+Salam_H/0/1/0/all/0/1">Humaira Abdul Salam</a>, <a href="http://arxiv.org/find/cs/1/au:+Davoli_F/0/1/0/all/0/1">Franco Davoli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13983">
                                    <div class="article-summary-box-inner">
                                        <span>We suggest an enhancement to structural coding through the use of (a)
causally bound codes, (b) basic constructs of graph theory and (c) statistics.
As is the norm with structural coding, the codes are collected into categories.
The categories are represented by nodes (graph theory). The causality is
illustrated through links (graph theory) between the nodes and the entire set
of linked nodes is collected into a single directed acyclic graph. The number
of occurrences of the nodes and the links provide the input required to analyze
relative frequency of occurrence, as well as opening a scope for further
statistical analysis. While our raw data was a corpus of literature from a
specific discipline, this enhancement is accessible to any qualitative analysis
that recognizes causality in its structural codes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Cross-Lingual Arabic Information REtrieval (CLAIRE) System. (arXiv:2107.13751v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhizhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1">Carsten Eickhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13751">
                                    <div class="article-summary-box-inner">
                                        <span>Despite advances in neural machine translation, cross-lingual retrieval tasks
in which queries and documents live in different natural language spaces remain
challenging. Although neural translation models may provide an intuitive
approach to tackle the cross-lingual problem, their resource-consuming training
and advanced model structures may complicate the overall retrieval pipeline and
reduce users engagement. In this paper, we build our end-to-end Cross-Lingual
Arabic Information REtrieval (CLAIRE) system based on the cross-lingual word
embedding where searchers are assumed to have a passable passive understanding
of Arabic and various supporting information in English is provided to aid
retrieval experience. The proposed system has three major advantages: (1) The
usage of English-Arabic word embedding simplifies the overall pipeline and
avoids the potential mistakes caused by machine translation. (2) Our CLAIRE
system can incorporate arbitrary word embedding-based neural retrieval models
without structural modification. (3) Early empirical results on an Arabic news
collection show promising performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Merge of k-NN Graph. (arXiv:1908.00814v6 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wan-Lei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1">Peng-Cheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngo_C/0/1/0/all/0/1">Chong-Wah Ngo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.00814">
                                    <div class="article-summary-box-inner">
                                        <span>k-nearest neighbor graph is a fundamental data structure in many disciplines
such as information retrieval, data-mining, pattern recognition, and machine
learning, etc. In the literature, considerable research has been focusing on
how to efficiently build an approximate k-nearest neighbor graph (k-NN graph)
for a fixed dataset. Unfortunately, a closely related issue of how to merge two
existing k-NN graphs has been overlooked. In this paper, we address the issue
of k-NN graph merging in two different scenarios. In the first scenario, a
symmetric merge algorithm is proposed to combine two approximate k-NN graphs.
The algorithm facilitates large-scale processing by the efficient merging of
k-NN graphs that are produced in parallel. In the second scenario, a joint
merge algorithm is proposed to expand an existing k-NN graph with a raw
dataset. The algorithm enables the incremental construction of a hierarchical
approximate k-NN graph. Superior performance is attained when leveraging the
hierarchy for NN search of various data types, dimensionality, and distance
measures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain-matched Pre-training Tasks for Dense Retrieval. (arXiv:2107.13602v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oguz_B/0/1/0/all/0/1">Barlas O&#x11f;uz</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakhotia_K/0/1/0/all/0/1">Kushal Lakhotia</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Anchit Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_P/0/1/0/all/0/1">Patrick Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Karpukhin_V/0/1/0/all/0/1">Vladimir Karpukhin</a>, <a href="http://arxiv.org/find/cs/1/au:+Piktus_A/0/1/0/all/0/1">Aleksandra Piktus</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xilun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1">Sebastian Riedel</a>, <a href="http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1">Wen-tau Yih</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Sonal Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1">Yashar Mehdad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13602">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-training on larger datasets with ever increasing model size is now a
proven recipe for increased performance across almost all NLP tasks. A notable
exception is information retrieval, where additional pre-training has so far
failed to produce convincing results. We show that, with the right pre-training
setup, this barrier can be overcome. We demonstrate this by pre-training large
bi-encoder models on 1) a recently released set of 65 million synthetically
generated questions, and 2) 200 million post-comment pairs from a preexisting
dataset of Reddit conversations made available by pushshift.io. We evaluate on
a set of information retrieval and dialogue retrieval benchmarks, showing
substantial improvements over supervised baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Elliot: a Comprehensive and Rigorous Framework for Reproducible Recommender Systems Evaluation. (arXiv:2103.02590v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anelli_V/0/1/0/all/0/1">Vito Walter Anelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellogin_A/0/1/0/all/0/1">Alejandro Bellog&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrara_A/0/1/0/all/0/1">Antonio Ferrara</a>, <a href="http://arxiv.org/find/cs/1/au:+Malitesta_D/0/1/0/all/0/1">Daniele Malitesta</a>, <a href="http://arxiv.org/find/cs/1/au:+Merra_F/0/1/0/all/0/1">Felice Antonio Merra</a>, <a href="http://arxiv.org/find/cs/1/au:+Pomo_C/0/1/0/all/0/1">Claudio Pomo</a>, <a href="http://arxiv.org/find/cs/1/au:+Donini_F/0/1/0/all/0/1">Francesco Maria Donini</a>, <a href="http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1">Tommaso Di Noia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02590">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender Systems have shown to be an effective way to alleviate the
over-choice problem and provide accurate and tailored recommendations. However,
the impressive number of proposed recommendation algorithms, splitting
strategies, evaluation protocols, metrics, and tasks, has made rigorous
experimental evaluation particularly challenging. Puzzled and frustrated by the
continuous recreation of appropriate evaluation benchmarks, experimental
pipelines, hyperparameter optimization, and evaluation procedures, we have
developed an exhaustive framework to address such needs. Elliot is a
comprehensive recommendation framework that aims to run and reproduce an entire
experimental pipeline by processing a simple configuration file. The framework
loads, filters, and splits the data considering a vast set of strategies (13
splitting methods and 8 filtering approaches, from temporal training-test
splitting to nested K-folds Cross-Validation). Elliot optimizes hyperparameters
(51 strategies) for several recommendation algorithms (50), selects the best
models, compares them with the baselines providing intra-model statistics,
computes metrics (36) spanning from accuracy to beyond-accuracy, bias, and
fairness, and conducts statistical analysis (Wilcoxon and Paired t-test). The
aim is to provide the researchers with a tool to ease (and make them
reproducible) all the experimental evaluation phases, from data reading to
results collection. Elliot is available on GitHub
(https://github.com/sisinflab/elliot).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Tale of Two Efficient and Informative Negative Sampling Distributions. (arXiv:2012.15843v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Daghaghi_S/0/1/0/all/0/1">Shabnam Daghaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Medini_T/0/1/0/all/0/1">Tharun Medini</a>, <a href="http://arxiv.org/find/cs/1/au:+Meisburger_N/0/1/0/all/0/1">Nicholas Meisburger</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Beidi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mengnan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1">Anshumali Shrivastava</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15843">
                                    <div class="article-summary-box-inner">
                                        <span>Softmax classifiers with a very large number of classes naturally occur in
many applications such as natural language processing and information
retrieval. The calculation of full softmax is costly from the computational and
energy perspective. There have been various sampling approaches to overcome
this challenge, popularly known as negative sampling (NS). Ideally, NS should
sample negative classes from a distribution that is dependent on the input
data, the current parameters, and the correct positive class. Unfortunately,
due to the dynamically updated parameters and data samples, there is no
sampling scheme that is provably adaptive and samples the negative classes
efficiently. Therefore, alternative heuristics like random sampling, static
frequency-based sampling, or learning-based biased sampling, which primarily
trade either the sampling cost or the adaptivity of samples per iteration are
adopted. In this paper, we show two classes of distributions where the sampling
scheme is truly adaptive and provably generates negative samples in
near-constant time. Our implementation in C++ on CPU is significantly superior,
both in terms of wall-clock time and accuracy, compared to the most optimized
TensorFlow implementations of other popular negative sampling approaches on
powerful NVIDIA V100 GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive GIS Web-Atlas for Twelve Pacific Islands Countries. (arXiv:2107.14041v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lartigou_F/0/1/0/all/0/1">Fabrice Lartigou</a>, <a href="http://arxiv.org/find/cs/1/au:+Govorov_M/0/1/0/all/0/1">Michael Govorov</a>, <a href="http://arxiv.org/find/cs/1/au:+Aisake_T/0/1/0/all/0/1">Tofiga Aisake</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1">Pankajeshwara N. Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14041">
                                    <div class="article-summary-box-inner">
                                        <span>This article deals with the development of an interactive up-to-date Pacific
Islands Web GIS Atlas. It focuses on the compilation of spatial data from the
twelve member countries of the University of the South Pacific (Cook Islands,
Fiji Islands, Kiribati Islands, Marshall Islands, Nauru, Niue, Tonga, Tuvalu,
Tokelau, Solomon Islands, Vanuatu, and Western Samoa). A previous bitmap web
Atlas was created in 1996, and was a pilot activity investigating the potential
for using Geographical Information Systems (GIS) in the South Pacific. The
objective of the new atlas is to provide sets of spatial and attributive data
and maps for use of educators, students, researchers, policy makers and other
relevant user groups and the public. GIS is a highly flexible and dynamic
technology that allows the construction and analysis of maps and data sets from
a variety of sources and formats. Nowadays, GIS application has moved from
local and client-server applications to a three-tier architecture: Client (Web
Browser) -- Application Web Map Server -- Spatial Data Warehouses. The
objective of this project is to produce an Atlas that will include interactive
maps and data on an Application Web Map Server. Intergraph products such as
GeoMedia Professional, Web Map and Web Publisher have been selected for the web
atlas production and design. In an interactive environment, an atlas will be
composed from a series of maps and data profiles, which will be based on legend
entries, queries, hot spots and cartographic tools. Only the first stage of
development of the atlas and related technological solutions are outlined in
this article.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ExpertRank: A Multi-level Coarse-grained Expert-based Listwise Ranking Loss. (arXiv:2107.13752v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhizhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1">Carsten Eickhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13752">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of information retrieval is to recommend a list of document
candidates that are most relevant to a given query. Listwise learning trains
neural retrieval models by comparing various candidates simultaneously on a
large scale, offering much more competitive performance than pairwise and
pointwise schemes. Existing listwise ranking losses treat the candidate
document list as a whole unit without further inspection. Some candidates with
moderate semantic prominence may be ignored by the noisy similarity signals or
overshadowed by a few especially pronounced candidates. As a result, existing
ranking losses fail to exploit the full potential of neural retrieval models.
To address these concerns, we apply the classic pooling technique to conduct
multi-level coarse graining and propose ExpertRank, a novel expert-based
listwise ranking loss. The proposed scheme has three major advantages: (1)
ExpertRank introduces the profound physics concept of coarse graining to
information retrieval by selecting prominent candidates at various local levels
based on model prediction and inter-document comparison. (2) ExpertRank applies
the mixture of experts (MoE) technique to combine different experts effectively
by extending the traditional ListNet. (3) Compared to other existing listwise
learning approaches, ExpertRank produces much more reliable and competitive
performance for various neural retrieval models with different complexities,
from traditional models, such as KNRM, ConvKNRM, MatchPyramid, to sophisticated
BERT/ALBERT-based retrieval models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sign and Search: Sign Search Functionality for Sign Language Lexica. (arXiv:2107.13637v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fragkiadakis_M/0/1/0/all/0/1">Manolis Fragkiadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Putten_P/0/1/0/all/0/1">Peter van der Putten</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13637">
                                    <div class="article-summary-box-inner">
                                        <span>Sign language lexica are a useful resource for researchers and people
learning sign languages. Current implementations allow a user to search a sign
either by its gloss or by selecting its primary features such as handshape and
location. This study focuses on exploring a reverse search functionality where
a user can sign a query sign in front of a webcam and retrieve a set of
matching signs. By extracting different body joints combinations (upper body,
dominant hand&#x27;s arm and wrist) using the pose estimation framework OpenPose, we
compare four techniques (PCA, UMAP, DTW and Euclidean distance) as distance
metrics between 20 query signs, each performed by eight participants on a 1200
sign lexicon. The results show that UMAP and DTW can predict a matching sign
with an 80\% and 71\% accuracy respectively at the top-20 retrieved signs using
the movement of the dominant hand arm. Using DTW and adding more sign instances
from other participants in the lexicon, the accuracy can be raised to 90\% at
the top-10 ranking. Our results suggest that our methodology can be used with
no training in any sign language lexicon regardless of its size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Approximation for Online Tensorial Independent Component Analysis. (arXiv:2012.14415v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chris Junchi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14415">
                                    <div class="article-summary-box-inner">
                                        <span>Independent component analysis (ICA) has been a popular dimension reduction
tool in statistical machine learning and signal processing. In this paper, we
present a convergence analysis for an online tensorial ICA algorithm, by
viewing the problem as a nonconvex stochastic approximation problem. For
estimating one component, we provide a dynamics-based analysis to prove that
our online tensorial ICA algorithm with a specific choice of stepsize achieves
a sharp finite-sample error bound. In particular, under a mild assumption on
the data-generating distribution and a scaling condition such that $d^4/T$ is
sufficiently small up to a polylogarithmic factor of data dimension $d$ and
sample size $T$, a sharp finite-sample error bound of $\tilde{O}(\sqrt{d/T})$
can be obtained.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modular Deep Reinforcement Learning for Continuous Motion Planning with Temporal Logic. (arXiv:2102.12855v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_M/0/1/0/all/0/1">Mingyu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasanbeig_M/0/1/0/all/0/1">Mohammadhosein Hasanbeig</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1">Shaoping Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Abate_A/0/1/0/all/0/1">Alessandro Abate</a>, <a href="http://arxiv.org/find/cs/1/au:+Kan_Z/0/1/0/all/0/1">Zhen Kan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12855">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates the motion planning of autonomous dynamical systems
modeled by Markov decision processes (MDP) with unknown transition
probabilities over continuous state and action spaces. Linear temporal logic
(LTL) is used to specify high-level tasks over infinite horizon, which can be
converted into a limit deterministic generalized B\&quot;uchi automaton (LDGBA) with
several accepting sets. The novelty is to design an embedded product MDP
(EP-MDP) between the LDGBA and the MDP by incorporating a synchronous
tracking-frontier function to record unvisited accepting sets of the automaton,
and to facilitate the satisfaction of the accepting conditions. The proposed
LDGBA-based reward shaping and discounting schemes for the model-free
reinforcement learning (RL) only depend on the EP-MDP states and can overcome
the issues of sparse rewards. Rigorous analysis shows that any RL method that
optimizes the expected discounted return is guaranteed to find an optimal
policy whose traces maximize the satisfaction probability. A modular deep
deterministic policy gradient (DDPG) is then developed to generate such
policies over continuous state and action spaces. The performance of our
framework is evaluated via an array of OpenAI gym environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Reinforcement Learning Policies for Multi-Agent Control. (arXiv:2011.08055v2 [cs.MA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1">Christopher D. Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_H/0/1/0/all/0/1">Heejin Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pappas_G/0/1/0/all/0/1">George J. Pappas</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhari_P/0/1/0/all/0/1">Pratik Chaudhari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08055">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a Multi-Agent Reinforcement Learning (MARL) method to learn
scalable control policies for target tracking. Our method can handle an
arbitrary number of pursuers and targets; we show results for tasks consisting
up to 1000 pursuers tracking 1000 targets. We use a decentralized,
partially-observable Markov Decision Process framework to model pursuers as
agents receiving partial observations (range and bearing) about targets which
move using fixed, unknown policies. An attention mechanism is used to
parameterize the value function of the agents; this mechanism allows us to
handle an arbitrary number of targets. Entropy-regularized off-policy RL
methods are used to train a stochastic policy, and we discuss how it enables a
hedging behavior between pursuers that leads to a weak form of cooperation in
spite of completely decentralized control execution. We further develop a
masking heuristic that allows training on smaller problems with few
pursuers-targets and execution on much larger problems. Thorough simulation
experiments, ablation studies, and comparisons to state of the art algorithms
are performed to study the scalability of the approach and robustness of
performance to varying numbers of agents and targets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TELESTO: A Graph Neural Network Model for Anomaly Classification in Cloud Services. (arXiv:2102.12877v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scheinert_D/0/1/0/all/0/1">Dominik Scheinert</a>, <a href="http://arxiv.org/find/cs/1/au:+Acker_A/0/1/0/all/0/1">Alexander Acker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12877">
                                    <div class="article-summary-box-inner">
                                        <span>Deployment, operation and maintenance of large IT systems becomes
increasingly complex and puts human experts under extreme stress when problems
occur. Therefore, utilization of machine learning (ML) and artificial
intelligence (AI) is applied on IT system operation and maintenance -
summarized in the term AIOps. One specific direction aims at the recognition of
re-occurring anomaly types to enable remediation automation. However, due to IT
system specific properties, especially their frequent changes (e.g. software
updates, reconfiguration or hardware modernization), recognition of reoccurring
anomaly types is challenging. Current methods mainly assume a static
dimensionality of provided data. We propose a method that is invariant to
dimensionality changes of given data. Resource metric data such as CPU
utilization, allocated memory and others are modelled as multivariate time
series. The extraction of temporal and spatial features together with the
subsequent anomaly classification is realized by utilizing TELESTO, our novel
graph convolutional neural network (GCNN) architecture. The experimental
evaluation is conducted in a real-world cloud testbed deployment that is
hosting two applications. Classification results of injected anomalies on a
cassandra database node show that TELESTO outperforms the alternative GCNNs and
achieves an overall classification accuracy of 85.1%. Classification results
for the other nodes show accuracy values between 85% and 60%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modern Non-Linear Function-on-Function Regression. (arXiv:2107.14151v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Rao_A/0/1/0/all/0/1">Aniruddha Rajendra Rao</a>, <a href="http://arxiv.org/find/stat/1/au:+Reimherr_M/0/1/0/all/0/1">Matthew Reimherr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14151">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new class of non-linear function-on-function regression models
for functional data using neural networks. We propose a framework using a
hidden layer consisting of continuous neurons, called a continuous hidden
layer, for functional response modeling and give two model fitting strategies,
Functional Direct Neural Network (FDNN) and Functional Basis Neural Network
(FBNN). Both are designed explicitly to exploit the structure inherent in
functional data and capture the complex relations existing between the
functional predictors and the functional response. We fit these models by
deriving functional gradients and implement regularization techniques for more
parsimonious results. We demonstrate the power and flexibility of our proposed
method in handling complex functional models through extensive simulation
studies as well as real data examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReLearn: A Robust Machine Learning Framework in Presence of Missing Data for Multimodal Stress Detection from Physiological Signals. (arXiv:2104.14278v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Iranfar_A/0/1/0/all/0/1">Arman Iranfar</a>, <a href="http://arxiv.org/find/cs/1/au:+Arza_A/0/1/0/all/0/1">Adriana Arza</a>, <a href="http://arxiv.org/find/cs/1/au:+Atienza_D/0/1/0/all/0/1">David Atienza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14278">
                                    <div class="article-summary-box-inner">
                                        <span>Continuous and multimodal stress detection has been performed recently
through wearable devices and machine learning algorithms. However, a well-known
and important challenge of working on physiological signals recorded by
conventional monitoring devices is missing data due to sensors insufficient
contact and interference by other equipment. This challenge becomes more
problematic when the user/patient is mentally or physically active or stressed
because of more frequent conscious or subconscious movements. In this paper, we
propose ReLearn, a robust machine learning framework for stress detection from
biomarkers extracted from multimodal physiological signals. ReLearn effectively
copes with missing data and outliers both at training and inference phases.
ReLearn, composed of machine learning models for feature selection, outlier
detection, data imputation, and classification, allows us to classify all
samples, including those with missing values at inference. In particular,
according to our experiments and stress database, while by discarding all
missing data, as a simplistic yet common approach, no prediction can be made
for 34% of the data at inference, our approach can achieve accurate
predictions, as high as 78%, for missing samples. Also, our experiments show
that the proposed framework obtains a cross-validation accuracy of 86.8% even
if more than 50% of samples within the features are missing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How To Make the Gradients Small Stochastically: Even Faster Convex and Nonconvex SGD. (arXiv:1801.02982v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1">Zeyuan Allen-Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1801.02982">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic gradient descent (SGD) gives an optimal convergence rate when
minimizing convex stochastic objectives $f(x)$. However, in terms of making the
gradients small, the original SGD does not give an optimal rate, even when
$f(x)$ is convex.

If $f(x)$ is convex, to find a point with gradient norm $\varepsilon$, we
design an algorithm SGD3 with a near-optimal rate
$\tilde{O}(\varepsilon^{-2})$, improving the best known rate
$O(\varepsilon^{-8/3})$ of [18].

If $f(x)$ is nonconvex, to find its $\varepsilon$-approximate local minimum,
we design an algorithm SGD5 with rate $\tilde{O}(\varepsilon^{-3.5})$, where
previously SGD variants only achieve $\tilde{O}(\varepsilon^{-4})$ [6, 15, 33].
This is no slower than the best known stochastic version of Newton&#x27;s method in
all parameter regimes [30].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Baseline Values for Shapley Values. (arXiv:2105.10719v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhanpeng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qirui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Quanshi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10719">
                                    <div class="article-summary-box-inner">
                                        <span>This paper aims to formulate the problem of estimating the optimal baseline
values for the Shapley value in game theory. The Shapley value measures the
attribution of each input variable of a complex model, which is computed as the
marginal benefit from the presence of this variable w.r.t.its absence under
different contexts. To this end, people usually set the input variable to its
baseline value to represent the absence of this variable (i.e.the no-signal
state of this variable). Previous studies usually determine the baseline values
in an empirical manner, which hurts the trustworthiness of the Shapley value.
In this paper, we revisit the feature representation of a deep model from the
perspective of game theory, and define the multi-variate interaction patterns
of input variables to define the no-signal state of an input variable. Based on
the multi-variate interaction, we learn the optimal baseline value of each
input variable. Experimental results have demonstrated the effectiveness of our
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RECOWNs: Probabilistic Circuits for Trustworthy Time Series Forecasting. (arXiv:2106.04148v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thoma_N/0/1/0/all/0/1">Nils Thoma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhongjie Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ventola_F/0/1/0/all/0/1">Fabrizio Ventola</a>, <a href="http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1">Kristian Kersting</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04148">
                                    <div class="article-summary-box-inner">
                                        <span>Time series forecasting is a relevant task that is performed in several
real-world scenarios such as product sales analysis and prediction of energy
demand. Given their accuracy performance, currently, Recurrent Neural Networks
(RNNs) are the models of choice for this task. Despite their success in time
series forecasting, less attention has been paid to make the RNNs trustworthy.
For example, RNNs can not naturally provide an uncertainty measure to their
predictions. This could be extremely useful in practice in several cases e.g.
to detect when a prediction might be completely wrong due to an unusual pattern
in the time series. Whittle Sum-Product Networks (WSPNs), prominent deep
tractable probabilistic circuits (PCs) for time series, can assist an RNN with
providing meaningful probabilities as uncertainty measure. With this aim, we
propose RECOWN, a novel architecture that employs RNNs and a discriminant
variant of WSPNs called Conditional WSPNs (CWSPNs). We also formulate a
Log-Likelihood Ratio Score as better estimation of uncertainty that is tailored
to time series and Whittle likelihoods. In our experiments, we show that
RECOWNs are accurate and trustworthy time series predictors, able to &quot;know when
they do not know&quot;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Sample Complexity Upper and Lower Bounds for Exact Ranking from Noisy Comparisons. (arXiv:1909.03194v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1">Wenbo Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shroff_N/0/1/0/all/0/1">Ness B. Shroff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.03194">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the problem of finding the exact ranking from noisy
comparisons. A comparison over a set of $m$ items produces a noisy outcome
about the most preferred item, and reveals some information about the ranking.
By repeatedly and adaptively choosing items to compare, we want to fully rank
the items with a certain confidence, and use as few comparisons as possible.
Different from most previous works, in this paper, we have three main
novelties: (i) compared to prior works, our upper bounds (algorithms) and lower
bounds on the sample complexity (aka number of comparisons) require the minimal
assumptions on the instances, and are not restricted to specific models; (ii)
we give lower bounds and upper bounds on instances with unequal noise levels;
and (iii) this paper aims at the exact ranking without knowledge on the
instances, while most of the previous works either focus on approximate
rankings or study exact ranking but require prior knowledge. We first derive
lower bounds for pairwise ranking (i.e., compare two items each time), and then
propose (nearly) optimal pairwise ranking algorithms. We further make
extensions to listwise ranking (i.e., comparing multiple items each time).
Numerical results also show our improvements against the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Merge of k-NN Graph. (arXiv:1908.00814v6 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wan-Lei Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_P/0/1/0/all/0/1">Peng-Cheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ngo_C/0/1/0/all/0/1">Chong-Wah Ngo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.00814">
                                    <div class="article-summary-box-inner">
                                        <span>k-nearest neighbor graph is a fundamental data structure in many disciplines
such as information retrieval, data-mining, pattern recognition, and machine
learning, etc. In the literature, considerable research has been focusing on
how to efficiently build an approximate k-nearest neighbor graph (k-NN graph)
for a fixed dataset. Unfortunately, a closely related issue of how to merge two
existing k-NN graphs has been overlooked. In this paper, we address the issue
of k-NN graph merging in two different scenarios. In the first scenario, a
symmetric merge algorithm is proposed to combine two approximate k-NN graphs.
The algorithm facilitates large-scale processing by the efficient merging of
k-NN graphs that are produced in parallel. In the second scenario, a joint
merge algorithm is proposed to expand an existing k-NN graph with a raw
dataset. The algorithm enables the incremental construction of a hierarchical
approximate k-NN graph. Superior performance is attained when leveraging the
hierarchy for NN search of various data types, dimensionality, and distance
measures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spot What Matters: Learning Context Using Graph Convolutional Networks for Weakly-Supervised Action Detection. (arXiv:2107.13648v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsiaousis_M/0/1/0/all/0/1">Michail Tsiaousis</a>, <a href="http://arxiv.org/find/cs/1/au:+Burghouts_G/0/1/0/all/0/1">Gertjan Burghouts</a>, <a href="http://arxiv.org/find/cs/1/au:+Hillerstrom_F/0/1/0/all/0/1">Fieke Hillerstr&#xf6;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Putten_P/0/1/0/all/0/1">Peter van der Putten</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13648">
                                    <div class="article-summary-box-inner">
                                        <span>The dominant paradigm in spatiotemporal action detection is to classify
actions using spatiotemporal features learned by 2D or 3D Convolutional
Networks. We argue that several actions are characterized by their context,
such as relevant objects and actors present in the video. To this end, we
introduce an architecture based on self-attention and Graph Convolutional
Networks in order to model contextual cues, such as actor-actor and
actor-object interactions, to improve human action detection in video. We are
interested in achieving this in a weakly-supervised setting, i.e. using as less
annotations as possible in terms of action bounding boxes. Our model aids
explainability by visualizing the learned context as an attention map, even for
actions and objects unseen during training. We evaluate how well our model
highlights the relevant context by introducing a quantitative metric based on
recall of objects retrieved by attention maps. Our model relies on a 3D
convolutional RGB stream, and does not require expensive optical flow
computation. We evaluate our models on the DALY dataset, which consists of
human-object interaction actions. Experimental results show that our
contextualized approach outperforms a baseline action detection approach by
more than 2 points in Video-mAP. Code is available at
\url{https://github.com/micts/acgcn}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Leakage and Rethinking the Kernel Size in CNNs. (arXiv:2101.10143v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tomen_N/0/1/0/all/0/1">Nergis Tomen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1">Jan van Gemert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10143">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional layers in CNNs implement linear filters which decompose the
input into different frequency bands. However, most modern architectures
neglect standard principles of filter design when optimizing their model
choices regarding the size and shape of the convolutional kernel. In this work,
we consider the well-known problem of spectral leakage caused by windowing
artifacts in filtering operations in the context of CNNs. We show that the
small size of CNN kernels make them susceptible to spectral leakage, which may
induce performance-degrading artifacts. To address this issue, we propose the
use of larger kernel sizes along with the Hamming window function to alleviate
leakage in CNN architectures. We demonstrate improved classification accuracy
on multiple benchmark datasets including Fashion-MNIST, CIFAR-10, CIFAR-100 and
ImageNet with the simple use of a standard window function in convolutional
layers. Finally, we show that CNNs employing the Hamming window display
increased robustness against various adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FATNN: Fast and Accurate Ternary Neural Networks. (arXiv:2008.05101v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1">Peng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1">Bohan Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.05101">
                                    <div class="article-summary-box-inner">
                                        <span>Ternary Neural Networks (TNNs) have received much attention due to being
potentially orders of magnitude faster in inference, as well as more power
efficient, than full-precision counterparts. However, 2 bits are required to
encode the ternary representation with only 3 quantization levels leveraged. As
a result, conventional TNNs have similar memory consumption and speed compared
with the standard 2-bit models, but have worse representational capability.
Moreover, there is still a significant gap in accuracy between TNNs and
full-precision networks, hampering their deployment to real applications. To
tackle these two challenges, in this work, we first show that, under some mild
constraints, computational complexity of the ternary inner product can be
reduced by a factor of 2. Second, to mitigate the performance gap, we
elaborately design an implementation-dependent ternary quantization algorithm.
The proposed framework is termed Fast and Accurate Ternary Neural Networks
(FATNN). Experiments on image classification demonstrate that our FATNN
surpasses the state-of-the-arts by a significant margin in accuracy. More
importantly, speedup evaluation compared with various precisions is analyzed on
several platforms, which serves as a strong benchmark for further research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relational Graph Neural Networks for Fraud Detection in a Super-Appe nvironment. (arXiv:2107.13673v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Acevedo_Viloria_J/0/1/0/all/0/1">Jaime D. Acevedo-Viloria</a>, <a href="http://arxiv.org/find/cs/1/au:+Roa_L/0/1/0/all/0/1">Luisa Roa</a>, <a href="http://arxiv.org/find/cs/1/au:+Adeshina_S/0/1/0/all/0/1">Soji Adeshina</a>, <a href="http://arxiv.org/find/cs/1/au:+Olazo_C/0/1/0/all/0/1">Cesar Charalla Olazo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Rey_A/0/1/0/all/0/1">Andr&#xe9;s Rodr&#xed;guez-Rey</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramos_J/0/1/0/all/0/1">Jose Alberto Ramos</a>, <a href="http://arxiv.org/find/cs/1/au:+Correa_Bahnsen_A/0/1/0/all/0/1">Alejandro Correa-Bahnsen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13673">
                                    <div class="article-summary-box-inner">
                                        <span>Large digital platforms create environments where different types of user
interactions are captured, these relationships offer a novel source of
information for fraud detection problems. In this paper we propose a framework
of relational graph convolutional networks methods for fraudulent behaviour
prevention in the financial services of a Super-App. To this end, we apply the
framework on different heterogeneous graphs of users, devices, and credit
cards; and finally use an interpretability algorithm for graph neural networks
to determine the most important relations to the classification task of the
users. Our results show that there is an added value when considering models
that take advantage of the alternative data of the Super-App and the
interactions found in their high connectivity, further proofing how they can
leverage that into better decisions and fraud detection strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the combined effect of class imbalance and concept complexity in deep learning. (arXiv:2107.14194v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_K/0/1/0/all/0/1">Kushankur Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellinger_C/0/1/0/all/0/1">Colin Bellinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Corizzo_R/0/1/0/all/0/1">Roberto Corizzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Krawczyk_B/0/1/0/all/0/1">Bartosz Krawczyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Japkowicz_N/0/1/0/all/0/1">Nathalie Japkowicz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14194">
                                    <div class="article-summary-box-inner">
                                        <span>Structural concept complexity, class overlap, and data scarcity are some of
the most important factors influencing the performance of classifiers under
class imbalance conditions. When these effects were uncovered in the early
2000s, understandably, the classifiers on which they were demonstrated belonged
to the classical rather than Deep Learning categories of approaches. As Deep
Learning is gaining ground over classical machine learning and is beginning to
be used in critical applied settings, it is important to assess systematically
how well they respond to the kind of challenges their classical counterparts
have struggled with in the past two decades. The purpose of this paper is to
study the behavior of deep learning systems in settings that have previously
been deemed challenging to classical machine learning systems to find out
whether the depth of the systems is an asset in such settings. The results in
both artificial and real-world image datasets (MNIST Fashion, CIFAR-10) show
that these settings remain mostly challenging for Deep Learning systems and
that deeper architectures seem to help with structural concept complexity but
not with overlap challenges in simple artificial domains. Data scarcity is not
overcome by deeper layers, either. In the real-world image domains, where
overfitting is a greater concern than in the artificial domains, the advantage
of deeper architectures is less obvious: while it is observed in certain cases,
it is quickly cancelled as models get deeper and perform worse than their
shallower counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Day-to-day and seasonal regularity of network passenger delay for metro networks. (arXiv:2107.14094v1 [physics.soc-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Krishnakumari_P/0/1/0/all/0/1">Panchamy Krishnakumari</a>, <a href="http://arxiv.org/find/physics/1/au:+Cats_O/0/1/0/all/0/1">Oded Cats</a>, <a href="http://arxiv.org/find/physics/1/au:+Lint_H/0/1/0/all/0/1">Hans van Lint</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14094">
                                    <div class="article-summary-box-inner">
                                        <span>In an effort to improve user satisfaction and transit image, transit service
providers worldwide offer delay compensations. Smart card data enables the
estimation of passenger delays throughout the network and aid in monitoring
service performance. Notwithstanding, in order to prioritize measures for
improving service reliability and hence reducing passenger delays, it is
paramount to identify the system components - stations and track segments -
where most passenger delay occurs. To this end, we propose a novel method for
estimating network passenger delay from individual trajectories. We decompose
the delay along a passenger trajectory into its corresponding track segment
delay, initial waiting time and transfer delay. We distinguish between two
different types of passenger delay in relation to the public transit network:
average passenger delay and total passenger delay. We employ temporal
clustering on these two quantities to reveal daily and seasonal regularity in
delay patterns of the transit network. The estimation and clustering methods
are demonstrated on one year of data from Washington metro network. The data
consists of schedule information and smart card data which includes
passenger-train assignment of the metro network for the months of August 2017
to August 2018. Our findings show that the average passenger delay is
relatively stable throughout the day. The temporal clustering reveals
pronounced and recurrent and thus predictable daily and weekly patterns with
distinct characteristics for certain months.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning more skills through optimistic exploration. (arXiv:2107.14226v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Strouse_D/0/1/0/all/0/1">DJ Strouse</a>, <a href="http://arxiv.org/find/cs/1/au:+Baumli_K/0/1/0/all/0/1">Kate Baumli</a>, <a href="http://arxiv.org/find/cs/1/au:+Warde_Farley_D/0/1/0/all/0/1">David Warde-Farley</a>, <a href="http://arxiv.org/find/cs/1/au:+Mnih_V/0/1/0/all/0/1">Vlad Mnih</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansen_S/0/1/0/all/0/1">Steven Hansen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14226">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised skill learning objectives (Gregor et al., 2016, Eysenbach et
al., 2018) allow agents to learn rich repertoires of behavior in the absence of
extrinsic rewards. They work by simultaneously training a policy to produce
distinguishable latent-conditioned trajectories, and a discriminator to
evaluate distinguishability by trying to infer latents from trajectories. The
hope is for the agent to explore and master the environment by encouraging each
skill (latent) to reliably reach different states. However, an inherent
exploration problem lingers: when a novel state is actually encountered, the
discriminator will necessarily not have seen enough training data to produce
accurate and confident skill classifications, leading to low intrinsic reward
for the agent and effective penalization of the sort of exploration needed to
actually maximize the objective. To combat this inherent pessimism towards
exploration, we derive an information gain auxiliary objective that involves
training an ensemble of discriminators and rewarding the policy for their
disagreement. Our objective directly estimates the epistemic uncertainty that
comes from the discriminator not having seen enough training examples, thus
providing an intrinsic reward more tailored to the true objective compared to
pseudocount-based methods (Burda et al., 2019). We call this exploration bonus
discriminator disagreement intrinsic reward, or DISDAIN. We demonstrate
empirically that DISDAIN improves skill learning both in a tabular grid world
(Four Rooms) and the 57 games of the Atari Suite (from pixels). Thus, we
encourage researchers to treat pessimism with DISDAIN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Fairness Testing of Neural Classifiers through Adversarial Sampling. (arXiv:2107.08176v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peixin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingyi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jun Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_G/0/1/0/all/0/1">Guoliang Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xingen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_T/0/1/0/all/0/1">Ting Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jin Song Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08176">
                                    <div class="article-summary-box-inner">
                                        <span>Although deep learning has demonstrated astonishing performance in many
applications, there are still concerns about its dependability. One desirable
property of deep learning applications with societal impact is fairness (i.e.,
non-discrimination). Unfortunately, discrimination might be intrinsically
embedded into the models due to the discrimination in the training data. As a
countermeasure, fairness testing systemically identifies discriminatory
samples, which can be used to retrain the model and improve the model&#x27;s
fairness. Existing fairness testing approaches however have two major
limitations. Firstly, they only work well on traditional machine learning
models and have poor performance (e.g., effectiveness and efficiency) on deep
learning models. Secondly, they only work on simple structured (e.g., tabular)
data and are not applicable for domains such as text. In this work, we bridge
the gap by proposing a scalable and effective approach for systematically
searching for discriminatory samples while extending existing fairness testing
approaches to address a more challenging domain, i.e., text classification.
Compared with state-of-the-art methods, our approach only employs lightweight
procedures like gradient computation and clustering, which is significantly
more scalable and effective. Experimental results show that on average, our
approach explores the search space much more effectively (9.62 and 2.38 times
more than the state-of-the-art methods respectively on tabular and text
datasets) and generates much more discriminatory samples (24.95 and 2.68 times)
within a same reasonable time. Moreover, the retrained models reduce
discrimination by 57.2% and 60.2% respectively on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Convergence of Reinforcement Learning in Nonlinear Continuous State Space Problems. (arXiv:2011.10829v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goyal_R/0/1/0/all/0/1">Raman Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravorty_S/0/1/0/all/0/1">Suman Chakravorty</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ran Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_M/0/1/0/all/0/1">Mohamed Naveed Gul Mohamed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10829">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of Reinforcement Learning for nonlinear stochastic
dynamical systems. We show that in the RL setting, there is an inherent &#x60;&#x60;Curse
of Variance&quot; in addition to Bellman&#x27;s infamous &#x60;&#x60;Curse of Dimensionality&quot;, in
particular, we show that the variance in the solution grows
factorial-exponentially in the order of the approximation. A fundamental
consequence is that this precludes the search for anything other than &#x60;&#x60;local&quot;
feedback solutions in RL, in order to control the explosive variance growth,
and thus, ensure accuracy. We further show that the deterministic optimal
control has a perturbation structure, in that the higher order terms do not
affect the calculation of lower order terms, which can be utilized in RL to get
accurate local solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modifications of FastICA in Convolutive Blind Source Separation. (arXiv:2107.14135v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">YunPeng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14135">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutive blind source separation (BSS) is intended to recover the unknown
components from their convolutive mixtures. Contrary to the contrast functions
used in instantaneous cases, the spatial-temporal prewhitening stage and the
para-unitary filters constraint are difficult to implement in a convolutive
context. In this paper, we propose several modifications of FastICA to
alleviate these difficulties. Our method performs the simple prewhitening step
on convolutive mixtures prior to the separation and optimizes the contrast
function under the diagonalization constraint implemented by single value
decomposition (SVD). Numerical simulations are implemented to verify the
performance of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpolating Classifiers Make Few Mistakes. (arXiv:2101.11815v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Liang_T/0/1/0/all/0/1">Tengyuan Liang</a>, <a href="http://arxiv.org/find/stat/1/au:+Recht_B/0/1/0/all/0/1">Benjamin Recht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11815">
                                    <div class="article-summary-box-inner">
                                        <span>This paper provides elementary analyses of the regret and generalization of
minimum-norm interpolating classifiers (MNIC). The MNIC is the function of
smallest Reproducing Kernel Hilbert Space norm that perfectly interpolates a
label pattern on a finite data set. We derive a mistake bound for MNIC and a
regularized variant that holds for all data sets. This bound follows from
elementary properties of matrix inverses. Under the assumption that the data is
independently and identically distributed, the mistake bound implies that MNIC
generalizes at a rate proportional to the norm of the interpolating solution
and inversely proportional to the number of data points. This rate matches
similar rates derived for margin classifiers and perceptrons. We derive several
plausible generative models where the norm of the interpolating classifier is
bounded or grows at a rate sublinear in $n$. We also show that as long as the
population class conditional distributions are sufficiently separable in total
variation, then MNIC generalizes with a fast rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Complexity of Finding Stationary Points with Stochastic Gradient Descent. (arXiv:1910.01845v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Drori_Y/0/1/0/all/0/1">Yoel Drori</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1">Ohad Shamir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.01845">
                                    <div class="article-summary-box-inner">
                                        <span>We study the iteration complexity of stochastic gradient descent (SGD) for
minimizing the gradient norm of smooth, possibly nonconvex functions. We
provide several results, implying that the $\mathcal{O}(\epsilon^{-4})$ upper
bound of Ghadimi and Lan~\cite{ghadimi2013stochastic} (for making the average
gradient norm less than $\epsilon$) cannot be improved upon, unless a
combination of additional assumptions is made. Notably, this holds even if we
limit ourselves to convex quadratic functions. We also show that for nonconvex
functions, the feasibility of minimizing gradients with SGD is surprisingly
sensitive to the choice of optimality criteria.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-Markovian Reinforcement Learning using Fractional Dynamics. (arXiv:2107.13790v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_G/0/1/0/all/0/1">Gaurav Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1">Chenzhong Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshmukh_J/0/1/0/all/0/1">Jyotirmoy V. Deshmukh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bogdan_P/0/1/0/all/0/1">Paul Bogdan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13790">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) is a technique to learn the control policy for an
agent that interacts with a stochastic environment. In any given state, the
agent takes some action, and the environment determines the probability
distribution over the next state as well as gives the agent some reward. Most
RL algorithms typically assume that the environment satisfies Markov
assumptions (i.e. the probability distribution over the next state depends only
on the current state). In this paper, we propose a model-based RL technique for
a system that has non-Markovian dynamics. Such environments are common in many
real-world applications such as in human physiology, biological systems,
material science, and population dynamics. Model-based RL (MBRL) techniques
typically try to simultaneously learn a model of the environment from the data,
as well as try to identify an optimal policy for the learned model. We propose
a technique where the non-Markovianity of the system is modeled through a
fractional dynamical system. We show that we can quantify the difference in the
performance of an MBRL algorithm that uses bounded horizon model predictive
control from the optimal policy. Finally, we demonstrate our proposed framework
on a pharmacokinetic model of human blood glucose dynamics and show that our
fractional models can capture distant correlations on real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Translatotron 2: Robust direct speech-to-speech translation. (arXiv:2107.08661v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Ye Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanovich_M/0/1/0/all/0/1">Michelle Tadmor Ramanovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Remez_T/0/1/0/all/0/1">Tal Remez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pomerantz_R/0/1/0/all/0/1">Roi Pomerantz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08661">
                                    <div class="article-summary-box-inner">
                                        <span>We present Translatotron 2, a neural direct speech-to-speech translation
model that can be trained end-to-end. Translatotron 2 consists of a speech
encoder, a phoneme decoder, a mel-spectrogram synthesizer, and an attention
module that connects all the previous three components. Experimental results
suggest that Translatotron 2 outperforms the original Translatotron by a large
margin in terms of translation quality and predicted speech naturalness, and
drastically improves the robustness of the predicted speech by mitigating
over-generation, such as babbling or long pause. We also propose a new method
for retaining the source speaker&#x27;s voice in the translated speech. The trained
model is restricted to retain the source speaker&#x27;s voice, and unlike the
original Translatotron, it is not able to generate speech in a different
speaker&#x27;s voice, making the model more robust for production deployment, by
mitigating potential misuse for creating spoofing audio artifacts. When the new
method is used together with a simple concatenation-based data augmentation,
the trained Translatotron 2 model is able to retain each speaker&#x27;s voice for
input with speaker turns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Did the Model Change? Efficiently Assessing Machine Learning API Shifts. (arXiv:2107.14203v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1">Lingjiao Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Cai_T/0/1/0/all/0/1">Tracy Cai</a>, <a href="http://arxiv.org/find/stat/1/au:+Zaharia_M/0/1/0/all/0/1">Matei Zaharia</a>, <a href="http://arxiv.org/find/stat/1/au:+Zou_J/0/1/0/all/0/1">James Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14203">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning (ML) prediction APIs are increasingly widely used. An ML API
can change over time due to model updates or retraining. This presents a key
challenge in the usage of the API because it is often not clear to the user if
and how the ML model has changed. Model shifts can affect downstream
application performance and also create oversight issues (e.g. if consistency
is desired). In this paper, we initiate a systematic investigation of ML API
shifts. We first quantify the performance shifts from 2020 to 2021 of popular
ML APIs from Google, Microsoft, Amazon, and others on a variety of datasets. We
identified significant model shifts in 12 out of 36 cases we investigated.
Interestingly, we found several datasets where the API&#x27;s predictions became
significantly worse over time. This motivated us to formulate the API shift
assessment problem at a more fine-grained level as estimating how the API
model&#x27;s confusion matrix changes over time when the data distribution is
constant. Monitoring confusion matrix shifts using standard random sampling can
require a large number of samples, which is expensive as each API call costs a
fee. We propose a principled adaptive sampling algorithm, MASA, to efficiently
estimate confusion matrix shifts. MASA can accurately estimate the confusion
matrix shifts in commercial ML APIs using up to 90% fewer samples compared to
random sampling. This work establishes ML API shifts as an important problem to
study and provides a cost-effective approach to monitor such shifts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Overview of Human Activity Recognition Using Wearable Sensors: Healthcare and Artificial Intelligence. (arXiv:2103.15990v4 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Rex Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramli_A/0/1/0/all/0/1">Albara Ah Ramli</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huanle Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Datta_E/0/1/0/all/0/1">Esha Datta</a>, <a href="http://arxiv.org/find/cs/1/au:+Henricson_E/0/1/0/all/0/1">Erik Henricson</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15990">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid development of the internet of things (IoT) and artificial
intelligence (AI) technologies, human activity recognition (HAR) has been
applied in a variety of domains such as security and surveillance, human-robot
interaction, and entertainment. Even though a number of surveys and review
papers have been published, there is a lack of HAR overview papers focusing on
healthcare applications that use wearable sensors. Therefore, we fill in the
gap by presenting this overview paper. In particular, we present our projects
to illustrate the system design of HAR applications for healthcare. Our
projects include early mobility identification of human activities for
intensive care unit (ICU) patients and gait analysis of Duchenne muscular
dystrophy (DMD) patients. We cover essential components of designing HAR
systems including sensor factors (e.g., type, number, and placement location),
AI model selection (e.g., classical machine learning models versus deep
learning models), and feature engineering. In addition, we highlight the
challenges of such healthcare-oriented HAR systems and propose several research
opportunities for both the medical and the computer science community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReconVAT: A Semi-Supervised Automatic Music Transcription Framework for Low-Resource Real-World Data. (arXiv:2107.04954v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheuk_K/0/1/0/all/0/1">Kin Wai Cheuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Herremans_D/0/1/0/all/0/1">Dorien Herremans</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1">Li Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04954">
                                    <div class="article-summary-box-inner">
                                        <span>Most of the current supervised automatic music transcription (AMT) models
lack the ability to generalize. This means that they have trouble transcribing
real-world music recordings from diverse musical genres that are not presented
in the labelled training data. In this paper, we propose a semi-supervised
framework, ReconVAT, which solves this issue by leveraging the huge amount of
available unlabelled music recordings. The proposed ReconVAT uses
reconstruction loss and virtual adversarial training. When combined with
existing U-net models for AMT, ReconVAT achieves competitive results on common
benchmark datasets such as MAPS and MusicNet. For example, in the few-shot
setting for the string part version of MusicNet, ReconVAT achieves F1-scores of
61.0% and 41.6% for the note-wise and note-with-offset-wise metrics
respectively, which translates into an improvement of 22.2% and 62.5% compared
to the supervised baseline model. Our proposed framework also demonstrates the
potential of continual learning on new data, which could be useful in
real-world applications whereby new data is constantly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Adversarial Robustness via Test-time Transformation Ensembling. (arXiv:2107.14110v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perez_J/0/1/0/all/0/1">Juan C. P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Alfarra_M/0/1/0/all/0/1">Motasem Alfarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeanneret_G/0/1/0/all/0/1">Guillaume Jeanneret</a>, <a href="http://arxiv.org/find/cs/1/au:+Rueda_L/0/1/0/all/0/1">Laura Rueda</a>, <a href="http://arxiv.org/find/cs/1/au:+Thabet_A/0/1/0/all/0/1">Ali Thabet</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbel&#xe1;ez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14110">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models are prone to being fooled by imperceptible perturbations
known as adversarial attacks. In this work, we study how equipping models with
Test-time Transformation Ensembling (TTE) can work as a reliable defense
against such attacks. While transforming the input data, both at train and test
times, is known to enhance model performance, its effects on adversarial
robustness have not been studied. Here, we present a comprehensive empirical
study of the impact of TTE, in the form of widely-used image transforms, on
adversarial robustness. We show that TTE consistently improves model robustness
against a variety of powerful attacks without any need for re-training, and
that this improvement comes at virtually no trade-off with accuracy on clean
samples. Finally, we show that the benefits of TTE transfer even to the
certified robustness domain, in which TTE provides sizable and consistent
improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning second order coupled differential equations that are subject to non-conservative forces. (arXiv:2010.11270v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Muller_R/0/1/0/all/0/1">Roger Alexander M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Laflamme_Janssen_J/0/1/0/all/0/1">Jonathan Laflamme-Janssen</a>, <a href="http://arxiv.org/find/cs/1/au:+Camacaro_J/0/1/0/all/0/1">Jaime Camacaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Bessega_C/0/1/0/all/0/1">Carolina Bessega</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11270">
                                    <div class="article-summary-box-inner">
                                        <span>In this article we address the question whether it is possible to learn the
differential equations describing the physical properties of a dynamical
system, subject to non-conservative forces, from observations of its realspace
trajectory(ies) only. We introduce a network that incorporates a difference
approximation for the second order derivative in terms of residual connections
between convolutional blocks, whose shared weights represent the coefficients
of a second order ordinary differential equation. We further combine this
solver-like architecture with a convolutional network, capable of learning the
relation between trajectories of coupled oscillators and therefore allows us to
make a stable forecast even if the system is only partially observed. We
optimize this map together with the solver network, while sharing their
weights, to form a powerful framework capable of learning the complex physical
properties of a dissipative dynamical system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guided Disentanglement in Generative Networks. (arXiv:2107.14229v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pizzati_F/0/1/0/all/0/1">Fabio Pizzati</a>, <a href="http://arxiv.org/find/cs/1/au:+Cerri_P/0/1/0/all/0/1">Pietro Cerri</a>, <a href="http://arxiv.org/find/cs/1/au:+Charette_R/0/1/0/all/0/1">Raoul de Charette</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14229">
                                    <div class="article-summary-box-inner">
                                        <span>Image-to-image translation (i2i) networks suffer from entanglement effects in
presence of physics-related phenomena in target domain (such as occlusions,
fog, etc), thus lowering the translation quality and variability. In this
paper, we present a comprehensive method for disentangling physics-based traits
in the translation, guiding the learning process with neural or physical
models. For the latter, we integrate adversarial estimation and genetic
algorithms to correctly achieve disentanglement. The results show our approach
dramatically increase performances in many challenging scenarios for image
translation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable Machine Learning: Moving From Mythos to Diagnostics. (arXiv:2103.06254v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_V/0/1/0/all/0/1">Valerie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jeffrey Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Joon Sik Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Plumb_G/0/1/0/all/0/1">Gregory Plumb</a>, <a href="http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1">Ameet Talwalkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06254">
                                    <div class="article-summary-box-inner">
                                        <span>Despite increasing interest in the field of Interpretable Machine Learning
(IML), a significant gap persists between the technical objectives targeted by
researchers&#x27; methods and the high-level goals of consumers&#x27; use cases. In this
work, we synthesize foundational work on IML methods and evaluation into an
actionable taxonomy. This taxonomy serves as a tool to conceptualize the gap
between researchers and consumers, illustrated by the lack of connections
between its methods and use cases components. It also provides the foundation
from which we describe a three-step workflow to better enable researchers and
consumers to work together to discover what types of methods are useful for
what use cases. Eventually, by building on the results generated from this
workflow, a more complete version of the taxonomy will increasingly allow
consumers to find relevant methods for their target use cases and researchers
to identify applicable use cases for their proposed methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot and Continual Learning with Attentive Independent Mechanisms. (arXiv:2107.14053v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_E/0/1/0/all/0/1">Eugene Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Cheng-Han Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1">Chen-Yi Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14053">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) are known to perform well when deployed to test
distributions that shares high similarity with the training distribution.
Feeding DNNs with new data sequentially that were unseen in the training
distribution has two major challenges -- fast adaptation to new tasks and
catastrophic forgetting of old tasks. Such difficulties paved way for the
on-going research on few-shot learning and continual learning. To tackle these
problems, we introduce Attentive Independent Mechanisms (AIM). We incorporate
the idea of learning using fast and slow weights in conjunction with the
decoupling of the feature extraction and higher-order conceptual learning of a
DNN. AIM is designed for higher-order conceptual learning, modeled by a mixture
of experts that compete to learn independent concepts to solve a new task. AIM
is a modular component that can be inserted into existing deep learning
frameworks. We demonstrate its capability for few-shot learning by adding it to
SIB and trained on MiniImageNet and CIFAR-FS, showing significant improvement.
AIM is also applied to ANML and OML trained on Omniglot, CIFAR-100 and
MiniImageNet to demonstrate its capability in continual learning. Code made
publicly available at https://github.com/huang50213/AIM-Fewshot-Continual.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point Cloud Audio Processing. (arXiv:2105.02469v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Subramani_K/0/1/0/all/0/1">Krishna Subramani</a>, <a href="http://arxiv.org/find/eess/1/au:+Smaragdis_P/0/1/0/all/0/1">Paris Smaragdis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02469">
                                    <div class="article-summary-box-inner">
                                        <span>Most audio processing pipelines involve transformations that act on
fixed-dimensional input representations of audio. For example, when using the
Short Time Fourier Transform (STFT) the DFT size specifies a fixed dimension
for the input representation. As a consequence, most audio machine learning
models are designed to process fixed-size vector inputs which often prohibits
the repurposing of learned models on audio with different sampling rates or
alternative representations. We note, however, that the intrinsic spectral
information in the audio signal is invariant to the choice of the input
representation or the sampling rate. Motivated by this, we introduce a novel
way of processing audio signals by treating them as a collection of points in
feature space, and we use point cloud machine learning models that give us
invariance to the choice of representation parameters, such as DFT size or the
sampling rate. Additionally, we observe that these methods result in smaller
models, and allow us to significantly subsample the input representation with
minimal effects to a trained model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised Learning for Data-driven Soft-sensing of Biological and Chemical Processes. (arXiv:2107.13822v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Esche_E/0/1/0/all/0/1">Erik Esche</a>, <a href="http://arxiv.org/find/eess/1/au:+Talis_T/0/1/0/all/0/1">Torben Talis</a>, <a href="http://arxiv.org/find/eess/1/au:+Weigert_J/0/1/0/all/0/1">Joris Weigert</a>, <a href="http://arxiv.org/find/eess/1/au:+Brand_Rihm_G/0/1/0/all/0/1">Gerardo Brand-Rihm</a>, <a href="http://arxiv.org/find/eess/1/au:+You_B/0/1/0/all/0/1">Byungjun You</a>, <a href="http://arxiv.org/find/eess/1/au:+Hoffmann_C/0/1/0/all/0/1">Christian Hoffmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Repke_J/0/1/0/all/0/1">Jens-Uwe Repke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13822">
                                    <div class="article-summary-box-inner">
                                        <span>Continuously operated (bio-)chemical processes increasingly suffer from
external disturbances, such as feed fluctuations or changes in market
conditions. Product quality often hinges on control of rarely measured
concentrations, which are expensive to measure. Semi-supervised regression is a
possible building block and method from machine learning to construct
soft-sensors for such infrequently measured states. Using two case studies,
i.e., the Williams-Otto process and a bioethanol production process,
semi-supervised regression is compared against standard regression to evaluate
its merits and its possible scope of application for process control in the
(bio-)chemical industry.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-Fine for Sim-to-Real: Sub-Millimetre Precision Across Wide Task Spaces. (arXiv:2105.11283v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Valassakis_E/0/1/0/all/0/1">Eugene Valassakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Palo_N/0/1/0/all/0/1">Norman Di Palo</a>, <a href="http://arxiv.org/find/cs/1/au:+Johns_E/0/1/0/all/0/1">Edward Johns</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11283">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the problem of zero-shot sim-to-real when the task
requires both highly precise control with sub-millimetre error tolerance, and
wide task space generalisation. Our framework involves a coarse-to-fine
controller, where trajectories begin with classical motion planning using
ICP-based pose estimation, and transition to a learned end-to-end controller
which maps images to actions and is trained in simulation with domain
randomisation. In this way, we achieve precise control whilst also generalising
the controller across wide task spaces, and keeping the robustness of
vision-based, end-to-end control. Real-world experiments on a range of
different tasks show that, by exploiting the best of both worlds, our framework
significantly outperforms purely motion planning methods, and purely
learning-based methods. Furthermore, we answer a range of questions on best
practices for precise sim-to-real transfer, such as how different image sensor
modalities and image feature representations perform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Active Learning with Temporal Output Discrepancy. (arXiv:2107.14153v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Siyu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huan_J/0/1/0/all/0/1">Jun Huan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14153">
                                    <div class="article-summary-box-inner">
                                        <span>While deep learning succeeds in a wide range of tasks, it highly depends on
the massive collection of annotated data which is expensive and time-consuming.
To lower the cost of data annotation, active learning has been proposed to
interactively query an oracle to annotate a small proportion of informative
samples in an unlabeled dataset. Inspired by the fact that the samples with
higher loss are usually more informative to the model than the samples with
lower loss, in this paper we present a novel deep active learning approach that
queries the oracle for data annotation when the unlabeled sample is believed to
incorporate high loss. The core of our approach is a measurement Temporal
Output Discrepancy (TOD) that estimates the sample loss by evaluating the
discrepancy of outputs given by models at different optimization steps. Our
theoretical investigation shows that TOD lower-bounds the accumulated sample
loss thus it can be used to select informative unlabeled samples. On basis of
TOD, we further develop an effective unlabeled data sampling strategy as well
as an unsupervised learning criterion that enhances model performance by
incorporating the unlabeled data. Due to the simplicity of TOD, our active
learning approach is efficient, flexible, and task-agnostic. Extensive
experimental results demonstrate that our approach achieves superior
performances than the state-of-the-art active learning methods on image
classification and semantic segmentation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do CNNs Encode Data Augmentations?. (arXiv:2003.08773v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_E/0/1/0/all/0/1">Eddie Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yanping Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.08773">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentations are important ingredients in the recipe for training
robust neural networks, especially in computer vision. A fundamental question
is whether neural network features encode data augmentation transformations. To
answer this question, we introduce a systematic approach to investigate which
layers of neural networks are the most predictive of augmentation
transformations. Our approach uses features in pre-trained vision models with
minimal additional processing to predict common properties transformed by
augmentation (scale, aspect ratio, hue, saturation, contrast, and brightness).
Surprisingly, neural network features not only predict data augmentation
transformations, but they predict many transformations with high accuracy.
After validating that neural networks encode features corresponding to
augmentation transformations, we show that these features are encoded in the
early layers of modern CNNs, though the augmentation signal fades in deeper
layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Fair and Ethical Healthcare Artificial Intelligence System for Monitoring Driver Behavior and Preventing Road Accidents. (arXiv:2107.14077v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oueida_S/0/1/0/all/0/1">Soraia Oueida</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_S/0/1/0/all/0/1">Soaad Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotb_Y/0/1/0/all/0/1">Yehia Kotb</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1">Syed Ishtiaque Ahmed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14077">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new approach to prevent transportation accidents and
monitor driver&#x27;s behavior using a healthcare AI system that incorporates
fairness and ethics. Dangerous medical cases and unusual behavior of the driver
are detected. Fairness algorithm is approached in order to improve
decision-making and address ethical issues such as privacy issues, and to
consider challenges that appear in the wild within AI in healthcare and
driving. A healthcare professional will be alerted about any unusual activity,
and the driver&#x27;s location when necessary, is provided in order to enable the
healthcare professional to immediately help to the unstable driver. Therefore,
using the healthcare AI system allows for accidents to be predicted and thus
prevented and lives may be saved based on the built-in AI system inside the
vehicle which interacts with the ER system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Tale of Two Efficient and Informative Negative Sampling Distributions. (arXiv:2012.15843v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Daghaghi_S/0/1/0/all/0/1">Shabnam Daghaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Medini_T/0/1/0/all/0/1">Tharun Medini</a>, <a href="http://arxiv.org/find/cs/1/au:+Meisburger_N/0/1/0/all/0/1">Nicholas Meisburger</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Beidi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mengnan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1">Anshumali Shrivastava</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15843">
                                    <div class="article-summary-box-inner">
                                        <span>Softmax classifiers with a very large number of classes naturally occur in
many applications such as natural language processing and information
retrieval. The calculation of full softmax is costly from the computational and
energy perspective. There have been various sampling approaches to overcome
this challenge, popularly known as negative sampling (NS). Ideally, NS should
sample negative classes from a distribution that is dependent on the input
data, the current parameters, and the correct positive class. Unfortunately,
due to the dynamically updated parameters and data samples, there is no
sampling scheme that is provably adaptive and samples the negative classes
efficiently. Therefore, alternative heuristics like random sampling, static
frequency-based sampling, or learning-based biased sampling, which primarily
trade either the sampling cost or the adaptivity of samples per iteration are
adopted. In this paper, we show two classes of distributions where the sampling
scheme is truly adaptive and provably generates negative samples in
near-constant time. Our implementation in C++ on CPU is significantly superior,
both in terms of wall-clock time and accuracy, compared to the most optimized
TensorFlow implementations of other popular negative sampling approaches on
powerful NVIDIA V100 GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recurrent U-net for automatic pelvic floor muscle segmentation on 3D ultrasound. (arXiv:2107.13833v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Noort_F/0/1/0/all/0/1">Frieda van den Noort</a>, <a href="http://arxiv.org/find/eess/1/au:+Sirmacek_B/0/1/0/all/0/1">Beril Sirmacek</a>, <a href="http://arxiv.org/find/eess/1/au:+Slump_C/0/1/0/all/0/1">Cornelis H. Slump</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13833">
                                    <div class="article-summary-box-inner">
                                        <span>The prevalance of pelvic floor problems is high within the female population.
Transperineal ultrasound (TPUS) is the main imaging modality used to
investigate these problems. Automating the analysis of TPUS data will help in
growing our understanding of pelvic floor related problems. In this study we
present a U-net like neural network with some convolutional long short term
memory (CLSTM) layers to automate the 3D segmentation of the levator ani muscle
(LAM) in TPUS volumes. The CLSTM layers are added to preserve the inter-slice
3D information. We reach human level performance on this segmentation task.
Therefore, we conclude that we successfully automated the segmentation of the
LAM on 3D TPUS data. This paves the way towards automatic in-vivo analysis of
the LAM mechanics in the context of large study populations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Learning for OFDM: From Neural Receivers to Pilotless Communication. (arXiv:2009.05261v3 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aoudia_F/0/1/0/all/0/1">Fay&#xe7;al Ait Aoudia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoydis_J/0/1/0/all/0/1">Jakob Hoydis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05261">
                                    <div class="article-summary-box-inner">
                                        <span>Previous studies have demonstrated that end-to-end learning enables
significant shaping gains over additive white Gaussian noise (AWGN) channels.
However, its benefits have not yet been quantified over realistic wireless
channel models. This work aims to fill this gap by exploring the gains of
end-to-end learning over a frequency- and time-selective fading channel using
orthogonal frequency division multiplexing (OFDM). With imperfect channel
knowledge at the receiver, the shaping gains observed on AWGN channels vanish.
Nonetheless, we identify two other sources of performance improvements. The
first comes from a neural network (NN)-based receiver operating over a large
number of subcarriers and OFDM symbols which allows to significantly reduce the
number of orthogonal pilots without loss of bit error rate (BER). The second
comes from entirely eliminating orthognal pilots by jointly learning a neural
receiver together with either superimposed pilots (SIPs), linearly combined
with conventional quadrature amplitude modulation (QAM), or an optimized
constellation geometry. The learned geometry works for a wide range of
signal-to-noise ratios (SNRs), Doppler and delay spreads, has zero mean and
does hence not contain any form of superimposed pilots. Both schemes achieve
the same BER as the pilot-based baseline with around 7% higher throughput.
Thus, we believe that a jointly learned transmitter and receiver are a very
interesting component for beyond-5G communication systems which could remove
the need and associated control overhead for demodulation reference signals
(DMRSs).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation. (arXiv:2102.06387v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kairouz_P/0/1/0/all/0/1">Peter Kairouz</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1">Thomas Steinke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06387">
                                    <div class="article-summary-box-inner">
                                        <span>We consider training models on private data that are distributed across user
devices. To ensure privacy, we add on-device noise and use secure aggregation
so that only the noisy sum is revealed to the server. We present a
comprehensive end-to-end system, which appropriately discretizes the data and
adds discrete Gaussian noise before performing secure aggregation. We provide a
novel privacy analysis for sums of discrete Gaussians and carefully analyze the
effects of data quantization and modular summation arithmetic. Our theoretical
guarantees highlight the complex tension between communication, privacy, and
accuracy. Our extensive experimental results demonstrate that our solution is
essentially able to match the accuracy to central differential privacy with
less than 16 bits of precision per value.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Variational Gradient Descent. (arXiv:2107.10731v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Langosco_L/0/1/0/all/0/1">Lauro Langosco di Langosco</a>, <a href="http://arxiv.org/find/cs/1/au:+Fortuin_V/0/1/0/all/0/1">Vincent Fortuin</a>, <a href="http://arxiv.org/find/cs/1/au:+Strathmann_H/0/1/0/all/0/1">Heiko Strathmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10731">
                                    <div class="article-summary-box-inner">
                                        <span>Particle-based approximate Bayesian inference approaches such as Stein
Variational Gradient Descent (SVGD) combine the flexibility and convergence
guarantees of sampling methods with the computational benefits of variational
inference. In practice, SVGD relies on the choice of an appropriate kernel
function, which impacts its ability to model the target distribution -- a
challenging problem with only heuristic solutions. We propose Neural
Variational Gradient Descent (NVGD), which is based on parameterizing the
witness function of the Stein discrepancy by a deep neural network whose
parameters are learned in parallel to the inference, mitigating the necessity
to make any kernel choices whatsoever. We empirically evaluate our method on
popular synthetic inference problems, real-world Bayesian linear regression,
and Bayesian neural network inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Optimization for Min Max Optimization. (arXiv:2107.13772v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weichert_D/0/1/0/all/0/1">Dorina Weichert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kister_A/0/1/0/all/0/1">Alexander Kister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13772">
                                    <div class="article-summary-box-inner">
                                        <span>A solution that is only reliable under favourable conditions is hardly a safe
solution. Min Max Optimization is an approach that returns optima that are
robust against worst case conditions. We propose algorithms that perform Min
Max Optimization in a setting where the function that should be optimized is
not known a priori and hence has to be learned by experiments. Therefore we
extend the Bayesian Optimization setting, which is tailored to maximization
problems, to Min Max Optimization problems. While related work extends the two
acquisition functions Expected Improvement and Gaussian Process Upper
Confidence Bound; we extend the two acquisition functions Entropy Search and
Knowledge Gradient. These acquisition functions are able to gain knowledge
about the optimum instead of just looking for points that are supposed to be
optimal. In our evaluation we show that these acquisition functions allow for
better solutions - converging faster to the optimum than the benchmark
settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Equivariant Energy Based Models with Equivariant Stein Variational Gradient Descent. (arXiv:2106.07832v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jaini_P/0/1/0/all/0/1">Priyank Jaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Holdijk_L/0/1/0/all/0/1">Lars Holdijk</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07832">
                                    <div class="article-summary-box-inner">
                                        <span>We focus on the problem of efficient sampling and learning of probability
densities by incorporating symmetries in probabilistic models. We first
introduce Equivariant Stein Variational Gradient Descent algorithm -- an
equivariant sampling method based on Stein&#x27;s identity for sampling from
densities with symmetries. Equivariant SVGD explicitly incorporates symmetry
information in a density through equivariant kernels which makes the resultant
sampler efficient both in terms of sample complexity and the quality of
generated samples. Subsequently, we define equivariant energy based models to
model invariant densities that are learned using contrastive divergence. By
utilizing our equivariant SVGD for training equivariant EBMs, we propose new
ways of improving and scaling up training of energy based models. We apply
these equivariant energy models for modelling joint densities in regression and
classification tasks for image datasets, many-body particle systems and
molecular structure generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning Advances aiding Recognition and Classification of Indian Monuments and Landmarks. (arXiv:2107.14070v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1">Aditya Jyoti Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghose_S/0/1/0/all/0/1">Smaranjit Ghose</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_K/0/1/0/all/0/1">Kanishka Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Nethaji_N/0/1/0/all/0/1">Niketha Nethaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1">Shivam Pal</a>, <a href="http://arxiv.org/find/cs/1/au:+Purkayastha_A/0/1/0/all/0/1">Arnab Dutta Purkayastha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14070">
                                    <div class="article-summary-box-inner">
                                        <span>Tourism in India plays a quintessential role in the country&#x27;s economy with an
estimated 9.2% GDP share for the year 2018. With a yearly growth rate of 6.2%,
the industry holds a huge potential for being the primary driver of the economy
as observed in the nations of the Middle East like the United Arab Emirates.
The historical and cultural diversity exhibited throughout the geography of the
nation is a unique spectacle for people around the world and therefore serves
to attract tourists in tens of millions in number every year. Traditionally,
tour guides or academic professionals who study these heritage monuments were
responsible for providing information to the visitors regarding their
architectural and historical significance. However, unfortunately this system
has several caveats when considered on a large scale such as unavailability of
sufficient trained people, lack of accurate information, failure to convey the
richness of details in an attractive format etc. Recently, machine learning
approaches revolving around the usage of monument pictures have been shown to
be useful for rudimentary analysis of heritage sights. This paper serves as a
survey of the research endeavors undertaken in this direction which would
eventually provide insights for building an automated decision system that
could be utilized to make the experience of tourism in India more modernized
for visitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bellamy: Reusing Performance Models for Distributed Dataflow Jobs Across Contexts. (arXiv:2107.13921v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scheinert_D/0/1/0/all/0/1">Dominik Scheinert</a>, <a href="http://arxiv.org/find/cs/1/au:+Thamsen_L/0/1/0/all/0/1">Lauritz Thamsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Houkun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Will_J/0/1/0/all/0/1">Jonathan Will</a>, <a href="http://arxiv.org/find/cs/1/au:+Acker_A/0/1/0/all/0/1">Alexander Acker</a>, <a href="http://arxiv.org/find/cs/1/au:+Wittkopp_T/0/1/0/all/0/1">Thorsten Wittkopp</a>, <a href="http://arxiv.org/find/cs/1/au:+Kao_O/0/1/0/all/0/1">Odej Kao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13921">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed dataflow systems enable the use of clusters for scalable data
analytics. However, selecting appropriate cluster resources for a processing
job is often not straightforward. Performance models trained on historical
executions of a concrete job are helpful in such situations, yet they are
usually bound to a specific job execution context (e.g. node type, software
versions, job parameters) due to the few considered input parameters. Even in
case of slight context changes, such supportive models need to be retrained and
cannot benefit from historical execution data from related contexts.

This paper presents Bellamy, a novel modeling approach that combines
scale-outs, dataset sizes, and runtimes with additional descriptive properties
of a dataflow job. It is thereby able to capture the context of a job
execution. Moreover, Bellamy is realizing a two-step modeling approach. First,
a general model is trained on all the available data for a specific scalable
analytics algorithm, hereby incorporating data from different contexts.
Subsequently, the general model is optimized for the specific situation at
hand, based on the available data for the concrete context. We evaluate our
approach on two publicly available datasets consisting of execution data from
various dataflow jobs carried out in different environments, showing that
Bellamy outperforms state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometry of Similarity Comparisons. (arXiv:2006.09858v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tabaghi_P/0/1/0/all/0/1">Puoya Tabaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1">Jianhao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Milenkovic_O/0/1/0/all/0/1">Olgica Milenkovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Dokmanic_I/0/1/0/all/0/1">Ivan Dokmani&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09858">
                                    <div class="article-summary-box-inner">
                                        <span>Many data analysis problems can be cast as distance geometry problems in
\emph{space forms} -- Euclidean, spherical, or hyperbolic spaces. Often,
absolute distance measurements are often unreliable or simply unavailable and
only proxies to absolute distances in the form of similarities are available.
Hence we ask the following: Given only \emph{comparisons} of similarities
amongst a set of entities, what can be said about the geometry of the
underlying space form? To study this question, we introduce the notions of the
\textit{ordinal capacity} of a target space form and \emph{ordinal spread} of
the similarity measurements. The latter is an indicator of complex patterns in
the measurements, while the former quantifies the capacity of a space form to
accommodate a set of measurements with a specific ordinal spread profile. We
prove that the ordinal capacity of a space form is related to its dimension and
the sign of its curvature. This leads to a lower bound on the Euclidean and
spherical embedding dimension of what we term similarity graphs. More
importantly, we show that the statistical behavior of the ordinal spread random
variables defined on a similarity graph can be used to identify its underlying
space form. We support our theoretical claims with experiments on weighted
trees, single-cell RNA expression data and spherical cartographic measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-objective optimization and explanation for stroke risk assessment in Shanxi province. (arXiv:2107.14060v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_i/0/1/0/all/0/1">ing Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yiyang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Junjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Huaxiong Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xiaoshuang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shixin Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14060">
                                    <div class="article-summary-box-inner">
                                        <span>Stroke is the top leading causes of death in China (Zhou et al. The Lancet
2019). A dataset from Shanxi Province is used to identify the risk of each
patient&#x27;s at four states low/medium/high/attack and provide the state
transition tendency through a SHAP DeepExplainer. To improve the accuracy on an
imbalance sample set, the Quadratic Interactive Deep Neural Network (QIDNN)
model is first proposed by flexible selecting and appending of quadratic
interactive features. The experimental results showed that the QIDNN model with
7 interactive features achieve the state-of-art accuracy $83.25\%$. Blood
pressure, physical inactivity, smoking, weight and total cholesterol are the
top five important features. Then, for the sake of high recall on the most
urgent state, attack state, the stroke occurrence prediction is taken as an
auxiliary objective to benefit from multi-objective optimization. The
prediction accuracy was promoted, meanwhile the recall of the attack state was
improved by $24.9\%$ (to $84.83\%$) compared to QIDNN (from $67.93\%$) with
same features. The prediction model and analysis tool in this paper not only
gave the theoretical optimized prediction method, but also provided the
attribution explanation of risk states and transition direction of each
patient, which provided a favorable tool for doctors to analyze and diagnose
the disease.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Malware Classification Using Transfer Learning. (arXiv:2107.13743v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Farhat_H/0/1/0/all/0/1">Hikmat Farhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Rammouz_V/0/1/0/all/0/1">Veronica Rammouz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13743">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid growth of the number of devices on the Internet, malware poses
a threat not only to the affected devices but also their ability to use said
devices to launch attacks on the Internet ecosystem. Rapid malware
classification is an important tools to combat that threat. One of the
successful approaches to classification is based on malware images and deep
learning. While many deep learning architectures are very accurate they usually
take a long time to train. In this work we perform experiments on multiple well
known, pre-trained, deep network architectures in the context of transfer
learning. We show that almost all them classify malware accurately with a very
short training period.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the temporal evolution of multivariate densities via normalizing flows. (arXiv:2107.13735v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lu_Y/0/1/0/all/0/1">Yubin Lu</a>, <a href="http://arxiv.org/find/stat/1/au:+Maulik_R/0/1/0/all/0/1">Romit Maulik</a>, <a href="http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1">Ting Gao</a>, <a href="http://arxiv.org/find/stat/1/au:+Dietrich_F/0/1/0/all/0/1">Felix Dietrich</a>, <a href="http://arxiv.org/find/stat/1/au:+Kevrekidis_I/0/1/0/all/0/1">Ioannis G. Kevrekidis</a>, <a href="http://arxiv.org/find/stat/1/au:+Duan_J/0/1/0/all/0/1">Jinqiao Duan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13735">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose a method to learn probability distributions using
sample path data from stochastic differential equations. Specifically, we
consider temporally evolving probability distributions (e.g., those produced by
integrating local or nonlocal Fokker-Planck equations). We analyze this
evolution through machine learning assisted construction of a time-dependent
mapping that takes a reference distribution (say, a Gaussian) to each and every
instance of our evolving distribution. If the reference distribution is the
initial condition of a Fokker-Planck equation, what we learn is the time-T map
of the corresponding solution. Specifically, the learned map is a normalizing
flow that deforms the support of the reference density to the support of each
and every density snapshot in time. We demonstrate that this approach can learn
solutions to non-local Fokker-Planck equations, such as those arising in
systems driven by both Brownian and L\&#x27;evy noise. We present examples with two-
and three-dimensional, uni- and multimodal distributions to validate the
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Experience Report on Machine Learning Reproducibility: Guidance for Practitioners and TensorFlow Model Garden Contributors. (arXiv:2107.00821v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Banna_V/0/1/0/all/0/1">Vishnu Banna</a>, <a href="http://arxiv.org/find/cs/1/au:+Chinnakotla_A/0/1/0/all/0/1">Akhil Chinnakotla</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhengxin Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vegesana_A/0/1/0/all/0/1">Anirudh Vegesana</a>, <a href="http://arxiv.org/find/cs/1/au:+Vivek_N/0/1/0/all/0/1">Naveen Vivek</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnappa_K/0/1/0/all/0/1">Kruthi Krishnappa</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Wenxin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yung-Hsiang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Thiruvathukal_G/0/1/0/all/0/1">George K. Thiruvathukal</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">James C. Davis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00821">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning techniques are becoming a fundamental tool for scientific
and engineering progress. These techniques are applied in contexts as diverse
as astronomy and spam filtering. However, correctly applying these techniques
requires careful engineering. Much attention has been paid to the technical
potential; relatively little attention has been paid to the software
engineering process required to bring research-based machine learning
techniques into practical utility. Technology companies have supported the
engineering community through machine learning frameworks such as TensorFLow
and PyTorch, but the details of how to engineer complex machine learning models
in these frameworks have remained hidden.

To promote best practices within the engineering community, academic
institutions and Google have partnered to launch a Special Interest Group on
Machine Learning Models (SIGMODELS) whose goal is to develop exemplary
implementations of prominent machine learning models in community locations
such as the TensorFlow Model Garden (TFMG). The purpose of this report is to
define a process for reproducing a state-of-the-art machine learning model at a
level of quality suitable for inclusion in the TFMG. We define the engineering
process and elaborate on each step, from paper analysis to model release. We
report on our experiences implementing the YOLO model family with a team of 26
student researchers, share the tools we developed, and describe the lessons we
learned along the way.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asymmetric Loss For Multi-Label Classification. (arXiv:2009.14119v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1">Emanuel Ben-Baruch</a>, <a href="http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1">Tal Ridnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamir_N/0/1/0/all/0/1">Nadav Zamir</a>, <a href="http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1">Asaf Noy</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedman_I/0/1/0/all/0/1">Itamar Friedman</a>, <a href="http://arxiv.org/find/cs/1/au:+Protter_M/0/1/0/all/0/1">Matan Protter</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1">Lihi Zelnik-Manor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.14119">
                                    <div class="article-summary-box-inner">
                                        <span>In a typical multi-label setting, a picture contains on average few positive
labels, and many negative ones. This positive-negative imbalance dominates the
optimization process, and can lead to under-emphasizing gradients from positive
labels during training, resulting in poor accuracy. In this paper, we introduce
a novel asymmetric loss (&quot;ASL&quot;), which operates differently on positive and
negative samples. The loss enables to dynamically down-weights and
hard-thresholds easy negative samples, while also discarding possibly
mislabeled samples. We demonstrate how ASL can balance the probabilities of
different samples, and how this balancing is translated to better mAP scores.
With ASL, we reach state-of-the-art results on multiple popular multi-label
datasets: MS-COCO, Pascal-VOC, NUS-WIDE and Open Images. We also demonstrate
ASL applicability for other tasks, such as single-label classification and
object detection. ASL is effective, easy to implement, and does not increase
the training time or complexity.

Implementation is available at: https://github.com/Alibaba-MIIL/ASL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Need and Status of Sea Turtle Conservation and Survey of Associated Computer Vision Advances. (arXiv:2107.14061v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1">Aditya Jyoti Paul</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14061">
                                    <div class="article-summary-box-inner">
                                        <span>For over hundreds of millions of years, sea turtles and their ancestors have
swum in the vast expanses of the ocean. They have undergone a number of
evolutionary changes, leading to speciation and sub-speciation. However, in the
past few decades, some of the most notable forces driving the genetic variance
and population decline have been global warming and anthropogenic impact
ranging from large-scale poaching, collecting turtle eggs for food, besides
dumping trash including plastic waste into the ocean. This leads to severe
detrimental effects in the sea turtle population, driving them to extinction.
This research focusses on the forces causing the decline in sea turtle
population, the necessity for the global conservation efforts along with its
successes and failures, followed by an in-depth analysis of the modern advances
in detection and recognition of sea turtles, involving Machine Learning and
Computer Vision systems, aiding the conservation efforts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gated recurrent units viewed through the lens of continuous time dynamical systems. (arXiv:1906.01005v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jordan_I/0/1/0/all/0/1">Ian D. Jordan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokol_P/0/1/0/all/0/1">Piotr Aleksander Sokol</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_I/0/1/0/all/0/1">Il Memming Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.01005">
                                    <div class="article-summary-box-inner">
                                        <span>Gated recurrent units (GRUs) are specialized memory elements for building
recurrent neural networks. Despite their incredible success on various tasks,
including extracting dynamics underlying neural data, little is understood
about the specific dynamics representable in a GRU network. As a result, it is
both difficult to know a priori how successful a GRU network will perform on a
given task, and also their capacity to mimic the underlying behavior of their
biological counterparts. Using a continuous time analysis, we gain intuition on
the inner workings of GRU networks. We restrict our presentation to low
dimensions, allowing for a comprehensive visualization. We found a surprisingly
rich repertoire of dynamical features that includes stable limit cycles
(nonlinear oscillations), multi-stable dynamics with various topologies, and
homoclinic bifurcations. At the same time we were unable to train GRU networks
to produce continuous attractors, which are hypothesized to exist in biological
neural networks. We contextualize the usefulness of different kinds of observed
dynamics and support our claims experimentally.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Gaussian DAGs from Network Data. (arXiv:1905.10848v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1">Hangjian Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Padilla_O/0/1/0/all/0/1">Oscar Hernan Madrid Padilla</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhou_Q/0/1/0/all/0/1">Qing Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10848">
                                    <div class="article-summary-box-inner">
                                        <span>Structural learning of directed acyclic graphs (DAGs) or Bayesian networks
has been studied extensively under the assumption that data are independent. We
propose a new Gaussian DAG model for dependent data which assumes the
observations are correlated according to an undirected network. Under this
model, we develop a method to estimate the DAG structure given a topological
ordering of the nodes. The proposed method jointly estimates the Bayesian
network and the correlations among observations by optimizing a scoring
function based on penalized likelihood. We show that under some mild
conditions, the proposed method produces consistent estimators after one
iteration. Extensive numerical experiments also demonstrate that by jointly
estimating the DAG structure and the sample correlation, our method achieves
much higher accuracy in structure learning. When the node ordering is unknown,
through experiments on synthetic and real data, we show that our algorithm can
be used to estimate the correlations between samples, with which we can
de-correlate the dependent data to significantly improve the performance of
classical DAG learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed Deep Convolutional Neural Networks for the Internet-of-Things. (arXiv:1908.01656v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Disabato_S/0/1/0/all/0/1">Simone Disabato</a>, <a href="http://arxiv.org/find/cs/1/au:+Roveri_M/0/1/0/all/0/1">Manuel Roveri</a>, <a href="http://arxiv.org/find/cs/1/au:+Alippi_C/0/1/0/all/0/1">Cesare Alippi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.01656">
                                    <div class="article-summary-box-inner">
                                        <span>Severe constraints on memory and computation characterizing the
Internet-of-Things (IoT) units may prevent the execution of Deep Learning
(DL)-based solutions, which typically demand large memory and high processing
load. In order to support a real-time execution of the considered DL model at
the IoT unit level, DL solutions must be designed having in mind constraints on
memory and processing capability exposed by the chosen IoT technology. In this
paper, we introduce a design methodology aiming at allocating the execution of
Convolutional Neural Networks (CNNs) on a distributed IoT application. Such a
methodology is formalized as an optimization problem where the latency between
the data-gathering phase and the subsequent decision-making one is minimized,
within the given constraints on memory and processing load at the units level.
The methodology supports multiple sources of data as well as multiple CNNs in
execution on the same IoT system allowing the design of CNN-based applications
demanding autonomy, low decision-latency, and high Quality-of-Service.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deterministic tensor completion with hypergraph expanders. (arXiv:1910.10692v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Harris_K/0/1/0/all/0/1">Kameron Decker Harris</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1">Yizhe Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.10692">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a novel analysis of low-rank tensor completion based on hypergraph
expanders. As a proxy for rank, we minimize the max-quasinorm of the tensor,
which generalizes the max-norm for matrices. Our analysis is deterministic and
shows that the number of samples required to approximately recover an order-$t$
tensor with at most $n$ entries per dimension is linear in $n$, under the
assumption that the rank and order of the tensor are $O(1)$. As steps in our
proof, we find a new expander mixing lemma for a $t$-partite, $t$-uniform
regular hypergraph model, and prove several new properties about tensor
max-quasinorm. To the best of our knowledge, this is the first deterministic
analysis of tensor completion. We develop a practical algorithm that solves a
relaxed version of the max-quasinorm minimization problem, and we demonstrate
its efficacy with numerical experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Open-World Entity Segmentation. (arXiv:2107.14228v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lu Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuen_J/0/1/0/all/0/1">Jason Kuen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jiuxiang Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hengshuang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhe Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14228">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new image segmentation task, termed Entity Segmentation (ES)
with the aim to segment all visual entities in an image without considering
semantic category labels. It has many practical applications in image
manipulation/editing where the segmentation mask quality is typically crucial
but category labels are less important. In this setting, all
semantically-meaningful segments are equally treated as categoryless entities
and there is no thing-stuff distinction. Based on our unified entity
representation, we propose a center-based entity segmentation framework with
two novel modules to improve mask quality. Experimentally, both our new task
and framework demonstrate superior advantages as against existing work. In
particular, ES enables the following: (1) merging multiple datasets to form a
large training set without the need to resolve label conflicts; (2) any model
trained on one dataset can generalize exceptionally well to other datasets with
unseen domains. Our code is made publicly available at
https://github.com/dvlab-research/Entity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Social Processes: Self-Supervised Forecasting of Nonverbal Cues in Social Conversations. (arXiv:2107.13576v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raman_C/0/1/0/all/0/1">Chirag Raman</a>, <a href="http://arxiv.org/find/cs/1/au:+Hung_H/0/1/0/all/0/1">Hayley Hung</a>, <a href="http://arxiv.org/find/cs/1/au:+Loog_M/0/1/0/all/0/1">Marco Loog</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13576">
                                    <div class="article-summary-box-inner">
                                        <span>The default paradigm for the forecasting of human behavior in social
conversations is characterized by top-down approaches. These involve
identifying predictive relationships between low level nonverbal cues and
future semantic events of interest (e.g. turn changes, group leaving). A common
hurdle however, is the limited availability of labeled data for supervised
learning. In this work, we take the first step in the direction of a bottom-up
self-supervised approach in the domain. We formulate the task of Social Cue
Forecasting to leverage the larger amount of unlabeled low-level behavior cues,
and characterize the modeling challenges involved. To address these, we take a
meta-learning approach and propose the Social Process (SP) models--socially
aware sequence-to-sequence (Seq2Seq) models within the Neural Process (NP)
family. SP models learn extractable representations of non-semantic future cues
for each participant, while capturing global uncertainty by jointly reasoning
about the future for all members of the group. Evaluation on synthesized and
real-world behavior data shows that our SP models achieve higher log-likelihood
than the NP baselines, and also highlights important considerations for
applying such techniques within the domain of social human interactions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Amplitude Mean of Functional Data on $\mathbb{S}^2$. (arXiv:2107.13721v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengwu Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Saparbayeva_B/0/1/0/all/0/1">Bayan Saparbayeva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13721">
                                    <div class="article-summary-box-inner">
                                        <span>Mainfold-valued functional data analysis (FDA) recently becomes an active
area of research motivated by the raising availability of trajectories or
longitudinal data observed on non-linear manifolds. The challenges of analyzing
such data comes from many aspects, including infinite dimensionality and
nonlinearity, as well as time domain or phase variability. In this paper, we
study the amplitude part of manifold-valued functions on $\S^2$, which is
invariant to random time warping or re-parameterization of the function.
Utilizing the nice geometry of $\S^2$, we develop a set of efficient and
accurate tools for temporal alignment of functions, geodesic and sample mean
calculation. At the heart of these tools, they rely on gradient descent
algorithms with carefully derived gradients. We show the advantages of these
newly developed tools over its competitors with extensive simulations and real
data, and demonstrate the importance of considering the amplitude part of
functions instead of mixing it with phase variability in mainfold-valued FDA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalizing Fairness: Discovery and Mitigation of Unknown Sensitive Attributes. (arXiv:2107.13625v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1">William Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1">Philippe Burlina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13625">
                                    <div class="article-summary-box-inner">
                                        <span>When deploying artificial intelligence (AI) in the real world, being able to
trust the operation of the AI by characterizing how it performs is an
ever-present and important topic. An important and still largely unexplored
task in this characterization is determining major factors within the real
world that affect the AI&#x27;s behavior, such as weather conditions or lighting,
and either a) being able to give justification for why it may have failed or b)
eliminating the influence the factor has. Determining these sensitive factors
heavily relies on collected data that is diverse enough to cover numerous
combinations of these factors, which becomes more onerous when having many
potential sensitive factors or operating in complex environments. This paper
investigates methods that discover and separate out individual semantic
sensitive factors from a given dataset to conduct this characterization as well
as addressing mitigation of these factors&#x27; sensitivity. We also broaden
remediation of fairness, which normally only addresses socially relevant
factors, and widen it to deal with the desensitization of AI with regard to all
possible aspects of variation in the domain. The proposed methods which
discover these major factors reduce the potentially onerous demands of
collecting a sufficiently diverse dataset. In experiments using the road sign
(GTSRB) and facial imagery (CelebA) datasets, we show the promise of using this
scheme to perform this characterization and remediation and demonstrate that
our approach outperforms state of the art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ranking Micro-Influencers: a Novel Multi-Task Learning and Interpretable Framework. (arXiv:2107.13943v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elwood_A/0/1/0/all/0/1">Adam Elwood</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasparin_A/0/1/0/all/0/1">Alberto Gasparin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rozza_A/0/1/0/all/0/1">Alessandro Rozza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13943">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise in use of social media to promote branded products, the demand
for effective influencer marketing has increased. Brands are looking for
improved ways to identify valuable influencers among a vast catalogue; this is
even more challenging with &quot;micro-influencers&quot;, which are more affordable than
mainstream ones but difficult to discover. In this paper, we propose a novel
multi-task learning framework to improve the state of the art in
micro-influencer ranking based on multimedia content. Moreover, since the
visual congruence between a brand and influencer has been shown to be good
measure of compatibility, we provide an effective visual method for
interpreting our models&#x27; decisions, which can also be used to inform brands&#x27;
media strategies. We compare with the current state-of-the-art on a recently
constructed public dataset and we show significant improvement both in terms of
accuracy and model complexity. The techniques for ranking and interpretation
presented in this work can be generalised to arbitrary multimedia ranking tasks
that have datasets with a similar structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Addressing materials&#x27; microstructure diversity using transfer learning. (arXiv:2107.13841v1 [cond-mat.mtrl-sci])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Goetz_A/0/1/0/all/0/1">Aur&#xe8;le Goetz</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Durmaz_A/0/1/0/all/0/1">Ali Riza Durmaz</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Muller_M/0/1/0/all/0/1">Martin M&#xfc;ller</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Thomas_A/0/1/0/all/0/1">Akhil Thomas</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Britz_D/0/1/0/all/0/1">Dominik Britz</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Kerfriden_P/0/1/0/all/0/1">Pierre Kerfriden</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Eberl_C/0/1/0/all/0/1">Chris Eberl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13841">
                                    <div class="article-summary-box-inner">
                                        <span>Materials&#x27; microstructures are signatures of their alloying composition and
processing history. Therefore, microstructures exist in a wide variety. As
materials become increasingly complex to comply with engineering demands,
advanced computer vision (CV) approaches such as deep learning (DL) inevitably
gain relevance for quantifying microstrucutures&#x27; constituents from micrographs.
While DL can outperform classical CV techniques for many tasks, shortcomings
are poor data efficiency and generalizability across datasets. This is
inherently in conflict with the expense associated with annotating materials
data through experts and extensive materials diversity. To tackle poor domain
generalizability and the lack of labeled data simultaneously, we propose to
apply a sub-class of transfer learning methods called unsupervised domain
adaptation (UDA). These algorithms address the task of finding domain-invariant
features when supplied with annotated source data and unannotated target data,
such that performance on the latter distribution is optimized despite the
absence of annotations. Exemplarily, this study is conducted on a lath-shaped
bainite segmentation task in complex phase steel micrographs. Here, the domains
to bridge are selected to be different metallographic specimen preparations
(surface etchings) and distinct imaging modalities. We show that a
state-of-the-art UDA approach surpasses the na\&quot;ive application of source
domain trained models on the target domain (generalization baseline) to a large
extent. This holds true independent of the domain shift, despite using little
data, and even when the baseline models were pre-trained or employed data
augmentation. Through UDA, mIoU was improved over generalization baselines from
82.2%, 61.0%, 49.7% to 84.7%, 67.3%, 73.3% on three target datasets,
respectively. This underlines this techniques&#x27; potential to cope with materials
variance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point-Cloud Deep Learning of Porous Media for Permeability Prediction. (arXiv:2107.14038v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kashefi_A/0/1/0/all/0/1">Ali Kashefi</a>, <a href="http://arxiv.org/find/eess/1/au:+Mukerji_T/0/1/0/all/0/1">Tapan Mukerji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14038">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel deep learning framework for predicting permeability of
porous media from their digital images. Unlike convolutional neural networks,
instead of feeding the whole image volume as inputs to the network, we model
the boundary between solid matrix and pore spaces as point clouds and feed them
as inputs to a neural network based on the PointNet architecture. This approach
overcomes the challenge of memory restriction of graphics processing units and
its consequences on the choice of batch size, and convergence. Compared to
convolutional neural networks, the proposed deep learning methodology provides
freedom to select larger batch sizes, due to reducing significantly the size of
network inputs. Specifically, we use the classification branch of PointNet and
adjust it for a regression task. As a test case, two and three dimensional
synthetic digital rock images are considered. We investigate the effect of
different components of our neural network on its performance. We compare our
deep learning strategy with a convolutional neural network from various
perspectives, specifically for maximum possible batch size. We inspect the
generalizability of our network by predicting the permeability of real-world
rock samples as well as synthetic digital rocks that are statistically
different from the samples used during training. The network predicts the
permeability of digital rocks a few thousand times faster than a Lattice
Boltzmann solver with a high level of prediction accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tianshou: a Highly Modularized Deep Reinforcement Learning Library. (arXiv:2107.14171v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weng_J/0/1/0/all/0/1">Jiayi Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huayu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_D/0/1/0/all/0/1">Dong Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+You_K/0/1/0/all/0/1">Kaichao You</a>, <a href="http://arxiv.org/find/cs/1/au:+Duburcq_A/0/1/0/all/0/1">Alexis Duburcq</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14171">
                                    <div class="article-summary-box-inner">
                                        <span>We present Tianshou, a highly modularized python library for deep
reinforcement learning (DRL) that uses PyTorch as its backend. Tianshou aims to
provide building blocks to replicate common RL experiments and has officially
supported more than 15 classic algorithms succinctly. To facilitate related
research and prove Tianshou&#x27;s reliability, we release Tianshou&#x27;s benchmark of
MuJoCo environments, covering 9 classic algorithms and 9/13 Mujoco tasks with
state-of-the-art performance. We open-sourced Tianshou at
https://github.com/thu-ml/tianshou/, which has received over 3k stars and
become one of the most popular PyTorch-based DRL libraries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence Hybrid Deep Learning Model for Groundwater Level Prediction Using MLP-ADAM. (arXiv:2107.13870v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zarafshan_P/0/1/0/all/0/1">Pejman Zarafshan</a>, <a href="http://arxiv.org/find/cs/1/au:+Javadi_S/0/1/0/all/0/1">Saman Javadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Roozbahani_A/0/1/0/all/0/1">Abbas Roozbahani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemy_S/0/1/0/all/0/1">Seyed Mehdi Hashemy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zarafshan_P/0/1/0/all/0/1">Payam Zarafshan</a>, <a href="http://arxiv.org/find/cs/1/au:+Etezadi_H/0/1/0/all/0/1">Hamed Etezadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13870">
                                    <div class="article-summary-box-inner">
                                        <span>Groundwater is the largest storage of freshwater resources, which serves as
the major inventory for most of the human consumption through agriculture,
industrial, and domestic water supply. In the fields of hydrological, some
researchers applied a neural network to forecast rainfall intensity in
space-time and introduced the advantages of neural networks compared to
numerical models. Then, many researches have been conducted applying
data-driven models. Some of them extended an Artificial Neural Networks (ANNs)
model to forecast groundwater level in semi-confined glacial sand and gravel
aquifer under variable state, pumping extraction and climate conditions with
significant accuracy. In this paper, a multi-layer perceptron is applied to
simulate groundwater level. The adaptive moment estimation optimization
algorithm is also used to this matter. The root mean squared error, mean
absolute error, mean squared error and the coefficient of determination ( ) are
used to evaluate the accuracy of the simulated groundwater level. Total value
of and RMSE are 0.9458 and 0.7313 respectively which are obtained from the
model output. Results indicate that deep learning algorithms can demonstrate a
high accuracy prediction. Although the optimization of parameters is
insignificant in numbers, but due to the value of time in modelling setup, it
is highly recommended to apply an optimization algorithm in modelling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lyapunov-based uncertainty-aware safe reinforcement learning. (arXiv:2107.13944v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeddi_A/0/1/0/all/0/1">Ashkan B. Jeddi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehghani_N/0/1/0/all/0/1">Nariman L. Dehghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafieezadeh_A/0/1/0/all/0/1">Abdollah Shafieezadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13944">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) has shown a promising performance in learning
optimal policies for a variety of sequential decision-making tasks. However, in
many real-world RL problems, besides optimizing the main objectives, the agent
is expected to satisfy a certain level of safety (e.g., avoiding collisions in
autonomous driving). While RL problems are commonly formalized as Markov
decision processes (MDPs), safety constraints are incorporated via constrained
Markov decision processes (CMDPs). Although recent advances in safe RL have
enabled learning safe policies in CMDPs, these safety requirements should be
satisfied during both training and in the deployment process. Furthermore, it
is shown that in memory-based and partially observable environments, these
methods fail to maintain safety over unseen out-of-distribution observations.
To address these limitations, we propose a Lyapunov-based uncertainty-aware
safe RL model. The introduced model adopts a Lyapunov function that converts
trajectory-based constraints to a set of local linear constraints. Furthermore,
to ensure the safety of the agent in highly uncertain environments, an
uncertainty quantification method is developed that enables identifying
risk-averse actions through estimating the probability of constraint
violations. Moreover, a Transformers model is integrated to provide the agent
with memory to process long time horizons of information via the self-attention
mechanism. The proposed model is evaluated in grid-world navigation tasks where
safety is defined as avoiding static and dynamic obstacles in fully and
partially observable environments. The results of these experiments show a
significant improvement in the performance of the agent both in achieving
optimality and satisfying safety constraints.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">To Boost or not to Boost: On the Limits of Boosted Neural Networks. (arXiv:2107.13600v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rambhatla_S/0/1/0/all/0/1">Sai Saketh Rambhatla</a>, <a href="http://arxiv.org/find/cs/1/au:+Jones_M/0/1/0/all/0/1">Michael Jones</a>, <a href="http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1">Rama Chellappa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13600">
                                    <div class="article-summary-box-inner">
                                        <span>Boosting is a method for finding a highly accurate hypothesis by linearly
combining many &#x60;&#x60;weak&quot; hypotheses, each of which may be only moderately
accurate. Thus, boosting is a method for learning an ensemble of classifiers.
While boosting has been shown to be very effective for decision trees, its
impact on neural networks has not been extensively studied. We prove one
important difference between sums of decision trees compared to sums of
convolutional neural networks (CNNs) which is that a sum of decision trees
cannot be represented by a single decision tree with the same number of
parameters while a sum of CNNs can be represented by a single CNN. Next, using
standard object recognition datasets, we verify experimentally the well-known
result that a boosted ensemble of decision trees usually generalizes much
better on testing data than a single decision tree with the same number of
parameters. In contrast, using the same datasets and boosting algorithms, our
experiments show the opposite to be true when using neural networks (both CNNs
and multilayer perceptrons (MLPs)). We find that a single neural network
usually generalizes better than a boosted ensemble of smaller neural networks
with the same total number of parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Co-learning: Challenges, Applications with Datasets, Recent Advances and Future Directions. (arXiv:2107.13782v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahate_A/0/1/0/all/0/1">Anil Rahate</a>, <a href="http://arxiv.org/find/cs/1/au:+Walambe_R/0/1/0/all/0/1">Rahee Walambe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanna_S/0/1/0/all/0/1">Sheela Ramanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotecha_K/0/1/0/all/0/1">Ketan Kotecha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13782">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal deep learning systems which employ multiple modalities like text,
image, audio, video, etc., are showing better performance in comparison with
individual modalities (i.e., unimodal) systems. Multimodal machine learning
involves multiple aspects: representation, translation, alignment, fusion, and
co-learning. In the current state of multimodal machine learning, the
assumptions are that all modalities are present, aligned, and noiseless during
training and testing time. However, in real-world tasks, typically, it is
observed that one or more modalities are missing, noisy, lacking annotated
data, have unreliable labels, and are scarce in training or testing and or
both. This challenge is addressed by a learning paradigm called multimodal
co-learning. The modeling of a (resource-poor) modality is aided by exploiting
knowledge from another (resource-rich) modality using transfer of knowledge
between modalities, including their representations and predictive models.
Co-learning being an emerging area, there are no dedicated reviews explicitly
focusing on all challenges addressed by co-learning. To that end, in this work,
we provide a comprehensive survey on the emerging area of multimodal
co-learning that has not been explored in its entirety yet. We review
implementations that overcome one or more co-learning challenges without
explicitly considering them as co-learning challenges. We present the
comprehensive taxonomy of multimodal co-learning based on the challenges
addressed by co-learning and associated implementations. The various techniques
employed to include the latest ones are reviewed along with some of the
applications and datasets. Our final goal is to discuss challenges and
perspectives along with the important ideas and directions for future work that
we hope to be beneficial for the entire research community focusing on this
exciting domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning and Deep Learning Methods for Building Intelligent Systems in Medicine and Drug Discovery: A Comprehensive Survey. (arXiv:2107.14037v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chowdary_G/0/1/0/all/0/1">G Jignesh Chowdary</a>, <a href="http://arxiv.org/find/cs/1/au:+G_S/0/1/0/all/0/1">Suganya G</a>, <a href="http://arxiv.org/find/cs/1/au:+M_P/0/1/0/all/0/1">Premalatha M</a>, <a href="http://arxiv.org/find/cs/1/au:+Y_A/0/1/0/all/0/1">Asnath Victy Phamila Y</a>, <a href="http://arxiv.org/find/cs/1/au:+K_K/0/1/0/all/0/1">Karunamurthy K</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14037">
                                    <div class="article-summary-box-inner">
                                        <span>With the advancements in computer technology, there is a rapid development of
intelligent systems to understand the complex relationships in data to make
predictions and classifications. Artificail Intelligence based framework is
rapidly revolutionizing the healthcare industry. These intelligent systems are
built with machine learning and deep learning based robust models for early
diagnosis of diseases and demonstrates a promising supplementary diagnostic
method for frontline clinical doctors and surgeons. Machine Learning and Deep
Learning based systems can streamline and simplify the steps involved in
diagnosis of diseases from clinical and image-based data, thus providing
significant clinician support and workflow optimization. They mimic human
cognition and are even capable of diagnosing diseases that cannot be diagnosed
with human intelligence. This paper focuses on the survey of machine learning
and deep learning applications in across 16 medical specialties, namely Dental
medicine, Haematology, Surgery, Cardiology, Pulmonology, Orthopedics,
Radiology, Oncology, General medicine, Psychiatry, Endocrinology, Neurology,
Dermatology, Hepatology, Nephrology, Ophthalmology, and Drug discovery. In this
paper along with the survey, we discuss the advancements of medical practices
with these systems and also the impact of these systems on medical
professionals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">QuPeD: Quantized Personalization via Distillation with Applications to Federated Learning. (arXiv:2107.13892v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozkara_K/0/1/0/all/0/1">Kaan Ozkara</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_N/0/1/0/all/0/1">Navjot Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Data_D/0/1/0/all/0/1">Deepesh Data</a>, <a href="http://arxiv.org/find/cs/1/au:+Diggavi_S/0/1/0/all/0/1">Suhas Diggavi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13892">
                                    <div class="article-summary-box-inner">
                                        <span>Traditionally, federated learning (FL) aims to train a single global model
while collaboratively using multiple clients and a server. Two natural
challenges that FL algorithms face are heterogeneity in data across clients and
collaboration of clients with {\em diverse resources}. In this work, we
introduce a \textit{quantized} and \textit{personalized} FL algorithm QuPeD
that facilitates collective (personalized model compression) training via
\textit{knowledge distillation} (KD) among clients who have access to
heterogeneous data and resources. For personalization, we allow clients to
learn \textit{compressed personalized models} with different quantization
parameters and model dimensions/structures. Towards this, first we propose an
algorithm for learning quantized models through a relaxed optimization problem,
where quantization values are also optimized over. When each client
participating in the (federated) learning process has different requirements
for the compressed model (both in model dimension and precision), we formulate
a compressed personalization framework by introducing knowledge distillation
loss for local client objectives collaborating through a global model. We
develop an alternating proximal gradient update for solving this compressed
personalization problem, and analyze its convergence properties. Numerically,
we validate that QuPeD outperforms competing personalized FL methods, FedAvg,
and local training of clients in various heterogeneous settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProtoTransformer: A Meta-Learning Approach to Providing Student Feedback. (arXiv:2107.14035v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Mike Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1">Noah Goodman</a>, <a href="http://arxiv.org/find/cs/1/au:+Piech_C/0/1/0/all/0/1">Chris Piech</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14035">
                                    <div class="article-summary-box-inner">
                                        <span>High-quality computer science education is limited by the difficulty of
providing instructor feedback to students at scale. While this feedback could
in principle be automated, supervised approaches to predicting the correct
feedback are bottlenecked by the intractability of annotating large quantities
of student code. In this paper, we instead frame the problem of providing
feedback as few-shot classification, where a meta-learner adapts to give
feedback to student code on a new programming question from just a few examples
annotated by instructors. Because data for meta-training is limited, we propose
a number of amendments to the typical few-shot learning framework, including
task augmentation to create synthetic tasks, and additional side information to
build stronger priors about each task. These additions are combined with a
transformer architecture to embed discrete sequences (e.g. code) to a
prototypical representation of a feedback class label. On a suite of few-shot
natural language processing tasks, we match or outperform state-of-the-art
performance. Then, on a collection of student solutions to exam questions from
an introductory university course, we show that our approach reaches an average
precision of 88% on unseen questions, surpassing the 82% precision of teaching
assistants. Our approach was successfully deployed to deliver feedback to
16,000 student exam-solutions in a programming course offered by a tier 1
university. This is, to the best of our knowledge, the first successful
deployment of a machine learning based feedback to open-ended student code.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structure and Performance of Fully Connected Neural Networks: Emerging Complex Network Properties. (arXiv:2107.14062v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scabini_L/0/1/0/all/0/1">Leonardo F. S. Scabini</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruno_O/0/1/0/all/0/1">Odemir M. Bruno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14062">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the behavior of Artificial Neural Networks is one of the main
topics in the field recently, as black-box approaches have become usual since
the widespread of deep learning. Such high-dimensional models may manifest
instabilities and weird properties that resemble complex systems. Therefore, we
propose Complex Network (CN) techniques to analyze the structure and
performance of fully connected neural networks. For that, we build a dataset
with 4 thousand models and their respective CN properties. They are employed in
a supervised classification setup considering four vision benchmarks. Each
neural network is approached as a weighted and undirected graph of neurons and
synapses, and centrality measures are computed after training. Results show
that these measures are highly related to the network classification
performance. We also propose the concept of Bag-Of-Neurons (BoN), a CN-based
approach for finding topological signatures linking similar neurons. Results
suggest that six neuronal types emerge in such networks, independently of the
target domain, and are distributed differently according to classification
accuracy. We also tackle specific CN properties related to performance, such as
higher subgraph centrality on lower-performing models. Our findings suggest
that CN properties play a critical role in the performance of fully connected
neural networks, with topological patterns emerging independently on a wide
range of models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HAFLO: GPU-Based Acceleration for Federated Logistic Regression. (arXiv:2107.13797v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiaodian Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wanhang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xinyang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shuihai Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kai Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13797">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, federated learning (FL) has been widely applied for
supporting decentralized collaborative learning scenarios. Among existing FL
models, federated logistic regression (FLR) is a widely used statistic model
and has been used in various industries. To ensure data security and user
privacy, FLR leverages homomorphic encryption (HE) to protect the exchanged
data among different collaborative parties. However, HE introduces significant
computational overhead (i.e., the cost of data encryption/decryption and
calculation over encrypted data), which eventually becomes the performance
bottleneck of the whole system. In this paper, we propose HAFLO, a GPU-based
solution to improve the performance of FLR. The core idea of HAFLO is to
summarize a set of performance-critical homomorphic operators (HO) used by FLR
and accelerate the execution of these operators through a joint optimization of
storage, IO, and computation. The preliminary results show that our
acceleration on FATE, a popular FL framework, achieves a 49.9$\times$ speedup
for heterogeneous LR and 88.4$\times$ for homogeneous LR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-temporal graph neural networks for multi-site PV power forecasting. (arXiv:2107.13875v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Simeunovic_J/0/1/0/all/0/1">Jelena Simeunovi&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Schubnel_B/0/1/0/all/0/1">Baptiste Schubnel</a>, <a href="http://arxiv.org/find/cs/1/au:+Alet_P/0/1/0/all/0/1">Pierre-Jean Alet</a>, <a href="http://arxiv.org/find/cs/1/au:+Carrillo_R/0/1/0/all/0/1">Rafael E. Carrillo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13875">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate forecasting of solar power generation with fine temporal and spatial
resolution is vital for the operation of the power grid. However,
state-of-the-art approaches that combine machine learning with numerical
weather predictions (NWP) have coarse resolution. In this paper, we take a
graph signal processing perspective and model multi-site photovoltaic (PV)
production time series as signals on a graph to capture their spatio-temporal
dependencies and achieve higher spatial and temporal resolution forecasts. We
present two novel graph neural network models for deterministic multi-site PV
forecasting dubbed the graph-convolutional long short term memory (GCLSTM) and
the graph-convolutional transformer (GCTrafo) models. These methods rely solely
on production data and exploit the intuition that PV systems provide a dense
network of virtual weather stations. The proposed methods were evaluated in two
data sets for an entire year: 1) production data from 304 real PV systems, and
2) simulated production of 1000 PV systems, both distributed over Switzerland.
The proposed models outperform state-of-the-art multi-site forecasting methods
for prediction horizons of six hours ahead. Furthermore, the proposed models
outperform state-of-the-art single-site methods with NWP as inputs on horizons
up to four hours ahead.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Competitive Control. (arXiv:2107.13657v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Goel_G/0/1/0/all/0/1">Gautam Goel</a>, <a href="http://arxiv.org/find/math/1/au:+Hassibi_B/0/1/0/all/0/1">Babak Hassibi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13657">
                                    <div class="article-summary-box-inner">
                                        <span>We consider control from the perspective of competitive analysis. Unlike much
prior work on learning-based control, which focuses on minimizing regret
against the best controller selected in hindsight from some specific class, we
focus on designing an online controller which competes against a clairvoyant
offline optimal controller. A natural performance metric in this setting is
competitive ratio, which is the ratio between the cost incurred by the online
controller and the cost incurred by the offline optimal controller. Using
operator-theoretic techniques from robust control, we derive a computationally
efficient state-space description of the the controller with optimal
competitive ratio in both finite-horizon and infinite-horizon settings. We
extend competitive control to nonlinear systems using Model Predictive Control
(MPC) and present numerical experiments which show that our competitive
controller can significantly outperform standard $H_2$ and $H_{\infty}$
controllers in the MPC setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Internet-of-Things Devices and Assistive Technologies for Healthcare: Applications, Challenges, and Opportunities. (arXiv:2107.14112v1 [physics.soc-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Baucas_M/0/1/0/all/0/1">Marc Jayson Baucas</a>, <a href="http://arxiv.org/find/physics/1/au:+Spachos_P/0/1/0/all/0/1">Petros Spachos</a>, <a href="http://arxiv.org/find/physics/1/au:+Gregori_S/0/1/0/all/0/1">Stefano Gregori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14112">
                                    <div class="article-summary-box-inner">
                                        <span>Medical conditions and cases are growing at a rapid pace, where physical
space is starting to be constrained. Hospitals and clinics no longer have the
ability to accommodate large numbers of incoming patients. It is clear that the
current state of the health industry needs to improve its valuable and limited
resources. The evolution of the Internet of Things (IoT) devices along with
assistive technologies can alleviate the problem in healthcare, by being a
convenient and easy means of accessing healthcare services wirelessly. There is
a plethora of IoT devices and potential applications that can take advantage of
the unique characteristics that these technologies can offer. However, at the
same time, these services pose novel challenges that need to be properly
addressed. In this article, we review some popular categories of IoT-based
applications for healthcare along with their devices. Then, we describe the
challenges and discuss how research can properly address the open issues and
improve the already existing implementations in healthcare. Further possible
solutions are also discussed to show their potential in being viable solutions
for future healthcare applications</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing. (arXiv:2107.13586v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1">Weizhe Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jinlan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhengbao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hayashi_H/0/1/0/all/0/1">Hiroaki Hayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13586">
                                    <div class="article-summary-box-inner">
                                        <span>This paper surveys and organizes research works in a new paradigm in natural
language processing, which we dub &quot;prompt-based learning&quot;. Unlike traditional
supervised learning, which trains a model to take in an input x and predict an
output y as P(y|x), prompt-based learning is based on language models that
model the probability of text directly. To use these models to perform
prediction tasks, the original input x is modified using a template into a
textual string prompt x&#x27; that has some unfilled slots, and then the language
model is used to probabilistically fill the unfilled information to obtain a
final string x, from which the final output y can be derived. This framework is
powerful and attractive for a number of reasons: it allows the language model
to be pre-trained on massive amounts of raw text, and by defining a new
prompting function the model is able to perform few-shot or even zero-shot
learning, adapting to new scenarios with few or no labeled data. In this paper
we introduce the basics of this promising paradigm, describe a unified set of
mathematical notations that can cover a wide variety of existing work, and
organize existing work along several dimensions, e.g.the choice of pre-trained
models, prompts, and tuning strategies. To make the field more accessible to
interested beginners, we not only make a systematic review of existing works
and a highly structured typology of prompt-based concepts, but also release
other resources, e.g., a website this http URL including
constantly-updated survey, and paperlist.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deeper Learning By Doing: Integrating Hands-On Research Projects Into a Machine Learning Course. (arXiv:2107.13671v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raschka_S/0/1/0/all/0/1">Sebastian Raschka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13671">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning has seen a vast increase of interest in recent years, along
with an abundance of learning resources. While conventional lectures provide
students with important information and knowledge, we also believe that
additional project-based learning components can motivate students to engage in
topics more deeply. In addition to incorporating project-based learning in our
courses, we aim to develop project-based learning components aligned with
real-world tasks, including experimental design and execution, report writing,
oral presentation, and peer-reviewing. This paper describes the organization of
our project-based machine learning courses with a particular emphasis on the
class project components and shares our resources with instructors who would
like to include similar elements in their courses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Excavating AI&quot; Re-excavated: Debunking a Fallacious Account of the JAFFE Dataset. (arXiv:2107.13998v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyons_M/0/1/0/all/0/1">Michael J. Lyons</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13998">
                                    <div class="article-summary-box-inner">
                                        <span>Twenty-five years ago, my colleagues Miyuki Kamachi and Jiro Gyoba and I
designed and photographed JAFFE, a set of facial expression images intended for
use in a study of face perception. In 2019, without seeking permission or
informing us, Kate Crawford and Trevor Paglen exhibited JAFFE in two widely
publicized art shows. In addition, they published a nonfactual account of the
images in the essay &quot;Excavating AI: The Politics of Images in Machine Learning
Training Sets.&quot; The present article recounts the creation of the JAFFE dataset
and unravels each of Crawford and Paglen&#x27;s fallacious statements. I also
discuss JAFFE more broadly in connection with research on facial expression,
affective computing, and human-computer interaction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pitch-Informed Instrument Assignment Using a Deep Convolutional Network with Multiple Kernel Shapes. (arXiv:2107.13617v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lordelo_C/0/1/0/all/0/1">Carlos Lordelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Benetos_E/0/1/0/all/0/1">Emmanouil Benetos</a>, <a href="http://arxiv.org/find/cs/1/au:+Dixon_S/0/1/0/all/0/1">Simon Dixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahlback_S/0/1/0/all/0/1">Sven Ahlb&#xe4;ck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13617">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a deep convolutional neural network for performing
note-level instrument assignment. Given a polyphonic multi-instrumental music
signal along with its ground truth or predicted notes, the objective is to
assign an instrumental source for each note. This problem is addressed as a
pitch-informed classification task where each note is analysed individually. We
also propose to utilise several kernel shapes in the convolutional layers in
order to facilitate learning of efficient timbre-discriminative feature maps.
Experiments on the MusicNet dataset using 7 instrument classes show that our
approach is able to achieve an average F-score of 0.904 when the original
multi-pitch annotations are used as the pitch information for the system, and
that it also excels if the note information is provided using third-party
multi-pitch estimation algorithms. We also include ablation studies
investigating the effects of the use of multiple kernel shapes and comparing
different input representations for the audio and the note-related information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demand Forecasting in Smart Grid Using Long Short-Term Memory. (arXiv:2107.13653v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1">Koushik Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishmam_A/0/1/0/all/0/1">Abtahi Ishmam</a>, <a href="http://arxiv.org/find/cs/1/au:+Taher_K/0/1/0/all/0/1">Kazi Abu Taher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13653">
                                    <div class="article-summary-box-inner">
                                        <span>Demand forecasting in power sector has become an important part of modern
demand management and response systems with the rise of smart metering enabled
grids. Long Short-Term Memory (LSTM) shows promising results in predicting time
series data which can also be applied to power load demand in smart grids. In
this paper, an LSTM based model using neural network architecture is proposed
to forecast power demand. The model is trained with hourly energy and power
usage data of four years from a smart grid. After training and prediction, the
accuracy of the model is compared against the traditional statistical time
series analysis algorithms, such as Auto-Regressive (AR), to determine the
efficiency. The mean absolute percentile error is found to be 1.22 in the
proposed LSTM model, which is the lowest among the other models. From the
findings, it is clear that the inclusion of neural network in predicting power
demand reduces the error of prediction significantly. Thus, the application of
LSTM can enable a more efficient demand response system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Graph Reinforcement Learning Model for Improving User Experience in Live Video Streaming. (arXiv:2107.13619v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Antaris_S/0/1/0/all/0/1">Stefanos Antaris</a>, <a href="http://arxiv.org/find/cs/1/au:+Rafailidis_D/0/1/0/all/0/1">Dimitrios Rafailidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Girdzijauskas_S/0/1/0/all/0/1">Sarunas Girdzijauskas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13619">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present a deep graph reinforcement learning model to predict
and improve the user experience during a live video streaming event,
orchestrated by an agent/tracker. We first formulate the user experience
prediction problem as a classification task, accounting for the fact that most
of the viewers at the beginning of an event have poor quality of experience due
to low-bandwidth connections and limited interactions with the tracker. In our
model we consider different factors that influence the quality of user
experience and train the proposed model on diverse state-action transitions
when viewers interact with the tracker. In addition, provided that past events
have various user experience characteristics we follow a gradient boosting
strategy to compute a global model that learns from different events. Our
experiments with three real-world datasets of live video streaming events
demonstrate the superiority of the proposed model against several baseline
strategies. Moreover, as the majority of the viewers at the beginning of an
event has poor experience, we show that our model can significantly increase
the number of viewers with high quality experience by at least 75% over the
first streaming minutes. Our evaluation datasets and implementation are
publicly available at https://publicresearch.z13.web.core.windows.net</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Secure Bayesian Federated Analytics for Privacy-Preserving Trend Detection. (arXiv:2107.13640v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chaulwar_A/0/1/0/all/0/1">Amit Chaulwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Huth_M/0/1/0/all/0/1">Michael Huth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13640">
                                    <div class="article-summary-box-inner">
                                        <span>Federated analytics has many applications in edge computing, its use can lead
to better decision making for service provision, product development, and user
experience. We propose a Bayesian approach to trend detection in which the
probability of a keyword being trendy, given a dataset, is computed via Bayes&#x27;
Theorem; the probability of a dataset, given that a keyword is trendy, is
computed through secure aggregation of such conditional probabilities over
local datasets of users. We propose a protocol, named SAFE, for Bayesian
federated analytics that offers sufficient privacy for production grade use
cases and reduces the computational burden of users and an aggregator. We
illustrate this approach with a trend detection experiment and discuss how this
approach could be extended further to make it production-ready.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Effects of Adversarial Personalized Ranking Optimization Method on Recommendation Quality. (arXiv:2107.13876v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anelli_V/0/1/0/all/0/1">Vito Walter Anelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Deldjoo_Y/0/1/0/all/0/1">Yashar Deldjoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1">Tommaso Di Noia</a>, <a href="http://arxiv.org/find/cs/1/au:+Merra_F/0/1/0/all/0/1">Felice Antonio Merra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13876">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems (RSs) employ user-item feedback, e.g., ratings, to match
customers to personalized lists of products. Approaches to top-k recommendation
mainly rely on Learning-To-Rank algorithms and, among them, the most widely
adopted is Bayesian Personalized Ranking (BPR), which bases on a pair-wise
optimization approach. Recently, BPR has been found vulnerable against
adversarial perturbations of its model parameters. Adversarial Personalized
Ranking (APR) mitigates this issue by robustifying BPR via an adversarial
training procedure. The empirical improvements of APR&#x27;s accuracy performance on
BPR have led to its wide use in several recommender models. However, a key
overlooked aspect has been the beyond-accuracy performance of APR, i.e.,
novelty, coverage, and amplification of popularity bias, considering that
recent results suggest that BPR, the building block of APR, is sensitive to the
intensification of biases and reduction of recommendation novelty. In this
work, we model the learning characteristics of the BPR and APR optimization
frameworks to give mathematical evidence that, when the feedback data have a
tailed distribution, APR amplifies the popularity bias more than BPR due to an
unbalanced number of received positive updates from short-head items. Using
matrix factorization (MF), we empirically validate the theoretical results by
performing preliminary experiments on two public datasets to compare BPR-MF and
APR-MF performance on accuracy and beyond-accuracy metrics. The experimental
results consistently show the degradation of novelty and coverage measures and
a worrying amplification of bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoTinyBERT: Automatic Hyper-parameter Optimization for Efficient Pre-trained Language Models. (arXiv:2107.13686v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yichun Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Cheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_L/0/1/0/all/0/1">Lifeng Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13686">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained language models (PLMs) have achieved great success in natural
language processing. Most of PLMs follow the default setting of architecture
hyper-parameters (e.g., the hidden dimension is a quarter of the intermediate
dimension in feed-forward sub-networks) in BERT (Devlin et al., 2019). Few
studies have been conducted to explore the design of architecture
hyper-parameters in BERT, especially for the more efficient PLMs with tiny
sizes, which are essential for practical deployment on resource-constrained
devices. In this paper, we adopt the one-shot Neural Architecture Search (NAS)
to automatically search architecture hyper-parameters. Specifically, we
carefully design the techniques of one-shot learning and the search space to
provide an adaptive and efficient development way of tiny PLMs for various
latency constraints. We name our method AutoTinyBERT and evaluate its
effectiveness on the GLUE and SQuAD benchmarks. The extensive experiments show
that our method outperforms both the SOTA search-based baseline (NAS-BERT) and
the SOTA distillation-based methods (such as DistilBERT, TinyBERT, MiniLM and
MobileBERT). In addition, based on the obtained architectures, we propose a
more efficient development method that is even faster than the development of a
single PLM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting battery end of life from solar off-grid system field data using machine learning. (arXiv:2107.13856v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aitio_A/0/1/0/all/0/1">Antti Aitio</a>, <a href="http://arxiv.org/find/cs/1/au:+Howey_D/0/1/0/all/0/1">David A. Howey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13856">
                                    <div class="article-summary-box-inner">
                                        <span>Hundreds of millions of people lack access to electricity. Decentralised
solar-battery systems are key for addressing this whilst avoiding carbon
emissions and air pollution, but are hindered by relatively high costs and
rural locations that inhibit timely preventative maintenance. Accurate
diagnosis of battery health and prediction of end of life from operational data
improves user experience and reduces costs. But lack of controlled validation
tests and variable data quality mean existing lab-based techniques fail to
work. We apply a scaleable probabilistic machine learning approach to diagnose
health in 1027 solar-connected lead-acid batteries, each running for 400-760
days, totalling 620 million data rows. We demonstrate 73% accurate prediction
of end of life, eight weeks in advance, rising to 82% at the point of failure.
This work highlights the opportunity to estimate health from existing
measurements using &#x60;big data&#x27; techniques, without additional equipment,
extending lifetime and improving performance in real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imbalanced Adversarial Training with Reweighting. (arXiv:2107.13639v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wentao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Han Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaorui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yaxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Thuraisingham_B/0/1/0/all/0/1">Bhavani Thuraisingham</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiliang Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13639">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training has been empirically proven to be one of the most
effective and reliable defense methods against adversarial attacks. However,
almost all existing studies about adversarial training are focused on balanced
datasets, where each class has an equal amount of training examples. Research
on adversarial training with imbalanced training datasets is rather limited. As
the initial effort to investigate this problem, we reveal the facts that
adversarially trained models present two distinguished behaviors from naturally
trained models in imbalanced datasets: (1) Compared to natural training,
adversarially trained models can suffer much worse performance on
under-represented classes, when the training dataset is extremely imbalanced.
(2) Traditional reweighting strategies may lose efficacy to deal with the
imbalance issue for adversarial training. For example, upweighting the
under-represented classes will drastically hurt the model&#x27;s performance on
well-represented classes, and as a result, finding an optimal reweighting value
can be tremendously challenging. In this paper, to further understand our
observations, we theoretically show that the poor data separability is one key
reason causing this strong tension between under-represented and
well-represented classes. Motivated by this finding, we propose Separable
Reweighted Adversarial Training (SRAT) to facilitate adversarial training under
imbalanced scenarios, by learning more separable features for different
classes. Extensive experiments on various datasets verify the effectiveness of
the proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Concept for a Technical Infrastructure for Management of Predictive Models in Industrial Applications. (arXiv:2107.13821v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bachinger_F/0/1/0/all/0/1">Florian Bachinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Kronberger_G/0/1/0/all/0/1">Gabriel Kronberger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13821">
                                    <div class="article-summary-box-inner">
                                        <span>With the increasing number of created and deployed prediction models and the
complexity of machine learning workflows we require so called model management
systems to support data scientists in their tasks. In this work we describe our
technological concept for such a model management system. This concept includes
versioned storage of data, support for different machine learning algorithms,
fine tuning of models, subsequent deployment of models and monitoring of model
performance after deployment. We describe this concept with a close focus on
model lifecycle requirements stemming from our industry application cases, but
generalize key features that are relevant for all applications of machine
learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Transformer based Dual Discriminator Generative Adversarial Networks for Video Anomaly Detection. (arXiv:2107.13720v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xinyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dongjin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuncong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengzhang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1">Jingchao Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13720">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting abnormal activities in real-world surveillance videos is an
important yet challenging task as the prior knowledge about video anomalies is
usually limited or unavailable. Despite that many approaches have been
developed to resolve this problem, few of them can capture the normal
spatio-temporal patterns effectively and efficiently. Moreover, existing works
seldom explicitly consider the local consistency at frame level and global
coherence of temporal dynamics in video sequences. To this end, we propose
Convolutional Transformer based Dual Discriminator Generative Adversarial
Networks (CT-D2GAN) to perform unsupervised video anomaly detection.
Specifically, we first present a convolutional transformer to perform future
frame prediction. It contains three key components, i.e., a convolutional
encoder to capture the spatial information of the input video clips, a temporal
self-attention module to encode the temporal dynamics, and a convolutional
decoder to integrate spatio-temporal features and predict the future frame.
Next, a dual discriminator based adversarial training procedure, which jointly
considers an image discriminator that can maintain the local consistency at
frame-level and a video discriminator that can enforce the global coherence of
temporal dynamics, is employed to enhance the future frame prediction. Finally,
the prediction error is used to identify abnormal video frames. Thoroughly
empirical studies on three public video anomaly detection datasets, i.e., UCSD
Ped2, CUHK Avenue, and Shanghai Tech Campus, demonstrate the effectiveness of
the proposed adversarial spatio-temporal modeling framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Artificial Intelligence in Achieving Sustainable Development Goals. (arXiv:2107.13966v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goh_H/0/1/0/all/0/1">Hoe-Han Goh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13966">
                                    <div class="article-summary-box-inner">
                                        <span>This perspective illustrates some of the AI applications that can accelerate
the achievement of SDGs and also highlights some of the considerations that
could hinder the efforts towards them. This emphasizes the importance of
establishing standard AI guidelines and regulations for the beneficial
applications of AI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Characterizing the Generalization Error of Gibbs Algorithm with Symmetrized KL information. (arXiv:2107.13656v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aminian_G/0/1/0/all/0/1">Gholamali Aminian</a>, <a href="http://arxiv.org/find/cs/1/au:+Bu_Y/0/1/0/all/0/1">Yuheng Bu</a>, <a href="http://arxiv.org/find/cs/1/au:+Toni_L/0/1/0/all/0/1">Laura Toni</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1">Miguel R. D. Rodrigues</a>, <a href="http://arxiv.org/find/cs/1/au:+Wornell_G/0/1/0/all/0/1">Gregory Wornell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13656">
                                    <div class="article-summary-box-inner">
                                        <span>Bounding the generalization error of a supervised learning algorithm is one
of the most important problems in learning theory, and various approaches have
been developed. However, existing bounds are often loose and lack of
guarantees. As a result, they may fail to characterize the exact generalization
ability of a learning algorithm. Our main contribution is an exact
characterization of the expected generalization error of the well-known Gibbs
algorithm in terms of symmetrized KL information between the input training
samples and the output hypothesis. Such a result can be applied to tighten
existing expected generalization error bound. Our analysis provides more
insight on the fundamental role the symmetrized KL information plays in
controlling the generalization error of the Gibbs algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mind the Performance Gap: Examining Dataset Shift During Prospective Validation. (arXiv:2107.13964v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Otles_E/0/1/0/all/0/1">Erkin &#xd6;tle&#x15f;</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1">Jeeheh Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Benjamin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bochinski_M/0/1/0/all/0/1">Michelle Bochinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Joo_H/0/1/0/all/0/1">Hyeon Joo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortwine_J/0/1/0/all/0/1">Justin Ortwine</a>, <a href="http://arxiv.org/find/cs/1/au:+Shenoy_E/0/1/0/all/0/1">Erica Shenoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Washer_L/0/1/0/all/0/1">Laraine Washer</a>, <a href="http://arxiv.org/find/cs/1/au:+Young_V/0/1/0/all/0/1">Vincent B. Young</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_K/0/1/0/all/0/1">Krishna Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiens_J/0/1/0/all/0/1">Jenna Wiens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13964">
                                    <div class="article-summary-box-inner">
                                        <span>Once integrated into clinical care, patient risk stratification models may
perform worse compared to their retrospective performance. To date, it is
widely accepted that performance will degrade over time due to changes in care
processes and patient populations. However, the extent to which this occurs is
poorly understood, in part because few researchers report prospective
validation performance. In this study, we compare the 2020-2021 (&#x27;20-&#x27;21)
prospective performance of a patient risk stratification model for predicting
healthcare-associated infections to a 2019-2020 (&#x27;19-&#x27;20) retrospective
validation of the same model. We define the difference in retrospective and
prospective performance as the performance gap. We estimate how i) &quot;temporal
shift&quot;, i.e., changes in clinical workflows and patient populations, and ii)
&quot;infrastructure shift&quot;, i.e., changes in access, extraction and transformation
of data, both contribute to the performance gap. Applied prospectively to
26,864 hospital encounters during a twelve-month period from July 2020 to June
2021, the model achieved an area under the receiver operating characteristic
curve (AUROC) of 0.767 (95% confidence interval (CI): 0.737, 0.801) and a Brier
score of 0.189 (95% CI: 0.186, 0.191). Prospective performance decreased
slightly compared to &#x27;19-&#x27;20 retrospective performance, in which the model
achieved an AUROC of 0.778 (95% CI: 0.744, 0.815) and a Brier score of 0.163
(95% CI: 0.161, 0.165). The resulting performance gap was primarily due to
infrastructure shift and not temporal shift. So long as we continue to develop
and validate models using data stored in large research data warehouses, we
must consider differences in how and when data are accessed, measure how these
differences may affect prospective performance, and work to mitigate those
differences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Relaxations of Logic for Neural Networks: A Comprehensive Study. (arXiv:2107.13646v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grespan_M/0/1/0/all/0/1">Mattia Medina Grespan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Ashim Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1">Vivek Srikumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13646">
                                    <div class="article-summary-box-inner">
                                        <span>Symbolic knowledge can provide crucial inductive bias for training neural
models, especially in low data regimes. A successful strategy for incorporating
such knowledge involves relaxing logical statements into sub-differentiable
losses for optimization. In this paper, we study the question of how best to
relax logical expressions that represent labeled examples and knowledge about a
problem; we focus on sub-differentiable t-norm relaxations of logic. We present
theoretical and empirical criteria for characterizing which relaxation would
perform best in various scenarios. In our theoretical study driven by the goal
of preserving tautologies, the Lukasiewicz t-norm performs best. However, in
our empirical analysis on the text chunking and digit recognition tasks, the
product t-norm achieves best predictive performance. We analyze this apparent
discrepancy, and conclude with a list of best practices for defining loss
functions via logic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large sample spectral analysis of graph-based multi-manifold clustering. (arXiv:2107.13610v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trillos_N/0/1/0/all/0/1">Nicolas Garcia Trillos</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengfei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenghui Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13610">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we study statistical properties of graph-based algorithms for
multi-manifold clustering (MMC). In MMC the goal is to retrieve the
multi-manifold structure underlying a given Euclidean data set when this one is
assumed to be obtained by sampling a distribution on a union of manifolds
$\mathcal{M} &#x3D; \mathcal{M}_1 \cup\dots \cup \mathcal{M}_N$ that may intersect
with each other and that may have different dimensions. We investigate
sufficient conditions that similarity graphs on data sets must satisfy in order
for their corresponding graph Laplacians to capture the right geometric
information to solve the MMC problem. Precisely, we provide high probability
error bounds for the spectral approximation of a tensorized Laplacian on
$\mathcal{M}$ with a suitable graph Laplacian built from the observations; the
recovered tensorized Laplacian contains all geometric information of all the
individual underlying manifolds. We provide an example of a family of
similarity graphs, which we call annular proximity graphs with angle
constraints, satisfying these sufficient conditions. We contrast our family of
graphs with other constructions in the literature based on the alignment of
tangent planes. Extensive numerical experiments expand the insights that our
theory provides on the MMC problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating Respiratory Rate From Breath Audio Obtained Through Wearable Microphones. (arXiv:2107.14028v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Agni Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_V/0/1/0/all/0/1">Vikramjit Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliver_C/0/1/0/all/0/1">Carolyn Oliver</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullal_A/0/1/0/all/0/1">Adeeti Ullal</a>, <a href="http://arxiv.org/find/cs/1/au:+Biddulph_M/0/1/0/all/0/1">Matt Biddulph</a>, <a href="http://arxiv.org/find/cs/1/au:+Mance_I/0/1/0/all/0/1">Irida Mance</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14028">
                                    <div class="article-summary-box-inner">
                                        <span>Respiratory rate (RR) is a clinical metric used to assess overall health and
physical fitness. An individual&#x27;s RR can change from their baseline due to
chronic illness symptoms (e.g., asthma, congestive heart failure), acute
illness (e.g., breathlessness due to infection), and over the course of the day
due to physical exhaustion during heightened exertion. Remote estimation of RR
can offer a cost-effective method to track disease progression and
cardio-respiratory fitness over time. This work investigates a model-driven
approach to estimate RR from short audio segments obtained after physical
exertion in healthy adults. Data was collected from 21 individuals using
microphone-enabled, near-field headphones before, during, and after strenuous
exercise. RR was manually annotated by counting perceived inhalations and
exhalations. A multi-task Long-Short Term Memory (LSTM) network with
convolutional layers was implemented to process mel-filterbank energies,
estimate RR in varying background noise conditions, and predict heavy
breathing, indicated by an RR of more than 25 breaths per minute. The
multi-task model performs both classification and regression tasks and
leverages a mixture of loss functions. It was observed that RR can be estimated
with a concordance correlation coefficient (CCC) of 0.76 and a mean squared
error (MSE) of 0.2, demonstrating that audio can be a viable signal for
approximating RR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Significance of Speaker Embeddings and Temporal Context for Depression Detection. (arXiv:2107.13969v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dumpala_S/0/1/0/all/0/1">Sri Harsha Dumpala</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_S/0/1/0/all/0/1">Sebastian Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Rempel_S/0/1/0/all/0/1">Sheri Rempel</a>, <a href="http://arxiv.org/find/cs/1/au:+Uher_R/0/1/0/all/0/1">Rudolf Uher</a>, <a href="http://arxiv.org/find/cs/1/au:+Oore_S/0/1/0/all/0/1">Sageev Oore</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13969">
                                    <div class="article-summary-box-inner">
                                        <span>Depression detection from speech has attracted a lot of attention in recent
years. However, the significance of speaker-specific information in depression
detection has not yet been explored. In this work, we analyze the significance
of speaker embeddings for the task of depression detection from speech.
Experimental results show that the speaker embeddings provide important cues to
achieve state-of-the-art performance in depression detection. We also show that
combining conventional OpenSMILE and COVAREP features, which carry
complementary information, with speaker embeddings further improves the
depression detection performance. The significance of temporal context in the
training of deep learning models for depression detection is also analyzed in
this paper.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Learning for Fine-Grained Image Classification. (arXiv:2107.13973v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Breiki_F/0/1/0/all/0/1">Farha Al Breiki</a>, <a href="http://arxiv.org/find/cs/1/au:+Ridzuan_M/0/1/0/all/0/1">Muhammad Ridzuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Grandhe_R/0/1/0/all/0/1">Rushali Grandhe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13973">
                                    <div class="article-summary-box-inner">
                                        <span>Fine-grained image classification involves identifying different
subcategories of a class which possess very subtle discriminatory features.
Fine-grained datasets usually provide bounding box annotations along with class
labels to aid the process of classification. However, building large scale
datasets with such annotations is a mammoth task. Moreover, this extensive
annotation is time-consuming and often requires expertise, which is a huge
bottleneck in building large datasets. On the other hand, self-supervised
learning (SSL) exploits the freely available data to generate supervisory
signals which act as labels. The features learnt by performing some pretext
tasks on huge unlabelled data proves to be very helpful for multiple downstream
tasks.

Our idea is to leverage self-supervision such that the model learns useful
representations of fine-grained image classes. We experimented with 3 kinds of
models: Jigsaw solving as pretext task, adversarial learning (SRGAN) and
contrastive learning based (SimCLR) model. The learned features are used for
downstream tasks such as fine-grained image classification. Our code is
available at
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal-Relational Hypergraph Tri-Attention Networks for Stock Trend Prediction. (arXiv:2107.14033v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Cui_C/0/1/0/all/0/1">Chaoran Cui</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Li_X/0/1/0/all/0/1">Xiaojie Li</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Du_J/0/1/0/all/0/1">Juan Du</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zhang_C/0/1/0/all/0/1">Chunyun Zhang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Nie_X/0/1/0/all/0/1">Xiushan Nie</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Yin_Y/0/1/0/all/0/1">Yilong Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14033">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting the future price trends of stocks is a challenging yet intriguing
problem given its critical role to help investors make profitable decisions. In
this paper, we present a collaborative temporal-relational modeling framework
for end-to-end stock trend prediction. The temporal dynamics of stocks is
firstly captured with an attention-based recurrent neural network. Then,
different from existing studies relying on the pairwise correlations between
stocks, we argue that stocks are naturally connected as a collective group, and
introduce the hypergraph structures to jointly characterize the stock
group-wise relationships of industry-belonging and fund-holding. A novel
hypergraph tri-attention network (HGTAN) is proposed to augment the hypergraph
convolutional networks with a hierarchical organization of intra-hyperedge,
inter-hyperedge, and inter-hypergraph attention modules. In this manner, HGTAN
adaptively determines the importance of nodes, hyperedges, and hypergraphs
during the information propagation among stocks, so that the potential
synergies between stock movements can be fully exploited. Extensive experiments
on real-world data demonstrate the effectiveness of our approach. Also, the
results of investment simulation show that our approach can achieve a more
desirable risk-adjusted return. The data and codes of our work have been
released at https://github.com/lixiaojieff/HGTAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Blind Room Parameter Estimation Using Multiple-Multichannel Speech Recordings. (arXiv:2107.13832v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Srivastava_P/0/1/0/all/0/1">Prerak Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Deleforge_A/0/1/0/all/0/1">Antoine Deleforge</a>, <a href="http://arxiv.org/find/cs/1/au:+Vincent_E/0/1/0/all/0/1">Emmanuel Vincent</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13832">
                                    <div class="article-summary-box-inner">
                                        <span>Knowing the geometrical and acoustical parameters of a room may benefit
applications such as audio augmented reality, speech dereverberation or audio
forensics. In this paper, we study the problem of jointly estimating the total
surface area, the volume, as well as the frequency-dependent reverberation time
and mean surface absorption of a room in a blind fashion, based on two-channel
noisy speech recordings from multiple, unknown source-receiver positions. A
novel convolutional neural network architecture leveraging both single- and
inter-channel cues is proposed and trained on a large, realistic simulated
dataset. Results on both simulated and real data show that using multiple
observations in one room significantly reduces estimation errors and variances
on all target quantities, and that using two channels helps the estimation of
surface and volume. The proposed model outperforms a recently proposed blind
volume estimation method on the considered datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis of User Preferences for Robot Motions in Immersive Telepresence. (arXiv:2103.03496v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mimnaugh_K/0/1/0/all/0/1">Katherine J. Mimnaugh</a>, <a href="http://arxiv.org/find/cs/1/au:+Suomalainen_M/0/1/0/all/0/1">Markku Suomalainen</a>, <a href="http://arxiv.org/find/cs/1/au:+Becerra_I/0/1/0/all/0/1">Israel Becerra</a>, <a href="http://arxiv.org/find/cs/1/au:+Lozano_E/0/1/0/all/0/1">Eliezer Lozano</a>, <a href="http://arxiv.org/find/cs/1/au:+Murrieta_Cid_R/0/1/0/all/0/1">Rafael Murrieta-Cid</a>, <a href="http://arxiv.org/find/cs/1/au:+LaValle_S/0/1/0/all/0/1">Steven M. LaValle</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03496">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers how the motions of a telepresence robot moving
autonomously affect a person immersed in the robot through a head-mounted
display. In particular, we explore the preference, comfort, and naturalness of
elements of piecewise linear paths compared to the same elements on a smooth
path. In a user study, thirty-six subjects watched panoramic videos of three
different paths through a simulated museum in virtual reality and responded to
questionnaires regarding each path. Preference for a particular path was
influenced the most by comfort, forward speed, and characteristics of the
turns. Preference was also strongly associated with the users&#x27; perceived
naturalness, which was primarily determined by the ability to see salient
objects, the distance to the walls and objects, as well as the turns.
Participants favored the paths that had a one meter per second forward speed
and rated the path with the least amount of turns as the most comfortable</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Transformer based Dual Discriminator Generative Adversarial Networks for Video Anomaly Detection. (arXiv:2107.13720v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1">Xinyang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dongjin Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuncong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhengzhang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_J/0/1/0/all/0/1">Jingchao Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13720">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting abnormal activities in real-world surveillance videos is an
important yet challenging task as the prior knowledge about video anomalies is
usually limited or unavailable. Despite that many approaches have been
developed to resolve this problem, few of them can capture the normal
spatio-temporal patterns effectively and efficiently. Moreover, existing works
seldom explicitly consider the local consistency at frame level and global
coherence of temporal dynamics in video sequences. To this end, we propose
Convolutional Transformer based Dual Discriminator Generative Adversarial
Networks (CT-D2GAN) to perform unsupervised video anomaly detection.
Specifically, we first present a convolutional transformer to perform future
frame prediction. It contains three key components, i.e., a convolutional
encoder to capture the spatial information of the input video clips, a temporal
self-attention module to encode the temporal dynamics, and a convolutional
decoder to integrate spatio-temporal features and predict the future frame.
Next, a dual discriminator based adversarial training procedure, which jointly
considers an image discriminator that can maintain the local consistency at
frame-level and a video discriminator that can enforce the global coherence of
temporal dynamics, is employed to enhance the future frame prediction. Finally,
the prediction error is used to identify abnormal video frames. Thoroughly
empirical studies on three public video anomaly detection datasets, i.e., UCSD
Ped2, CUHK Avenue, and Shanghai Tech Campus, demonstrate the effectiveness of
the proposed adversarial spatio-temporal modeling framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReconVAT: A Semi-Supervised Automatic Music Transcription Framework for Low-Resource Real-World Data. (arXiv:2107.04954v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheuk_K/0/1/0/all/0/1">Kin Wai Cheuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Herremans_D/0/1/0/all/0/1">Dorien Herremans</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1">Li Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04954">
                                    <div class="article-summary-box-inner">
                                        <span>Most of the current supervised automatic music transcription (AMT) models
lack the ability to generalize. This means that they have trouble transcribing
real-world music recordings from diverse musical genres that are not presented
in the labelled training data. In this paper, we propose a semi-supervised
framework, ReconVAT, which solves this issue by leveraging the huge amount of
available unlabelled music recordings. The proposed ReconVAT uses
reconstruction loss and virtual adversarial training. When combined with
existing U-net models for AMT, ReconVAT achieves competitive results on common
benchmark datasets such as MAPS and MusicNet. For example, in the few-shot
setting for the string part version of MusicNet, ReconVAT achieves F1-scores of
61.0% and 41.6% for the note-wise and note-with-offset-wise metrics
respectively, which translates into an improvement of 22.2% and 62.5% compared
to the supervised baseline model. Our proposed framework also demonstrates the
potential of continual learning on new data, which could be useful in
real-world applications whereby new data is constantly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video-based Point Cloud Compression Artifact Removal. (arXiv:2107.14179v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhtar_A/0/1/0/all/0/1">Anique Akhtar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wen Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Li Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_W/0/1/0/all/0/1">Wei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.14179">
                                    <div class="article-summary-box-inner">
                                        <span>Photo-realistic point cloud capture and transmission are the fundamental
enablers for immersive visual communication. The coding process of dynamic
point clouds, especially video-based point cloud compression (V-PCC) developed
by the MPEG standardization group, is now delivering state-of-the-art
performance in compression efficiency. V-PCC is based on the projection of the
point cloud patches to 2D planes and encoding the sequence as 2D texture and
geometry patch sequences. However, the resulting quantization errors from
coding can introduce compression artifacts, which can be very unpleasant for
the quality of experience (QoE). In this work, we developed a novel
out-of-the-loop point cloud geometry artifact removal solution that can
significantly improve reconstruction quality without additional bandwidth cost.
Our novel framework consists of a point cloud sampling scheme, an artifact
removal network, and an aggregation scheme. The point cloud sampling scheme
employs a cube-based neighborhood patch extraction to divide the point cloud
into patches. The geometry artifact removal network then processes these
patches to obtain artifact-removed patches. The artifact-removed patches are
then merged together using an aggregation scheme to obtain the final
artifact-removed point cloud. We employ 3D deep convolutional feature learning
for geometry artifact removal that jointly recovers both the quantization
direction and the quantization noise level by exploiting projection and
quantization prior. The simulation results demonstrate that the proposed method
is highly effective and can considerably improve the quality of the
reconstructed point cloud.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sign and Search: Sign Search Functionality for Sign Language Lexica. (arXiv:2107.13637v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fragkiadakis_M/0/1/0/all/0/1">Manolis Fragkiadakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Putten_P/0/1/0/all/0/1">Peter van der Putten</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13637">
                                    <div class="article-summary-box-inner">
                                        <span>Sign language lexica are a useful resource for researchers and people
learning sign languages. Current implementations allow a user to search a sign
either by its gloss or by selecting its primary features such as handshape and
location. This study focuses on exploring a reverse search functionality where
a user can sign a query sign in front of a webcam and retrieve a set of
matching signs. By extracting different body joints combinations (upper body,
dominant hand&#x27;s arm and wrist) using the pose estimation framework OpenPose, we
compare four techniques (PCA, UMAP, DTW and Euclidean distance) as distance
metrics between 20 query signs, each performed by eight participants on a 1200
sign lexicon. The results show that UMAP and DTW can predict a matching sign
with an 80\% and 71\% accuracy respectively at the top-20 retrieved signs using
the movement of the dominant hand arm. Using DTW and adding more sign instances
from other participants in the lexicon, the accuracy can be raised to 90\% at
the top-10 ranking. Our results suggest that our methodology can be used with
no training in any sign language lexicon regardless of its size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-29">2021-07-29</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3x as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results (e.g., a moderate size of 55.8M model solely trained
on 224x224 ImageNet-1K can obtain Top-1 accuracy 84.1%), while being more
scalable on high-resolution images. The source code and models are released at
https://github.com/NVIDIA/transformer-ls .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exceeding the Limits of Visual-Linguistic Multi-Task Learning. (arXiv:2107.13054v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lundgaard_K/0/1/0/all/0/1">Keld T. Lundgaard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13054">
                                    <div class="article-summary-box-inner">
                                        <span>By leveraging large amounts of product data collected across hundreds of live
e-commerce websites, we construct 1000 unique classification tasks that share
similarly-structured input data, comprised of both text and images. These
classification tasks focus on learning the product hierarchy of different
e-commerce websites, causing many of them to be correlated. Adopting a
multi-modal transformer model, we solve these tasks in unison using multi-task
learning (MTL). Extensive experiments are presented over an initial 100-task
dataset to reveal best practices for &quot;large-scale MTL&quot; (i.e., MTL with more
than 100 tasks). From these experiments, a final, unified methodology is
derived, which is composed of both best practices and new proposals such as
DyPa, a simple heuristic for automatically allocating task-specific parameters
to tasks that could benefit from extra capacity. Using our large-scale MTL
methodology, we successfully train a single model across all 1000 tasks in our
dataset while using minimal task specific parameters, thereby showing that it
is possible to extend several orders of magnitude beyond current efforts in
MTL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Plug-and-Blend: A Framework for Controllable Story Generation with Blended Control Codes. (arXiv:2104.04039v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhiyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1">Mark Riedl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04039">
                                    <div class="article-summary-box-inner">
                                        <span>Large pre-trained neural language models (LM) have very powerful text
generation capabilities. However, in practice, they are hard to control for
creative purposes. We describe a Plug-and-Play controllable language generation
framework, Plug-and-Blend, that allows a human user to input multiple control
codes (topics). In the context of automated story generation, this allows a
human user loose or fine-grained control of the topics and transitions between
them that will appear in the generated story, and can even allow for
overlapping, blended topics. Automated evaluations show our framework, working
with different generative LMs, controls the generation towards given
continuous-weighted control codes while keeping the generated sentences fluent,
demonstrating strong blending capability. A human participant evaluation shows
that the generated stories are observably transitioning between two topics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local and non-local dependency learning and emergence of rule-like representations in speech data by Deep Convolutional Generative Adversarial Networks. (arXiv:2009.12711v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Begus_G/0/1/0/all/0/1">Ga&#x161;per Begu&#x161;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12711">
                                    <div class="article-summary-box-inner">
                                        <span>This paper argues that training GANs on local and non-local dependencies in
speech data offers insights into how deep neural networks discretize continuous
data and how symbolic-like rule-based morphophonological processes emerge in a
deep convolutional architecture. Acquisition of speech has recently been
modeled as a dependency between latent space and data generated by GANs in
Begu\v{s} (2020b; arXiv:2006.03965), who models learning of a simple local
allophonic distribution. We extend this approach to test learning of local and
non-local phonological processes that include approximations of morphological
processes. We further parallel outputs of the model to results of a behavioral
experiment where human subjects are trained on the data used for training the
GAN network. Four main conclusions emerge: (i) the networks provide useful
information for computational models of speech acquisition even if trained on a
comparatively small dataset of an artificial grammar learning experiment; (ii)
local processes are easier to learn than non-local processes, which matches
both behavioral data in human subjects and typology in the world&#x27;s languages.
This paper also proposes (iii) how we can actively observe the network&#x27;s
progress in learning and explore the effect of training steps on learning
representations by keeping latent space constant across different training
steps. Finally, this paper shows that (iv) the network learns to encode the
presence of a prefix with a single latent variable; by interpolating this
variable, we can actively observe the operation of a non-local phonological
process. The proposed technique for retrieving learning representations has
general implications for our understanding of how GANs discretize continuous
speech data and suggests that rule-like generalizations in the training data
are represented as an interaction between variables in the network&#x27;s latent
space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classifying Textual Data with Pre-trained Vision Models through Transfer Learning and Data Transformations. (arXiv:2106.12479v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Benarab_C/0/1/0/all/0/1">Charaf Eddine Benarab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12479">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge is acquired by humans through experience, and no boundary is set
between the kinds of knowledge or skill levels we can achieve on different
tasks at the same time. When it comes to Neural Networks, that is not the case,
the major breakthroughs in the field are extremely task and domain specific.
Vision and language are dealt with in separate manners, using separate methods
and different datasets. In this work, we propose to use knowledge acquired by
benchmark Vision Models which are trained on ImageNet to help a much smaller
architecture learn to classify text. After transforming the textual data
contained in the IMDB dataset to gray scale images. An analysis of different
domains and the Transfer Learning method is carried out. Despite the challenge
posed by the very different datasets, promising results are achieved. The main
contribution of this work is a novel approach which links large pretrained
models on both language and vision to achieve state-of-the-art results in
different sub-fields from the original task. Without needing high compute
capacity resources. Specifically, Sentiment Analysis is achieved after
transferring knowledge between vision and language models. BERT embeddings are
transformed into grayscale images, these images are then used as training
examples for pre-trained vision models such as VGG16 and ResNet

Index Terms: BERT, Convolutional Neural Networks, Domain Adaptation, image
classification, Natural Language Processing, t-SNE, text classification,
Transfer Learning</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">POS tagging, lemmatization and dependency parsing of West Frisian. (arXiv:2107.07974v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heeringa_W/0/1/0/all/0/1">Wilbert Heeringa</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouma_G/0/1/0/all/0/1">Gosse Bouma</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofman_M/0/1/0/all/0/1">Martha Hofman</a>, <a href="http://arxiv.org/find/cs/1/au:+Drenth_E/0/1/0/all/0/1">Eduard Drenth</a>, <a href="http://arxiv.org/find/cs/1/au:+Wijffels_J/0/1/0/all/0/1">Jan Wijffels</a>, <a href="http://arxiv.org/find/cs/1/au:+Velde_H/0/1/0/all/0/1">Hans Van de Velde</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07974">
                                    <div class="article-summary-box-inner">
                                        <span>We present a lemmatizer/POS-tagger/dependency parser for West Frisian using a
corpus of 44,714 words in 3,126 sentences that were annotated according to the
guidelines of Universal Dependency version 2. POS tags were assigned to words
by using a Dutch POS tagger that was applied to a literal word-by-word
translation, or to sentences of a Dutch parallel text. Best results were
obtained when using literal translations that were created by using the Frisian
translation program Oersetter. Morphologic and syntactic annotations were
generated on the basis of a literal Dutch translation as well. The performance
of the lemmatizer/tagger/annotator when it was trained using default parameters
was compared to the performance that was obtained when using the parameter
values that were used for training the LassySmall UD 2.5 corpus. A significant
improvement was found for &#x60;lemma&#x27;. The Frisian lemmatizer/PoS tagger/dependency
parser is released as a web app and as a web service.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Listen, Read, and Identify: Multimodal Singing Language Identification of Music. (arXiv:2103.01893v4 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_K/0/1/0/all/0/1">Keunwoo Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuxuan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01893">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a multimodal singing language classification model that uses both
audio content and textual metadata. LRID-Net, the proposed model, takes an
audio signal and a language probability vector estimated from the metadata and
outputs the probabilities of the target languages. Optionally, LRID-Net is
facilitated with modality dropouts to handle a missing modality. In the
experiment, we trained several LRID-Nets with varying modality dropout
configuration and tested them with various combinations of input modalities.
The experiment results demonstrate that using multimodal input improves
performance. The results also suggest that adopting modality dropout does not
degrade the performance of the model when there are full modality inputs while
enabling the model to handle missing modality cases to some extent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Arabic aspect based sentiment analysis using BERT. (arXiv:2107.13290v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdelgwad_M/0/1/0/all/0/1">Mohammed M.Abdelgwad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13290">
                                    <div class="article-summary-box-inner">
                                        <span>Aspect-based sentiment analysis(ABSA) is a textual analysis methodology that
defines the polarity of opinions on certain aspects related to specific
targets. The majority of research on ABSA is in English, with a small amount of
work available in Arabic. Most previous Arabic research has relied on deep
learning models that depend primarily on context-independent word embeddings
(e.g.word2vec), where each word has a fixed representation independent of its
context. This article explores the modeling capabilities of contextual
embeddings from pre-trained language models, such as BERT, and making use of
sentence pair input on Arabic ABSA tasks. In particular, we are building a
simple but effective BERT-based neural baseline to handle this task. Our BERT
architecture with a simple linear classification layer surpassed the
state-of-the-art works, according to the experimental results on the
benchmarked Arabic hotel reviews dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Emotion-Aware Agents For Negotiation Dialogues. (arXiv:2107.13165v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chawla_K/0/1/0/all/0/1">Kushal Chawla</a>, <a href="http://arxiv.org/find/cs/1/au:+Clever_R/0/1/0/all/0/1">Rene Clever</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramirez_J/0/1/0/all/0/1">Jaysa Ramirez</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucas_G/0/1/0/all/0/1">Gale Lucas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gratch_J/0/1/0/all/0/1">Jonathan Gratch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13165">
                                    <div class="article-summary-box-inner">
                                        <span>Negotiation is a complex social interaction that encapsulates emotional
encounters in human decision-making. Virtual agents that can negotiate with
humans are useful in pedagogy and conversational AI. To advance the development
of such agents, we explore the prediction of two important subjective goals in
a negotiation - outcome satisfaction and partner perception. Specifically, we
analyze the extent to which emotion attributes extracted from the negotiation
help in the prediction, above and beyond the individual difference variables.
We focus on a recent dataset in chat-based negotiations, grounded in a
realistic camping scenario. We study three degrees of emotion dimensions -
emoticons, lexical, and contextual by leveraging affective lexicons and a
state-of-the-art deep learning architecture. Our insights will be helpful in
designing adaptive negotiation agents that interact through realistic
communication interfaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings. (arXiv:2106.03143v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Likhomanenko_T/0/1/0/all/0/1">Tatiana Likhomanenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiantong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Collobert_R/0/1/0/all/0/1">Ronan Collobert</a>, <a href="http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1">Gabriel Synnaeve</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogozhnikov_A/0/1/0/all/0/1">Alex Rogozhnikov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03143">
                                    <div class="article-summary-box-inner">
                                        <span>Without positional information, attention-based transformer neural networks
are permutation-invariant. Absolute or relative positional embeddings are the
most popular ways to feed transformer models positional information. Absolute
positional embeddings are simple to implement, but suffer from generalization
issues when evaluating on sequences of different length than those seen at
training time. Relative positions are more robust to length change, but are
more complex to implement and yield inferior model throughput. In this paper,
we propose an augmentation-based approach (CAPE) for absolute positional
embeddings, which keeps the advantages of both absolute (simplicity and speed)
and relative position embeddings (better generalization). In addition, our
empirical evaluation on state-of-the-art models in machine translation, image
and speech recognition demonstrates that CAPE leads to better generalization
performance as well as increased stability with respect to training
hyper-parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Robustness Against Natural Language Word Substitutions. (arXiv:2107.13541v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xinshuai Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1">Anh Tuan Luu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1">Rongrong Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13541">
                                    <div class="article-summary-box-inner">
                                        <span>Robustness against word substitutions has a well-defined and widely
acceptable form, i.e., using semantically similar words as substitutions, and
thus it is considered as a fundamental stepping-stone towards broader
robustness in natural language processing. Previous defense methods capture
word substitutions in vector space by using either $l_2$-ball or
hyper-rectangle, which results in perturbation sets that are not inclusive
enough or unnecessarily large, and thus impedes mimicry of worst cases for
robust training. In this paper, we introduce a novel \textit{Adversarial Sparse
Convex Combination} (ASCC) method. We model the word substitution attack space
as a convex hull and leverages a regularization term to enforce perturbation
towards an actual substitution, thus aligning our modeling better with the
discrete textual space. Based on the ASCC method, we further propose
ASCC-defense, which leverages ASCC to generate worst-case perturbations and
incorporates adversarial training towards robustness. Experiments show that
ASCC-defense outperforms the current state-of-the-arts in terms of robustness
on two prevailing NLP tasks, \emph{i.e.}, sentiment analysis and natural
language inference, concerning several attacks across multiple model
architectures. Besides, we also envision a new class of defense towards
robustness in NLP, where our robustly trained word vectors can be plugged into
a normally trained model and enforce its robustness without applying any other
defense techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text-guided Legal Knowledge Graph Reasoning. (arXiv:2104.02284v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Luoqiu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_Z/0/1/0/all/0/1">Zhen Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hongbin Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shumin Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tou_H/0/1/0/all/0/1">Huaixiao Tou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02284">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have witnessed the prosperity of legal artificial intelligence
with the development of technologies. In this paper, we propose a novel legal
application of legal provision prediction (LPP), which aims to predict the
related legal provisions of affairs. We formulate this task as a challenging
knowledge graph completion problem, which requires not only text understanding
but also graph reasoning. To this end, we propose a novel text-guided graph
reasoning approach. We collect amounts of real-world legal provision data from
the Guangdong government service website and construct a legal dataset called
LegalLPP. Extensive experimental results on the dataset show that our approach
achieves better performance compared with baselines. The code and dataset are
available in \url{https://github.com/zjunlp/LegalPP} for reproducibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual-wav2vec2: an Application of Continual Learning for Self-Supervised Automatic Speech Recognition. (arXiv:2107.13530v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kessler_S/0/1/0/all/0/1">Samuel Kessler</a>, <a href="http://arxiv.org/find/eess/1/au:+Thomas_B/0/1/0/all/0/1">Bethan Thomas</a>, <a href="http://arxiv.org/find/eess/1/au:+Karout_S/0/1/0/all/0/1">Salah Karout</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13530">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for continual learning of speech representations for
multiple languages using self-supervised learning (SSL) and applying these for
automatic speech recognition. There is an abundance of unannotated speech, so
creating self-supervised representations from raw audio and finetuning on a
small annotated datasets is a promising direction to build speech recognition
systems. Wav2vec models perform SSL on raw audio in a pretraining phase and
then finetune on a small fraction of annotated data. SSL models have produced
state of the art results for ASR. However, these models are very expensive to
pretrain with self-supervision. We tackle the problem of learning new language
representations continually from audio without forgetting a previous language
representation. We use ideas from continual learning to transfer knowledge from
a previous task to speed up pretraining a new language task. Our
continual-wav2vec2 model can decrease pretraining times by 32% when learning a
new language task, and learn this new audio-language representation without
forgetting previous language representation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Rule-Execution Tracking Machine For Transformer-Based Text Generation. (arXiv:2107.13077v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yufei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Can Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Huang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1">Chongyang Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_S/0/1/0/all/0/1">Stephen Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dras_M/0/1/0/all/0/1">Mark Dras</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1">Mark Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Daxin Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13077">
                                    <div class="article-summary-box-inner">
                                        <span>Sequence-to-Sequence (S2S) neural text generation models, especially the
pre-trained ones (e.g., BART and T5), have exhibited compelling performance on
various natural language generation tasks. However, the black-box nature of
these models limits their application in tasks where specific rules (e.g.,
controllable constraints, prior knowledge) need to be executed. Previous works
either design specific model structure (e.g., Copy Mechanism corresponding to
the rule &quot;the generated output should include certain words in the source
input&quot;) or implement specialized inference algorithm (e.g., Constrained Beam
Search) to execute particular rules through the text generation. These methods
require careful design case-by-case and are difficult to support multiple rules
concurrently. In this paper, we propose a novel module named Neural
Rule-Execution Tracking Machine that can be equipped into various
transformer-based generators to leverage multiple rules simultaneously to guide
the neural generation model for superior generation performance in a unified
and scalable way. Extensive experimental results on several benchmarks verify
the effectiveness of our proposed model in both controllable and general text
generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Growing knowledge culturally across generations to solve novel, complex tasks. (arXiv:2107.13377v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tessler_M/0/1/0/all/0/1">Michael Henry Tessler</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsividis_P/0/1/0/all/0/1">Pedro A. Tsividis</a>, <a href="http://arxiv.org/find/cs/1/au:+Madeano_J/0/1/0/all/0/1">Jason Madeano</a>, <a href="http://arxiv.org/find/cs/1/au:+Harper_B/0/1/0/all/0/1">Brin Harper</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13377">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge built culturally across generations allows humans to learn far more
than an individual could glean from their own experience in a lifetime.
Cultural knowledge in turn rests on language: language is the richest record of
what previous generations believed, valued, and practiced. The power and
mechanisms of language as a means of cultural learning, however, are not well
understood. We take a first step towards reverse-engineering cultural learning
through language. We developed a suite of complex high-stakes tasks in the form
of minimalist-style video games, which we deployed in an iterated learning
paradigm. Game participants were limited to only two attempts (two lives) to
beat each game and were allowed to write a message to a future participant who
read the message before playing. Knowledge accumulated gradually across
generations, allowing later generations to advance further in the games and
perform more efficient actions. Multigenerational learning followed a
strikingly similar trajectory to individuals learning alone with an unlimited
number of lives. These results suggest that language provides a sufficient
medium to express and accumulate the knowledge people acquire in these diverse
tasks: the dynamics of the environment, valuable goals, dangerous risks, and
strategies for success. The video game paradigm we pioneer here is thus a rich
test bed for theories of cultural transmission and learning from language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pretrained Transformers for Text Ranking: BERT and Beyond. (arXiv:2010.06467v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jimmy Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nogueira_R/0/1/0/all/0/1">Rodrigo Nogueira</a>, <a href="http://arxiv.org/find/cs/1/au:+Yates_A/0/1/0/all/0/1">Andrew Yates</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06467">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of text ranking is to generate an ordered list of texts retrieved
from a corpus in response to a query. Although the most common formulation of
text ranking is search, instances of the task can also be found in many natural
language processing applications. This survey provides an overview of text
ranking with neural network architectures known as transformers, of which BERT
is the best-known example. The combination of transformers and self-supervised
pretraining has been responsible for a paradigm shift in natural language
processing (NLP), information retrieval (IR), and beyond. In this survey, we
provide a synthesis of existing work as a single point of entry for
practitioners who wish to gain a better understanding of how to apply
transformers to text ranking problems and researchers who wish to pursue work
in this area. We cover a wide range of modern techniques, grouped into two
high-level categories: transformer models that perform reranking in multi-stage
architectures and dense retrieval techniques that perform ranking directly.
There are two themes that pervade our survey: techniques for handling long
documents, beyond typical sentence-by-sentence processing in NLP, and
techniques for addressing the tradeoff between effectiveness (i.e., result
quality) and efficiency (e.g., query latency, model and index size). Although
transformer architectures and pretraining techniques are recent innovations,
many aspects of how they are applied to text ranking are relatively well
understood and represent mature techniques. However, there remain many open
research questions, and thus in addition to laying out the foundations of
pretrained transformers for text ranking, this survey also attempts to
prognosticate where the field is heading.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transforming Multi-Conditioned Generation from Meaning Representation. (arXiv:2101.04257v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Joosung Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04257">
                                    <div class="article-summary-box-inner">
                                        <span>In task-oriented conversation systems, natural language generation systems
that generate sentences with specific information related to conversation flow
are useful. Our study focuses on language generation by considering various
information representing the meaning of utterances as multiple conditions of
generation. NLG from meaning representations, the conditions for sentence
meaning, generally goes through two steps: sentence planning and surface
realization. However, we propose a simple one-stage framework to generate
utterances directly from MR (Meaning Representation). Our model is based on
GPT2 and generates utterances with flat conditions on slot and value pairs,
which does not need to determine the structure of the sentence. We evaluate
several systems in the E2E dataset with 6 automatic metrics. Our system is a
simple method, but it demonstrates comparable performance to previous systems
in automated metrics. In addition, using only 10\% of the data set without any
other techniques, our model achieves comparable performance, and shows the
possibility of performing zero-shot generation and expanding to other datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Goal-Oriented Script Construction. (arXiv:2107.13189v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_Q/0/1/0/all/0/1">Qing Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Callison_Burch_C/0/1/0/all/0/1">Chris Callison-Burch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13189">
                                    <div class="article-summary-box-inner">
                                        <span>The knowledge of scripts, common chains of events in stereotypical scenarios,
is a valuable asset for task-oriented natural language understanding systems.
We propose the Goal-Oriented Script Construction task, where a model produces a
sequence of steps to accomplish a given goal. We pilot our task on the first
multilingual script learning dataset supporting 18 languages collected from
wikiHow, a website containing half a million how-to articles. For baselines, we
consider both a generation-based approach using a language model and a
retrieval-based approach by first retrieving the relevant steps from a large
candidate pool and then ordering them. We show that our task is practical,
feasible but challenging for state-of-the-art Transformer models, and that our
methods can be readily deployed for various other datasets and domains with
decent zero-shot performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Scale Feature and Metric Learning for Relation Extraction. (arXiv:2107.13425v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_T/0/1/0/all/0/1">Tieyun Qian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13425">
                                    <div class="article-summary-box-inner">
                                        <span>Existing methods in relation extraction have leveraged the lexical features
in the word sequence and the syntactic features in the parse tree. Though
effective, the lexical features extracted from the successive word sequence may
introduce some noise that has little or no meaningful content. Meanwhile, the
syntactic features are usually encoded via graph convolutional networks which
have restricted receptive field. To address the above limitations, we propose a
multi-scale feature and metric learning framework for relation extraction.
Specifically, we first develop a multi-scale convolutional neural network to
aggregate the non-successive mainstays in the lexical sequence. We also design
a multi-scale graph convolutional network which can increase the receptive
field towards specific syntactic roles. Moreover, we present a multi-scale
metric learning paradigm to exploit both the feature-level relation between
lexical and syntactic features and the sample-level relation between instances
with the same or different classes. We conduct extensive experiments on three
real world datasets for various types of relation extraction tasks. The results
demonstrate that our model significantly outperforms the state-of-the-art
approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Red Dragon AI at TextGraphs 2021 Shared Task: Multi-Hop Inference Explanation Regeneration by Matching Expert Ratings. (arXiv:2107.13031v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalyan_V/0/1/0/all/0/1">Vivek Kalyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Witteveen_S/0/1/0/all/0/1">Sam Witteveen</a>, <a href="http://arxiv.org/find/cs/1/au:+Andrews_M/0/1/0/all/0/1">Martin Andrews</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13031">
                                    <div class="article-summary-box-inner">
                                        <span>Creating explanations for answers to science questions is a challenging task
that requires multi-hop inference over a large set of fact sentences. This
year, to refocus the Textgraphs Shared Task on the problem of gathering
relevant statements (rather than solely finding a single &#x27;correct path&#x27;), the
WorldTree dataset was augmented with expert ratings of &#x27;relevance&#x27; of
statements to each overall explanation. Our system, which achieved second place
on the Shared Task leaderboard, combines initial statement retrieval; language
models trained to predict the relevance scores; and ensembling of a number of
the resulting rankings. Our code implementation is made available at
https://github.com/mdda/worldtree_corpus/tree/textgraphs_2021</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CiwGAN and fiwGAN: Encoding information in acoustic data to model lexical learning with Generative Adversarial Networks. (arXiv:2006.02951v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Begus_G/0/1/0/all/0/1">Ga&#x161;per Begu&#x161;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.02951">
                                    <div class="article-summary-box-inner">
                                        <span>How can deep neural networks encode information that corresponds to words in
human speech into raw acoustic data? This paper proposes two neural network
architectures for modeling unsupervised lexical learning from raw acoustic
inputs, ciwGAN (Categorical InfoWaveGAN) and fiwGAN (Featural InfoWaveGAN),
that combine a Deep Convolutional GAN architecture for audio data (WaveGAN;
arXiv:1705.07904) with an information theoretic extension of GAN -- InfoGAN
(arXiv:1606.03657), and propose a new latent space structure that can model
featural learning simultaneously with a higher level classification and allows
for a very low-dimension vector representation of lexical items. Lexical
learning is modeled as emergent from an architecture that forces a deep neural
network to output data such that unique information is retrievable from its
acoustic outputs. The networks trained on lexical items from TIMIT learn to
encode unique information corresponding to lexical items in the form of
categorical variables in their latent space. By manipulating these variables,
the network outputs specific lexical items. The network occasionally outputs
innovative lexical items that violate training data, but are linguistically
interpretable and highly informative for cognitive modeling and neural network
interpretability. Innovative outputs suggest that phonetic and phonological
representations learned by the network can be productively recombined and
directly paralleled to productivity in human speech: a fiwGAN network trained
on &#x60;suit&#x27; and &#x60;dark&#x27; outputs innovative &#x60;start&#x27;, even though it never saw
&#x60;start&#x27; or even a [st] sequence in the training data. We also argue that
setting latent featural codes to values well beyond training range results in
almost categorical generation of prototypical lexical items and reveals
underlying values of each latent code.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Perla: A Conversational Agent for Depression Screening in Digital Ecosystems. Design, Implementation and Validation. (arXiv:2008.12875v2 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arrabales_R/0/1/0/all/0/1">Ra&#xfa;l Arrabales</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.12875">
                                    <div class="article-summary-box-inner">
                                        <span>Most depression assessment tools are based on self-report questionnaires,
such as the Patient Health Questionnaire (PHQ-9). These psychometric
instruments can be easily adapted to an online setting by means of electronic
forms. However, this approach lacks the interacting and engaging features of
modern digital environments. With the aim of making depression screening more
available, attractive and effective, we developed Perla, a conversational agent
able to perform an interview based on the PHQ-9. We also conducted a validation
study in which we compared the results obtained by the traditional self-report
questionnaire with Perla&#x27;s automated interview. Analyzing the results from this
study we draw two significant conclusions: firstly, Perla is much preferred by
Internet users, achieving more than 2.5 times more reach than a traditional
form-based questionnaire; secondly, her psychometric properties (Cronbach&#x27;s
alpha of 0.81, sensitivity of 96% and specificity of 90%) are excellent and
comparable to the traditional well-established depression screening
questionnaires.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Plant Cover Estimation with Convolutional Neural Networks. (arXiv:2106.11154v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korschens_M/0/1/0/all/0/1">Matthias K&#xf6;rschens</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodesheim_P/0/1/0/all/0/1">Paul Bodesheim</a>, <a href="http://arxiv.org/find/cs/1/au:+Romermann_C/0/1/0/all/0/1">Christine R&#xf6;mermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bucher_S/0/1/0/all/0/1">Solveig Franziska Bucher</a>, <a href="http://arxiv.org/find/cs/1/au:+Migliavacca_M/0/1/0/all/0/1">Mirco Migliavacca</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulrich_J/0/1/0/all/0/1">Josephine Ulrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Denzler_J/0/1/0/all/0/1">Joachim Denzler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11154">
                                    <div class="article-summary-box-inner">
                                        <span>Monitoring the responses of plants to environmental changes is essential for
plant biodiversity research. This, however, is currently still being done
manually by botanists in the field. This work is very laborious, and the data
obtained is, though following a standardized method to estimate plant coverage,
usually subjective and has a coarse temporal resolution. To remedy these
caveats, we investigate approaches using convolutional neural networks (CNNs)
to automatically extract the relevant data from images, focusing on plant
community composition and species coverages of 9 herbaceous plant species. To
this end, we investigate several standard CNN architectures and different
pretraining methods. We find that we outperform our previous approach at higher
image resolutions using a custom CNN with a mean absolute error of 5.16%. In
addition to these investigations, we also conduct an error analysis based on
the temporal aspect of the plant cover images. This analysis gives insight into
where problems for automatic approaches lie, like occlusion and likely
misclassifications caused by temporal changes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Robust Method for Image Stitching. (arXiv:2004.03860v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pellikka_M/0/1/0/all/0/1">Matti Pellikka</a>, <a href="http://arxiv.org/find/cs/1/au:+Lahtinen_V/0/1/0/all/0/1">Valtteri Lahtinen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.03860">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel method for large-scale image stitching that is robust
against repetitive patterns and featureless regions in the imagery. In such
cases, state-of-the-art image stitching methods easily produce image alignment
artifacts, since they may produce false pairwise image registrations that are
in conflict within the global connectivity graph. Our method augments the
current methods by collecting all the plausible pairwise image registration
candidates, among which globally consistent candidates are chosen. This enables
the stitching process to determine the correct pairwise registrations by
utilizing all the available information from the whole imagery, such as
unambiguous registrations outside the repeating pattern and featureless
regions. We formalize the method as a weighted multigraph whose nodes represent
the individual image transformations from the composite image, and whose sets
of multiple edges between two nodes represent all the plausible transformations
between the pixel coordinates of the two images. The edge weights represent the
plausibility of the transformations. The image transformations and the edge
weights are solved from a non-linear minimization problem with linear
constraints, for which a projection method is used. As an example, we apply the
method in a large-scale scanning application where the transformations are
primarily translations with only slight rotation and scaling component. Despite
these simplifications, the state-of-the-art methods do not produce adequate
results in such applications, since the image overlap is small, which can be
featureless or repetitive, and misalignment artifacts and their concealment are
unacceptable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Confluence: A Robust Non-IoU Alternative to Non-Maxima Suppression in Object Detection. (arXiv:2012.00257v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shepley_A/0/1/0/all/0/1">Andrew Shepley</a>, <a href="http://arxiv.org/find/cs/1/au:+Falzon_G/0/1/0/all/0/1">Greg Falzon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwan_P/0/1/0/all/0/1">Paul Kwan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00257">
                                    <div class="article-summary-box-inner">
                                        <span>Confluence is a novel non-Intersection over Union (IoU) alternative to
Non-Maxima Suppression (NMS) in bounding box post-processing in object
detection. It overcomes the inherent limitations of IoU-based NMS variants to
provide a more stable, consistent predictor of bounding box clustering by using
a normalized Manhattan Distance inspired proximity metric to represent bounding
box clustering. Unlike Greedy and Soft NMS, it does not rely solely on
classification confidence scores to select optimal bounding boxes, instead
selecting the box which is closest to every other box within a given cluster
and removing highly confluent neighboring boxes. Confluence is experimentally
validated on the MS COCO and CrowdHuman benchmarks, improving Average Precision
by up to 2.3-3.8% and Average Recall by up to 5.3-7.2% when compared against
de-facto standard and state of the art NMS variants. Quantitative results are
supported by extensive qualitative analysis and threshold sensitivity analysis
experiments support the conclusion that Confluence is more robust than NMS
variants. Confluence represents a paradigm shift in bounding box processing,
with potential to replace IoU in bounding box regression processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inferring bias and uncertainty in camera calibration. (arXiv:2107.13484v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hagemann_A/0/1/0/all/0/1">Annika Hagemann</a>, <a href="http://arxiv.org/find/cs/1/au:+Knorr_M/0/1/0/all/0/1">Moritz Knorr</a>, <a href="http://arxiv.org/find/cs/1/au:+Janssen_H/0/1/0/all/0/1">Holger Janssen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiller_C/0/1/0/all/0/1">Christoph Stiller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13484">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate camera calibration is a precondition for many computer vision
applications. Calibration errors, such as wrong model assumptions or imprecise
parameter estimation, can deteriorate a system&#x27;s overall performance, making
the reliable detection and quantification of these errors critical. In this
work, we introduce an evaluation scheme to capture the fundamental error
sources in camera calibration: systematic errors (biases) and uncertainty
(variance). The proposed bias detection method uncovers smallest systematic
errors and thereby reveals imperfections of the calibration setup and provides
the basis for camera model selection. A novel resampling-based uncertainty
estimator enables uncertainty estimation under non-ideal conditions and thereby
extends the classical covariance estimator. Furthermore, we derive a simple
uncertainty metric that is independent of the camera model. In combination, the
proposed methods can be used to assess the accuracy of individual calibrations,
but also to benchmark new calibration algorithms, camera models, or calibration
setups. We evaluate the proposed methods with simulations and real cameras.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Unsupervised Domain Adaptation with Conditional and Label Shift: Infer, Align and Iterate. (arXiv:2107.13469v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhenhua Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Site Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_F/0/1/0/all/0/1">Fangxu Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jane You</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakhri_G/0/1/0/all/0/1">Georges El Fakhri</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1">Jonghye Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13469">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose an adversarial unsupervised domain adaptation (UDA)
approach with the inherent conditional and label shifts, in which we aim to
align the distributions w.r.t. both $p(x|y)$ and $p(y)$. Since the label is
inaccessible in the target domain, the conventional adversarial UDA assumes
$p(y)$ is invariant across domains, and relies on aligning $p(x)$ as an
alternative to the $p(x|y)$ alignment. To address this, we provide a thorough
theoretical and empirical analysis of the conventional adversarial UDA methods
under both conditional and label shifts, and propose a novel and practical
alternative optimization scheme for adversarial UDA. Specifically, we infer the
marginal $p(y)$ and align $p(x|y)$ iteratively in the training, and precisely
align the posterior $p(y|x)$ in testing. Our experimental results demonstrate
its effectiveness on both classification and segmentation UDA, and partial UDA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stable deep neural network architectures for mitochondria segmentation on electron microscopy volumes. (arXiv:2104.03577v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Franco_Barranco_D/0/1/0/all/0/1">Daniel Franco-Barranco</a>, <a href="http://arxiv.org/find/eess/1/au:+Munoz_Barrutia_A/0/1/0/all/0/1">Arrate Mu&#xf1;oz-Barrutia</a>, <a href="http://arxiv.org/find/eess/1/au:+Arganda_Carreras_I/0/1/0/all/0/1">Ignacio Arganda-Carreras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03577">
                                    <div class="article-summary-box-inner">
                                        <span>Electron microscopy (EM) allows the identification of intracellular
organelles such as mitochondria, providing insights for clinical and scientific
studies. In recent years, a number of novel deep learning architectures have
been published reporting superior performance, or even human-level accuracy,
compared to previous approaches on public mitochondria segmentation datasets.
Unfortunately, many of these publications do not make neither the code nor the
full training details public to support the results obtained, leading to
reproducibility issues and dubious model comparisons. For that reason, and
following a recent code of best practices for reporting experimental results,
we present an extensive study of the state-of-the-art deep learning
architectures for the segmentation of mitochondria on EM volumes, and evaluate
the impact in performance of different variations of 2D and 3D U-Net-like
models for this task. To better understand the contribution of each component,
a common set of pre- and post-processing operations has been implemented and
tested with each approach. Moreover, an exhaustive sweep of hyperparameters
values for all architectures have been performed and each configuration has
been run multiple times to report the mean and standard deviation values of the
evaluation metrics. Using this methodology, we found very stable architectures
and hyperparameter configurations that consistently obtain state-of-the-art
results in the well-known EPFL Hippocampus mitochondria segmentation dataset.
Furthermore, we have benchmarked our proposed models on two other available
datasets, Lucchi++ and Kasthuri++, where they outperform all previous works.
The code derived from this research and its documentation are publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Board Volcanic Eruption Detection through CNNs and Satellite Multispectral Imagery. (arXiv:2106.15281v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosso_M/0/1/0/all/0/1">Maria Pia Del Rosso</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastianelli_A/0/1/0/all/0/1">Alessandro Sebastianelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Spiller_D/0/1/0/all/0/1">Dario Spiller</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_P/0/1/0/all/0/1">Pierre Philippe Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullo_S/0/1/0/all/0/1">Silvia Liberata Ullo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15281">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the growth of Machine Learning (ML) algorithms has raised
the number of studies including their applicability in a variety of different
scenarios. Among all, one of the hardest ones is the aerospace, due to its
peculiar physical requirements. In this context, a feasibility study and a
first prototype for an Artificial Intelligence (AI) model to be deployed on
board satellites are presented in this work. As a case study, the detection of
volcanic eruptions has been investigated as a method to swiftly produce alerts
and allow immediate interventions. Two Convolutional Neural Networks (CNNs)
have been proposed and designed, showing how to efficiently implement them for
identifying the eruptions and at the same time adapting their complexity in
order to fit on board requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel CropdocNet for Automated Potato Late Blight Disease Detection from the Unmanned Aerial Vehicle-based Hyperspectral Imagery. (arXiv:2107.13277v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yue Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Liangxiu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleerekoper_A/0/1/0/all/0/1">Anthony Kleerekoper</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Sheng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1">Tongle Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13277">
                                    <div class="article-summary-box-inner">
                                        <span>Late blight disease is one of the most destructive diseases in potato crop,
leading to serious yield losses globally. Accurate diagnosis of the disease at
early stage is critical for precision disease control and management. Current
farm practices in crop disease diagnosis are based on manual visual inspection,
which is costly, time consuming, subject to individual bias. Recent advances in
imaging sensors (e.g. RGB, multiple spectral and hyperspectral cameras), remote
sensing and machine learning offer the opportunity to address this challenge.
Particularly, hyperspectral imagery (HSI) combining with machine learning/deep
learning approaches is preferable for accurately identifying specific plant
diseases because the HSI consists of a wide range of high-quality reflectance
information beyond human vision, capable of capturing both spectral-spatial
information. The proposed method considers the potential disease specific
reflectance radiation variance caused by the canopy structural diversity,
introduces the multiple capsule layers to model the hierarchical structure of
the spectral-spatial disease attributes with the encapsulated features to
represent the various classes and the rotation invariance of the disease
attributes in the feature space. We have evaluated the proposed method with the
real UAV-based HSI data under the controlled field conditions. The
effectiveness of the hierarchical features has been quantitatively assessed and
compared with the existing representative machine learning/deep learning
methods. The experiment results show that the proposed model significantly
improves the accuracy performance when considering hierarchical-structure of
spectral-spatial features, comparing to the existing methods only using
spectral, or spatial or spectral-spatial features without consider
hierarchical-structure of spectral-spatial features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Use of Reconstruction Error for Novelty Localization. (arXiv:2107.13379v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feeney_P/0/1/0/all/0/1">Patrick Feeney</a>, <a href="http://arxiv.org/find/cs/1/au:+Hughes_M/0/1/0/all/0/1">Michael C. Hughes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13379">
                                    <div class="article-summary-box-inner">
                                        <span>The pixelwise reconstruction error of deep autoencoders is often utilized for
image novelty detection and localization under the assumption that pixels with
high error indicate which parts of the input image are unfamiliar and therefore
likely to be novel. This assumed correlation between pixels with high
reconstruction error and novel regions of input images has not been verified
and may limit the accuracy of these methods. In this paper we utilize saliency
maps to evaluate whether this correlation exists. Saliency maps reveal directly
how much a change in each input pixel would affect reconstruction loss, while
each pixel&#x27;s reconstruction error may be attributed to many input pixels when
layers are fully connected. We compare saliency maps to reconstruction error
maps via qualitative visualizations as well as quantitative correspondence
between the top K elements of the maps for both novel and normal images. Our
results indicate that reconstruction error maps do not closely correlate with
the importance of pixels in the input images, making them insufficient for
novelty localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WaveCNet: Wavelet Integrated CNNs to Suppress Aliasing Effect for Noise-Robust Image Classification. (arXiv:2107.13335v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiufu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Linlin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Sheng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1">Zhihui Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13335">
                                    <div class="article-summary-box-inner">
                                        <span>Though widely used in image classification, convolutional neural networks
(CNNs) are prone to noise interruptions, i.e. the CNN output can be drastically
changed by small image noise. To improve the noise robustness, we try to
integrate CNNs with wavelet by replacing the common down-sampling (max-pooling,
strided-convolution, and average pooling) with discrete wavelet transform
(DWT). We firstly propose general DWT and inverse DWT (IDWT) layers applicable
to various orthogonal and biorthogonal discrete wavelets like Haar, Daubechies,
and Cohen, etc., and then design wavelet integrated CNNs (WaveCNets) by
integrating DWT into the commonly used CNNs (VGG, ResNets, and DenseNet).
During the down-sampling, WaveCNets apply DWT to decompose the feature maps
into the low-frequency and high-frequency components. Containing the main
information including the basic object structures, the low-frequency component
is transmitted into the following layers to generate robust high-level
features. The high-frequency components are dropped to remove most of the data
noises. The experimental results show that %wavelet accelerates the CNN
training, and WaveCNets achieve higher accuracy on ImageNet than various
vanilla CNNs. We have also tested the performance of WaveCNets on the noisy
version of ImageNet, ImageNet-C and six adversarial attacks, the results
suggest that the proposed DWT/IDWT layers could provide better noise-robustness
and adversarial robustness. When applying WaveCNets as backbones, the
performance of object detectors (i.e., faster R-CNN and RetinaNet) on COCO
detection dataset are consistently improved. We believe that suppression of
aliasing effect, i.e. separation of low frequency and high frequency
information, is the main advantages of our approach. The code of our DWT/IDWT
layer and different WaveCNets are available at
https://github.com/CVI-SZU/WaveCNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subjective evaluation of traditional and learning-based image coding methods. (arXiv:2107.13122v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zhigao Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Lu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yin Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13122">
                                    <div class="article-summary-box-inner">
                                        <span>We conduct a subjective experiment to compare the performance of traditional
image coding methods and learning-based image coding methods. HEVC and VVC, the
state-of-the-art traditional coding methods, are used as the representative
traditional methods. The learning-based methods used contain not only CNN-based
methods, but also a GAN-based method, all of which are advanced or typical.
Single Stimuli (SS), which is also called Absolute Category Rating (ACR), is
adopted as the methodology of the experiment to obtain perceptual quality of
images. Additionally, we utilize some typical and frequently used objective
quality metrics to evaluate the coding methods in the experiment as comparison.
The experiment shows that CNN-based and GAN-based methods can perform better
than traditional methods in low bit-rates. In high bit-rates, however, it is
hard to verify whether CNN-based methods are superior to traditional methods.
Because the GAN method does not provide models with high target bit-rates, we
cannot exactly tell the performance of the GAN method in high bit-rates.
Furthermore, some popular objective quality metrics have not shown the ability
well to measure quality of images generated by learning-based coding methods,
especially the GAN-based one.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shape Controllable Virtual Try-on for Underwear Models. (arXiv:2107.13156v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xin Gao</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenjiang Liu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zunlei Feng</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chengji Shen</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Ou_K/0/1/0/all/0/1">Kairi Ou</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Haihong Tang</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1">Mingli Song</a> (2) ((1) Alibaba Group, (2) Zhejiang University)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13156">
                                    <div class="article-summary-box-inner">
                                        <span>Image virtual try-on task has abundant applications and has become a hot
research topic recently. Existing 2D image-based virtual try-on methods aim to
transfer a target clothing image onto a reference person, which has two main
disadvantages: cannot control the size and length precisely; unable to
accurately estimate the user&#x27;s figure in the case of users wearing thick
clothes, resulting in inaccurate dressing effect. In this paper, we put forward
an akin task that aims to dress clothing for underwear models. %, which is also
an urgent need in e-commerce scenarios. To solve the above drawbacks, we
propose a Shape Controllable Virtual Try-On Network (SC-VTON), where a graph
attention network integrates the information of model and clothing to generate
the warped clothing image. In addition, the control points are incorporated
into SC-VTON for the desired clothing shape. Furthermore, by adding a Splitting
Network and a Synthesis Network, we can use clothing/model pair data to help
optimize the deformation module and generalize the task to the typical virtual
try-on task. Extensive experiments show that the proposed method can achieve
accurate shape control. Meanwhile, compared with other methods, our method can
generate high-resolution results with detailed textures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial Uncertainty-Aware Semi-Supervised Crowd Counting. (arXiv:2107.13271v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1">Yanda Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongrun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yitian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaoyun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xuesheng Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaowei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yalin Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13271">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised approaches for crowd counting attract attention, as the fully
supervised paradigm is expensive and laborious due to its request for a large
number of images of dense crowd scenarios and their annotations. This paper
proposes a spatial uncertainty-aware semi-supervised approach via regularized
surrogate task (binary segmentation) for crowd counting problems. Different
from existing semi-supervised learning-based crowd counting methods, to exploit
the unlabeled data, our proposed spatial uncertainty-aware teacher-student
framework focuses on high confident regions&#x27; information while addressing the
noisy supervision from the unlabeled data in an end-to-end manner.
Specifically, we estimate the spatial uncertainty maps from the teacher model&#x27;s
surrogate task to guide the feature learning of the main task (density
regression) and the surrogate task of the student model at the same time.
Besides, we introduce a simple yet effective differential transformation layer
to enforce the inherent spatial consistency regularization between the main
task and the surrogate task in the student model, which helps the surrogate
task to yield more reliable predictions and generates high-quality uncertainty
maps. Thus, our model can also address the task-level perturbation problems
that occur spatial inconsistency between the primary and surrogate tasks in the
student model. Experimental results on four challenging crowd counting datasets
demonstrate that our method achieves superior performance to the
state-of-the-art semi-supervised methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Event Camera Calibration. (arXiv:2107.06749v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kneip_L/0/1/0/all/0/1">Laurent Kneip</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06749">
                                    <div class="article-summary-box-inner">
                                        <span>Camera calibration is an important prerequisite towards the solution of 3D
computer vision problems. Traditional methods rely on static images of a
calibration pattern. This raises interesting challenges towards the practical
usage of event cameras, which notably require image change to produce
sufficient measurements. The current standard for event camera calibration
therefore consists of using flashing patterns. They have the advantage of
simultaneously triggering events in all reprojected pattern feature locations,
but it is difficult to construct or use such patterns in the field. We present
the first dynamic event camera calibration algorithm. It calibrates directly
from events captured during relative motion between camera and calibration
pattern. The method is propelled by a novel feature extraction mechanism for
calibration patterns, and leverages existing calibration tools before
optimizing all parameters through a multi-segment continuous-time formulation.
As demonstrated through our results on real data, the obtained calibration
method is highly convenient and reliably calibrates from data sequences
spanning less than 10 seconds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised Learning. (arXiv:2107.08369v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1">Sayak Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1">Siddha Ganju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08369">
                                    <div class="article-summary-box-inner">
                                        <span>Floods wreak havoc throughout the world, causing billions of dollars in
damages, and uprooting communities, ecosystems and economies. Accurate and
robust flood detection including delineating open water flood areas and
identifying flood levels can aid in disaster response and mitigation. However,
estimating flood levels remotely is of essence as physical access to flooded
areas is limited and the ability to deploy instruments in potential flood zones
can be dangerous. Aligning flood extent mapping with local topography can
provide a plan-of-action that the disaster response team can consider. Thus,
remote flood level estimation via satellites like Sentinel-1 can prove to be
remedial. The Emerging Techniques in Computational Intelligence (ETCI)
competition on Flood Detection tasked participants with predicting flooded
pixels after training with synthetic aperture radar (SAR) images in a
supervised setting. We use a cyclical approach involving two stages (1)
training an ensemble model of multiple UNet architectures with available high
and low confidence labeled data and, (2) generating pseudo labels or low
confidence labels on the unlabeled test dataset, and then, combining the
generated labels with the previously available high confidence labeled dataset.
This assimilated dataset is used for the next round of training ensemble
models. This cyclical process is repeated until the performance improvement
plateaus. Additionally, we post process our results with Conditional Random
Fields. Our approach sets a high score on the public leaderboard for the ETCI
competition with 0.7654 IoU. Our method, which we release with all the code
including trained models, can also be used as an open science benchmark for the
Sentinel-1 released dataset on GitHub. To the best of our knowledge we believe
this the first works to try out semi-supervised learning to improve flood
segmentation models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3x as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results (e.g., a moderate size of 55.8M model solely trained
on 224x224 ImageNet-1K can obtain Top-1 accuracy 84.1%), while being more
scalable on high-resolution images. The source code and models are released at
https://github.com/NVIDIA/transformer-ls .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings. (arXiv:2106.03143v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Likhomanenko_T/0/1/0/all/0/1">Tatiana Likhomanenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiantong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Collobert_R/0/1/0/all/0/1">Ronan Collobert</a>, <a href="http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1">Gabriel Synnaeve</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogozhnikov_A/0/1/0/all/0/1">Alex Rogozhnikov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03143">
                                    <div class="article-summary-box-inner">
                                        <span>Without positional information, attention-based transformer neural networks
are permutation-invariant. Absolute or relative positional embeddings are the
most popular ways to feed transformer models positional information. Absolute
positional embeddings are simple to implement, but suffer from generalization
issues when evaluating on sequences of different length than those seen at
training time. Relative positions are more robust to length change, but are
more complex to implement and yield inferior model throughput. In this paper,
we propose an augmentation-based approach (CAPE) for absolute positional
embeddings, which keeps the advantages of both absolute (simplicity and speed)
and relative position embeddings (better generalization). In addition, our
empirical evaluation on state-of-the-art models in machine translation, image
and speech recognition demonstrates that CAPE leads to better generalization
performance as well as increased stability with respect to training
hyper-parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CarveNet: Carving Point-Block for Complex 3D Shape Completion. (arXiv:2107.13452v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhijie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Juefei_Xu_F/0/1/0/all/0/1">Felix Juefei-Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Di Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_W/0/1/0/all/0/1">Wei Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13452">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud completion is very challenging because it heavily relies on
the accurate understanding of the complex 3D shapes (e.g., high-curvature,
concave/convex, and hollowed-out 3D shapes) and the unknown &amp; diverse patterns
of the partially available point clouds. In this paper, we propose a novel
solution,i.e., Point-block Carving (PC), for completing the complex 3D point
cloud completion. Given the partial point cloud as the guidance, we carve a3D
block that contains the uniformly distributed 3D points, yielding the entire
point cloud. To achieve PC, we propose a new network architecture, i.e.,
CarveNet. This network conducts the exclusive convolution on each point of the
block, where the convolutional kernels are trained on the 3D shape data.
CarveNet determines which point should be carved, for effectively recovering
the details of the complete shapes. Furthermore, we propose a sensor-aware
method for data augmentation,i.e., SensorAug, for training CarveNet on richer
patterns of partial point clouds, thus enhancing the completion power of the
network. The extensive evaluations on the ShapeNet and KITTI datasets
demonstrate the generality of our approach on the partial point clouds with
diverse patterns. On these datasets, CarveNet successfully outperforms the
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepSMILE: Self-supervised heterogeneity-aware multiple instance learning for DNA damage response defect classification directly from H&amp;E whole-slide images. (arXiv:2107.09405v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Schirris_Y/0/1/0/all/0/1">Yoni Schirris</a>, <a href="http://arxiv.org/find/eess/1/au:+Gavves_E/0/1/0/all/0/1">Efstratios Gavves</a>, <a href="http://arxiv.org/find/eess/1/au:+Nederlof_I/0/1/0/all/0/1">Iris Nederlof</a>, <a href="http://arxiv.org/find/eess/1/au:+Horlings_H/0/1/0/all/0/1">Hugo Mark Horlings</a>, <a href="http://arxiv.org/find/eess/1/au:+Teuwen_J/0/1/0/all/0/1">Jonas Teuwen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09405">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a Deep learning-based weak label learning method for analysing
whole slide images (WSIs) of Hematoxylin and Eosin (H&amp;E) stained tumorcells not
requiring pixel-level or tile-level annotations using Self-supervised
pre-training and heterogeneity-aware deep Multiple Instance LEarning
(DeepSMILE). We apply DeepSMILE to the task of Homologous recombination
deficiency (HRD) and microsatellite instability (MSI) prediction. We utilize
contrastive self-supervised learning to pre-train a feature extractor on
histopathology tiles of cancer tissue. Additionally, we use variability-aware
deep multiple instance learning to learn the tile feature aggregation function
while modeling tumor heterogeneity. Compared to state-of-the-art genomic label
classification methods, DeepSMILE improves classification performance for HRD
from $70.43\pm4.10\%$ to $83.79\pm1.25\%$ AUC and MSI from $78.56\pm6.24\%$ to
$90.32\pm3.58\%$ AUC in a multi-center breast and colorectal cancer dataset,
respectively. These improvements suggest we can improve genomic label
classification performance without collecting larger datasets. In the future,
this may reduce the need for expensive genome sequencing techniques, provide
personalized therapy recommendations based on widely available WSIs of cancer
tissue, and improve patient care with quicker treatment decisions - also in
medical centers without access to genome sequencing resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Know Thyself: Transferable Visuomotor Control Through Robot-Awareness. (arXiv:2107.09047v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1">Edward S. Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rybkin_O/0/1/0/all/0/1">Oleh Rybkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1">Dinesh Jayaraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09047">
                                    <div class="article-summary-box-inner">
                                        <span>Training visuomotor robot controllers from scratch on a new robot typically
requires generating large amounts of robot-specific data. Could we leverage
data previously collected on another robot to reduce or even completely remove
this need for robot-specific data? We propose a &quot;robot-aware&quot; solution paradigm
that exploits readily available robot &quot;self-knowledge&quot; such as proprioception,
kinematics, and camera calibration to achieve this. First, we learn modular
dynamics models that pair a transferable, robot-agnostic world dynamics module
with a robot-specific, analytical robot dynamics module. Next, we set up visual
planning costs that draw a distinction between the robot self and the world.
Our experiments on tabletop manipulation tasks in simulation and on real robots
demonstrate that these plug-in improvements dramatically boost the
transferability of visuomotor controllers, even permitting zero-shot transfer
onto new robots for the very first time. Project website:
https://hueds.github.io/rac/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Boosting for Domain Adaptation: Towards Robust Predictions in Scene Segmentation. (arXiv:2103.15685v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhedong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15685">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation is to transfer the shared knowledge learned from the source
domain to a new environment, i.e., target domain. One common practice is to
train the model on both labeled source-domain data and unlabeled target-domain
data. Yet the learned models are usually biased due to the strong supervision
of the source domain. Most researchers adopt the early-stopping strategy to
prevent over-fitting, but when to stop training remains a challenging problem
since the lack of the target-domain validation set. In this paper, we propose
one efficient bootstrapping method, called Adaboost Student, explicitly
learning complementary models during training and liberating users from
empirical early stopping. Adaboost Student combines the deep model learning
with the conventional training strategy, i.e., adaptive boosting, and enables
interactions between learned models and the data sampler. We adopt one adaptive
data sampler to progressively facilitate learning on hard samples and aggregate
&quot;weak&quot; models to prevent over-fitting. Extensive experiments show that (1)
Without the need to worry about the stopping time, AdaBoost Student provides
one robust solution by efficient complementary model learning during training.
(2) AdaBoost Student is orthogonal to most domain adaptation methods, which can
be combined with existing approaches to further improve the state-of-the-art
performance. We have achieved competitive results on three widely-used scene
segmentation domain adaptation benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal SAR-Optical Data Fusion for Cloud Removal via a Deep Hierarchical Model. (arXiv:2106.12226v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sebastianelli_A/0/1/0/all/0/1">Alessandro Sebastianelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Nowakowski_A/0/1/0/all/0/1">Artur Nowakowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Puglisi_E/0/1/0/all/0/1">Erika Puglisi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosso_M/0/1/0/all/0/1">Maria Pia Del Rosso</a>, <a href="http://arxiv.org/find/cs/1/au:+Mifdal_J/0/1/0/all/0/1">Jamila Mifdal</a>, <a href="http://arxiv.org/find/cs/1/au:+Pirri_F/0/1/0/all/0/1">Fiora Pirri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_P/0/1/0/all/0/1">Pierre Philippe Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullo_S/0/1/0/all/0/1">Silvia Liberata Ullo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12226">
                                    <div class="article-summary-box-inner">
                                        <span>The abundance of clouds, located both spatially and temporally, often makes
remote sensing (RS) applications with optical images difficult or even
impossible to perform. Traditional cloud removing techniques have been studied
for years, and recently, Machine Learning (ML)-based approaches have also been
considered. In this manuscript, a novel method for the restoration of
clouds-corrupted optical images is presented, able to generate the whole
optical scene of interest, not only the cloudy pixels, and based on a Joint
Data Fusion paradigm, where three deep neural networks are hierarchically
combined. Spatio-temporal features are separately extracted by a conditional
Generative Adversarial Network (cGAN) and by a Convolutional Long Short-Term
Memory (ConvLSTM), from Synthetic Aperture Radar (SAR) data and optical
time-series of data respectively, and then combined with a U-shaped network.
The use of time-series of data has been rarely explored in the state of the art
for this peculiar objective, and moreover existing models do not combine both
spatio-temporal domains and SAR-optical imagery. Quantitative and qualitative
results have shown a good ability of the proposed method in producing
cloud-free images, by also preserving the details and outperforming the cGAN
and the ConvLSTM when individually used. Both the code and the dataset have
been implemented from scratch and made available to interested researchers for
further analysis and investigation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking ResNets: Improved Stacking Strategies With High Order Schemes. (arXiv:2103.15244v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhengbo Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zitang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Weilian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zizhang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamata_S/0/1/0/all/0/1">Sei-ichiro Kamata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15244">
                                    <div class="article-summary-box-inner">
                                        <span>Various deep neural network architectures (DNNs) maintain massive vital
records in computer vision. While drawing attention worldwide, the design of
the overall structure lacks general guidance. Based on the relationship between
DNN design and numerical differential equations, we performed a fair comparison
of the residual design with higher-order perspectives. We show that the widely
used DNN design strategy, constantly stacking a small design (usually 2-3
layers), could be easily improved, supported by solid theoretical knowledge and
with no extra parameters needed. We reorganise the residual design in
higher-order ways, which is inspired by the observation that many effective
networks can be interpreted as different numerical discretisations of
differential equations. The design of ResNet follows a relatively simple
scheme, which is Euler forward; however, the situation becomes complicated
rapidly while stacking. We suppose that stacked ResNet is somehow equalled to a
higher-order scheme; then, the current method of forwarding propagation might
be relatively weak compared with a typical high-order method such as
Runge-Kutta. We propose HO-ResNet to verify the hypothesis of widely used CV
benchmarks with sufficient experiments. Stable and noticeable increases in
performance are observed, and convergence and robustness are also improved. Our
stacking strategy improved ResNet-30 by 2.15 per cent and ResNet-58 by 2.35 per
cent on CIFAR-10, with the same settings and parameters. The proposed strategy
is fundamental and theoretical and can therefore be applied to any network as a
general guideline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistically Significant Stopping of Neural Network Training. (arXiv:2103.01205v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Terry_J/0/1/0/all/0/1">J. K. Terry</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayakumar_M/0/1/0/all/0/1">Mario Jayakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Alwis_K/0/1/0/all/0/1">Kusal De Alwis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01205">
                                    <div class="article-summary-box-inner">
                                        <span>The general approach taken when training deep learning classifiers is to save
the parameters after every few iterations, train until either a human observer
or a simple metric-based heuristic decides the network isn&#x27;t learning anymore,
and then backtrack and pick the saved parameters with the best validation
accuracy. Simple methods are used to determine if a neural network isn&#x27;t
learning anymore because, as long as it&#x27;s well after the optimal values are
found, the condition doesn&#x27;t impact the final accuracy of the model. However
from a runtime perspective, this is of great significance to the many cases
where numerous neural networks are trained simultaneously (e.g. hyper-parameter
tuning). Motivated by this, we introduce a statistical significance test to
determine if a neural network has stopped learning. This stopping criterion
appears to represent a happy medium compared to other popular stopping
criterions, achieving comparable accuracy to the criterions that achieve the
highest final accuracies in 77% or fewer epochs, while the criterions which
stop sooner do so with an appreciable loss to final accuracy. Additionally, we
use this as the basis of a new learning rate scheduler, removing the need to
manually choose learning rate schedules and acting as a quasi-line search,
achieving superior or comparable empirical performance to existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoLA: Weakly-Supervised Temporal Action Localization with Snippet Contrastive Learning. (arXiv:2103.16392v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Can Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_M/0/1/0/all/0/1">Meng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1">Dongming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jie Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16392">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-supervised temporal action localization (WS-TAL) aims to localize
actions in untrimmed videos with only video-level labels. Most existing models
follow the &quot;localization by classification&quot; procedure: locate temporal regions
contributing most to the video-level classification. Generally, they process
each snippet (or frame) individually and thus overlook the fruitful temporal
context relation. Here arises the single snippet cheating issue: &quot;hard&quot;
snippets are too vague to be classified. In this paper, we argue that learning
by comparing helps identify these hard snippets and we propose to utilize
snippet Contrastive learning to Localize Actions, CoLA for short. Specifically,
we propose a Snippet Contrast (SniCo) Loss to refine the hard snippet
representation in feature space, which guides the network to perceive precise
temporal boundaries and avoid the temporal interval interruption. Besides,
since it is infeasible to access frame-level annotations, we introduce a Hard
Snippet Mining algorithm to locate the potential hard snippets. Substantial
analyses verify that this mining strategy efficaciously captures the hard
snippets and SniCo Loss leads to more informative feature representation.
Extensive experiments show that CoLA achieves state-of-the-art results on
THUMOS&#x27;14 and ActivityNet v1.2 datasets. CoLA code is publicly available at
https://github.com/zhang-can/CoLA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Playing to distraction: towards a robust training of CNN classifiers through visual explanation techniques. (arXiv:2012.14173v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Morales_D/0/1/0/all/0/1">David Morales</a>, <a href="http://arxiv.org/find/cs/1/au:+Talavera_E/0/1/0/all/0/1">Estefania Talavera</a>, <a href="http://arxiv.org/find/cs/1/au:+Remeseiro_B/0/1/0/all/0/1">Beatriz Remeseiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14173">
                                    <div class="article-summary-box-inner">
                                        <span>The field of deep learning is evolving in different directions, with still
the need for more efficient training strategies. In this work, we present a
novel and robust training scheme that integrates visual explanation techniques
in the learning process. Unlike the attention mechanisms that focus on the
relevant parts of images, we aim to improve the robustness of the model by
making it pay attention to other regions as well. Broadly speaking, the idea is
to distract the classifier in the learning process to force it to focus not
only on relevant regions but also on those that, a priori, are not so
informative for the discrimination of the class. We tested the proposed
approach by embedding it into the learning process of a convolutional neural
network for the analysis and classification of two well-known datasets, namely
Stanford cars and FGVC-Aircraft. Furthermore, we evaluated our model on a
real-case scenario for the classification of egocentric images, allowing us to
obtain relevant information about peoples&#x27; lifestyles. In particular, we work
on the challenging EgoFoodPlaces dataset, achieving state-of-the-art results
with a lower level of complexity. The obtained results indicate the suitability
of our proposed training scheme for image classification, improving the
robustness of the final model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Adversarial Patch Analysis and Certified Defense against Crowd Counting. (arXiv:2104.10868v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qiming Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiaoqing Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Binghui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Ang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10868">
                                    <div class="article-summary-box-inner">
                                        <span>Crowd counting has drawn much attention due to its importance in
safety-critical surveillance systems. Especially, deep neural network (DNN)
methods have significantly reduced estimation errors for crowd counting
missions. Recent studies have demonstrated that DNNs are vulnerable to
adversarial attacks, i.e., normal images with human-imperceptible perturbations
could mislead DNNs to make false predictions. In this work, we propose a robust
attack strategy called Adversarial Patch Attack with Momentum (APAM) to
systematically evaluate the robustness of crowd counting models, where the
attacker&#x27;s goal is to create an adversarial perturbation that severely degrades
their performances, thus leading to public safety accidents (e.g., stampede
accidents). Especially, the proposed attack leverages the extreme-density
background information of input images to generate robust adversarial patches
via a series of transformations (e.g., interpolation, rotation, etc.). We
observe that by perturbing less than 6\% of image pixels, our attacks severely
degrade the performance of crowd counting systems, both digitally and
physically. To better enhance the adversarial robustness of crowd counting
models, we propose the first regression model-based Randomized Ablation (RA),
which is more sufficient than Adversarial Training (ADT) (Mean Absolute Error
of RA is 5 lower than ADT on clean samples and 30 lower than ADT on adversarial
examples). Extensive experiments on five crowd counting models demonstrate the
effectiveness and generality of the proposed method. The supplementary
materials and certificate retrained models are available at
\url{https://www.dropbox.com/s/hc4fdx133vht0qb/ACM_MM2021_Supp.pdf?dl&#x3D;0}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HDR Environment Map Estimation for Real-Time Augmented Reality. (arXiv:2011.10687v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Somanath_G/0/1/0/all/0/1">Gowri Somanath</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurz_D/0/1/0/all/0/1">Daniel Kurz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10687">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method to estimate an HDR environment map from a narrow
field-of-view LDR camera image in real-time. This enables perceptually
appealing reflections and shading on virtual objects of any material finish,
from mirror to diffuse, rendered into a real physical environment using
augmented reality. Our method is based on our efficient convolutional neural
network architecture, EnvMapNet, trained end-to-end with two novel losses,
ProjectionLoss for the generated image, and ClusterLoss for adversarial
training. Through qualitative and quantitative comparison to state-of-the-art
methods, we demonstrate that our algorithm reduces the directional error of
estimated light sources by more than 50%, and achieves 3.7 times lower Frechet
Inception Distance (FID). We further showcase a mobile application that is able
to run our neural network model in under 9 ms on an iPhone XS, and render in
real-time, visually coherent virtual objects in previously unseen real-world
environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Efficient Performance Estimators of Neural Architectures. (arXiv:2008.03064v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ning_X/0/1/0/all/0/1">Xuefei Ning</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1">Changcheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenshuo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zixuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1">Shuang Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Huazhong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03064">
                                    <div class="article-summary-box-inner">
                                        <span>Conducting efficient performance estimations of neural architectures is a
major challenge in neural architecture search (NAS). To reduce the architecture
training costs in NAS, one-shot estimators (OSEs) amortize the architecture
training costs by sharing the parameters of one supernet between all
architectures. Recently, zero-shot estimators (ZSEs) that involve no training
are proposed to further reduce the architecture evaluation cost. Despite the
high efficiency of these estimators, the quality of such estimations has not
been thoroughly studied. In this paper, we conduct an extensive and organized
assessment of OSEs and ZSEs on three NAS benchmarks: NAS-Bench-101/201/301.
Specifically, we employ a set of NAS-oriented criteria to study the behavior of
OSEs and ZSEs and reveal that they have certain biases and variances. After
analyzing how and why the OSE estimations are unsatisfying, we explore how to
mitigate the correlation gap of OSEs from several perspectives. For ZSEs, we
find that current ZSEs are not satisfying enough in these benchmark search
spaces, and analyze their biases. Through our analysis, we give out suggestions
for future application and development of efficient architecture performance
estimators. Furthermore, the analysis framework proposed in our work could be
utilized in future research to give a more comprehensive understanding of newly
designed architecture performance estimators. All codes and analysis scripts
are available at https://github.com/walkerning/aw_nas.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Unifying Intrinsic Calibration for Spinning and Solid-State LiDARs. (arXiv:2012.03321v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiunn-Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_C/0/1/0/all/0/1">Chenxi Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Achar_M/0/1/0/all/0/1">Madhav Achar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghaffari_M/0/1/0/all/0/1">Maani Ghaffari</a>, <a href="http://arxiv.org/find/cs/1/au:+Grizzle_J/0/1/0/all/0/1">Jessy W. Grizzle</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03321">
                                    <div class="article-summary-box-inner">
                                        <span>Sensor calibration, which can be intrinsic or extrinsic, is an essential step
to achieve the measurement accuracy required for modern perception and
navigation systems deployed on autonomous robots. To date, intrinsic
calibration models for spinning LiDARs have been based on hypothesized based on
their physical mechanisms, resulting in anywhere from three to ten parameters
to be estimated from data, while no phenomenological models have yet been
proposed for solid-state LiDARs. Instead of going down that road, we propose to
abstract away from the physics of a LiDAR type (spinning vs solid-state, for
example), and focus on the spatial geometry of the point cloud generated by the
sensor. By modeling the calibration parameters as an element of a special
matrix Lie Group, we achieve a unifying view of calibration for different types
of LiDARs. We further prove mathematically that the proposed model is
well-constrained (has a unique answer) given four appropriately orientated
targets. The proof provides a guideline for target positioning in the form of a
tetrahedron. Moreover, an existing Semidefinite programming global solver for
SE(3) can be modified to compute efficiently the optimal calibration
parameters. For solid state LiDARs, we illustrate how the method works in
simulation. For spinning LiDARs, we show with experimental data that the
proposed matrix Lie Group model performs equally well as physics-based models
in terms of reducing the P2P distance, while being more robust to noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TEDS-Net: Enforcing Diffeomorphisms in Spatial Transformers to Guarantee Topology Preservation in Segmentations. (arXiv:2107.13542v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wyburd_M/0/1/0/all/0/1">Madeleine K. Wyburd</a>, <a href="http://arxiv.org/find/eess/1/au:+Dinsdale_N/0/1/0/all/0/1">Nicola K. Dinsdale</a>, <a href="http://arxiv.org/find/eess/1/au:+Namburete_A/0/1/0/all/0/1">Ana I.L. Namburete</a>, <a href="http://arxiv.org/find/eess/1/au:+Jenkinson_M/0/1/0/all/0/1">Mark Jenkinson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13542">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate topology is key when performing meaningful anatomical segmentations,
however, it is often overlooked in traditional deep learning methods. In this
work we propose TEDS-Net: a novel segmentation method that guarantees accurate
topology. Our method is built upon a continuous diffeomorphic framework, which
enforces topology preservation. However, in practice, diffeomorphic fields are
represented using a finite number of parameters and sampled using methods such
as linear interpolation, violating the theoretical guarantees. We therefore
introduce additional modifications to more strictly enforce it. Our network
learns how to warp a binary prior, with the desired topological
characteristics, to complete the segmentation task. We tested our method on
myocardium segmentation from an open-source 2D heart dataset. TEDS-Net
preserved topology in 100% of the cases, compared to 90% from the U-Net,
without sacrificing on Hausdorff Distance or Dice performance. Code will be
made available at: www.github.com/mwyburd/TEDS-Net</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When and how do CNNs generalize to out-of-distribution category-viewpoint combinations?. (arXiv:2007.08032v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madan_S/0/1/0/all/0/1">Spandan Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Henry_T/0/1/0/all/0/1">Timothy Henry</a>, <a href="http://arxiv.org/find/cs/1/au:+Dozier_J/0/1/0/all/0/1">Jamell Dozier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_H/0/1/0/all/0/1">Helen Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhandari_N/0/1/0/all/0/1">Nishchal Bhandari</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasaki_T/0/1/0/all/0/1">Tomotake Sasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1">Fr&#xe9;do Durand</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1">Hanspeter Pfister</a>, <a href="http://arxiv.org/find/cs/1/au:+Boix_X/0/1/0/all/0/1">Xavier Boix</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08032">
                                    <div class="article-summary-box-inner">
                                        <span>Object recognition and viewpoint estimation lie at the heart of visual
understanding. Recent works suggest that convolutional neural networks (CNNs)
fail to generalize to out-of-distribution (OOD) category-viewpoint
combinations, ie. combinations not seen during training. In this paper, we
investigate when and how such OOD generalization may be possible by evaluating
CNNs trained to classify both object category and 3D viewpoint on OOD
combinations, and identifying the neural mechanisms that facilitate such OOD
generalization. We show that increasing the number of in-distribution
combinations (ie. data diversity) substantially improves generalization to OOD
combinations, even with the same amount of training data. We compare learning
category and viewpoint in separate and shared network architectures, and
observe starkly different trends on in-distribution and OOD combinations, ie.
while shared networks are helpful in-distribution, separate networks
significantly outperform shared ones at OOD combinations. Finally, we
demonstrate that such OOD generalization is facilitated by the neural mechanism
of specialization, ie. the emergence of two types of neurons -- neurons
selective to category and invariant to viewpoint, and vice versa.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recursively Conditional Gaussian for Ordinal Unsupervised Domain Adaptation. (arXiv:2107.13467v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Site Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yubin Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_P/0/1/0/all/0/1">Pengyi Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jane You</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13467">
                                    <div class="article-summary-box-inner">
                                        <span>There has been a growing interest in unsupervised domain adaptation (UDA) to
alleviate the data scalability issue, while the existing works usually focus on
classifying independently discrete labels. However, in many tasks (e.g.,
medical diagnosis), the labels are discrete and successively distributed. The
UDA for ordinal classification requires inducing non-trivial ordinal
distribution prior to the latent space. Target for this, the partially ordered
set (poset) is defined for constraining the latent vector. Instead of the
typically i.i.d. Gaussian latent prior, in this work, a recursively conditional
Gaussian (RCG) set is proposed for ordered constraint modeling, which admits a
tractable joint distribution prior. Furthermore, we are able to control the
density of content vectors that violate the poset constraint by a simple
&quot;three-sigma rule&quot;. We explicitly disentangle the cross-domain images into a
shared ordinal prior induced ordinal content space and two separate
source/target ordinal-unrelated spaces, and the self-training is worked on the
shared space exclusively for ordinal-aware domain alignment. Extensive
experiments on UDA medical diagnoses and facial age estimation demonstrate its
effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantically Controllable Scene Generation with Guidance of Explicit Knowledge. (arXiv:2106.04066v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1">Wenhao Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Eun_K/0/1/0/all/0/1">Kim Ji Eun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Ding Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04066">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Generative Models (DGMs) are known for their superior capability in
generating realistic data. Extending purely data-driven approaches, recent
specialized DGMs may satisfy additional controllable requirements such as
embedding a traffic sign in a driving scene, by manipulating patterns
\textit{implicitly} in the neuron or feature level. In this paper, we introduce
a novel method to incorporate domain knowledge \textit{explicitly} in the
generation process to achieve semantically controllable scene generation. We
categorize our knowledge into two types to be consistent with the composition
of natural scenes, where the first type represents the property of objects and
the second type represents the relationship among objects. We then propose a
tree-structured generative model to learn complex scene representation, whose
nodes and edges are naturally corresponding to the two types of knowledge
respectively. Knowledge can be explicitly integrated to enable semantically
controllable scene generation by imposing semantic rules on properties of nodes
and edges in the tree structure. We construct a synthetic example to illustrate
the controllability and explainability of our method in a clean setting. We
further extend the synthetic example to realistic autonomous vehicle driving
environments and conduct extensive experiments to show that our method
efficiently identifies adversarial traffic scenes against different
state-of-the-art 3D point cloud segmentation models satisfying the traffic
rules specified as the explicit knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-speed object detection with a single-photon time-of-flight image sensor. (arXiv:2107.13407v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mora_Martin_G/0/1/0/all/0/1">Germ&#xe1;n Mora-Mart&#xed;n</a>, <a href="http://arxiv.org/find/eess/1/au:+Turpin_A/0/1/0/all/0/1">Alex Turpin</a>, <a href="http://arxiv.org/find/eess/1/au:+Ruget_A/0/1/0/all/0/1">Alice Ruget</a>, <a href="http://arxiv.org/find/eess/1/au:+Halimi_A/0/1/0/all/0/1">Abderrahim Halimi</a>, <a href="http://arxiv.org/find/eess/1/au:+Henderson_R/0/1/0/all/0/1">Robert Henderson</a>, <a href="http://arxiv.org/find/eess/1/au:+Leach_J/0/1/0/all/0/1">Jonathan Leach</a>, <a href="http://arxiv.org/find/eess/1/au:+Gyongy_I/0/1/0/all/0/1">Istvan Gyongy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13407">
                                    <div class="article-summary-box-inner">
                                        <span>3D time-of-flight (ToF) imaging is used in a variety of applications such as
augmented reality (AR), computer interfaces, robotics and autonomous systems.
Single-photon avalanche diodes (SPADs) are one of the enabling technologies
providing accurate depth data even over long ranges. By developing SPADs in
array format with integrated processing combined with pulsed, flood-type
illumination, high-speed 3D capture is possible. However, array sizes tend to
be relatively small, limiting the lateral resolution of the resulting depth
maps, and, consequently, the information that can be extracted from the image
for applications such as object detection. In this paper, we demonstrate that
these limitations can be overcome through the use of convolutional neural
networks (CNNs) for high-performance object detection. We present outdoor
results from a portable SPAD camera system that outputs 16-bin photon timing
histograms with 64x32 spatial resolution. The results, obtained with exposure
times down to 2 ms (equivalent to 500 FPS) and in signal-to-background (SBR)
ratios as low as 0.05, point to the advantages of providing the CNN with full
histogram data rather than point clouds alone. Alternatively, a combination of
point cloud and active intensity data may be used as input, for a similar level
of performance. In either case, the GPU-accelerated processing time is less
than 1 ms per frame, leading to an overall latency (image acquisition plus
processing) in the millisecond range, making the results relevant for
safety-critical computer vision applications which would benefit from faster
than human reaction times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Shared Knowledge from Non-COVID Lesions for Annotation-Efficient COVID-19 CT Lung Infection Segmentation. (arXiv:2012.15564v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yichi Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liao_Q/0/1/0/all/0/1">Qingcheng Liao</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuan_L/0/1/0/all/0/1">Lin Yuan</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_H/0/1/0/all/0/1">He Zhu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xing_J/0/1/0/all/0/1">Jiezhen Xing</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_J/0/1/0/all/0/1">Jicong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15564">
                                    <div class="article-summary-box-inner">
                                        <span>The novel Coronavirus disease (COVID-19) is a highly contagious virus and has
spread all over the world, posing an extremely serious threat to all countries.
Automatic lung infection segmentation from computed tomography (CT) plays an
important role in the quantitative analysis of COVID-19. However, the major
challenge lies in the inadequacy of annotated COVID-19 datasets. Currently,
there are several public non-COVID lung lesion segmentation datasets, providing
the potential for generalizing useful information to the related COVID-19
segmentation task. In this paper, we propose a novel relation-driven
collaborative learning model to exploit shared knowledge from non-COVID lesions
for annotation-efficient COVID-19 CT lung infection segmentation. The model
consists of a general encoder to capture general lung lesion features based on
multiple non-COVID lesions, and a target encoder to focus on task-specific
features based on COVID-19 infections. Features extracted from the two parallel
encoders are concatenated for the subsequent decoder part. We develop a
collaborative learning scheme to regularize feature-level relation consistency
of given input and encourage the model to learn more general and discriminative
representation of COVID-19 infections. Extensive experiments demonstrate that
trained with limited COVID-19 data, exploiting shared knowledge from non-COVID
lesions can further improve state-of-the-art performance with up to 3.0% in
dice similarity coefficient and 4.2% in normalized surface dice. Our proposed
method promotes new insights into annotation-efficient deep learning for
COVID-19 infection segmentation and illustrates strong potential for real-world
applications in the global fight against COVID-19 in the absence of sufficient
high-quality annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Densely Guided Knowledge Distillation using Multiple Teacher Assistants. (arXiv:2009.08825v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Son_W/0/1/0/all/0/1">Wonchul Son</a>, <a href="http://arxiv.org/find/cs/1/au:+Na_J/0/1/0/all/0/1">Jaemin Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Junyong Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_W/0/1/0/all/0/1">Wonjun Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08825">
                                    <div class="article-summary-box-inner">
                                        <span>With the success of deep neural networks, knowledge distillation which guides
the learning of a small student network from a large teacher network is being
actively studied for model compression and transfer learning. However, few
studies have been performed to resolve the poor learning issue of the student
network when the student and teacher model sizes significantly differ. In this
paper, we propose a densely guided knowledge distillation using multiple
teacher assistants that gradually decreases the model size to efficiently
bridge the large gap between the teacher and student networks. To stimulate
more efficient learning of the student network, we guide each teacher assistant
to every other smaller teacher assistants iteratively. Specifically, when
teaching a smaller teacher assistant at the next step, the existing larger
teacher assistants from the previous step are used as well as the teacher
network. Moreover, we design stochastic teaching where, for each mini-batch, a
teacher or teacher assistants are randomly dropped. This acts as a regularizer
to improve the efficiency of teaching of the student network. Thus, the student
can always learn salient distilled knowledge from the multiple sources. We
verified the effectiveness of the proposed method for a classification task
using CIFAR-10, CIFAR-100, and ImageNet. We also achieved significant
performance improvements with various backbone architectures such as ResNet,
WideResNet, and VGG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the shape of female breasts: an open-access 3D statistical shape model of the female breast built from 110 breast scans. (arXiv:2107.13463v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weiherer_M/0/1/0/all/0/1">Maximilian Weiherer</a>, <a href="http://arxiv.org/find/cs/1/au:+Eigenberger_A/0/1/0/all/0/1">Andreas Eigenberger</a>, <a href="http://arxiv.org/find/cs/1/au:+Brebant_V/0/1/0/all/0/1">Vanessa Br&#xe9;bant</a>, <a href="http://arxiv.org/find/cs/1/au:+Prantl_L/0/1/0/all/0/1">Lukas Prantl</a>, <a href="http://arxiv.org/find/cs/1/au:+Palm_C/0/1/0/all/0/1">Christoph Palm</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13463">
                                    <div class="article-summary-box-inner">
                                        <span>We present the Regensburg Breast Shape Model (RBSM) - a 3D statistical shape
model of the female breast built from 110 breast scans, and the first ever
publicly available. Together with the model, a fully automated, pairwise
surface registration pipeline used to establish correspondence among 3D breast
scans is introduced. Our method is computationally efficient and requires only
four landmarks to guide the registration process. In order to weaken the strong
coupling between breast and thorax, we propose to minimize the variance outside
the breast region as much as possible. To achieve this goal, a novel concept
called breast probability masks (BPMs) is introduced. A BPM assigns
probabilities to each point of a 3D breast scan, telling how likely it is that
a particular point belongs to the breast area. During registration, we use BPMs
to align the template to the target as accurately as possible inside the breast
region and only roughly outside. This simple yet effective strategy
significantly reduces the unwanted variance outside the breast region, leading
to better statistical shape models in which breast shapes are quite well
decoupled from the thorax. The RBSM is thus able to produce a variety of
different breast shapes as independently as possible from the shape of the
thorax. Our systematic experimental evaluation reveals a generalization ability
of 0.17 mm and a specificity of 2.8 mm for the RBSM. Ultimately, our model is
seen as a first step towards combining physically motivated deformable models
of the breast and statistical approaches in order to enable more realistic
surgical outcome simulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AI assisted method for efficiently generating breast ultrasound screening reports. (arXiv:2107.13431v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ge_S/0/1/0/all/0/1">Shuang Ge</a>, <a href="http://arxiv.org/find/eess/1/au:+Ye_Q/0/1/0/all/0/1">Qiongyu Ye</a>, <a href="http://arxiv.org/find/eess/1/au:+Xie_W/0/1/0/all/0/1">Wenquan Xie</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_D/0/1/0/all/0/1">Desheng Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1">Huabin Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1">Xiaobo Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuan_K/0/1/0/all/0/1">Kehong Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13431">
                                    <div class="article-summary-box-inner">
                                        <span>Ultrasound is the preferred choice for early screening of dense breast
cancer. Clinically, doctors have to manually write the screening report which
is time-consuming and laborious, and it is easy to miss and miswrite.
Therefore, this paper proposes a method for efficiently generating personalized
breast ultrasound screening preliminary reports by AI, especially for benign
and normal cases which account for the majority. Doctors then make simple
adjustments or corrections to quickly generate final reports. The proposed
approach has been tested using a database of 1133 breast tumor instances.
Experimental results indicate this pipeline improves doctors&#x27; work efficiency
by up to 90%, which greatly reduces repetitive work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi Point-Voxel Convolution (MPVConv) for Deep Learning on Point Clouds. (arXiv:2107.13152v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xin Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaodan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_X/0/1/0/all/0/1">Xingxing Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dekui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Ying He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13152">
                                    <div class="article-summary-box-inner">
                                        <span>The existing 3D deep learning methods adopt either individual point-based
features or local-neighboring voxel-based features, and demonstrate great
potential for processing 3D data. However, the point based models are
inefficient due to the unordered nature of point clouds and the voxel-based
models suffer from large information loss. Motivated by the success of recent
point-voxel representation, such as PVCNN, we propose a new convolutional
neural network, called Multi Point-Voxel Convolution (MPVConv), for deep
learning on point clouds. Integrating both the advantages of voxel and
point-based methods, MPVConv can effectively increase the neighboring
collection between point-based features and also promote independence among
voxel-based features. Moreover, most of the existing approaches aim at solving
one specific task, and only a few of them can handle a variety of tasks. Simply
replacing the corresponding convolution module with MPVConv, we show that
MPVConv can fit in different backbones to solve a wide range of 3D tasks.
Extensive experiments on benchmark datasets such as ShapeNet Part, S3DIS and
KITTI for various tasks show that MPVConv improves the accuracy of the backbone
(PointNet) by up to \textbf{36\%}, and achieves higher accuracy than the
voxel-based model with up to \textbf{34}$\times$ speedups. In addition, MPVConv
outperforms the state-of-the-art point-based models with up to
\textbf{8}$\times$ speedups. Notably, our MPVConv achieves better accuracy than
the newest point-voxel-based model PVCNN (a model more efficient than PointNet)
with lower latency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task-Specific Normalization for Continual Learning of Blind Image Quality Models. (arXiv:2107.13429v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weixia Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1">Kede Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13429">
                                    <div class="article-summary-box-inner">
                                        <span>The computational vision community has recently paid attention to continual
learning for blind image quality assessment (BIQA). The primary challenge is to
combat catastrophic forgetting of previously-seen IQA datasets (i.e., tasks).
In this paper, we present a simple yet effective continual learning method for
BIQA with improved quality prediction accuracy, plasticity-stability trade-off,
and task-order/length robustness. The key step in our approach is to freeze all
convolution filters of a pre-trained deep neural network (DNN) for an explicit
promise of stability, and learn task-specific normalization parameters for
plasticity. We assign each new task a prediction head, and load the
corresponding normalization parameters to produce a quality score. The final
quality estimate is computed by feature fusion and adaptive weighting using
hierarchical representations, without leveraging the test-time oracle.
Extensive experiments on six IQA datasets demonstrate the advantages of the
proposed method in comparison to previous training techniques for BIQA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A method to integrate and classify normal distributions. (arXiv:2012.14331v7 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Das_A/0/1/0/all/0/1">Abhranil Das</a>, <a href="http://arxiv.org/find/stat/1/au:+Geisler_W/0/1/0/all/0/1">Wilson S Geisler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14331">
                                    <div class="article-summary-box-inner">
                                        <span>Univariate and multivariate normal probability distributions are widely used
when modeling decisions under uncertainty. Computing the performance of such
models requires integrating these distributions over specific domains, which
can vary widely across models. Besides some special cases where these integrals
are easy to calculate, there exist no general analytical expressions, standard
numerical methods or software for these integrals. Here we present mathematical
results and open-source software that provide (i) the probability in any domain
of a normal in any dimensions with any parameters, (ii) the probability
density, cumulative distribution, and inverse cumulative distribution of any
function of a normal vector, (iii) the classification errors among any number
of normal distributions, the Bayes-optimal discriminability index and relation
to the operating characteristic, (iv) dimension reduction and visualizations
for such problems, and (v) tests for how reliably these methods may be used on
given data. We demonstrate these tools with vision research applications of
detecting occluding objects in natural scenes, and detecting camouflage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Indoor Future Person Localization from an Egocentric Wearable Camera. (arXiv:2103.04019v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jianing Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_F/0/1/0/all/0/1">Frank P.-W. Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1">Xiao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yingnan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shuo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_B/0/1/0/all/0/1">Benny Lo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04019">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate prediction of future person location and movement trajectory from an
egocentric wearable camera can benefit a wide range of applications, such as
assisting visually impaired people in navigation, and the development of
mobility assistance for people with disability. In this work, a new egocentric
dataset was constructed using a wearable camera, with 8,250 short clips of a
targeted person either walking 1) toward, 2) away, or 3) across the camera
wearer in indoor environments, or 4) staying still in the scene, and 13,817
person bounding boxes were manually labelled. Apart from the bounding boxes,
the dataset also contains the estimated pose of the targeted person as well as
the IMU signal of the wearable camera at each time point. An LSTM-based
encoder-decoder framework was designed to predict the future location and
movement trajectory of the targeted person in this egocentric setting.
Extensive experiments have been conducted on the new dataset, and have shown
that the proposed method is able to reliably and better predict future person
location and trajectory in egocentric videos captured by the wearable camera
compared to three baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Realistic River Image Synthesis using Deep Generative Adversarial Networks. (arXiv:2003.00826v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gautam_A/0/1/0/all/0/1">Akshat Gautam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sit_M/0/1/0/all/0/1">Muhammed Sit</a>, <a href="http://arxiv.org/find/cs/1/au:+Demir_I/0/1/0/all/0/1">Ibrahim Demir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.00826">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we demonstrated a practical application of realistic river
image generation using deep learning. Specifically, we explored a generative
adversarial network (GAN) model capable of generating high-resolution and
realistic river images that can be used to support modeling and analysis in
surface water estimation, river meandering, wetland loss, and other
hydrological research studies. First, we have created an extensive repository
of overhead river images to be used in training. Second, we incorporated the
Progressive Growing GAN (PGGAN), a network architecture that iteratively trains
smaller-resolution GANs to gradually build up to a very high resolution to
generate high quality (i.e., 1024x1024) synthetic river imagery. With simpler
GAN architectures, difficulties arose in terms of exponential increase of
training time and vanishing/exploding gradient issues, which the PGGAN
implementation seemed to significantly reduce. The results presented in this
study show great promise in generating high-quality images and capturing the
details of river structure and flow to support hydrological research, which
often requires extensive imagery for model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Surrogate Model-Based Explainability Methods for Point Cloud NNs. (arXiv:2107.13459v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hanxiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotthaus_H/0/1/0/all/0/1">Helena Kotthaus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13459">
                                    <div class="article-summary-box-inner">
                                        <span>In the field of autonomous driving and robotics, point clouds are showing
their excellent real-time performance as raw data from most of the mainstream
3D sensors. Therefore, point cloud neural networks have become a popular
research direction in recent years. So far, however, there has been little
discussion about the explainability of deep neural networks for point clouds.
In this paper, we propose new explainability approaches for point cloud deep
neural networks based on local surrogate model-based methods to show which
components make the main contribution to the classification. Moreover, we
propose a quantitative validation method for explainability methods of point
clouds which enhances the persuasive power of explainability by dropping the
most positive or negative contributing features and monitoring how the
classification scores of specific categories change. To enable an intuitive
explanation of misclassified instances, we display features with confounding
contributions. Our new explainability approach provides a fairly accurate, more
intuitive and widely applicable explanation for point cloud classification
tasks. Our code is available at https://github.com/Explain3D/Explainable3D</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pseudo-LiDAR Based Road Detection. (arXiv:2107.13279v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Libo Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haokui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1">Wei Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13279">
                                    <div class="article-summary-box-inner">
                                        <span>Road detection is a critically important task for self-driving cars. By
employing LiDAR data, recent works have significantly improved the accuracy of
road detection. Relying on LiDAR sensors limits the wide application of those
methods when only cameras are available. In this paper, we propose a novel road
detection approach with RGB being the only input during inference.
Specifically, we exploit pseudo-LiDAR using depth estimation, and propose a
feature fusion network where RGB and learned depth information are fused for
improved road detection. To further optimize the network structure and improve
the efficiency of the network. we search for the network structure of the
feature fusion module using NAS techniques. Finally, be aware of that
generating pseudo-LiDAR from RGB via depth estimation introduces extra
computational costs and relies on depth estimation networks, we design a
modality distillation strategy and leverage it to further free our network from
these extra computational cost and dependencies during inference. The proposed
method achieves state-of-the-art performance on two challenging benchmarks,
KITTI and R2D.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An explainable two-dimensional single model deep learning approach for Alzheimer&#x27;s disease diagnosis and brain atrophy localization. (arXiv:2107.13200v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Pan_B/0/1/0/all/0/1">Bo Pan</a>, <a href="http://arxiv.org/find/eess/1/au:+Shao_P/0/1/0/all/0/1">Pengfei Shao</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1">Peng Liu</a> (Alzheimer&#x27;s Disease Neuroimaging Initiative, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing), <a href="http://arxiv.org/find/eess/1/au:+Shen_S/0/1/0/all/0/1">Shuwei Shen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yao_P/0/1/0/all/0/1">Peng Yao</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_R/0/1/0/all/0/1">Ronald X. Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13200">
                                    <div class="article-summary-box-inner">
                                        <span>Early and accurate diagnosis of Alzheimer&#x27;s disease (AD) and its prodromal
period mild cognitive impairment (MCI) is essential for the delayed disease
progression and the improved quality of patients&#x27;life. The emerging
computer-aided diagnostic methods that combine deep learning with structural
magnetic resonance imaging (sMRI) have achieved encouraging results, but some
of them are limit of issues such as data leakage and unexplainable diagnosis.
In this research, we propose a novel end-to-end deep learning approach for
automated diagnosis of AD and localization of important brain regions related
to the disease from sMRI data. This approach is based on a 2D single model
strategy and has the following differences from the current approaches: 1)
Convolutional Neural Network (CNN) models of different structures and
capacities are evaluated systemically and the most suitable model is adopted
for AD diagnosis; 2) a data augmentation strategy named Two-stage Random
RandAugment (TRRA) is proposed to alleviate the overfitting issue caused by
limited training data and to improve the classification performance in AD
diagnosis; 3) an explainable method of Grad-CAM++ is introduced to generate the
visually explainable heatmaps that localize and highlight the brain regions
that our model focuses on and to make our model more transparent. Our approach
has been evaluated on two publicly accessible datasets for two classification
tasks of AD vs. cognitively normal (CN) and progressive MCI (pMCI) vs. stable
MCI (sMCI). The experimental results indicate that our approach outperforms the
state-of-the-art approaches, including those using multi-model and 3D CNN
methods. The resultant localization heatmaps from our approach also highlight
the lateral ventricle and some disease-relevant regions of cortex, coincident
with the commonly affected regions during the development of AD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search. (arXiv:1907.01845v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiangxiang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ruijun Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.01845">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most critical problems in weight-sharing neural architecture
search is the evaluation of candidate models within a predefined search space.
In practice, a one-shot supernet is trained to serve as an evaluator. A
faithful ranking certainly leads to more accurate searching results. However,
current methods are prone to making misjudgments. In this paper, we prove that
their biased evaluation is due to inherent unfairness in the supernet training.
In view of this, we propose two levels of constraints: expectation fairness and
strict fairness. Particularly, strict fairness ensures equal optimization
opportunities for all choice blocks throughout the training, which neither
overestimates nor underestimates their capacity. We demonstrate that this is
crucial for improving the confidence of models&#x27; ranking. Incorporating the
one-shot supernet trained under the proposed fairness constraints with a
multi-objective evolutionary search algorithm, we obtain various
state-of-the-art models, e.g., FairNAS-A attains 77.5% top-1 validation
accuracy on ImageNet. The models and their evaluation codes are made publicly
available online this http URL .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Dataset, Poisson GAN and AquaNet for Underwater Object Grabbing. (arXiv:2003.01446v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chongwei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhihui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shijie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1">Tao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1">Yulong Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Caifei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haojie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xin Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.01446">
                                    <div class="article-summary-box-inner">
                                        <span>To boost the object grabbing capability of underwater robots for open-sea
farming, we propose a new dataset (UDD) consisting of three categories
(seacucumber, seaurchin, and scallop) with 2,227 images. To the best of our
knowledge, it is the first 4K HD dataset collected in a real open-sea farm. We
also propose a novel Poisson-blending Generative Adversarial Network (Poisson
GAN) and an efficient object detection network (AquaNet) to address two common
issues within related datasets: the class-imbalance problem and the problem of
mass small object, respectively. Specifically, Poisson GAN combines Poisson
blending into its generator and employs a new loss called Dual Restriction loss
(DR loss), which supervises both implicit space features and image-level
features during training to generate more realistic images. By utilizing
Poisson GAN, objects of minority class like seacucumber or scallop could be
added into an image naturally and annotated automatically, which could increase
the loss of minority classes during training detectors to eliminate the
class-imbalance problem; AquaNet is a high-efficiency detector to address the
problem of detecting mass small objects from cloudy underwater pictures. Within
it, we design two efficient components: a depth-wise-convolution-based
Multi-scale Contextual Features Fusion (MFF) block and a Multi-scale
Blursampling (MBP) module to reduce the parameters of the network to 1.3
million. Both two components could provide multi-scale features of small
objects under a short backbone configuration without any loss of accuracy. In
addition, we construct a large-scale augmented dataset (AUDD) and a
pre-training dataset via Poisson GAN from UDD. Extensive experiments show the
effectiveness of the proposed Poisson GAN, AquaNet, UDD, AUDD, and pre-training
dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning-Based Depth and Pose Estimation for Monocular Endoscope with Loss Generalization. (arXiv:2107.13263v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Widya_A/0/1/0/all/0/1">Aji Resindra Widya</a>, <a href="http://arxiv.org/find/cs/1/au:+Monno_Y/0/1/0/all/0/1">Yusuke Monno</a>, <a href="http://arxiv.org/find/cs/1/au:+Okutomi_M/0/1/0/all/0/1">Masatoshi Okutomi</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_S/0/1/0/all/0/1">Sho Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Gotoda_T/0/1/0/all/0/1">Takuji Gotoda</a>, <a href="http://arxiv.org/find/cs/1/au:+Miki_K/0/1/0/all/0/1">Kenji Miki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13263">
                                    <div class="article-summary-box-inner">
                                        <span>Gastroendoscopy has been a clinical standard for diagnosing and treating
conditions that affect a part of a patient&#x27;s digestive system, such as the
stomach. Despite the fact that gastroendoscopy has a lot of advantages for
patients, there exist some challenges for practitioners, such as the lack of 3D
perception, including the depth and the endoscope pose information. Such
challenges make navigating the endoscope and localizing any found lesion in a
digestive tract difficult. To tackle these problems, deep learning-based
approaches have been proposed to provide monocular gastroendoscopy with
additional yet important depth and pose information. In this paper, we propose
a novel supervised approach to train depth and pose estimation networks using
consecutive endoscopy images to assist the endoscope navigation in the stomach.
We firstly generate real depth and pose training data using our previously
proposed whole stomach 3D reconstruction pipeline to avoid poor generalization
ability between computer-generated (CG) models and real data for the stomach.
In addition, we propose a novel generalized photometric loss function to avoid
the complicated process of finding proper weights for balancing the depth and
the pose loss terms, which is required for existing direct depth and pose
supervision approaches. We then experimentally show that our proposed
generalized loss performs better than existing direct supervision losses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimROD: A Simple Adaptation Method for Robust Object Detection. (arXiv:2107.13389v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramamonjison_R/0/1/0/all/0/1">Rindra Ramamonjison</a>, <a href="http://arxiv.org/find/cs/1/au:+Banitalebi_Dehkordi_A/0/1/0/all/0/1">Amin Banitalebi-Dehkordi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xinyu Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xiaolong Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13389">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a Simple and effective unsupervised adaptation method for
Robust Object Detection (SimROD). To overcome the challenging issues of domain
shift and pseudo-label noise, our method integrates a novel domain-centric
augmentation method, a gradual self-labeling adaptation procedure, and a
teacher-guided fine-tuning mechanism. Using our method, target domain samples
can be leveraged to adapt object detection models without changing the model
architecture or generating synthetic data. When applied to image corruptions
and high-level cross-domain adaptation benchmarks, our method outperforms prior
baselines on multiple domain adaptation benchmarks. SimROD achieves new
state-of-the-art on standard real-to-synthetic and cross-camera setup
benchmarks. On the image corruption benchmark, models adapted with our method
achieved a relative robustness improvement of 15-25% AP50 on Pascal-C and 5-6%
AP on COCO-C and Cityscapes-C. On the cross-domain benchmark, our method
outperformed the best baseline performance by up to 8% AP50 on Comic dataset
and up to 4% on Watercolor dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CRD-CGAN: Category-Consistent and Relativistic Constraints for Diverse Text-to-Image Generation. (arXiv:2107.13516v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1">Tao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_C/0/1/0/all/0/1">Chengjiang Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chunxia Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13516">
                                    <div class="article-summary-box-inner">
                                        <span>Generating photo-realistic images from a text description is a challenging
problem in computer vision. Previous works have shown promising performance to
generate synthetic images conditional on text by Generative Adversarial
Networks (GANs). In this paper, we focus on the category-consistent and
relativistic diverse constraints to optimize the diversity of synthetic images.
Based on those constraints, a category-consistent and relativistic diverse
conditional GAN (CRD-CGAN) is proposed to synthesize $K$ photo-realistic images
simultaneously. We use the attention loss and diversity loss to improve the
sensitivity of the GAN to word attention and noises. Then, we employ the
relativistic conditional loss to estimate the probability of relatively real or
fake for synthetic images, which can improve the performance of basic
conditional loss. Finally, we introduce a category-consistent loss to alleviate
the over-category issues between K synthetic images. We evaluate our approach
using the Birds-200-2011, Oxford-102 flower and MSCOCO 2014 datasets, and the
extensive experiments demonstrate superiority of the proposed method in
comparison with state-of-the-art methods in terms of photorealistic and
diversity of the generated synthetic images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Computer Vision-Based Approach for Driver Distraction Recognition using Deep Learning and Genetic Algorithm Based Ensemble. (arXiv:2107.13355v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Ashlesha Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sangwan_K/0/1/0/all/0/1">Kuldip Singh Sangwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhiraj/0/1/0/all/0/1">Dhiraj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13355">
                                    <div class="article-summary-box-inner">
                                        <span>As the proportion of road accidents increases each year, driver distraction
continues to be an important risk component in road traffic injuries and
deaths. The distractions caused by the increasing use of mobile phones and
other wireless devices pose a potential risk to road safety. Our current study
aims to aid the already existing techniques in driver posture recognition by
improving the performance in the driver distraction classification problem. We
present an approach using a genetic algorithm-based ensemble of six independent
deep neural architectures, namely, AlexNet, VGG-16, EfficientNet B0, Vanilla
CNN, Modified DenseNet, and InceptionV3 + BiLSTM. We test it on two
comprehensive datasets, the AUC Distracted Driver Dataset, on which our
technique achieves an accuracy of 96.37%, surpassing the previously obtained
95.98%, and on the State Farm Driver Distraction Dataset, on which we attain an
accuracy of 99.75%. The 6-Model Ensemble gave an inference time of 0.024
seconds as measured on our machine with Ubuntu 20.04(64-bit) and GPU as GeForce
GTX 1080.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransAction: ICL-SJTU Submission to EPIC-Kitchens Action Anticipation Challenge 2021. (arXiv:2107.13259v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1">Xiao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jianing Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lo_B/0/1/0/all/0/1">Benny Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guang-Zhong Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13259">
                                    <div class="article-summary-box-inner">
                                        <span>In this report, the technical details of our submission to the EPIC-Kitchens
Action Anticipation Challenge 2021 are given. We developed a hierarchical
attention model for action anticipation, which leverages Transformer-based
attention mechanism to aggregate features across temporal dimension,
modalities, symbiotic branches respectively. In terms of Mean Top-5 Recall of
action, our submission with team name ICL-SJTU achieved 13.39% for overall
testing set, 10.05% for unseen subsets and 11.88% for tailed subsets.
Additionally, it is noteworthy that our submission ranked 1st in terms of verb
class in all three (sub)sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Aggregation then Local Distribution for Scene Parsing. (arXiv:2107.13154v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiangtai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Guangliang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kuiyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1">Yunhai Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiatian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tao Xiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13154">
                                    <div class="article-summary-box-inner">
                                        <span>Modelling long-range contextual relationships is critical for pixel-wise
prediction tasks such as semantic segmentation. However, convolutional neural
networks (CNNs) are inherently limited to model such dependencies due to the
naive structure in its building modules (\eg, local convolution kernel). While
recent global aggregation methods are beneficial for long-range structure
information modelling, they would oversmooth and bring noise to the regions
containing fine details (\eg,~boundaries and small objects), which are very
much cared for the semantic segmentation task. To alleviate this problem, we
propose to explore the local context for making the aggregated long-range
relationship being distributed more accurately in local regions. In particular,
we design a novel local distribution module which models the affinity map
between global and local relationship for each pixel adaptively. Integrating
existing global aggregation modules, we show that our approach can be
modularized as an end-to-end trainable block and easily plugged into existing
semantic segmentation networks, giving rise to the \emph{GALD} networks.
Despite its simplicity and versatility, our approach allows us to build new
state of the art on major semantic segmentation benchmarks including
Cityscapes, ADE20K, Pascal Context, Camvid and COCO-stuff. Code and trained
models are released at \url{https://github.com/lxtGH/GALD-DGCNet} to foster
further research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Normalization Matters in Weakly Supervised Object Localization. (arXiv:2107.13221v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jeesoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Choe_J/0/1/0/all/0/1">Junsuk Choe</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Sangdoo Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwak_N/0/1/0/all/0/1">Nojun Kwak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13221">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly-supervised object localization (WSOL) enables finding an object using
a dataset without any localization information. By simply training a
classification model using only image-level annotations, the feature map of the
model can be utilized as a score map for localization. In spite of many WSOL
methods proposing novel strategies, there has not been any de facto standard
about how to normalize the class activation map (CAM). Consequently, many WSOL
methods have failed to fully exploit their own capacity because of the misuse
of a normalization method. In this paper, we review many existing normalization
methods and point out that they should be used according to the property of the
given dataset. Additionally, we propose a new normalization method which
substantially enhances the performance of any CAM-based WSOL methods. Using the
proposed normalization method, we provide a comprehensive evaluation over three
datasets (CUB, ImageNet and OpenImages) on three different architectures and
observe significant performance gains over the conventional min-max
normalization method in all the evaluated cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Multi-View Stereo via Super-Resolution. (arXiv:2107.13261v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lomurno_E/0/1/0/all/0/1">Eugenio Lomurno</a>, <a href="http://arxiv.org/find/cs/1/au:+Romanoni_A/0/1/0/all/0/1">Andrea Romanoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Matteucci_M/0/1/0/all/0/1">Matteo Matteucci</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13261">
                                    <div class="article-summary-box-inner">
                                        <span>Today, Multi-View Stereo techniques are able to reconstruct robust and
detailed 3D models, especially when starting from high-resolution images.
However, there are cases in which the resolution of input images is relatively
low, for instance, when dealing with old photos, or when hardware constrains
the amount of data that can be acquired. In this paper, we investigate if, how,
and how much increasing the resolution of such input images through
Super-Resolution techniques reflects in quality improvements of the
reconstructed 3D models, despite the artifacts that sometimes this may
generate. We show that applying a Super-Resolution step before recovering the
depth maps in most cases leads to a better 3D model both in the case of
PatchMatch-based and deep-learning-based algorithms. The use of
Super-Resolution improves especially the completeness of reconstructed models
and turns out to be particularly effective in the case of textured scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Proof-of-Concept Study of Artificial Intelligence Assisted Contour Revision. (arXiv:2107.13465v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_T/0/1/0/all/0/1">Ti Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Balagopal_A/0/1/0/all/0/1">Anjali Balagopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dohopolski_M/0/1/0/all/0/1">Michael Dohopolski</a>, <a href="http://arxiv.org/find/cs/1/au:+Morgan_H/0/1/0/all/0/1">Howard E. Morgan</a>, <a href="http://arxiv.org/find/cs/1/au:+McBeth_R/0/1/0/all/0/1">Rafe McBeth</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1">Jun Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1">Mu-Han Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sher_D/0/1/0/all/0/1">David J. Sher</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dan Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Steve Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13465">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic segmentation of anatomical structures is critical for many medical
applications. However, the results are not always clinically acceptable and
require tedious manual revision. Here, we present a novel concept called
artificial intelligence assisted contour revision (AIACR) and demonstrate its
feasibility. The proposed clinical workflow of AIACR is as follows given an
initial contour that requires a clinicians revision, the clinician indicates
where a large revision is needed, and a trained deep learning (DL) model takes
this input to update the contour. This process repeats until a clinically
acceptable contour is achieved. The DL model is designed to minimize the
clinicians input at each iteration and to minimize the number of iterations
needed to reach acceptance. In this proof-of-concept study, we demonstrated the
concept on 2D axial images of three head-and-neck cancer datasets, with the
clinicians input at each iteration being one mouse click on the desired
location of the contour segment. The performance of the model is quantified
with Dice Similarity Coefficient (DSC) and 95th percentile of Hausdorff
Distance (HD95). The average DSC/HD95 (mm) of the auto-generated initial
contours were 0.82/4.3, 0.73/5.6 and 0.67/11.4 for three datasets, which were
improved to 0.91/2.1, 0.86/2.4 and 0.86/4.7 with three mouse clicks,
respectively. Each DL-based contour update requires around 20 ms. We proposed a
novel AIACR concept that uses DL models to assist clinicians in revising
contours in an efficient and effective way, and we demonstrated its feasibility
by using 2D axial CT images from three head-and-neck cancer datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Squeeze-Excitation Convolutional Recurrent Neural Networks for Audio-Visual Scene Classification. (arXiv:2107.13180v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naranjo_Alcazar_J/0/1/0/all/0/1">Javier Naranjo-Alcazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Castanos_S/0/1/0/all/0/1">Sergi Perez-Castanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_Garcia_A/0/1/0/all/0/1">Aaron Lopez-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuccarello_P/0/1/0/all/0/1">Pedro Zuccarello</a>, <a href="http://arxiv.org/find/cs/1/au:+Cobos_M/0/1/0/all/0/1">Maximo Cobos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferri_F/0/1/0/all/0/1">Francesc J. Ferri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13180">
                                    <div class="article-summary-box-inner">
                                        <span>The use of multiple and semantically correlated sources can provide
complementary information to each other that may not be evident when working
with individual modalities on their own. In this context, multi-modal models
can help producing more accurate and robust predictions in machine learning
tasks where audio-visual data is available. This paper presents a multi-modal
model for automatic scene classification that exploits simultaneously auditory
and visual information. The proposed approach makes use of two separate
networks which are respectively trained in isolation on audio and visual data,
so that each network specializes in a given modality. The visual subnetwork is
a pre-trained VGG16 model followed by a bidiretional recurrent layer, while the
residual audio subnetwork is based on stacked squeeze-excitation convolutional
blocks trained from scratch. After training each subnetwork, the fusion of
information from the audio and visual streams is performed at two different
stages. The early fusion stage combines features resulting from the last
convolutional block of the respective subnetworks at different time steps to
feed a bidirectional recurrent structure. The late fusion stage combines the
output of the early fusion stage with the independent predictions provided by
the two subnetworks, resulting in the final prediction. We evaluate the method
using the recently published TAU Audio-Visual Urban Scenes 2021, which contains
synchronized audio and video recordings from 12 European cities in 10 different
scene classes. The proposed model has been shown to provide an excellent
trade-off between prediction performance (86.5%) and system complexity (15M
parameters) in the evaluation results of the DCASE 2021 Challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rank-based verification for long-term face tracking in crowded scenes. (arXiv:2107.13273v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barquero_G/0/1/0/all/0/1">Germ&#xe1;n Barquero</a>, <a href="http://arxiv.org/find/cs/1/au:+Hupont_I/0/1/0/all/0/1">Isabelle Hupont</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_C/0/1/0/all/0/1">Carles Fern&#xe1;ndez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13273">
                                    <div class="article-summary-box-inner">
                                        <span>Most current multi-object trackers focus on short-term tracking, and are
based on deep and complex systems that often cannot operate in real-time,
making them impractical for video-surveillance. In this paper we present a
long-term, multi-face tracking architecture conceived for working in crowded
contexts where faces are often the only visible part of a person. Our system
benefits from advances in the fields of face detection and face recognition to
achieve long-term tracking, and is particularly unconstrained to the motion and
occlusions of people. It follows a tracking-by-detection approach, combining a
fast short-term visual tracker with a novel online tracklet reconnection
strategy grounded on rank-based face verification. The proposed rank-based
constraint favours higher inter-class distance among tracklets, and reduces the
propagation of errors due to wrong reconnections. Additionally, a correction
module is included to correct past assignments with no extra computational
cost. We present a series of experiments introducing novel specialized metrics
for the evaluation of long-term tracking capabilities, and publicly release a
video dataset with 10 manually annotated videos and a total length of 8&#x27; 54&quot;.
Our findings validate the robustness of each of the proposed modules, and
demonstrate that, in these challenging contexts, our approach yields up to 50%
longer tracks than state-of-the-art deep learning trackers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting the Future from First Person (Egocentric) Vision: A Survey. (arXiv:2107.13411v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rodin_I/0/1/0/all/0/1">Ivan Rodin</a>, <a href="http://arxiv.org/find/cs/1/au:+Furnari_A/0/1/0/all/0/1">Antonino Furnari</a>, <a href="http://arxiv.org/find/cs/1/au:+Mavroedis_D/0/1/0/all/0/1">Dimitrios Mavroedis</a>, <a href="http://arxiv.org/find/cs/1/au:+Farinella_G/0/1/0/all/0/1">Giovanni Maria Farinella</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13411">
                                    <div class="article-summary-box-inner">
                                        <span>Egocentric videos can bring a lot of information about how humans perceive
the world and interact with the environment, which can be beneficial for the
analysis of human behaviour. The research in egocentric video analysis is
developing rapidly thanks to the increasing availability of wearable devices
and the opportunities offered by new large-scale egocentric datasets. As
computer vision techniques continue to develop at an increasing pace, the tasks
related to the prediction of future are starting to evolve from the need of
understanding the present. Predicting future human activities, trajectories and
interactions with objects is crucial in applications such as human-robot
interaction, assistive wearable technologies for both industrial and daily
living scenarios, entertainment and virtual or augmented reality. This survey
summarises the evolution of studies in the context of future prediction from
egocentric vision making an overview of applications, devices, existing
problems, commonly used datasets, models and input modalities. Our analysis
highlights that methods for future prediction from egocentric vision can have a
significant impact in a range of applications and that further research efforts
should be devoted to the standardisation of tasks and the proposal of datasets
considering real-world scenarios such as the ones with an industrial vocation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Content-aware Directed Propagation Network with Pixel Adaptive Kernel Attention. (arXiv:2107.13144v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagong_M/0/1/0/all/0/1">Min-Cheol Sagong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_Y/0/1/0/all/0/1">Yoon-Jae Yeo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Seung-Won Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Ko_S/0/1/0/all/0/1">Sung-Jea Ko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13144">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have been not only widespread but also
achieved noticeable results on numerous applications including image
classification, restoration, and generation. Although the weight-sharing
property of convolutions makes them widely adopted in various tasks, its
content-agnostic characteristic can also be considered a major drawback. To
solve this problem, in this paper, we propose a novel operation, called pixel
adaptive kernel attention (PAKA). PAKA provides directivity to the filter
weights by multiplying spatially varying attention from learnable features. The
proposed method infers pixel-adaptive attention maps along the channel and
spatial directions separately to address the decomposed model with fewer
parameters. Our method is trainable in an end-to-end manner and applicable to
any CNN-based models. In addition, we propose an improved information
aggregation module with PAKA, called the hierarchical PAKA module (HPM). We
demonstrate the superiority of our HPM by presenting state-of-the-art
performance on semantic segmentation compared to the conventional information
aggregation modules. We validate the proposed method through additional
ablation studies and visualizing the effect of PAKA providing directivity to
the weights of convolutions. We also show the generalizability of the proposed
method by applying it to multi-modal tasks especially color-guided depth map
super-resolution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Segmentation for Terracotta Warrior with Seed-Region-Growing CNN(SRG-Net). (arXiv:2107.13167v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_G/0/1/0/all/0/1">Guohua Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_X/0/1/0/all/0/1">Xingxing Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xin Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13167">
                                    <div class="article-summary-box-inner">
                                        <span>The repairing work of terracotta warriors in Emperor Qinshihuang Mausoleum
Site Museum is handcrafted by experts, and the increasing amounts of unearthed
pieces of terracotta warriors make the archaeologists too challenging to
conduct the restoration of terracotta warriors efficiently. We hope to segment
the 3D point cloud data of the terracotta warriors automatically and store the
fragment data in the database to assist the archaeologists in matching the
actual fragments with the ones in the database, which could result in higher
repairing efficiency of terracotta warriors. Moreover, the existing 3D neural
network research is mainly focusing on supervised classification, clustering,
unsupervised representation, and reconstruction. There are few pieces of
researches concentrating on unsupervised point cloud part segmentation. In this
paper, we present SRG-Net for 3D point clouds of terracotta warriors to address
these problems. Firstly, we adopt a customized seed-region-growing algorithm to
segment the point cloud coarsely. Then we present a supervised segmentation and
unsupervised reconstruction networks to learn the characteristics of 3D point
clouds. Finally, we combine the SRG algorithm with our improved CNN using a
refinement method. This pipeline is called SRG-Net, which aims at conducting
segmentation tasks on the terracotta warriors. Our proposed SRG-Net is
evaluated on the terracotta warriors data and ShapeNet dataset by measuring the
accuracy and the latency. The experimental results show that our SRG-Net
outperforms the state-of-the-art methods. Our code is shown in Code File
1~\cite{Srgnet_2021}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Constrained Data Representation Learning for Human Motion Segmentation. (arXiv:2107.13362v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dimiccoli_M/0/1/0/all/0/1">Mariella Dimiccoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Garrido_L/0/1/0/all/0/1">Llu&#xed;s Garrido</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodriguez_Corominas_G/0/1/0/all/0/1">Guillem Rodriguez-Corominas</a>, <a href="http://arxiv.org/find/cs/1/au:+Wendt_H/0/1/0/all/0/1">Herwig Wendt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13362">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, transfer subspace learning based approaches have shown to be a
valid alternative to unsupervised subspace clustering and temporal data
clustering for human motion segmentation (HMS). These approaches leverage prior
knowledge from a source domain to improve clustering performance on a target
domain, and currently they represent the state of the art in HMS. Bucking this
trend, in this paper, we propose a novel unsupervised model that learns a
representation of the data and digs clustering information from the data
itself. Our model is reminiscent of temporal subspace clustering, but presents
two critical differences. First, we learn an auxiliary data matrix that can
deviate from the initial data, hence confer more degrees of freedom to the
coding matrix. Second, we introduce a regularization term for this auxiliary
data matrix that preserves the local geometrical structure present in the
high-dimensional space. The proposed model is efficiently optimized by using an
original Alternating Direction Method of Multipliers (ADMM) formulation
allowing to learn jointly the auxiliary data representation, a nonnegative
dictionary and a coding matrix. Experimental results on four benchmark datasets
for HMS demonstrate that our approach achieves significantly better clustering
performance then state-of-the-art methods, including both unsupervised and more
recent semi-supervised transfer learning approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Visual Domain Transfer Learning Approach for Heartbeat Sound Classification. (arXiv:2107.13237v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mukherjee_U/0/1/0/all/0/1">Uddipan Mukherjee</a>, <a href="http://arxiv.org/find/eess/1/au:+Pancholi_S/0/1/0/all/0/1">Sidharth Pancholi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13237">
                                    <div class="article-summary-box-inner">
                                        <span>Heart disease is the most common reason for human mortality that causes
almost one-third of deaths throughout the world. Detecting the disease early
increases the chances of survival of the patient and there are several ways a
sign of heart disease can be detected early. This research proposes to convert
cleansed and normalized heart sound into visual mel scale spectrograms and then
using visual domain transfer learning approaches to automatically extract
features and categorize between heart sounds. Some of the previous studies
found that the spectrogram of various types of heart sounds is visually
distinguishable to human eyes, which motivated this study to experiment on
visual domain classification approaches for automated heart sound
classification. It will use convolution neural network-based architectures i.e.
ResNet, MobileNetV2, etc as the automated feature extractors from spectrograms.
These well-accepted models in the image domain showed to learn generalized
feature representations of cardiac sounds collected from different environments
with varying amplitude and noise levels. Model evaluation criteria used were
categorical accuracy, precision, recall, and AUROC as the chosen dataset is
unbalanced. The proposed approach has been implemented on datasets A and B of
the PASCAL heart sound collection and resulted in ~ 90% categorical accuracy
and AUROC of ~0.97 for both sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepTeeth: A Teeth-photo Based Human Authentication System for Mobile and Hand-held Devices. (arXiv:2107.13217v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arora_G/0/1/0/all/0/1">Geetika Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharadwaj_R/0/1/0/all/0/1">Rohit K Bharadwaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_K/0/1/0/all/0/1">Kamlesh Tiwari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13217">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes teeth-photo, a new biometric modality for human
authentication on mobile and hand held devices. Biometrics samples are acquired
using the camera mounted on mobile device with the help of a mobile application
having specific markers to register the teeth area. Region of interest (RoI) is
then extracted using the markers and the obtained sample is enhanced using
contrast limited adaptive histogram equalization (CLAHE) for better visual
clarity. We propose a deep learning architecture and novel regularization
scheme to obtain highly discriminative embedding for small size RoI. Proposed
custom loss function was able to achieve perfect classification for the tiny
RoI of $75\times 75$ size. The model is end-to-end and few-shot and therefore
is very efficient in terms of time and energy requirements. The system can be
used in many ways including device unlocking and secure authentication. To the
best of our understanding, this is the first work on teeth-photo based
authentication for mobile device. Experiments have been conducted on an
in-house teeth-photo database collected using our application. The database is
made publicly available. Results have shown that the proposed system has
perfect accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Video Instance Segmentation via Temporal Pyramid Routing. (arXiv:2107.13155v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiangtai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">Hao He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Henghui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kuiyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_G/0/1/0/all/0/1">Guangliang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jianping Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1">Yunhai Tong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13155">
                                    <div class="article-summary-box-inner">
                                        <span>Video Instance Segmentation (VIS) is a new and inherently multi-task problem,
which aims to detect, segment and track each instance in a video sequence.
Existing approaches are mainly based on single-frame features or single-scale
features of multiple frames, where temporal information or multi-scale
information is ignored. To incorporate both temporal and scale information, we
propose a Temporal Pyramid Routing (TPR) strategy to conditionally align and
conduct pixel-level aggregation from a feature pyramid pair of two adjacent
frames. Specifically, TPR contains two novel components, including Dynamic
Aligned Cell Routing (DACR) and Cross Pyramid Routing (CPR), where DACR is
designed for aligning and gating pyramid features across temporal dimension,
while CPR transfers temporally aggregated features across scale dimension.
Moreover, our approach is a plug-and-play module and can be easily applied to
existing instance segmentation methods. Extensive experiments on YouTube-VIS
dataset demonstrate the effectiveness and efficiency of the proposed approach
on several state-of-the-art instance segmentation methods. Codes and trained
models will be publicly available to facilitate future
research.(\url{https://github.com/lxtGH/TemporalPyramidRouting}).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Rays for Occlusion-aware Image-based Rendering. (arXiv:2107.13421v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Sida Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qianqian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_X/0/1/0/all/0/1">Xiaowei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13421">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new neural representation, called Neural Ray (NeuRay), for the
novel view synthesis (NVS) task with multi-view images as input. Existing
neural scene representations for solving the NVS problem, such as NeRF, cannot
generalize to new scenes and take an excessively long time on training on each
new scene from scratch. The other subsequent neural rendering methods based on
stereo matching, such as PixelNeRF, SRF and IBRNet are designed to generalize
to unseen scenes but suffer from view inconsistency in complex scenes with
self-occlusions. To address these issues, our NeuRay method represents every
scene by encoding the visibility of rays associated with the input views. This
neural representation can efficiently be initialized from depths estimated by
external MVS methods, which is able to generalize to new scenes and achieves
satisfactory rendering images without any training on the scene. Then, the
initialized NeuRay can be further optimized on every scene with little training
timing to enforce spatial coherence to ensure view consistency in the presence
of severe self-occlusion. Experiments demonstrate that NeuRay can quickly
generate high-quality novel view images of unseen scenes with little finetuning
and can handle complex scenes with severe self-occlusions which previous
methods struggle with.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">C^3Net: End-to-End deep learning for efficient real-time visual active camera control. (arXiv:2107.13233v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kyrkou_C/0/1/0/all/0/1">Christos Kyrkou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13233">
                                    <div class="article-summary-box-inner">
                                        <span>The need for automated real-time visual systems in applications such as smart
camera surveillance, smart environments, and drones necessitates the
improvement of methods for visual active monitoring and control. Traditionally,
the active monitoring task has been handled through a pipeline of modules such
as detection, filtering, and control. However, such methods are difficult to
jointly optimize and tune their various parameters for real-time processing in
resource constraint systems. In this paper a deep Convolutional Camera
Controller Neural Network is proposed to go directly from visual information to
camera movement to provide an efficient solution to the active vision problem.
It is trained end-to-end without bounding box annotations to control a camera
and follow multiple targets from raw pixel values. Evaluation through both a
simulation framework and real experimental setup, indicate that the proposed
solution is robust to varying conditions and able to achieve better monitoring
performance than traditional approaches both in terms of number of targets
monitored as well as in effective monitoring time. The advantage of the
proposed approach is that it is computationally less demanding and can run at
over 10 FPS (~4x speedup) on an embedded smart camera providing a practical and
affordable solution to real-time active monitoring.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessment of Deep Learning-based Heart Rate Estimation using Remote Photoplethysmography under Different Illuminations. (arXiv:2107.13193v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ze Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haofei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_F/0/1/0/all/0/1">Feng Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13193">
                                    <div class="article-summary-box-inner">
                                        <span>Remote photoplethysmography (rPPG) monitors heart rate without requiring
physical contact, which allows for a wide variety of applications. Deep
learning-based rPPG have demonstrated superior performance over the traditional
approaches in controlled context. However, the lighting situation in indoor
space is typically complex, with uneven light distribution and frequent
variations in illumination. It lacks a fair comparison of different methods
under different illuminations using the same dataset. In this paper, we present
a public dataset, namely the BH-rPPG dataset, which contains data from twelve
subjects under three illuminations: low, medium, and high illumination. We also
provide the ground truth heart rate measured by an oximeter. We evaluate the
performance of three deep learning-based methods to that of four traditional
methods using two public datasets: the UBFC-rPPG dataset and the BH-rPPG
dataset. The experimental results demonstrate that traditional methods are
generally more resistant to fluctuating illuminations. We found that the
rPPGNet achieves lowest MAE among deep learning-based method under medium
illumination, whereas the CHROM achieves 1.5 beats per minute (BPM),
outperforming the rPPGNet by 60%. These findings suggest that while developing
deep learning-based heart rate estimation algorithms, illumination variation
should be taken into account. This work serves as a benchmark for rPPG
performance evaluation and it opens a pathway for future investigation into
deep learning-based rPPG under illumination variations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Whole Slide Images are 2D Point Clouds: Context-Aware Survival Prediction using Patch-based Graph Convolutional Networks. (arXiv:2107.13048v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_R/0/1/0/all/0/1">Richard J. Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_M/0/1/0/all/0/1">Ming Y. Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Shaban_M/0/1/0/all/0/1">Muhammad Shaban</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_C/0/1/0/all/0/1">Chengkuan Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_T/0/1/0/all/0/1">Tiffany Y. Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Williamson_D/0/1/0/all/0/1">Drew F. K. Williamson</a>, <a href="http://arxiv.org/find/eess/1/au:+Mahmood_F/0/1/0/all/0/1">Faisal Mahmood</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13048">
                                    <div class="article-summary-box-inner">
                                        <span>Cancer prognostication is a challenging task in computational pathology that
requires context-aware representations of histology features to adequately
infer patient survival. Despite the advancements made in weakly-supervised deep
learning, many approaches are not context-aware and are unable to model
important morphological feature interactions between cell identities and tissue
types that are prognostic for patient survival. In this work, we present
Patch-GCN, a context-aware, spatially-resolved patch-based graph convolutional
network that hierarchically aggregates instance-level histology features to
model local- and global-level topological structures in the tumor
microenvironment. We validate Patch-GCN with 4,370 gigapixel WSIs across five
different cancer types from the Cancer Genome Atlas (TCGA), and demonstrate
that Patch-GCN outperforms all prior weakly-supervised approaches by
3.58-9.46%. Our code and corresponding models are publicly available at
https://github.com/mahmoodlab/Patch-GCN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aug3D-RPN: Improving Monocular 3D Object Detection by Synthetic Images with Virtual Depth. (arXiv:2107.13269v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Chenhang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xian-Sheng Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13269">
                                    <div class="article-summary-box-inner">
                                        <span>Current geometry-based monocular 3D object detection models can efficiently
detect objects by leveraging perspective geometry, but their performance is
limited due to the absence of accurate depth information. Though this issue can
be alleviated in a depth-based model where a depth estimation module is plugged
to predict depth information before 3D box reasoning, the introduction of such
module dramatically reduces the detection speed. Instead of training a costly
depth estimator, we propose a rendering module to augment the training data by
synthesizing images with virtual-depths. The rendering module takes as input
the RGB image and its corresponding sparse depth image, outputs a variety of
photo-realistic synthetic images, from which the detection model can learn more
discriminative features to adapt to the depth changes of the objects. Besides,
we introduce an auxiliary module to improve the detection model by jointly
optimizing it through a depth estimation task. Both modules are working in the
training time and no extra computation will be introduced to the detection
model. Experiments show that by working with our proposed modules, a
geometry-based model can represent the leading accuracy on the KITTI 3D
detection benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Retinal Microvasculature as Biomarker for Diabetes and Cardiovascular Diseases. (arXiv:2107.13157v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Trivedi_A/0/1/0/all/0/1">Anusua Trivedi</a>, <a href="http://arxiv.org/find/eess/1/au:+Desbiens_J/0/1/0/all/0/1">Jocelyn Desbiens</a>, <a href="http://arxiv.org/find/eess/1/au:+Gross_R/0/1/0/all/0/1">Ron Gross</a>, <a href="http://arxiv.org/find/eess/1/au:+Gupta_S/0/1/0/all/0/1">Sunil Gupta</a>, <a href="http://arxiv.org/find/eess/1/au:+Dodhia_R/0/1/0/all/0/1">Rahul Dodhia</a>, <a href="http://arxiv.org/find/eess/1/au:+Ferres_J/0/1/0/all/0/1">Juan Lavista Ferres</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13157">
                                    <div class="article-summary-box-inner">
                                        <span>Purpose: To demonstrate that retinal microvasculature per se is a reliable
biomarker for Diabetic Retinopathy (DR) and, by extension, cardiovascular
diseases. Methods: Deep Learning Convolutional Neural Networks (CNN) applied to
color fundus images for semantic segmentation of the blood vessels and severity
classification on both vascular and full images. Vessel reconstruction through
harmonic descriptors is also used as a smoothing and de-noising tool. The
mathematical background of the theory is also outlined. Results: For diabetic
patients, at least 93.8% of DR No-Refer vs. Refer classification can be related
to vasculature defects. As for the Non-Sight Threatening vs. Sight Threatening
case, the ratio is as high as 96.7%. Conclusion: In the case of DR, most of the
disease biomarkers are related topologically to the vasculature. Translational
Relevance: Experiments conducted on eye blood vasculature reconstruction as a
biomarker shows a strong correlation between vasculature shape and later stages
of DR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exceeding the Limits of Visual-Linguistic Multi-Task Learning. (arXiv:2107.13054v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lundgaard_K/0/1/0/all/0/1">Keld T. Lundgaard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13054">
                                    <div class="article-summary-box-inner">
                                        <span>By leveraging large amounts of product data collected across hundreds of live
e-commerce websites, we construct 1000 unique classification tasks that share
similarly-structured input data, comprised of both text and images. These
classification tasks focus on learning the product hierarchy of different
e-commerce websites, causing many of them to be correlated. Adopting a
multi-modal transformer model, we solve these tasks in unison using multi-task
learning (MTL). Extensive experiments are presented over an initial 100-task
dataset to reveal best practices for &quot;large-scale MTL&quot; (i.e., MTL with more
than 100 tasks). From these experiments, a final, unified methodology is
derived, which is composed of both best practices and new proposals such as
DyPa, a simple heuristic for automatically allocating task-specific parameters
to tasks that could benefit from extra capacity. Using our large-scale MTL
methodology, we successfully train a single model across all 1000 tasks in our
dataset while using minimal task specific parameters, thereby showing that it
is possible to extend several orders of magnitude beyond current efforts in
MTL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MixFaceNets: Extremely Efficient Face Recognition Networks. (arXiv:2107.13046v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boutros_F/0/1/0/all/0/1">Fadi Boutros</a>, <a href="http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1">Naser Damer</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1">Meiling Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirchbuchner_F/0/1/0/all/0/1">Florian Kirchbuchner</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuijper_A/0/1/0/all/0/1">Arjan Kuijper</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13046">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a set of extremely efficient and high throughput
models for accurate face verification, MixFaceNets which are inspired by Mixed
Depthwise Convolutional Kernels. Extensive experiment evaluations on Label Face
in the Wild (LFW), Age-DB, MegaFace, and IARPA Janus Benchmarks IJB-B and IJB-C
datasets have shown the effectiveness of our MixFaceNets for applications
requiring extremely low computational complexity. Under the same level of
computation complexity (&lt; 500M FLOPs), our MixFaceNets outperform
MobileFaceNets on all the evaluated datasets, achieving 99.60% accuracy on LFW,
97.05% accuracy on AgeDB-30, 93.60 TAR (at FAR1e-6) on MegaFace, 90.94 TAR (at
FAR1e-4) on IJB-B and 93.08 TAR (at FAR1e-4) on IJB-C. With computational
complexity between 500M and 1G FLOPs, our MixFaceNets achieved results
comparable to the top-ranked models, while using significantly fewer FLOPs and
less computation overhead, which proves the practical value of our proposed
MixFaceNets. All training codes, pre-trained models, and training logs have
been made available https://github.com/fdbtrs/mixfacenets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accurate Grid Keypoint Learning for Efficient Video Prediction. (arXiv:2107.13170v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiaojie Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yueming Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Q/0/1/0/all/0/1">Qi Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Chi-Wing Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Heng_P/0/1/0/all/0/1">Pheng-Ann Heng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13170">
                                    <div class="article-summary-box-inner">
                                        <span>Video prediction methods generally consume substantial computing resources in
training and deployment, among which keypoint-based approaches show promising
improvement in efficiency by simplifying dense image prediction to light
keypoint prediction. However, keypoint locations are often modeled only as
continuous coordinates, so noise from semantically insignificant deviations in
videos easily disrupt learning stability, leading to inaccurate keypoint
modeling. In this paper, we design a new grid keypoint learning framework,
aiming at a robust and explainable intermediate keypoint representation for
long-term efficient video prediction. We have two major technical
contributions. First, we detect keypoints by jumping among candidate locations
in our raised grid space and formulate a condensation loss to encourage
meaningful keypoints with strong representative capability. Second, we
introduce a 2D binary map to represent the detected grid keypoints and then
suggest propagating keypoint locations with stochasticity by selecting entries
in the discrete grid space, thus preserving the spatial structure of keypoints
in the longterm horizon for better future frame generation. Extensive
experiments verify that our method outperforms the state-ofthe-art stochastic
video prediction methods while saves more than 98% of computing resources. We
also demonstrate our method on a robotic-assisted surgery dataset with
promising results. Our code is available at
https://github.com/xjgaocs/Grid-Keypoint-Learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Thorough Review on Recent Deep Learning Methodologies for Image Captioning. (arXiv:2107.13114v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elhagry_A/0/1/0/all/0/1">Ahmed Elhagry</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadaoui_K/0/1/0/all/0/1">Karima Kadaoui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13114">
                                    <div class="article-summary-box-inner">
                                        <span>Image Captioning is a task that combines computer vision and natural language
processing, where it aims to generate descriptive legends for images. It is a
two-fold process relying on accurate image understanding and correct language
understanding both syntactically and semantically. It is becoming increasingly
difficult to keep up with the latest research and findings in the field of
image captioning due to the growing amount of knowledge available on the topic.
There is not, however, enough coverage of those findings in the available
review papers. We perform in this paper a run-through of the current
techniques, datasets, benchmarks and evaluation metrics used in image
captioning. The current research on the field is mostly focused on deep
learning-based methods, where attention mechanisms along with deep
reinforcement and adversarial learning appear to be in the forefront of this
research topic. In this paper, we review recent methodologies such as UpDown,
OSCAR, VIVO, Meta Learning and a model that uses conditional generative
adversarial nets. Although the GAN-based model achieves the highest score,
UpDown represents an important basis for image captioning and OSCAR and VIVO
are more useful as they use novel object captioning. This review paper serves
as a roadmap for researchers to keep up to date with the latest contributions
made in the field of image caption generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Monocular Depth Estimation in Highly Complex Environments. (arXiv:2107.13137v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chaoqiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Qiyu Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13137">
                                    <div class="article-summary-box-inner">
                                        <span>Previous unsupervised monocular depth estimation methods mainly focus on the
day-time scenario, and their frameworks are driven by warped photometric
consistency. While in some challenging environments, like night, rainy night or
snowy winter, the photometry of the same pixel on different frames is
inconsistent because of the complex lighting and reflection, so that the
day-time unsupervised frameworks cannot be directly applied to these complex
scenarios. In this paper, we investigate the problem of unsupervised monocular
depth estimation in certain highly complex scenarios. We address this
challenging problem by using domain adaptation, and a unified image
transfer-based adaptation framework is proposed based on monocular videos in
this paper. The depth model trained on day-time scenarios is adapted to
different complex scenarios. Instead of adapting the whole depth network, we
just consider the encoder network for lower computational complexity. The depth
models adapted by the proposed framework to different scenarios share the same
decoder, which is practical. Constraints on both feature space and output space
promote the framework to learn the key features for depth decoding, and the
smoothness loss is introduced into the adaptation framework for better depth
estimation performance. Extensive experiments show the effectiveness of the
proposed unsupervised framework in estimating the dense depth map from the
night-time, rainy night-time and snowy winter images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Experimenting with Self-Supervision using Rotation Prediction for Image Captioning. (arXiv:2107.13111v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elhagry_A/0/1/0/all/0/1">Ahmed Elhagry</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadaoui_K/0/1/0/all/0/1">Karima Kadaoui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13111">
                                    <div class="article-summary-box-inner">
                                        <span>Image captioning is a task in the field of Artificial Intelligence that
merges between computer vision and natural language processing. It is
responsible for generating legends that describe images, and has various
applications like descriptions used by assistive technology or indexing images
(for search engines for instance). This makes it a crucial topic in AI that is
undergoing a lot of research. This task however, like many others, is trained
on large images labeled via human annotation, which can be very cumbersome: it
needs manual effort, both financial and temporal costs, it is error-prone and
potentially difficult to execute in some cases (e.g. medical images). To
mitigate the need for labels, we attempt to use self-supervised learning, a
type of learning where models use the data contained within the images
themselves as labels. It is challenging to accomplish though, since the task is
two-fold: the images and captions come from two different modalities and
usually handled by different types of networks. It is thus not obvious what a
completely self-supervised solution would look like. How it would achieve
captioning in a comparable way to how self-supervision is applied today on
image recognition tasks is still an ongoing research topic. In this project, we
are using an encoder-decoder architecture where the encoder is a convolutional
neural network (CNN) trained on OpenImages dataset and learns image features in
a self-supervised fashion using the rotation pretext task. The decoder is a
Long Short-Term Memory (LSTM), and it is trained, along within the image
captioning model, on MS COCO dataset and is responsible of generating captions.
Our GitHub repository can be found:
https://github.com/elhagry1/SSL_ImageCaptioning_RotationPrediction</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Tale Of Two Long Tails. (arXiv:2107.13098v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dsouza_D/0/1/0/all/0/1">Daniel D&#x27;souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Nussbaum_Z/0/1/0/all/0/1">Zach Nussbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1">Chirag Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1">Sara Hooker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13098">
                                    <div class="article-summary-box-inner">
                                        <span>As machine learning models are increasingly employed to assist human
decision-makers, it becomes critical to communicate the uncertainty associated
with these model predictions. However, the majority of work on uncertainty has
focused on traditional probabilistic or ranking approaches - where the model
assigns low probabilities or scores to uncertain examples. While this captures
what examples are challenging for the model, it does not capture the underlying
source of the uncertainty. In this work, we seek to identify examples the model
is uncertain about and characterize the source of said uncertainty. We explore
the benefits of designing a targeted intervention - targeted data augmentation
of the examples where the model is uncertain over the course of training. We
investigate whether the rate of learning in the presence of additional
information differs between atypical and noisy examples? Our results show that
this is indeed the case, suggesting that well-designed interventions over the
course of training can be an effective way to characterize and distinguish
between different sources of uncertainty.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Divide-and-Assemble: Learning Block-wise Memory for Unsupervised Anomaly Detection. (arXiv:2107.13118v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Jinlei Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yingying Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Q/0/1/0/all/0/1">Qiaoyong Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_D/0/1/0/all/0/1">Di Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1">Shiliang Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hong Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13118">
                                    <div class="article-summary-box-inner">
                                        <span>Reconstruction-based methods play an important role in unsupervised anomaly
detection in images. Ideally, we expect a perfect reconstruction for normal
samples and poor reconstruction for abnormal samples. Since the
generalizability of deep neural networks is difficult to control, existing
models such as autoencoder do not work well. In this work, we interpret the
reconstruction of an image as a divide-and-assemble procedure. Surprisingly, by
varying the granularity of division on feature maps, we are able to modulate
the reconstruction capability of the model for both normal and abnormal
samples. That is, finer granularity leads to better reconstruction, while
coarser granularity leads to poorer reconstruction. With proper granularity,
the gap between the reconstruction error of normal and abnormal samples can be
maximized. The divide-and-assemble framework is implemented by embedding a
novel multi-scale block-wise memory module into an autoencoder network.
Besides, we introduce adversarial learning and explore the semantic latent
representation of the discriminator, which improves the detection of subtle
anomaly. We achieve state-of-the-art performance on the challenging MVTec AD
dataset. Remarkably, we improve the vanilla autoencoder model by 10.1% in terms
of the AUROC score.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Human Cell Classification in Sparse Datasets using Few-Shot Learning. (arXiv:2107.13093v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Walsh_R/0/1/0/all/0/1">Reece Walsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelpakey_M/0/1/0/all/0/1">Mohamed H. Abdelpakey</a>, <a href="http://arxiv.org/find/cs/1/au:+Shehata_M/0/1/0/all/0/1">Mohamed S. Shehata</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_M/0/1/0/all/0/1">Mostafa M.Mohamed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13093">
                                    <div class="article-summary-box-inner">
                                        <span>Classifying and analyzing human cells is a lengthy procedure, often involving
a trained professional. In an attempt to expedite this process, an active area
of research involves automating cell classification through use of deep
learning-based techniques. In practice, a large amount of data is required to
accurately train these deep learning models. However, due to the sparse human
cell datasets currently available, the performance of these models is typically
low. This study investigates the feasibility of using few-shot learning-based
techniques to mitigate the data requirements for accurate training. The study
is comprised of three parts: First, current state-of-the-art few-shot learning
techniques are evaluated on human cell classification. The selected techniques
are trained on a non-medical dataset and then tested on two out-of-domain,
human cell datasets. The results indicate that, overall, the test accuracy of
state-of-the-art techniques decreased by at least 30% when transitioning from a
non-medical dataset to a medical dataset. Second, this study evaluates the
potential benefits, if any, to varying the backbone architecture and training
schemes in current state-of-the-art few-shot learning techniques when used in
human cell classification. Even with these variations, the overall test
accuracy decreased from 88.66% on non-medical datasets to 44.13% at best on the
medical datasets. Third, this study presents future directions for using
few-shot learning in human cell classification. In general, few-shot learning
in its current state performs poorly on human cell classification. The study
proves that attempts to modify existing network architectures are not effective
and concludes that future research effort should be focused on improving
robustness towards out-of-domain testing using optimization-based or
self-supervised few-shot learning techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Insights from Generative Modeling for Neural Video Compression. (arXiv:2107.13136v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yang_R/0/1/0/all/0/1">Ruihan Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1">Yibo Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Marino_J/0/1/0/all/0/1">Joseph Marino</a>, <a href="http://arxiv.org/find/eess/1/au:+Mandt_S/0/1/0/all/0/1">Stephan Mandt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13136">
                                    <div class="article-summary-box-inner">
                                        <span>While recent machine learning research has revealed connections between deep
generative models such as VAEs and rate-distortion losses used in learned
compression, most of this work has focused on images. In a similar spirit, we
view recently proposed neural video coding algorithms through the lens of deep
autoregressive and latent variable modeling. We present recent neural video
codecs as instances of a generalized stochastic temporal autoregressive
transform, and propose new avenues for further improvements inspired by
normalizing flows and structured priors. We propose several architectures that
yield state-of-the-art video compression performance on full-resolution video
and discuss their tradeoffs and ablations. In particular, we propose (i)
improved temporal autoregressive transforms, (ii) improved entropy models with
structured and temporal dependencies, and (iii) variable bitrate versions of
our algorithms. Since our improvements are compatible with a large class of
existing models, we provide further evidence that the generative modeling
viewpoint can advance the neural video coding field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image color correction, enhancement, and editing. (arXiv:2107.13117v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Afifi_M/0/1/0/all/0/1">Mahmoud Afifi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13117">
                                    <div class="article-summary-box-inner">
                                        <span>This thesis presents methods and approaches to image color correction, color
enhancement, and color editing. To begin, we study the color correction problem
from the standpoint of the camera&#x27;s image signal processor (ISP). A camera&#x27;s
ISP is hardware that applies a series of in-camera image processing and color
manipulation steps, many of which are nonlinear in nature, to render the
initial sensor image to its final photo-finished representation saved in the
8-bit standard RGB (sRGB) color space. As white balance (WB) is one of the
major procedures applied by the ISP for color correction, this thesis presents
two different methods for ISP white balancing. Afterward, we discuss another
scenario of correcting and editing image colors, where we present a set of
methods to correct and edit WB settings for images that have been improperly
white-balanced by the ISP. Then, we explore another factor that has a
significant impact on the quality of camera-rendered colors, in which we
outline two different methods to correct exposure errors in camera-rendered
images. Lastly, we discuss post-capture auto color editing and manipulation. In
particular, we propose auto image recoloring methods to generate different
realistic versions of the same camera-rendered image with new colors. Through
extensive evaluations, we demonstrate that our methods provide superior
solutions compared to existing alternatives targeting color correction, color
enhancement, and color editing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PlaneTR: Structure-Guided Transformers for 3D Plane Recovery. (arXiv:2107.13108v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_B/0/1/0/all/0/1">Bin Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_N/0/1/0/all/0/1">Nan Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1">Song Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tianfu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_G/0/1/0/all/0/1">Gui-Song Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13108">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a neural network built upon Transformers, namely PlaneTR,
to simultaneously detect and reconstruct planes from a single image. Different
from previous methods, PlaneTR jointly leverages the context information and
the geometric structures in a sequence-to-sequence way to holistically detect
plane instances in one forward pass. Specifically, we represent the geometric
structures as line segments and conduct the network with three main components:
(i) context and line segments encoders, (ii) a structure-guided plane decoder,
(iii) a pixel-wise plane embedding decoder. Given an image and its detected
line segments, PlaneTR generates the context and line segment sequences via two
specially designed encoders and then feeds them into a Transformers-based
decoder to directly predict a sequence of plane instances by simultaneously
considering the context and global structure cues. Finally, the pixel-wise
embeddings are computed to assign each pixel to one predicted plane instance
which is nearest to it in embedding space. Comprehensive experiments
demonstrate that PlaneTR achieves a state-of-the-art performance on the ScanNet
and NYUv2 datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DCL: Differential Contrastive Learning for Geometry-Aware Depth Synthesis. (arXiv:2107.13087v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yanchao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuefan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Youyi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">C. Karen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas Guibas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13087">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a method for realistic depth synthesis that learns diverse
variations from the real depth scans and ensures geometric consistency for
effective synthetic-to-real transfer. Unlike general image synthesis pipelines,
where geometries are mostly ignored, we treat geometries carried by the depth
based on their own existence. We propose differential contrastive learning that
explicitly enforces the underlying geometric properties to be invariant
regarding the real variations been learned. The resulting depth synthesis
method is task-agnostic and can be used for training any task-specific networks
with synthetic labels. We demonstrate the effectiveness of the proposed method
by extensive evaluations on downstream real-world geometric reasoning tasks. We
show our method achieves better synthetic-to-real transfer performance than the
other state-of-the-art. When fine-tuned on a small number of real-world
annotations, our method can even surpass the fully supervised baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is Object Detection Necessary for Human-Object Interaction Recognition?. (arXiv:2107.13083v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Ying Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinpeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lijuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Pei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_J/0/1/0/all/0/1">Jenq-Neng Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13083">
                                    <div class="article-summary-box-inner">
                                        <span>This paper revisits human-object interaction (HOI) recognition at image level
without using supervisions of object location and human pose. We name it
detection-free HOI recognition, in contrast to the existing
detection-supervised approaches which rely on object and keypoint detections to
achieve state of the art. With our method, not only the detection supervision
is evitable, but superior performance can be achieved by properly using
image-text pre-training (such as CLIP) and the proposed Log-Sum-Exp Sign
(LSE-Sign) loss function. Specifically, using text embeddings of class labels
to initialize the linear classifier is essential for leveraging the CLIP
pre-trained image encoder. In addition, LSE-Sign loss facilitates learning from
multiple labels on an imbalanced dataset by normalizing gradients over all
classes in a softmax format. Surprisingly, our detection-free solution achieves
60.5 mAP on the HICO dataset, outperforming the detection-supervised state of
the art by 13.4 mAP</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Split for Evaluating True Zero-Shot Action Recognition. (arXiv:2107.13029v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gowda_S/0/1/0/all/0/1">Shreyank N Gowda</a>, <a href="http://arxiv.org/find/cs/1/au:+Sevilla_Lara_L/0/1/0/all/0/1">Laura Sevilla-Lara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kiyoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Keller_F/0/1/0/all/0/1">Frank Keller</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrbach_M/0/1/0/all/0/1">Marcus Rohrbach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13029">
                                    <div class="article-summary-box-inner">
                                        <span>Zero-shot action recognition is the task of classifying action categories
that are not available in the training set. In this setting, the standard
evaluation protocol is to use existing action recognition datasets (e.g.
UCF101) and randomly split the classes into seen and unseen. However, most
recent work builds on representations pre-trained on the Kinetics dataset,
where classes largely overlap with classes in the zero-shot evaluation
datasets. As a result, classes which are supposed to be unseen, are present
during supervised pre-training, invalidating the condition of the zero-shot
setting. A similar concern was previously noted several years ago for image
based zero-shot recognition, but has not been considered by the zero-shot
action recognition community. In this paper, we propose a new split for true
zero-shot action recognition with no overlap between unseen test classes and
training or pre-training classes. We benchmark several recent approaches on the
proposed True Zero-Shot (TruZe) Split for UCF101 and HMDB51, with zero-shot and
generalized zero-shot evaluation. In our extensive analysis we find that our
TruZe splits are significantly harder than comparable random splits as nothing
is leaking from pre-training, i.e. unseen performance is consistently lower, up
to 9.4% for zero-shot action recognition. In an additional evaluation we also
find that similar issues exist in the splits used in few-shot action
recognition, here we see differences of up to 14.1%. We publish our splits and
hope that our benchmark analysis will change how the field is evaluating zero-
and few-shot action recognition moving forward.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ranker-agnostic Contextual Position Bias Estimation. (arXiv:2107.13327v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mayor_O/0/1/0/all/0/1">Oriol Barbany Mayor</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellini_V/0/1/0/all/0/1">Vito Bellini</a>, <a href="http://arxiv.org/find/cs/1/au:+Buchholz_A/0/1/0/all/0/1">Alexander Buchholz</a>, <a href="http://arxiv.org/find/cs/1/au:+Benedetto_G/0/1/0/all/0/1">Giuseppe Di Benedetto</a>, <a href="http://arxiv.org/find/cs/1/au:+Granziol_D/0/1/0/all/0/1">Diego Marco Granziol</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruffini_M/0/1/0/all/0/1">Matteo Ruffini</a>, <a href="http://arxiv.org/find/cs/1/au:+Stein_Y/0/1/0/all/0/1">Yannik Stein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13327">
                                    <div class="article-summary-box-inner">
                                        <span>Learning-to-rank (LTR) algorithms are ubiquitous and necessary to explore the
extensive catalogs of media providers. To avoid the user examining all the
results, its preferences are used to provide a subset of relatively small size.
The user preferences can be inferred from the interactions with the presented
content if explicit ratings are unavailable. However, directly using implicit
feedback can lead to learning wrong relevance models and is known as biased
LTR. The mismatch between implicit feedback and true relevances is due to
various nuisances, with position bias one of the most relevant. Position bias
models consider that the lack of interaction with a presented item is not only
attributed to the item being irrelevant but because the item was not examined.
This paper introduces a method for modeling the probability of an item being
seen in different contexts, e.g., for different users, with a single estimator.
Our suggested method, denoted as contextual (EM)-based regression, is
ranker-agnostic and able to correctly learn the latent examination
probabilities while only using implicit feedback. Our empirical results
indicate that the method introduced in this paper outperforms other existing
position bias estimators in terms of relative error when the examination
probability varies across queries. Moreover, the estimated values provide a
ranking performance boost when used to debias the implicit ranking data even if
there is no context dependency on the examination probabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Payload Optimization Method for Federated Recommender Systems. (arXiv:2107.13078v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1">Farwa K. Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Flanagan_A/0/1/0/all/0/1">Adrian Flanagan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1">Kuan E. Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alamgir_Z/0/1/0/all/0/1">Zareen Alamgir</a>, <a href="http://arxiv.org/find/cs/1/au:+Ammad_Ud_Din_M/0/1/0/all/0/1">Muhammad Ammad-Ud-Din</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13078">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the payload optimization method for federated recommender
systems (FRS). In federated learning (FL), the global model payload that is
moved between the server and users depends on the number of items to recommend.
The model payload grows when there is an increasing number of items. This
becomes challenging for an FRS if it is running in production mode. To tackle
the payload challenge, we formulated a multi-arm bandit solution that selected
part of the global model and transmitted it to all users. The selection process
was guided by a novel reward function suitable for FL systems. So far as we are
aware, this is the first optimization method that seeks to address item
dependent payloads. The method was evaluated using three benchmark
recommendation datasets. The empirical validation confirmed that the proposed
method outperforms the simpler methods that do not benefit from the bandits for
the purpose of item selection. In addition, we have demonstrated the usefulness
of our proposed method by rigorously evaluating the effects of a payload
reduction on the recommendation performance degradation. Our method achieved up
to a 90\% reduction in model payload, yielding only a $\sim$4\% - 8\% loss in
the recommendation performance for highly sparse datasets</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pretrained Transformers for Text Ranking: BERT and Beyond. (arXiv:2010.06467v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jimmy Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Nogueira_R/0/1/0/all/0/1">Rodrigo Nogueira</a>, <a href="http://arxiv.org/find/cs/1/au:+Yates_A/0/1/0/all/0/1">Andrew Yates</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06467">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of text ranking is to generate an ordered list of texts retrieved
from a corpus in response to a query. Although the most common formulation of
text ranking is search, instances of the task can also be found in many natural
language processing applications. This survey provides an overview of text
ranking with neural network architectures known as transformers, of which BERT
is the best-known example. The combination of transformers and self-supervised
pretraining has been responsible for a paradigm shift in natural language
processing (NLP), information retrieval (IR), and beyond. In this survey, we
provide a synthesis of existing work as a single point of entry for
practitioners who wish to gain a better understanding of how to apply
transformers to text ranking problems and researchers who wish to pursue work
in this area. We cover a wide range of modern techniques, grouped into two
high-level categories: transformer models that perform reranking in multi-stage
architectures and dense retrieval techniques that perform ranking directly.
There are two themes that pervade our survey: techniques for handling long
documents, beyond typical sentence-by-sentence processing in NLP, and
techniques for addressing the tradeoff between effectiveness (i.e., result
quality) and efficiency (e.g., query latency, model and index size). Although
transformer architectures and pretraining techniques are recent innovations,
many aspects of how they are applied to text ranking are relatively well
understood and represent mature techniques. However, there remain many open
research questions, and thus in addition to laying out the foundations of
pretrained transformers for text ranking, this survey also attempts to
prognosticate where the field is heading.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reenvisioning Collaborative Filtering vs Matrix Factorization. (arXiv:2107.13472v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anelli_V/0/1/0/all/0/1">Vito Walter Anelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellogin_A/0/1/0/all/0/1">Alejandro Bellog&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1">Tommaso Di Noia</a>, <a href="http://arxiv.org/find/cs/1/au:+Pomo_C/0/1/0/all/0/1">Claudio Pomo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13472">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering models based on matrix factorization and learned
similarities using Artificial Neural Networks (ANNs) have gained significant
attention in recent years. This is, in part, because ANNs have demonstrated
good results in a wide variety of recommendation tasks. The introduction of
ANNs within the recommendation ecosystem has been recently questioned, raising
several comparisons in terms of efficiency and effectiveness. One aspect most
of these comparisons have in common is their focus on accuracy, neglecting
other evaluation dimensions important for the recommendation, such as novelty,
diversity, or accounting for biases. We replicate experiments from three papers
that compare Neural Collaborative Filtering (NCF) and Matrix Factorization
(MF), to extend the analysis to other evaluation dimensions. Our contribution
shows that the experiments are entirely reproducible, and we extend the study
including other accuracy metrics and two statistical hypothesis tests. We
investigated the Diversity and Novelty of the recommendations, showing that MF
provides a better accuracy also on the long tail, although NCF provides a
better item coverage and more diversified recommendations. We discuss the bias
effect generated by the tested methods. They show a relatively small bias, but
other recommendation baselines, with competitive accuracy performance,
consistently show to be less affected by this issue. This is the first work, to
the best of our knowledge, where several evaluation dimensions have been
explored for an array of SOTA algorithms covering recent adaptations of ANNs
and MF. Hence, we show the potential these techniques may have on
beyond-accuracy evaluation while analyzing the effect on reproducibility these
complementary dimensions may spark. Available at
github.com/sisinflab/Reenvisioning-the-comparison-between-Neural-Collaborative-Filtering-and-Matrix-Factorization</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding and Generalizing Monotonic Proximity Graphs for Approximate Nearest Neighbor Search. (arXiv:2107.13052v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1">Dantong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Minjia Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13052">
                                    <div class="article-summary-box-inner">
                                        <span>Graph-based algorithms have shown great empirical potential for the
approximate nearest neighbor (ANN) search problem. Currently, graph-based ANN
search algorithms are designed mainly using heuristics, whereas theoretical
analysis of such algorithms is quite lacking. In this paper, we study a
fundamental model of proximity graphs used in graph-based ANN search, called
Monotonic Relative Neighborhood Graph (MRNG), from a theoretical perspective.
We use mathematical proofs to explain why proximity graphs that are built based
on MRNG tend to have good searching performance. We also run experiments on
MRNG and graphs generalizing MRNG to obtain a deeper understanding of the
model. Our experiments give guidance on how to approximate and generalize MRNG
to build proximity graphs on a large scale. In addition, we discover and study
a hidden structure of MRNG called conflicting nodes, and we give theoretical
evidence how conflicting nodes could be used to improve ANN search methods that
are based on MRNG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Red Dragon AI at TextGraphs 2021 Shared Task: Multi-Hop Inference Explanation Regeneration by Matching Expert Ratings. (arXiv:2107.13031v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalyan_V/0/1/0/all/0/1">Vivek Kalyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Witteveen_S/0/1/0/all/0/1">Sam Witteveen</a>, <a href="http://arxiv.org/find/cs/1/au:+Andrews_M/0/1/0/all/0/1">Martin Andrews</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13031">
                                    <div class="article-summary-box-inner">
                                        <span>Creating explanations for answers to science questions is a challenging task
that requires multi-hop inference over a large set of fact sentences. This
year, to refocus the Textgraphs Shared Task on the problem of gathering
relevant statements (rather than solely finding a single &#x27;correct path&#x27;), the
WorldTree dataset was augmented with expert ratings of &#x27;relevance&#x27; of
statements to each overall explanation. Our system, which achieved second place
on the Shared Task leaderboard, combines initial statement retrieval; language
models trained to predict the relevance scores; and ensembling of a number of
the resulting rankings. Our code implementation is made available at
https://github.com/mdda/worldtree_corpus/tree/textgraphs_2021</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Case Study on Sampling Strategies for Evaluating Neural Sequential Item Recommendation Models. (arXiv:2107.13045v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dallmann_A/0/1/0/all/0/1">Alexander Dallmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Zoller_D/0/1/0/all/0/1">Daniel Zoller</a>, <a href="http://arxiv.org/find/cs/1/au:+Hotho_A/0/1/0/all/0/1">Andreas Hotho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13045">
                                    <div class="article-summary-box-inner">
                                        <span>At the present time, sequential item recommendation models are compared by
calculating metrics on a small item subset (target set) to speed up
computation. The target set contains the relevant item and a set of negative
items that are sampled from the full item set. Two well-known strategies to
sample negative items are uniform random sampling and sampling by popularity to
better approximate the item frequency distribution in the dataset. Most
recently published papers on sequential item recommendation rely on sampling by
popularity to compare the evaluated models. However, recent work has already
shown that an evaluation with uniform random sampling may not be consistent
with the full ranking, that is, the model ranking obtained by evaluating a
metric using the full item set as target set, which raises the question whether
the ranking obtained by sampling by popularity is equal to the full ranking. In
this work, we re-evaluate current state-of-the-art sequential recommender
models from the point of view, whether these sampling strategies have an impact
on the final ranking of the models. We therefore train four recently proposed
sequential recommendation models on five widely known datasets. For each
dataset and model, we employ three evaluation strategies. First, we compute the
full model ranking. Then we evaluate all models on a target set sampled by the
two different sampling strategies, uniform random sampling and sampling by
popularity with the commonly used target set size of 100, compute the model
ranking for each strategy and compare them with each other. Additionally, we
vary the size of the sampled target set. Overall, we find that both sampling
strategies can produce inconsistent rankings compared with the full ranking of
the models. Furthermore, both sampling by popularity and uniform random
sampling do not consistently produce the same ranking ...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Drug-Target Interaction Prediction via Ensemble Modeling and Transfer Learning. (arXiv:2107.00719v2 [q-bio.BM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Kao_P/0/1/0/all/0/1">Po-Yu Kao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kao_S/0/1/0/all/0/1">Shu-Min Kao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Huang_N/0/1/0/all/0/1">Nan-Lan Huang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lin_Y/0/1/0/all/0/1">Yen-Chu Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00719">
                                    <div class="article-summary-box-inner">
                                        <span>Drug-target interaction (DTI) prediction plays a crucial role in drug
discovery, and deep learning approaches have achieved state-of-the-art
performance in this field. We introduce an ensemble of deep learning models
(EnsembleDLM) for DTI prediction. EnsembleDLM only uses the sequence
information of chemical compounds and proteins, and it aggregates the
predictions from multiple deep neural networks. This approach not only achieves
state-of-the-art performance in Davis and KIBA datasets but also reaches
cutting-edge performance in the cross-domain applications across different
bio-activity types and different protein classes. We also demonstrate that
EnsembleDLM achieves a good performance (Pearson correlation coefficient and
concordance index &gt; 0.8) in the new domain with approximately 50% transfer
learning data, i.e., the training set has twice as much data as the test set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Tale Of Two Long Tails. (arXiv:2107.13098v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dsouza_D/0/1/0/all/0/1">Daniel D&#x27;souza</a>, <a href="http://arxiv.org/find/cs/1/au:+Nussbaum_Z/0/1/0/all/0/1">Zach Nussbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_C/0/1/0/all/0/1">Chirag Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1">Sara Hooker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13098">
                                    <div class="article-summary-box-inner">
                                        <span>As machine learning models are increasingly employed to assist human
decision-makers, it becomes critical to communicate the uncertainty associated
with these model predictions. However, the majority of work on uncertainty has
focused on traditional probabilistic or ranking approaches - where the model
assigns low probabilities or scores to uncertain examples. While this captures
what examples are challenging for the model, it does not capture the underlying
source of the uncertainty. In this work, we seek to identify examples the model
is uncertain about and characterize the source of said uncertainty. We explore
the benefits of designing a targeted intervention - targeted data augmentation
of the examples where the model is uncertain over the course of training. We
investigate whether the rate of learning in the presence of additional
information differs between atypical and noisy examples? Our results show that
this is indeed the case, suggesting that well-designed interventions over the
course of training can be an effective way to characterize and distinguish
between different sources of uncertainty.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Know Thyself: Transferable Visuomotor Control Through Robot-Awareness. (arXiv:2107.09047v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1">Edward S. Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kun Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rybkin_O/0/1/0/all/0/1">Oleh Rybkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1">Dinesh Jayaraman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09047">
                                    <div class="article-summary-box-inner">
                                        <span>Training visuomotor robot controllers from scratch on a new robot typically
requires generating large amounts of robot-specific data. Could we leverage
data previously collected on another robot to reduce or even completely remove
this need for robot-specific data? We propose a &quot;robot-aware&quot; solution paradigm
that exploits readily available robot &quot;self-knowledge&quot; such as proprioception,
kinematics, and camera calibration to achieve this. First, we learn modular
dynamics models that pair a transferable, robot-agnostic world dynamics module
with a robot-specific, analytical robot dynamics module. Next, we set up visual
planning costs that draw a distinction between the robot self and the world.
Our experiments on tabletop manipulation tasks in simulation and on real robots
demonstrate that these plug-in improvements dramatically boost the
transferability of visuomotor controllers, even permitting zero-shot transfer
onto new robots for the very first time. Project website:
https://hueds.github.io/rac/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Attributed Graph Representations with Communicative Message Passing Transformer. (arXiv:2107.08773v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jianwen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Shuangjia Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Ying Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1">Jiahua Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuedong Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08773">
                                    <div class="article-summary-box-inner">
                                        <span>Constructing appropriate representations of molecules lies at the core of
numerous tasks such as material science, chemistry and drug designs. Recent
researches abstract molecules as attributed graphs and employ graph neural
networks (GNN) for molecular representation learning, which have made
remarkable achievements in molecular graph modeling. Albeit powerful, current
models either are based on local aggregation operations and thus miss
higher-order graph properties or focus on only node information without fully
using the edge information. For this sake, we propose a Communicative Message
Passing Transformer (CoMPT) neural network to improve the molecular graph
representation by reinforcing message interactions between nodes and edges
based on the Transformer architecture. Unlike the previous transformer-style
GNNs that treat molecules as fully connected graphs, we introduce a message
diffusion mechanism to leverage the graph connectivity inductive bias and
reduce the message enrichment explosion. Extensive experiments demonstrated
that the proposed model obtained superior performances (around 4$\%$ on
average) against state-of-the-art baselines on seven chemical property datasets
(graph-level tasks) and two chemical shift datasets (node-level tasks). Further
visualization studies also indicated a better representation capacity achieved
by our model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CiwGAN and fiwGAN: Encoding information in acoustic data to model lexical learning with Generative Adversarial Networks. (arXiv:2006.02951v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Begus_G/0/1/0/all/0/1">Ga&#x161;per Begu&#x161;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.02951">
                                    <div class="article-summary-box-inner">
                                        <span>How can deep neural networks encode information that corresponds to words in
human speech into raw acoustic data? This paper proposes two neural network
architectures for modeling unsupervised lexical learning from raw acoustic
inputs, ciwGAN (Categorical InfoWaveGAN) and fiwGAN (Featural InfoWaveGAN),
that combine a Deep Convolutional GAN architecture for audio data (WaveGAN;
arXiv:1705.07904) with an information theoretic extension of GAN -- InfoGAN
(arXiv:1606.03657), and propose a new latent space structure that can model
featural learning simultaneously with a higher level classification and allows
for a very low-dimension vector representation of lexical items. Lexical
learning is modeled as emergent from an architecture that forces a deep neural
network to output data such that unique information is retrievable from its
acoustic outputs. The networks trained on lexical items from TIMIT learn to
encode unique information corresponding to lexical items in the form of
categorical variables in their latent space. By manipulating these variables,
the network outputs specific lexical items. The network occasionally outputs
innovative lexical items that violate training data, but are linguistically
interpretable and highly informative for cognitive modeling and neural network
interpretability. Innovative outputs suggest that phonetic and phonological
representations learned by the network can be productively recombined and
directly paralleled to productivity in human speech: a fiwGAN network trained
on &#x60;suit&#x27; and &#x60;dark&#x27; outputs innovative &#x60;start&#x27;, even though it never saw
&#x60;start&#x27; or even a [st] sequence in the training data. We also argue that
setting latent featural codes to values well beyond training range results in
almost categorical generation of prototypical lexical items and reveals
underlying values of each latent code.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flood Segmentation on Sentinel-1 SAR Imagery with Semi-Supervised Learning. (arXiv:2107.08369v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1">Sayak Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganju_S/0/1/0/all/0/1">Siddha Ganju</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08369">
                                    <div class="article-summary-box-inner">
                                        <span>Floods wreak havoc throughout the world, causing billions of dollars in
damages, and uprooting communities, ecosystems and economies. Accurate and
robust flood detection including delineating open water flood areas and
identifying flood levels can aid in disaster response and mitigation. However,
estimating flood levels remotely is of essence as physical access to flooded
areas is limited and the ability to deploy instruments in potential flood zones
can be dangerous. Aligning flood extent mapping with local topography can
provide a plan-of-action that the disaster response team can consider. Thus,
remote flood level estimation via satellites like Sentinel-1 can prove to be
remedial. The Emerging Techniques in Computational Intelligence (ETCI)
competition on Flood Detection tasked participants with predicting flooded
pixels after training with synthetic aperture radar (SAR) images in a
supervised setting. We use a cyclical approach involving two stages (1)
training an ensemble model of multiple UNet architectures with available high
and low confidence labeled data and, (2) generating pseudo labels or low
confidence labels on the unlabeled test dataset, and then, combining the
generated labels with the previously available high confidence labeled dataset.
This assimilated dataset is used for the next round of training ensemble
models. This cyclical process is repeated until the performance improvement
plateaus. Additionally, we post process our results with Conditional Random
Fields. Our approach sets a high score on the public leaderboard for the ETCI
competition with 0.7654 IoU. Our method, which we release with all the code
including trained models, can also be used as an open science benchmark for the
Sentinel-1 released dataset on GitHub. To the best of our knowledge we believe
this the first works to try out semi-supervised learning to improve flood
segmentation models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On automatic extraction of on-street parking spaces using park-out events data. (arXiv:2102.06758v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Navarro_B_J/0/1/0/all/0/1">J.-Emeterio Navarro-B</a>, <a href="http://arxiv.org/find/cs/1/au:+Gebert_M/0/1/0/all/0/1">Martin Gebert</a>, <a href="http://arxiv.org/find/cs/1/au:+Bielig_R/0/1/0/all/0/1">Ralf Bielig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06758">
                                    <div class="article-summary-box-inner">
                                        <span>This article proposes two different approaches to automatically create a map
for valid on-street car parking spaces. For this, we use car sharing park-out
events data. The first one uses spatial aggregation and the second a machine
learning algorithm. For the former, we chose rasterization and road sectioning;
for the latter we chose decision trees. We compare the results of these
approaches and discuss their advantages and disadvantages. Furthermore, we show
our results for a neighborhood in the city of Berlin and report a
classification accuracy of 91.6\% on the original imbalanced data. Finally, we
discuss further work; from gathering more data over a longer period of time to
fitting spatial Gaussian densities to the data and the usage of apps for manual
validation and annotation of parking spaces to improve ground truth data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate Bayesian Computation for an Explicit-Duration Hidden Markov Model of COVID-19 Hospital Trajectories. (arXiv:2105.00773v2 [stat.AP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Visani_G/0/1/0/all/0/1">Gian Marco Visani</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_A/0/1/0/all/0/1">Alexandra Hope Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_C/0/1/0/all/0/1">Cuong Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Kent_D/0/1/0/all/0/1">David M. Kent</a>, <a href="http://arxiv.org/find/stat/1/au:+Wong_J/0/1/0/all/0/1">John B. Wong</a>, <a href="http://arxiv.org/find/stat/1/au:+Cohen_J/0/1/0/all/0/1">Joshua T. Cohen</a>, <a href="http://arxiv.org/find/stat/1/au:+Hughes_M/0/1/0/all/0/1">Michael C. Hughes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00773">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of modeling constrained hospital resources in the
midst of the COVID-19 pandemic in order to inform decision-makers of future
demand and assess the societal value of possible interventions. For broad
applicability, we focus on the common yet challenging scenario where
patient-level data for a region of interest are not available. Instead, given
daily admissions counts, we model aggregated counts of observed resource use,
such as the number of patients in the general ward, in the intensive care unit,
or on a ventilator. In order to explain how individual patient trajectories
produce these counts, we propose an aggregate count explicit-duration hidden
Markov model, nicknamed the ACED-HMM, with an interpretable, compact
parameterization. We develop an Approximate Bayesian Computation approach that
draws samples from the posterior distribution over the model&#x27;s transition and
duration parameters given aggregate counts from a specific location, thus
adapting the model to a region or individual hospital site of interest. Samples
from this posterior can then be used to produce future forecasts of any counts
of interest. Using data from the United States and the United Kingdom, we show
our mechanistic approach provides competitive probabilistic forecasts for the
future even as the dynamics of the pandemic shift. Furthermore, we show how our
model provides insight about recovery probabilities or length of stay
distributions, and we suggest its potential to answer challenging what-if
questions about the societal value of possible interventions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partial Recovery in the Graph Alignment Problem. (arXiv:2007.00533v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Hall_G/0/1/0/all/0/1">Georgina Hall</a>, <a href="http://arxiv.org/find/stat/1/au:+Massoulie_L/0/1/0/all/0/1">Laurent Massouli&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.00533">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we consider the graph alignment problem, which is the problem
of recovering, given two graphs, a one-to-one mapping between nodes that
maximizes edge overlap. This problem can be viewed as a noisy version of the
well-known graph isomorphism problem and appears in many applications,
including social network deanonymization and cellular biology. Our focus here
is on partial recovery, i.e., we look for a one-to-one mapping which is correct
on a fraction of the nodes of the graph rather than on all of them, and we
assume that the two input graphs to the problem are correlated
Erd\H{o}s-R\&#x27;enyi graphs of parameters $(n,q,s)$. Our main contribution is then
to give necessary and sufficient conditions on $(n,q,s)$ under which partial
recovery is possible with high probability as the number of nodes $n$ goes to
infinity. In particular, we show that it is possible to achieve partial
recovery in the $nqs&#x3D;\Theta(1)$ regime under certain additional assumptions. An
interesting byproduct of the analysis techniques we develop to obtain the
sufficiency result in the partial recovery setting is a tighter analysis of the
maximum likelihood estimator for the graph alignment problem, which leads to
improved sufficient conditions for exact recovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gym-$\mu$RTS: Toward Affordable Full Game Real-time Strategy Games Research with Deep Reinforcement Learning. (arXiv:2105.13807v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shengyi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ontanon_S/0/1/0/all/0/1">Santiago Onta&#xf1;&#xf3;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Bamford_C/0/1/0/all/0/1">Chris Bamford</a>, <a href="http://arxiv.org/find/cs/1/au:+Grela_L/0/1/0/all/0/1">Lukasz Grela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13807">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, researchers have achieved great success in applying Deep
Reinforcement Learning (DRL) algorithms to Real-time Strategy (RTS) games,
creating strong autonomous agents that could defeat professional players in
StarCraft~II. However, existing approaches to tackle full games have high
computational costs, usually requiring the use of thousands of GPUs and CPUs
for weeks. This paper has two main contributions to address this issue: 1) We
introduce Gym-$\mu$RTS (pronounced &quot;gym-micro-RTS&quot;) as a fast-to-run RL
environment for full-game RTS research and 2) we present a collection of
techniques to scale DRL to play full-game $\mu$RTS as well as ablation studies
to demonstrate their empirical importance. Our best-trained bot can defeat
every $\mu$RTS bot we tested from the past $\mu$RTS competitions when working
in a single-map setting, resulting in a state-of-the-art DRL agent while only
taking about 60 hours of training using a single machine (one GPU, three vCPU,
16GB RAM). See the blog post at
https://wandb.ai/vwxyzjn/gym-microrts-paper/reports/Gym-RTS-Toward-Affordable-Deep-Reinforcement-Learning-Research-in-Real-Time-Strategy-Games--Vmlldzo2MDIzMTg
and the source code at https://github.com/vwxyzjn/gym-microrts-paper</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consensus-Based Optimization on the Sphere: Convergence to Global Minimizers and Machine Learning. (arXiv:2001.11988v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fornasier_M/0/1/0/all/0/1">Massimo Fornasier</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Hui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pareschi_L/0/1/0/all/0/1">Lorenzo Pareschi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunnen_P/0/1/0/all/0/1">Philippe S&#xfc;nnen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.11988">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the implementation of a new stochastic Kuramoto-Vicsek-type
model for global optimization of nonconvex functions on the sphere. This model
belongs to the class of Consensus-Based Optimization. In fact, particles move
on the sphere driven by a drift towards an instantaneous consensus point, which
is computed as a convex combination of particle locations, weighted by the cost
function according to Laplace&#x27;s principle, and it represents an approximation
to a global minimizer. The dynamics is further perturbed by a random vector
field to favor exploration, whose variance is a function of the distance of the
particles to the consensus point. In particular, as soon as the consensus is
reached the stochastic component vanishes. The main results of this paper are
about the proof of convergence of the numerical scheme to global minimizers
provided conditions of well-preparation of the initial datum. The proof
combines previous results of mean-field limit with a novel asymptotic analysis,
and classical convergence results of numerical methods for SDE. We present
several numerical experiments, which show that the algorithm proposed in the
present paper scales well with the dimension and is extremely versatile. To
quantify the performances of the new approach, we show that the algorithm is
able to perform essentially as good as ad hoc state of the art methods in
challenging problems in signal processing and machine learning, namely the
phase retrieval problem and the robust subspace detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Defensive Approximation: Enhancing CNNs Security through Approximate Computing. (arXiv:2006.07700v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guesmi_A/0/1/0/all/0/1">Amira Guesmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alouani_I/0/1/0/all/0/1">Ihsen Alouani</a>, <a href="http://arxiv.org/find/cs/1/au:+Khasawneh_K/0/1/0/all/0/1">Khaled Khasawneh</a>, <a href="http://arxiv.org/find/cs/1/au:+Baklouti_M/0/1/0/all/0/1">Mouna Baklouti</a>, <a href="http://arxiv.org/find/cs/1/au:+Frikha_T/0/1/0/all/0/1">Tarek Frikha</a>, <a href="http://arxiv.org/find/cs/1/au:+Abid_M/0/1/0/all/0/1">Mohamed Abid</a>, <a href="http://arxiv.org/find/cs/1/au:+Abu_Ghazaleh_N/0/1/0/all/0/1">Nael Abu-Ghazaleh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07700">
                                    <div class="article-summary-box-inner">
                                        <span>In the past few years, an increasing number of machine-learning and deep
learning structures, such as Convolutional Neural Networks (CNNs), have been
applied to solving a wide range of real-life problems. However, these
architectures are vulnerable to adversarial attacks. In this paper, we propose
for the first time to use hardware-supported approximate computing to improve
the robustness of machine learning classifiers. We show that our approximate
computing implementation achieves robustness across a wide range of attack
scenarios. Specifically, for black-box and grey-box attack scenarios, we show
that successful adversarial attacks against the exact classifier have poor
transferability to the approximate implementation. Surprisingly, the robustness
advantages also apply to white-box attacks where the attacker has access to the
internal implementation of the approximate classifier. We explain some of the
possible reasons for this robustness through analysis of the internal operation
of the approximate implementation. Furthermore, our approximate computing model
maintains the same level in terms of classification accuracy, does not require
retraining, and reduces resource utilization and energy consumption of the CNN.
We conducted extensive experiments on a set of strong adversarial attacks; We
empirically show that the proposed implementation increases the robustness of a
LeNet-5 and an Alexnet CNNs by up to 99% and 87%, respectively for strong
grey-box adversarial attacks along with up to 67% saving in energy consumption
due to the simpler nature of the approximate logic. We also show that a
white-box attack requires a remarkably higher noise budget to fool the
approximate classifier, causing an average of 4db degradation of the PSNR of
the input image relative to the images that succeed in fooling the exact
classifier</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring the Limits of Out-of-Distribution Detection. (arXiv:2106.03004v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fort_S/0/1/0/all/0/1">Stanislav Fort</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1">Balaji Lakshminarayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03004">
                                    <div class="article-summary-box-inner">
                                        <span>Near out-of-distribution detection (OOD) is a major challenge for deep neural
networks. We demonstrate that large-scale pre-trained transformers can
significantly improve the state-of-the-art (SOTA) on a range of near OOD tasks
across different data modalities. For instance, on CIFAR-100 vs CIFAR-10 OOD
detection, we improve the AUROC from 85% (current SOTA) to more than 96% using
Vision Transformers pre-trained on ImageNet-21k. On a challenging genomics OOD
detection benchmark, we improve the AUROC from 66% to 77% using transformers
and unsupervised pre-training. To further improve performance, we explore the
few-shot outlier exposure setting where a few examples from outlier classes may
be available; we show that pre-trained transformers are particularly
well-suited for outlier exposure, and that the AUROC of OOD detection on
CIFAR-100 vs CIFAR-10 can be improved to 98.7% with just 1 image per OOD class,
and 99.46% with 10 images per OOD class. For multi-modal image-text pre-trained
transformers such as CLIP, we explore a new way of using just the names of
outlier classes as a sole source of information without any accompanying
images, and show that this outperforms previous SOTA on standard vision OOD
benchmark tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3x as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results (e.g., a moderate size of 55.8M model solely trained
on 224x224 ImageNet-1K can obtain Top-1 accuracy 84.1%), while being more
scalable on high-resolution images. The source code and models are released at
https://github.com/NVIDIA/transformer-ls .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A novel Time-frequency Transformer and its Application in Fault Diagnosis of Rolling Bearings. (arXiv:2104.09079v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_Y/0/1/0/all/0/1">Yifei Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_M/0/1/0/all/0/1">Minping Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_Q/0/1/0/all/0/1">Qiuhua Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yudong Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09079">
                                    <div class="article-summary-box-inner">
                                        <span>The scope of data-driven fault diagnosis models is greatly improved through
deep learning (DL). However, the classical convolution and recurrent structure
have their defects in computational efficiency and feature representation,
while the latest Transformer architecture based on attention mechanism has not
been applied in this field. To solve these problems, we propose a novel
time-frequency Transformer (TFT) model inspired by the massive success of
standard Transformer in sequence processing. Specially, we design a fresh
tokenizer and encoder module to extract effective abstractions from the
time-frequency representation (TFR) of vibration signals. On this basis, a new
end-to-end fault diagnosis framework based on time-frequency Transformer is
presented in this paper. Through the case studies on bearing experimental
datasets, we constructed the optimal Transformer structure and verified the
performance of the diagnostic method. The superiority of the proposed method is
demonstrated in comparison with the benchmark model and other state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Molecular Embeddings in QSAR Modeling: Does it Make a Difference?. (arXiv:2104.02604v2 [q-bio.BM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Sabando_M/0/1/0/all/0/1">Mar&#xed;a Virginia Sabando</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ponzoni_I/0/1/0/all/0/1">Ignacio Ponzoni</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Milios_E/0/1/0/all/0/1">Evangelos E. Milios</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Soto_A/0/1/0/all/0/1">Axel J. Soto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02604">
                                    <div class="article-summary-box-inner">
                                        <span>With the consolidation of deep learning in drug discovery, several novel
algorithms for learning molecular representations have been proposed. Despite
the interest of the community in developing new methods for learning molecular
embeddings and their theoretical benefits, comparing molecular embeddings with
each other and with traditional representations is not straightforward, which
in turn hinders the process of choosing a suitable representation for QSAR
modeling. A reason behind this issue is the difficulty of conducting a fair and
thorough comparison of the different existing embedding approaches, which
requires numerous experiments on various datasets and training scenarios. To
close this gap, we reviewed the literature on methods for molecular embeddings
and reproduced three unsupervised and two supervised molecular embedding
techniques recently proposed in the literature. We compared these five methods
concerning their performance in QSAR scenarios using different classification
and regression datasets. We also compared these representations to traditional
molecular representations, namely molecular descriptors and fingerprints. As
opposed to the expected outcome, our experimental setup consisting of over
25,000 trained models and statistical tests revealed that the predictive
performance using molecular embeddings did not significantly surpass that of
traditional representations. While supervised embeddings yielded competitive
results compared to those using traditional molecular representations,
unsupervised embeddings tended to perform worse than traditional
representations. Our results highlight the need for conducting a careful
comparison and analysis of the different embedding techniques prior to using
them in drug design tasks, and motivate a discussion about the potential of
molecular embeddings in computer-aided drug design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Certifiable Machine Unlearning for Linear Models. (arXiv:2106.15093v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahadevan_A/0/1/0/all/0/1">Ananth Mahadevan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathioudakis_M/0/1/0/all/0/1">Michael Mathioudakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15093">
                                    <div class="article-summary-box-inner">
                                        <span>Machine unlearning is the task of updating machine learning (ML) models after
a subset of the training data they were trained on is deleted. Methods for the
task are desired to combine effectiveness and efficiency, i.e., they should
effectively &quot;unlearn&quot; deleted data, but in a way that does not require
excessive computation effort (e.g., a full retraining) for a small amount of
deletions. Such a combination is typically achieved by tolerating some amount
of approximation in the unlearning. In addition, laws and regulations in the
spirit of &quot;the right to be forgotten&quot; have given rise to requirements for
certifiability, i.e., the ability to demonstrate that the deleted data has
indeed been unlearned by the ML model.

In this paper, we present an experimental study of the three state-of-the-art
approximate unlearning methods for linear models and demonstrate the trade-offs
between efficiency, effectiveness and certifiability offered by each method. In
implementing the study, we extend some of the existing works and describe a
common ML pipeline to compare and evaluate the unlearning methods on six
real-world datasets and a variety of settings. We provide insights into the
effect of the quantity and distribution of the deleted data on ML models and
the performance of each unlearning method in different settings. We also
propose a practical online strategy to determine when the accumulated error
from approximate unlearning is large enough to warrant a full retrain of the ML
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A method to integrate and classify normal distributions. (arXiv:2012.14331v7 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Das_A/0/1/0/all/0/1">Abhranil Das</a>, <a href="http://arxiv.org/find/stat/1/au:+Geisler_W/0/1/0/all/0/1">Wilson S Geisler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14331">
                                    <div class="article-summary-box-inner">
                                        <span>Univariate and multivariate normal probability distributions are widely used
when modeling decisions under uncertainty. Computing the performance of such
models requires integrating these distributions over specific domains, which
can vary widely across models. Besides some special cases where these integrals
are easy to calculate, there exist no general analytical expressions, standard
numerical methods or software for these integrals. Here we present mathematical
results and open-source software that provide (i) the probability in any domain
of a normal in any dimensions with any parameters, (ii) the probability
density, cumulative distribution, and inverse cumulative distribution of any
function of a normal vector, (iii) the classification errors among any number
of normal distributions, the Bayes-optimal discriminability index and relation
to the operating characteristic, (iv) dimension reduction and visualizations
for such problems, and (v) tests for how reliably these methods may be used on
given data. We demonstrate these tools with vision research applications of
detecting occluding objects in natural scenes, and detecting camouflage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking ResNets: Improved Stacking Strategies With High Order Schemes. (arXiv:2103.15244v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhengbo Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zitang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Weilian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zizhang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamata_S/0/1/0/all/0/1">Sei-ichiro Kamata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15244">
                                    <div class="article-summary-box-inner">
                                        <span>Various deep neural network architectures (DNNs) maintain massive vital
records in computer vision. While drawing attention worldwide, the design of
the overall structure lacks general guidance. Based on the relationship between
DNN design and numerical differential equations, we performed a fair comparison
of the residual design with higher-order perspectives. We show that the widely
used DNN design strategy, constantly stacking a small design (usually 2-3
layers), could be easily improved, supported by solid theoretical knowledge and
with no extra parameters needed. We reorganise the residual design in
higher-order ways, which is inspired by the observation that many effective
networks can be interpreted as different numerical discretisations of
differential equations. The design of ResNet follows a relatively simple
scheme, which is Euler forward; however, the situation becomes complicated
rapidly while stacking. We suppose that stacked ResNet is somehow equalled to a
higher-order scheme; then, the current method of forwarding propagation might
be relatively weak compared with a typical high-order method such as
Runge-Kutta. We propose HO-ResNet to verify the hypothesis of widely used CV
benchmarks with sufficient experiments. Stable and noticeable increases in
performance are observed, and convergence and robustness are also improved. Our
stacking strategy improved ResNet-30 by 2.15 per cent and ResNet-58 by 2.35 per
cent on CIFAR-10, with the same settings and parameters. The proposed strategy
is fundamental and theoretical and can therefore be applied to any network as a
general guideline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Understanding Learning in Neural Networks with Linear Teachers. (arXiv:2101.02533v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sarussi_R/0/1/0/all/0/1">Roei Sarussi</a>, <a href="http://arxiv.org/find/cs/1/au:+Brutzkus_A/0/1/0/all/0/1">Alon Brutzkus</a>, <a href="http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1">Amir Globerson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02533">
                                    <div class="article-summary-box-inner">
                                        <span>Can a neural network minimizing cross-entropy learn linearly separable data?
Despite progress in the theory of deep learning, this question remains
unsolved. Here we prove that SGD globally optimizes this learning problem for a
two-layer network with Leaky ReLU activations. The learned network can in
principle be very complex. However, empirical evidence suggests that it often
turns out to be approximately linear. We provide theoretical support for this
phenomenon by proving that if network weights converge to two weight clusters,
this will imply an approximately linear decision boundary. Finally, we show a
condition on the optimization that leads to weight clustering. We provide
empirical results that validate our theoretical analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stronger Privacy for Federated Collaborative Filtering with Implicit Feedback. (arXiv:2105.03941v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Minto_L/0/1/0/all/0/1">Lorenzo Minto</a>, <a href="http://arxiv.org/find/cs/1/au:+Haller_M/0/1/0/all/0/1">Moritz Haller</a>, <a href="http://arxiv.org/find/cs/1/au:+Haddadi_H/0/1/0/all/0/1">Hamed Haddadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Livshits_B/0/1/0/all/0/1">Benjamin Livshits</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03941">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems are commonly trained on centrally collected user
interaction data like views or clicks. This practice however raises serious
privacy concerns regarding the recommender&#x27;s collection and handling of
potentially sensitive data. Several privacy-aware recommender systems have been
proposed in recent literature, but comparatively little attention has been
given to systems at the intersection of implicit feedback and privacy. To
address this shortcoming, we propose a practical federated recommender system
for implicit data under user-level local differential privacy (LDP). The
privacy-utility trade-off is controlled by parameters $\epsilon$ and $k$,
regulating the per-update privacy budget and the number of $\epsilon$-LDP
gradient updates sent by each user respectively. To further protect the user&#x27;s
privacy, we introduce a proxy network to reduce the fingerprinting surface by
anonymizing and shuffling the reports before forwarding them to the
recommender. We empirically demonstrate the effectiveness of our framework on
the MovieLens dataset, achieving up to Hit Ratio with K&#x3D;10 (HR@10) 0.68 on 50k
users with 5k items. Even on the full dataset, we show that it is possible to
achieve reasonable utility with HR@10&gt;0.5 without compromising user privacy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Decision-Making and Control in Power Systems: Tutorial, Review, and Vision. (arXiv:2102.01168v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_G/0/1/0/all/0/1">Guannan Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yujie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Low_S/0/1/0/all/0/1">Steven Low</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1">Na Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01168">
                                    <div class="article-summary-box-inner">
                                        <span>With large-scale integration of renewable generation and distributed energy
resources (DERs), modern power systems are confronted with new operational
challenges, such as growing complexity, increasing uncertainty, and aggravating
volatility. Meanwhile, more and more data are becoming available owing to the
widespread deployment of smart meters, smart sensors, and upgraded
communication networks. As a result, data-driven control techniques, especially
reinforcement learning (RL), have attracted surging attention in recent years.
In this paper, we provide a tutorial on various RL techniques and how they can
be applied to decision-making in power systems. We illustrate RL-based models
and solutions in three key applications, frequency regulation, voltage control,
and energy management. We conclude with three critical issues in the
application of RL, i.e., safety, scalability, and data. Several potential
future directions are discussed as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SPINN: Sparse, Physics-based, and partially Interpretable Neural Networks for PDEs. (arXiv:2102.13037v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramabathiran_A/0/1/0/all/0/1">Amuthan A. Ramabathiran</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_P/0/1/0/all/0/1">Prabhu Ramachandran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13037">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a class of Sparse, Physics-based, and partially Interpretable
Neural Networks (SPINN) for solving ordinary and partial differential equations
(PDEs). By reinterpreting a traditional meshless representation of solutions of
PDEs we develop a class of sparse neural network architectures that are
partially interpretable. The SPINN model we propose here serves as a seamless
bridge between two extreme modeling tools for PDEs, namely dense neural network
based methods like Physics Informed Neural Networks (PINNs) and traditional
mesh-free numerical methods, thereby providing a novel means to develop a new
class of hybrid algorithms that build on the best of both these viewpoints. A
unique feature of the SPINN model that distinguishes it from other neural
network based approximations proposed earlier is that it is (i) interpretable,
in a particular sense made precise in the work, and (ii) sparse in the sense
that it has much fewer connections than typical dense neural networks used for
PDEs. Further, the SPINN algorithm implicitly encodes mesh adaptivity and is
able to handle discontinuities in the solutions. In addition, we demonstrate
that Fourier series representations can also be expressed as a special class of
SPINN and propose generalized neural network analogues of Fourier
representations. We illustrate the utility of the proposed method with a
variety of examples involving ordinary differential equations, elliptic,
parabolic, hyperbolic and nonlinear partial differential equations, and an
example in fluid dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning based CVD Virtual Metrology in Mass Produced Semiconductor Process. (arXiv:2107.05071v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yunsong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Stearrett_R/0/1/0/all/0/1">Ryan Stearrett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05071">
                                    <div class="article-summary-box-inner">
                                        <span>A cross-benchmark has been done on three critical aspects, data imputing,
feature selection and regression algorithms, for machine learning based
chemical vapor deposition (CVD) virtual metrology (VM). The result reveals that
linear feature selection regression algorithm would extensively under-fit the
VM data. Data imputing is also necessary to achieve a higher prediction
accuracy as the data availability is only ~70% when optimal accuracy is
obtained. This work suggests a nonlinear feature selection and regression
algorithm combined with nearest data imputing algorithm would provide a
prediction accuracy as high as 0.7. This would lead to 70% reduced CVD
processing variation, which is believed to will lead to reduced frequency of
physical metrology as well as more reliable mass-produced wafer with improved
quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classifying Textual Data with Pre-trained Vision Models through Transfer Learning and Data Transformations. (arXiv:2106.12479v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Benarab_C/0/1/0/all/0/1">Charaf Eddine Benarab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.12479">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge is acquired by humans through experience, and no boundary is set
between the kinds of knowledge or skill levels we can achieve on different
tasks at the same time. When it comes to Neural Networks, that is not the case,
the major breakthroughs in the field are extremely task and domain specific.
Vision and language are dealt with in separate manners, using separate methods
and different datasets. In this work, we propose to use knowledge acquired by
benchmark Vision Models which are trained on ImageNet to help a much smaller
architecture learn to classify text. After transforming the textual data
contained in the IMDB dataset to gray scale images. An analysis of different
domains and the Transfer Learning method is carried out. Despite the challenge
posed by the very different datasets, promising results are achieved. The main
contribution of this work is a novel approach which links large pretrained
models on both language and vision to achieve state-of-the-art results in
different sub-fields from the original task. Without needing high compute
capacity resources. Specifically, Sentiment Analysis is achieved after
transferring knowledge between vision and language models. BERT embeddings are
transformed into grayscale images, these images are then used as training
examples for pre-trained vision models such as VGG16 and ResNet

Index Terms: BERT, Convolutional Neural Networks, Domain Adaptation, image
classification, Natural Language Processing, t-SNE, text classification,
Transfer Learning</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying social organization and political polarization in online platforms. (arXiv:2010.00590v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Waller_I/0/1/0/all/0/1">Isaac Waller</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_A/0/1/0/all/0/1">Ashton Anderson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00590">
                                    <div class="article-summary-box-inner">
                                        <span>Optimism about the Internet&#x27;s potential to bring the world together has been
tempered by concerns about its role in inflaming the &#x27;culture wars&#x27;. Via mass
selection into like-minded groups, online society may be becoming more
fragmented and polarized, particularly with respect to partisan differences.
However, our ability to measure the social makeup of online communities, and in
turn understand the social organization of online platforms, is limited by the
pseudonymous, unstructured, and large-scale nature of digital discussion. We
develop a neural embedding methodology to quantify the positioning of online
communities along social dimensions by leveraging large-scale patterns of
aggregate behaviour. Applying our methodology to 5.1B Reddit comments made in
10K communities over 14 years, we measure how the macroscale community
structure is organized with respect to age, gender, and U.S. political
partisanship. Examining political content, we find Reddit underwent a
significant polarization event around the 2016 U.S. presidential election, and
remained highly polarized for years afterward. Contrary to conventional wisdom,
however, individual-level polarization is rare; the system-level shift in 2016
was disproportionately driven by the arrival of new and newly political users.
Political polarization on Reddit is unrelated to previous activity on the
platform, and is instead temporally aligned with external events. We also
observe a stark ideological asymmetry, with the sharp increase in 2016 being
entirely attributable to changes in right-wing activity. Our methodology is
broadly applicable to the study of online interaction, and our findings have
implications for the design of online platforms, understanding the social
contexts of online behaviour, and quantifying the dynamics and mechanisms of
online polarization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Process Model Forecasting Using Time Series Analysis of Event Sequence Data. (arXiv:2105.01092v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Smedt_J/0/1/0/all/0/1">Johannes De Smedt</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeshchenko_A/0/1/0/all/0/1">Anton Yeshchenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Polyvyanyy_A/0/1/0/all/0/1">Artem Polyvyanyy</a>, <a href="http://arxiv.org/find/cs/1/au:+Weerdt_J/0/1/0/all/0/1">Jochen De Weerdt</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendling_J/0/1/0/all/0/1">Jan Mendling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01092">
                                    <div class="article-summary-box-inner">
                                        <span>Process analytics is an umbrella of data-driven techniques which includes
making predictions for individual process instances or overall process models.
At the instance level, various novel techniques have been recently devised,
tackling next activity, remaining time, and outcome prediction. At the model
level, there is a notable void. It is the ambition of this paper to fill this
gap. To this end, we develop a technique to forecast the entire process model
from historical event data. A forecasted model is a will-be process model
representing a probable future state of the overall process. Such a forecast
helps to investigate the consequences of drift and emerging bottlenecks. Our
technique builds on a representation of event data as multiple time series,
each capturing the evolution of a behavioural aspect of the process model, such
that corresponding forecasting techniques can be applied. Our implementation
demonstrates the accuracy of our technique on real-world event log data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local and non-local dependency learning and emergence of rule-like representations in speech data by Deep Convolutional Generative Adversarial Networks. (arXiv:2009.12711v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Begus_G/0/1/0/all/0/1">Ga&#x161;per Begu&#x161;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12711">
                                    <div class="article-summary-box-inner">
                                        <span>This paper argues that training GANs on local and non-local dependencies in
speech data offers insights into how deep neural networks discretize continuous
data and how symbolic-like rule-based morphophonological processes emerge in a
deep convolutional architecture. Acquisition of speech has recently been
modeled as a dependency between latent space and data generated by GANs in
Begu\v{s} (2020b; arXiv:2006.03965), who models learning of a simple local
allophonic distribution. We extend this approach to test learning of local and
non-local phonological processes that include approximations of morphological
processes. We further parallel outputs of the model to results of a behavioral
experiment where human subjects are trained on the data used for training the
GAN network. Four main conclusions emerge: (i) the networks provide useful
information for computational models of speech acquisition even if trained on a
comparatively small dataset of an artificial grammar learning experiment; (ii)
local processes are easier to learn than non-local processes, which matches
both behavioral data in human subjects and typology in the world&#x27;s languages.
This paper also proposes (iii) how we can actively observe the network&#x27;s
progress in learning and explore the effect of training steps on learning
representations by keeping latent space constant across different training
steps. Finally, this paper shows that (iv) the network learns to encode the
presence of a prefix with a single latent variable; by interpolating this
variable, we can actively observe the operation of a non-local phonological
process. The proposed technique for retrieving learning representations has
general implications for our understanding of how GANs discretize continuous
speech data and suggests that rule-like generalizations in the training data
are represented as an interaction between variables in the network&#x27;s latent
space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Entropic alternatives to initialization. (arXiv:2107.07757v2 [cond-mat.dis-nn] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Musso_D/0/1/0/all/0/1">Daniele Musso</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07757">
                                    <div class="article-summary-box-inner">
                                        <span>Local entropic loss functions provide a versatile framework to define
architecture-aware regularization procedures. Besides the possibility of being
anisotropic in the synaptic space, the local entropic smoothening of the loss
function can vary during training, thus yielding a tunable model complexity. A
scoping protocol where the regularization is strong in the early-stage of the
training and then fades progressively away constitutes an alternative to
standard initialization procedures for deep convolutional neural networks,
nonetheless, it has wider applicability. We analyze anisotropic, local entropic
smoothenings in the language of statistical physics and information theory,
providing insight into both their interpretation and workings. We comment some
aspects related to the physics of renormalization and the spacetime structure
of convolutional networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Realistic River Image Synthesis using Deep Generative Adversarial Networks. (arXiv:2003.00826v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gautam_A/0/1/0/all/0/1">Akshat Gautam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sit_M/0/1/0/all/0/1">Muhammed Sit</a>, <a href="http://arxiv.org/find/cs/1/au:+Demir_I/0/1/0/all/0/1">Ibrahim Demir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.00826">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we demonstrated a practical application of realistic river
image generation using deep learning. Specifically, we explored a generative
adversarial network (GAN) model capable of generating high-resolution and
realistic river images that can be used to support modeling and analysis in
surface water estimation, river meandering, wetland loss, and other
hydrological research studies. First, we have created an extensive repository
of overhead river images to be used in training. Second, we incorporated the
Progressive Growing GAN (PGGAN), a network architecture that iteratively trains
smaller-resolution GANs to gradually build up to a very high resolution to
generate high quality (i.e., 1024x1024) synthetic river imagery. With simpler
GAN architectures, difficulties arose in terms of exponential increase of
training time and vanishing/exploding gradient issues, which the PGGAN
implementation seemed to significantly reduce. The results presented in this
study show great promise in generating high-quality images and capturing the
details of river structure and flow to support hydrological research, which
often requires extensive imagery for model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">User Acceptance of Gender Stereotypes in Automated Career Recommendations. (arXiv:2106.07112v2 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Clarice Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kathryn Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_A/0/1/0/all/0/1">Andrew Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_R/0/1/0/all/0/1">Rashidul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Keya_K/0/1/0/all/0/1">Kamrun Naher Keya</a>, <a href="http://arxiv.org/find/cs/1/au:+Foulds_J/0/1/0/all/0/1">James Foulds</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shimei Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07112">
                                    <div class="article-summary-box-inner">
                                        <span>Currently, there is a surge of interest in fair Artificial Intelligence (AI)
and Machine Learning (ML) research which aims to mitigate discriminatory bias
in AI algorithms, e.g. along lines of gender, age, and race. While most
research in this domain focuses on developing fair AI algorithms, in this work,
we show that a fair AI algorithm on its own may be insufficient to achieve its
intended results in the real world. Using career recommendation as a case
study, we build a fair AI career recommender by employing gender debiasing
machine learning techniques. Our offline evaluation showed that the debiased
recommender makes fairer career recommendations without sacrificing its
accuracy. Nevertheless, an online user study of more than 200 college students
revealed that participants on average prefer the original biased system over
the debiased system. Specifically, we found that perceived gender disparity is
a determining factor for the acceptance of a recommendation. In other words,
our results demonstrate we cannot fully address the gender bias issue in AI
recommendations without addressing the gender bias in humans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Numerical issues in maximum likelihood parameter estimation for Gaussian process interpolation. (arXiv:2101.09747v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Basak_S/0/1/0/all/0/1">Subhasish Basak</a>, <a href="http://arxiv.org/find/stat/1/au:+Petit_S/0/1/0/all/0/1">S&#xe9;bastien Petit</a>, <a href="http://arxiv.org/find/stat/1/au:+Bect_J/0/1/0/all/0/1">Julien Bect</a>, <a href="http://arxiv.org/find/stat/1/au:+Vazquez_E/0/1/0/all/0/1">Emmanuel Vazquez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09747">
                                    <div class="article-summary-box-inner">
                                        <span>This article investigates the origin of numerical issues in maximum
likelihood parameter estimation for Gaussian process (GP) interpolation and
investigates simple but effective strategies for improving commonly used
open-source software implementations. This work targets a basic problem but a
host of studies, particularly in the literature of Bayesian optimization, rely
on off-the-shelf GP implementations. For the conclusions of these studies to be
reliable and reproducible, robust GP implementations are critical.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cooperative Online Learning. (arXiv:2106.04982v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cesari_T/0/1/0/all/0/1">Tommaso R. Cesari</a>, <a href="http://arxiv.org/find/cs/1/au:+Vecchia_R/0/1/0/all/0/1">Riccardo Della Vecchia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04982">
                                    <div class="article-summary-box-inner">
                                        <span>In this preliminary (and unpolished) version of the paper, we study an
asynchronous online learning setting with a network of agents. At each time
step, some of the agents are activated, requested to make a prediction, and pay
the corresponding loss. Some feedback is then revealed to these agents and is
later propagated through the network. We consider the case of full, bandit, and
semi-bandit feedback. In particular, we construct a reduction to delayed
single-agent learning that applies to both the full and the bandit feedback
case and allows to obtain regret guarantees for both settings. We complement
these results with a near-matching lower bound.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HDR Environment Map Estimation for Real-Time Augmented Reality. (arXiv:2011.10687v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Somanath_G/0/1/0/all/0/1">Gowri Somanath</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurz_D/0/1/0/all/0/1">Daniel Kurz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10687">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method to estimate an HDR environment map from a narrow
field-of-view LDR camera image in real-time. This enables perceptually
appealing reflections and shading on virtual objects of any material finish,
from mirror to diffuse, rendered into a real physical environment using
augmented reality. Our method is based on our efficient convolutional neural
network architecture, EnvMapNet, trained end-to-end with two novel losses,
ProjectionLoss for the generated image, and ClusterLoss for adversarial
training. Through qualitative and quantitative comparison to state-of-the-art
methods, we demonstrate that our algorithm reduces the directional error of
estimated light sources by more than 50%, and achieves 3.7 times lower Frechet
Inception Distance (FID). We further showcase a mobile application that is able
to run our neural network model in under 9 ms on an iPhone XS, and render in
real-time, visually coherent virtual objects in previously unseen real-world
environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Inertial Newton Algorithm for Deep Learning. (arXiv:1905.12278v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castera_C/0/1/0/all/0/1">Camille Castera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bolte_J/0/1/0/all/0/1">J&#xe9;r&#xf4;me Bolte</a>, <a href="http://arxiv.org/find/cs/1/au:+Fevotte_C/0/1/0/all/0/1">C&#xe9;dric F&#xe9;votte</a>, <a href="http://arxiv.org/find/cs/1/au:+Pauwels_E/0/1/0/all/0/1">Edouard Pauwels</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.12278">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new second-order inertial optimization method for machine
learning called INNA. It exploits the geometry of the loss function while only
requiring stochastic approximations of the function values and the generalized
gradients. This makes INNA fully implementable and adapted to large-scale
optimization problems such as the training of deep neural networks. The
algorithm combines both gradient-descent and Newton-like behaviors as well as
inertia. We prove the convergence of INNA for most deep learning problems. To
do so, we provide a well-suited framework to analyze deep learning loss
functions involving tame optimization in which we study a continuous dynamical
system together with its discrete stochastic approximations. We prove sublinear
convergence for the continuous-time differential inclusion which underlies our
algorithm. Additionally, we also show how standard optimization mini-batch
methods applied to non-smooth non-convex problems can yield a certain type of
spurious stationary points never discussed before. We address this issue by
providing a theoretical framework around the new idea of $D$-criticality; we
then give a simple asymptotic analysis of INNA. Our algorithm allows for using
an aggressive learning rate of $o(1/\log k)$. From an empirical viewpoint, we
show that INNA returns competitive results with respect to state of the art
(stochastic gradient descent, ADAGRAD, ADAM) on popular deep learning benchmark
problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural Architecture Search. (arXiv:1907.01845v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiangxiang Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ruijun Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.01845">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most critical problems in weight-sharing neural architecture
search is the evaluation of candidate models within a predefined search space.
In practice, a one-shot supernet is trained to serve as an evaluator. A
faithful ranking certainly leads to more accurate searching results. However,
current methods are prone to making misjudgments. In this paper, we prove that
their biased evaluation is due to inherent unfairness in the supernet training.
In view of this, we propose two levels of constraints: expectation fairness and
strict fairness. Particularly, strict fairness ensures equal optimization
opportunities for all choice blocks throughout the training, which neither
overestimates nor underestimates their capacity. We demonstrate that this is
crucial for improving the confidence of models&#x27; ranking. Incorporating the
one-shot supernet trained under the proposed fairness constraints with a
multi-objective evolutionary search algorithm, we obtain various
state-of-the-art models, e.g., FairNAS-A attains 77.5% top-1 validation
accuracy on ImageNet. The models and their evaluation codes are made publicly
available online this http URL .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty-Aware Credit Card Fraud Detection Using Deep Learning. (arXiv:2107.13508v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Habibpour_M/0/1/0/all/0/1">Maryam Habibpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Gharoun_H/0/1/0/all/0/1">Hassan Gharoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdipour_M/0/1/0/all/0/1">Mohammadreza Mehdipour</a>, <a href="http://arxiv.org/find/cs/1/au:+Tajally_A/0/1/0/all/0/1">AmirReza Tajally</a>, <a href="http://arxiv.org/find/cs/1/au:+Asgharnezhad_H/0/1/0/all/0/1">Hamzeh Asgharnezhad</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamsi_A/0/1/0/all/0/1">Afshar Shamsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosravi_A/0/1/0/all/0/1">Abbas Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafie_Khah_M/0/1/0/all/0/1">Miadreza Shafie-Khah</a>, <a href="http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Catalao_J/0/1/0/all/0/1">Joao P.S. Catalao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13508">
                                    <div class="article-summary-box-inner">
                                        <span>Countless research works of deep neural networks (DNNs) in the task of credit
card fraud detection have focused on improving the accuracy of point
predictions and mitigating unwanted biases by building different network
architectures or learning models. Quantifying uncertainty accompanied by point
estimation is essential because it mitigates model unfairness and permits
practitioners to develop trustworthy systems which abstain from suboptimal
decisions due to low confidence. Explicitly, assessing uncertainties associated
with DNNs predictions is critical in real-world card fraud detection settings
for characteristic reasons, including (a) fraudsters constantly change their
strategies, and accordingly, DNNs encounter observations that are not generated
by the same process as the training distribution, (b) owing to the
time-consuming process, very few transactions are timely checked by
professional experts to update DNNs. Therefore, this study proposes three
uncertainty quantification (UQ) techniques named Monte Carlo dropout, ensemble,
and ensemble Monte Carlo dropout for card fraud detection applied on
transaction data. Moreover, to evaluate the predictive uncertainty estimates,
UQ confusion matrix and several performance metrics are utilized. Through
experimental results, we show that the ensemble is more effective in capturing
uncertainty corresponding to generated predictions. Additionally, we
demonstrate that the proposed UQ methods provide extra insight to the point
predictions, leading to elevate the fraud prevention process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Learning and the Finite-Temperature String Method for Computing Committor Functions and Reaction Rates. (arXiv:2107.13522v1 [cond-mat.stat-mech])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Hasyim_M/0/1/0/all/0/1">Muhammad R. Hasyim</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Batton_C/0/1/0/all/0/1">Clay H. Batton</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Mandadapu_K/0/1/0/all/0/1">Kranthi K. Mandadapu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13522">
                                    <div class="article-summary-box-inner">
                                        <span>A central object in the computational studies of rare events is the committor
function. Though costly to compute, the committor function encodes complete
mechanistic information of the processes involving rare events, including
reaction rates and transition-state ensembles. Under the framework of
transition path theory (TPT), recent work [1] proposes an algorithm where a
feedback loop couples a neural network that models the committor function with
importance sampling, mainly umbrella sampling, which collects data needed for
adaptive training. In this work, we show additional modifications are needed to
improve the accuracy of the algorithm. The first modification adds elements of
supervised learning, which allows the neural network to improve its prediction
by fitting to sample-mean estimates of committor values obtained from short
molecular dynamics trajectories. The second modification replaces the
committor-based umbrella sampling with the finite-temperature string (FTS)
method, which enables homogeneous sampling in regions where transition pathways
are located. We test our modifications on low-dimensional systems with
non-convex potential energy where reference solutions can be found via
analytical or the finite element methods, and show how combining supervised
learning and the FTS method yields accurate computation of committor functions
and reaction rates. We also provide an error analysis for algorithms that use
the FTS method, using which reaction rates can be accurately estimated during
training with a small number of samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Recurrent Semi-Supervised EEG Representation Learning for Emotion Recognition. (arXiv:2107.13505v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guangyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Etemad_A/0/1/0/all/0/1">Ali Etemad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13505">
                                    <div class="article-summary-box-inner">
                                        <span>EEG-based emotion recognition often requires sufficient labeled training
samples to build an effective computational model. Labeling EEG data, on the
other hand, is often expensive and time-consuming. To tackle this problem and
reduce the need for output labels in the context of EEG-based emotion
recognition, we propose a semi-supervised pipeline to jointly exploit both
unlabeled and labeled data for learning EEG representations. Our
semi-supervised framework consists of both unsupervised and supervised
components. The unsupervised part maximizes the consistency between original
and reconstructed input data using an autoencoder, while simultaneously the
supervised part minimizes the cross-entropy between the input and output
labels. We evaluate our framework using both a stacked autoencoder and an
attention-based recurrent autoencoder. We test our framework on the large-scale
SEED EEG dataset and compare our results with several other popular
semi-supervised methods. Our semi-supervised framework with a deep
attention-based recurrent autoencoder consistently outperforms the benchmark
methods, even when small sub-sets (3\%, 5\% and 10\%) of the output labels are
available during training, achieving a new state-of-the-art semi-supervised
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Reasonable Crowd: Towards evidence-based and interpretable models of driving behavior. (arXiv:2107.13507v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Helou_B/0/1/0/all/0/1">Bassam Helou</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusi_A/0/1/0/all/0/1">Aditya Dusi</a>, <a href="http://arxiv.org/find/cs/1/au:+Collin_A/0/1/0/all/0/1">Anne Collin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdipour_N/0/1/0/all/0/1">Noushin Mehdipour</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhiliang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lizarazo_C/0/1/0/all/0/1">Cristhian Lizarazo</a>, <a href="http://arxiv.org/find/cs/1/au:+Belta_C/0/1/0/all/0/1">Calin Belta</a>, <a href="http://arxiv.org/find/cs/1/au:+Wongpiromsarn_T/0/1/0/all/0/1">Tichakorn Wongpiromsarn</a>, <a href="http://arxiv.org/find/cs/1/au:+Tebbens_R/0/1/0/all/0/1">Radboud Duintjer Tebbens</a>, <a href="http://arxiv.org/find/cs/1/au:+Beijbom_O/0/1/0/all/0/1">Oscar Beijbom</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13507">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous vehicles must balance a complex set of objectives. There is no
consensus on how they should do so, nor on a model for specifying a desired
driving behavior. We created a dataset to help address some of these questions
in a limited operating domain. The data consists of 92 traffic scenarios, with
multiple ways of traversing each scenario. Multiple annotators expressed their
preference between pairs of scenario traversals. We used the data to compare an
instance of a rulebook, carefully hand-crafted independently of the dataset,
with several interpretable machine learning models such as Bayesian networks,
decision trees, and logistic regression trained on the dataset. To compare
driving behavior, these models use scores indicating by how much different
scenario traversals violate each of 14 driving rules. The rules are
interpretable and designed by subject-matter experts. First, we found that
these rules were enough for these models to achieve a high classification
accuracy on the dataset. Second, we found that the rulebook provides high
interpretability without excessively sacrificing performance. Third, the data
pointed to possible improvements in the rulebook and the rules, and to
potential new rules. Fourth, we explored the interpretability vs performance
trade-off by also training non-interpretable models such as a random forest.
Finally, we make the dataset publicly available to encourage a discussion from
the wider community on behavior specification for AVs. Please find it at
github.com/bassam-motional/Reasonable-Crowd.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quasi-Newton Methods for Machine Learning: Forget the Past, Just Sample. (arXiv:1901.09997v5 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Berahas_A/0/1/0/all/0/1">Albert S. Berahas</a>, <a href="http://arxiv.org/find/math/1/au:+Jahani_M/0/1/0/all/0/1">Majid Jahani</a>, <a href="http://arxiv.org/find/math/1/au:+Richtarik_P/0/1/0/all/0/1">Peter Richt&#xe1;rik</a>, <a href="http://arxiv.org/find/math/1/au:+Takac_M/0/1/0/all/0/1">Martin Tak&#xe1;&#x10d;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1901.09997">
                                    <div class="article-summary-box-inner">
                                        <span>We present two sampled quasi-Newton methods (sampled LBFGS and sampled LSR1)
for solving empirical risk minimization problems that arise in machine
learning. Contrary to the classical variants of these methods that sequentially
build Hessian or inverse Hessian approximations as the optimization progresses,
our proposed methods sample points randomly around the current iterate at every
iteration to produce these approximations. As a result, the approximations
constructed make use of more reliable (recent and local) information, and do
not depend on past iterate information that could be significantly stale. Our
proposed algorithms are efficient in terms of accessed data points (epochs) and
have enough concurrency to take advantage of parallel/distributed computing
environments. We provide convergence guarantees for our proposed methods.
Numerical tests on a toy classification problem as well as on popular
benchmarking binary classification and neural network training tasks reveal
that the methods outperform their classical variants.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReLMM: Practical RL for Learning Mobile Manipulation Skills Using Only Onboard Sensors. (arXiv:2107.13545v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Charles Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Orbik_J/0/1/0/all/0/1">J&#x119;drzej Orbik</a>, <a href="http://arxiv.org/find/cs/1/au:+Devin_C/0/1/0/all/0/1">Coline Devin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1">Brian Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Abhishek Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Berseth_G/0/1/0/all/0/1">Glen Berseth</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13545">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study how robots can autonomously learn skills that require
a combination of navigation and grasping. Learning robotic skills in the real
world remains challenging without large-scale data collection and supervision.
Our aim is to devise a robotic reinforcement learning system for learning
navigation and manipulation together, in an \textit{autonomous} way without
human intervention, enabling continual learning under realistic assumptions.
Specifically, our system, ReLMM, can learn continuously on a real-world
platform without any environment instrumentation, without human intervention,
and without access to privileged information, such as maps, objects positions,
or a global view of the environment. Our method employs a modularized policy
with components for manipulation and navigation, where uncertainty over the
manipulation success drives exploration for the navigation controller, and the
manipulation module provides rewards for navigation. We evaluate our method on
a room cleanup task, where the robot must navigate to and pick up items of
scattered on the floor. After a grasp curriculum training phase, ReLMM can
learn navigation and grasping together fully automatically, in around 40 hours
of real-world training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Portiloop: a deep learning-based open science tool for closed-loop brain stimulation. (arXiv:2107.13473v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Valenchon_N/0/1/0/all/0/1">Nicolas Valenchon</a>, <a href="http://arxiv.org/find/eess/1/au:+Bouteiller_Y/0/1/0/all/0/1">Yann Bouteiller</a>, <a href="http://arxiv.org/find/eess/1/au:+Jourde_H/0/1/0/all/0/1">Hugo R. Jourde</a>, <a href="http://arxiv.org/find/eess/1/au:+Coffey_E/0/1/0/all/0/1">Emily B.J. Coffey</a>, <a href="http://arxiv.org/find/eess/1/au:+Beltrame_G/0/1/0/all/0/1">Giovanni Beltrame</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13473">
                                    <div class="article-summary-box-inner">
                                        <span>Electroencephalography (EEG) is a method of measuring the brain&#x27;s electrical
activity, using non-invasive scalp electrodes. In this article, we propose the
Portiloop, a deep learning-based portable and low-cost device enabling the
neuroscience community to capture EEG, process it in real time, detect patterns
of interest, and respond with precisely-timed stimulation. The core of the
Portiloop is a System on Chip composed of an Analog to Digital Converter (ADC)
and a Field-Programmable Gate Array (FPGA). After being converted to digital by
the ADC, the EEG signal is processed in the FPGA. The FPGA contains an ad-hoc
Artificial Neural Network (ANN) with convolutional and recurrent units,
directly implemented in hardware. The output of the ANN is then used to trigger
the user-defined feedback. We use the Portiloop to develop a real-time sleep
spindle stimulating application, as a case study. Sleep spindles are a specific
type of transient oscillation ($\sim$2.5 s, 12-16 Hz) that are observed in EEG
recordings, and are related to memory consolidation during sleep. We tested the
Portiloop&#x27;s capacity to detect and stimulate sleep spindles in real time using
an existing database of EEG sleep recordings. With 71% for both precision and
recall as compared with expert labels, the system is able to stimulate spindles
within $\sim$300 ms of their onset, enabling experimental manipulation of early
the entire spindle. The Portiloop can be extended to detect and stimulate other
neural events in EEG. It is fully available to the research community as an
open science project.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold Coordinates with Physical Meaning. (arXiv:1811.11891v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Koelle_S/0/1/0/all/0/1">Samson Koelle</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1">Hanyu Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Meila_M/0/1/0/all/0/1">Marina Meila</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1">Yu-Chia Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.11891">
                                    <div class="article-summary-box-inner">
                                        <span>Manifold embedding algorithms map high-dimensional data down to coordinates
in a much lower-dimensional space. One of the aims of dimension reduction is to
find intrinsic coordinates that describe the data manifold. The coordinates
returned by the embedding algorithm are abstract, and finding their physical or
domain-related meaning is not formalized and often left to domain experts. This
paper studies the problem of recovering the meaning of the new low-dimensional
representation in an automatic, principled fashion. We propose a method to
explain embedding coordinates of a manifold as non-linear compositions of
functions from a user-defined dictionary. We show that this problem can be set
up as a sparse linear Group Lasso recovery problem, find sufficient recovery
conditions, and demonstrate its effectiveness on data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering by Orthogonal NMF Model and Non-Convex Penalty Optimization. (arXiv:1906.00570v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_T/0/1/0/all/0/1">Tsung-Hui Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Ying Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jong-Shi Pang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.00570">
                                    <div class="article-summary-box-inner">
                                        <span>The non-negative matrix factorization (NMF) model with an additional
orthogonality constraint on one of the factor matrices, called the orthogonal
NMF (ONMF), has been found a promising clustering model and can outperform the
classical K-means. However, solving the ONMF model is a challenging
optimization problem because the coupling of the orthogonality and
non-negativity constraints introduces a mixed combinatorial aspect into the
problem due to the determination of the correct status of the variables
(positive or zero). Most of the existing methods directly deal with the
orthogonality constraint in its original form via various optimization
techniques, but are not scalable for large-scale problems. In this paper, we
propose a new ONMF based clustering formulation that equivalently transforms
the orthogonality constraint into a set of norm-based non-convex equality
constraints. We then apply a non-convex penalty (NCP) approach to add them to
the objective as penalty terms, leading to a problem that is efficiently
solvable. One smooth penalty formulation and one non-smooth penalty formulation
are respectively studied. We build theoretical conditions for the penalized
problems to provide feasible stationary solutions to the ONMF based clustering
problem, as well as proposing efficient algorithms for solving the penalized
problems of the two NCP methods. Experimental results based on both synthetic
and real datasets are presented to show that the proposed NCP methods are
computationally time efficient, and either match or outperform the existing
K-means and ONMF based methods in terms of the clustering performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Satisfiability and Synthesis Modulo Oracles. (arXiv:2107.13477v1 [cs.LO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Polgreen_E/0/1/0/all/0/1">Elizabeth Polgreen</a>, <a href="http://arxiv.org/find/cs/1/au:+Reynolds_A/0/1/0/all/0/1">Andrew Reynolds</a>, <a href="http://arxiv.org/find/cs/1/au:+Seshia_S/0/1/0/all/0/1">Sanjit A. Seshia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13477">
                                    <div class="article-summary-box-inner">
                                        <span>In classic program synthesis algorithms, such as counterexample-guided
inductive synthesis (CEGIS), the algorithms alternate between a synthesis phase
and an oracle (verification) phase. Many synthesis algorithms use a white-box
oracle based on satisfiability modulo theory (SMT) solvers to provide
counterexamples. But what if a white-box oracle is either not available or not
easy to work with? We present a framework for solving a general class of
oracle-guided synthesis problems which we term synthesis modulo oracles. In
this setting, oracles may be black boxes with a query-response interface
defined by the synthesis problem. As a necessary component of this framework,
we also formalize the problem of satisfiability modulo theories and oracles,
and present an algorithm for solving this problem. We implement a prototype
solver for satisfiability and synthesis modulo oracles and demonstrate that, by
using oracles that execute functions not easily modeled in SMT-constraints,
such as recursive functions or oracles that incorporate compilation and
execution of code, SMTO and SyMO are able to solve problems beyond the
abilities of standard SMT and synthesis solvers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MARViN -- Multiple Arithmetic Resolutions Vacillating in Neural Networks. (arXiv:2107.13490v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kummer_L/0/1/0/all/0/1">Lorenz Kummer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidak_K/0/1/0/all/0/1">Kevin Sidak</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichmann_T/0/1/0/all/0/1">Tabea Reichmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Gansterer_W/0/1/0/all/0/1">Wilfried Gansterer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13490">
                                    <div class="article-summary-box-inner">
                                        <span>Quantization is a technique for reducing deep neural networks (DNNs) training
and inference times, which is crucial for training in resource constrained
environments or time critical inference applications. State-of-the-art (SOTA)
quantization approaches focus on post-training quantization, i.e. quantization
of pre-trained DNNs for speeding up inference. Very little work on quantized
training exists, which neither al-lows dynamic intra-epoch precision switches
nor em-ploys an information theory based switching heuristic. Usually, existing
approaches require full precision refinement afterwards and enforce a global
word length across the whole DNN. This leads to suboptimal quantization
mappings and resource usage. Recognizing these limits, we introduce MARViN, a
new quantized training strategy using information theory-based intra-epoch
precision switching, which decides on a per-layer basis which precision should
be used in order to minimize quantization-induced information loss. Note that
any quantization must leave enough precision such that future learning steps do
not suffer from vanishing gradients. We achieve an average speedup of 1.86
compared to a float32 basis while limiting mean accuracy degradation on
AlexNet/ResNet to only -0.075%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAPE: Encoding Relative Positions with Continuous Augmented Positional Embeddings. (arXiv:2106.03143v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Likhomanenko_T/0/1/0/all/0/1">Tatiana Likhomanenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qiantong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Collobert_R/0/1/0/all/0/1">Ronan Collobert</a>, <a href="http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1">Gabriel Synnaeve</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogozhnikov_A/0/1/0/all/0/1">Alex Rogozhnikov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03143">
                                    <div class="article-summary-box-inner">
                                        <span>Without positional information, attention-based transformer neural networks
are permutation-invariant. Absolute or relative positional embeddings are the
most popular ways to feed transformer models positional information. Absolute
positional embeddings are simple to implement, but suffer from generalization
issues when evaluating on sequences of different length than those seen at
training time. Relative positions are more robust to length change, but are
more complex to implement and yield inferior model throughput. In this paper,
we propose an augmentation-based approach (CAPE) for absolute positional
embeddings, which keeps the advantages of both absolute (simplicity and speed)
and relative position embeddings (better generalization). In addition, our
empirical evaluation on state-of-the-art models in machine translation, image
and speech recognition demonstrates that CAPE leads to better generalization
performance as well as increased stability with respect to training
hyper-parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistically Significant Stopping of Neural Network Training. (arXiv:2103.01205v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Terry_J/0/1/0/all/0/1">J. K. Terry</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayakumar_M/0/1/0/all/0/1">Mario Jayakumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Alwis_K/0/1/0/all/0/1">Kusal De Alwis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01205">
                                    <div class="article-summary-box-inner">
                                        <span>The general approach taken when training deep learning classifiers is to save
the parameters after every few iterations, train until either a human observer
or a simple metric-based heuristic decides the network isn&#x27;t learning anymore,
and then backtrack and pick the saved parameters with the best validation
accuracy. Simple methods are used to determine if a neural network isn&#x27;t
learning anymore because, as long as it&#x27;s well after the optimal values are
found, the condition doesn&#x27;t impact the final accuracy of the model. However
from a runtime perspective, this is of great significance to the many cases
where numerous neural networks are trained simultaneously (e.g. hyper-parameter
tuning). Motivated by this, we introduce a statistical significance test to
determine if a neural network has stopped learning. This stopping criterion
appears to represent a happy medium compared to other popular stopping
criterions, achieving comparable accuracy to the criterions that achieve the
highest final accuracies in 77% or fewer epochs, while the criterions which
stop sooner do so with an appreciable loss to final accuracy. Additionally, we
use this as the basis of a new learning rate scheduler, removing the need to
manually choose learning rate schedules and acting as a quasi-line search,
achieving superior or comparable empirical performance to existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When and how do CNNs generalize to out-of-distribution category-viewpoint combinations?. (arXiv:2007.08032v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Madan_S/0/1/0/all/0/1">Spandan Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Henry_T/0/1/0/all/0/1">Timothy Henry</a>, <a href="http://arxiv.org/find/cs/1/au:+Dozier_J/0/1/0/all/0/1">Jamell Dozier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_H/0/1/0/all/0/1">Helen Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhandari_N/0/1/0/all/0/1">Nishchal Bhandari</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasaki_T/0/1/0/all/0/1">Tomotake Sasaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1">Fr&#xe9;do Durand</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1">Hanspeter Pfister</a>, <a href="http://arxiv.org/find/cs/1/au:+Boix_X/0/1/0/all/0/1">Xavier Boix</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08032">
                                    <div class="article-summary-box-inner">
                                        <span>Object recognition and viewpoint estimation lie at the heart of visual
understanding. Recent works suggest that convolutional neural networks (CNNs)
fail to generalize to out-of-distribution (OOD) category-viewpoint
combinations, ie. combinations not seen during training. In this paper, we
investigate when and how such OOD generalization may be possible by evaluating
CNNs trained to classify both object category and 3D viewpoint on OOD
combinations, and identifying the neural mechanisms that facilitate such OOD
generalization. We show that increasing the number of in-distribution
combinations (ie. data diversity) substantially improves generalization to OOD
combinations, even with the same amount of training data. We compare learning
category and viewpoint in separate and shared network architectures, and
observe starkly different trends on in-distribution and OOD combinations, ie.
while shared networks are helpful in-distribution, separate networks
significantly outperform shared ones at OOD combinations. Finally, we
demonstrate that such OOD generalization is facilitated by the neural mechanism
of specialization, ie. the emergence of two types of neurons -- neurons
selective to category and invariant to viewpoint, and vice versa.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven effective model shows a liquid-like deep learning. (arXiv:2007.08093v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zou_W/0/1/0/all/0/1">Wenxuan Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haiping Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08093">
                                    <div class="article-summary-box-inner">
                                        <span>The geometric structure of an optimization landscape is argued to be
fundamentally important to support the success of deep neural network learning.
A direct computation of the landscape beyond two layers is hard. Therefore, to
capture the global view of the landscape, an interpretable model of the
network-parameter (or weight) space must be established. However, the model is
lacking so far. Furthermore, it remains unknown what the landscape looks like
for deep networks of binary synapses, which plays a key role in robust and
energy efficient neuromorphic computation. Here, we propose a statistical
mechanics framework by directly building a least structured model of the
high-dimensional weight space, considering realistic structured data,
stochastic gradient descent training, and the computational depth of neural
networks. We also consider whether the number of network parameters outnumbers
the number of supplied training data, namely, over- or under-parametrization.
Our least structured model reveals that the weight spaces of the
under-parametrization and over-parameterization cases belong to the same class,
in the sense that these weight spaces are well-connected without any
hierarchical clustering structure. In contrast, the shallow-network has a
broken weight space, characterized by a discontinuous phase transition, thereby
clarifying the benefit of depth in deep learning from the angle of high
dimensional geometry. Our effective model also reveals that inside a deep
network, there exists a liquid-like central part of the architecture in the
sense that the weights in this part behave as randomly as possible, providing
algorithmic implications. Our data-driven model thus provides a statistical
mechanics insight about why deep learning is unreasonably effective in terms of
the high-dimensional weight space, and how deep networks are different from
shallow ones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Board Volcanic Eruption Detection through CNNs and Satellite Multispectral Imagery. (arXiv:2106.15281v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosso_M/0/1/0/all/0/1">Maria Pia Del Rosso</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebastianelli_A/0/1/0/all/0/1">Alessandro Sebastianelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Spiller_D/0/1/0/all/0/1">Dario Spiller</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_P/0/1/0/all/0/1">Pierre Philippe Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullo_S/0/1/0/all/0/1">Silvia Liberata Ullo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15281">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, the growth of Machine Learning (ML) algorithms has raised
the number of studies including their applicability in a variety of different
scenarios. Among all, one of the hardest ones is the aerospace, due to its
peculiar physical requirements. In this context, a feasibility study and a
first prototype for an Artificial Intelligence (AI) model to be deployed on
board satellites are presented in this work. As a case study, the detection of
volcanic eruptions has been investigated as a method to swiftly produce alerts
and allow immediate interventions. Two Convolutional Neural Networks (CNNs)
have been proposed and designed, showing how to efficiently implement them for
identifying the eruptions and at the same time adapting their complexity in
order to fit on board requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proximal boosting and variants. (arXiv:1808.09670v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fouillen_E/0/1/0/all/0/1">Erwan Fouillen</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyer_C/0/1/0/all/0/1">Claire Boyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sangnier_M/0/1/0/all/0/1">Maxime Sangnier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1808.09670">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient boosting is a prediction method that iteratively combines weak
learners to produce a complex and accurate model. From an optimization point of
view, the learning procedure of gradient boosting mimics a gradient descent on
a functional variable. This paper proposes to build upon the proximal point
algorithm, when the empirical risk to minimize is not differentiable, in order
to introduce a novel boosting approach, called proximal boosting. Besides being
motivated by non-differentiable optimization, the proposed algorithm benefits
from algorithmic improvements such as controlling the approximation error and
Nesterov&#x27;s acceleration, in the same way as gradient boosting [Grubb and
Bagnell, 2011, Biau et al., 2018]. This leads to two variants, respectively
called residual proximal boosting and accelerated proximal boosting.
Theoretical convergence is proved for the first two procedures under different
hypotheses on the empirical risk and advantages of leveraging proximal methods
for boosting are illustrated by numerical experiments on simulated and
real-world data. In particular, we exhibit a favorable comparison over gradient
boosting regarding convergence rate and prediction accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Reflection on Learning from Data: Epistemology Issues and Limitations. (arXiv:2107.13270v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hammoudeh_A/0/1/0/all/0/1">Ahmad Hammoudeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Tedmori_S/0/1/0/all/0/1">Sara Tedmori</a>, <a href="http://arxiv.org/find/cs/1/au:+Obeid_N/0/1/0/all/0/1">Nadim Obeid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13270">
                                    <div class="article-summary-box-inner">
                                        <span>Although learning from data is effective and has achieved significant
milestones, it has many challenges and limitations. Learning from data starts
from observations and then proceeds to broader generalizations. This framework
is controversial in science, yet it has achieved remarkable engineering
successes. This paper reflects on some epistemological issues and some of the
limitations of the knowledge discovered in data. The document discusses the
common perception that getting more data is the key to achieving better machine
learning models from theoretical and practical perspectives. The paper sheds
some light on the shortcomings of using generic mathematical theories to
describe the process. It further highlights the need for theories specialized
in learning from data. While more data leverages the performance of machine
learning models in general, the relation in practice is shown to be logarithmic
at its best; After a specific limit, more data stabilize or degrade the machine
learning models. Recent work in reinforcement learning showed that the trend is
shifting away from data-oriented approaches and relying more on algorithms. The
paper concludes that learning from data is hindered by many limitations. Hence
an approach that has an intensional orientation is needed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Navigation Turing Test (NTT): Learning to Evaluate Human-Like Navigation. (arXiv:2105.09637v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Devlin_S/0/1/0/all/0/1">Sam Devlin</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgescu_R/0/1/0/all/0/1">Raluca Georgescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Momennejad_I/0/1/0/all/0/1">Ida Momennejad</a>, <a href="http://arxiv.org/find/cs/1/au:+Rzepecki_J/0/1/0/all/0/1">Jaroslaw Rzepecki</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuniga_E/0/1/0/all/0/1">Evelyn Zuniga</a>, <a href="http://arxiv.org/find/cs/1/au:+Costello_G/0/1/0/all/0/1">Gavin Costello</a>, <a href="http://arxiv.org/find/cs/1/au:+Leroy_G/0/1/0/all/0/1">Guy Leroy</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaw_A/0/1/0/all/0/1">Ali Shaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1">Katja Hofmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09637">
                                    <div class="article-summary-box-inner">
                                        <span>A key challenge on the path to developing agents that learn complex
human-like behavior is the need to quickly and accurately quantify
human-likeness. While human assessments of such behavior can be highly
accurate, speed and scalability are limited. We address these limitations
through a novel automated Navigation Turing Test (ANTT) that learns to predict
human judgments of human-likeness. We demonstrate the effectiveness of our
automated NTT on a navigation task in a complex 3D environment. We investigate
six classification models to shed light on the types of architectures best
suited to this task, and validate them against data collected through a human
NTT. Our best models achieve high accuracy when distinguishing true human and
agent behavior. At the same time, we show that predicting finer-grained human
assessment of agents&#x27; progress towards human-like behavior remains unsolved.
Our work takes an important step towards agents that more effectively learn
complex human-like behavior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Payload Optimization Method for Federated Recommender Systems. (arXiv:2107.13078v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_F/0/1/0/all/0/1">Farwa K. Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Flanagan_A/0/1/0/all/0/1">Adrian Flanagan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_K/0/1/0/all/0/1">Kuan E. Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alamgir_Z/0/1/0/all/0/1">Zareen Alamgir</a>, <a href="http://arxiv.org/find/cs/1/au:+Ammad_Ud_Din_M/0/1/0/all/0/1">Muhammad Ammad-Ud-Din</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13078">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the payload optimization method for federated recommender
systems (FRS). In federated learning (FL), the global model payload that is
moved between the server and users depends on the number of items to recommend.
The model payload grows when there is an increasing number of items. This
becomes challenging for an FRS if it is running in production mode. To tackle
the payload challenge, we formulated a multi-arm bandit solution that selected
part of the global model and transmitted it to all users. The selection process
was guided by a novel reward function suitable for FL systems. So far as we are
aware, this is the first optimization method that seeks to address item
dependent payloads. The method was evaluated using three benchmark
recommendation datasets. The empirical validation confirmed that the proposed
method outperforms the simpler methods that do not benefit from the bandits for
the purpose of item selection. In addition, we have demonstrated the usefulness
of our proposed method by rigorously evaluating the effects of a payload
reduction on the recommendation performance degradation. Our method achieved up
to a 90\% reduction in model payload, yielding only a $\sim$4\% - 8\% loss in
the recommendation performance for highly sparse datasets</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Use of Reconstruction Error for Novelty Localization. (arXiv:2107.13379v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feeney_P/0/1/0/all/0/1">Patrick Feeney</a>, <a href="http://arxiv.org/find/cs/1/au:+Hughes_M/0/1/0/all/0/1">Michael C. Hughes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13379">
                                    <div class="article-summary-box-inner">
                                        <span>The pixelwise reconstruction error of deep autoencoders is often utilized for
image novelty detection and localization under the assumption that pixels with
high error indicate which parts of the input image are unfamiliar and therefore
likely to be novel. This assumed correlation between pixels with high
reconstruction error and novel regions of input images has not been verified
and may limit the accuracy of these methods. In this paper we utilize saliency
maps to evaluate whether this correlation exists. Saliency maps reveal directly
how much a change in each input pixel would affect reconstruction loss, while
each pixel&#x27;s reconstruction error may be attributed to many input pixels when
layers are fully connected. We compare saliency maps to reconstruction error
maps via qualitative visualizations as well as quantitative correspondence
between the top K elements of the maps for both novel and normal images. Our
results indicate that reconstruction error maps do not closely correlate with
the importance of pixels in the input images, making them insufficient for
novelty localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel CropdocNet for Automated Potato Late Blight Disease Detection from the Unmanned Aerial Vehicle-based Hyperspectral Imagery. (arXiv:2107.13277v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yue Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_L/0/1/0/all/0/1">Liangxiu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleerekoper_A/0/1/0/all/0/1">Anthony Kleerekoper</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Sheng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_T/0/1/0/all/0/1">Tongle Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13277">
                                    <div class="article-summary-box-inner">
                                        <span>Late blight disease is one of the most destructive diseases in potato crop,
leading to serious yield losses globally. Accurate diagnosis of the disease at
early stage is critical for precision disease control and management. Current
farm practices in crop disease diagnosis are based on manual visual inspection,
which is costly, time consuming, subject to individual bias. Recent advances in
imaging sensors (e.g. RGB, multiple spectral and hyperspectral cameras), remote
sensing and machine learning offer the opportunity to address this challenge.
Particularly, hyperspectral imagery (HSI) combining with machine learning/deep
learning approaches is preferable for accurately identifying specific plant
diseases because the HSI consists of a wide range of high-quality reflectance
information beyond human vision, capable of capturing both spectral-spatial
information. The proposed method considers the potential disease specific
reflectance radiation variance caused by the canopy structural diversity,
introduces the multiple capsule layers to model the hierarchical structure of
the spectral-spatial disease attributes with the encapsulated features to
represent the various classes and the rotation invariance of the disease
attributes in the feature space. We have evaluated the proposed method with the
real UAV-based HSI data under the controlled field conditions. The
effectiveness of the hierarchical features has been quantitatively assessed and
compared with the existing representative machine learning/deep learning
methods. The experiment results show that the proposed model significantly
improves the accuracy performance when considering hierarchical-structure of
spectral-spatial features, comparing to the existing methods only using
spectral, or spatial or spectral-spatial features without consider
hierarchical-structure of spectral-spatial features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Wireless Sensor Anomaly Detection based on Data Stream in Edge Computing Enabled Smart Greenhouse. (arXiv:2107.13353v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yihong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_S/0/1/0/all/0/1">Sheng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuwen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_S/0/1/0/all/0/1">Shunmei Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_X/0/1/0/all/0/1">Xiaoxiao Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_R/0/1/0/all/0/1">Rui Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Chao Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13353">
                                    <div class="article-summary-box-inner">
                                        <span>Edge computing enabled smart greenhouse is a representative application of
Internet of Things technology, which can monitor the environmental information
in real time and employ the information to contribute to intelligent
decision-making. In the process, anomaly detection for wireless sensor data
plays an important role. However, traditional anomaly detection algorithms
originally designed for anomaly detection in static data have not properly
considered the inherent characteristics of data stream produced by wireless
sensor such as infiniteness, correlations and concept drift, which may pose a
considerable challenge on anomaly detection based on data stream, and lead to
low detection accuracy and efficiency. First, data stream usually generates
quickly which means that it is infinite and enormous, so any traditional
off-line anomaly detection algorithm that attempts to store the whole dataset
or to scan the dataset multiple times for anomaly detection will run out of
memory space. Second, there exist correlations among different data streams,
which traditional algorithms hardly consider. Third, the underlying data
generation process or data distribution may change over time. Thus, traditional
anomaly detection algorithms with no model update will lose their effects.
Considering these issues, a novel method (called DLSHiForest) on basis of
Locality-Sensitive Hashing and time window technique in this paper is proposed
to solve these problems while achieving accurate and efficient detection.
Comprehensive experiments are executed using real-world agricultural greenhouse
dataset to demonstrate the feasibility of our approach. Experimental results
show that our proposal is practicable in addressing challenges of traditional
anomaly detection while ensuring accuracy and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Models of Computational Profiles to Study the Likelihood of DNN Metamorphic Test Cases. (arXiv:2107.13491v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Merlo_E/0/1/0/all/0/1">Ettore Merlo</a>, <a href="http://arxiv.org/find/cs/1/au:+Marhaba_M/0/1/0/all/0/1">Mira Marhaba</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a>, <a href="http://arxiv.org/find/cs/1/au:+Braiek_H/0/1/0/all/0/1">Houssem Ben Braiek</a>, <a href="http://arxiv.org/find/cs/1/au:+Antoniol_G/0/1/0/all/0/1">Giuliano Antoniol</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13491">
                                    <div class="article-summary-box-inner">
                                        <span>Neural network test cases are meant to exercise different reasoning paths in
an architecture and used to validate the prediction outcomes. In this paper, we
introduce &quot;computational profiles&quot; as vectors of neuron activation levels. We
investigate the distribution of computational profile likelihood of metamorphic
test cases with respect to the likelihood distributions of training, test and
error control cases. We estimate the non-parametric probability densities of
neuron activation levels for each distinct output class. Probabilities are
inferred using training cases only, without any additional knowledge about
metamorphic test cases. Experiments are performed by training a network on the
MNIST Fashion library of images and comparing prediction likelihoods with those
obtained from error control-data and from metamorphic test cases. Experimental
results show that the distributions of computational profile likelihood for
training and test cases are somehow similar, while the distribution of the
random-noise control-data is always remarkably lower than the observed one for
the training and testing sets. In contrast, metamorphic test cases show a
prediction likelihood that lies in an extended range with respect to training,
tests, and random noise. Moreover, the presented approach allows the
independent assessment of different training classes and experiments to show
that some of the classes are more sensitive to misclassifying metamorphic test
cases than other classes. In conclusion, metamorphic test cases represent very
aggressive tests for neural network architectures. Furthermore, since
metamorphic test cases force a network to misclassify those inputs whose
likelihood is similar to that of training cases, they could also be considered
as adversarial attacks that evade defenses based on computational profile
likelihood evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual-wav2vec2: an Application of Continual Learning for Self-Supervised Automatic Speech Recognition. (arXiv:2107.13530v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kessler_S/0/1/0/all/0/1">Samuel Kessler</a>, <a href="http://arxiv.org/find/eess/1/au:+Thomas_B/0/1/0/all/0/1">Bethan Thomas</a>, <a href="http://arxiv.org/find/eess/1/au:+Karout_S/0/1/0/all/0/1">Salah Karout</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13530">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for continual learning of speech representations for
multiple languages using self-supervised learning (SSL) and applying these for
automatic speech recognition. There is an abundance of unannotated speech, so
creating self-supervised representations from raw audio and finetuning on a
small annotated datasets is a promising direction to build speech recognition
systems. Wav2vec models perform SSL on raw audio in a pretraining phase and
then finetune on a small fraction of annotated data. SSL models have produced
state of the art results for ASR. However, these models are very expensive to
pretrain with self-supervision. We tackle the problem of learning new language
representations continually from audio without forgetting a previous language
representation. We use ideas from continual learning to transfer knowledge from
a previous task to speed up pretraining a new language task. Our
continual-wav2vec2 model can decrease pretraining times by 32% when learning a
new language task, and learn this new audio-language representation without
forgetting previous language representation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incentivizing Compliance with Algorithmic Instruments. (arXiv:2107.10093v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ngo_D/0/1/0/all/0/1">Daniel Ngo</a>, <a href="http://arxiv.org/find/cs/1/au:+Stapleton_L/0/1/0/all/0/1">Logan Stapleton</a>, <a href="http://arxiv.org/find/cs/1/au:+Syrgkanis_V/0/1/0/all/0/1">Vasilis Syrgkanis</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiwei Steven Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10093">
                                    <div class="article-summary-box-inner">
                                        <span>Randomized experiments can be susceptible to selection bias due to potential
non-compliance by the participants. While much of the existing work has studied
compliance as a static behavior, we propose a game-theoretic model to study
compliance as dynamic behavior that may change over time. In rounds, a social
planner interacts with a sequence of heterogeneous agents who arrive with their
unobserved private type that determines both their prior preferences across the
actions (e.g., control and treatment) and their baseline rewards without taking
any treatment. The planner provides each agent with a randomized recommendation
that may alter their beliefs and their action selection. We develop a novel
recommendation mechanism that views the planner&#x27;s recommendation as a form of
instrumental variable (IV) that only affects an agents&#x27; action selection, but
not the observed rewards. We construct such IVs by carefully mapping the
history -- the interactions between the planner and the previous agents -- to a
random recommendation. Even though the initial agents may be completely
non-compliant, our mechanism can incentivize compliance over time, thereby
enabling the estimation of the treatment effect of each treatment, and
minimizing the cumulative regret of the planner whose goal is to identify the
optimal treatment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective Eigendecomposition based Graph Adaptation for Heterophilic Networks. (arXiv:2107.13312v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lingam_V/0/1/0/all/0/1">Vijay Lingam</a>, <a href="http://arxiv.org/find/cs/1/au:+Ragesh_R/0/1/0/all/0/1">Rahul Ragesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Iyer_A/0/1/0/all/0/1">Arun Iyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sellamanickam_S/0/1/0/all/0/1">Sundararajan Sellamanickam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13312">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) exhibit excellent performance when graphs have
strong homophily property, i.e. connected nodes have the same labels. However,
they perform poorly on heterophilic graphs. Several approaches address the
issue of heterophily by proposing models that adapt the graph by optimizing
task-specific loss function using labelled data. These adaptations are made
either via attention or by attenuating or enhancing various
low-frequency/high-frequency signals, as needed for the task at hand. More
recent approaches adapt the eigenvalues of the graph. One important
interpretation of this adaptation is that these models select/weigh the
eigenvectors of the graph. Based on this interpretation, we present an
eigendecomposition based approach and propose EigenNetwork models that improve
the performance of GNNs on heterophilic graphs. Performance improvement is
achieved by learning flexible graph adaptation functions that modulate the
eigenvalues of the graph. Regularization of these functions via parameter
sharing helps to improve the performance even more. Our approach achieves up to
11% improvement in performance over the state-of-the-art methods on
heterophilic graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Retinal Microvasculature as Biomarker for Diabetes and Cardiovascular Diseases. (arXiv:2107.13157v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Trivedi_A/0/1/0/all/0/1">Anusua Trivedi</a>, <a href="http://arxiv.org/find/eess/1/au:+Desbiens_J/0/1/0/all/0/1">Jocelyn Desbiens</a>, <a href="http://arxiv.org/find/eess/1/au:+Gross_R/0/1/0/all/0/1">Ron Gross</a>, <a href="http://arxiv.org/find/eess/1/au:+Gupta_S/0/1/0/all/0/1">Sunil Gupta</a>, <a href="http://arxiv.org/find/eess/1/au:+Dodhia_R/0/1/0/all/0/1">Rahul Dodhia</a>, <a href="http://arxiv.org/find/eess/1/au:+Ferres_J/0/1/0/all/0/1">Juan Lavista Ferres</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13157">
                                    <div class="article-summary-box-inner">
                                        <span>Purpose: To demonstrate that retinal microvasculature per se is a reliable
biomarker for Diabetic Retinopathy (DR) and, by extension, cardiovascular
diseases. Methods: Deep Learning Convolutional Neural Networks (CNN) applied to
color fundus images for semantic segmentation of the blood vessels and severity
classification on both vascular and full images. Vessel reconstruction through
harmonic descriptors is also used as a smoothing and de-noising tool. The
mathematical background of the theory is also outlined. Results: For diabetic
patients, at least 93.8% of DR No-Refer vs. Refer classification can be related
to vasculature defects. As for the Non-Sight Threatening vs. Sight Threatening
case, the ratio is as high as 96.7%. Conclusion: In the case of DR, most of the
disease biomarkers are related topologically to the vasculature. Translational
Relevance: Experiments conducted on eye blood vasculature reconstruction as a
biomarker shows a strong correlation between vasculature shape and later stages
of DR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimROD: A Simple Adaptation Method for Robust Object Detection. (arXiv:2107.13389v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramamonjison_R/0/1/0/all/0/1">Rindra Ramamonjison</a>, <a href="http://arxiv.org/find/cs/1/au:+Banitalebi_Dehkordi_A/0/1/0/all/0/1">Amin Banitalebi-Dehkordi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xinyu Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xiaolong Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yong Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13389">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a Simple and effective unsupervised adaptation method for
Robust Object Detection (SimROD). To overcome the challenging issues of domain
shift and pseudo-label noise, our method integrates a novel domain-centric
augmentation method, a gradual self-labeling adaptation procedure, and a
teacher-guided fine-tuning mechanism. Using our method, target domain samples
can be leveraged to adapt object detection models without changing the model
architecture or generating synthetic data. When applied to image corruptions
and high-level cross-domain adaptation benchmarks, our method outperforms prior
baselines on multiple domain adaptation benchmarks. SimROD achieves new
state-of-the-art on standard real-to-synthetic and cross-camera setup
benchmarks. On the image corruption benchmark, models adapted with our method
achieved a relative robustness improvement of 15-25% AP50 on Pascal-C and 5-6%
AP on COCO-C and Cityscapes-C. On the cross-domain benchmark, our method
outperformed the best baseline performance by up to 8% AP50 on Comic dataset
and up to 4% on Watercolor dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vowel-based Meeteilon dialect identification using a Random Forest classifier. (arXiv:2107.13419v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Devi_T/0/1/0/all/0/1">Thangjam Clarinda Devi</a>, <a href="http://arxiv.org/find/eess/1/au:+Thaoroijam_K/0/1/0/all/0/1">Kabita Thaoroijam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13419">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a vowel-based dialect identification system for
Meeteilon. For this work, a vowel dataset is created by using Meeteilon Speech
Corpora available at Linguistic Data Consortium for Indian Languages (LDC-IL).
Spectral features such as formant frequencies (F1, F1 and F3) and prosodic
features such as pitch (F0), energy, intensity and segment duration values are
extracted from monophthong vowel sounds. Random forest classifier, a decision
tree-based ensemble algorithm is used for classification of three major
dialects of Meeteilon namely, Imphal, Kakching and Sekmai. Model has shown an
average dialect identification performance in terms of accuracy of around
61.57%. The role of spectral and prosodic features are found to be significant
in Meeteilon dialect classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">XFL: eXtreme Function Labeling. (arXiv:2107.13404v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patrick_Evans_J/0/1/0/all/0/1">James Patrick-Evans</a>, <a href="http://arxiv.org/find/cs/1/au:+Dannehl_M/0/1/0/all/0/1">Moritz Dannehl</a>, <a href="http://arxiv.org/find/cs/1/au:+Kinder_J/0/1/0/all/0/1">Johannes Kinder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13404">
                                    <div class="article-summary-box-inner">
                                        <span>Reverse engineers would benefit from identifiers like function names, but
these are usually unavailable in binaries. Training a machine learning model to
predict function names automatically is promising but fundamentally hard due to
the enormous number of classes. In this paper, we introduce eXtreme Function
Labeling (XFL), an extreme multi-label learning approach to selecting
appropriate labels for binary functions. XFL splits function names into tokens,
treating each as an informative label akin to the problem of tagging texts in
natural language. To capture the semantics of binary code, we introduce DEXTER,
a novel function embedding that combines static analysis-based features with
local context from the call graph and global context from the entire binary. We
demonstrate that XFL outperforms state-of-the-art approaches to function
labeling on a dataset of over 10,000 binaries from the Debian project,
achieving a precision of 82.5%. We also study combinations of XFL with
different published embeddings for binary functions and show that DEXTER
consistently improves over the state of the art in information gain. As a
result, we are able to show that binary function labeling is best phrased in
terms of multi-label learning, and that binary function embeddings benefit from
moving beyond just learning from syntax.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Snippet Policy Network for Multi-class Varied-length ECG Early Classification. (arXiv:2107.13361v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yen_G/0/1/0/all/0/1">Gary G. Yen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_V/0/1/0/all/0/1">Vincent S. Tseng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13361">
                                    <div class="article-summary-box-inner">
                                        <span>Arrhythmia detection from ECG is an important research subject in the
prevention and diagnosis of cardiovascular diseases. The prevailing studies
formulate arrhythmia detection from ECG as a time series classification
problem. Meanwhile, early detection of arrhythmia presents a real-world demand
for early prevention and diagnosis. In this paper, we address a problem of
cardiovascular disease early classification, which is a varied-length and
long-length time series early classification problem as well. For solving this
problem, we propose a deep reinforcement learning-based framework, namely
Snippet Policy Network (SPN), consisting of four modules, snippet generator,
backbone network, controlling agent, and discriminator. Comparing to the
existing approaches, the proposed framework features flexible input length,
solves the dual-optimization solution of the earliness and accuracy goals.
Experimental results demonstrate that SPN achieves an excellent performance of
over 80\% in terms of accuracy. Compared to the state-of-the-art methods, at
least 7% improvement on different metrics, including the precision, recall,
F1-score, and harmonic mean, is delivered by the proposed SPN. To the best of
our knowledge, this is the first work focusing on solving the cardiovascular
early classification problem based on varied-length ECG data. Based on these
excellent features from SPN, it offers a good exemplification for addressing
all kinds of varied-length time series early classification problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonlinear State Space Modeling and Control of the Impact of Patients&#x27; Modifiable Lifestyle Behaviors on the Emergence of Multiple Chronic Conditions. (arXiv:2107.13394v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Faruqui_S/0/1/0/all/0/1">Syed Hasib Akhter Faruqui</a>, <a href="http://arxiv.org/find/stat/1/au:+Alaeddini_A/0/1/0/all/0/1">Adel Alaeddini</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1">Jing Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Fisher_Hoch_S/0/1/0/all/0/1">Susan P Fisher-Hoch</a>, <a href="http://arxiv.org/find/stat/1/au:+Mccormic_J/0/1/0/all/0/1">Joseph B Mccormic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13394">
                                    <div class="article-summary-box-inner">
                                        <span>The emergence and progression of multiple chronic conditions (MCC) over time
often form a dynamic network that depends on patient&#x27;s modifiable risk factors
and their interaction with non-modifiable risk factors and existing conditions.
Continuous time Bayesian networks (CTBNs) are effective methods for modeling
the complex network of MCC relationships over time. However, CTBNs are not able
to effectively formulate the dynamic impact of patient&#x27;s modifiable risk
factors on the emergence and progression of MCC. Considering a functional CTBN
(FCTBN) to represent the underlying structure of the MCC relationships with
respect to individuals&#x27; risk factors and existing conditions, we propose a
nonlinear state-space model based on Extended Kalman filter (EKF) to capture
the dynamics of the patients&#x27; modifiable risk factors and existing conditions
on the MCC evolution over time. We also develop a tensor control chart to
dynamically monitor the effect of changes in the modifiable risk factors of
individual patients on the risk of new chronic conditions emergence. We
validate the proposed approach based on a combination of simulation and real
data from a dataset of 385 patients from Cameron County Hispanic Cohort (CCHC)
over multiple years. The dataset examines the emergence of 5 chronic conditions
(Diabetes, Obesity, Cognitive Impairment, Hyperlipidemia, and Hypertension)
based on 4 modifiable risk factors representing lifestyle behaviors (Diet,
Exercise, Smoking Habit, and Drinking Habit) and 3 non-modifiable risk factors,
including demographic information (Age, Gender, Education). The results
demonstrate the effectiveness of the proposed methodology for dynamic
prediction and monitoring of the risk of MCC emergence in individual patients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Unstructured Handwashing Recognition using Smartwatch to Reduce Contact Transmission of Pathogens. (arXiv:2107.13405v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lattanzi_E/0/1/0/all/0/1">Emanuele Lattanzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Calisti_L/0/1/0/all/0/1">Lorenzo Calisti</a>, <a href="http://arxiv.org/find/cs/1/au:+Freschi_V/0/1/0/all/0/1">Valerio Freschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13405">
                                    <div class="article-summary-box-inner">
                                        <span>Current guidelines from the World Health Organization indicate that the
SARSCoV-2 coronavirus, which results in the novel coronavirus disease
(COVID-19), is transmitted through respiratory droplets or by contact. Contact
transmission occurs when contaminated hands touch the mucous membrane of the
mouth, nose, or eyes. Moreover, pathogens can also be transferred from one
surface to another by contaminated hands, which facilitates transmission by
indirect contact. Consequently, hands hygiene is extremely important to prevent
the spread of the SARSCoV-2 virus. Additionally, hand washing and/or hand
rubbing disrupts also the transmission of other viruses and bacteria that cause
common colds, flu and pneumonia, thereby reducing the overall disease burden.
The vast proliferation of wearable devices, such as smartwatches, containing
acceleration, rotation, magnetic field sensors, etc., together with the modern
technologies of artificial intelligence, such as machine learning and more
recently deep-learning, allow the development of accurate applications for
recognition and classification of human activities such as: walking, climbing
stairs, running, clapping, sitting, sleeping, etc. In this work we evaluate the
feasibility of an automatic system, based on current smartwatches, which is
able to recognize when a subject is washing or rubbing its hands, in order to
monitor parameters such as frequency and duration, and to evaluate the
effectiveness of the gesture. Our preliminary results show a classification
accuracy of about 95% and of about 94% for respectively deep and standard
learning techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Neural Schema Alignment for OpenStreetMap and Knowledge Graphs. (arXiv:2107.13257v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dsouza_A/0/1/0/all/0/1">Alishiba Dsouza</a>, <a href="http://arxiv.org/find/cs/1/au:+Tempelmeier_N/0/1/0/all/0/1">Nicolas Tempelmeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Demidova_E/0/1/0/all/0/1">Elena Demidova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13257">
                                    <div class="article-summary-box-inner">
                                        <span>OpenStreetMap (OSM) is one of the richest openly available sources of
volunteered geographic information. Although OSM includes various geographical
entities, their descriptions are highly heterogeneous, incomplete, and do not
follow any well-defined ontology. Knowledge graphs can potentially provide
valuable semantic information to enrich OSM entities. However, interlinking OSM
entities with knowledge graphs is inherently difficult due to the large,
heterogeneous, ambiguous, and flat OSM schema and the annotation sparsity. This
paper tackles the alignment of OSM tags with the corresponding knowledge graph
classes holistically by jointly considering the schema and instance layers. We
propose a novel neural architecture that capitalizes upon a shared latent space
for tag-to-class alignment created using linked entities in OSM and knowledge
graphs. Our experiments performed to align OSM datasets for several countries
with two of the most prominent openly available knowledge graphs, namely,
Wikidata and DBpedia, demonstrate that the proposed approach outperforms the
state-of-the-art schema alignment baselines by up to 53 percentage points in
terms of F1-score. The resulting alignment facilitates new semantic annotations
for over 10 million OSM entities worldwide, which is more than a 400% increase
compared to the existing semantic annotations in OSM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SONG: Self-Organizing Neural Graphs. (arXiv:2107.13214v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Struski_L/0/1/0/all/0/1">&#x141;ukasz Struski</a>, <a href="http://arxiv.org/find/cs/1/au:+Danel_T/0/1/0/all/0/1">Tomasz Danel</a>, <a href="http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1">Marek &#x15a;mieja</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1">Jacek Tabor</a>, <a href="http://arxiv.org/find/cs/1/au:+Zielinski_B/0/1/0/all/0/1">Bartosz Zieli&#x144;ski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13214">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen a surge in research on deep interpretable neural
networks with decision trees as one of the most commonly incorporated tools.
There are at least three advantages of using decision trees over logistic
regression classification models: they are easy to interpret since they are
based on binary decisions, they can make decisions faster, and they provide a
hierarchy of classes. However, one of the well-known drawbacks of decision
trees, as compared to decision graphs, is that decision trees cannot reuse the
decision nodes. Nevertheless, decision graphs were not commonly used in deep
learning due to the lack of efficient gradient-based training techniques. In
this paper, we fill this gap and provide a general paradigm based on Markov
processes, which allows for efficient training of the special type of decision
graphs, which we call Self-Organizing Neural Graphs (SONG). We provide an
extensive theoretical study of SONG, complemented by experiments conducted on
Letter, Connect4, MNIST, CIFAR, and TinyImageNet datasets, showing that our
method performs on par or better than existing decision models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Autoencoders for Drift Detection in Industrial Environments. (arXiv:2107.13249v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yong_B/0/1/0/all/0/1">Bang Xiang Yong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fathy_Y/0/1/0/all/0/1">Yasmin Fathy</a>, <a href="http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1">Alexandra Brintrup</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13249">
                                    <div class="article-summary-box-inner">
                                        <span>Autoencoders are unsupervised models which have been used for detecting
anomalies in multi-sensor environments. A typical use includes training a
predictive model with data from sensors operating under normal conditions and
using the model to detect anomalies. Anomalies can come either from real
changes in the environment (real drift) or from faulty sensory devices (virtual
drift); however, the use of Autoencoders to distinguish between different
anomalies has not yet been considered. To this end, we first propose the
development of Bayesian Autoencoders to quantify epistemic and aleatoric
uncertainties. We then test the Bayesian Autoencoder using a real-world
industrial dataset for hydraulic condition monitoring. The system is injected
with noise and drifts, and we have found the epistemic uncertainty to be less
sensitive to sensor perturbations as compared to the reconstruction loss. By
observing the reconstructed signals with the uncertainties, we gain
interpretable insights, and these uncertainties offer a potential avenue for
distinguishing real and virtual drifts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning with Multiclass AUC: Theory and Algorithms. (arXiv:2107.13171v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhiyong Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qianqian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_S/0/1/0/all/0/1">Shilong Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiaochun Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qingming Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13171">
                                    <div class="article-summary-box-inner">
                                        <span>The Area under the ROC curve (AUC) is a well-known ranking metric for
problems such as imbalanced learning and recommender systems. The vast majority
of existing AUC-optimization-based machine learning methods only focus on
binary-class cases, while leaving the multiclass cases unconsidered. In this
paper, we start an early trial to consider the problem of learning multiclass
scoring functions via optimizing multiclass AUC metrics. Our foundation is
based on the M metric, which is a well-known multiclass extension of AUC. We
first pay a revisit to this metric, showing that it could eliminate the
imbalance issue from the minority class pairs. Motivated by this, we propose an
empirical surrogate risk minimization framework to approximately optimize the M
metric. Theoretically, we show that: (i) optimizing most of the popular
differentiable surrogate losses suffices to reach the Bayes optimal scoring
function asymptotically; (ii) the training framework enjoys an imbalance-aware
generalization error bound, which pays more attention to the bottleneck samples
of minority classes compared with the traditional $O(\sqrt{1/N})$ result.
Practically, to deal with the low scalability of the computational operations,
we propose acceleration methods for three popular surrogate loss functions,
including the exponential loss, squared loss, and hinge loss, to speed up loss
and gradient evaluations. Finally, experimental results on 11 real-world
datasets demonstrate the effectiveness of our proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepTeeth: A Teeth-photo Based Human Authentication System for Mobile and Hand-held Devices. (arXiv:2107.13217v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Arora_G/0/1/0/all/0/1">Geetika Arora</a>, <a href="http://arxiv.org/find/cs/1/au:+Bharadwaj_R/0/1/0/all/0/1">Rohit K Bharadwaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_K/0/1/0/all/0/1">Kamlesh Tiwari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13217">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes teeth-photo, a new biometric modality for human
authentication on mobile and hand held devices. Biometrics samples are acquired
using the camera mounted on mobile device with the help of a mobile application
having specific markers to register the teeth area. Region of interest (RoI) is
then extracted using the markers and the obtained sample is enhanced using
contrast limited adaptive histogram equalization (CLAHE) for better visual
clarity. We propose a deep learning architecture and novel regularization
scheme to obtain highly discriminative embedding for small size RoI. Proposed
custom loss function was able to achieve perfect classification for the tiny
RoI of $75\times 75$ size. The model is end-to-end and few-shot and therefore
is very efficient in terms of time and energy requirements. The system can be
used in many ways including device unlocking and secure authentication. To the
best of our understanding, this is the first work on teeth-photo based
authentication for mobile device. Experiments have been conducted on an
in-house teeth-photo database collected using our application. The database is
made publicly available. Results have shown that the proposed system has
perfect accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AutoML Meets Time Series Regression Design and Analysis of the AutoSeries Challenge. (arXiv:2107.13186v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_W/0/1/0/all/0/1">Wei-Wei Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guyon_I/0/1/0/all/0/1">Isabelle Guyon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13186">
                                    <div class="article-summary-box-inner">
                                        <span>Analyzing better time series with limited human effort is of interest to
academia and industry. Driven by business scenarios, we organized the first
Automated Time Series Regression challenge (AutoSeries) for the WSDM Cup 2020.
We present its design, analysis, and post-hoc experiments. The code submission
requirement precluded participants from any manual intervention, testing
automated machine learning capabilities of solutions, across many datasets,
under hardware and time limitations. We prepared 10 datasets from diverse
application domains (sales, power consumption, air quality, traffic, and
parking), featuring missing data, mixed continuous and categorical variables,
and various sampling rates. Each dataset was split into a training and a test
sequence (which was streamed, allowing models to continuously adapt). The
setting of time series regression, differs from classical forecasting in that
covariates at the present time are known. Great strides were made by
participants to tackle this AutoSeries problem, as demonstrated by the jump in
performance from the sample submission, and post-hoc comparisons with
AutoGluon. Simple yet effective methods were used, based on feature
engineering, LightGBM, and random search hyper-parameter tuning, addressing all
aspects of the challenge. Our post-hoc analyses revealed that providing
additional time did not yield significant improvements. The winners&#x27; code was
open-sourced https://www.4paradigm.com/competition/autoseries2020.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Graph Convolutional-Recurrent Neural Network (MGC-RNN) for Short-Term Forecasting of Transit Passenger Flow. (arXiv:2107.13226v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yuxin He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lishuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xinting Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsui_K/0/1/0/all/0/1">Kwok Leung Tsui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13226">
                                    <div class="article-summary-box-inner">
                                        <span>Short-term forecasting of passenger flow is critical for transit management
and crowd regulation. Spatial dependencies, temporal dependencies,
inter-station correlations driven by other latent factors, and exogenous
factors bring challenges to the short-term forecasts of passenger flow of urban
rail transit networks. An innovative deep learning approach, Multi-Graph
Convolutional-Recurrent Neural Network (MGC-RNN) is proposed to forecast
passenger flow in urban rail transit systems to incorporate these complex
factors. We propose to use multiple graphs to encode the spatial and other
heterogenous inter-station correlations. The temporal dynamics of the
inter-station correlations are also modeled via the proposed multi-graph
convolutional-recurrent neural network structure. Inflow and outflow of all
stations can be collectively predicted with multiple time steps ahead via a
sequence to sequence(seq2seq) architecture. The proposed method is applied to
the short-term forecasts of passenger flow in Shenzhen Metro, China. The
experimental results show that MGC-RNN outperforms the benchmark algorithms in
terms of forecasting accuracy. Besides, it is found that the inter-station
driven by network distance, network structure, and recent flow patterns are
significant factors for passenger flow forecasting. Moreover, the architecture
of LSTM-encoder-decoder can capture the temporal dependencies well. In general,
the proposed framework could provide multiple views of passenger flow dynamics
for fine prediction and exhibit a possibility for multi-source heterogeneous
data fusion in the spatiotemporal forecast tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Hybrid Inference in State-Space Models. (arXiv:2107.13349v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruhe_D/0/1/0/all/0/1">David Ruhe</a>, <a href="http://arxiv.org/find/cs/1/au:+Forre_P/0/1/0/all/0/1">Patrick Forr&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13349">
                                    <div class="article-summary-box-inner">
                                        <span>We perform approximate inference in state-space models that allow for
nonlinear higher-order Markov chains in latent space. The conditional
independencies of the generative model enable us to parameterize only an
inference model, which learns to estimate clean states in a self-supervised
manner using maximum likelihood. First, we propose a recurrent method that is
trained directly on noisy observations. Afterward, we cast the model such that
the optimization problem leads to an update scheme that backpropagates through
a recursion similar to the classical Kalman filter and smoother. In scientific
applications, domain knowledge can give a linear approximation of the latent
transition maps. We can easily incorporate this knowledge into our model,
leading to a hybrid inference approach. In contrast to other methods,
experiments show that the hybrid method makes the inferred latent states
physically more interpretable and accurate, especially in low-data regimes.
Furthermore, we do not rely on an additional parameterization of the generative
model or supervision via uncorrupted observations or ground truth latent
states. Despite our model&#x27;s simplicity, we obtain competitive results on the
chaotic Lorenz system compared to a fully supervised approach and outperform a
method based on variational inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward AI Assistants That Let Designers Design. (arXiv:2107.13074v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peuter_S/0/1/0/all/0/1">Sebastiaan De Peuter</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Oulasvirta_A/0/1/0/all/0/1">Antti Oulasvirta</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1">Samuel Kaski</a> (1 and 3) ((1) Department of Computer Science, Aalto University, Finland, (2) Department of Communications and Networking, Aalto University, Finland, (3) Department of Computer Science, University of Manchester, UK)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13074">
                                    <div class="article-summary-box-inner">
                                        <span>AI for supporting designers needs to be rethought. It should aim to
cooperate, not automate, by supporting and leveraging the creativity and
problem-solving of designers. The challenge for such AI is how to infer
designers&#x27; goals and then help them without being needlessly disruptive. We
present AI-assisted design: a framework for creating such AI, built around
generative user models which enable reasoning about designers&#x27; goals,
reasoning, and capabilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Learning of Neurosymbolic Encoders. (arXiv:2107.13132v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhan_E/0/1/0/all/0/1">Eric Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jennifer J. Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kennedy_A/0/1/0/all/0/1">Ann Kennedy</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1">Yisong Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1">Swarat Chaudhuri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13132">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework for the unsupervised learning of neurosymbolic
encoders, i.e., encoders obtained by composing neural networks with symbolic
programs from a domain-specific language. Such a framework can naturally
incorporate symbolic expert knowledge into the learning process and lead to
more interpretable and factorized latent representations than fully neural
encoders. Also, models learned this way can have downstream impact, as many
analysis workflows can benefit from having clean programmatic descriptions. We
ground our learning algorithm in the variational autoencoding (VAE) framework,
where we aim to learn a neurosymbolic encoder in conjunction with a standard
decoder. Our algorithm integrates standard VAE-style training with modern
program synthesis techniques. We evaluate our method on learning latent
representations for real-world trajectory data from animal biology and sports
analytics. We show that our approach offers significantly better separation
than standard VAEs and leads to practical gains on downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi Agent System for Machine Learning Under Uncertainty in Cyber Physical Manufacturing System. (arXiv:2107.13252v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yong_B/0/1/0/all/0/1">Bang Xiang Yong</a>, <a href="http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1">Alexandra Brintrup</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13252">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in predictive machine learning has led to its application
in various use cases in manufacturing. Most research focused on maximising
predictive accuracy without addressing the uncertainty associated with it.
While accuracy is important, focusing primarily on it poses an overfitting
danger, exposing manufacturers to risk, ultimately hindering the adoption of
these techniques. In this paper, we determine the sources of uncertainty in
machine learning and establish the success criteria of a machine learning
system to function well under uncertainty in a cyber-physical manufacturing
system (CPMS) scenario. Then, we propose a multi-agent system architecture
which leverages probabilistic machine learning as a means of achieving such
criteria. We propose possible scenarios for which our proposed architecture is
useful and discuss future work. Experimentally, we implement Bayesian Neural
Networks for multi-tasks classification on a public dataset for the real-time
condition monitoring of a hydraulic system and demonstrate the usefulness of
the system by evaluating the probability of a prediction being accurate given
its uncertainty. We deploy these models using our proposed agent-based
framework and integrate web visualisation to demonstrate its real-time
feasibility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Chance constrained conic-segmentation support vector machine with uncertain data. (arXiv:2107.13319v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shen Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Canessa_G/0/1/0/all/0/1">Gianpiero Canessa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13319">
                                    <div class="article-summary-box-inner">
                                        <span>Support vector machines (SVM) is one of the well known supervised classes of
learning algorithms. Furthermore, the conic-segmentation SVM (CS-SVM) is a
natural multiclass analogue of the standard binary SVM, as CS-SVM models are
dealing with the situation where the exact values of the data points are known.
This paper studies CS-SVM when the data points are uncertain or mislabelled.
With some properties known for the distributions, a chance-constrained CS-SVM
approach is used to ensure the small probability of misclassification for the
uncertain data. The geometric interpretation is presented to show how CS-SVM
works. Finally, we present experimental results to investigate the chance
constrained CS-SVM&#x27;s performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meaning Versus Information, Prediction Versus Memory, and Question Versus Answer. (arXiv:2107.13393v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Choe_Y/0/1/0/all/0/1">Yoonsuck Choe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13393">
                                    <div class="article-summary-box-inner">
                                        <span>Brain science and artificial intelligence have made great progress toward the
understanding and engineering of the human mind. The progress has accelerated
significantly since the turn of the century thanks to new methods for probing
the brain (both structure and function), and rapid development in deep learning
research. However, despite these new developments, there are still many open
questions, such as how to understand the brain at the system level, and various
robustness issues and limitations of deep learning. In this informal essay, I
will talk about some of the concepts that are central to brain science and
artificial intelligence, such as information and memory, and discuss how a
different view on these concepts can help us move forward, beyond current
limits of our understanding in these fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Storytelling for Children: A Case-study of Design and Development Considerations for Ethical Conversational AI. (arXiv:2107.13076v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chubba_e/0/1/0/all/0/1">ennifer Chubba</a>, <a href="http://arxiv.org/find/cs/1/au:+Missaouib_S/0/1/0/all/0/1">Sondess Missaouib</a>, <a href="http://arxiv.org/find/cs/1/au:+Concannonc_S/0/1/0/all/0/1">Shauna Concannonc</a>, <a href="http://arxiv.org/find/cs/1/au:+Maloneyb_L/0/1/0/all/0/1">Liam Maloneyb</a>, <a href="http://arxiv.org/find/cs/1/au:+Walker_J/0/1/0/all/0/1">James Alfred Walker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13076">
                                    <div class="article-summary-box-inner">
                                        <span>Conversational Artificial Intelligence (CAI) systems and Intelligent Personal
Assistants (IPA), such as Alexa, Cortana, Google Home and Siri are becoming
ubiquitous in our lives, including those of children, the implications of which
is receiving increased attention, specifically with respect to the effects of
these systems on children&#x27;s cognitive, social and linguistic development.
Recent advances address the implications of CAI with respect to privacy,
safety, security, and access. However, there is a need to connect and embed the
ethical and technical aspects in the design. Using a case-study of a research
and development project focused on the use of CAI in storytelling for children,
this paper reflects on the social context within a specific case of technology
development, as substantiated and supported by argumentation from within the
literature. It describes the decision making process behind the recommendations
made on this case for their adoption in the creative industries. Further
research that engages with developers and stakeholders in the ethics of
storytelling through CAI is highlighted as a matter of urgency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pixyz: a library for developing deep generative models. (arXiv:2107.13109v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suzuki_M/0/1/0/all/0/1">Masahiro Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaneko_T/0/1/0/all/0/1">Takaaki Kaneko</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsuo_Y/0/1/0/all/0/1">Yutaka Matsuo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13109">
                                    <div class="article-summary-box-inner">
                                        <span>With the recent rapid progress in the study of deep generative models (DGMs),
there is a need for a framework that can implement them in a simple and generic
way. In this research, we focus on two features of the latest DGMs: (1) deep
neural networks are encapsulated by probability distributions and (2) models
are designed and learned based on an objective function. Taking these features
into account, we propose a new DGM library called Pixyz. We experimentally show
that our library is faster than existing probabilistic modeling languages in
learning simple DGMs and we show that our library can be used to implement
complex DGMs in a simple and concise manner, which is difficult to do with
existing libraries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Doing Great at Estimating CATE? On the Neglected Assumptions in Benchmark Comparisons of Treatment Effect Estimators. (arXiv:2107.13346v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Curth_A/0/1/0/all/0/1">Alicia Curth</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13346">
                                    <div class="article-summary-box-inner">
                                        <span>The machine learning toolbox for estimation of heterogeneous treatment
effects from observational data is expanding rapidly, yet many of its
algorithms have been evaluated only on a very limited set of semi-synthetic
benchmark datasets. In this paper, we show that even in arguably the simplest
setting -- estimation under ignorability assumptions -- the results of such
empirical evaluations can be misleading if (i) the assumptions underlying the
data-generating mechanisms in benchmark datasets and (ii) their interplay with
baseline algorithms are inadequately discussed. We consider two popular machine
learning benchmark datasets for evaluation of heterogeneous treatment effect
estimators -- the IHDP and ACIC2016 datasets -- in detail. We identify problems
with their current use and highlight that the inherent characteristics of the
benchmark datasets favor some algorithms over others -- a fact that is rarely
acknowledged but of immense relevance for interpretation of empirical results.
We close by discussing implications and possible next steps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Unsupervised Domain Adaptation with Conditional and Label Shift: Infer, Align and Iterate. (arXiv:2107.13469v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhenhua Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Site Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_F/0/1/0/all/0/1">Fangxu Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jane You</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakhri_G/0/1/0/all/0/1">Georges El Fakhri</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1">Jonghye Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13469">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose an adversarial unsupervised domain adaptation (UDA)
approach with the inherent conditional and label shifts, in which we aim to
align the distributions w.r.t. both $p(x|y)$ and $p(y)$. Since the label is
inaccessible in the target domain, the conventional adversarial UDA assumes
$p(y)$ is invariant across domains, and relies on aligning $p(x)$ as an
alternative to the $p(x|y)$ alignment. To address this, we provide a thorough
theoretical and empirical analysis of the conventional adversarial UDA methods
under both conditional and label shifts, and propose a novel and practical
alternative optimization scheme for adversarial UDA. Specifically, we infer the
marginal $p(y)$ and align $p(x|y)$ iteratively in the training, and precisely
align the posterior $p(y|x)$ in testing. Our experimental results demonstrate
its effectiveness on both classification and segmentation UDA, and partial UDA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Policy Gradient Methods Find the Nash Equilibrium in N-player General-sum Linear-quadratic Games. (arXiv:2107.13090v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Hambly_B/0/1/0/all/0/1">Ben Hambly</a>, <a href="http://arxiv.org/find/math/1/au:+Xu_R/0/1/0/all/0/1">Renyuan Xu</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_H/0/1/0/all/0/1">Huining Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13090">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a general-sum N-player linear-quadratic game with stochastic
dynamics over a finite horizon and prove the global convergence of the natural
policy gradient method to the Nash equilibrium. In order to prove the
convergence of the method, we require a certain amount of noise in the system.
We give a condition, essentially a lower bound on the covariance of the noise
in terms of the model parameters, in order to guarantee convergence. We
illustrate our results with numerical experiments to show that even in
situations where the policy gradient method may not converge in the
deterministic setting, the addition of noise leads to convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Removing Operational Friction Using Process Mining: Challenges Provided by the Internet of Production (IoP). (arXiv:2107.13066v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aalst_W/0/1/0/all/0/1">Wil van der Aalst</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockhoff_T/0/1/0/all/0/1">Tobias Brockhoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghahfarokhi_A/0/1/0/all/0/1">Anahita Farhang Ghahfarokhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pourbafrani_M/0/1/0/all/0/1">Mahsa Pourbafrani</a>, <a href="http://arxiv.org/find/cs/1/au:+Uysal_M/0/1/0/all/0/1">Merih Seran Uysal</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelst_S/0/1/0/all/0/1">Sebastiaan van Zelst</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13066">
                                    <div class="article-summary-box-inner">
                                        <span>Operational processes in production, logistics, material handling,
maintenance, etc., are supported by cyber-physical systems combining hardware
and software components. As a result, the digital and the physical world are
closely aligned, and it is possible to track operational processes in detail
(e.g., using sensors). The abundance of event data generated by today&#x27;s
operational processes provides opportunities and challenges for process mining
techniques supporting process discovery, performance analysis, and conformance
checking. Using existing process mining tools, it is already possible to
automatically discover process models and uncover performance and compliance
problems. In the DFG-funded Cluster of Excellence &quot;Internet of Production&quot;
(IoP), process mining is used to create &quot;digital shadows&quot; to improve a wide
variety of operational processes. However, operational processes are dynamic,
distributed, and complex. Driven by the challenges identified in the IoP
cluster, we work on novel techniques for comparative process mining (comparing
process variants for different products at different locations at different
times), object-centric process mining (to handle processes involving different
types of objects that interact), and forward-looking process mining (to explore
&quot;What if?&quot; questions). By addressing these challenges, we aim to develop
valuable &quot;digital shadows&quot; that can be used to remove operational friction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Homogeneous Architecture Augmentation for Neural Predictor. (arXiv:2107.13153v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yuqiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yehui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yanan Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13153">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Architecture Search (NAS) can automatically design well-performed
architectures of Deep Neural Networks (DNNs) for the tasks at hand. However,
one bottleneck of NAS is the prohibitively computational cost largely due to
the expensive performance evaluation. The neural predictors can directly
estimate the performance without any training of the DNNs to be evaluated, thus
have drawn increasing attention from researchers. Despite their popularity,
they also suffer a severe limitation: the shortage of annotated DNN
architectures for effectively training the neural predictors. In this paper, we
proposed Homogeneous Architecture Augmentation for Neural Predictor (HAAP) of
DNN architectures to address the issue aforementioned. Specifically, a
homogeneous architecture augmentation algorithm is proposed in HAAP to generate
sufficient training data taking the use of homogeneous representation.
Furthermore, the one-hot encoding strategy is introduced into HAAP to make the
representation of DNN architectures more effective. The experiments have been
conducted on both NAS-Benchmark-101 and NAS-Bench-201 dataset. The experimental
results demonstrate that the proposed HAAP algorithm outperforms the state of
the arts compared, yet with much less training data. In addition, the ablation
studies on both benchmark datasets have also shown the universality of the
homogeneous architecture augmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Q-Learning for Conflict Resolution in B5G Network Automation. (arXiv:2107.13268v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Majumdar_S/0/1/0/all/0/1">Sayantini Majumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivisonno_R/0/1/0/all/0/1">Riccardo Trivisonno</a>, <a href="http://arxiv.org/find/cs/1/au:+Carle_G/0/1/0/all/0/1">Georg Carle</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13268">
                                    <div class="article-summary-box-inner">
                                        <span>Network automation is gaining significant attention in the development of B5G
networks, primarily for reducing operational complexity, expenditures and
improving network efficiency. Concurrently operating closed loops aiming for
individual optimization targets may cause conflicts which, left unresolved,
would lead to significant degradation in network Key Performance Indicators
(KPIs), thereby resulting in sub-optimal network performance. Centralized
coordination, albeit optimal, is impractical in large scale networks and for
time-critical applications. Decentralized approaches are therefore envisaged in
the evolution to B5G and subsequently, 6G networks. This work explores
pervasive intelligence for conflict resolution in network automation, as an
alternative to centralized orchestration. A Q-Learning decentralized approach
to network automation is proposed, and an application to network slice
auto-scaling is designed and evaluated. Preliminary results highlight the
potential of the proposed scheme and justify further research work in this
direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reenvisioning Collaborative Filtering vs Matrix Factorization. (arXiv:2107.13472v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anelli_V/0/1/0/all/0/1">Vito Walter Anelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bellogin_A/0/1/0/all/0/1">Alejandro Bellog&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Noia_T/0/1/0/all/0/1">Tommaso Di Noia</a>, <a href="http://arxiv.org/find/cs/1/au:+Pomo_C/0/1/0/all/0/1">Claudio Pomo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13472">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative filtering models based on matrix factorization and learned
similarities using Artificial Neural Networks (ANNs) have gained significant
attention in recent years. This is, in part, because ANNs have demonstrated
good results in a wide variety of recommendation tasks. The introduction of
ANNs within the recommendation ecosystem has been recently questioned, raising
several comparisons in terms of efficiency and effectiveness. One aspect most
of these comparisons have in common is their focus on accuracy, neglecting
other evaluation dimensions important for the recommendation, such as novelty,
diversity, or accounting for biases. We replicate experiments from three papers
that compare Neural Collaborative Filtering (NCF) and Matrix Factorization
(MF), to extend the analysis to other evaluation dimensions. Our contribution
shows that the experiments are entirely reproducible, and we extend the study
including other accuracy metrics and two statistical hypothesis tests. We
investigated the Diversity and Novelty of the recommendations, showing that MF
provides a better accuracy also on the long tail, although NCF provides a
better item coverage and more diversified recommendations. We discuss the bias
effect generated by the tested methods. They show a relatively small bias, but
other recommendation baselines, with competitive accuracy performance,
consistently show to be less affected by this issue. This is the first work, to
the best of our knowledge, where several evaluation dimensions have been
explored for an array of SOTA algorithms covering recent adaptations of ANNs
and MF. Hence, we show the potential these techniques may have on
beyond-accuracy evaluation while analyzing the effect on reproducibility these
complementary dimensions may spark. Available at
github.com/sisinflab/Reenvisioning-the-comparison-between-Neural-Collaborative-Filtering-and-Matrix-Factorization</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recursively Conditional Gaussian for Ordinal Unsupervised Domain Adaptation. (arXiv:2107.13467v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Site Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1">Yubin Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_P/0/1/0/all/0/1">Pengyi Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jane You</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13467">
                                    <div class="article-summary-box-inner">
                                        <span>There has been a growing interest in unsupervised domain adaptation (UDA) to
alleviate the data scalability issue, while the existing works usually focus on
classifying independently discrete labels. However, in many tasks (e.g.,
medical diagnosis), the labels are discrete and successively distributed. The
UDA for ordinal classification requires inducing non-trivial ordinal
distribution prior to the latent space. Target for this, the partially ordered
set (poset) is defined for constraining the latent vector. Instead of the
typically i.i.d. Gaussian latent prior, in this work, a recursively conditional
Gaussian (RCG) set is proposed for ordered constraint modeling, which admits a
tractable joint distribution prior. Furthermore, we are able to control the
density of content vectors that violate the poset constraint by a simple
&quot;three-sigma rule&quot;. We explicitly disentangle the cross-domain images into a
shared ordinal prior induced ordinal content space and two separate
source/target ordinal-unrelated spaces, and the self-training is worked on the
shared space exclusively for ordinal-aware domain alignment. Extensive
experiments on UDA medical diagnoses and facial age estimation demonstrate its
effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explicit Pairwise Factorized Graph Neural Network for Semi-Supervised Node Classification. (arXiv:2107.13059v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuesong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1">Daniel Cremers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13059">
                                    <div class="article-summary-box-inner">
                                        <span>Node features and structural information of a graph are both crucial for
semi-supervised node classification problems. A variety of graph neural network
(GNN) based approaches have been proposed to tackle these problems, which
typically determine output labels through feature aggregation. This can be
problematic, as it implies conditional independence of output nodes given
hidden representations, despite their direct connections in the graph. To learn
the direct influence among output nodes in a graph, we propose the Explicit
Pairwise Factorized Graph Neural Network (EPFGNN), which models the whole graph
as a partially observed Markov Random Field. It contains explicit pairwise
factors to model output-output relations and uses a GNN backbone to model
input-output relations. To balance model complexity and expressivity, the
pairwise factors have a shared component and a separate scaling coefficient for
each edge. We apply the EM algorithm to train our model, and utilize a
star-shaped piecewise likelihood for the tractable surrogate objective. We
conduct experiments on various datasets, which shows that our model can
effectively improve the performance for semi-supervised node classification on
graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Functorial String Diagrams for Reverse-Mode Automatic Differentiation. (arXiv:2107.13433v1 [cs.PL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alvarez_Picallo_M/0/1/0/all/0/1">Mario Alvarez-Picallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghica_D/0/1/0/all/0/1">Dan R. Ghica</a>, <a href="http://arxiv.org/find/cs/1/au:+Sprunger_D/0/1/0/all/0/1">David Sprunger</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanasi_F/0/1/0/all/0/1">Fabio Zanasi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13433">
                                    <div class="article-summary-box-inner">
                                        <span>We enhance the calculus of string diagrams for monoidal categories with
hierarchical features in order to capture closed monoidal (and cartesian
closed) structure. Using this new syntax we formulate an automatic
differentiation algorithm for (applied) simply typed lambda calculus in the
style of [Pearlmutter and Siskind 2008] and we prove for the first time its
soundness. To give an efficient yet principled implementation of the AD
algorithm we define a sound and complete representation of hierarchical string
diagrams as a class of hierarchical hypergraphs we call hypernets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Surrogate Model-Based Explainability Methods for Point Cloud NNs. (arXiv:2107.13459v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1">Hanxiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kotthaus_H/0/1/0/all/0/1">Helena Kotthaus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13459">
                                    <div class="article-summary-box-inner">
                                        <span>In the field of autonomous driving and robotics, point clouds are showing
their excellent real-time performance as raw data from most of the mainstream
3D sensors. Therefore, point cloud neural networks have become a popular
research direction in recent years. So far, however, there has been little
discussion about the explainability of deep neural networks for point clouds.
In this paper, we propose new explainability approaches for point cloud deep
neural networks based on local surrogate model-based methods to show which
components make the main contribution to the classification. Moreover, we
propose a quantitative validation method for explainability methods of point
clouds which enhances the persuasive power of explainability by dropping the
most positive or negative contributing features and monitoring how the
classification scores of specific categories change. To enable an intuitive
explanation of misclassified instances, we display features with confounding
contributions. Our new explainability approach provides a fairly accurate, more
intuitive and widely applicable explanation for point cloud classification
tasks. Our code is available at https://github.com/Explain3D/Explainable3D</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Signal Detection Scheme Based on Deep Learning in OFDM Systems. (arXiv:2107.13423v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_G/0/1/0/all/0/1">Guangliang Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zitong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Minglei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13423">
                                    <div class="article-summary-box-inner">
                                        <span>Channel estimation and signal detection are essential steps to ensure the
quality of end-to-end communication in orthogonal frequency-division
multiplexing (OFDM) systems. In this paper, we develop a DDLSD approach, i.e.,
Data-driven Deep Learning for Signal Detection in OFDM systems. First, the OFDM
system model is established. Then, the long short-term memory (LSTM) is
introduced into the OFDM system model. Wireless channel data is generated
through simulation, the preprocessed time series feature information is input
into the LSTM to complete the offline training. Finally, the trained model is
used for online recovery of transmitted signal. The difference between this
scheme and existing OFDM receiver is that explicit estimated channel state
information (CSI) is transformed into invisible estimated CSI, and the transmit
symbol is directly restored. Simulation results show that the DDLSD scheme
outperforms the existing traditional methods in terms of improving channel
estimation and signal detection performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learned Optimizers for Analytic Continuation. (arXiv:2107.13265v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Dongchen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-feng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13265">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional maximum entropy and sparsity-based algorithms for analytic
continuation often suffer from the ill-posed kernel matrix or demand tremendous
computation time for parameter tuning. Here we propose a neural network method
by convex optimization and replace the ill-posed inverse problem by a sequence
of well-conditioned surrogate problems. After training, the learned optimizers
are able to give a solution of high quality with low time cost and achieve
higher parameter efficiency than heuristic full-connected networks. The output
can also be used as a neural default model to improve the maximum entropy for
better performance. Our methods may be easily extended to other
high-dimensional inverse problems via large-scale pretraining.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-learning Emulators and Eigenvector Continuation. (arXiv:2107.13449v1 [nucl-th])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/nucl-th/1/au:+Sarkar_A/0/1/0/all/0/1">Avik Sarkar</a>, <a href="http://arxiv.org/find/nucl-th/1/au:+Lee_D/0/1/0/all/0/1">Dean Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13449">
                                    <div class="article-summary-box-inner">
                                        <span>Emulators that can bypass computationally expensive scientific calculations
with high accuracy and speed can enable new studies of fundamental science as
well as more potential applications. In this work we focus on solving a system
of constraint equations efficiently using a new machine learning approach that
we call self-learning emulation. A self-learning emulator is an active learning
protocol that can rapidly solve a system of equations over some range of
control parameters. The key ingredient is a fast estimate of the emulator error
that becomes progressively more accurate as the emulator improves. This
acceleration is possible because the emulator itself is used to estimate the
error, and we illustrate with two examples. The first uses cubic spline
interpolation to find the roots of a polynomial with variable coefficients. The
second example uses eigenvector continuation to find the eigenvectors and
eigenvalues of a large Hamiltonian matrix that depends on several control
parameters. We envision future applications of self-learning emulators for
solving systems of algebraic equations, linear and nonlinear differential
equations, and linear and nonlinear eigenvalue problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Machine Learning Classifiers for Stock Trading with Effective Feature Extraction. (arXiv:2107.13148v1 [q-fin.TR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Ullah_A/0/1/0/all/0/1">A. K. M. Amanat Ullah</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Imtiaz_F/0/1/0/all/0/1">Fahim Imtiaz</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Ihsan_M/0/1/0/all/0/1">Miftah Uddin Md Ihsan</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Alam_M/0/1/0/all/0/1">Md. Golam Rabiul Alam</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Majumdar_M/0/1/0/all/0/1">Mahbub Majumdar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13148">
                                    <div class="article-summary-box-inner">
                                        <span>The unpredictability and volatility of the stock market render it challenging
to make a substantial profit using any generalized scheme. This paper intends
to discuss our machine learning model, which can make a significant amount of
profit in the US stock market by performing live trading in the Quantopian
platform while using resources free of cost. Our top approach was to use
ensemble learning with four classifiers: Gaussian Naive Bayes, Decision Tree,
Logistic Regression with L1 regularization and Stochastic Gradient Descent, to
decide whether to go long or short on a particular stock. Our best model
performed daily trade between July 2011 and January 2019, generating 54.35%
profit. Finally, our work showcased that mixtures of weighted classifiers
perform better than any individual predictor about making trading decisions in
the stock market.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">New Metrics to Evaluate the Performance and Fairness of Personalized Federated Learning. (arXiv:2107.13173v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Divi_S/0/1/0/all/0/1">Siddharth Divi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yi-Shan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Farrukh_H/0/1/0/all/0/1">Habiba Farrukh</a>, <a href="http://arxiv.org/find/cs/1/au:+Celik_Z/0/1/0/all/0/1">Z. Berkay Celik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13173">
                                    <div class="article-summary-box-inner">
                                        <span>In Federated Learning (FL), the clients learn a single global model (FedAvg)
through a central aggregator. In this setting, the non-IID distribution of the
data across clients restricts the global FL model from delivering good
performance on the local data of each client. Personalized FL aims to address
this problem by finding a personalized model for each client. Recent works
widely report the average personalized model accuracy on a particular data
split of a dataset to evaluate the effectiveness of their methods. However,
considering the multitude of personalization approaches proposed, it is
critical to study the per-user personalized accuracy and the accuracy
improvements among users with an equitable notion of fairness. To address these
issues, we present a set of performance and fairness metrics intending to
assess the quality of personalized FL methods. We apply these metrics to four
recently proposed personalized FL methods, PersFL, FedPer, pFedMe, and
Per-FedAvg, on three different data splits of the CIFAR-10 dataset. Our
evaluations show that the personalized model with the highest average accuracy
across users may not necessarily be the fairest. Our code is available at
https://tinyurl.com/1hp9ywfa for public use.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Autoencoders: Analysing and Fixing the Bernoulli likelihood for Out-of-Distribution Detection. (arXiv:2107.13304v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yong_B/0/1/0/all/0/1">Bang Xiang Yong</a>, <a href="http://arxiv.org/find/cs/1/au:+Pearce_T/0/1/0/all/0/1">Tim Pearce</a>, <a href="http://arxiv.org/find/cs/1/au:+Brintrup_A/0/1/0/all/0/1">Alexandra Brintrup</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13304">
                                    <div class="article-summary-box-inner">
                                        <span>After an autoencoder (AE) has learnt to reconstruct one dataset, it might be
expected that the likelihood on an out-of-distribution (OOD) input would be
low. This has been studied as an approach to detect OOD inputs. Recent work
showed this intuitive approach can fail for the dataset pairs FashionMNIST vs
MNIST. This paper suggests this is due to the use of Bernoulli likelihood and
analyses why this is the case, proposing two fixes: 1) Compute the uncertainty
of likelihood estimate by using a Bayesian version of the AE. 2) Use
alternative distributions to model the likelihood.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kernel Density Estimation by Stagewise Algorithm with a Simple Dictionary. (arXiv:2107.13430v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Nishida_K/0/1/0/all/0/1">Kiheiji Nishida</a>, <a href="http://arxiv.org/find/stat/1/au:+Naito_K/0/1/0/all/0/1">Kanta Naito</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13430">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies kernel density estimation by stagewise minimization
algorithm with a simple dictionary on U-divergence. We randomly split an i.i.d.
sample into the two disjoint sets, one to be used for constructing the kernels
in the dictionary and the other for evaluating the estimator, and implement the
algorithm. The resulting estimator brings us data-adaptive weighting parameters
and bandwidth matrices, and realizes a sparse representation of kernel density
estimation. We present the non-asymptotic error bounds of our estimator and
confirm its performance by simulations compared with the direct plug-in
bandwidth matrices and the reduced set density estimator.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Insights from Generative Modeling for Neural Video Compression. (arXiv:2107.13136v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yang_R/0/1/0/all/0/1">Ruihan Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1">Yibo Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Marino_J/0/1/0/all/0/1">Joseph Marino</a>, <a href="http://arxiv.org/find/eess/1/au:+Mandt_S/0/1/0/all/0/1">Stephan Mandt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13136">
                                    <div class="article-summary-box-inner">
                                        <span>While recent machine learning research has revealed connections between deep
generative models such as VAEs and rate-distortion losses used in learned
compression, most of this work has focused on images. In a similar spirit, we
view recently proposed neural video coding algorithms through the lens of deep
autoregressive and latent variable modeling. We present recent neural video
codecs as instances of a generalized stochastic temporal autoregressive
transform, and propose new avenues for further improvements inspired by
normalizing flows and structured priors. We propose several architectures that
yield state-of-the-art video compression performance on full-resolution video
and discuss their tradeoffs and ablations. In particular, we propose (i)
improved temporal autoregressive transforms, (ii) improved entropy models with
structured and temporal dependencies, and (iii) variable bitrate versions of
our algorithms. Since our improvements are compatible with a large class of
existing models, we provide further evidence that the generative modeling
viewpoint can advance the neural video coding field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistically Meaningful Approximation: a Case Study on Approximating Turing Machines with Transformers. (arXiv:2107.13163v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Colin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yining Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13163">
                                    <div class="article-summary-box-inner">
                                        <span>A common lens to theoretically study neural net architectures is to analyze
the functions they can approximate. However, the constructions from
approximation theory often have unrealistic aspects, for example, reliance on
infinite precision to memorize target function values, which make these results
potentially less meaningful. To address these issues, this work proposes a
formal definition of statistically meaningful approximation which requires the
approximating network to exhibit good statistical learnability. We present case
studies on statistically meaningful approximation for two classes of functions:
boolean circuits and Turing machines. We show that overparameterized
feedforward neural nets can statistically meaningfully approximate boolean
circuits with sample complexity depending only polynomially on the circuit
size, not the size of the approximating network. In addition, we show that
transformers can statistically meaningfully approximate Turing machines with
computation time bounded by $T$, requiring sample complexity polynomial in the
alphabet size, state space size, and $\log (T)$. Our analysis introduces new
tools for generalization bounds that provide much tighter sample complexity
guarantees than the typical VC-dimension or norm-based bounds, which may be of
independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An explainable two-dimensional single model deep learning approach for Alzheimer&#x27;s disease diagnosis and brain atrophy localization. (arXiv:2107.13200v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Pan_B/0/1/0/all/0/1">Bo Pan</a>, <a href="http://arxiv.org/find/eess/1/au:+Shao_P/0/1/0/all/0/1">Pengfei Shao</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_P/0/1/0/all/0/1">Peng Liu</a> (Alzheimer&#x27;s Disease Neuroimaging Initiative, the Australian Imaging Biomarkers and Lifestyle flagship study of ageing), <a href="http://arxiv.org/find/eess/1/au:+Shen_S/0/1/0/all/0/1">Shuwei Shen</a>, <a href="http://arxiv.org/find/eess/1/au:+Yao_P/0/1/0/all/0/1">Peng Yao</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_R/0/1/0/all/0/1">Ronald X. Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13200">
                                    <div class="article-summary-box-inner">
                                        <span>Early and accurate diagnosis of Alzheimer&#x27;s disease (AD) and its prodromal
period mild cognitive impairment (MCI) is essential for the delayed disease
progression and the improved quality of patients&#x27;life. The emerging
computer-aided diagnostic methods that combine deep learning with structural
magnetic resonance imaging (sMRI) have achieved encouraging results, but some
of them are limit of issues such as data leakage and unexplainable diagnosis.
In this research, we propose a novel end-to-end deep learning approach for
automated diagnosis of AD and localization of important brain regions related
to the disease from sMRI data. This approach is based on a 2D single model
strategy and has the following differences from the current approaches: 1)
Convolutional Neural Network (CNN) models of different structures and
capacities are evaluated systemically and the most suitable model is adopted
for AD diagnosis; 2) a data augmentation strategy named Two-stage Random
RandAugment (TRRA) is proposed to alleviate the overfitting issue caused by
limited training data and to improve the classification performance in AD
diagnosis; 3) an explainable method of Grad-CAM++ is introduced to generate the
visually explainable heatmaps that localize and highlight the brain regions
that our model focuses on and to make our model more transparent. Our approach
has been evaluated on two publicly accessible datasets for two classification
tasks of AD vs. cognitively normal (CN) and progressive MCI (pMCI) vs. stable
MCI (sMCI). The experimental results indicate that our approach outperforms the
state-of-the-art approaches, including those using multi-model and 3D CNN
methods. The resultant localization heatmaps from our approach also highlight
the lateral ventricle and some disease-relevant regions of cortex, coincident
with the commonly affected regions during the development of AD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Approximation of Refinable Functions. (arXiv:2107.13191v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Daubechies_I/0/1/0/all/0/1">Ingrid Daubechies</a>, <a href="http://arxiv.org/find/cs/1/au:+DeVore_R/0/1/0/all/0/1">Ronald DeVore</a>, <a href="http://arxiv.org/find/cs/1/au:+Dym_N/0/1/0/all/0/1">Nadav Dym</a>, <a href="http://arxiv.org/find/cs/1/au:+Faigenbaum_Golovin_S/0/1/0/all/0/1">Shira Faigenbaum-Golovin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovalsky_S/0/1/0/all/0/1">Shahar Z. Kovalsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kung-Ching Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Josiah Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Petrova_G/0/1/0/all/0/1">Guergana Petrova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sober_B/0/1/0/all/0/1">Barak Sober</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13191">
                                    <div class="article-summary-box-inner">
                                        <span>In the desire to quantify the success of neural networks in deep learning and
other applications, there is a great interest in understanding which functions
are efficiently approximated by the outputs of neural networks. By now, there
exists a variety of results which show that a wide range of functions can be
approximated with sometimes surprising accuracy by these outputs. For example,
it is known that the set of functions that can be approximated with exponential
accuracy (in terms of the number of parameters used) includes, on one hand,
very smooth functions such as polynomials and analytic functions (see e.g.
\cite{E,S,Y}) and, on the other hand, very rough functions such as the
Weierstrass function (see e.g. \cite{EPGB,DDFHP}), which is nowhere
differentiable. In this paper, we add to the latter class of rough functions by
showing that it also includes refinable functions. Namely, we show that
refinable functions are approximated by the outputs of deep ReLU networks with
a fixed width and increasing depth with accuracy exponential in terms of their
number of parameters. Our results apply to functions used in the standard
construction of wavelets as well as to functions constructed via subdivision
algorithms in Computer Aided Geometric Design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Balancing for Causal Continuous Treatment-Effect Estimation. (arXiv:2107.13068v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bahadori_M/0/1/0/all/0/1">Mohammad Taha Bahadori</a>, <a href="http://arxiv.org/find/cs/1/au:+Tchetgen_E/0/1/0/all/0/1">Eric Tchetgen Tchetgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Heckerman_D/0/1/0/all/0/1">David E. Heckerman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13068">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of observational causal inference with continuous
treatment. We focus on the challenge of estimating the causal response curve
for infrequently-observed treatment values. We design a new algorithm based on
the framework of entropy balancing which learns weights that directly maximize
causal inference accuracy using end-to-end optimization. Our weights can be
customized for different datasets and causal inference algorithms. We propose a
new theory for consistency of entropy balancing for continuous treatments.
Using synthetic and real-world data, we show that our proposed algorithm
outperforms the entropy balancing in terms of causal inference accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exceeding the Limits of Visual-Linguistic Multi-Task Learning. (arXiv:2107.13054v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolfe_C/0/1/0/all/0/1">Cameron R. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lundgaard_K/0/1/0/all/0/1">Keld T. Lundgaard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13054">
                                    <div class="article-summary-box-inner">
                                        <span>By leveraging large amounts of product data collected across hundreds of live
e-commerce websites, we construct 1000 unique classification tasks that share
similarly-structured input data, comprised of both text and images. These
classification tasks focus on learning the product hierarchy of different
e-commerce websites, causing many of them to be correlated. Adopting a
multi-modal transformer model, we solve these tasks in unison using multi-task
learning (MTL). Extensive experiments are presented over an initial 100-task
dataset to reveal best practices for &quot;large-scale MTL&quot; (i.e., MTL with more
than 100 tasks). From these experiments, a final, unified methodology is
derived, which is composed of both best practices and new proposals such as
DyPa, a simple heuristic for automatically allocating task-specific parameters
to tasks that could benefit from extra capacity. Using our large-scale MTL
methodology, we successfully train a single model across all 1000 tasks in our
dataset while using minimal task specific parameters, thereby showing that it
is possible to extend several orders of magnitude beyond current efforts in
MTL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust and Active Learning for Deep Neural Network Regression. (arXiv:2107.13124v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kesidis_G/0/1/0/all/0/1">George Kesidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_D/0/1/0/all/0/1">David J. Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergeron_M/0/1/0/all/0/1">Maxime Bergeron</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferguson_R/0/1/0/all/0/1">Ryan Ferguson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lucic_V/0/1/0/all/0/1">Vladimir Lucic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13124">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a gradient-based method to discover local error maximizers of a
deep neural network (DNN) used for regression, assuming the availability of an
&quot;oracle&quot; capable of providing real-valued supervision (a regression target) for
samples. For example, the oracle could be a numerical solver which,
operationally, is much slower than the DNN. Given a discovered set of local
error maximizers, the DNN is either fine-tuned or retrained in the manner of
active learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Learning Algorithm for Piecewise Linear Interface Construction (PLIC). (arXiv:2107.13067v1 [physics.flu-dyn])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Ataei_M/0/1/0/all/0/1">Mohammadmehdi Ataei</a>, <a href="http://arxiv.org/find/physics/1/au:+Pirmorad_E/0/1/0/all/0/1">Erfan Pirmorad</a>, <a href="http://arxiv.org/find/physics/1/au:+Costa_F/0/1/0/all/0/1">Franco Costa</a>, <a href="http://arxiv.org/find/physics/1/au:+Han_S/0/1/0/all/0/1">Sejin Han</a>, <a href="http://arxiv.org/find/physics/1/au:+Park_C/0/1/0/all/0/1">Chul B Park</a>, <a href="http://arxiv.org/find/physics/1/au:+Bussmann_M/0/1/0/all/0/1">Markus Bussmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13067">
                                    <div class="article-summary-box-inner">
                                        <span>Piecewise Linear Interface Construction (PLIC) is frequently used to
geometrically reconstruct fluid interfaces in Computational Fluid Dynamics
(CFD) modeling of two-phase flows. PLIC reconstructs interfaces from a scalar
field that represents the volume fraction of each phase in each computational
cell. Given the volume fraction and interface normal, the location of a linear
interface is uniquely defined. For a cubic computational cell (3D), the
position of the planar interface is determined by intersecting the cube with a
plane, such that the volume of the resulting truncated polyhedron cell is equal
to the volume fraction. Yet it is geometrically complex to find the exact
position of the plane, and it involves calculations that can be a computational
bottleneck of many CFD models. However, while the forward problem of 3D PLIC is
challenging, the inverse problem, of finding the volume of the truncated
polyhedron cell given a defined plane, is simple. In this work, we propose a
deep learning model for the solution to the forward problem of PLIC by only
making use of its inverse problem. The proposed model is up to several orders
of magnitude faster than traditional schemes, which significantly reduces the
computational bottleneck of PLIC in CFD simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Case Study on Sampling Strategies for Evaluating Neural Sequential Item Recommendation Models. (arXiv:2107.13045v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dallmann_A/0/1/0/all/0/1">Alexander Dallmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Zoller_D/0/1/0/all/0/1">Daniel Zoller</a>, <a href="http://arxiv.org/find/cs/1/au:+Hotho_A/0/1/0/all/0/1">Andreas Hotho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13045">
                                    <div class="article-summary-box-inner">
                                        <span>At the present time, sequential item recommendation models are compared by
calculating metrics on a small item subset (target set) to speed up
computation. The target set contains the relevant item and a set of negative
items that are sampled from the full item set. Two well-known strategies to
sample negative items are uniform random sampling and sampling by popularity to
better approximate the item frequency distribution in the dataset. Most
recently published papers on sequential item recommendation rely on sampling by
popularity to compare the evaluated models. However, recent work has already
shown that an evaluation with uniform random sampling may not be consistent
with the full ranking, that is, the model ranking obtained by evaluating a
metric using the full item set as target set, which raises the question whether
the ranking obtained by sampling by popularity is equal to the full ranking. In
this work, we re-evaluate current state-of-the-art sequential recommender
models from the point of view, whether these sampling strategies have an impact
on the final ranking of the models. We therefore train four recently proposed
sequential recommendation models on five widely known datasets. For each
dataset and model, we employ three evaluation strategies. First, we compute the
full model ranking. Then we evaluate all models on a target set sampled by the
two different sampling strategies, uniform random sampling and sampling by
popularity with the commonly used target set size of 100, compute the model
ranking for each strategy and compare them with each other. Additionally, we
vary the size of the sampled target set. Overall, we find that both sampling
strategies can produce inconsistent rankings compared with the full ranking of
the models. Furthermore, both sampling by popularity and uniform random
sampling do not consistently produce the same ranking ...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Human Cell Classification in Sparse Datasets using Few-Shot Learning. (arXiv:2107.13093v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Walsh_R/0/1/0/all/0/1">Reece Walsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelpakey_M/0/1/0/all/0/1">Mohamed H. Abdelpakey</a>, <a href="http://arxiv.org/find/cs/1/au:+Shehata_M/0/1/0/all/0/1">Mohamed S. Shehata</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_M/0/1/0/all/0/1">Mostafa M.Mohamed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13093">
                                    <div class="article-summary-box-inner">
                                        <span>Classifying and analyzing human cells is a lengthy procedure, often involving
a trained professional. In an attempt to expedite this process, an active area
of research involves automating cell classification through use of deep
learning-based techniques. In practice, a large amount of data is required to
accurately train these deep learning models. However, due to the sparse human
cell datasets currently available, the performance of these models is typically
low. This study investigates the feasibility of using few-shot learning-based
techniques to mitigate the data requirements for accurate training. The study
is comprised of three parts: First, current state-of-the-art few-shot learning
techniques are evaluated on human cell classification. The selected techniques
are trained on a non-medical dataset and then tested on two out-of-domain,
human cell datasets. The results indicate that, overall, the test accuracy of
state-of-the-art techniques decreased by at least 30% when transitioning from a
non-medical dataset to a medical dataset. Second, this study evaluates the
potential benefits, if any, to varying the backbone architecture and training
schemes in current state-of-the-art few-shot learning techniques when used in
human cell classification. Even with these variations, the overall test
accuracy decreased from 88.66% on non-medical datasets to 44.13% at best on the
medical datasets. Third, this study presents future directions for using
few-shot learning in human cell classification. In general, few-shot learning
in its current state performs poorly on human cell classification. The study
proves that attempts to modify existing network architectures are not effective
and concludes that future research effort should be focused on improving
robustness towards out-of-domain testing using optimization-based or
self-supervised few-shot learning techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fully Homomorphically Encrypted Deep Learning as a Service. (arXiv:2107.12997v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Onoufriou_G/0/1/0/all/0/1">George Onoufriou</a>, <a href="http://arxiv.org/find/cs/1/au:+Mayfield_P/0/1/0/all/0/1">Paul Mayfield</a>, <a href="http://arxiv.org/find/cs/1/au:+Leontidis_G/0/1/0/all/0/1">Georgios Leontidis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12997">
                                    <div class="article-summary-box-inner">
                                        <span>Fully Homomorphic Encryption (FHE) is a relatively recent advancement in the
field of privacy-preserving technologies. FHE allows for the arbitrary depth
computation of both addition and multiplication, and thus the application of
abelian/polynomial equations, like those found in deep learning algorithms.
This project investigates, derives, and proves how FHE with deep learning can
be used at scale, with relatively low time complexity, the problems that such a
system incurs, and mitigations/solutions for such problems. In addition, we
discuss how this could have an impact on the future of data privacy and how it
can enable data sharing across various actors in the agri-food supply chain,
hence allowing the development of machine learning-based systems. Finally, we
find that although FHE incurs a high spatial complexity cost, the time
complexity is within expected reasonable bounds, while allowing for absolutely
private predictions to be made, in our case for milk yield prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dataset Distillation with Infinitely Wide Convolutional Networks. (arXiv:2107.13034v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Timothy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Novak_R/0/1/0/all/0/1">Roman Novak</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_L/0/1/0/all/0/1">Lechao Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jaehoon Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13034">
                                    <div class="article-summary-box-inner">
                                        <span>The effectiveness of machine learning algorithms arises from being able to
extract useful features from large amounts of data. As model and dataset sizes
increase, dataset distillation methods that compress large datasets into
significantly smaller yet highly performant ones will become valuable in terms
of training efficiency and useful feature extraction. To that end, we apply a
novel distributed kernel based meta-learning framework to achieve
state-of-the-art results for dataset distillation using infinitely wide
convolutional neural networks. For instance, using only 10 datapoints (0.02% of
original dataset), we obtain over 64% test accuracy on CIFAR-10 image
classification task, a dramatic improvement over the previous best test
accuracy of 40%. Our state-of-the-art results extend across many other settings
for MNIST, Fashion-MNIST, CIFAR-10, CIFAR-100, and SVHN. Furthermore, we
perform some preliminary analyses of our distilled datasets to shed light on
how they differ from naturally occurring data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long-Short Transformer: Efficient Transformers for Language and Vision. (arXiv:2107.02192v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chaowei Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02192">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have achieved success in both language and vision domains.
However, it is prohibitively expensive to scale them to long sequences such as
long documents or high-resolution images, because self-attention mechanism has
quadratic time and memory complexities with respect to the input sequence
length. In this paper, we propose Long-Short Transformer (Transformer-LS), an
efficient self-attention mechanism for modeling long sequences with linear
complexity for both language and vision tasks. It aggregates a novel long-range
attention with dynamic projection to model distant correlations and a
short-term attention to capture fine-grained local correlations. We propose a
dual normalization strategy to account for the scale mismatch between the two
attention mechanisms. Transformer-LS can be applied to both autoregressive and
bidirectional models without additional complexity. Our method outperforms the
state-of-the-art models on multiple tasks in language and vision domains,
including the Long Range Arena benchmark, autoregressive language modeling, and
ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on
enwik8 using half the number of parameters than previous method, while being
faster and is able to handle 3x as long sequences compared to its
full-attention version on the same hardware. On ImageNet, it can obtain the
state-of-the-art results (e.g., a moderate size of 55.8M model solely trained
on 224x224 ImageNet-1K can obtain Top-1 accuracy 84.1%), while being more
scalable on high-resolution images. The source code and models are released at
https://github.com/NVIDIA/transformer-ls .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Squeeze-Excitation Convolutional Recurrent Neural Networks for Audio-Visual Scene Classification. (arXiv:2107.13180v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Naranjo_Alcazar_J/0/1/0/all/0/1">Javier Naranjo-Alcazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_Castanos_S/0/1/0/all/0/1">Sergi Perez-Castanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_Garcia_A/0/1/0/all/0/1">Aaron Lopez-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zuccarello_P/0/1/0/all/0/1">Pedro Zuccarello</a>, <a href="http://arxiv.org/find/cs/1/au:+Cobos_M/0/1/0/all/0/1">Maximo Cobos</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferri_F/0/1/0/all/0/1">Francesc J. Ferri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13180">
                                    <div class="article-summary-box-inner">
                                        <span>The use of multiple and semantically correlated sources can provide
complementary information to each other that may not be evident when working
with individual modalities on their own. In this context, multi-modal models
can help producing more accurate and robust predictions in machine learning
tasks where audio-visual data is available. This paper presents a multi-modal
model for automatic scene classification that exploits simultaneously auditory
and visual information. The proposed approach makes use of two separate
networks which are respectively trained in isolation on audio and visual data,
so that each network specializes in a given modality. The visual subnetwork is
a pre-trained VGG16 model followed by a bidiretional recurrent layer, while the
residual audio subnetwork is based on stacked squeeze-excitation convolutional
blocks trained from scratch. After training each subnetwork, the fusion of
information from the audio and visual streams is performed at two different
stages. The early fusion stage combines features resulting from the last
convolutional block of the respective subnetworks at different time steps to
feed a bidirectional recurrent structure. The late fusion stage combines the
output of the early fusion stage with the independent predictions provided by
the two subnetworks, resulting in the final prediction. We evaluate the method
using the recently published TAU Audio-Visual Urban Scenes 2021, which contains
synchronized audio and video recordings from 12 European cities in 10 different
scene classes. The proposed model has been shown to provide an excellent
trade-off between prediction performance (86.5%) and system complexity (15M
parameters) in the evaluation results of the DCASE 2021 Challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Unsupervised Domain Adaptation with Conditional and Label Shift: Infer, Align and Iterate. (arXiv:2107.13469v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhenhua Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Site Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_F/0/1/0/all/0/1">Fangxu Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jane You</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1">C.-C. Jay Kuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakhri_G/0/1/0/all/0/1">Georges El Fakhri</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1">Jonghye Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13469">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose an adversarial unsupervised domain adaptation (UDA)
approach with the inherent conditional and label shifts, in which we aim to
align the distributions w.r.t. both $p(x|y)$ and $p(y)$. Since the label is
inaccessible in the target domain, the conventional adversarial UDA assumes
$p(y)$ is invariant across domains, and relies on aligning $p(x)$ as an
alternative to the $p(x|y)$ alignment. To address this, we provide a thorough
theoretical and empirical analysis of the conventional adversarial UDA methods
under both conditional and label shifts, and propose a novel and practical
alternative optimization scheme for adversarial UDA. Specifically, we infer the
marginal $p(y)$ and align $p(x|y)$ iteratively in the training, and precisely
align the posterior $p(y|x)$ in testing. Our experimental results demonstrate
its effectiveness on both classification and segmentation UDA, and partial UDA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Complete End-To-End Open Source Toolchain for the Versatile Video Coding (VVC) Standard. (arXiv:2107.13385v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wieckowski_A/0/1/0/all/0/1">Adam Wieckowski</a>, <a href="http://arxiv.org/find/eess/1/au:+Lehmann_C/0/1/0/all/0/1">Christian Lehmann</a>, <a href="http://arxiv.org/find/eess/1/au:+Bross_B/0/1/0/all/0/1">Benjamin Bross</a>, <a href="http://arxiv.org/find/eess/1/au:+Marpe_D/0/1/0/all/0/1">Detlev Marpe</a>, <a href="http://arxiv.org/find/eess/1/au:+Biatek_T/0/1/0/all/0/1">Thibaud Biatek</a>, <a href="http://arxiv.org/find/eess/1/au:+Raulet_M/0/1/0/all/0/1">Mickael Raulet</a>, <a href="http://arxiv.org/find/eess/1/au:+Feuvre_J/0/1/0/all/0/1">Jean Le Feuvre</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13385">
                                    <div class="article-summary-box-inner">
                                        <span>Versatile Video Coding (VVC) is the most recent international video coding
standard jointly developed by ITU-T and ISO/IEC, which has been finalized in
July 2020. VVC allows for significant bit-rate reductions around 50% for the
same subjective video quality compared to its predecessor, High Efficiency
Video Coding (HEVC). One year after finalization, VVC support in devices and
chipsets is still under development, which is aligned with the typical
development cycles of new video coding standards. This paper presents
open-source software packages that allow building a complete VVC end-to-end
toolchain already one year after its finalization. This includes the Fraunhofer
HHI VVenC library for fast and efficient VVC encoding as well as HHI&#x27;s VVdeC
library for live decoding. An experimental integration of VVC in the GPAC
software tools and FFmpeg media framework allows packaging VVC bitstreams, e.g.
encoded with VVenC, in MP4 file format and using DASH for content creation and
streaming. The integration of VVdeC allows playback on the receiver. Given
these packages, step-by-step tutorials are provided for two possible
application scenarios: VVC file encoding plus playback and adaptive streaming
with DASH.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JPEG Steganography with Embedding Cost Learning and Side-Information Estimation. (arXiv:2107.13151v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianhua Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yi Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shang_F/0/1/0/all/0/1">Fei Shang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1">Xiangui Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yun-Qing Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.13151">
                                    <div class="article-summary-box-inner">
                                        <span>A great challenge to steganography has arisen with the wide application of
steganalysis methods based on convolutional neural networks (CNNs). To this
end, embedding cost learning frameworks based on generative adversarial
networks (GANs) have been proposed and achieved success for spatial
steganography. However, the application of GAN to JPEG steganography is still
in the prototype stage; its anti-detectability and training efficiency should
be improved. In conventional steganography, research has shown that the
side-information calculated from the precover can be used to enhance security.
However, it is hard to calculate the side-information without the spatial
domain image. In this work, an embedding cost learning framework for JPEG
Steganography via a Generative Adversarial Network (JS-GAN) has been proposed,
the learned embedding cost can be further adjusted asymmetrically according to
the estimated side-information. Experimental results have demonstrated that the
proposed method can automatically learn a content-adaptive embedding cost
function, and use the estimated side-information properly can effectively
improve the security performance. For example, under the attack of a classic
steganalyzer GFR with quality factor 75 and 0.4 bpnzAC, the proposed JS-GAN can
increase the detection error 2.58% over J-UNIWARD, and the estimated
side-information aided version JS-GAN(ESI) can further increase the security
performance by 11.25% over JS-GAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-28">2021-07-28</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disfluency Detection with Unlabeled Data and Small BERT Models. (arXiv:2104.10769v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rocholl_J/0/1/0/all/0/1">Johann C. Rocholl</a>, <a href="http://arxiv.org/find/cs/1/au:+Zayats_V/0/1/0/all/0/1">Vicky Zayats</a>, <a href="http://arxiv.org/find/cs/1/au:+Walker_D/0/1/0/all/0/1">Daniel D. Walker</a>, <a href="http://arxiv.org/find/cs/1/au:+Murad_N/0/1/0/all/0/1">Noah B. Murad</a>, <a href="http://arxiv.org/find/cs/1/au:+Schneider_A/0/1/0/all/0/1">Aaron Schneider</a>, <a href="http://arxiv.org/find/cs/1/au:+Liebling_D/0/1/0/all/0/1">Daniel J. Liebling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10769">
                                    <div class="article-summary-box-inner">
                                        <span>Disfluency detection models now approach high accuracy on English text.
However, little exploration has been done in improving the size and inference
time of the model. At the same time, automatic speech recognition (ASR) models
are moving from server-side inference to local, on-device inference. Supporting
models in the transcription pipeline (like disfluency detection) must follow
suit. In this work we concentrate on the disfluency detection task, focusing on
small, fast, on-device models based on the BERT architecture. We demonstrate it
is possible to train disfluency detection models as small as 1.3 MiB, while
retaining high performance. We build on previous work that showed the benefit
of data augmentation approaches such as self-training. Then, we evaluate the
effect of domain mismatch between conversational and written text on model
performance. We find that domain adaptation and data augmentation strategies
have a more pronounced effect on these smaller models, as compared to
conventional BERT models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Statistical Analysis of Summarization Evaluation Metrics using Resampling Methods. (arXiv:2104.00054v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deutsch_D/0/1/0/all/0/1">Daniel Deutsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Dror_R/0/1/0/all/0/1">Rotem Dror</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1">Dan Roth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00054">
                                    <div class="article-summary-box-inner">
                                        <span>The quality of a summarization evaluation metric is quantified by calculating
the correlation between its scores and human annotations across a large number
of summaries. Currently, it is unclear how precise these correlation estimates
are, nor whether differences between two metrics&#x27; correlations reflect a true
difference or if it is due to mere chance. In this work, we address these two
problems by proposing methods for calculating confidence intervals and running
hypothesis tests for correlations using two resampling methods, bootstrapping
and permutation. After evaluating which of the proposed methods is most
appropriate for summarization through two simulation experiments, we analyze
the results of applying these methods to several different automatic evaluation
metrics across three sets of human annotations. We find that the confidence
intervals are rather wide, demonstrating high uncertainty in the reliability of
automatic metrics. Further, although many metrics fail to show statistical
improvements over ROUGE, two recent works, QAEval and BERTScore, do in some
evaluation settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Francis_J/0/1/0/all/0/1">Jonathan Francis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitamura_N/0/1/0/all/0/1">Nariaki Kitamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Labelle_F/0/1/0/all/0/1">Felix Labelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaopeng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Navarro_I/0/1/0/all/0/1">Ingrid Navarro</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1">Jean Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13948">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in the areas of multimodal machine learning and artificial
intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Embodied AI.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly use computer vision and natural language. We propose a
taxonomy to unify these tasks and provide an in-depth analysis and comparison
of the new and current algorithmic approaches, metrics, simulated environments,
as well as the datasets used for EVLP tasks. Finally, we present the core
challenges that we believe new EVLP works should seek to address, and we
advocate for task construction that enables model generalizability and furthers
real-world deployment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Formal Language Theory Meets Modern NLP. (arXiv:2102.10094v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1">William Merrill</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10094">
                                    <div class="article-summary-box-inner">
                                        <span>NLP is deeply intertwined with the formal study of language, both
conceptually and historically. Arguably, this connection goes all the way back
to Chomsky&#x27;s Syntactic Structures in 1957. It also still holds true today, with
a strand of recent works building formal analysis of modern neural networks
methods in terms of formal languages. In this document, I aim to explain
background about formal languages as they relate to this recent work. I will by
necessity ignore large parts of the rich history of this field, instead
focusing on concepts connecting to modern deep learning-based NLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Competition in Cross-situational Word Learning: A Computational Study. (arXiv:2012.03370v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nematzadeh_A/0/1/0/all/0/1">Aida Nematzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarchi_Z/0/1/0/all/0/1">Zahra Shekarchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1">Thomas L. Griffiths</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevenson_S/0/1/0/all/0/1">Suzanne Stevenson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03370">
                                    <div class="article-summary-box-inner">
                                        <span>Children learn word meanings by tapping into the commonalities across
different situations in which words are used and overcome the high level of
uncertainty involved in early word learning experiences. We propose a modeling
framework to investigate the role of mutual exclusivity bias - asserting
one-to-one mappings between words and their meanings - in reducing uncertainty
in word learning. In a set of computational studies, we show that to
successfully learn word meanings in the face of uncertainty, a learner needs to
use two types of competition: words competing for association to a referent
when learning from an observation and referents competing for a word when the
word is used. Our work highlights the importance of an algorithmic-level
analysis to shed light on the utility of different mechanisms that can
implement the same computational-level theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Question-Answering as an Automatic Metric for Evaluating the Content Quality of a Summary. (arXiv:2010.00490v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deutsch_D/0/1/0/all/0/1">Daniel Deutsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Bedrax_Weiss_T/0/1/0/all/0/1">Tania Bedrax-Weiss</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1">Dan Roth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00490">
                                    <div class="article-summary-box-inner">
                                        <span>A desirable property of a reference-based evaluation metric that measures the
content quality of a summary is that it should estimate how much information
that summary has in common with a reference. Traditional text overlap based
metrics such as ROUGE fail to achieve this because they are limited to matching
tokens, either lexically or via embeddings. In this work, we propose a metric
to evaluate the content quality of a summary using question-answering (QA).
QA-based methods directly measure a summary&#x27;s information overlap with a
reference, making them fundamentally different than text overlap metrics. We
demonstrate the experimental benefits of QA-based metrics through an analysis
of our proposed metric, QAEval. QAEval out-performs current state-of-the-art
metrics on most evaluations using benchmark datasets, while being competitive
on others due to limitations of state-of-the-art models. Through a careful
analysis of each component of QAEval, we identify its performance bottlenecks
and estimate that its potential upper-bound performance surpasses all other
automatic metrics, approaching that of the gold-standard Pyramid Method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noisy Self-Knowledge Distillation for Text Summarization. (arXiv:2009.07032v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1">Sheng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1">Mirella Lapata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07032">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we apply self-knowledge distillation to text summarization
which we argue can alleviate problems with maximum-likelihood training on
single reference and noisy datasets. Instead of relying on one-hot annotation
labels, our student summarization model is trained with guidance from a teacher
which generates smoothed labels to help regularize training. Furthermore, to
better model uncertainty during training, we introduce multiple noise signals
for both teacher and student models. We demonstrate experimentally on three
benchmarks that our framework boosts the performance of both pretrained and
non-pretrained summarizers achieving state-of-the-art results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Emotion Stimulus Detection in German News Headlines. (arXiv:2107.12920v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dang%7D_%7B/0/1/0/all/0/1">{Bao Minh} {Doan Dang}</a>, <a href="http://arxiv.org/find/cs/1/au:+Oberlander_L/0/1/0/all/0/1">Laura Oberl&#xe4;nder</a>, <a href="http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1">Roman Klinger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12920">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion stimulus extraction is a fine-grained subtask of emotion analysis
that focuses on identifying the description of the cause behind an emotion
expression from a text passage (e.g., in the sentence &quot;I am happy that I passed
my exam&quot; the phrase &quot;passed my exam&quot; corresponds to the stimulus.). Previous
work mainly focused on Mandarin and English, with no resources or models for
German. We fill this research gap by developing a corpus of 2006 German news
headlines annotated with emotions and 811 instances with annotations of
stimulus phrases. Given that such corpus creation efforts are time-consuming
and expensive, we additionally work on an approach for projecting the existing
English GoodNewsEveryone (GNE) corpus to a machine-translated German version.
We compare the performance of a conditional random field (CRF) model (trained
monolingually on German and cross-lingually via projection) with a multilingual
XLM-RoBERTa (XLM-R) model. Our results show that training with the German
corpus achieves higher F1 scores than projection. Experiments with XLM-R
outperform their respective CRF counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation. (arXiv:2101.00390v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Riviere_M/0/1/0/all/0/1">Morgane Rivi&#xe8;re</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1">Ann Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1">Anne Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Talnikar_C/0/1/0/all/0/1">Chaitanya Talnikar</a>, <a href="http://arxiv.org/find/cs/1/au:+Haziza_D/0/1/0/all/0/1">Daniel Haziza</a>, <a href="http://arxiv.org/find/cs/1/au:+Williamson_M/0/1/0/all/0/1">Mary Williamson</a>, <a href="http://arxiv.org/find/cs/1/au:+Pino_J/0/1/0/all/0/1">Juan Pino</a>, <a href="http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1">Emmanuel Dupoux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00390">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce VoxPopuli, a large-scale multilingual corpus providing 100K
hours of unlabelled speech data in 23 languages. It is the largest open data to
date for unsupervised representation learning as well as semi-supervised
learning. VoxPopuli also contains 1.8K hours of transcribed speeches in 16
languages and their aligned oral interpretations into 5 other languages
totaling 5.1K hours. We provide speech recognition baselines and validate the
versatility of VoxPopuli unlabelled data in semi-supervised learning under
challenging out-of-domain settings. We will release the corpus at
https://github.com/facebookresearch/voxpopuli under an open license.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extraction and Analysis of Fictional Character Networks: A Survey. (arXiv:1907.02704v4 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Labatut_V/0/1/0/all/0/1">Vincent Labatut</a> (LIA), <a href="http://arxiv.org/find/cs/1/au:+Bost_X/0/1/0/all/0/1">Xavier Bost</a> (LIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.02704">
                                    <div class="article-summary-box-inner">
                                        <span>A character network is a graph extracted from a narrative, in which vertices
represent characters and edges correspond to interactions between them. A
number of narrative-related problems can be addressed automatically through the
analysis of character networks, such as summarization, classification, or role
detection. Character networks are particularly relevant when considering works
of fictions (e.g. novels, plays, movies, TV series), as their exploitation
allows developing information retrieval and recommendation systems. However,
works of fiction possess specific properties making these tasks harder. This
survey aims at presenting and organizing the scientific literature related to
the extraction of character networks from works of fiction, as well as their
analysis. We first describe the extraction process in a generic way, and
explain how its constituting steps are implemented in practice, depending on
the medium of the narrative, the goal of the network analysis, and other
factors. We then review the descriptive tools used to characterize character
networks, with a focus on the way they are interpreted in this context. We
illustrate the relevance of character networks by also providing a review of
applications derived from their analysis. Finally, we identify the limitations
of the existing approaches, and the most promising perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting User Emotional Tone in Mental Disorder Online Communities. (arXiv:2005.07473v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Silveira_B/0/1/0/all/0/1">B&#xe1;rbara Silveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_H/0/1/0/all/0/1">Henrique S. Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Murai_F/0/1/0/all/0/1">Fabricio Murai</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1">Ana Paula Couto da Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.07473">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, Online Social Networks have become an important medium for
people who suffer from mental disorders to share moments of hardship, and
receive emotional and informational support. In this work, we analyze how
discussions in Reddit communities related to mental disorders can help improve
the health conditions of their users. Using the emotional tone of users&#x27;
writing as a proxy for emotional state, we uncover relationships between user
interactions and state changes. First, we observe that authors of negative
posts often write rosier comments after engaging in discussions, indicating
that users&#x27; emotional state can improve due to social support. Second, we build
models based on SOTA text embedding techniques and RNNs to predict shifts in
emotional tone. This differs from most of related work, which focuses primarily
on detecting mental disorders from user activity. We demonstrate the
feasibility of accurately predicting the users&#x27; reactions to the interactions
experienced in these platforms, and present some examples which illustrate that
the models are correctly capturing the effects of comments on the author&#x27;s
emotional tone. Our models hold promising implications for interventions to
provide support for people struggling with mental illnesses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">gaBERT -- an Irish Language Model. (arXiv:2107.12930v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barry_J/0/1/0/all/0/1">James Barry</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_J/0/1/0/all/0/1">Joachim Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Cassidy_L/0/1/0/all/0/1">Lauren Cassidy</a>, <a href="http://arxiv.org/find/cs/1/au:+Cowap_A/0/1/0/all/0/1">Alan Cowap</a>, <a href="http://arxiv.org/find/cs/1/au:+Lynn_T/0/1/0/all/0/1">Teresa Lynn</a>, <a href="http://arxiv.org/find/cs/1/au:+Walsh_A/0/1/0/all/0/1">Abigail Walsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Meachair_M/0/1/0/all/0/1">M&#xed;che&#xe1;l J. &#xd3; Meachair</a>, <a href="http://arxiv.org/find/cs/1/au:+Foster_J/0/1/0/all/0/1">Jennifer Foster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12930">
                                    <div class="article-summary-box-inner">
                                        <span>The BERT family of neural language models have become highly popular due to
their ability to provide sequences of text with rich context-sensitive token
encodings which are able to generalise well to many Natural Language Processing
tasks. Over 120 monolingual BERT models covering over 50 languages have been
released, as well as a multilingual model trained on 104 languages. We
introduce, gaBERT, a monolingual BERT model for the Irish language. We compare
our gaBERT model to multilingual BERT and show that gaBERT provides better
representations for a downstream parsing task. We also show how different
filtering criteria, vocabulary size and the choice of subword tokenisation
model affect downstream performance. We release gaBERT and related code to the
community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Emotion Recognition under Consideration of the Emotion Component Process Model. (arXiv:2107.12895v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Casel_F/0/1/0/all/0/1">Felix Casel</a>, <a href="http://arxiv.org/find/cs/1/au:+Heindl_A/0/1/0/all/0/1">Amelie Heindl</a>, <a href="http://arxiv.org/find/cs/1/au:+Klinger_R/0/1/0/all/0/1">Roman Klinger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12895">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion classification in text is typically performed with neural network
models which learn to associate linguistic units with emotions. While this
often leads to good predictive performance, it does only help to a limited
degree to understand how emotions are communicated in various domains. The
emotion component process model (CPM) by Scherer (2005) is an interesting
approach to explain emotion communication. It states that emotions are a
coordinated process of various subcomponents, in reaction to an event, namely
the subjective feeling, the cognitive appraisal, the expression, a
physiological bodily reaction, and a motivational action tendency. We
hypothesize that these components are associated with linguistic realizations:
an emotion can be expressed by describing a physiological bodily reaction (&quot;he
was trembling&quot;), or the expression (&quot;she smiled&quot;), etc. We annotate existing
literature and Twitter emotion corpora with emotion component classes and find
that emotions on Twitter are predominantly expressed by event descriptions or
subjective reports of the feeling, while in literature, authors prefer to
describe what characters do, and leave the interpretation to the reader. We
further include the CPM in a multitask learning model and find that this
supports the emotion categorization. The annotated corpora are available at
https://www.ims.uni-stuttgart.de/data/emotion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grover&#x27;s Algorithm for Question Answering. (arXiv:2106.05299v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Correia_A/0/1/0/all/0/1">A. D. Correia</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Moortgat_M/0/1/0/all/0/1">M. Moortgat</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Stoof_H/0/1/0/all/0/1">H. T. C. Stoof</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05299">
                                    <div class="article-summary-box-inner">
                                        <span>Grover&#x27;s algorithm, a well-know quantum search algorithm, allows one to find
the correct item in a database, with quadratic speedup. In this paper we adapt
Grover&#x27;s algorithm to the problem of finding a correct answer to a natural
language question in English, thus contributing to the growing field of Quantum
Natural Language Processing. Using a grammar that can be interpreted as tensor
contractions, each word is represented as a quantum state that serves as input
to the quantum circuit. We here introduce a quantum measurement to contract the
representations of words, resulting in the representation of larger text
fragments. Using this framework, a representation for the question is found
that contains all the possible answers in equal quantum superposition, and
allows for the building of an oracle that can detect a correct answer, being
agnostic to the specific question. Furthermore, we show that our construction
can deal with certain types of ambiguous phrases by keeping the various
different meanings in quantum superposition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anchor-based Bilingual Word Embeddings for Low-Resource Languages. (arXiv:2010.12627v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eder_T/0/1/0/all/0/1">Tobias Eder</a>, <a href="http://arxiv.org/find/cs/1/au:+Hangya_V/0/1/0/all/0/1">Viktor Hangya</a>, <a href="http://arxiv.org/find/cs/1/au:+Fraser_A/0/1/0/all/0/1">Alexander Fraser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12627">
                                    <div class="article-summary-box-inner">
                                        <span>Good quality monolingual word embeddings (MWEs) can be built for languages
which have large amounts of unlabeled text. MWEs can be aligned to bilingual
spaces using only a few thousand word translation pairs. For low resource
languages training MWEs monolingually results in MWEs of poor quality, and thus
poor bilingual word embeddings (BWEs) as well. This paper proposes a new
approach for building BWEs in which the vector space of the high resource
source language is used as a starting point for training an embedding space for
the low resource target language. By using the source vectors as anchors the
vector spaces are automatically aligned during training. We experiment on
English-German, English-Hiligaynon and English-Macedonian. We show that our
approach results not only in improved BWEs and bilingual lexicon induction
performance, but also in improved target language MWE quality as measured using
monolingual word similarity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning Meets Natural Language Processing: A Survey. (arXiv:2107.12603v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ho_S/0/1/0/all/0/1">Stella Ho</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Longxiang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1">Yuan Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">He Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12603">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning aims to learn machine learning models from multiple
decentralized edge devices (e.g. mobiles) or servers without sacrificing local
data privacy. Recent Natural Language Processing techniques rely on deep
learning and large pre-trained language models. However, both big deep neural
and language models are trained with huge amounts of data which often lies on
the server side. Since text data is widely originated from end users, in this
work, we look into recent NLP models and techniques which use federated
learning as the learning framework. Our survey discusses major challenges in
federated natural language processing, including the algorithm challenges,
system challenges as well as the privacy issues. We also provide a critical
review of the existing Federated NLP evaluation methods and tools. Finally, we
highlight the current research gaps and future directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Slot Selector via Local Reliability Verification for Dialogue State Tracking. (arXiv:2107.12578v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jinyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shuang_K/0/1/0/all/0/1">Kai Shuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jijie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zihan Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12578">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of dialogue state tracking (DST) is to predict the current dialogue
state given all previous dialogue contexts. Existing approaches generally
predict the dialogue state at every turn from scratch. However, the
overwhelming majority of the slots in each turn should simply inherit the slot
values from the previous turn. Therefore, the mechanism of treating slots
equally in each turn not only is inefficient but also may lead to additional
errors because of the redundant slot value generation. To address this problem,
we devise the two-stage DSS-DST which consists of the Dual Slot Selector based
on the current turn dialogue, and the Slot Value Generator based on the
dialogue history. The Dual Slot Selector determines each slot whether to update
slot value or to inherit the slot value from the previous turn from two
aspects: (1) if there is a strong relationship between it and the current turn
dialogue utterances; (2) if a slot value with high reliability can be obtained
for it through the current turn dialogue. The slots selected to be updated are
permitted to enter the Slot Value Generator to update values by a hybrid
method, while the other slots directly inherit the values from the previous
turn. Empirical results show that our method achieves 56.93%, 60.73%, and
58.04% joint accuracy on MultiWOZ 2.0, MultiWOZ 2.1, and MultiWOZ 2.2 datasets
respectively and achieves a new state-of-the-art performance with significant
improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring daily-life fear perception change: a computational study in the context of COVID-19. (arXiv:2107.12606v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chai_Y/0/1/0/all/0/1">Yuchen Chai</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Palacios_J/0/1/0/all/0/1">Juan Palacios</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianghao Wang</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1">Yichun Fan</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Siqi Zheng</a> (1) ((1) Massachusetts Institute of Technology, (2) Chinese Academy of Science)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12606">
                                    <div class="article-summary-box-inner">
                                        <span>COVID-19, as a global health crisis, has triggered the fear emotion with
unprecedented intensity. Besides the fear of getting infected, the outbreak of
COVID-19 also created significant disruptions in people&#x27;s daily life and thus
evoked intensive psychological responses indirect to COVID-19 infections. Here,
we construct an expressed fear database using 16 million social media posts
generated by 536 thousand users between January 1st, 2019 and August 31st, 2020
in China. We employ deep learning techniques to detect the fear emotion within
each post and apply topic models to extract the central fear topics. Based on
this database, we find that sleep disorders (&quot;nightmare&quot; and &quot;insomnia&quot;) take
up the largest share of fear-labeled posts in the pre-pandemic period (January
2019-December 2019), and significantly increase during the COVID-19. We
identify health and work-related concerns are the two major sources of fear
induced by the COVID-19. We also detect gender differences, with females
generating more posts containing the daily-life fear sources during the
COVID-19 period. This research adopts a data-driven approach to trace back
public emotion, which can be used to complement traditional surveys to achieve
real-time emotion monitoring to discern societal concerns and support policy
decision-making.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Grounding with 3D Objects. (arXiv:2107.12514v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thomason_J/0/1/0/all/0/1">Jesse Thomason</a>, <a href="http://arxiv.org/find/cs/1/au:+Shridhar_M/0/1/0/all/0/1">Mohit Shridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1">Yonatan Bisk</a>, <a href="http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1">Chris Paxton</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12514">
                                    <div class="article-summary-box-inner">
                                        <span>Seemingly simple natural language requests to a robot are generally
underspecified, for example &quot;Can you bring me the wireless mouse?&quot; When viewing
mice on the shelf, the number of buttons or presence of a wire may not be
visible from certain angles or positions. Flat images of candidate mice may not
provide the discriminative information needed for &quot;wireless&quot;. The world, and
objects in it, are not flat images but complex 3D shapes. If a human requests
an object based on any of its basic properties, such as color, shape, or
texture, robots should perform the necessary exploration to accomplish the
task. In particular, while substantial effort and progress has been made on
understanding explicitly visual attributes like color and category,
comparatively little progress has been made on understanding language about
shapes and contours. In this work, we introduce a novel reasoning task that
targets both visual and non-visual language about 3D objects. Our new
benchmark, ShapeNet Annotated with Referring Expressions (SNARE), requires a
model to choose which of two objects is being referenced by a natural language
description. We introduce several CLIP-based models for distinguishing objects
and demonstrate that while recent advances in jointly modeling vision and
language are useful for robotic language understanding, it is still the case
that these models are weaker at understanding the 3D nature of objects --
properties which play a key role in manipulation. In particular, we find that
adding view estimation to language grounding models improves accuracy on both
SNARE and when identifying objects referred to in language on a robot platform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">QA Dataset Explosion: A Taxonomy of NLP Resources for Question Answering and Reading Comprehension. (arXiv:2107.12708v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rogers_A/0/1/0/all/0/1">Anna Rogers</a>, <a href="http://arxiv.org/find/cs/1/au:+Gardner_M/0/1/0/all/0/1">Matt Gardner</a>, <a href="http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1">Isabelle Augenstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12708">
                                    <div class="article-summary-box-inner">
                                        <span>Alongside huge volumes of research on deep learning models in NLP in the
recent years, there has been also much work on benchmark datasets needed to
track modeling progress. Question answering and reading comprehension have been
particularly prolific in this regard, with over 80 new datasets appearing in
the past two years. This study is the largest survey of the field to date. We
provide an overview of the various formats and domains of the current
resources, highlighting the current lacunae for future work. We further discuss
the current classifications of &#x60;&#x60;reasoning types&quot; in question answering and
propose a new taxonomy. We also discuss the implications of over-focusing on
English, and survey the current monolingual resources for other languages and
multilingual resources. The study is aimed at both practitioners looking for
pointers to the wealth of existing data, and at researchers working on new
resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-based Unknown Intent Detection with Data Manipulation. (arXiv:2107.12542v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ouyang_Y/0/1/0/all/0/1">Yawen Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jiasheng Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1">Xinyu Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shujian Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiajun Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12542">
                                    <div class="article-summary-box-inner">
                                        <span>Unknown intent detection aims to identify the out-of-distribution (OOD)
utterance whose intent has never appeared in the training set. In this paper,
we propose using energy scores for this task as the energy score is
theoretically aligned with the density of the input and can be derived from any
classifier. However, high-quality OOD utterances are required during the
training stage in order to shape the energy gap between OOD and in-distribution
(IND), and these utterances are difficult to collect in practice. To tackle
this problem, we propose a data manipulation framework to Generate high-quality
OOD utterances with importance weighTs (GOT). Experimental results show that
the energy-based detector fine-tuned by GOT can achieve state-of-the-art
results on two benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-lingual Transferring of Pre-trained Contextualized Language Models. (arXiv:2107.12627v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zuchao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Parnow_K/0/1/0/all/0/1">Kevin Parnow</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hai Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Rui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Utiyama_M/0/1/0/all/0/1">Masao Utiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Sumita_E/0/1/0/all/0/1">Eiichiro Sumita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12627">
                                    <div class="article-summary-box-inner">
                                        <span>Though the pre-trained contextualized language model (PrLM) has made a
significant impact on NLP, training PrLMs in languages other than English can
be impractical for two reasons: other languages often lack corpora sufficient
for training powerful PrLMs, and because of the commonalities among human
languages, computationally expensive PrLM training for different languages is
somewhat redundant. In this work, building upon the recent works connecting
cross-lingual model transferring and neural machine translation, we thus
propose a novel cross-lingual model transferring framework for PrLMs: TreLM. To
handle the symbol order and sequence length differences between languages, we
propose an intermediate &#x60;&#x60;TRILayer&quot; structure that learns from these
differences and creates a better transfer in our primary translation direction,
as well as a new cross-lingual language modeling objective for transfer
training. Additionally, we showcase an embedding aligning that adversarially
adapts a PrLM&#x27;s non-contextualized embedding space and the TRILayer structure
to learn a text transformation network across languages, which addresses the
vocabulary difference between languages. Experiments on both language
understanding and structure parsing tasks show the proposed framework
significantly outperforms language models trained from scratch with limited
data in both performance and efficiency. Moreover, despite an insignificant
performance loss compared to pre-training from scratch in resource-rich
scenarios, our cross-lingual model transferring framework is significantly more
economical.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Greedy Gradient Ensemble for Robust Visual Question Answering. (arXiv:2107.12651v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xinzhe Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuhui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qingming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12651">
                                    <div class="article-summary-box-inner">
                                        <span>Language bias is a critical issue in Visual Question Answering (VQA), where
models often exploit dataset biases for the final decision without considering
the image information. As a result, they suffer from performance drop on
out-of-distribution data and inadequate visual explanation. Based on
experimental analysis for existing robust VQA methods, we stress the language
bias in VQA that comes from two aspects, i.e., distribution bias and shortcut
bias. We further propose a new de-bias framework, Greedy Gradient Ensemble
(GGE), which combines multiple biased models for unbiased base model learning.
With the greedy strategy, GGE forces the biased models to over-fit the biased
data distribution in priority, thus makes the base model pay more attention to
examples that are hard to solve by biased models. The experiments demonstrate
that our method makes better use of visual information and achieves
state-of-the-art performance on diagnosing dataset VQA-CP without using extra
annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Domain Adaptation for Hate Speech Detection Using a Data Augmentation Approach. (arXiv:2107.12866v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sarwar_S/0/1/0/all/0/1">Sheikh Muhammad Sarwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Murdock_V/0/1/0/all/0/1">Vanessa Murdock</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12866">
                                    <div class="article-summary-box-inner">
                                        <span>Online harassment in the form of hate speech has been on the rise in recent
years. Addressing the issue requires a combination of content moderation by
people, aided by automatic detection methods. As content moderation is itself
harmful to the people doing it, we desire to reduce the burden by improving the
automatic detection of hate speech. Hate speech presents a challenge as it is
directed at different target groups using a completely different vocabulary.
Further the authors of the hate speech are incentivized to disguise their
behavior to avoid being removed from a platform. This makes it difficult to
develop a comprehensive data set for training and evaluating hate speech
detection models because the examples that represent one hate speech domain do
not typically represent others, even within the same language or culture. We
propose an unsupervised domain adaptation approach to augment labeled data for
hate speech detection. We evaluate the approach with three different models
(character CNNs, BiLSTMs and BERT) on three different collections. We show our
approach improves Area under the Precision/Recall curve by as much as 42% and
recall by as much as 278%, with no loss (and in some cases a significant gain)
in precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Word Recognition in Speech Transcriptions by Decision-level Fusion of Stemming and Two-way Phoneme Pruning. (arXiv:2107.12428v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mehra_S/0/1/0/all/0/1">Sunakshi Mehra</a>, <a href="http://arxiv.org/find/cs/1/au:+Susan_S/0/1/0/all/0/1">Seba Susan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12428">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce an unsupervised approach for correcting highly imperfect speech
transcriptions based on a decision-level fusion of stemming and two-way phoneme
pruning. Transcripts are acquired from videos by extracting audio using Ffmpeg
framework and further converting audio to text transcript using Google API. In
the benchmark LRW dataset, there are 500 word categories, and 50 videos per
class in mp4 format. All videos consist of 29 frames (each 1.16 s long) and the
word appears in the middle of the video. In our approach we tried to improve
the baseline accuracy from 9.34% by using stemming, phoneme extraction,
filtering and pruning. After applying the stemming algorithm to the text
transcript and evaluating the results, we achieved 23.34% accuracy in word
recognition. To convert words to phonemes we used the Carnegie Mellon
University (CMU) pronouncing dictionary that provides a phonetic mapping of
English words to their pronunciations. A two-way phoneme pruning is proposed
that comprises of the two non-sequential steps: 1) filtering and pruning the
phonemes containing vowels and plosives 2) filtering and pruning the phonemes
containing vowels and fricatives. After obtaining results of stemming and
two-way phoneme pruning, we applied decision-level fusion and that led to an
improvement of word recognition rate upto 32.96%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uniformity in Heterogeneity:Diving Deep into Count Interval Partition for Crowd Counting. (arXiv:2107.12619v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qingyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Boshen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xuyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiayi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12619">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the problem of inaccurate learning targets in crowd counting draws
increasing attention. Inspired by a few pioneering work, we solve this problem
by trying to predict the indices of pre-defined interval bins of counts instead
of the count values themselves. However, an inappropriate interval setting
might make the count error contributions from different intervals extremely
imbalanced, leading to inferior counting performance. Therefore, we propose a
novel count interval partition criterion called Uniform Error Partition (UEP),
which always keeps the expected counting error contributions equal for all
intervals to minimize the prediction risk. Then to mitigate the inevitably
introduced discretization errors in the count quantization process, we propose
another criterion called Mean Count Proxies (MCP). The MCP criterion selects
the best count proxy for each interval to represent its count value during
inference, making the overall expected discretization error of an image nearly
negligible. As far as we are aware, this work is the first to delve into such a
classification task and ends up with a promising solution for count interval
partition. Following the above two theoretically demonstrated criterions, we
propose a simple yet effective model termed Uniform Error Partition Network
(UEPNet), which achieves state-of-the-art performance on several challenging
datasets. The codes will be available at:
https://github.com/TencentYoutuResearch/CrowdCounting-UEPNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Angel&#x27;s Girl for Blind Painters: an Efficient Painting Navigation System Validated by Multimodal Evaluation Approach. (arXiv:2107.12921v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Menghan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuzhen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingli Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Simon X. Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao-Ping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12921">
                                    <div class="article-summary-box-inner">
                                        <span>For people who ardently love painting but unfortunately have visual
impairments, holding a paintbrush to create a work is a very difficult task.
People in this special group are eager to pick up the paintbrush, like Leonardo
da Vinci, to create and make full use of their own talents. Therefore, to
maximally bridge this gap, we propose a painting navigation system to assist
blind people in painting and artistic creation. The proposed system is composed
of cognitive system and guidance system. The system adopts drawing board
positioning based on QR code, brush navigation based on target detection and
bush real-time positioning. Meanwhile, this paper uses human-computer
interaction on the basis of voice and a simple but efficient position
information coding rule. In addition, we design a criterion to efficiently
judge whether the brush reaches the target or not. According to the
experimental results, the thermal curves extracted from the faces of testers
show that it is relatively well accepted by blindfolded and even blind testers.
With the prompt frequency of 1s, the painting navigation system performs best
with the completion degree of 89% with SD of 8.37% and overflow degree of 347%
with SD of 162.14%. Meanwhile, the excellent and good types of brush tip
trajectory account for 74%, and the relative movement distance is 4.21 with SD
of 2.51. This work demonstrates that it is practicable for the blind people to
feel the world through the brush in their hands. In the future, we plan to
deploy Angle&#x27;s Eyes on the phone to make it more portable. The demo video of
the proposed painting navigation system is available at:
https://doi.org/10.6084/m9.figshare.9760004.v1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Fusion Methods for Indexing and Retrieval of Biometric Data: Application to Face Recognition with Privacy Protection. (arXiv:2107.12675v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Drozdowski_P/0/1/0/all/0/1">Pawel Drozdowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Stockhardt_F/0/1/0/all/0/1">Fabian Stockhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Rathgeb_C/0/1/0/all/0/1">Christian Rathgeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Osorio_Roig_D/0/1/0/all/0/1">Dail&#xe9; Osorio-Roig</a>, <a href="http://arxiv.org/find/cs/1/au:+Busch_C/0/1/0/all/0/1">Christoph Busch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12675">
                                    <div class="article-summary-box-inner">
                                        <span>Computationally efficient, accurate, and privacy-preserving data storage and
retrieval are among the key challenges faced by practical deployments of
biometric identification systems worldwide. In this work, a method of protected
indexing of biometric data is presented. By utilising feature-level fusion of
intelligently paired templates, a multi-stage search structure is created.
During retrieval, the list of potential candidate identities is successively
pre-filtered, thereby reducing the number of template comparisons necessary for
a biometric identification transaction. Protection of the biometric probe
templates, as well as the stored reference templates and the created index is
carried out using homomorphic encryption. The proposed method is extensively
evaluated in closed-set and open-set identification scenarios on publicly
available databases using two state-of-the-art open-source face recognition
systems. With respect to a typical baseline algorithm utilising an exhaustive
search-based retrieval algorithm, the proposed method enables a reduction of
the computational workload associated with a biometric identification
transaction by 90%, while simultaneously suffering no degradation of the
biometric performance. Furthermore, by facilitating a seamless integration of
template protection with open-source homomorphic encryption libraries, the
proposed method guarantees unlinkability, irreversibility, and renewability of
the protected biometric data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Learning to Classify Macromolecular Structures in situ for Less Supervision in Cryo-Electron Tomography. (arXiv:2102.12040v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Du_X/0/1/0/all/0/1">Xuefeng Du</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_H/0/1/0/all/0/1">Haohan Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenxi Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zeng_X/0/1/0/all/0/1">Xiangrui Zeng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chang_Y/0/1/0/all/0/1">Yi-Wei Chang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xu_M/0/1/0/all/0/1">Min Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12040">
                                    <div class="article-summary-box-inner">
                                        <span>Motivation: Cryo-Electron Tomography (cryo-ET) is a 3D bioimaging tool that
visualizes the structural and spatial organization of macromolecules at a
near-native state in single cells, which has broad applications in life
science. However, the systematic structural recognition and recovery of
macromolecules captured by cryo-ET are difficult due to high structural
complexity and imaging limits. Deep learning based subtomogram classification
have played critical roles for such tasks. As supervised approaches, however,
their performance relies on sufficient and laborious annotation on a large
training dataset.

Results: To alleviate this major labeling burden, we proposed a Hybrid Active
Learning (HAL) framework for querying subtomograms for labelling from a large
unlabeled subtomogram pool. Firstly, HAL adopts uncertainty sampling to select
the subtomograms that have the most uncertain predictions. Moreover, to
mitigate the sampling bias caused by such strategy, a discriminator is
introduced to judge if a certain subtomogram is labeled or unlabeled and
subsequently the model queries the subtomogram that have higher probabilities
to be unlabeled. Additionally, HAL introduces a subset sampling strategy to
improve the diversity of the query set, so that the information overlap is
decreased between the queried batches and the algorithmic efficiency is
improved. Our experiments on subtomogram classification tasks using both
simulated and real data demonstrate that we can achieve comparable testing
performance (on average only 3% accuracy drop) by using less than 30% of the
labeled subtomograms, which shows a very promising result for subtomogram
classification task with limited labeling resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VIPose: Real-time Visual-Inertial 6D Object Pose Tracking. (arXiv:2107.12617v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ge_R/0/1/0/all/0/1">Rundong Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Loianno_G/0/1/0/all/0/1">Giuseppe Loianno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12617">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating the 6D pose of objects is beneficial for robotics tasks such as
transportation, autonomous navigation, manipulation as well as in scenarios
beyond robotics like virtual and augmented reality. With respect to single
image pose estimation, pose tracking takes into account the temporal
information across multiple frames to overcome possible detection
inconsistencies and to improve the pose estimation efficiency. In this work, we
introduce a novel Deep Neural Network (DNN) called VIPose, that combines
inertial and camera data to address the object pose tracking problem in
real-time. The key contribution is the design of a novel DNN architecture which
fuses visual and inertial features to predict the objects&#x27; relative 6D pose
between consecutive image frames. The overall 6D pose is then estimated by
consecutively combining relative poses. Our approach shows remarkable pose
estimation results for heavily occluded objects that are well known to be very
challenging to handle by existing state-of-the-art solutions. The effectiveness
of the proposed approach is validated on a new dataset called VIYCB with RGB
image, IMU data, and accurate 6D pose annotations created by employing an
automated labeling technique. The approach presents accuracy performances
comparable to state-of-the-art techniques, but with additional benefit to be
real-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Greedy Gradient Ensemble for Robust Visual Question Answering. (arXiv:2107.12651v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xinzhe Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuhui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qingming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12651">
                                    <div class="article-summary-box-inner">
                                        <span>Language bias is a critical issue in Visual Question Answering (VQA), where
models often exploit dataset biases for the final decision without considering
the image information. As a result, they suffer from performance drop on
out-of-distribution data and inadequate visual explanation. Based on
experimental analysis for existing robust VQA methods, we stress the language
bias in VQA that comes from two aspects, i.e., distribution bias and shortcut
bias. We further propose a new de-bias framework, Greedy Gradient Ensemble
(GGE), which combines multiple biased models for unbiased base model learning.
With the greedy strategy, GGE forces the biased models to over-fit the biased
data distribution in priority, thus makes the base model pay more attention to
examples that are hard to solve by biased models. The experiments demonstrate
that our method makes better use of visual information and achieves
state-of-the-art performance on diagnosing dataset VQA-CP without using extra
annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A persistent homology-based topological loss for CNN-based multi-class segmentation of CMR. (arXiv:2107.12689v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Byrne_N/0/1/0/all/0/1">Nick Byrne</a>, <a href="http://arxiv.org/find/eess/1/au:+Clough_J/0/1/0/all/0/1">James R Clough</a>, <a href="http://arxiv.org/find/eess/1/au:+Valverde_I/0/1/0/all/0/1">Isra Valverde</a>, <a href="http://arxiv.org/find/eess/1/au:+Montana_G/0/1/0/all/0/1">Giovanni Montana</a>, <a href="http://arxiv.org/find/eess/1/au:+King_A/0/1/0/all/0/1">Andrew P King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12689">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-class segmentation of cardiac magnetic resonance (CMR) images seeks a
separation of data into anatomical components with known structure and
configuration. The most popular CNN-based methods are optimised using pixel
wise loss functions, ignorant of the spatially extended features that
characterise anatomy. Therefore, whilst sharing a high spatial overlap with the
ground truth, inferred CNN-based segmentations can lack coherence, including
spurious connected components, holes and voids. Such results are implausible,
violating anticipated anatomical topology. In response, (single-class)
persistent homology-based loss functions have been proposed to capture global
anatomical features. Our work extends these approaches to the task of
multi-class segmentation. Building an enriched topological description of all
class labels and class label pairs, our loss functions make predictable and
statistically significant improvements in segmentation topology using a
CNN-based post-processing framework. We also present (and make available) a
highly efficient implementation based on cubical complexes and parallel
execution, enabling practical application within high resolution 3D data for
the first time. We demonstrate our approach on 2D short axis and 3D whole heart
CMR segmentation, advancing a detailed and faithful analysis of performance on
two publicly available datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DSP: Dual Soft-Paste for Unsupervised Domain Adaptive Semantic Segmentation. (arXiv:2107.09600v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1">Li Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lefei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.09600">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) for semantic segmentation aims to adapt
a segmentation model trained on the labeled source domain to the unlabeled
target domain. Existing methods try to learn domain invariant features while
suffering from large domain gaps that make it difficult to correctly align
discrepant features, especially in the initial training phase. To address this
issue, we propose a novel Dual Soft-Paste (DSP) method in this paper.
Specifically, DSP selects some classes from a source domain image using a
long-tail class first sampling strategy and softly pastes the corresponding
image patch on both the source and target training images with a fusion weight.
Technically, we adopt the mean teacher framework for domain adaptation, where
the pasted source and target images go through the student network while the
original target image goes through the teacher network. Output-level alignment
is carried out by aligning the probability maps of the target fused image from
both networks using a weighted cross-entropy loss. In addition, feature-level
alignment is carried out by aligning the feature maps of the source and target
images from student network using a weighted maximum mean discrepancy loss. DSP
facilitates the model learning domain-invariant features from the intermediate
domains, leading to faster convergence and better performance. Experiments on
two challenging benchmarks demonstrate the superiority of DSP over
state-of-the-art methods. Code is available at
\url{https://github.com/GaoLii/DSP}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">H3D-Net: Few-Shot High-Fidelity 3D Head Reconstruction. (arXiv:2107.12512v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramon_E/0/1/0/all/0/1">Eduard Ramon</a>, <a href="http://arxiv.org/find/cs/1/au:+Triginer_G/0/1/0/all/0/1">Gil Triginer</a>, <a href="http://arxiv.org/find/cs/1/au:+Escur_J/0/1/0/all/0/1">Janna Escur</a>, <a href="http://arxiv.org/find/cs/1/au:+Pumarola_A/0/1/0/all/0/1">Albert Pumarola</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_J/0/1/0/all/0/1">Jaime Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Giro_i_Nieto_X/0/1/0/all/0/1">Xavier Giro-i-Nieto</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_Noguer_F/0/1/0/all/0/1">Francesc Moreno-Noguer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12512">
                                    <div class="article-summary-box-inner">
                                        <span>Recent learning approaches that implicitly represent surface geometry using
coordinate-based neural representations have shown impressive results in the
problem of multi-view 3D reconstruction. The effectiveness of these techniques
is, however, subject to the availability of a large number (several tens) of
input views of the scene, and computationally demanding optimizations. In this
paper, we tackle these limitations for the specific problem of few-shot full 3D
head reconstruction, by endowing coordinate-based representations with a
probabilistic shape prior that enables faster convergence and better
generalization when using few input images (down to three). First, we learn a
shape model of 3D heads from thousands of incomplete raw scans using implicit
representations. At test time, we jointly overfit two coordinate-based neural
networks to the scene, one modeling the geometry and another estimating the
surface radiance, using implicit differentiable rendering. We devise a
two-stage optimization strategy in which the learned prior is used to
initialize and constrain the geometry during an initial optimization phase.
Then, the prior is unfrozen and fine-tuned to the scene. By doing this, we
achieve high-fidelity head reconstructions, including hair and shoulders, and
with a high level of detail that consistently outperforms both state-of-the-art
3D Morphable Models methods in the few-shot scenario, and non-parametric
methods when large sets of views are available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse to Fine: Domain Adaptive Crowd Counting via Adversarial Scoring Network. (arXiv:2107.12858v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1">Xiaoye Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuangjie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiaoqing Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jin Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12858">
                                    <div class="article-summary-box-inner">
                                        <span>Recent deep networks have convincingly demonstrated high capability in crowd
counting, which is a critical task attracting widespread attention due to its
various industrial applications. Despite such progress, trained data-dependent
models usually can not generalize well to unseen scenarios because of the
inherent domain shift. To facilitate this issue, this paper proposes a novel
adversarial scoring network (ASNet) to gradually bridge the gap across domains
from coarse to fine granularity. In specific, at the coarse-grained stage, we
design a dual-discriminator strategy to adapt source domain to be close to the
targets from the perspectives of both global and local feature space via
adversarial learning. The distributions between two domains can thus be aligned
roughly. At the fine-grained stage, we explore the transferability of source
characteristics by scoring how similar the source samples are to target ones
from multiple levels based on generative probability derived from coarse stage.
Guided by these hierarchical scores, the transferable source features are
properly selected to enhance the knowledge transfer during the adaptation
process. With the coarse-to-fine design, the generalization bottleneck induced
from the domain discrepancy can be effectively alleviated. Three sets of
migration experiments show that the proposed methods achieve state-of-the-art
counting performance compared with major unsupervised methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving ClusterGAN Using Self-AugmentedInformation Maximization of Disentangling LatentSpaces. (arXiv:2107.12706v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dam_T/0/1/0/all/0/1">Tanmoy Dam</a>, <a href="http://arxiv.org/find/cs/1/au:+Anavatti_S/0/1/0/all/0/1">Sreenatha G. Anavatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbass_H/0/1/0/all/0/1">Hussein A. Abbass</a> (Fellow, IEEESchool of Engineering and Information Technology, University of New South Wales Canberra, Australia)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12706">
                                    <div class="article-summary-box-inner">
                                        <span>The Latent Space Clustering in Generative adversarial networks (ClusterGAN)
method has been successful with high-dimensional data. However, the method
assumes uniformlydistributed priors during the generation of modes, which isa
restrictive assumption in real-world data and cause loss ofdiversity in the
generated modes. In this paper, we proposeself-augmentation information
maximization improved Clus-terGAN (SIMI-ClusterGAN) to learn the distinctive
priorsfrom the data. The proposed SIMI-ClusterGAN consists offour deep neural
networks: self-augmentation prior network,generator, discriminator and
clustering inference autoencoder.The proposed method has been validated using
seven bench-mark data sets and has shown improved performance overstate-of-the
art methods. To demonstrate the superiority ofSIMI-ClusterGAN performance on
imbalanced dataset, wehave discussed two imbalanced conditions on MNIST
datasetswith one-class imbalance and three classes imbalanced cases.The results
highlight the advantages of SIMI-ClusterGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DV-Det: Efficient 3D Point Cloud Object Detection with Dynamic Voxelization. (arXiv:2107.12707v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1">Zhaoyu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_P/0/1/0/all/0/1">Pin Siang Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Hsing Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12707">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose a novel two-stage framework for the efficient 3D
point cloud object detection. Instead of transforming point clouds into 2D bird
eye view projections, we parse the raw point cloud data directly in the 3D
space yet achieve impressive efficiency and accuracy. To achieve this goal, we
propose dynamic voxelization, a method that voxellizes points at local scale
on-the-fly. By doing so, we preserve the point cloud geometry with 3D voxels,
and therefore waive the dependence on expensive MLPs to learn from point
coordinates. On the other hand, we inherently still follow the same processing
pattern as point-wise methods (e.g., PointNet) and no longer suffer from the
quantization issue like conventional convolutions. For further speed
optimization, we propose the grid-based downsampling and voxelization method,
and provide different CUDA implementations to accommodate to the discrepant
requirements during training and inference phases. We highlight our efficiency
on KITTI 3D object detection dataset with 75 FPS and on Waymo Open dataset with
25 FPS inference speed with satisfactory accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Operating Points for High Performance Lesion Detection and Segmentation Using Lesion Size Reweighting. (arXiv:2107.12978v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nichyporuk_B/0/1/0/all/0/1">Brennan Nichyporuk</a>, <a href="http://arxiv.org/find/eess/1/au:+Szeto_J/0/1/0/all/0/1">Justin Szeto</a>, <a href="http://arxiv.org/find/eess/1/au:+Arnold_D/0/1/0/all/0/1">Douglas L. Arnold</a>, <a href="http://arxiv.org/find/eess/1/au:+Arbel_T/0/1/0/all/0/1">Tal Arbel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12978">
                                    <div class="article-summary-box-inner">
                                        <span>There are many clinical contexts which require accurate detection and
segmentation of all focal pathologies (e.g. lesions, tumours) in patient
images. In cases where there are a mix of small and large lesions, standard
binary cross entropy loss will result in better segmentation of large lesions
at the expense of missing small ones. Adjusting the operating point to
accurately detect all lesions generally leads to oversegmentation of large
lesions. In this work, we propose a novel reweighing strategy to eliminate this
performance gap, increasing small pathology detection performance while
maintaining segmentation accuracy. We show that our reweighing strategy vastly
outperforms competing strategies based on experiments on a large scale,
multi-scanner, multi-center dataset of Multiple Sclerosis patient images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Temperature Scaling for Probability Calibration. (arXiv:2008.05105v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zhipeng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peirong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Niethammer_M/0/1/0/all/0/1">Marc Niethammer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.05105">
                                    <div class="article-summary-box-inner">
                                        <span>For semantic segmentation, label probabilities are often uncalibrated as they
are typically only the by-product of a segmentation task. Intersection over
Union (IoU) and Dice score are often used as criteria for segmentation success,
while metrics related to label probabilities are not often explored. However,
probability calibration approaches have been studied, which match probability
outputs with experimentally observed errors. These approaches mainly focus on
classification tasks, but not on semantic segmentation. Thus, we propose a
learning-based calibration method that focuses on multi-label semantic
segmentation. Specifically, we adopt a convolutional neural network to predict
local temperature values for probability calibration. One advantage of our
approach is that it does not change prediction accuracy, hence allowing for
calibration as a post-processing step. Experiments on the COCO, CamVid, and
LPBA40 datasets demonstrate improved calibration performance for a range of
different metrics. We also demonstrate the good performance of our method for
multi-atlas brain segmentation from magnetic resonance images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quaternion Generative Adversarial Networks. (arXiv:2104.09630v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grassucci_E/0/1/0/all/0/1">Eleonora Grassucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Cicero_E/0/1/0/all/0/1">Edoardo Cicero</a>, <a href="http://arxiv.org/find/cs/1/au:+Comminiello_D/0/1/0/all/0/1">Danilo Comminiello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09630">
                                    <div class="article-summary-box-inner">
                                        <span>Latest Generative Adversarial Networks (GANs) are gathering outstanding
results through a large-scale training, thus employing models composed of
millions of parameters requiring extensive computational capabilities. Building
such huge models undermines their replicability and increases the training
instability. Moreover, multi-channel data, such as images or audio, are usually
processed by realvalued convolutional networks that flatten and concatenate the
input, often losing intra-channel spatial relations. To address these issues
related to complexity and information loss, we propose a family of
quaternion-valued generative adversarial networks (QGANs). QGANs exploit the
properties of quaternion algebra, e.g., the Hamilton product, that allows to
process channels as a single entity and capture internal latent relations,
while reducing by a factor of 4 the overall number of parameters. We show how
to design QGANs and to extend the proposed approach even to advanced models.We
compare the proposed QGANs with real-valued counterparts on several image
generation benchmarks. Results show that QGANs are able to obtain better FID
scores than real-valued GANs and to generate visually pleasing images.
Furthermore, QGANs save up to 75% of the training parameters. We believe these
results may pave the way to novel, more accessible, GANs capable of improving
performance and saving computational resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Self-Consistency for Deepfake Detection. (arXiv:2012.09311v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tianchen Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingze Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1">Hui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yuanjun Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_W/0/1/0/all/0/1">Wei Xia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09311">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new method to detect deepfake images using the cue of the source
feature inconsistency within the forged images. It is based on the hypothesis
that images&#x27; distinct source features can be preserved and extracted after
going through state-of-the-art deepfake generation processes. We introduce a
novel representation learning approach, called pair-wise self-consistency
learning (PCL), for training ConvNets to extract these source features and
detect deepfake images. It is accompanied by a new image synthesis approach,
called inconsistency image generator (I2G), to provide richly annotated
training data for PCL. Experimental results on seven popular datasets show that
our models improve averaged AUC over the state of the art from 96.45% to 98.05%
in the in-dataset evaluation and from 86.03% to 92.18% in the cross-dataset
evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Estimate Hidden Motions with Global Motion Aggregation. (arXiv:2104.02409v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shihao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Campbell_D/0/1/0/all/0/1">Dylan Campbell</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongdong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hartley_R/0/1/0/all/0/1">Richard Hartley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02409">
                                    <div class="article-summary-box-inner">
                                        <span>Occlusions pose a significant challenge to optical flow algorithms that rely
on local evidences. We consider an occluded point to be one that is imaged in
the first frame but not in the next, a slight overloading of the standard
definition since it also includes points that move out-of-frame. Estimating the
motion of these points is extremely difficult, particularly in the two-frame
setting. Previous work relies on CNNs to learn occlusions, without much
success, or requires multiple frames to reason about occlusions using temporal
smoothness. In this paper, we argue that the occlusion problem can be better
solved in the two-frame case by modelling image self-similarities. We introduce
a global motion aggregation module, a transformer-based approach to find
long-range dependencies between pixels in the first image, and perform global
aggregation on the corresponding motion features. We demonstrate that the
optical flow estimates in the occluded regions can be significantly improved
without damaging the performance in non-occluded regions. This approach obtains
new state-of-the-art results on the challenging Sintel dataset, improving the
average end-point error by 13.6% on Sintel Final and 13.7% on Sintel Clean. At
the time of submission, our method ranks first on these benchmarks among all
published and unpublished approaches. Code is available at
https://github.com/zacjiang/GMA</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alleviate Representation Overlapping in Class Incremental Learning by Contrastive Class Concentration. (arXiv:2107.12308v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ni_Z/0/1/0/all/0/1">Zixuan Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Haizhou Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Siliang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1">Yueting Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12308">
                                    <div class="article-summary-box-inner">
                                        <span>The challenge of the Class Incremental Learning (CIL) lies in difficulty for
a learner to discern the old classes&#x27; data from the new while no previous data
is preserved. Namely, the representation distribution of different phases
overlaps with each other. In this paper, to alleviate the phenomenon of
representation overlapping for both memory-based and memory-free methods, we
propose a new CIL framework, Contrastive Class Concentration for CIL (C4IL).
Our framework leverages the class concentration effect of contrastive
representation learning, therefore yielding a representation distribution with
better intra-class compactibility and inter-class separability. Quantitative
experiments showcase our framework that is effective in both memory-based and
memory-free cases: it outperforms the baseline methods of both cases by 5% in
terms of the average and top-1 accuracy in 10-phase and 20-phase CIL.
Qualitative results also demonstrate that our method generates a more compact
representation distribution that alleviates the overlapping problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Entropy Maximization and Meta Classification for Out-Of-Distribution Detection in Semantic Segmentation. (arXiv:2012.06575v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_R/0/1/0/all/0/1">Robin Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1">Matthias Rottmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Gottschalk_H/0/1/0/all/0/1">Hanno Gottschalk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06575">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) for the semantic segmentation of images are
usually trained to operate on a predefined closed set of object classes. This
is in contrast to the &quot;open world&quot; setting where DNNs are envisioned to be
deployed to. From a functional safety point of view, the ability to detect
so-called &quot;out-of-distribution&quot; (OoD) samples, i.e., objects outside of a DNN&#x27;s
semantic space, is crucial for many applications such as automated driving. A
natural baseline approach to OoD detection is to threshold on the pixel-wise
softmax entropy. We present a two-step procedure that significantly improves
that approach. Firstly, we utilize samples from the COCO dataset as OoD proxy
and introduce a second training objective to maximize the softmax entropy on
these samples. Starting from pretrained semantic segmentation networks we
re-train a number of DNNs on different in-distribution datasets and
consistently observe improved OoD detection performance when evaluating on
completely disjoint OoD datasets. Secondly, we perform a transparent
post-processing step to discard false positive OoD samples by so-called &quot;meta
classification&quot;. To this end, we apply linear models to a set of hand-crafted
metrics derived from the DNN&#x27;s softmax probabilities. In our experiments we
consistently observe a clear additional gain in OoD detection performance,
cutting down the number of detection errors by up to 52% when comparing the
best baseline with our results. We achieve this improvement sacrificing only
marginally in original segmentation performance. Therefore, our method
contributes to safer DNNs with more reliable overall system performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-Path Convolutional Image-Text Embeddings with Instance Loss. (arXiv:1711.05535v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhedong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Liang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Garrett_M/0/1/0/all/0/1">Michael Garrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingliang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yi-Dong Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1711.05535">
                                    <div class="article-summary-box-inner">
                                        <span>Matching images and sentences demands a fine understanding of both
modalities. In this paper, we propose a new system to discriminatively embed
the image and text to a shared visual-textual space. In this field, most
existing works apply the ranking loss to pull the positive image / text pairs
close and push the negative pairs apart from each other. However, directly
deploying the ranking loss is hard for network learning, since it starts from
the two heterogeneous features to build inter-modal relationship. To address
this problem, we propose the instance loss which explicitly considers the
intra-modal data distribution. It is based on an unsupervised assumption that
each image / text group can be viewed as a class. So the network can learn the
fine granularity from every image/text group. The experiment shows that the
instance loss offers better weight initialization for the ranking loss, so that
more discriminative embeddings can be learned. Besides, existing works usually
apply the off-the-shelf features, i.e., word2vec and fixed visual feature. So
in a minor contribution, this paper constructs an end-to-end dual-path
convolutional network to learn the image and text representations. End-to-end
learning allows the system to directly learn from the data and fully utilize
the supervision. On two generic retrieval datasets (Flickr30k and MSCOCO),
experiments demonstrate that our method yields competitive accuracy compared to
state-of-the-art methods. Moreover, in language based person retrieval, we
improve the state of the art by a large margin. The code has been made publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangle Your Dense Object Detector. (arXiv:2107.02963v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zehui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chenhongyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiaofei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Feng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zheng-Jun Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Feng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.02963">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based dense object detectors have achieved great success in the
past few years and have been applied to numerous multimedia applications such
as video understanding. However, the current training pipeline for dense
detectors is compromised to lots of conjunctions that may not hold. In this
paper, we investigate three such important conjunctions: 1) only samples
assigned as positive in classification head are used to train the regression
head; 2) classification and regression share the same input feature and
computational fields defined by the parallel head architecture; and 3) samples
distributed in different feature pyramid layers are treated equally when
computing the loss. We first carry out a series of pilot experiments to show
disentangling such conjunctions can lead to persistent performance improvement.
Then, based on these findings, we propose Disentangled Dense Object Detector
(DDOD), in which simple and effective disentanglement mechanisms are designed
and integrated into the current state-of-the-art dense object detectors.
Extensive experiments on MS COCO benchmark show that our approach can lead to
2.0 mAP, 2.4 mAP and 2.2 mAP absolute improvements on RetinaNet, FCOS, and ATSS
baselines with negligible extra overhead. Notably, our best model reaches 55.0
mAP on the COCO test-dev set and 93.5 AP on the hard subset of WIDER FACE,
achieving new state-of-the-art performance on these two competitive benchmarks.
Code is available at https://github.com/zehuichen123/DDOD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weight Reparametrization for Budget-Aware Network Pruning. (arXiv:2107.03909v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dupont_R/0/1/0/all/0/1">Robin Dupont</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahbi_H/0/1/0/all/0/1">Hichem Sahbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Michel_G/0/1/0/all/0/1">Guillaume Michel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03909">
                                    <div class="article-summary-box-inner">
                                        <span>Pruning seeks to design lightweight architectures by removing redundant
weights in overparameterized networks. Most of the existing techniques first
remove structured sub-networks (filters, channels,...) and then fine-tune the
resulting networks to maintain a high accuracy. However, removing a whole
structure is a strong topological prior and recovering the accuracy, with
fine-tuning, is highly cumbersome. In this paper, we introduce an &quot;end-to-end&quot;
lightweight network design that achieves training and pruning simultaneously
without fine-tuning. The design principle of our method relies on
reparametrization that learns not only the weights but also the topological
structure of the lightweight sub-network. This reparametrization acts as a
prior (or regularizer) that defines pruning masks implicitly from the weights
of the underlying network, without increasing the number of training
parameters. Sparsity is induced with a budget loss that provides an accurate
pruning. Extensive experiments conducted on the CIFAR10 and the TinyImageNet
datasets, using standard architectures (namely Conv4, VGG19 and ResNet18), show
compelling results without fine-tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sharp U-Net: Depthwise Convolutional Network for Biomedical Image Segmentation. (arXiv:2107.12461v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zunair_H/0/1/0/all/0/1">Hasib Zunair</a>, <a href="http://arxiv.org/find/eess/1/au:+Hamza_A/0/1/0/all/0/1">A. Ben Hamza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12461">
                                    <div class="article-summary-box-inner">
                                        <span>The U-Net architecture, built upon the fully convolutional network, has
proven to be effective in biomedical image segmentation. However, U-Net applies
skip connections to merge semantically different low- and high-level
convolutional features, resulting in not only blurred feature maps, but also
over- and under-segmented target regions. To address these limitations, we
propose a simple, yet effective end-to-end depthwise encoder-decoder fully
convolutional network architecture, called Sharp U-Net, for binary and
multi-class biomedical image segmentation. The key rationale of Sharp U-Net is
that instead of applying a plain skip connection, a depthwise convolution of
the encoder feature map with a sharpening kernel filter is employed prior to
merging the encoder and decoder features, thereby producing a sharpened
intermediate feature map of the same size as the encoder map. Using this
sharpening filter layer, we are able to not only fuse semantically less
dissimilar features, but also to smooth out artifacts throughout the network
layers during the early stages of training. Our extensive experiments on six
datasets show that the proposed Sharp U-Net model consistently outperforms or
matches the recent state-of-the-art baselines in both binary and multi-class
segmentation tasks, while adding no extra learnable parameters. Furthermore,
Sharp U-Net outperforms baselines that have more than three times the number of
learnable parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved-Mask R-CNN: Towards an Accurate Generic MSK MRI instance segmentation platform (Data from the Osteoarthritis Initiative). (arXiv:2107.12889v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Felfeliyan_B/0/1/0/all/0/1">Banafshe Felfeliyan</a>, <a href="http://arxiv.org/find/eess/1/au:+Hareendranathan_A/0/1/0/all/0/1">Abhilash Hareendranathan</a>, <a href="http://arxiv.org/find/eess/1/au:+Kuntze_G/0/1/0/all/0/1">Gregor Kuntze</a>, <a href="http://arxiv.org/find/eess/1/au:+Jaremko_J/0/1/0/all/0/1">Jacob L. Jaremko</a>, <a href="http://arxiv.org/find/eess/1/au:+Ronsky_J/0/1/0/all/0/1">Janet L. Ronsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12889">
                                    <div class="article-summary-box-inner">
                                        <span>Objective assessment of Magnetic Resonance Imaging (MRI) scans of
osteoarthritis (OA) can address the limitation of the current OA assessment.
Segmentation of bone, cartilage, and joint fluid is necessary for the OA
objective assessment. Most of the proposed segmentation methods are not
performing instance segmentation and suffer from class imbalance problems. This
study deployed Mask R-CNN instance segmentation and improved it (improved-Mask
R-CNN (iMaskRCNN)) to obtain a more accurate generalized segmentation for
OA-associated tissues. Training and validation of the method were performed
using 500 MRI knees from the Osteoarthritis Initiative (OAI) dataset and 97 MRI
scans of patients with symptomatic hip OA. Three modifications to Mask R-CNN
yielded the iMaskRCNN: adding a 2nd ROIAligned block, adding an extra decoder
layer to the mask-header, and connecting them by a skip connection. The results
were assessed using Hausdorff distance, dice score, and coefficients of
variation (CoV). The iMaskRCNN led to improved bone and cartilage segmentation
compared to Mask RCNN as indicated with the increase in dice score from 95% to
98% for the femur, 95% to 97% for tibia, 71% to 80% for femoral cartilage, and
81% to 82% for tibial cartilage. For the effusion detection, dice improved with
iMaskRCNN 72% versus MaskRCNN 71%. The CoV values for effusion detection
between Reader1 and Mask R-CNN (0.33), Reader1 and iMaskRCNN (0.34), Reader2
and Mask R-CNN (0.22), Reader2 and iMaskRCNN (0.29) are close to CoV between
two readers (0.21), indicating a high agreement between the human readers and
both Mask R-CNN and iMaskRCNN. Mask R-CNN and iMaskRCNN can reliably and
simultaneously extract different scale articular tissues involved in OA,
forming the foundation for automated assessment of OA. The iMaskRCNN results
show that the modification improved the network performance around the edges.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comprehensive Validation of Automated Whole Body Skeletal Muscle, Adipose Tissue, and Bone Segmentation from 3D CT images for Body Composition Analysis: Towards Extended Body Composition. (arXiv:2106.00652v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1">Da Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chow_V/0/1/0/all/0/1">Vincent Chow</a>, <a href="http://arxiv.org/find/cs/1/au:+Popuri_K/0/1/0/all/0/1">Karteek Popuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Beg_M/0/1/0/all/0/1">Mirza Faisal Beg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00652">
                                    <div class="article-summary-box-inner">
                                        <span>The latest advances in computer-assisted precision medicine are making it
feasible to move from population-wide models that are useful to discover
aggregate patterns that hold for group-based analysis to patient-specific
models that can drive patient-specific decisions with regard to treatment
choices, and predictions of outcomes of treatment. Body Composition is
recognized as an important driver and risk factor for a wide variety of
diseases, as well as a predictor of individual patient-specific clinical
outcomes to treatment choices or surgical interventions. 3D CT images are
routinely acquired in the oncological worklows and deliver accurate rendering
of internal anatomy and therefore can be used opportunistically to assess the
amount of skeletal muscle and adipose tissue compartments. Powerful tools of
artificial intelligence such as deep learning are making it feasible now to
segment the entire 3D image and generate accurate measurements of all internal
anatomy. These will enable the overcoming of the severe bottleneck that existed
previously, namely, the need for manual segmentation, which was prohibitive to
scale to the hundreds of 2D axial slices that made up a 3D volumetric image.
Automated tools such as presented here will now enable harvesting whole-body
measurements from 3D CT or MRI images, leading to a new era of discovery of the
drivers of various diseases based on individual tissue, organ volume, shape,
and functional status. These measurements were hitherto unavailable thereby
limiting the field to a very small and limited subset. These discoveries and
the potential to perform individual image segmentation with high speed and
accuracy are likely to lead to the incorporation of these 3D measures into
individual specific treatment planning models related to nutrition, aging,
chemotoxicity, surgery and survival after the onset of a major disease such as
cancer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Path-Restore: Learning Network Path Selection for Image Restoration. (arXiv:1904.10343v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1">Ke Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xintao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1">Chao Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaoou Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1">Chen Change Loy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.10343">
                                    <div class="article-summary-box-inner">
                                        <span>Very deep Convolutional Neural Networks (CNNs) have greatly improved the
performance on various image restoration tasks. However, this comes at a price
of increasing computational burden, hence limiting their practical usages. We
observe that some corrupted image regions are inherently easier to restore than
others since the distortion and content vary within an image. To leverage this,
we propose Path-Restore, a multi-path CNN with a pathfinder that can
dynamically select an appropriate route for each image region. We train the
pathfinder using reinforcement learning with a difficulty-regulated reward.
This reward is related to the performance, complexity and &quot;the difficulty of
restoring a region&quot;. A policy mask is further investigated to jointly process
all the image regions. We conduct experiments on denoising and mixed
restoration tasks. The results show that our method achieves comparable or
superior performance to existing approaches with less computational cost. In
particular, Path-Restore is effective for real-world denoising, where the noise
distribution varies across different regions on a single image. Compared to the
state-of-the-art RIDNet, our method achieves comparable performance and runs
2.7x faster on the realistic Darmstadt Noise Dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ENHANCE (ENriching Health data by ANnotations of Crowd and Experts): A case study for skin lesion classification. (arXiv:2107.12734v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raumanns_R/0/1/0/all/0/1">Ralf Raumanns</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouten_G/0/1/0/all/0/1">Gerard Schouten</a>, <a href="http://arxiv.org/find/cs/1/au:+Joosten_M/0/1/0/all/0/1">Max Joosten</a>, <a href="http://arxiv.org/find/cs/1/au:+Pluim_J/0/1/0/all/0/1">Josien P. W. Pluim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheplygina_V/0/1/0/all/0/1">Veronika Cheplygina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12734">
                                    <div class="article-summary-box-inner">
                                        <span>We present ENHANCE, an open dataset with multiple annotations to complement
the existing ISIC and PH2 skin lesion classification datasets. This dataset
contains annotations of visual ABC (asymmetry, border, colour) features from
non-expert annotation sources: undergraduate students, crowd workers from
Amazon MTurk and classic image processing algorithms. In this paper we first
analyse the correlations between the annotations and the diagnostic label of
the lesion, as well as study the agreement between different annotation
sources. Overall we find weak correlations of non-expert annotations with the
diagnostic label, and low agreement between different annotation sources. We
then study multi-task learning (MTL) with the annotations as additional labels,
and show that non-expert annotations can improve (ensembles of)
state-of-the-art convolutional neural networks via MTL. We hope that our
dataset can be used in further research into multiple annotations and/or MTL.
All data and models are available on Github:
https://github.com/raumannsr/ENHANCE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COPS: Controlled Pruning Before Training Starts. (arXiv:2107.12673v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wimmer_P/0/1/0/all/0/1">Paul Wimmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehnert_J/0/1/0/all/0/1">Jens Mehnert</a>, <a href="http://arxiv.org/find/cs/1/au:+Condurache_A/0/1/0/all/0/1">Alexandru Condurache</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12673">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art deep neural network (DNN) pruning techniques, applied
one-shot before training starts, evaluate sparse architectures with the help of
a single criterion -- called pruning score. Pruning weights based on a solitary
score works well for some architectures and pruning rates but may also fail for
other ones. As a common baseline for pruning scores, we introduce the notion of
a generalized synaptic score (GSS). In this work we do not concentrate on a
single pruning criterion, but provide a framework for combining arbitrary GSSs
to create more powerful pruning strategies. These COmbined Pruning Scores
(COPS) are obtained by solving a constrained optimization problem. Optimizing
for more than one score prevents the sparse network to overly specialize on an
individual task, thus COntrols Pruning before training Starts. The
combinatorial optimization problem given by COPS is relaxed on a linear program
(LP). This LP is solved analytically and determines a solution for COPS.
Furthermore, an algorithm to compute it for two scores numerically is proposed
and evaluated. Solving COPS in such a way has lower complexity than the best
general LP solver. In our experiments we compared pruning with COPS against
state-of-the-art methods for different network architectures and image
classification tasks and obtained improved results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-stream Network for Visual Recognition. (arXiv:2105.14734v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_M/0/1/0/all/0/1">Mingyuan Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Renrui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Honghui Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Peng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Teli Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Baochang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shumin Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14734">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers with remarkable global representation capacities achieve
competitive results for visual tasks, but fail to consider high-level local
pattern information in input images. In this paper, we present a generic
Dual-stream Network (DS-Net) to fully explore the representation capacity of
local and global pattern features for image classification. Our DS-Net can
simultaneously calculate fine-grained and integrated features and efficiently
fuse them. Specifically, we propose an Intra-scale Propagation module to
process two different resolutions in each block and an Inter-Scale Alignment
module to perform information interaction across features at dual scales.
Besides, we also design a Dual-stream FPN (DS-FPN) to further enhance
contextual information for downstream dense predictions. Without bells and
whistles, the propsed DS-Net outperforms Deit-Small by 2.4% in terms of top-1
accuracy on ImageNet-1k and achieves state-of-the-art performance over other
Vision Transformers and ResNets. For object detection and instance
segmentation, DS-Net-Small respectively outperforms ResNet-50 by 6.4% and 5.5 %
in terms of mAP on MSCOCO 2017, and surpasses the previous state-of-the-art
scheme, which significantly demonstrates its potential to be a general backbone
in vision tasks. The code will be released soon.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision-Guided Forecasting -- Visual Context for Multi-Horizon Time Series Forecasting. (arXiv:2107.12674v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kosman_E/0/1/0/all/0/1">Eitan Kosman</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_D/0/1/0/all/0/1">Dotan Di Castro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12674">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous driving gained huge traction in recent years, due to its potential
to change the way we commute. Much effort has been put into trying to estimate
the state of a vehicle. Meanwhile, learning to forecast the state of a vehicle
ahead introduces new capabilities, such as predicting dangerous situations.
Moreover, forecasting brings new supervision opportunities by learning to
predict richer a context, expressed by multiple horizons. Intuitively, a video
stream originated from a front-facing camera is necessary because it encodes
information about the upcoming road. Besides, historical traces of the
vehicle&#x27;s states give more context. In this paper, we tackle multi-horizon
forecasting of vehicle states by fusing the two modalities. We design and
experiment with 3 end-to-end architectures that exploit 3D convolutions for
visual features extraction and 1D convolutions for features extraction from
speed and steering angle traces. To demonstrate the effectiveness of our
method, we perform extensive experiments on two publicly available real-world
datasets, Comma2k19 and the Udacity challenge. We show that we are able to
forecast a vehicle&#x27;s state to various horizons, while outperforming the current
state-of-the-art results on the related task of driving state estimation. We
examine the contribution of vision features, and find that a model fed with
vision features achieves an error that is 56.6% and 66.9% of the error of a
model that doesn&#x27;t use those features, on the Udacity and Comma2k19 datasets
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clickbait Detection in YouTube Videos. (arXiv:2107.12791v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gothankar_R/0/1/0/all/0/1">Ruchira Gothankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Troia_F/0/1/0/all/0/1">Fabio Di Troia</a>, <a href="http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1">Mark Stamp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12791">
                                    <div class="article-summary-box-inner">
                                        <span>YouTube videos often include captivating descriptions and intriguing
thumbnails designed to increase the number of views, and thereby increase the
revenue for the person who posted the video. This creates an incentive for
people to post clickbait videos, in which the content might deviate
significantly from the title, description, or thumbnail. In effect, users are
tricked into clicking on clickbait videos. In this research, we consider the
challenging problem of detecting clickbait YouTube videos. We experiment with
multiple state-of-the-art machine learning techniques using a variety of
textual features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Denoising via GainTuning. (arXiv:2107.12815v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohan_S/0/1/0/all/0/1">Sreyas Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vincent_J/0/1/0/all/0/1">Joshua L. Vincent</a>, <a href="http://arxiv.org/find/cs/1/au:+Manzorro_R/0/1/0/all/0/1">Ramon Manzorro</a>, <a href="http://arxiv.org/find/cs/1/au:+Crozier_P/0/1/0/all/0/1">Peter A. Crozier</a>, <a href="http://arxiv.org/find/cs/1/au:+Simoncelli_E/0/1/0/all/0/1">Eero P. Simoncelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Granda_C/0/1/0/all/0/1">Carlos Fernandez-Granda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12815">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks (CNNs) for image denoising are usually
trained on large datasets. These models achieve the current state of the art,
but they have difficulties generalizing when applied to data that deviate from
the training distribution. Recent work has shown that it is possible to train
denoisers on a single noisy image. These models adapt to the features of the
test image, but their performance is limited by the small amount of information
used to train them. Here we propose &quot;GainTuning&quot;, in which CNN models
pre-trained on large datasets are adaptively and selectively adjusted for
individual test images. To avoid overfitting, GainTuning optimizes a single
multiplicative scaling parameter (the &quot;Gain&quot;) of each channel in the
convolutional layers of the CNN. We show that GainTuning improves
state-of-the-art CNNs on standard image-denoising benchmarks, boosting their
denoising performance on nearly every image in a held-out test set. These
adaptive improvements are even more substantial for test images differing
systematically from the training data, either in noise level or image type. We
illustrate the potential of adaptive denoising in a scientific application, in
which a CNN is trained on synthetic data, and tested on real
transmission-electron-microscope images. In contrast to the existing
methodology, GainTuning is able to faithfully reconstruct the structure of
catalytic nanoparticles from these data at extremely low signal-to-noise
ratios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-Time Activity Recognition and Intention Recognition Using a Vision-based Embedded System. (arXiv:2107.12744v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Darafsh_S/0/1/0/all/0/1">Sahar Darafsh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghidary_S/0/1/0/all/0/1">Saeed Shiry Ghidary</a>, <a href="http://arxiv.org/find/cs/1/au:+Zamani_M/0/1/0/all/0/1">Morteza Saheb Zamani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12744">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid increase in digital technologies, most fields of study include
recognition of human activity and intention recognition, which are important in
smart environments. In this research, we introduce a real-time activity
recognition to recognize people&#x27;s intentions to pass or not pass a door. This
system, if applied in elevators and automatic doors will save energy and
increase efficiency. For this study, data preparation is applied to combine the
spatial and temporal features with the help of digital image processing
principles. Nevertheless, unlike previous studies, only one AlexNet neural
network is used instead of two-stream convolutional neural networks. Our
embedded system was implemented with an accuracy of 98.78% on our Intention
Recognition dataset. We also examined our data representation approach on other
datasets, including HMDB-51, KTH, and Weizmann, and obtained accuracy of
78.48%, 97.95%, and 100%, respectively. The image recognition and neural
network models were simulated and implemented using Xilinx simulators for
ZCU102 board. The operating frequency of this embedded system is 333 MHz, and
it works in real-time with 120 frames per second (fps).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Physiologically-adapted Gold Standard for Arousal During a Stress Induced Scenario. (arXiv:2107.12964v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baird_A/0/1/0/all/0/1">Alice Baird</a>, <a href="http://arxiv.org/find/cs/1/au:+Stappen_L/0/1/0/all/0/1">Lukas Stappen</a>, <a href="http://arxiv.org/find/cs/1/au:+Christ_L/0/1/0/all/0/1">Lukas Christ</a>, <a href="http://arxiv.org/find/cs/1/au:+Schumann_L/0/1/0/all/0/1">Lea Schumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Messner_E/0/1/0/all/0/1">Eva-Maria Me&#xdf;ner</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn W. Schuller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12964">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion is an inherently subjective psychophysiological human-state and to
produce an agreed-upon representation (gold standard) for continuous emotion
requires a time-consuming and costly training procedure of multiple human
annotators. There is strong evidence in the literature that physiological
signals are sufficient objective markers for states of emotion, particularly
arousal. In this contribution, we utilise a dataset which includes continuous
emotion and physiological signals - Heartbeats per Minute (BPM), Electrodermal
Activity (EDA), and Respiration-rate - captured during a stress induced
scenario (Trier Social Stress Test). We utilise a Long Short-Term Memory,
Recurrent Neural Network to explore the benefit of fusing these physiological
signals with arousal as the target, learning from various audio, video, and
textual based features. We utilise the state-of-the-art MuSe-Toolbox to
consider both annotation delay and inter-rater agreement weighting when fusing
the target signals. An improvement in Concordance Correlation Coefficient (CCC)
is seen across features sets when fusing EDA with arousal, compared to the
arousal only gold standard results. Additionally, BERT-based textual features&#x27;
results improved for arousal plus all physiological signals, obtaining up to
.3344 CCC compared to .2118 CCC for arousal only. Multimodal fusion also
improves overall CCC with audio plus video features obtaining up to .6157 CCC
to recognize arousal plus EDA and BPM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discriminative-Generative Representation Learning for One-Class Anomaly Detection. (arXiv:2107.12753v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xia_X/0/1/0/all/0/1">Xuan Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xizhou Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xing He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingfei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_N/0/1/0/all/0/1">Ning Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lin Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12753">
                                    <div class="article-summary-box-inner">
                                        <span>As a kind of generative self-supervised learning methods, generative
adversarial nets have been widely studied in the field of anomaly detection.
However, the representation learning ability of the generator is limited since
it pays too much attention to pixel-level details, and generator is difficult
to learn abstract semantic representations from label prediction pretext tasks
as effective as discriminator. In order to improve the representation learning
ability of generator, we propose a self-supervised learning framework combining
generative methods and discriminative methods. The generator no longer learns
representation by reconstruction error, but the guidance of discriminator, and
could benefit from pretext tasks designed for discriminative methods. Our
discriminative-generative representation learning method has performance close
to discriminative methods and has a great advantage in speed. Our method used
in one-class anomaly detection task significantly outperforms several
state-of-the-arts on multiple benchmark data sets, increases the performance of
the top-performing GAN-based baseline by 6% on CIFAR-10 and 2% on MVTAD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RGL-NET: A Recurrent Graph Learning framework for Progressive Part Assembly. (arXiv:2107.12859v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Harish_A/0/1/0/all/0/1">Abhinav Narayan Harish</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagar_R/0/1/0/all/0/1">Rajendra Nagar</a>, <a href="http://arxiv.org/find/cs/1/au:+Raman_S/0/1/0/all/0/1">Shanmuganathan Raman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12859">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous assembly of objects is an essential task in robotics and 3D
computer vision. It has been studied extensively in robotics as a problem of
motion planning, actuator control and obstacle avoidance. However, the task of
developing a generalized framework for assembly robust to structural variants
remains relatively unexplored. In this work, we tackle this problem using a
recurrent graph learning framework considering inter-part relations and the
progressive update of the part pose. Our network can learn more plausible
predictions of shape structure by accounting for priorly assembled parts.
Compared to the current state-of-the-art, our network yields up to 10%
improvement in part accuracy and up to 15% improvement in connectivity accuracy
on the PartNet dataset. Moreover, our resulting latent space facilitates
exciting applications such as shape recovery from the point-cloud components.
We conduct extensive experiments to justify our design choices and demonstrate
the effectiveness of the proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PiSLTRc: Position-informed Sign Language Transformer with Content-aware Convolution. (arXiv:2107.12600v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1">Pan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mengyi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiaohui Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12600">
                                    <div class="article-summary-box-inner">
                                        <span>Since the superiority of Transformer in learning long-term dependency, the
sign language Transformer model achieves remarkable progress in Sign Language
Recognition (SLR) and Translation (SLT). However, there are several issues with
the Transformer that prevent it from better sign language understanding. The
first issue is that the self-attention mechanism learns sign video
representation in a frame-wise manner, neglecting the temporal semantic
structure of sign gestures. Secondly, the attention mechanism with absolute
position encoding is direction and distance unaware, thus limiting its ability.
To address these issues, we propose a new model architecture, namely PiSLTRc,
with two distinctive characteristics: (i) content-aware and position-aware
convolution layers. Specifically, we explicitly select relevant features using
a novel content-aware neighborhood gathering method. Then we aggregate these
features with position-informed temporal convolution layers, thus generating
robust neighborhood-enhanced sign representation. (ii) injecting the relative
position information to the attention mechanism in the encoder, decoder, and
even encoder-decoder cross attention. Compared with the vanilla Transformer
model, our model performs consistently better on three large-scale sign
language benchmarks: PHOENIX-2014, PHOENIX-2014-T and CSL. Furthermore,
extensive experiments demonstrate that the proposed method achieves
state-of-the-art performance on translation quality with $+1.6$ BLEU
improvements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning-based Single Image Face Depth Data Enhancement. (arXiv:2006.11091v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schlett_T/0/1/0/all/0/1">Torsten Schlett</a>, <a href="http://arxiv.org/find/cs/1/au:+Rathgeb_C/0/1/0/all/0/1">Christian Rathgeb</a>, <a href="http://arxiv.org/find/cs/1/au:+Busch_C/0/1/0/all/0/1">Christoph Busch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.11091">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition can benefit from the utilization of depth data captured
using low-cost cameras, in particular for presentation attack detection
purposes. Depth video output from these capture devices can however contain
defects such as holes or general depth inaccuracies. This work proposes a deep
learning face depth enhancement method in this context of facial biometrics,
which adds a security aspect to the topic. U-Net-like architectures are
utilized, and the networks are compared against hand-crafted enhancer types, as
well as a similar depth enhancer network from related work trained for an
adjacent application scenario. All tested enhancer types exclusively use depth
data as input, which differs from methods that enhance depth based on
additional input data such as visible light color images. Synthetic face depth
ground truth images and degraded forms thereof are created with help of PRNet,
to train multiple deep learning enhancer models with different network sizes
and training configurations. Evaluations are carried out on the synthetic data,
on Kinect v1 images from the KinectFaceDB, and on in-house RealSense D435
images. These evaluations include an assessment of the falsification for
occluded face depth input, which is relevant to biometric security. The
proposed deep learning enhancers yield noticeably better results than the
tested preexisting enhancers, without overly falsifying depth data when
non-face input is provided, and are shown to reduce the error of a simple
landmark-based PAD method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">StarEnhancer: Learning Real-Time and Style-Aware Image Enhancement. (arXiv:2107.12898v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yuda Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1">Hui Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1">Xin Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12898">
                                    <div class="article-summary-box-inner">
                                        <span>Image enhancement is a subjective process whose targets vary with user
preferences. In this paper, we propose a deep learning-based image enhancement
method covering multiple tonal styles using only a single model dubbed
StarEnhancer. It can transform an image from one tonal style to another, even
if that style is unseen. With a simple one-time setting, users can customize
the model to make the enhanced images more in line with their aesthetics. To
make the method more practical, we propose a well-designed enhancer that can
process a 4K-resolution image over 200 FPS but surpasses the contemporaneous
single style image enhancement methods in terms of PSNR, SSIM, and LPIPS.
Finally, our proposed enhancement method has good interactability, which allows
the user to fine-tune the enhanced image using intuitive options.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Take-over Time for Autonomous Driving with Real-World Data: Robust Data Augmentation, Models, and Evaluation. (arXiv:2107.12932v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rangesh_A/0/1/0/all/0/1">Akshay Rangesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Deo_N/0/1/0/all/0/1">Nachiket Deo</a>, <a href="http://arxiv.org/find/cs/1/au:+Greer_R/0/1/0/all/0/1">Ross Greer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunaratne_P/0/1/0/all/0/1">Pujitha Gunaratne</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_M/0/1/0/all/0/1">Mohan M. Trivedi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12932">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding occupant-vehicle interactions by modeling control transitions
is important to ensure safe approaches to passenger vehicle automation. Models
which contain contextual, semantically meaningful representations of driver
states can be used to determine the appropriate timing and conditions for
transfer of control between driver and vehicle. However, such models rely on
real-world control take-over data from drivers engaged in distracting
activities, which is costly to collect. Here, we introduce a scheme for data
augmentation for such a dataset. Using the augmented dataset, we develop and
train take-over time (TOT) models that operate sequentially on mid and
high-level features produced by computer vision algorithms operating on
different driver-facing camera views, showing models trained on the augmented
dataset to outperform the initial dataset. The demonstrated model features
encode different aspects of the driver state, pertaining to the face, hands,
foot and upper body of the driver. We perform ablative experiments on feature
combinations as well as model architectures, showing that a TOT model supported
by augmented data can be used to produce continuous estimates of take-over
times without delay, suitable for complex real-world scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effects of Image Size on Deep Learning. (arXiv:2101.11508v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rukundo_O/0/1/0/all/0/1">Olivier Rukundo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11508">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the evaluation of effects of image size on deep learning
performance via semantic segmentation of magnetic resonance heart images with
U-net for fully automated quantification of myocardial infarction. Both
non-extra pixel and extra pixel interpolation algorithms are used to change the
size of images in datasets of interest. Extra class labels, in interpolated
ground truth segmentation images, are removed using thresholding, median
filtering, and subtraction strategies. Common class metrics are used to
evaluate the quality of semantic segmentation with U-net against the ground
truth segmentation while arbitrary threshold, comparison of the sums, and sums
of differences between medical experts and fully automated results are options
used to estimate the relationship between medical experts-based quantification
and fully automated quantification results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Local Recurrent Models for Human Mesh Recovery. (arXiv:2107.12847v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Runze Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Karanam_S/0/1/0/all/0/1">Srikrishna Karanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ren Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Terrence Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhanu_B/0/1/0/all/0/1">Bir Bhanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Ziyan Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12847">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of estimating frame-level full human body meshes
given a video of a person with natural motion dynamics. While much progress in
this field has been in single image-based mesh estimation, there has been a
recent uptick in efforts to infer mesh dynamics from video given its role in
alleviating issues such as depth ambiguity and occlusions. However, a key
limitation of existing work is the assumption that all the observed motion
dynamics can be modeled using one dynamical/recurrent model. While this may
work well in cases with relatively simplistic dynamics, inference with
in-the-wild videos presents many challenges. In particular, it is typically the
case that different body parts of a person undergo different dynamics in the
video, e.g., legs may move in a way that may be dynamically different from
hands (e.g., a person dancing). To address these issues, we present a new
method for video mesh recovery that divides the human mesh into several local
parts following the standard skeletal model. We then model the dynamics of each
local part with separate recurrent models, with each model conditioned
appropriately based on the known kinematic structure of the human body. This
results in a structure-informed local recurrent learning architecture that can
be trained in an end-to-end fashion with available annotations. We conduct a
variety of experiments on standard video mesh recovery benchmark datasets such
as Human3.6M, MPI-INF-3DHP, and 3DPW, demonstrating the efficacy of our design
of modeling local dynamics as well as establishing state-of-the-art results
based on standard evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reinforcement Learning for L3 Slice Localization in Sarcopenia Assessment. (arXiv:2107.12800v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laousy_O/0/1/0/all/0/1">Othmane Laousy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chassagnon_G/0/1/0/all/0/1">Guillaume Chassagnon</a>, <a href="http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1">Edouard Oyallon</a>, <a href="http://arxiv.org/find/cs/1/au:+Paragios_N/0/1/0/all/0/1">Nikos Paragios</a>, <a href="http://arxiv.org/find/cs/1/au:+Revel_M/0/1/0/all/0/1">Marie-Pierre Revel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakalopoulou_M/0/1/0/all/0/1">Maria Vakalopoulou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12800">
                                    <div class="article-summary-box-inner">
                                        <span>Sarcopenia is a medical condition characterized by a reduction in muscle mass
and function. A quantitative diagnosis technique consists of localizing the CT
slice passing through the middle of the third lumbar area (L3) and segmenting
muscles at this level. In this paper, we propose a deep reinforcement learning
method for accurate localization of the L3 CT slice. Our method trains a
reinforcement learning agent by incentivizing it to discover the right
position. Specifically, a Deep Q-Network is trained to find the best policy to
follow for this problem. Visualizing the training process shows that the agent
mimics the scrolling of an experienced radiologist. Extensive experiments
against other state-of-the-art deep learning based methods for L3 localization
prove the superiority of our technique which performs well even with limited
amount of data and annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic and Static Object Detection Considering Fusion Regions and Point-wise Features. (arXiv:2107.12692v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1">Andr&#xe9;s G&#xf3;mez</a>, <a href="http://arxiv.org/find/cs/1/au:+Genevois_T/0/1/0/all/0/1">Thomas Genevois</a>, <a href="http://arxiv.org/find/cs/1/au:+Lussereau_J/0/1/0/all/0/1">Jerome Lussereau</a>, <a href="http://arxiv.org/find/cs/1/au:+Laugier_C/0/1/0/all/0/1">Christian Laugier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12692">
                                    <div class="article-summary-box-inner">
                                        <span>Object detection is a critical problem for the safe interaction between
autonomous vehicles and road users. Deep-learning methodologies allowed the
development of object detection approaches with better performance. However,
there is still the challenge to obtain more characteristics from the objects
detected in real-time. The main reason is that more information from the
environment&#x27;s objects can improve the autonomous vehicle capacity to face
different urban situations. This paper proposes a new approach to detect static
and dynamic objects in front of an autonomous vehicle. Our approach can also
get other characteristics from the objects detected, like their position,
velocity, and heading. We develop our proposal fusing results of the
environment&#x27;s interpretations achieved of YoloV3 and a Bayesian filter. To
demonstrate our proposal&#x27;s performance, we asses it through a benchmark dataset
and real-world data obtained from an autonomous platform. We compared the
results achieved with another approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic sparse adversarial attacks. (arXiv:2011.12423v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cesaire_M/0/1/0/all/0/1">Manon C&#xe9;saire</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajri_H/0/1/0/all/0/1">Hatem Hajri</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamprier_S/0/1/0/all/0/1">Sylvain Lamprier</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12423">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces stochastic sparse adversarial attacks (SSAA), simple,
fast and purely noise-based targeted and untargeted $L_0$ attacks of neural
network classifiers (NNC). SSAA are devised by exploiting a simple small-time
expansion idea widely used for Markov processes and offer new examples of $L_0$
attacks whose studies have been limited. They are designed to solve the known
scalability issue of the family of Jacobian-based saliency maps attacks to
large datasets and they succeed in solving it. Experiments on small and large
datasets (CIFAR-10 and ImageNet) illustrate further advantages of SSAA in
comparison with the-state-of-the-art methods. For instance, in the untargeted
case, our method called Voting Folded Gaussian Attack (VFGA) scales efficiently
to ImageNet and achieves a significantly lower $L_0$ score than SparseFool (up
to $\frac{2}{5}$ lower) while being faster. Moreover, VFGA achieves better
$L_0$ scores on ImageNet than Sparse-RS when both attacks are fully successful
on a large number of samples. Codes are publicly available through the link
https://github.com/SSAA3/stochastic-sparse-adv-attacks</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extraction and Analysis of Fictional Character Networks: A Survey. (arXiv:1907.02704v4 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Labatut_V/0/1/0/all/0/1">Vincent Labatut</a> (LIA), <a href="http://arxiv.org/find/cs/1/au:+Bost_X/0/1/0/all/0/1">Xavier Bost</a> (LIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.02704">
                                    <div class="article-summary-box-inner">
                                        <span>A character network is a graph extracted from a narrative, in which vertices
represent characters and edges correspond to interactions between them. A
number of narrative-related problems can be addressed automatically through the
analysis of character networks, such as summarization, classification, or role
detection. Character networks are particularly relevant when considering works
of fictions (e.g. novels, plays, movies, TV series), as their exploitation
allows developing information retrieval and recommendation systems. However,
works of fiction possess specific properties making these tasks harder. This
survey aims at presenting and organizing the scientific literature related to
the extraction of character networks from works of fiction, as well as their
analysis. We first describe the extraction process in a generic way, and
explain how its constituting steps are implemented in practice, depending on
the medium of the narrative, the goal of the network analysis, and other
factors. We then review the descriptive tools used to characterize character
networks, with a focus on the way they are interpreted in this context. We
illustrate the relevance of character networks by also providing a review of
applications derived from their analysis. Finally, we identify the limitations
of the existing approaches, and the most promising perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Scale Local-Temporal Similarity Fusion for Continuous Sign Language Recognition. (arXiv:2107.12762v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1">Pan Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zhi Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yao Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mengyi Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jianwei Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Bin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiaohui Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12762">
                                    <div class="article-summary-box-inner">
                                        <span>Continuous sign language recognition (cSLR) is a public significant task that
transcribes a sign language video into an ordered gloss sequence. It is
important to capture the fine-grained gloss-level details, since there is no
explicit alignment between sign video frames and the corresponding glosses.
Among the past works, one promising way is to adopt a one-dimensional
convolutional network (1D-CNN) to temporally fuse the sequential frames.
However, CNNs are agnostic to similarity or dissimilarity, and thus are unable
to capture local consistent semantics within temporally neighboring frames. To
address the issue, we propose to adaptively fuse local features via temporal
similarity for this task. Specifically, we devise a Multi-scale Local-Temporal
Similarity Fusion Network (mLTSF-Net) as follows: 1) In terms of a specific
video frame, we firstly select its similar neighbours with multi-scale
receptive regions to accommodate different lengths of glosses. 2) To ensure
temporal consistency, we then use position-aware convolution to temporally
convolve each scale of selected frames. 3) To obtain a local-temporally
enhanced frame-wise representation, we finally fuse the results of different
scales using a content-dependent aggregator. We train our model in an
end-to-end fashion, and the experimental results on RWTH-PHOENIX-Weather 2014
datasets (RWTH) demonstrate that our model achieves competitive performance
compared with several state-of-the-art models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PointBA: Towards Backdoor Attacks in 3D Point Cloud. (arXiv:2103.16074v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhirui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yue Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_Z/0/1/0/all/0/1">Zekun Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yabang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_A/0/1/0/all/0/1">Andrew Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Joey Tianyi Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16074">
                                    <div class="article-summary-box-inner">
                                        <span>3D deep learning has been increasingly more popular for a variety of tasks
including many safety-critical applications. However, recently several works
raise the security issues of 3D deep nets. Although most of these works
consider adversarial attacks, we identify that backdoor attack is indeed a more
serious threat to 3D deep learning systems but remains unexplored. We present
the backdoor attacks in 3D with a unified framework that exploits the unique
properties of 3D data and networks. In particular, we design two attack
approaches: the poison-label attack and the clean-label attack. The first one
is straightforward and effective in practice, while the second one is more
sophisticated assuming there are certain data inspections. The attack
algorithms are mainly motivated and developed by 1) the recent discovery of 3D
adversarial samples which demonstrate the vulnerability of 3D deep nets under
spatial transformations; 2) the proposed feature disentanglement technique that
manipulates the feature of the data through optimization methods and its
potential to embed a new task. Extensive experiments show the efficacy of the
poison-label attack with over 95% success rate across several 3D datasets and
models, and the ability of clean-label attack against data filtering with
around 50% success rate. Our proposed backdoor attack in 3D point cloud is
expected to perform as a baseline for improving the robustness of 3D deep
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Sample Selection for Robust Learning under Label Noise. (arXiv:2106.15292v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Deep Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sastry_P/0/1/0/all/0/1">P.S. Sastry</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15292">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Networks (DNNs) have been shown to be susceptible to memorization
or overfitting in the presence of noisily labelled data. For the problem of
robust learning under such noisy data, several algorithms have been proposed. A
prominent class of algorithms rely on sample selection strategies, motivated by
curriculum learning. For example, many algorithms use the &#x60;small loss trick&#x27;
wherein a fraction of samples with loss values below a certain threshold are
selected for training. These algorithms are sensitive to such thresholds, and
it is difficult to fix or learn these thresholds. Often, these algorithms also
require information such as label noise rates which are typically unavailable
in practice. In this paper, we propose a data-dependent, adaptive sample
selection strategy that relies only on batch statistics of a given mini-batch
to provide robustness against label noise. The algorithm does not have any
additional hyperparameters for sample selection, does not need any information
on noise rates, and does not need access to separate data with clean labels. We
empirically demonstrate the effectiveness of our algorithm on benchmark
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Co-Transport for Class-Incremental Learning. (arXiv:2107.12654v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Da-Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12654">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional learning systems are trained in closed-world for a fixed number
of classes, and need pre-collected datasets in advance. However, new classes
often emerge in real-world applications and should be learned incrementally.
For example, in electronic commerce, new types of products appear daily, and in
a social media community, new topics emerge frequently. Under such
circumstances, incremental models should learn several new classes at a time
without forgetting. We find a strong correlation between old and new classes in
incremental learning, which can be applied to relate and facilitate different
learning stages mutually. As a result, we propose CO-transport for class
Incremental Learning (COIL), which learns to relate across incremental tasks
with the class-wise semantic relationship. In detail, co-transport has two
aspects: prospective transport tries to augment the old classifier with optimal
transported knowledge as fast model adaptation. Retrospective transport aims to
transport new class classifiers backward as old ones to overcome forgetting.
With these transports, COIL efficiently adapts to new tasks, and stably resists
forgetting. Experiments on benchmark and real-world multimedia datasets
validate the effectiveness of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LETI: Latency Estimation Tool and Investigation of Neural Networks inference on Mobile GPU. (arXiv:2010.02871v2 [cs.PF] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ponomarev_E/0/1/0/all/0/1">Evgeny Ponomarev</a>, <a href="http://arxiv.org/find/cs/1/au:+Matveev_S/0/1/0/all/0/1">Sergey Matveev</a>, <a href="http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1">Ivan Oseledets</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02871">
                                    <div class="article-summary-box-inner">
                                        <span>A lot of deep learning applications are desired to be run on mobile devices.
Both accuracy and inference time are meaningful for a lot of them. While the
number of FLOPs is usually used as a proxy for neural network latency, it may
be not the best choice. In order to obtain a better approximation of latency,
research community uses look-up tables of all possible layers for latency
calculation for the final prediction of the inference on mobile CPU. It
requires only a small number of experiments. Unfortunately, on mobile GPU this
method is not applicable in a straight-forward way and shows low precision. In
this work, we consider latency approximation on mobile GPU as a data and
hardware-specific problem. Our main goal is to construct a convenient latency
estimation tool for investigation(LETI) of neural network inference and
building robust and accurate latency prediction models for each specific task.
To achieve this goal, we build open-source tools which provide a convenient way
to conduct massive experiments on different target devices focusing on mobile
GPU. After evaluation of the dataset, we learn the regression model on
experimental data and use it for future latency prediction and analysis. We
experimentally demonstrate the applicability of such an approach on a subset of
popular NAS-Benchmark 101 dataset and also evaluate the most popular neural
network architectures for two mobile GPUs. As a result, we construct latency
prediction model with good precision on the target evaluation subset. We
consider LETI as a useful tool for neural architecture search or massive
latency evaluation. The project is available at https://github.com/leti-ai</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analyzing vehicle pedestrian interactions combining data cube structure and predictive collision risk estimation model. (arXiv:2107.12507v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Noh_B/0/1/0/all/0/1">Byeongjoon Noh</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hansaem Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_H/0/1/0/all/0/1">Hwasoo Yeo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12507">
                                    <div class="article-summary-box-inner">
                                        <span>Traffic accidents are a threat to human lives, particularly pedestrians
causing premature deaths. Therefore, it is necessary to devise systems to
prevent accidents in advance and respond proactively, using potential risky
situations as one of the surrogate safety measurements. This study introduces a
new concept of a pedestrian safety system that combines the field and the
centralized processes. The system can warn of upcoming risks immediately in the
field and improve the safety of risk frequent areas by assessing the safety
levels of roads without actual collisions. In particular, this study focuses on
the latter by introducing a new analytical framework for a crosswalk safety
assessment with behaviors of vehicle/pedestrian and environmental features. We
obtain these behavioral features from actual traffic video footage in the city
with complete automatic processing. The proposed framework mainly analyzes
these behaviors in multidimensional perspectives by constructing a data cube
structure, which combines the LSTM based predictive collision risk estimation
model and the on line analytical processing operations. From the PCR estimation
model, we categorize the severity of risks as four levels and apply the
proposed framework to assess the crosswalk safety with behavioral features. Our
analytic experiments are based on two scenarios, and the various descriptive
results are harvested the movement patterns of vehicles and pedestrians by road
environment and the relationships between risk levels and car speeds. Thus, the
proposed framework can support decision makers by providing valuable
information to improve pedestrian safety for future accidents, and it can help
us better understand their behaviors near crosswalks proactively. In order to
confirm the feasibility and applicability of the proposed framework, we
implement and apply it to actual operating CCTVs in Osan City, Korea.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Super-Human Performance in Online Low-latency Recognition of Conversational Speech. (arXiv:2010.03449v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thai-Son Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Stueker_S/0/1/0/all/0/1">Sebastian Stueker</a>, <a href="http://arxiv.org/find/cs/1/au:+Waibel_A/0/1/0/all/0/1">Alex Waibel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03449">
                                    <div class="article-summary-box-inner">
                                        <span>Achieving super-human performance in recognizing human speech has been a goal
for several decades, as researchers have worked on increasingly challenging
tasks. In the 1990&#x27;s it was discovered, that conversational speech between two
humans turns out to be considerably more difficult than read speech as
hesitations, disfluencies, false starts and sloppy articulation complicate
acoustic processing and require robust handling of acoustic, lexical and
language context, jointly. Early attempts with statistical models could only
reach error rates over 50% and far from human performance (WER of around 5.5%).
Neural hybrid models and recent attention-based encoder-decoder models have
considerably improved performance as such contexts can now be learned in an
integral fashion. However, processing such contexts requires an entire
utterance presentation and thus introduces unwanted delays before a recognition
result can be output. In this paper, we address performance as well as latency.
We present results for a system that can achieve super-human performance (at a
WER of 5.0%, over the Switchboard conversational benchmark) at a word based
latency of only 1 second behind a speaker&#x27;s speech. The system uses multiple
attention-based encoder-decoder networks integrated within a novel low latency
incremental inference approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RGB cameras failures and their effects in autonomous driving applications. (arXiv:2008.05938v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Secci_F/0/1/0/all/0/1">Francesco Secci</a>, <a href="http://arxiv.org/find/cs/1/au:+Ceccarelli_A/0/1/0/all/0/1">Andrea Ceccarelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.05938">
                                    <div class="article-summary-box-inner">
                                        <span>RGB cameras are one of the most relevant sensors for autonomous driving
applications. It is undeniable that failures of vehicle cameras may compromise
the autonomous driving task, possibly leading to unsafe behaviors when images
that are subsequently processed by the driving system are altered. To support
the definition of safe and robust vehicle architectures and intelligent
systems, in this paper we define the failure modes of a vehicle camera,
together with an analysis of effects and known mitigations. Further, we build a
software library for the generation of the corresponding failed images and we
feed them to six object detectors for mono and stereo cameras and to the
self-driving agent of an autonomous driving simulator. The resulting
misbehaviors with respect to operating with clean images allow a better
understanding of failures effects and the related safety risks in image-based
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Frozen-to-Paraffin: Categorization of Histological Frozen Sections by the Aid of Paraffin Sections and Generative Adversarial Networks. (arXiv:2012.08158v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gadermayr_M/0/1/0/all/0/1">Michael Gadermayr</a>, <a href="http://arxiv.org/find/eess/1/au:+Tschuchnig_M/0/1/0/all/0/1">Maximilian Tschuchnig</a>, <a href="http://arxiv.org/find/eess/1/au:+Stangassinger_L/0/1/0/all/0/1">Lea Maria Stangassinger</a>, <a href="http://arxiv.org/find/eess/1/au:+Kreutzer_C/0/1/0/all/0/1">Christina Kreutzer</a>, <a href="http://arxiv.org/find/eess/1/au:+Couillard_Despres_S/0/1/0/all/0/1">Sebastien Couillard-Despres</a>, <a href="http://arxiv.org/find/eess/1/au:+Oostingh_G/0/1/0/all/0/1">Gertie Janneke Oostingh</a>, <a href="http://arxiv.org/find/eess/1/au:+Hittmair_A/0/1/0/all/0/1">Anton Hittmair</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08158">
                                    <div class="article-summary-box-inner">
                                        <span>In contrast to paraffin sections, frozen sections can be quickly generated
during surgical interventions. This procedure allows surgeons to wait for
histological findings during the intervention to base intra-operative decisions
on the outcome of the histology. However, compared to paraffin sections, the
quality of frozen sections is typically lower, leading to a higher ratio of
miss-classification. In this work, we investigated the effect of the section
type on automated decision support approaches for classification of thyroid
cancer. This was enabled by a data set consisting of pairs of sections for
individual patients. Moreover, we investigated, whether a frozen-to-paraffin
translation could help to optimize classification scores. Finally, we propose a
specific data augmentation strategy to deal with a small amount of training
data and to increase classification accuracy even further.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Learning with Neuron Activation Importance. (arXiv:2107.12657v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sohee Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seungkyu Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12657">
                                    <div class="article-summary-box-inner">
                                        <span>Continual learning is a concept of online learning with multiple sequential
tasks. One of the critical barriers of continual learning is that a network
should learn a new task keeping the knowledge of old tasks without access to
any data of the old tasks. In this paper, we propose a neuron activation
importance-based regularization method for stable continual learning regardless
of the order of tasks. We conduct comprehensive experiments on existing
benchmark data sets to evaluate not just the stability and plasticity of our
method with improved classification accuracy also the robustness of the
performance along the changes of task order.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real-time Keypoints Detection for Autonomous Recovery of the Unmanned Ground Vehicle. (arXiv:2107.12852v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Sheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1">Xia Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chunxia Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12852">
                                    <div class="article-summary-box-inner">
                                        <span>The combination of a small unmanned ground vehicle (UGV) and a large unmanned
carrier vehicle allows more flexibility in real applications such as rescue in
dangerous scenarios. The autonomous recovery system, which is used to guide the
small UGV back to the carrier vehicle, is an essential component to achieve a
seamless combination of the two vehicles. This paper proposes a novel
autonomous recovery framework with a low-cost monocular vision system to
provide accurate positioning and attitude estimation of the UGV during
navigation. First, we introduce a light-weight convolutional neural network
called UGV-KPNet to detect the keypoints of the small UGV from the images
captured by a monocular camera. UGV-KPNet is computationally efficient with a
small number of parameters and provides pixel-level accurate keypoints
detection results in real-time. Then, six degrees of freedom pose is estimated
using the detected keypoints to obtain positioning and attitude information of
the UGV. Besides, we are the first to create a large-scale real-world keypoints
dataset of the UGV. The experimental results demonstrate that the proposed
system achieves state-of-the-art performance in terms of both accuracy and
speed on UGV keypoint detection, and can further boost the 6-DoF pose
estimation for the UGV.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scale-Localized Abstract Reasoning. (arXiv:2009.09405v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Benny_Y/0/1/0/all/0/1">Yaniv Benny</a>, <a href="http://arxiv.org/find/cs/1/au:+Pekar_N/0/1/0/all/0/1">Niv Pekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1">Lior Wolf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.09405">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the abstract relational reasoning task, which is commonly used as
an intelligence test. Since some patterns have spatial rationales, while others
are only semantic, we propose a multi-scale architecture that processes each
query in multiple resolutions. We show that indeed different rules are solved
by different resolutions and a combined multi-scale approach outperforms the
existing state of the art in this task on all benchmarks by 5-54%. The success
of our method is shown to arise from multiple novelties. First, it searches for
relational patterns in multiple resolutions, which allows it to readily detect
visual relations, such as location, in higher resolution, while allowing the
lower resolution module to focus on semantic relations, such as shape type.
Second, we optimize the reasoning network of each resolution proportionally to
its performance, hereby we motivate each resolution to specialize on the rules
for which it performs better than the others and ignore cases that are already
solved by the other resolutions. Third, we propose a new way to pool
information along the rows and the columns of the illustration-grid of the
query. Our work also analyses the existing benchmarks, demonstrating that the
RAVEN dataset selects the negative examples in a way that is easily exploited.
We, therefore, propose a modified version of the RAVEN dataset, named
RAVEN-FAIR. Our code and pretrained models are available at
https://github.com/yanivbenny/MRNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DV-ConvNet: Fully Convolutional Deep Learning on Point Clouds with Dynamic Voxelization and 3D Group Convolution. (arXiv:2009.02918v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1">Zhaoyu Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_P/0/1/0/all/0/1">Pin Siang Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chow_J/0/1/0/all/0/1">Junkang Chow</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jimmy Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheong_Y/0/1/0/all/0/1">Yehur Cheong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu-Hsing Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.02918">
                                    <div class="article-summary-box-inner">
                                        <span>3D point cloud interpretation is a challenging task due to the randomness and
sparsity of the component points. Many of the recently proposed methods like
PointNet and PointCNN have been focusing on learning shape descriptions from
point coordinates as point-wise input features, which usually involves
complicated network architectures. In this work, we draw attention back to the
standard 3D convolutions towards an efficient 3D point cloud interpretation.
Instead of converting the entire point cloud into voxel representations like
the other volumetric methods, we voxelize the sub-portions of the point cloud
only at necessary locations within each convolution layer on-the-fly, using our
dynamic voxelization operation with self-adaptive voxelization resolution. In
addition, we incorporate 3D group convolution into our dense convolution kernel
implementation to further exploit the rotation invariant features of point
cloud. Benefiting from its simple fully-convolutional architecture, our network
is able to run and converge at a considerably fast speed, while yields on-par
or even better performance compared with the state-of-the-art methods on
several benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating Parkinsonism Severity in Natural Gait Videos of Older Adults with Dementia. (arXiv:2105.03464v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sabo_A/0/1/0/all/0/1">Andrea Sabo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdizadeh_S/0/1/0/all/0/1">Sina Mehdizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Iaboni_A/0/1/0/all/0/1">Andrea Iaboni</a>, <a href="http://arxiv.org/find/cs/1/au:+Taati_B/0/1/0/all/0/1">Babak Taati</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03464">
                                    <div class="article-summary-box-inner">
                                        <span>Drug-induced parkinsonism affects many older adults with dementia, often
causing gait disturbances. New advances in vision-based human pose-estimation
have opened possibilities for frequent and unobtrusive analysis of gait in
residential settings. This work proposes novel spatial-temporal graph
convolutional network (ST-GCN) architectures and training procedures to predict
clinical scores of parkinsonism in gait from video of individuals with
dementia. We propose a two-stage training approach consisting of a
self-supervised pretraining stage that encourages the ST-GCN model to learn
about gait patterns before predicting clinical scores in the finetuning stage.
The proposed ST-GCN models are evaluated on joint trajectories extracted from
video and are compared against traditional (ordinal, linear, random forest)
regression models and temporal convolutional network baselines. Three 2D human
pose-estimation libraries (OpenPose, Detectron, AlphaPose) and the Microsoft
Kinect (2D and 3D) are used to extract joint trajectories of 4787 natural
walking bouts from 53 older adults with dementia. A subset of 399 walks from 14
participants is annotated with scores of parkinsonism severity on the gait
criteria of the Unified Parkinson&#x27;s Disease Rating Scale (UPDRS) and the
Simpson-Angus Scale (SAS). Our results demonstrate that ST-GCN models operating
on 3D joint trajectories extracted from the Kinect consistently outperform all
other models and feature sets. Prediction of parkinsonism scores in natural
walking bouts of unseen participants remains a challenging task, with the best
models achieving macro-averaged F1-scores of 0.53 +/- 0.03 and 0.40 +/- 0.02
for UPDRS-gait and SAS-gait, respectively. Pre-trained model and demo code for
this work is available:
https://github.com/TaatiTeam/stgcn_parkinsonism_prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Francis_J/0/1/0/all/0/1">Jonathan Francis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitamura_N/0/1/0/all/0/1">Nariaki Kitamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Labelle_F/0/1/0/all/0/1">Felix Labelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaopeng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Navarro_I/0/1/0/all/0/1">Ingrid Navarro</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1">Jean Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13948">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in the areas of multimodal machine learning and artificial
intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Embodied AI.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly use computer vision and natural language. We propose a
taxonomy to unify these tasks and provide an in-depth analysis and comparison
of the new and current algorithmic approaches, metrics, simulated environments,
as well as the datasets used for EVLP tasks. Finally, we present the core
challenges that we believe new EVLP works should seek to address, and we
advocate for task construction that enables model generalizability and furthers
real-world deployment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantically Self-Aligned Network for Text-to-Image Part-aware Person Re-identification. (arXiv:2107.12666v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1">Zefeng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Changxing Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhiyin Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12666">
                                    <div class="article-summary-box-inner">
                                        <span>Text-to-image person re-identification (ReID) aims to search for images
containing a person of interest using textual descriptions. However, due to the
significant modality gap and the large intra-class variance in textual
descriptions, text-to-image ReID remains a challenging problem. Accordingly, in
this paper, we propose a Semantically Self-Aligned Network (SSAN) to handle the
above problems. First, we propose a novel method that automatically extracts
semantically aligned part-level features from the two modalities. Second, we
design a multi-view non-local network that captures the relationships between
body parts, thereby establishing better correspondences between body parts and
noun phrases. Third, we introduce a Compound Ranking (CR) loss that makes use
of textual descriptions for other images of the same identity to provide extra
supervision, thereby effectively reducing the intra-class variance in textual
features. Finally, to expedite future research in text-to-image ReID, we build
a new database named ICFG-PEDES. Extensive experiments demonstrate that SSAN
outperforms state-of-the-art approaches by significant margins. Both the new
ICFG-PEDES database and the SSAN code are available at
https://github.com/zifyloo/SSAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Boundary Proposal Network for Arbitrary Shape Text Detection. (arXiv:2107.12664v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shi-Xue Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaobin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongfa Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_X/0/1/0/all/0/1">Xu-Cheng Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12664">
                                    <div class="article-summary-box-inner">
                                        <span>Arbitrary shape text detection is a challenging task due to the high
complexity and variety of scene texts. In this work, we propose a novel
adaptive boundary proposal network for arbitrary shape text detection, which
can learn to directly produce accurate boundary for arbitrary shape text
without any post-processing. Our method mainly consists of a boundary proposal
model and an innovative adaptive boundary deformation model. The boundary
proposal model constructed by multi-layer dilated convolutions is adopted to
produce prior information (including classification map, distance field, and
direction field) and coarse boundary proposals. The adaptive boundary
deformation model is an encoder-decoder network, in which the encoder mainly
consists of a Graph Convolutional Network (GCN) and a Recurrent Neural Network
(RNN). It aims to perform boundary deformation in an iterative way for
obtaining text instance shape guided by prior information from the boundary
proposal model.In this way, our method can directly and efficiently generate
accurate text boundaries without complex post-processing. Extensive experiments
on publicly available datasets demonstrate the state-of-the-art performance of
our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Counting and Localization in Crowds:A Purely Point-Based Framework. (arXiv:2107.12746v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qingyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhengkai Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12746">
                                    <div class="article-summary-box-inner">
                                        <span>Localizing individuals in crowds is more in accordance with the practical
demands of subsequent high-level crowd analysis tasks than simply counting.
However, existing localization based methods relying on intermediate
representations (\textit{i.e.}, density maps or pseudo boxes) serving as
learning targets are counter-intuitive and error-prone. In this paper, we
propose a purely point-based framework for joint crowd counting and individual
localization. For this framework, instead of merely reporting the absolute
counting error at image level, we propose a new metric, called density
Normalized Average Precision (nAP), to provide more comprehensive and more
precise performance evaluation. Moreover, we design an intuitive solution under
this framework, which is called Point to Point Network (P2PNet). P2PNet
discards superfluous steps and directly predicts a set of point proposals to
represent heads in an image, being consistent with the human annotation
results. By thorough analysis, we reveal the key step towards implementing such
a novel idea is to assign optimal learning targets for these proposals.
Therefore, we propose to conduct this crucial association in an one-to-one
matching manner using the Hungarian algorithm. The P2PNet not only
significantly surpasses state-of-the-art methods on popular counting
benchmarks, but also achieves promising localization accuracy. The codes will
be available at: https://github.com/TencentYoutuResearch/CrowdCounting-P2PNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identify Apple Leaf Diseases Using Deep Learning Algorithm. (arXiv:2107.12598v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Daping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jiayu Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12598">
                                    <div class="article-summary-box-inner">
                                        <span>Agriculture is an essential industry in the both society and economy of a
country. However, the pests and diseases cause a great amount of reduction in
agricultural production while there is not sufficient guidance for farmers to
avoid this disaster. To address this problem, we apply CNNs to plant disease
recognition by building a classification model. Within the dataset of 3,642
images of apple leaves, We use a pre-trained image classification model
Restnet34 based on a Convolutional neural network (CNN) with the Fastai
framework in order to save the training time. Overall, the accuracy of
classification is 93.765%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows. (arXiv:2107.12571v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gudovskiy_D/0/1/0/all/0/1">Denis Gudovskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishizaka_S/0/1/0/all/0/1">Shun Ishizaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozuka_K/0/1/0/all/0/1">Kazuki Kozuka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12571">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised anomaly detection with localization has many practical
applications when labeling is infeasible and, moreover, when anomaly examples
are completely missing in the train data. While recently proposed models for
such data setup achieve high accuracy metrics, their complexity is a limiting
factor for real-time processing. In this paper, we propose a real-time model
and analytically derive its relationship to prior methods. Our CFLOW-AD model
is based on a conditional normalizing flow framework adopted for anomaly
detection with localization. In particular, CFLOW-AD consists of a
discriminatively pretrained encoder followed by a multi-scale generative
decoders where the latter explicitly estimate likelihood of the encoded
features. Our approach results in a computationally and memory-efficient model:
CFLOW-AD is faster and smaller by a factor of 10x than prior state-of-the-art
with the same input setting. Our experiments on the MVTec dataset show that
CFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by
1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source
our code with fully reproducible experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enriching Local and Global Contexts for Temporal Action Localization. (arXiv:2107.12960v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zixin Zhu</a> (Xi&#x27;an jiaotong University), <a href="http://arxiv.org/find/cs/1/au:+Tang_W/0/1/0/all/0/1">Wei Tang</a> (University of Illinois at Chicago), <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Le Wang</a> (Xi&#x27;an Jiaotong University), <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a> (Xi&#x27;an Jiaotong University), <a href="http://arxiv.org/find/cs/1/au:+Hua_G/0/1/0/all/0/1">Gang Hua</a> (Wormpex AI Research)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12960">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively tackling the problem of temporal action localization (TAL)
necessitates a visual representation that jointly pursues two confounding
goals, i.e., fine-grained discrimination for temporal localization and
sufficient visual invariance for action classification. We address this
challenge by enriching both the local and global contexts in the popular
two-stage temporal localization framework, where action proposals are first
generated followed by action classification and temporal boundary regression.
Our proposed model, dubbed ContextLoc, can be divided into three sub-networks:
L-Net, G-Net and P-Net. L-Net enriches the local context via fine-grained
modeling of snippet-level features, which is formulated as a
query-and-retrieval process. G-Net enriches the global context via higher-level
modeling of the video-level representation. In addition, we introduce a novel
context adaptation module to adapt the global context to different proposals.
P-Net further models the context-aware inter-proposal relations. We explore two
existing models to be the P-Net in our experiments. The efficacy of our
proposed method is validated by experimental results on the THUMOS14 (54.3\% at
IoU@0.5) and ActivityNet v1.3 (51.24\% at IoU@0.5) datasets, which outperforms
recent states of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Technical Report: Quality Assessment Tool for Machine Learning with Clinical CT. (arXiv:2107.12842v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1">Riqiang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mirza S. Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yucheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kaiwen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Deppen_S/0/1/0/all/0/1">Steve Deppen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1">Yuankai Huo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandler_K/0/1/0/all/0/1">Kim L. Sandler</a>, <a href="http://arxiv.org/find/cs/1/au:+Massion_P/0/1/0/all/0/1">Pierre P. Massion</a>, <a href="http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1">Bennett A. Landman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12842">
                                    <div class="article-summary-box-inner">
                                        <span>Image Quality Assessment (IQA) is important for scientific inquiry,
especially in medical imaging and machine learning. Potential data quality
issues can be exacerbated when human-based workflows use limited views of the
data that may obscure digital artifacts. In practice, multiple factors such as
network issues, accelerated acquisitions, motion artifacts, and imaging
protocol design can impede the interpretation of image collections. The medical
image processing community has developed a wide variety of tools for the
inspection and validation of imaging data. Yet, IQA of computed tomography (CT)
remains an under-recognized challenge, and no user-friendly tool is commonly
available to address these potential issues. Here, we create and illustrate a
pipeline specifically designed to identify and resolve issues encountered with
large-scale data mining of clinically acquired CT data. Using the widely
studied National Lung Screening Trial (NLST), we have identified approximately
4% of image volumes with quality concerns out of 17,392 scans. To assess
robustness, we applied the proposed pipeline to our internal datasets where we
find our tool is generalizable to clinically acquired medical images. In
conclusion, the tool has been useful and time-saving for research study of
clinical data, and the code and tutorials are publicly available at
https://github.com/MASILab/QA_tool.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CKConv: Learning Feature Voxelization for Point Cloud Analysis. (arXiv:2107.12655v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Sungmin Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Dogyoon Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Junhyeop Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sangwon Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1">Woojin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sangyoun Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12655">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the remarkable success of deep learning, optimal convolution
operation on point cloud remains indefinite due to its irregular data
structure. In this paper, we present Cubic Kernel Convolution (CKConv) that
learns to voxelize the features of local points by exploiting both continuous
and discrete convolutions. Our continuous convolution uniquely employs a 3D
cubic form of kernel weight representation that splits a feature into voxels in
embedding space. By consecutively applying discrete 3D convolutions on the
voxelized features in a spatial manner, preceding continuous convolution is
forced to learn spatial feature mapping, i.e., feature voxelization. In this
way, geometric information can be detailed by encoding with subdivided
features, and our 3D convolutions on these fixed structured data do not suffer
from discretization artifacts thanks to voxelization in embedding space.
Furthermore, we propose a spatial attention module, Local Set Attention (LSA),
to provide comprehensive structure awareness within the local point set and
hence produce representative features. By learning feature voxelization with
LSA, CKConv can extract enriched features for effective point cloud analysis.
We show that CKConv has great applicability to point cloud processing tasks
including object classification, object part segmentation, and scene semantic
segmentation with state-of-the-art results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal estimation of the properties of containers and their content: survey and evaluation. (arXiv:2107.12719v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xompero_A/0/1/0/all/0/1">Alessio Xompero</a>, <a href="http://arxiv.org/find/cs/1/au:+Donaher_S/0/1/0/all/0/1">Santiago Donaher</a>, <a href="http://arxiv.org/find/cs/1/au:+Iashin_V/0/1/0/all/0/1">Vladimir Iashin</a>, <a href="http://arxiv.org/find/cs/1/au:+Palermo_F/0/1/0/all/0/1">Francesca Palermo</a>, <a href="http://arxiv.org/find/cs/1/au:+Solak_G/0/1/0/all/0/1">G&#xf6;khan Solak</a>, <a href="http://arxiv.org/find/cs/1/au:+Coppola_C/0/1/0/all/0/1">Claudio Coppola</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_R/0/1/0/all/0/1">Reina Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagao_Y/0/1/0/all/0/1">Yuichi Nagao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hachiuma_R/0/1/0/all/0/1">Ryo Hachiuma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1">Chuanlin Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_R/0/1/0/all/0/1">Rosa H. M. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Christmann_G/0/1/0/all/0/1">Guilherme Christmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jyun-Ting Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Neeharika_G/0/1/0/all/0/1">Gonuguntla Neeharika</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1">Chinnakotla Krishna Teja Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1">Dinesh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehman_B/0/1/0/all/0/1">Bakhtawar Ur Rehman</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallaro_A/0/1/0/all/0/1">Andrea Cavallaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12719">
                                    <div class="article-summary-box-inner">
                                        <span>Acoustic and visual sensing can support the contactless estimation of the
weight of a container and the amount of its content when the container is
manipulated by a person. However, transparencies (both of the container and of
the content) and the variability of materials, shapes and sizes make this
problem challenging. In this paper, we present an open benchmarking framework
and an in-depth comparative analysis of recent methods that estimate the
capacity of a container, as well as the type, mass, and amount of its content.
These methods use learned and handcrafted features, such as mel-frequency
cepstrum coefficients, zero-crossing rate, spectrograms, with different types
of classifiers to estimate the type and amount of the content with acoustic
data, and geometric approaches with visual data to determine the capacity of
the container. Results on a newly distributed dataset show that audio alone is
a strong modality and methods achieves a weighted average F1-score up to 81%
and 97% for content type and level classification, respectively. Estimating the
container capacity with vision-only approaches and filling mass with
multi-modal, multi-stage algorithms reaches up to 65% weighted average capacity
and mass scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Remember What You have drawn: Semantic Image Manipulation with Memory. (arXiv:2107.12579v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xiangxi Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhonghua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guosheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1">Shafiq Joty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12579">
                                    <div class="article-summary-box-inner">
                                        <span>Image manipulation with natural language, which aims to manipulate images
with the guidance of language descriptions, has been a challenging problem in
the fields of computer vision and natural language processing (NLP). Currently,
a number of efforts have been made for this task, but their performances are
still distant away from generating realistic and text-conformed manipulated
images. Therefore, in this paper, we propose a memory-based Image Manipulation
Network (MIM-Net), where a set of memories learned from images is introduced to
synthesize the texture information with the guidance of the textual
description. We propose a two-stage network with an additional reconstruction
stage to learn the latent memories efficiently. To avoid the unnecessary
background changes, we propose a Target Localization Unit (TLU) to focus on the
manipulation of the region mentioned by the text. Moreover, to learn a robust
memory, we further propose a novel randomized memory training loss. Experiments
on the four popular datasets show the better performance of our method compared
to the existing ones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-Based Open-World Uncertainty Modeling for Confidence Calibration. (arXiv:2107.12628v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yezhen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_T/0/1/0/all/0/1">Tong Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaiyang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12628">
                                    <div class="article-summary-box-inner">
                                        <span>Confidence calibration is of great importance to the reliability of decisions
made by machine learning systems. However, discriminative classifiers based on
deep neural networks are often criticized for producing overconfident
predictions that fail to reflect the true correctness likelihood of
classification accuracy. We argue that such an inability to model uncertainty
is mainly caused by the closed-world nature in softmax: a model trained by the
cross-entropy loss will be forced to classify input into one of $K$ pre-defined
categories with high probability. To address this problem, we for the first
time propose a novel $K$+1-way softmax formulation, which incorporates the
modeling of open-world uncertainty as the extra dimension. To unify the
learning of the original $K$-way classification task and the extra dimension
that models uncertainty, we propose a novel energy-based objective function,
and moreover, theoretically prove that optimizing such an objective essentially
forces the extra dimension to capture the marginal data distribution. Extensive
experiments show that our approach, Energy-based Open-World Softmax
(EOW-Softmax), is superior to existing state-of-the-art methods in improving
confidence calibration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Outlier Detection using Memory and Contrastive Learning. (arXiv:2107.12642v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huyan_N/0/1/0/all/0/1">Ning Huyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_D/0/1/0/all/0/1">Dou Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiangrong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xuefeng Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1">Jocelyn Chanussot</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Licheng Jiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12642">
                                    <div class="article-summary-box-inner">
                                        <span>Outlier detection is one of the most important processes taken to create
good, reliable data in machine learning. The most methods of outlier detection
leverage an auxiliary reconstruction task by assuming that outliers are more
difficult to be recovered than normal samples (inliers). However, it is not
always true, especially for auto-encoder (AE) based models. They may recover
certain outliers even outliers are not in the training data, because they do
not constrain the feature learning. Instead, we think outlier detection can be
done in the feature space by measuring the feature distance between outliers
and inliers. We then propose a framework, MCOD, using a memory module and a
contrastive learning module. The memory module constrains the consistency of
features, which represent the normal data. The contrastive learning module
learns more discriminating features, which boosts the distinction between
outliers and inliers. Extensive experiments on four benchmark datasets show
that our proposed MCOD achieves a considerable performance and outperforms nine
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Sequence Feature Alignment for Domain Adaptive Detection Transformers. (arXiv:2107.12636v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1">Fengxiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zheng-Jun Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yonggang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12636">
                                    <div class="article-summary-box-inner">
                                        <span>Detection transformers have recently shown promising object detection results
and attracted increasing attention. However, how to develop effective domain
adaptation techniques to improve its cross-domain performance remains
unexplored and unclear. In this paper, we delve into this topic and empirically
find that direct feature distribution alignment on the CNN backbone only brings
limited improvements, as it does not guarantee domain-invariant sequence
features in the transformer for prediction. To address this issue, we propose a
novel Sequence Feature Alignment (SFA) method that is specially designed for
the adaptation of detection transformers. Technically, SFA consists of a domain
query-based feature alignment (DQFA) module and a token-wise feature alignment
(TDA) module. In DQFA, a novel domain query is used to aggregate and align
global context from the token sequence of both domains. DQFA reduces the domain
discrepancy in global feature representations and object relations when
deploying in the transformer encoder and decoder, respectively. Meanwhile, TDA
aligns token features in the sequence from both domains, which reduces the
domain gaps in local and instance-level feature representations in the
transformer encoder and decoder, respectively. Besides, a novel bipartite
matching consistency loss is proposed to enhance the feature discriminability
for robust object detection. Experiments on three challenging benchmarks show
that SFA outperforms state-of-the-art domain adaptive object detection methods.
Code has been made available at: https://github.com/encounter1997/SFA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Computer Vision-Based Guidance Assistance Concept for Plowing Using RGB-D Camera. (arXiv:2107.12646v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Turkoz_E/0/1/0/all/0/1">Erkin T&#xfc;rk&#xf6;z</a>, <a href="http://arxiv.org/find/cs/1/au:+Olcay_E/0/1/0/all/0/1">Ertug Olcay</a>, <a href="http://arxiv.org/find/cs/1/au:+Oksanen_T/0/1/0/all/0/1">Timo Oksanen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12646">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a concept of computer vision-based guidance assistance
for agricultural vehicles to increase the accuracy in plowing and reduce
driver&#x27;s cognitive burden in long-lasting tillage operations. Plowing is a
common agricultural practice to prepare the soil for planting in many countries
and it can take place both in the spring and the fall. Since plowing operation
requires high traction forces, it causes increased energy consumption.
Moreover, longer operation time due to unnecessary maneuvers leads to higher
fuel consumption. To provide necessary information for the driver and the
control unit of the tractor, a first concept of furrow detection system based
on an RGB-D camera was developed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parallel Detection for Efficient Video Analytics at the Edge. (arXiv:2107.12563v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yanzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Ling Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kompella_R/0/1/0/all/0/1">Ramana Kompella</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12563">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Network (DNN) trained object detectors are widely deployed in
many mission-critical systems for real time video analytics at the edge, such
as autonomous driving and video surveillance. A common performance requirement
in these mission-critical edge services is the near real-time latency of online
object detection on edge devices. However, even with well-trained DNN object
detectors, the online detection quality at edge may deteriorate for a number of
reasons, such as limited capacity to run DNN object detection models on
heterogeneous edge devices, and detection quality degradation due to random
frame dropping when the detection processing rate is significantly slower than
the incoming video frame rate. This paper addresses these problems by
exploiting multi-model multi-device detection parallelism for fast object
detection in edge systems with heterogeneous edge devices. First, we analyze
the performance bottleneck of running a well-trained DNN model at edge for real
time online object detection. We use the offline detection as a reference
model, and examine the root cause by analyzing the mismatch among the incoming
video streaming rate, video processing rate for object detection, and output
rate for real time detection visualization of video streaming. Second, we study
performance optimizations by exploiting multi-model detection parallelism. We
show that the model-parallel detection approach can effectively speed up the
FPS detection processing rate, minimizing the FPS disparity with the incoming
video frame rate on heterogeneous edge devices. We evaluate the proposed
approach using SSD300 and YOLOv3 on benchmark videos of different video stream
rates. The results show that exploiting multi-model detection parallelism can
speed up the online object detection processing rate and deliver near real-time
object detection performance for efficient video analytics at edge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BridgeNet: A Joint Learning Network of Depth Map Super-Resolution and Monocular Depth Estimation. (arXiv:2107.12541v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Q/0/1/0/all/0/1">Qi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_R/0/1/0/all/0/1">Runmin Cong</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_R/0/1/0/all/0/1">Ronghui Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lingzhi He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwong_S/0/1/0/all/0/1">Sam Kwong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12541">
                                    <div class="article-summary-box-inner">
                                        <span>Depth map super-resolution is a task with high practical application
requirements in the industry. Existing color-guided depth map super-resolution
methods usually necessitate an extra branch to extract high-frequency detail
information from RGB image to guide the low-resolution depth map
reconstruction. However, because there are still some differences between the
two modalities, direct information transmission in the feature dimension or
edge map dimension cannot achieve satisfactory result, and may even trigger
texture copying in areas where the structures of the RGB-D pair are
inconsistent. Inspired by the multi-task learning, we propose a joint learning
network of depth map super-resolution (DSR) and monocular depth estimation
(MDE) without introducing additional supervision labels. For the interaction of
two subnetworks, we adopt a differentiated guidance strategy and design two
bridges correspondingly. One is the high-frequency attention bridge (HABdg)
designed for the feature encoding process, which learns the high-frequency
information of the MDE task to guide the DSR task. The other is the content
guidance bridge (CGBdg) designed for the depth map reconstruction process,
which provides the content guidance learned from DSR task for MDE task. The
entire network architecture is highly portable and can provide a paradigm for
associating the DSR and MDE tasks. Extensive experiments on benchmark datasets
demonstrate that our method achieves competitive performance. Our code and
models are available at https://rmcong.github.io/proj_BridgeNet.html.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nearest Neighborhood-Based Deep Clustering for Source Data-absent Unsupervised Domain Adaptation. (arXiv:2107.12585v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Song Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhiyuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Hendrich_N/0/1/0/all/0/1">Norman Hendrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1">Fanyu Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ge_S/0/1/0/all/0/1">Shuzhi Sam Ge</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianwei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12585">
                                    <div class="article-summary-box-inner">
                                        <span>In the classic setting of unsupervised domain adaptation (UDA), the labeled
source data are available in the training phase. However, in many real-world
scenarios, owing to some reasons such as privacy protection and information
security, the source data is inaccessible, and only a model trained on the
source domain is available. This paper proposes a novel deep clustering method
for this challenging task. Aiming at the dynamical clustering at feature-level,
we introduce extra constraints hidden in the geometric structure between data
to assist the process. Concretely, we propose a geometry-based constraint,
named semantic consistency on the nearest neighborhood (SCNNH), and use it to
encourage robust clustering. To reach this goal, we construct the nearest
neighborhood for every target data and take it as the fundamental clustering
unit by building our objective on the geometry. Also, we develop a more
SCNNH-compliant structure with an additional semantic credibility constraint,
named semantic hyper-nearest neighborhood (SHNNH). After that, we extend our
method to this new geometry. Extensive experiments on three challenging UDA
datasets indicate that our method achieves state-of-the-art results. The
proposed method has significant improvement on all datasets (as we adopt SHNNH,
the average accuracy increases by over 3.0\% on the large-scaled dataset). Code
is available at https://github.com/tntek/N2DCX.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Perception-and-Regulation Network for Salient Object Detection. (arXiv:2107.12560v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jinchao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xian Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Junnan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12560">
                                    <div class="article-summary-box-inner">
                                        <span>Effective fusion of different types of features is the key to salient object
detection. The majority of existing network structure design is based on the
subjective experience of scholars and the process of feature fusion does not
consider the relationship between the fused features and highest-level
features. In this paper, we focus on the feature relationship and propose a
novel global attention unit, which we term the &quot;perception- and-regulation&quot;
(PR) block, that adaptively regulates the feature fusion process by explicitly
modeling interdependencies between features. The perception part uses the
structure of fully-connected layers in classification networks to learn the
size and shape of objects. The regulation part selectively strengthens and
weakens the features to be fused. An imitating eye observation module (IEO) is
further employed for improving the global perception ability of the network.
The imitation of foveal vision and peripheral vision enables IEO to scrutinize
highly detailed objects and to organize the broad spatial scene to better
segment objects. Sufficient experiments conducted on SOD datasets demonstrate
that the proposed method performs favorably against 22 state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Attacks with Time-Scale Representations. (arXiv:2107.12473v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Santamaria_Pang_A/0/1/0/all/0/1">Alberto Santamaria-Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1">Jianwei Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1">Aritra Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Kubricht_J/0/1/0/all/0/1">James Kubricht</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_P/0/1/0/all/0/1">Peter Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Naresh_I/0/1/0/all/0/1">Iyer Naresh</a>, <a href="http://arxiv.org/find/cs/1/au:+Virani_N/0/1/0/all/0/1">Nurali Virani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12473">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel framework for real-time black-box universal attacks which
disrupts activations of early convolutional layers in deep learning models. Our
hypothesis is that perturbations produced in the wavelet space disrupt early
convolutional layers more effectively than perturbations performed in the time
domain. The main challenge in adversarial attacks is to preserve low frequency
image content while minimally changing the most meaningful high frequency
content. To address this, we formulate an optimization problem using time-scale
(wavelet) representations as a dual space in three steps. First, we project
original images into orthonormal sub-spaces for low and high scales via wavelet
coefficients. Second, we perturb wavelet coefficients for high scale projection
using a generator network. Third, we generate new adversarial images by
projecting back the original coefficients from the low scale and the perturbed
coefficients from the high scale sub-space. We provide a theoretical framework
that guarantees a dual mapping from time and time-scale domain representations.
We compare our results with state-of-the-art black-box attacks from
generative-based and gradient-based models. We also verify efficacy against
multiple defense methods such as JPEG compression, Guided Denoiser and
Comdefend. Our results show that wavelet-based perturbations consistently
outperform time-based attacks thus providing new insights into vulnerabilities
of deep learning models and could potentially lead to robust architectures or
new defense and attack mechanisms by leveraging time-scale representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MonoIndoor: Towards Good Practice of Self-Supervised Monocular Depth Estimation for Indoor Environments. (arXiv:2107.12429v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ji_P/0/1/0/all/0/1">Pan Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Runze Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhanu_B/0/1/0/all/0/1">Bir Bhanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12429">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised depth estimation for indoor environments is more challenging
than its outdoor counterpart in at least the following two aspects: (i) the
depth range of indoor sequences varies a lot across different frames, making it
difficult for the depth network to induce consistent depth cues, whereas the
maximum distance in outdoor scenes mostly stays the same as the camera usually
sees the sky; (ii) the indoor sequences contain much more rotational motions,
which cause difficulties for the pose network, while the motions of outdoor
sequences are pre-dominantly translational, especially for driving datasets
such as KITTI. In this paper, special considerations are given to those
challenges and a set of good practices are consolidated for improving the
performance of self-supervised monocular depth estimation in indoor
environments. The proposed method mainly consists of two novel modules, \ie, a
depth factorization module and a residual pose estimation module, each of which
is designed to respectively tackle the aforementioned challenges. The
effectiveness of each module is shown through a carefully conducted ablation
study and the demonstration of the state-of-the-art performance on two indoor
datasets, \ie, EuRoC and NYUv2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Video Object Segmentation by Motion-Aware Mask Propagation. (arXiv:2107.12569v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Miao_B/0/1/0/all/0/1">Bo Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1">Mohammed Bennamoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yongsheng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mian_A/0/1/0/all/0/1">Ajmal Mian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12569">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a self-supervised spatio-temporal matching method coined
Motion-Aware Mask Propagation (MAMP) for semi-supervised video object
segmentation. During training, MAMP leverages the frame reconstruction task to
train the model without the need for annotations. During inference, MAMP
extracts high-resolution features from each frame to build a memory bank from
the features as well as the predicted masks of selected past frames. MAMP then
propagates the masks from the memory bank to subsequent frames according to our
motion-aware spatio-temporal matching module, also proposed in this paper.
Evaluation on DAVIS-2017 and YouTube-VOS datasets show that MAMP achieves
state-of-the-art performance with stronger generalization ability compared to
existing self-supervised methods, i.e. 4.9\% higher mean
$\mathcal{J}\&amp;\mathcal{F}$ on DAVIS-2017 and 4.85\% higher mean
$\mathcal{J}\&amp;\mathcal{F}$ on the unseen categories of YouTube-VOS than the
nearest competitor. Moreover, MAMP performs on par with many supervised video
object segmentation methods. Our code is available at:
\url{https://github.com/bo-miao/MAMP}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Circular-Symmetric Correlation Layer based on FFT. (arXiv:2107.12480v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azari_B/0/1/0/all/0/1">Bahar Azari</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdogmus_D/0/1/0/all/0/1">Deniz Erdogmus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12480">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the vast success of standard planar convolutional neural networks,
they are not the most efficient choice for analyzing signals that lie on an
arbitrarily curved manifold, such as a cylinder. The problem arises when one
performs a planar projection of these signals and inevitably causes them to be
distorted or broken where there is valuable information. We propose a
Circular-symmetric Correlation Layer (CCL) based on the formalism of
roto-translation equivariant correlation on the continuous group $S^1 \times
\mathbb{R}$, and implement it efficiently using the well-known Fast Fourier
Transform (FFT) algorithm. We showcase the performance analysis of a general
network equipped with CCL on various recognition and classification tasks and
datasets. The PyTorch package implementation of CCL is provided online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Grounding with 3D Objects. (arXiv:2107.12514v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thomason_J/0/1/0/all/0/1">Jesse Thomason</a>, <a href="http://arxiv.org/find/cs/1/au:+Shridhar_M/0/1/0/all/0/1">Mohit Shridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1">Yonatan Bisk</a>, <a href="http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1">Chris Paxton</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12514">
                                    <div class="article-summary-box-inner">
                                        <span>Seemingly simple natural language requests to a robot are generally
underspecified, for example &quot;Can you bring me the wireless mouse?&quot; When viewing
mice on the shelf, the number of buttons or presence of a wire may not be
visible from certain angles or positions. Flat images of candidate mice may not
provide the discriminative information needed for &quot;wireless&quot;. The world, and
objects in it, are not flat images but complex 3D shapes. If a human requests
an object based on any of its basic properties, such as color, shape, or
texture, robots should perform the necessary exploration to accomplish the
task. In particular, while substantial effort and progress has been made on
understanding explicitly visual attributes like color and category,
comparatively little progress has been made on understanding language about
shapes and contours. In this work, we introduce a novel reasoning task that
targets both visual and non-visual language about 3D objects. Our new
benchmark, ShapeNet Annotated with Referring Expressions (SNARE), requires a
model to choose which of two objects is being referenced by a natural language
description. We introduce several CLIP-based models for distinguishing objects
and demonstrate that while recent advances in jointly modeling vision and
language are useful for robotic language understanding, it is still the case
that these models are weaker at understanding the 3D nature of objects --
properties which play a key role in manipulation. In particular, we find that
adding view estimation to language grounding models improves accuracy on both
SNARE and when identifying objects referred to in language on a robot platform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transferable Knowledge-Based Multi-Granularity Aggregation Network for Temporal Action Localization: Submission to ActivityNet Challenge 2021. (arXiv:2107.12618v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Haisheng Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_P/0/1/0/all/0/1">Peiqin Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yukun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dongliang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_W/0/1/0/all/0/1">Weihao Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12618">
                                    <div class="article-summary-box-inner">
                                        <span>This technical report presents an overview of our solution used in the
submission to 2021 HACS Temporal Action Localization Challenge on both
Supervised Learning Track and Weakly-Supervised Learning Track. Temporal Action
Localization (TAL) requires to not only precisely locate the temporal
boundaries of action instances, but also accurately classify the untrimmed
videos into specific categories. However, Weakly-Supervised TAL indicates
locating the action instances using only video-level class labels. In this
paper, to train a supervised temporal action localizer, we adopt Temporal
Context Aggregation Network (TCANet) to generate high-quality action proposals
through &#x60;&#x60;local and global&quot; temporal context aggregation and complementary as
well as progressive boundary refinement. As for the WSTAL, a novel framework is
proposed to handle the poor quality of CAS generated by simple classification
network, which can only focus on local discriminative parts, rather than locate
the entire interval of target actions. Further inspired by the transfer
learning method, we also adopt an additional module to transfer the knowledge
from trimmed videos (HACS Clips dataset) to untrimmed videos (HACS Segments
dataset), aiming at promoting the classification performance on untrimmed
videos. Finally, we employ a boundary regression module embedded with
Outer-Inner-Contrastive (OIC) loss to automatically predict the boundaries
based on the enhanced CAS. Our proposed scheme achieves 39.91 and 29.78 average
mAP on the challenge testing set of supervised and weakly-supervised temporal
action localization track respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangled Implicit Shape and Pose Learning for Scalable 6D Pose Estimation. (arXiv:2107.12549v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yilin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiangyu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Hao Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Komura_T/0/1/0/all/0/1">Taku Komura</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenping Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12549">
                                    <div class="article-summary-box-inner">
                                        <span>6D pose estimation of rigid objects from a single RGB image has seen
tremendous improvements recently by using deep learning to combat complex
real-world variations, but a majority of methods build models on the per-object
level, failing to scale to multiple objects simultaneously. In this paper, we
present a novel approach for scalable 6D pose estimation, by self-supervised
learning on synthetic data of multiple objects using a single autoencoder. To
handle multiple objects and generalize to unseen objects, we disentangle the
latent object shape and pose representations, so that the latent shape space
models shape similarities, and the latent pose code is used for rotation
retrieval by comparison with canonical rotations. To encourage shape space
construction, we apply contrastive metric learning and enable the processing of
unseen objects by referring to similar training objects. The different
symmetries across objects induce inconsistent latent pose spaces, which we
capture with a conditioned block producing shape-dependent pose codebooks by
re-entangling shape and pose representations. We test our method on two
multi-object benchmarks with real data, T-LESS and NOCS REAL275, and show it
outperforms existing RGB-based methods in terms of pose estimation accuracy and
generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Efficient Tensor Decomposition-Based DNN Model Compression with Optimization Framework. (arXiv:2107.12422v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_M/0/1/0/all/0/1">Miao Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1">Yang Sui</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1">Siyu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1">Bo Yuan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12422">
                                    <div class="article-summary-box-inner">
                                        <span>Advanced tensor decomposition, such as Tensor train (TT) and Tensor ring
(TR), has been widely studied for deep neural network (DNN) model compression,
especially for recurrent neural networks (RNNs). However, compressing
convolutional neural networks (CNNs) using TT/TR always suffers significant
accuracy loss. In this paper, we propose a systematic framework for tensor
decomposition-based model compression using Alternating Direction Method of
Multipliers (ADMM). By formulating TT decomposition-based model compression to
an optimization problem with constraints on tensor ranks, we leverage ADMM
technique to systemically solve this optimization problem in an iterative way.
During this procedure, the entire DNN model is trained in the original
structure instead of TT format, but gradually enjoys the desired low tensor
rank characteristics. We then decompose this uncompressed model to TT format
and fine-tune it to finally obtain a high-accuracy TT-format DNN model. Our
framework is very general, and it works for both CNNs and RNNs, and can be
easily modified to fit other tensor decomposition approaches. We evaluate our
proposed framework on different DNN models for image classification and video
recognition tasks. Experimental results show that our ADMM-based TT-format
models demonstrate very high compression performance with high accuracy.
Notably, on CIFAR-100, with 2.3X and 2.4X compression ratios, our models have
1.96% and 2.21% higher top-1 accuracy than the original ResNet-20 and
ResNet-32, respectively. For compressing ResNet-18 on ImageNet, our model
achieves 2.47X FLOPs reduction without accuracy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmentation in Style: Unsupervised Semantic Image Segmentation with Stylegan and CLIP. (arXiv:2107.12518v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pakhomov_D/0/1/0/all/0/1">Daniil Pakhomov</a>, <a href="http://arxiv.org/find/cs/1/au:+Hira_S/0/1/0/all/0/1">Sanchit Hira</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagle_N/0/1/0/all/0/1">Narayani Wagle</a>, <a href="http://arxiv.org/find/cs/1/au:+Green_K/0/1/0/all/0/1">Kemar E. Green</a>, <a href="http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12518">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a method that allows to automatically segment images into
semantically meaningful regions without human supervision. Derived regions are
consistent across different images and coincide with human-defined semantic
classes on some datasets. In cases where semantic regions might be hard for
human to define and consistently label, our method is still able to find
meaningful and consistent semantic classes. In our work, we use pretrained
StyleGAN2~\cite{karras2020analyzing} generative model: clustering in the
feature space of the generative model allows to discover semantic classes. Once
classes are discovered, a synthetic dataset with generated images and
corresponding segmentation masks can be created. After that a segmentation
model is trained on the synthetic dataset and is able to generalize to real
images. Additionally, by using CLIP~\cite{radford2021learning} we are able to
use prompts defined in a natural language to discover some desired semantic
classes. We test our method on publicly available datasets and show
state-of-the-art results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-modal Consensus Network for Weakly Supervised Temporal Action Localization. (arXiv:2107.12589v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hong_F/0/1/0/all/0/1">Fa-Ting Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jia-Chang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_Y/0/1/0/all/0/1">Ying Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1">Wei-Shi Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12589">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly supervised temporal action localization (WS-TAL) is a challenging task
that aims to localize action instances in the given video with video-level
categorical supervision. Both appearance and motion features are used in
previous works, while they do not utilize them in a proper way but apply simple
concatenation or score-level fusion. In this work, we argue that the features
extracted from the pretrained extractor, e.g., I3D, are not the
WS-TALtask-specific features, thus the feature re-calibration is needed for
reducing the task-irrelevant information redundancy. Therefore, we propose a
cross-modal consensus network (CO2-Net) to tackle this problem. In CO2-Net, we
mainly introduce two identical proposed cross-modal consensus modules (CCM)
that design a cross-modal attention mechanism to filter out the task-irrelevant
information redundancy using the global information from the main modality and
the cross-modal local information of the auxiliary modality. Moreover, we treat
the attention weights derived from each CCMas the pseudo targets of the
attention weights derived from another CCM to maintain the consistency between
the predictions derived from two CCMs, forming a mutual learning manner.
Finally, we conduct extensive experiments on two common used temporal action
localization datasets, THUMOS14 and ActivityNet1.2, to verify our method and
achieve the state-of-the-art results. The experimental results show that our
proposed cross-modal consensus module can produce more representative features
for temporal action localization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Scene Graph Generation (SGG) Benchmark. (arXiv:2107.12604v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xiaotian Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jianwei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Houdong Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengchuan Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12604">
                                    <div class="article-summary-box-inner">
                                        <span>There is a surge of interest in image scene graph generation (object,
attribute and relationship detection) due to the need of building fine-grained
image understanding models that go beyond object detection. Due to the lack of
a good benchmark, the reported results of different scene graph generation
models are not directly comparable, impeding the research progress. We have
developed a much-needed scene graph generation benchmark based on the
maskrcnn-benchmark and several popular models. This paper presents main
features of our benchmark and a comprehensive ablation study of scene graph
generation models using the Visual Genome and OpenImages Visual relationship
detection datasets. Our codebase is made publicly available at
https://github.com/microsoft/scene_graph_benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comprehensive Study on Colorectal Polyp Segmentation with ResUNet++, Conditional Random Field and Test-Time Augmentation. (arXiv:2107.12435v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jha_D/0/1/0/all/0/1">Debesh Jha</a>, <a href="http://arxiv.org/find/cs/1/au:+Smedsrud_P/0/1/0/all/0/1">Pia H. Smedsrud</a>, <a href="http://arxiv.org/find/cs/1/au:+Johansen_D/0/1/0/all/0/1">Dag Johansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lange_T/0/1/0/all/0/1">Thomas de Lange</a>, <a href="http://arxiv.org/find/cs/1/au:+Johansen_H/0/1/0/all/0/1">H&#xe5;vard D. Johansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Halvorsen_P/0/1/0/all/0/1">P&#xe5;l Halvorsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Riegler_M/0/1/0/all/0/1">Michael A. Riegler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12435">
                                    <div class="article-summary-box-inner">
                                        <span>Colonoscopy is considered the gold standard for detection of colorectal
cancer and its precursors. Existing examination methods are, however, hampered
by high overall miss-rate, and many abnormalities are left undetected.
Computer-Aided Diagnosis systems based on advanced machine learning algorithms
are touted as a game-changer that can identify regions in the colon overlooked
by the physicians during endoscopic examinations, and help detect and
characterize lesions. In previous work, we have proposed the ResUNet++
architecture and demonstrated that it produces more efficient results compared
with its counterparts U-Net and ResUNet. In this paper, we demonstrate that
further improvements to the overall prediction performance of the ResUNet++
architecture can be achieved by using conditional random field and test-time
augmentation. We have performed extensive evaluations and validated the
improvements using six publicly available datasets: Kvasir-SEG, CVC-ClinicDB,
CVC-ColonDB, ETIS-Larib Polyp DB, ASU-Mayo Clinic Colonoscopy Video Database,
and CVC-VideoClinicDB. Moreover, we compare our proposed architecture and
resulting model with other State-of-the-art methods. To explore the
generalization capability of ResUNet++ on different publicly available polyp
datasets, so that it could be used in a real-world setting, we performed an
extensive cross-dataset evaluation. The experimental results show that applying
CRF and TTA improves the performance on various polyp segmentation datasets
both on the same dataset and cross-dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CalCROP21: A Georeferenced multi-spectral dataset of Satellite Imagery and Crop Labels. (arXiv:2107.12499v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1">Rahul Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravirathinam_P/0/1/0/all/0/1">Praveen Ravirathinam</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xiaowei Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Khandelwal_A/0/1/0/all/0/1">Ankush Khandelwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulla_D/0/1/0/all/0/1">David Mulla</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1">Vipin Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12499">
                                    <div class="article-summary-box-inner">
                                        <span>Mapping and monitoring crops is a key step towards sustainable
intensification of agriculture and addressing global food security. A dataset
like ImageNet that revolutionized computer vision applications can accelerate
development of novel crop mapping techniques. Currently, the United States
Department of Agriculture (USDA) annually releases the Cropland Data Layer
(CDL) which contains crop labels at 30m resolution for the entire United States
of America. While CDL is state of the art and is widely used for a number of
agricultural applications, it has a number of limitations (e.g., pixelated
errors, labels carried over from previous errors and absence of input imagery
along with class labels). In this work, we create a new semantic segmentation
benchmark dataset, which we call CalCROP21, for the diverse crops in the
Central Valley region of California at 10m spatial resolution using a Google
Earth Engine based robust image processing pipeline and a novel attention based
spatio-temporal semantic segmentation algorithm STATT. STATT uses re-sampled
(interpolated) CDL labels for training, but is able to generate a better
prediction than CDL by leveraging spatial and temporal patterns in Sentinel2
multi-spectral image series to effectively capture phenologic differences
amongst crops and uses attention to reduce the impact of clouds and other
atmospheric disturbances. We also present a comprehensive evaluation to show
that STATT has significantly better results when compared to the resampled CDL
labels. We have released the dataset and the processing pipeline code for
generating the benchmark dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SaRNet: A Dataset for Deep Learning Assisted Search and Rescue with Satellite Imagery. (arXiv:2107.12469v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Thoreau_M/0/1/0/all/0/1">Michael Thoreau</a>, <a href="http://arxiv.org/find/eess/1/au:+Wilson_F/0/1/0/all/0/1">Frazer Wilson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12469">
                                    <div class="article-summary-box-inner">
                                        <span>Access to high resolution satellite imagery has dramatically increased in
recent years as several new constellations have entered service. High revisit
frequencies as well as improved resolution has widened the use cases of
satellite imagery to areas such as humanitarian relief and even Search and
Rescue (SaR). We propose a novel remote sensing object detection dataset for
deep learning assisted SaR. This dataset contains only small objects that have
been identified as potential targets as part of a live SaR response. We
evaluate the application of popular object detection models to this dataset as
a baseline to inform further research. We also propose a novel object detection
metric, specifically designed to be used in a deep learning assisted SaR
setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extraction and Analysis of Fictional Character Networks: A Survey. (arXiv:1907.02704v4 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Labatut_V/0/1/0/all/0/1">Vincent Labatut</a> (LIA), <a href="http://arxiv.org/find/cs/1/au:+Bost_X/0/1/0/all/0/1">Xavier Bost</a> (LIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.02704">
                                    <div class="article-summary-box-inner">
                                        <span>A character network is a graph extracted from a narrative, in which vertices
represent characters and edges correspond to interactions between them. A
number of narrative-related problems can be addressed automatically through the
analysis of character networks, such as summarization, classification, or role
detection. Character networks are particularly relevant when considering works
of fictions (e.g. novels, plays, movies, TV series), as their exploitation
allows developing information retrieval and recommendation systems. However,
works of fiction possess specific properties making these tasks harder. This
survey aims at presenting and organizing the scientific literature related to
the extraction of character networks from works of fiction, as well as their
analysis. We first describe the extraction process in a generic way, and
explain how its constituting steps are implemented in practice, depending on
the medium of the narrative, the goal of the network analysis, and other
factors. We then review the descriptive tools used to characterize character
networks, with a focus on the way they are interpreted in this context. We
illustrate the relevance of character networks by also providing a review of
applications derived from their analysis. Finally, we identify the limitations
of the existing approaches, and the most promising perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Biomedically oriented automatically annotated Twitter COVID-19 Dataset. (arXiv:2107.12565v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hernandez_L/0/1/0/all/0/1">Luis Alberto Robles Hernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Callahan_T/0/1/0/all/0/1">Tiffany J. Callahan</a>, <a href="http://arxiv.org/find/cs/1/au:+Banda_J/0/1/0/all/0/1">Juan M. Banda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12565">
                                    <div class="article-summary-box-inner">
                                        <span>The use of social media data, like Twitter, for biomedical research has been
gradually increasing over the years. With the COVID-19 pandemic, researchers
have turned to more nontraditional sources of clinical data to characterize the
disease in near real-time, study the societal implications of interventions, as
well as the sequelae that recovered COVID-19 cases present (Long-COVID).
However, manually curated social media datasets are difficult to come by due to
the expensive costs of manual annotation and the efforts needed to identify the
correct texts. When datasets are available, they are usually very small and
their annotations do not generalize well over time or to larger sets of
documents. As part of the 2021 Biomedical Linked Annotation Hackathon, we
release our dataset of over 120 million automatically annotated tweets for
biomedical research purposes. Incorporating best practices, we identify tweets
with potentially high clinical relevance. We evaluated our work by comparing
several SpaCy-based annotation frameworks against a manually annotated
gold-standard dataset. Selecting the best method to use for automatic
annotation, we then annotated 120 million tweets and released them publicly for
future downstream usage within the biomedical domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Graph Neural Networks for Sequential Recommendation. (arXiv:2104.07368v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mengqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xueli Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07368">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling user preference from his historical sequences is one of the core
problems of sequential recommendation. Existing methods in this field are
widely distributed from conventional methods to deep learning methods. However,
most of them only model users&#x27; interests within their own sequences and ignore
the dynamic collaborative signals among different user sequences, making it
insufficient to explore users&#x27; preferences. We take inspiration from dynamic
graph neural networks to cope with this challenge, modeling the user sequence
and dynamic collaborative signals into one framework. We propose a new method
named Dynamic Graph Neural Network for Sequential Recommendation (DGSR), which
connects different user sequences through a dynamic graph structure, exploring
the interactive behavior of users and items with time and order information.
Furthermore, we design a Dynamic Graph Recommendation Network to extract user&#x27;s
preferences from the dynamic graph. Consequently, the next-item prediction task
in sequential recommendation is converted into a link prediction between the
user node and the item node in a dynamic graph. Extensive experiments on three
public benchmarks show that DGSR outperforms several state-of-the-art methods.
Further studies demonstrate the rationality and effectiveness of modeling user
sequences through a dynamic graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Variational Models for Collaborative Filtering-based Recommender Systems. (arXiv:2107.12677v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bobadilla_J/0/1/0/all/0/1">Jes&#xfa;s Bobadilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_F/0/1/0/all/0/1">Fernando Ortega</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_A/0/1/0/all/0/1">Abraham Guti&#xe9;rrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Prieto_A/0/1/0/all/0/1">&#xc1;ngel Gonz&#xe1;lez-Prieto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12677">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning provides accurate collaborative filtering models to improve
recommender system results. Deep matrix factorization and their related
collaborative neural networks are the state-of-art in the field; nevertheless,
both models lack the necessary stochasticity to create the robust, continuous,
and structured latent spaces that variational autoencoders exhibit. On the
other hand, data augmentation through variational autoencoder does not provide
accurate results in the collaborative filtering field due to the high sparsity
of recommender systems. Our proposed models apply the variational concept to
inject stochasticity in the latent space of the deep architecture, introducing
the variational technique in the neural collaborative filtering field. This
method does not depend on the particular model used to generate the latent
representation. In this way, this approach can be applied as a plugin to any
current and future specific models. The proposed models have been tested using
four representative open datasets, three different quality measures, and
state-of-art baselines. The results show the superiority of the proposed
approach in scenarios where the variational enrichment exceeds the injected
noise effect. Additionally, a framework is provided to enable the
reproducibility of the conducted experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What is all this new MeSH about? Exploring the semantic provenance of new descriptors in the MeSH thesaurus. (arXiv:2101.08293v3 [cs.DL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nentidis_A/0/1/0/all/0/1">Anastasios Nentidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Krithara_A/0/1/0/all/0/1">Anastasia Krithara</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsoumakas_G/0/1/0/all/0/1">Grigorios Tsoumakas</a>, <a href="http://arxiv.org/find/cs/1/au:+Paliouras_G/0/1/0/all/0/1">Georgios Paliouras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08293">
                                    <div class="article-summary-box-inner">
                                        <span>The Medical Subject Headings (MeSH) thesaurus is a controlled vocabulary
widely used in biomedical knowledge systems, particularly for semantic indexing
of scientific literature. As the MeSH hierarchy evolves through annual version
updates, some new descriptors are introduced that were not previously
available. This paper explores the conceptual provenance of these new
descriptors. In particular, we investigate whether such new descriptors have
been previously covered by older descriptors and what is their current relation
to them. To this end, we propose a framework to categorize new descriptors
based on their current relation to older descriptors. Based on the proposed
classification scheme, we quantify, analyse and present the different types of
new descriptors introduced in MeSH during the last fifteen years. The results
show that only about 25% of new MeSH descriptors correspond to new emerging
concepts, whereas the rest were previously covered by one or more existing
descriptors, either implicitly or explicitly. Most of them were covered by a
single existing descriptor and they usually end up as descendants of it in the
current hierarchy, gradually leading towards a more fine-grained MeSH
vocabulary. These insights about the dynamics of the thesaurus are useful for
the retrospective study of scientific articles annotated with MeSH, but could
also be used to inform the policy of updating the thesaurus in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SaliencyMix: A Saliency Guided Data Augmentation Strategy for Better Regularization. (arXiv:2006.01791v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Uddin_A/0/1/0/all/0/1">A. F. M. Shahab Uddin</a>, <a href="http://arxiv.org/find/cs/1/au:+Monira_M/0/1/0/all/0/1">Mst. Sirazam Monira</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_W/0/1/0/all/0/1">Wheemyung Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_T/0/1/0/all/0/1">TaeChoong Chung</a>, <a href="http://arxiv.org/find/cs/1/au:+Bae_S/0/1/0/all/0/1">Sung-Ho Bae</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.01791">
                                    <div class="article-summary-box-inner">
                                        <span>Advanced data augmentation strategies have widely been studied to improve the
generalization ability of deep learning models. Regional dropout is one of the
popular solutions that guides the model to focus on less discriminative parts
by randomly removing image regions, resulting in improved regularization.
However, such information removal is undesirable. On the other hand, recent
strategies suggest to randomly cut and mix patches and their labels among
training images, to enjoy the advantages of regional dropout without having any
pointless pixel in the augmented images. We argue that such random selection
strategies of the patches may not necessarily represent sufficient information
about the corresponding object and thereby mixing the labels according to that
uninformative patch enables the model to learn unexpected feature
representation. Therefore, we propose SaliencyMix that carefully selects a
representative image patch with the help of a saliency map and mixes this
indicative patch with the target image, thus leading the model to learn more
appropriate feature representation. SaliencyMix achieves the best known top-1
error of 21.26% and 20.09% for ResNet-50 and ResNet-101 architectures on
ImageNet classification, respectively, and also improves the model robustness
against adversarial perturbations. Furthermore, models that are trained with
SaliencyMix help to improve the object detection performance. Source code is
available at https://github.com/SaliencyMix/SaliencyMix.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Task-Based Information Compression for Multi-Agent Communication Problems with Channel Rate Constraints. (arXiv:2005.14220v2 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mostaani_A/0/1/0/all/0/1">Arsham Mostaani</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1">Thang X. Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatzinotas_S/0/1/0/all/0/1">Symeon Chatzinotas</a>, <a href="http://arxiv.org/find/cs/1/au:+Ottersten_B/0/1/0/all/0/1">Bj&#xf6;rn Ottersten</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.14220">
                                    <div class="article-summary-box-inner">
                                        <span>A collaborative task is assigned to a multiagent system (MAS) in which agents
are allowed to communicate. The MAS runs over an underlying Markov decision
process and its task is to maximize the averaged sum of discounted one-stage
rewards. Although knowing the global state of the environment is necessary for
the optimal action selection of the MAS, agents are limited to individual
observations. The inter-agent communication can tackle the issue of local
observability, however, the limited rate of the inter-agent communication
prevents the agent from acquiring the precise global state information. To
overcome this challenge, agents need to communicate their observations in a
compact way such that the MAS compromises the minimum possible sum of rewards.
We show that this problem is equivalent to a form of rate-distortion problem
which we call the task-based information compression. We introduce a scheme for
task-based information compression titled State aggregation for information
compression (SAIC), for which a state aggregation algorithm is analytically
designed. The SAIC is shown to be capable of achieving near-optimal performance
in terms of the achieved sum of discounted rewards. The proposed algorithm is
applied to a rendezvous problem and its performance is compared with several
benchmarks. Numerical experiments confirm the superiority of the proposed
algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RGB cameras failures and their effects in autonomous driving applications. (arXiv:2008.05938v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Secci_F/0/1/0/all/0/1">Francesco Secci</a>, <a href="http://arxiv.org/find/cs/1/au:+Ceccarelli_A/0/1/0/all/0/1">Andrea Ceccarelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.05938">
                                    <div class="article-summary-box-inner">
                                        <span>RGB cameras are one of the most relevant sensors for autonomous driving
applications. It is undeniable that failures of vehicle cameras may compromise
the autonomous driving task, possibly leading to unsafe behaviors when images
that are subsequently processed by the driving system are altered. To support
the definition of safe and robust vehicle architectures and intelligent
systems, in this paper we define the failure modes of a vehicle camera,
together with an analysis of effects and known mitigations. Further, we build a
software library for the generation of the corresponding failed images and we
feed them to six object detectors for mono and stereo cameras and to the
self-driving agent of an autonomous driving simulator. The resulting
misbehaviors with respect to operating with clean images allow a better
understanding of failures effects and the related safety risks in image-based
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-architecture Tuning of Silicon and SiGe-based Quantum Devices Using Machine Learning. (arXiv:2107.12975v1 [cond-mat.mes-hall])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Severin_B/0/1/0/all/0/1">B. Severin</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Lennon_D/0/1/0/all/0/1">D. T. Lennon</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Camenzind_L/0/1/0/all/0/1">L. C. Camenzind</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Vigneau_F/0/1/0/all/0/1">F. Vigneau</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Fedele_F/0/1/0/all/0/1">F. Fedele</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Jirovec_D/0/1/0/all/0/1">D. Jirovec</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Ballabio_A/0/1/0/all/0/1">A. Ballabio</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Chrastina_D/0/1/0/all/0/1">D. Chrastina</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Isella_G/0/1/0/all/0/1">G. Isella</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Kruijf_M/0/1/0/all/0/1">M. de Kruijf</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Carballido_M/0/1/0/all/0/1">M. J. Carballido</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Svab_S/0/1/0/all/0/1">S. Svab</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Kuhlmann_A/0/1/0/all/0/1">A. V. Kuhlmann</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Braakman_F/0/1/0/all/0/1">F. R. Braakman</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Geyer_S/0/1/0/all/0/1">S. Geyer</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Froning_F/0/1/0/all/0/1">F. N. M. Froning</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Moon_H/0/1/0/all/0/1">H. Moon</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Osborne_M/0/1/0/all/0/1">M. A. Osborne</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Sejdinovic_D/0/1/0/all/0/1">D. Sejdinovic</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Katsaros_G/0/1/0/all/0/1">G. Katsaros</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Zumbuhl_D/0/1/0/all/0/1">D. M. Zumb&#xfc;hl</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Briggs_G/0/1/0/all/0/1">G. A. D. Briggs</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Ares_N/0/1/0/all/0/1">N. Ares</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12975">
                                    <div class="article-summary-box-inner">
                                        <span>The potential of Si and SiGe-based devices for the scaling of quantum
circuits is tainted by device variability. Each device needs to be tuned to
operation conditions. We give a key step towards tackling this variability with
an algorithm that, without modification, is capable of tuning a 4-gate Si
FinFET, a 5-gate GeSi nanowire and a 7-gate SiGe heterostructure double quantum
dot device from scratch. We achieve tuning times of 30, 10, and 92 minutes,
respectively. The algorithm also provides insight into the parameter space
landscape for each of these devices. These results show that overarching
solutions for the tuning of quantum devices are enabled by machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting User Emotional Tone in Mental Disorder Online Communities. (arXiv:2005.07473v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Silveira_B/0/1/0/all/0/1">B&#xe1;rbara Silveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_H/0/1/0/all/0/1">Henrique S. Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Murai_F/0/1/0/all/0/1">Fabricio Murai</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_A/0/1/0/all/0/1">Ana Paula Couto da Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.07473">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, Online Social Networks have become an important medium for
people who suffer from mental disorders to share moments of hardship, and
receive emotional and informational support. In this work, we analyze how
discussions in Reddit communities related to mental disorders can help improve
the health conditions of their users. Using the emotional tone of users&#x27;
writing as a proxy for emotional state, we uncover relationships between user
interactions and state changes. First, we observe that authors of negative
posts often write rosier comments after engaging in discussions, indicating
that users&#x27; emotional state can improve due to social support. Second, we build
models based on SOTA text embedding techniques and RNNs to predict shifts in
emotional tone. This differs from most of related work, which focuses primarily
on detecting mental disorders from user activity. We demonstrate the
feasibility of accurately predicting the users&#x27; reactions to the interactions
experienced in these platforms, and present some examples which illustrate that
the models are correctly capturing the effects of comments on the author&#x27;s
emotional tone. Our models hold promising implications for interventions to
provide support for people struggling with mental illnesses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Asynchronous Distributed Reinforcement Learning for LQR Control via Zeroth-Order Block Coordinate Descent. (arXiv:2107.12416v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Jing_G/0/1/0/all/0/1">Gangshan Jing</a>, <a href="http://arxiv.org/find/eess/1/au:+Bai_H/0/1/0/all/0/1">He Bai</a>, <a href="http://arxiv.org/find/eess/1/au:+George_J/0/1/0/all/0/1">Jemin George</a>, <a href="http://arxiv.org/find/eess/1/au:+Chakrabortty_A/0/1/0/all/0/1">Aranya Chakrabortty</a>, <a href="http://arxiv.org/find/eess/1/au:+Sharma_P/0/1/0/all/0/1">Piyush K. Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12416">
                                    <div class="article-summary-box-inner">
                                        <span>Recently introduced distributed zeroth-order optimization (ZOO) algorithms
have shown their utility in distributed reinforcement learning (RL).
Unfortunately, in the gradient estimation process, almost all of them require
random samples with the same dimension as the global variable and/or require
evaluation of the global cost function, which may induce high estimation
variance for large-scale networks. In this paper, we propose a novel
distributed zeroth-order algorithm by leveraging the network structure inherent
in the optimization objective, which allows each agent to estimate its local
gradient by local cost evaluation independently, without use of any consensus
protocol. The proposed algorithm exhibits an asynchronous update scheme, and is
designed for stochastic non-convex optimization with a possibly non-convex
feasible domain based on the block coordinate descent method. The algorithm is
later employed as a distributed model-free RL algorithm for distributed linear
quadratic regulator design, where a learning graph is designed to describe the
required interaction relationship among agents in distributed learning. We
provide an empirical validation of the proposed algorithm to benchmark its
performance on convergence rate and variance against a centralized ZOO
algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invariant Representation Learning for Treatment Effect Estimation. (arXiv:2011.12379v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Claudia Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Veitch_V/0/1/0/all/0/1">Victor Veitch</a>, <a href="http://arxiv.org/find/cs/1/au:+Blei_D/0/1/0/all/0/1">David Blei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12379">
                                    <div class="article-summary-box-inner">
                                        <span>The defining challenge for causal inference from observational data is the
presence of &#x60;confounders&#x27;, covariates that affect both treatment assignment and
the outcome. To address this challenge, practitioners collect and adjust for
the covariates, hoping that they adequately correct for confounding. However,
including every observed covariate in the adjustment runs the risk of including
&#x60;bad controls&#x27;, variables that induce bias when they are conditioned on. The
problem is that we do not always know which variables in the covariate set are
safe to adjust for and which are not. To address this problem, we develop
Nearly Invariant Causal Estimation (NICE). NICE uses invariant risk
minimization (IRM) [Arj19] to learn a representation of the covariates that,
under some assumptions, strips out bad controls but preserves sufficient
information to adjust for confounding. Adjusting for the learned
representation, rather than the covariates themselves, avoids the induced bias
and provides valid causal inferences. We evaluate NICE on both synthetic and
semi-synthetic data. When the covariates contain unknown collider variables and
other bad controls, NICE performs better than adjusting for all the covariates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Symmetry-Aware Reservoir Computing. (arXiv:2102.00310v3 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbosa_W/0/1/0/all/0/1">Wendson A. S. Barbosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffith_A/0/1/0/all/0/1">Aaron Griffith</a>, <a href="http://arxiv.org/find/cs/1/au:+Rowlands_G/0/1/0/all/0/1">Graham E. Rowlands</a>, <a href="http://arxiv.org/find/cs/1/au:+Govia_L/0/1/0/all/0/1">Luke C. G. Govia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeill_G/0/1/0/all/0/1">Guilhem J. Ribeill</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Minh-Hai Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohki_T/0/1/0/all/0/1">Thomas A. Ohki</a>, <a href="http://arxiv.org/find/cs/1/au:+Gauthier_D/0/1/0/all/0/1">Daniel J. Gauthier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00310">
                                    <div class="article-summary-box-inner">
                                        <span>We demonstrate that matching the symmetry properties of a reservoir computer
(RC) to the data being processed dramatically increases its processing power.
We apply our method to the parity task, a challenging benchmark problem that
highlights inversion and permutation symmetries, and to a chaotic system
inference task that presents an inversion symmetry rule. For the parity task,
our symmetry-aware RC obtains zero error using an exponentially reduced neural
network and training data, greatly speeding up the time to result and
outperforming hand crafted artificial neural networks. When both symmetries are
respected, we find that the network size $N$ necessary to obtain zero error for
50 different RC instances scales linearly with the parity-order $n$. Moreover,
some symmetry-aware RC instances perform a zero error classification with only
$N&#x3D;1$ for $n\leq7$. Furthermore, we show that a symmetry-aware RC only needs a
training data set with size on the order of $(n+n/2)$ to obtain such
performance, an exponential reduction in comparison to a regular RC which
requires a training data set with size on the order of $n2^n$ to contain all
$2^n$ possible $n-$bit-long sequences. For the inference task, we show that a
symmetry-aware RC presents a normalized root-mean-square error three
orders-of-magnitude smaller than regular RCs. For both tasks, our RC approach
respects the symmetries by adjusting only the input and the output layers, and
not by problem-based modifications to the neural network. We anticipate that
generalizations of our procedure can be applied in information processing for
problems with known symmetries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Methodology guided by Decision Trees Ensemble and Smart Data for Imbalanced Big Data. (arXiv:2001.05759v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garcia_Gil_D/0/1/0/all/0/1">Diego Garc&#xed;a-Gil</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_S/0/1/0/all/0/1">Salvador Garc&#xed;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_N/0/1/0/all/0/1">Ning Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Herrera_F/0/1/0/all/0/1">Francisco Herrera</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.05759">
                                    <div class="article-summary-box-inner">
                                        <span>Differences in data size per class, also known as imbalanced data
distribution, have become a common problem affecting data quality. Big Data
scenarios pose a new challenge to traditional imbalanced classification
algorithms, since they are not prepared to work with such amount of data. Split
data strategies and lack of data in the minority class due to the use of
MapReduce paradigm have posed new challenges for tackling the imbalance between
classes in Big Data scenarios. Ensembles have shown to be able to successfully
address imbalanced data problems. Smart Data refers to data of enough quality
to achieve high performance models. The combination of ensembles and Smart
Data, achieved through Big Data preprocessing, should be a great synergy. In
this paper, we propose a novel methodology based on Decision Trees Ensemble
with Smart Data for addressing the imbalanced classification problem in Big
Data domains, namely DeTE_SD methodology. This methodology is based on the
learning of different decision trees using distributed quality data for the
ensemble process. This quality data is achieved by fusing Random
Discretization, Principal Components Analysis and clustering-based Random
Oversampling for obtaining different Smart Data versions of the original data.
Experiments carried out in 21 binary adapted datasets have shown that our
methodology outperforms Random Forest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble Learning For Mega Man Level Generation. (arXiv:2107.12524v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bowei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1">Ruohan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1">Yuqing Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ricky Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenwen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1">Matthew Guzdial</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12524">
                                    <div class="article-summary-box-inner">
                                        <span>Procedural content generation via machine learning (PCGML) is the process of
procedurally generating game content using models trained on existing game
content. PCGML methods can struggle to capture the true variance present in
underlying data with a single model. In this paper, we investigated the use of
ensembles of Markov chains for procedurally generating \emph{Mega Man} levels.
We conduct an initial investigation of our approach and evaluate it on measures
of playability and stylistic similarity in comparison to a non-ensemble,
existing Markov chain approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Core Challenges in Embodied Vision-Language Planning. (arXiv:2106.13948v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Francis_J/0/1/0/all/0/1">Jonathan Francis</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitamura_N/0/1/0/all/0/1">Nariaki Kitamura</a>, <a href="http://arxiv.org/find/cs/1/au:+Labelle_F/0/1/0/all/0/1">Felix Labelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Xiaopeng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Navarro_I/0/1/0/all/0/1">Ingrid Navarro</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1">Jean Oh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13948">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in the areas of multimodal machine learning and artificial
intelligence (AI) have led to the development of challenging tasks at the
intersection of Computer Vision, Natural Language Processing, and Embodied AI.
Whereas many approaches and previous survey pursuits have characterised one or
two of these dimensions, there has not been a holistic analysis at the center
of all three. Moreover, even when combinations of these topics are considered,
more focus is placed on describing, e.g., current architectural methods, as
opposed to also illustrating high-level challenges and opportunities for the
field. In this survey paper, we discuss Embodied Vision-Language Planning
(EVLP) tasks, a family of prominent embodied navigation and manipulation
problems that jointly use computer vision and natural language. We propose a
taxonomy to unify these tasks and provide an in-depth analysis and comparison
of the new and current algorithmic approaches, metrics, simulated environments,
as well as the datasets used for EVLP tasks. Finally, we present the core
challenges that we believe new EVLP works should seek to address, and we
advocate for task construction that enables model generalizability and furthers
real-world deployment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical Guarantees for Fairness Aware Plug-In Algorithms. (arXiv:2107.12783v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Khurana_D/0/1/0/all/0/1">Drona Khurana</a>, <a href="http://arxiv.org/find/stat/1/au:+Ravichandran_S/0/1/0/all/0/1">Srinivasan Ravichandran</a>, <a href="http://arxiv.org/find/stat/1/au:+Jain_S/0/1/0/all/0/1">Sparsh Jain</a>, <a href="http://arxiv.org/find/stat/1/au:+Edakunni_N/0/1/0/all/0/1">Narayanan Unny Edakunni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12783">
                                    <div class="article-summary-box-inner">
                                        <span>A plug-in algorithm to estimate Bayes Optimal Classifiers for fairness-aware
binary classification has been proposed in (Menon &amp; Williamson, 2018). However,
the statistical efficacy of their approach has not been established. We prove
that the plug-in algorithm is statistically consistent. We also derive finite
sample guarantees associated with learning the Bayes Optimal Classifiers via
the plug-in algorithm. Finally, we propose a protocol that modifies the plug-in
approach, so as to simultaneously guarantee fairness and differential privacy
with respect to a binary feature deemed sensitive.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global optimization using random embeddings. (arXiv:2107.12102v1 [math.OC] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Cartis_C/0/1/0/all/0/1">Coralia Cartis</a>, <a href="http://arxiv.org/find/math/1/au:+Massart_E/0/1/0/all/0/1">Estelle Massart</a>, <a href="http://arxiv.org/find/math/1/au:+Otemissov_A/0/1/0/all/0/1">Adilet Otemissov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12102">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a random-subspace algorithmic framework for global optimization of
Lipschitz-continuous objectives, and analyse its convergence using novel tools
from conic integral geometry. X-REGO randomly projects, in a sequential or
simultaneous manner, the high-dimensional original problem into low-dimensional
subproblems that can then be solved with any global, or even local,
optimization solver. We estimate the probability that the randomly-embedded
subproblem shares (approximately) the same global optimum as the original
problem. This success probability is then used to show convergence of X-REGO to
an approximate global solution of the original problem, under weak assumptions
on the problem (having a strictly feasible global solution) and on the solver
(guaranteed to find an approximate global solution of the reduced problem with
sufficiently high probability). In the particular case of unconstrained
objectives with low effective dimension, that only vary over a low-dimensional
subspace, we propose an X-REGO variant that explores random subspaces of
increasing dimension until finding the effective dimension of the problem,
leading to X-REGO globally converging after a finite number of embeddings,
proportional to the effective dimension. We show numerically that this variant
efficiently finds both the effective dimension and an approximate global
minimizer of the original problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-speaker Style Transfer with Prosody Bottleneck in Neural Speech Synthesis. (arXiv:2107.12562v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shifeng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1">Lei He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12562">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-speaker style transfer is crucial to the applications of multi-style
and expressive speech synthesis at scale. It does not require the target
speakers to be experts in expressing all styles and to collect corresponding
recordings for model training. However, the performances of existing style
transfer methods are still far behind real application needs. The root causes
are mainly twofold. Firstly, the style embedding extracted from single
reference speech can hardly provide fine-grained and appropriate prosody
information for arbitrary text to synthesize. Secondly, in these models the
content/text, prosody, and speaker timbre are usually highly entangled, it&#x27;s
therefore not realistic to expect a satisfied result when freely combining
these components, such as to transfer speaking style between speakers. In this
paper, we propose a cross-speaker style transfer text-to-speech (TTS) model
with explicit prosody bottleneck. The prosody bottleneck builds up the kernels
accounting for speaking style robustly, and disentangles the prosody from
content and speaker timbre, therefore guarantees high quality cross-speaker
style transfer. Evaluation result shows the proposed method even achieves
on-par performance with source speaker&#x27;s speaker-dependent (SD) model in
objective measurement of prosody, and significantly outperforms the cycle
consistency and GMVAE-based baselines in objective and subjective evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Role of Optimization in Double Descent: A Least Squares Study. (arXiv:2107.12685v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuzborskij_I/0/1/0/all/0/1">Ilja Kuzborskij</a>, <a href="http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1">Csaba Szepesv&#xe1;ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivasplata_O/0/1/0/all/0/1">Omar Rivasplata</a>, <a href="http://arxiv.org/find/cs/1/au:+Rannen_Triki_A/0/1/0/all/0/1">Amal Rannen-Triki</a>, <a href="http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1">Razvan Pascanu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12685">
                                    <div class="article-summary-box-inner">
                                        <span>Empirically it has been observed that the performance of deep neural networks
steadily improves as we increase model size, contradicting the classical view
on overfitting and generalization. Recently, the double descent phenomena has
been proposed to reconcile this observation with theory, suggesting that the
test error has a second descent when the model becomes sufficiently
overparameterized, as the model size itself acts as an implicit regularizer. In
this paper we add to the growing body of work in this space, providing a
careful study of learning dynamics as a function of model size for the least
squares scenario. We show an excess risk bound for the gradient descent
solution of the least squares objective. The bound depends on the smallest
non-zero eigenvalue of the covariance matrix of the input features, via a
functional form that has the double descent behavior. This gives a new
perspective on the double descent curves reported in the literature. Our
analysis of the excess risk allows to decouple the effect of optimization and
generalization error. In particular, we find that in case of noiseless
regression, double descent is explained solely by optimization-related
quantities, which was missed in studies focusing on the Moore-Penrose
pseudoinverse solution. We believe that our derivation provides an alternative
view compared to existing work, shedding some light on a possible cause of this
phenomena, at least in the considered least squares setting. We empirically
explore if our predictions hold for neural networks, in particular whether the
covariance of intermediary hidden activations has a similar behavior as the one
predicted by our derivations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Formalising the Use of the Activation Function in Neural Inference. (arXiv:2102.04896v2 [q-bio.NC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Sakthivadivel_D/0/1/0/all/0/1">Dalton A R Sakthivadivel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04896">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate how the activation function can be used to describe neural
firing in an abstract way, and in turn, why it works well in artificial neural
networks. We discuss how a spike in a biological neurone belongs to a
particular universality class of phase transitions in statistical physics. We
then show that the artificial neurone is, mathematically, a mean field model of
biological neural membrane dynamics, which arises from modelling spiking as a
phase transition. This allows us to treat selective neural firing in an
abstract way, and formalise the role of the activation function in perceptron
learning. The resultant statistical physical model allows us to recover the
expressions for some known activation functions as various special cases. Along
with deriving this model and specifying the analogous neural case, we analyse
the phase transition to understand the physics of neural network learning.
Together, it is shown that there is not only a biological meaning, but a
physical justification, for the emergence and performance of typical activation
functions; implications for neural learning and inference are also discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An AI-Assisted Design Method for Topology Optimization Without Pre-Optimized Training Data. (arXiv:2012.06384v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Halle_A/0/1/0/all/0/1">Alex Halle</a>, <a href="http://arxiv.org/find/cs/1/au:+Campanile_L/0/1/0/all/0/1">L. Flavio Campanile</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasse_A/0/1/0/all/0/1">Alexander Hasse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06384">
                                    <div class="article-summary-box-inner">
                                        <span>Topology optimization is widely used by engineers during the initial product
development process to get a first possible geometry design. The
state-of-the-art is the iterative calculation, which requires both time and
computational power. Some newly developed methods use artificial intelligence
to accelerate the topology optimization. These require conventionally
pre-optimized data and therefore are dependent on the quality and number of
available data. This paper proposes an AI-assisted design method for topology
optimization, which does not require pre-optimized data. The designs are
provided by an artificial neural network, the predictor, on the basis of
boundary conditions and degree of filling (the volume percentage filled by
material) as input data. In the training phase, geometries generated on the
basis of random input data are evaluated with respect to given criteria. The
results of those evaluations flow into an objective function which is minimized
by adapting the predictor&#x27;s parameters. After the training is completed, the
presented AI-assisted design procedure supplies geometries which are similar to
the ones generated by conventional topology optimizers, but requires a small
fraction of the computational effort required by those algorithms. We
anticipate our paper to be a starting point for AI-based methods that requires
data, that is hard to compute or not available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Optimization Framework for Training Shallow Neural Networks Using Reachability Method. (arXiv:2107.12801v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yejiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_W/0/1/0/all/0/1">Weiming Xiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12801">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, a robust optimization framework is developed to train shallow
neural networks based on reachability analysis of neural networks. To
characterize noises of input data, the input training data is disturbed in the
description of interval sets. Interval-based reachability analysis is then
performed for the hidden layer. With the reachability analysis results, a
robust optimization training method is developed in the framework of robust
least-square problems. Then, the developed robust least-square problem is
relaxed to a semidefinite programming problem. It has been shown that the
developed robust learning method can provide better robustness against
perturbations at the price of loss of training accuracy to some extent. At
last, the proposed method is evaluated on a robot arm model learning example.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning with Formal Performance Metrics for Quadcopter Attitude Control under Non-nominal Contexts. (arXiv:2107.12942v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bernini_N/0/1/0/all/0/1">Nicola Bernini</a>, <a href="http://arxiv.org/find/cs/1/au:+Bessa_M/0/1/0/all/0/1">Mikhail Bessa</a>, <a href="http://arxiv.org/find/cs/1/au:+Delmas_R/0/1/0/all/0/1">R&#xe9;mi Delmas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gold_A/0/1/0/all/0/1">Arthur Gold</a>, <a href="http://arxiv.org/find/cs/1/au:+Goubault_E/0/1/0/all/0/1">Eric Goubault</a>, <a href="http://arxiv.org/find/cs/1/au:+Pennec_R/0/1/0/all/0/1">Romain Pennec</a>, <a href="http://arxiv.org/find/cs/1/au:+Putot_S/0/1/0/all/0/1">Sylvie Putot</a>, <a href="http://arxiv.org/find/cs/1/au:+Sillion_F/0/1/0/all/0/1">Fran&#xe7;ois Sillion</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12942">
                                    <div class="article-summary-box-inner">
                                        <span>We explore the reinforcement learning approach to designing controllers by
extensively discussing the case of a quadcopter attitude controller. We provide
all details allowing to reproduce our approach, starting with a model of the
dynamics of a crazyflie 2.0 under various nominal and non-nominal conditions,
including partial motor failures and wind gusts. We develop a robust form of a
signal temporal logic to quantitatively evaluate the vehicle&#x27;s behavior and
measure the performance of controllers. The paper thoroughly describes the
choices in training algorithms, neural net architecture, hyperparameters,
observation space in view of the different performance metrics we have
introduced. We discuss the robustness of the obtained controllers, both to
partial loss of power for one rotor and to wind gusts and finish by drawing
conclusions on practical controller design by reinforcement learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parallel Surrogate-assisted Optimization Using Mesh Adaptive Direct Search. (arXiv:2107.12421v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Talgorn_B/0/1/0/all/0/1">Bastien Talgorn</a>, <a href="http://arxiv.org/find/math/1/au:+Alarie_S/0/1/0/all/0/1">St&#xe9;phane Alarie</a>, <a href="http://arxiv.org/find/math/1/au:+Kokkolaras_M/0/1/0/all/0/1">Michael Kokkolaras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12421">
                                    <div class="article-summary-box-inner">
                                        <span>We consider computationally expensive blackbox optimization problems and
present a method that employs surrogate models and concurrent computing at the
search step of the mesh adaptive direct search (MADS) algorithm. Specifically,
we solve a surrogate optimization problem using locally weighted scatterplot
smoothing (LOWESS) models to find promising candidate points to be evaluated by
the blackboxes. We consider several methods for selecting promising points from
a large number of points. We conduct numerical experiments to assess the
performance of the modified MADS algorithm with respect to available CPU
resources by means of five engineering design problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Power Constrained Bandits. (arXiv:2004.06230v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jiayu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1">Emma Brunskill</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Weiwei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Murphy_S/0/1/0/all/0/1">Susan Murphy</a>, <a href="http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1">Finale Doshi-Velez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.06230">
                                    <div class="article-summary-box-inner">
                                        <span>Contextual bandits often provide simple and effective personalization in
decision making problems, making them popular tools to deliver personalized
interventions in mobile health as well as other health applications. However,
when bandits are deployed in the context of a scientific study -- e.g. a
clinical trial to test if a mobile health intervention is effective -- the aim
is not only to personalize for an individual, but also to determine, with
sufficient statistical power, whether or not the system&#x27;s intervention is
effective. It is essential to assess the effectiveness of the intervention
before broader deployment for better resource allocation. The two objectives
are often deployed under different model assumptions, making it hard to
determine how achieving the personalization and statistical power affect each
other. In this work, we develop general meta-algorithms to modify existing
algorithms such that sufficient power is guaranteed while still improving each
user&#x27;s well-being. We also demonstrate that our meta-algorithms are robust to
various model mis-specifications possibly appearing in statistical studies,
thus providing a valuable tool to study designers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clickbait Detection in YouTube Videos. (arXiv:2107.12791v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gothankar_R/0/1/0/all/0/1">Ruchira Gothankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Troia_F/0/1/0/all/0/1">Fabio Di Troia</a>, <a href="http://arxiv.org/find/cs/1/au:+Stamp_M/0/1/0/all/0/1">Mark Stamp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12791">
                                    <div class="article-summary-box-inner">
                                        <span>YouTube videos often include captivating descriptions and intriguing
thumbnails designed to increase the number of views, and thereby increase the
revenue for the person who posted the video. This creates an incentive for
people to post clickbait videos, in which the content might deviate
significantly from the title, description, or thumbnail. In effect, users are
tricked into clicking on clickbait videos. In this research, we consider the
challenging problem of detecting clickbait YouTube videos. We experiment with
multiple state-of-the-art machine learning techniques using a variety of
textual features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedH2L: Federated Learning with Model and Statistical Heterogeneity. (arXiv:2101.11296v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yiying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huaimin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mi_H/0/1/0/all/0/1">Haibo Mi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1">Timothy M. Hospedales</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11296">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) enables distributed participants to collectively
learn a strong global model without sacrificing their individual data privacy.
Mainstream FL approaches require each participant to share a common network
architecture and further assume that data are are sampled IID across
participants. However, in real-world deployments participants may require
heterogeneous network architectures; and the data distribution is almost
certainly non-uniform across participants. To address these issues we introduce
FedH2L, which is agnostic to both the model architecture and robust to
different data distributions across participants. In contrast to approaches
sharing parameters or gradients, FedH2L relies on mutual distillation,
exchanging only posteriors on a shared seed set between participants in a
decentralized manner. This makes it extremely bandwidth efficient, model
agnostic, and crucially produces models capable of performing well on the whole
data distribution when learning from heterogeneous silos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transfer Learning in Electronic Health Records through Clinical Concept Embedding. (arXiv:2107.12919v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Solares_J/0/1/0/all/0/1">Jose Roberto Ayala Solares</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yajie Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassaine_A/0/1/0/all/0/1">Abdelaali Hassaine</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1">Shishir Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yikuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mamouei_M/0/1/0/all/0/1">Mohammad Mamouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Canoy_D/0/1/0/all/0/1">Dexter Canoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahimi_K/0/1/0/all/0/1">Kazem Rahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Salimi_Khorshidi_G/0/1/0/all/0/1">Gholamreza Salimi-Khorshidi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12919">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models have shown tremendous potential in learning
representations, which are able to capture some key properties of the data.
This makes them great candidates for transfer learning: Exploiting
commonalities between different learning tasks to transfer knowledge from one
task to another. Electronic health records (EHR) research is one of the domains
that has witnessed a growing number of deep learning techniques employed for
learning clinically-meaningful representations of medical concepts (such as
diseases and medications). Despite this growth, the approaches to benchmark and
assess such learned representations (or, embeddings) is under-investigated;
this can be a big issue when such embeddings are shared to facilitate transfer
learning. In this study, we aim to (1) train some of the most prominent disease
embedding techniques on a comprehensive EHR data from 3.1 million patients, (2)
employ qualitative and quantitative evaluation techniques to assess these
embeddings, and (3) provide pre-trained disease embeddings for transfer
learning. This study can be the first comprehensive approach for clinical
concept embedding evaluation and can be applied to any embedding techniques and
for any EHR concept.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Realistic Ultrasound Image Synthesis for Improved Classification of Liver Disease. (arXiv:2107.12775v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Che_H/0/1/0/all/0/1">Hui Che</a>, <a href="http://arxiv.org/find/eess/1/au:+Ramanathan_S/0/1/0/all/0/1">Sumana Ramanathan</a>, <a href="http://arxiv.org/find/eess/1/au:+Foran_D/0/1/0/all/0/1">David Foran</a>, <a href="http://arxiv.org/find/eess/1/au:+Nosher_J/0/1/0/all/0/1">John L Nosher</a>, <a href="http://arxiv.org/find/eess/1/au:+Patel_V/0/1/0/all/0/1">Vishal M Patel</a>, <a href="http://arxiv.org/find/eess/1/au:+Hacihaliloglu_I/0/1/0/all/0/1">Ilker Hacihaliloglu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12775">
                                    <div class="article-summary-box-inner">
                                        <span>With the success of deep learning-based methods applied in medical image
analysis, convolutional neural networks (CNNs) have been investigated for
classifying liver disease from ultrasound (US) data. However, the scarcity of
available large-scale labeled US data has hindered the success of CNNs for
classifying liver disease from US data. In this work, we propose a novel
generative adversarial network (GAN) architecture for realistic diseased and
healthy liver US image synthesis. We adopt the concept of stacking to
synthesize realistic liver US data. Quantitative and qualitative evaluation is
performed on 550 in-vivo B-mode liver US images collected from 55 subjects. We
also show that the synthesized images, together with real in vivo data, can be
used to significantly improve the performance of traditional CNN architectures
for Nonalcoholic fatty liver disease (NAFLD) classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Entropy Maximization and Meta Classification for Out-Of-Distribution Detection in Semantic Segmentation. (arXiv:2012.06575v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chan_R/0/1/0/all/0/1">Robin Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1">Matthias Rottmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Gottschalk_H/0/1/0/all/0/1">Hanno Gottschalk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06575">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) for the semantic segmentation of images are
usually trained to operate on a predefined closed set of object classes. This
is in contrast to the &quot;open world&quot; setting where DNNs are envisioned to be
deployed to. From a functional safety point of view, the ability to detect
so-called &quot;out-of-distribution&quot; (OoD) samples, i.e., objects outside of a DNN&#x27;s
semantic space, is crucial for many applications such as automated driving. A
natural baseline approach to OoD detection is to threshold on the pixel-wise
softmax entropy. We present a two-step procedure that significantly improves
that approach. Firstly, we utilize samples from the COCO dataset as OoD proxy
and introduce a second training objective to maximize the softmax entropy on
these samples. Starting from pretrained semantic segmentation networks we
re-train a number of DNNs on different in-distribution datasets and
consistently observe improved OoD detection performance when evaluating on
completely disjoint OoD datasets. Secondly, we perform a transparent
post-processing step to discard false positive OoD samples by so-called &quot;meta
classification&quot;. To this end, we apply linear models to a set of hand-crafted
metrics derived from the DNN&#x27;s softmax probabilities. In our experiments we
consistently observe a clear additional gain in OoD detection performance,
cutting down the number of detection errors by up to 52% when comparing the
best baseline with our results. We achieve this improvement sacrificing only
marginally in original segmentation performance. Therefore, our method
contributes to safer DNNs with more reliable overall system performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Frozen-to-Paraffin: Categorization of Histological Frozen Sections by the Aid of Paraffin Sections and Generative Adversarial Networks. (arXiv:2012.08158v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gadermayr_M/0/1/0/all/0/1">Michael Gadermayr</a>, <a href="http://arxiv.org/find/eess/1/au:+Tschuchnig_M/0/1/0/all/0/1">Maximilian Tschuchnig</a>, <a href="http://arxiv.org/find/eess/1/au:+Stangassinger_L/0/1/0/all/0/1">Lea Maria Stangassinger</a>, <a href="http://arxiv.org/find/eess/1/au:+Kreutzer_C/0/1/0/all/0/1">Christina Kreutzer</a>, <a href="http://arxiv.org/find/eess/1/au:+Couillard_Despres_S/0/1/0/all/0/1">Sebastien Couillard-Despres</a>, <a href="http://arxiv.org/find/eess/1/au:+Oostingh_G/0/1/0/all/0/1">Gertie Janneke Oostingh</a>, <a href="http://arxiv.org/find/eess/1/au:+Hittmair_A/0/1/0/all/0/1">Anton Hittmair</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08158">
                                    <div class="article-summary-box-inner">
                                        <span>In contrast to paraffin sections, frozen sections can be quickly generated
during surgical interventions. This procedure allows surgeons to wait for
histological findings during the intervention to base intra-operative decisions
on the outcome of the histology. However, compared to paraffin sections, the
quality of frozen sections is typically lower, leading to a higher ratio of
miss-classification. In this work, we investigated the effect of the section
type on automated decision support approaches for classification of thyroid
cancer. This was enabled by a data set consisting of pairs of sections for
individual patients. Moreover, we investigated, whether a frozen-to-paraffin
translation could help to optimize classification scores. Finally, we propose a
specific data augmentation strategy to deal with a small amount of training
data and to increase classification accuracy even further.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Greedy Gradient Ensemble for Robust Visual Question Answering. (arXiv:2107.12651v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xinzhe Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuhui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1">Chi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qingming Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12651">
                                    <div class="article-summary-box-inner">
                                        <span>Language bias is a critical issue in Visual Question Answering (VQA), where
models often exploit dataset biases for the final decision without considering
the image information. As a result, they suffer from performance drop on
out-of-distribution data and inadequate visual explanation. Based on
experimental analysis for existing robust VQA methods, we stress the language
bias in VQA that comes from two aspects, i.e., distribution bias and shortcut
bias. We further propose a new de-bias framework, Greedy Gradient Ensemble
(GGE), which combines multiple biased models for unbiased base model learning.
With the greedy strategy, GGE forces the biased models to over-fit the biased
data distribution in priority, thus makes the base model pay more attention to
examples that are hard to solve by biased models. The experiments demonstrate
that our method makes better use of visual information and achieves
state-of-the-art performance on diagnosing dataset VQA-CP without using extra
annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Adversarial User Privacy in Lossy Single-Server Information Retrieval. (arXiv:2012.03902v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weng_C/0/1/0/all/0/1">Chung-Wei Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yakimenka_Y/0/1/0/all/0/1">Yauhen Yakimenka</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hsuan-Yin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rosnes_E/0/1/0/all/0/1">Eirik Rosnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Kliewer_J/0/1/0/all/0/1">Joerg Kliewer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03902">
                                    <div class="article-summary-box-inner">
                                        <span>We propose to extend the concept of private information retrieval by allowing
for distortion in the retrieval process and relaxing the perfect privacy
requirement at the same time. In particular, we study the tradeoff between
download rate, distortion, and user privacy leakage, and show that in the limit
of large file sizes this trade-off can be captured via a novel
information-theoretical formulation for datasets with a known distribution.
Moreover, for scenarios where the statistics of the dataset is unknown, we
propose a new deep learning framework by leveraging a generative adversarial
network approach, which allows the user to learn efficient schemes from the
data itself, minimizing the download cost. We evaluate the performance of the
scheme on a synthetic Gaussian dataset as well as on both the MNIST and
CIFAR-10 datasets. For the MNIST dataset, the data-driven approach
significantly outperforms a non-learning based scheme which combines source
coding with multiple file download, while the CIFAR-10 performance is notably
better.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Verifiable Coded Computing: Towards Fast, Secure and Private Distributed Machine Learning. (arXiv:2107.12958v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1">Tingting Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_R/0/1/0/all/0/1">Ramy E. Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_H/0/1/0/all/0/1">Hanieh Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangwani_T/0/1/0/all/0/1">Tynan Gangwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1">Salman Avestimehr</a>, <a href="http://arxiv.org/find/cs/1/au:+Annavaram_M/0/1/0/all/0/1">Murali Annavaram</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12958">
                                    <div class="article-summary-box-inner">
                                        <span>Stragglers, Byzantine workers, and data privacy are the main bottlenecks in
distributed cloud computing. Several prior works proposed coded computing
strategies to jointly address all three challenges. They require either a large
number of workers, a significant communication cost or a significant
computational complexity to tolerate malicious workers. Much of the overhead in
prior schemes comes from the fact that they tightly couple coding for all three
problems into a single framework. In this work, we propose Verifiable Coded
Computing (VCC) framework that decouples Byzantine node detection challenge
from the straggler tolerance. VCC leverages coded computing just for handling
stragglers and privacy, and then uses an orthogonal approach of verifiable
computing to tackle Byzantine nodes. Furthermore, VCC dynamically adapts its
coding scheme to tradeoff straggler tolerance with Byzantine protection and
vice-versa. We evaluate VCC on compute intensive distributed logistic
regression application. Our experiments show that VCC speeds up the
conventional uncoded implementation of distributed logistic regression by
$3.2\times-6.9\times$, and also improves the test accuracy by up to $12.6\%$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Restricted Boltzmann Machine and Deep Belief Network: Tutorial and Survey. (arXiv:2107.12521v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghojogh_B/0/1/0/all/0/1">Benyamin Ghojogh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghodsi_A/0/1/0/all/0/1">Ali Ghodsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Karray_F/0/1/0/all/0/1">Fakhri Karray</a>, <a href="http://arxiv.org/find/cs/1/au:+Crowley_M/0/1/0/all/0/1">Mark Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12521">
                                    <div class="article-summary-box-inner">
                                        <span>This is a tutorial and survey paper on Boltzmann Machine (BM), Restricted
Boltzmann Machine (RBM), and Deep Belief Network (DBN). We start with the
required background on probabilistic graphical models, Markov random field,
Gibbs sampling, statistical physics, Ising model, and the Hopfield network.
Then, we introduce the structures of BM and RBM. The conditional distributions
of visible and hidden variables, Gibbs sampling in RBM for generating
variables, training BM and RBM by maximum likelihood estimation, and
contrastive divergence are explained. Then, we discuss different possible
discrete and continuous distributions for the variables. We introduce
conditional RBM and how it is trained. Finally, we explain deep belief network
as a stack of RBM models. This paper on Boltzmann machines can be useful in
various fields including data science, statistics, neural computation, and
statistical physics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Synergy, Redundancy, and Independence in Global Model Explanations using SHAP Vector Decomposition. (arXiv:2107.12436v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ittner_J/0/1/0/all/0/1">Jan Ittner</a>, <a href="http://arxiv.org/find/cs/1/au:+Bolikowski_L/0/1/0/all/0/1">Lukasz Bolikowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Hemker_K/0/1/0/all/0/1">Konstantin Hemker</a>, <a href="http://arxiv.org/find/cs/1/au:+Kennedy_R/0/1/0/all/0/1">Ricardo Kennedy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12436">
                                    <div class="article-summary-box-inner">
                                        <span>We offer a new formalism for global explanations of pairwise feature
dependencies and interactions in supervised models. Building upon SHAP values
and SHAP interaction values, our approach decomposes feature contributions into
synergistic, redundant and independent components (S-R-I decomposition of SHAP
vectors). We propose a geometric interpretation of the components and formally
prove its basic properties. Finally, we demonstrate the utility of synergy,
redundancy and independence by applying them to a constructed data set and
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Thompson Sampling strategies for support-aware CVaR bandits. (arXiv:2012.05754v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baudry_D/0/1/0/all/0/1">Dorian Baudry</a>, <a href="http://arxiv.org/find/cs/1/au:+Gautron_R/0/1/0/all/0/1">Romain Gautron</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaufmann_E/0/1/0/all/0/1">Emilie Kaufmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Maillard_O/0/1/0/all/0/1">Odalric-Ambryn Maillard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05754">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we study a multi-arm bandit problem in which the quality of
each arm is measured by the Conditional Value at Risk (CVaR) at some level
alpha of the reward distribution. While existing works in this setting mainly
focus on Upper Confidence Bound algorithms, we introduce a new Thompson
Sampling approach for CVaR bandits on bounded rewards that is flexible enough
to solve a variety of problems grounded on physical resources. Building on a
recent work by Riou &amp; Honda (2020), we introduce B-CVTS for continuous bounded
rewards and M-CVTS for multinomial distributions. On the theoretical side, we
provide a non-trivial extension of their analysis that enables to theoretically
bound their CVaR regret minimization performance. Strikingly, our results show
that these strategies are the first to provably achieve asymptotic optimality
in CVaR bandits, matching the corresponding asymptotic lower bounds for this
setting. Further, we illustrate empirically the benefit of Thompson Sampling
approaches both in a realistic environment simulating a use-case in agriculture
and on various synthetic examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Small-loss bounds for online learning with partial information. (arXiv:1711.03639v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lykouris_T/0/1/0/all/0/1">Thodoris Lykouris</a>, <a href="http://arxiv.org/find/cs/1/au:+Sridharan_K/0/1/0/all/0/1">Karthik Sridharan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tardos_E/0/1/0/all/0/1">Eva Tardos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1711.03639">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of adversarial (non-stochastic) online learning with
partial information feedback, where at each round, a decision maker selects an
action from a finite set of alternatives. We develop a black-box approach for
such problems where the learner observes as feedback only losses of a subset of
the actions that includes the selected action. When losses of actions are
non-negative, under the graph-based feedback model introduced by Mannor and
Shamir, we offer algorithms that attain the so called &quot;small-loss&quot; $o(\alpha
L^{\star})$ regret bounds with high probability, where $\alpha$ is the
independence number of the graph, and $L^{\star}$ is the loss of the best
action. Prior to our work, there was no data-dependent guarantee for general
feedback graphs even for pseudo-regret (without dependence on the number of
actions, i.e. utilizing the increased information feedback). Taking advantage
of the black-box nature of our technique, we extend our results to many other
applications such as semi-bandits (including routing in networks), contextual
bandits (even with an infinite comparator class), as well as learning with
slowly changing (shifting) comparators.

In the special case of classical bandit and semi-bandit problems, we provide
optimal small-loss, high-probability guarantees of
$\tilde{O}(\sqrt{dL^{\star}})$ for actual regret, where $d$ is the number of
actions, answering open questions of Neu. Previous bounds for bandits and
semi-bandits were known only for pseudo-regret and only in expectation. We also
offer an optimal $\tilde{O}(\sqrt{\kappa L^{\star}})$ regret guarantee for
fixed feedback graphs with clique-partition number at most $\kappa$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Graph Attention Network with Fast Eigen-approximation. (arXiv:2003.07450v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Heng Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1">Yu Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tingyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wenbing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sojoudi_S/0/1/0/all/0/1">Somayeh Sojoudi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junzhou Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wenwu Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.07450">
                                    <div class="article-summary-box-inner">
                                        <span>Variants of Graph Neural Networks (GNNs) for representation learning have
been proposed recently and achieved fruitful results in various fields. Among
them, Graph Attention Network (GAT) first employs a self-attention strategy to
learn attention weights for each edge in the spatial domain. However, learning
the attentions over edges can only focus on the local information of graphs and
greatly increases the computational costs. In this paper, we first introduce
the attention mechanism in the spectral domain of graphs and present Spectral
Graph Attention Network (SpGAT) that learns representations for different
frequency components regarding weighted filters and graph wavelets bases. In
this way, SpGAT can better capture global patterns of graphs in an efficient
manner with much fewer learned parameters than that of GAT. Further, to reduce
the computational cost of SpGAT brought by the eigen-decomposition, we propose
a fast approximation variant SpGAT-Cheby. We thoroughly evaluate the
performance of SpGAT and SpGAT-Cheby in semi-supervised node classification
tasks and verify the effectiveness of the learned attentions in the spectral
domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Channel-Wise Early Stopping without a Validation Set via NNK Polytope Interpolation. (arXiv:2107.12972v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bonet_D/0/1/0/all/0/1">David Bonet</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_A/0/1/0/all/0/1">Antonio Ortega</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruiz_Hidalgo_J/0/1/0/all/0/1">Javier Ruiz-Hidalgo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekkizhar_S/0/1/0/all/0/1">Sarath Shekkizhar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12972">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art neural network architectures continue to scale in size and
deliver impressive generalization results, although this comes at the expense
of limited interpretability. In particular, a key challenge is to determine
when to stop training the model, as this has a significant impact on
generalization. Convolutional neural networks (ConvNets) comprise
high-dimensional feature spaces formed by the aggregation of multiple channels,
where analyzing intermediate data representations and the model&#x27;s evolution can
be challenging owing to the curse of dimensionality. We present channel-wise
DeepNNK (CW-DeepNNK), a novel channel-wise generalization estimate based on
non-negative kernel regression (NNK) graphs with which we perform local
polytope interpolation on low-dimensional channels. This method leads to
instance-based interpretability of both the learned data representations and
the relationship between channels. Motivated by our observations, we use
CW-DeepNNK to propose a novel early stopping criterion that (i) does not
require a validation set, (ii) is based on a task performance metric, and (iii)
allows stopping to be reached at different points for each channel. Our
experiments demonstrate that our proposed method has advantages as compared to
the standard criterion based on validation set performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Competition in Cross-situational Word Learning: A Computational Study. (arXiv:2012.03370v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nematzadeh_A/0/1/0/all/0/1">Aida Nematzadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarchi_Z/0/1/0/all/0/1">Zahra Shekarchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1">Thomas L. Griffiths</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevenson_S/0/1/0/all/0/1">Suzanne Stevenson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03370">
                                    <div class="article-summary-box-inner">
                                        <span>Children learn word meanings by tapping into the commonalities across
different situations in which words are used and overcome the high level of
uncertainty involved in early word learning experiences. We propose a modeling
framework to investigate the role of mutual exclusivity bias - asserting
one-to-one mappings between words and their meanings - in reducing uncertainty
in word learning. In a set of computational studies, we show that to
successfully learn word meanings in the face of uncertainty, a learner needs to
use two types of competition: words competing for association to a referent
when learning from an observation and referents competing for a word when the
word is used. Our work highlights the importance of an algorithmic-level
analysis to shed light on the utility of different mechanisms that can
implement the same computational-level theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic sparse adversarial attacks. (arXiv:2011.12423v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cesaire_M/0/1/0/all/0/1">Manon C&#xe9;saire</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajri_H/0/1/0/all/0/1">Hatem Hajri</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamprier_S/0/1/0/all/0/1">Sylvain Lamprier</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallinari_P/0/1/0/all/0/1">Patrick Gallinari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12423">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces stochastic sparse adversarial attacks (SSAA), simple,
fast and purely noise-based targeted and untargeted $L_0$ attacks of neural
network classifiers (NNC). SSAA are devised by exploiting a simple small-time
expansion idea widely used for Markov processes and offer new examples of $L_0$
attacks whose studies have been limited. They are designed to solve the known
scalability issue of the family of Jacobian-based saliency maps attacks to
large datasets and they succeed in solving it. Experiments on small and large
datasets (CIFAR-10 and ImageNet) illustrate further advantages of SSAA in
comparison with the-state-of-the-art methods. For instance, in the untargeted
case, our method called Voting Folded Gaussian Attack (VFGA) scales efficiently
to ImageNet and achieves a significantly lower $L_0$ score than SparseFool (up
to $\frac{2}{5}$ lower) while being faster. Moreover, VFGA achieves better
$L_0$ scores on ImageNet than Sparse-RS when both attacks are fully successful
on a large number of samples. Codes are publicly available through the link
https://github.com/SSAA3/stochastic-sparse-adv-attacks</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Persistent Reinforcement Learning via Subgoal Curricula. (arXiv:2107.12931v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Archit Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1">Abhishek Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1">Karol Hausman</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12931">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) promises to enable autonomous acquisition of
complex behaviors for diverse agents. However, the success of current
reinforcement learning algorithms is predicated on an often under-emphasised
requirement -- each trial needs to start from a fixed initial state
distribution. Unfortunately, resetting the environment to its initial state
after each trial requires substantial amount of human supervision and extensive
instrumentation of the environment which defeats the purpose of autonomous
reinforcement learning. In this work, we propose Value-accelerated Persistent
Reinforcement Learning (VaPRL), which generates a curriculum of initial states
such that the agent can bootstrap on the success of easier tasks to efficiently
learn harder tasks. The agent also learns to reach the initial states proposed
by the curriculum, minimizing the reliance on human interventions into the
learning. We observe that VaPRL reduces the interventions required by three
orders of magnitude compared to episodic RL while outperforming prior
state-of-the art methods for reset-free RL both in terms of sample efficiency
and asymptotic performance on a variety of simulated robotics problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Simplified Framework for Air Route Clustering Based on ADS-B Data. (arXiv:2107.12869v1 [physics.soc-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Duong_Q/0/1/0/all/0/1">Quan Duong</a>, <a href="http://arxiv.org/find/physics/1/au:+Tran_T/0/1/0/all/0/1">Tan Tran</a>, <a href="http://arxiv.org/find/physics/1/au:+Pham_D/0/1/0/all/0/1">Duc-Thinh Pham</a>, <a href="http://arxiv.org/find/physics/1/au:+Mai_A/0/1/0/all/0/1">An Mai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12869">
                                    <div class="article-summary-box-inner">
                                        <span>The volume of flight traffic gets increasing over the time, which makes the
strategic traffic flow management become one of the challenging problems since
it requires a lot of computational resources to model entire traffic data. On
the other hand, Automatic Dependent Surveillance - Broadcast (ADS-B) technology
has been considered as a promising data technology to provide both flight crews
and ground control staff the necessary information safely and efficiently about
the position and velocity of the airplanes in a specific area. In the attempt
to tackle this problem, we presented in this paper a simplified framework that
can support to detect the typical air routes between airports based on ADS-B
data. Specifically, the flight traffic will be classified into major groups
based on similarity measures, which helps to reduce the number of flight paths
between airports. As a matter of fact, our framework can be taken into account
to reduce practically the computational cost for air flow optimization and
evaluate the operational performance. Finally, in order to illustrate the
potential applications of our proposed framework, an experiment was performed
using ADS-B traffic flight data of three different pairs of airports. The
detected typical routes between each couple of airports show promising results
by virtue of combining two indices for measuring the clustering performance and
incorporating human judgment into the visual inspection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Data-driven feature selection and machine-learning model benchmark for the prediction of longitudinal dispersion coefficient. (arXiv:2107.12970v1 [physics.geo-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Zhao_Y/0/1/0/all/0/1">Yifeng Zhao</a>, <a href="http://arxiv.org/find/physics/1/au:+Zhang_P/0/1/0/all/0/1">Pei Zhang</a>, <a href="http://arxiv.org/find/physics/1/au:+Galindo_Torres_S/0/1/0/all/0/1">S.A. Galindo-Torres</a>, <a href="http://arxiv.org/find/physics/1/au:+Li_S/0/1/0/all/0/1">Stan Z. Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12970">
                                    <div class="article-summary-box-inner">
                                        <span>Longitudinal Dispersion(LD) is the dominant process of scalar transport in
natural streams. An accurate prediction on LD coefficient(Dl) can produce a
performance leap in related simulation. The emerging machine learning(ML)
techniques provide a self-adaptive tool for this problem. However, most of the
existing studies utilize an unproved quaternion feature set, obtained through
simple theoretical deduction. Few studies have put attention on its reliability
and rationality. Besides, due to the lack of comparative comparison, the proper
choice of ML models in different scenarios still remains unknown. In this
study, the Feature Gradient selector was first adopted to distill the local
optimal feature sets directly from multivariable data. Then, a global optimal
feature set (the channel width, the flow velocity, the channel slope and the
cross sectional area) was proposed through numerical comparison of the
distilled local optimums in performance with representative ML models. The
channel slope is identified to be the key parameter for the prediction of LDC.
Further, we designed a weighted evaluation metric which enables comprehensive
model comparison. With the simple linear model as the baseline, a benchmark of
single and ensemble learning models was provided. Advantages and disadvantages
of the methods involved were also discussed. Results show that the support
vector machine has significantly better performance than other models. Decision
tree is not suitable for this problem due to poor generalization ability.
Notably, simple models show superiority over complicated model on this
low-dimensional problem, for their better balance between regression and
generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Operating Points for High Performance Lesion Detection and Segmentation Using Lesion Size Reweighting. (arXiv:2107.12978v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Nichyporuk_B/0/1/0/all/0/1">Brennan Nichyporuk</a>, <a href="http://arxiv.org/find/eess/1/au:+Szeto_J/0/1/0/all/0/1">Justin Szeto</a>, <a href="http://arxiv.org/find/eess/1/au:+Arnold_D/0/1/0/all/0/1">Douglas L. Arnold</a>, <a href="http://arxiv.org/find/eess/1/au:+Arbel_T/0/1/0/all/0/1">Tal Arbel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12978">
                                    <div class="article-summary-box-inner">
                                        <span>There are many clinical contexts which require accurate detection and
segmentation of all focal pathologies (e.g. lesions, tumours) in patient
images. In cases where there are a mix of small and large lesions, standard
binary cross entropy loss will result in better segmentation of large lesions
at the expense of missing small ones. Adjusting the operating point to
accurately detect all lesions generally leads to oversegmentation of large
lesions. In this work, we propose a novel reweighing strategy to eliminate this
performance gap, increasing small pathology detection performance while
maintaining segmentation accuracy. We show that our reweighing strategy vastly
outperforms competing strategies based on experiments on a large scale,
multi-scanner, multi-center dataset of Multiple Sclerosis patient images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Numeric Optimal Differentially Private Truncated Additive Mechanisms. (arXiv:2107.12957v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sommer_D/0/1/0/all/0/1">David M. Sommer</a>, <a href="http://arxiv.org/find/cs/1/au:+Abfalterer_L/0/1/0/all/0/1">Lukas Abfalterer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zingg_S/0/1/0/all/0/1">Sheila Zingg</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohammadi_E/0/1/0/all/0/1">Esfandiar Mohammadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12957">
                                    <div class="article-summary-box-inner">
                                        <span>Differentially private (DP) mechanisms face the challenge of providing
accurate results while protecting their inputs: the privacy-utility trade-off.
A simple but powerful technique for DP adds noise to sensitivity-bounded query
outputs to blur the exact query output: additive mechanisms. While a vast body
of work considers infinitely wide noise distributions, some applications (e.g.,
real-time operating systems) require hard bounds on the deviations from the
real query, and only limited work on such mechanisms exist. An additive
mechanism with truncated noise (i.e., with bounded range) can offer such hard
bounds. We introduce a gradient-descent-based tool to learn truncated noise for
additive mechanisms with strong utility bounds while simultaneously optimizing
for differential privacy under sequential composition, i.e., scenarios where
multiple noisy queries on the same data are revealed. Our method can learn
discrete noise patterns and not only hyper-parameters of a predefined
probability distribution. For sensitivity bounded mechanisms, we show that it
is sufficient to consider symmetric and that\new{, for from the mean
monotonically falling noise,} ensuring privacy for a pair of representative
query outputs guarantees privacy for all pairs of inputs (that differ in one
element). We find that the utility-privacy trade-off curves of our generated
noise are remarkably close to truncated Gaussians and even replicate their
shape for $l_2$ utility-loss. For a low number of compositions, we also
improved DP-SGD (sub-sampling). Moreover, we extend Moments Accountant to
truncated distributions, allowing to incorporate mechanism output events with
varying input-dependent zero occurrence probability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Low-Cost Neural ODE with Depthwise Separable Convolution for Edge Domain Adaptation on FPGAs. (arXiv:2107.12824v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kawakami_H/0/1/0/all/0/1">Hiroki Kawakami</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_H/0/1/0/all/0/1">Hirohisa Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiura_K/0/1/0/all/0/1">Keisuke Sugiura</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsutani_H/0/1/0/all/0/1">Hiroki Matsutani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12824">
                                    <div class="article-summary-box-inner">
                                        <span>Although high-performance deep neural networks are in high demand in edge
environments, computation resources are strictly limited in edge devices, and
light-weight neural network techniques, such as Depthwise Separable Convolution
(DSC), have been developed. ResNet is one of conventional deep neural network
models that stack a lot of layers and parameters for a higher accuracy. To
reduce the parameter size of ResNet, by utilizing a similarity to ODE (Ordinary
Differential Equation), Neural ODE repeatedly uses most of weight parameters
instead of having a lot of different parameters. Thus, Neural ODE becomes
significantly small compared to that of ResNet so that it can be implemented in
resource-limited edge devices. In this paper, a combination of Neural ODE and
DSC, called dsODENet, is designed and implemented for FPGAs (Field-Programmable
Gate Arrays). dsODENet is then applied to edge domain adaptation as a practical
use case and evaluated with image classification datasets. It is implemented on
Xilinx ZCU104 board and evaluated in terms of domain adaptation accuracy,
training speed, FPGA resource utilization, and speedup rate compared to a
software execution. The results demonstrate that dsODENet is comparable to or
slightly better than our baseline Neural ODE implementation in terms of domain
adaptation accuracy, while the total parameter size without pre- and
post-processing layers is reduced by 54.2% to 79.8%. The FPGA implementation
accelerates the prediction tasks by 27.9 times faster than a software
implementation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Prediction Residual for Efficient Diagnosis of Parkinson&#x27;s Disease from Gait. (arXiv:2107.12878v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Alle_S/0/1/0/all/0/1">Shanmukh Alle</a>, <a href="http://arxiv.org/find/eess/1/au:+Priyakumar_U/0/1/0/all/0/1">U. Deva Priyakumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12878">
                                    <div class="article-summary-box-inner">
                                        <span>Parkinson&#x27;s Disease (PD) is a chronic and progressive neurological disorder
that results in rigidity, tremors and postural instability. There is no
definite medical test to diagnose PD and diagnosis is mostly a clinical
exercise. Although guidelines exist, about 10-30% of the patients are wrongly
diagnosed with PD. Hence, there is a need for an accurate, unbiased and fast
method for diagnosis. In this study, we propose LPGNet, a fast and accurate
method to diagnose PD from gait. LPGNet uses Linear Prediction Residuals (LPR)
to extract discriminating patterns from gait recordings and then uses a 1D
convolution neural network with depth-wise separable convolutions to perform
diagnosis. LPGNet achieves an AUC of 0.91 with a 21 times speedup and about 99%
lesser parameters in the model compared to the state of the art. We also
undertake an analysis of various cross-validation strategies used in literature
in PD diagnosis from gait and find that most methods are affected by some form
of data leakage between various folds which leads to unnecessarily large models
and inflated performance due to overfitting. The analysis clears the path for
future works in correctly evaluating their methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparse Bayesian Deep Learning for Dynamic System Identification. (arXiv:2107.12910v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhou_H/0/1/0/all/0/1">Hongpeng Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Ibrahim_C/0/1/0/all/0/1">Chahine Ibrahim</a>, <a href="http://arxiv.org/find/eess/1/au:+Zheng_W/0/1/0/all/0/1">Wei Xing Zheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Pan_W/0/1/0/all/0/1">Wei Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12910">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a sparse Bayesian treatment of deep neural networks
(DNNs) for system identification. Although DNNs show impressive approximation
ability in various fields, several challenges still exist for system
identification problems. First, DNNs are known to be too complex that they can
easily overfit the training data. Second, the selection of the input regressors
for system identification is nontrivial. Third, uncertainty quantification of
the model parameters and predictions are necessary. The proposed Bayesian
approach offers a principled way to alleviate the above challenges by marginal
likelihood/model evidence approximation and structured group sparsity-inducing
priors construction. The identification algorithm is derived as an iterative
regularized optimization procedure that can be solved as efficiently as
training typical DNNs. Furthermore, a practical calculation approach based on
the Monte-Carlo integration method is derived to quantify the uncertainty of
the parameters and predictions. The effectiveness of the proposed Bayesian
approach is demonstrated on several linear and nonlinear systems identification
benchmarks with achieving good and competitive simulation accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Physiologically-adapted Gold Standard for Arousal During a Stress Induced Scenario. (arXiv:2107.12964v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baird_A/0/1/0/all/0/1">Alice Baird</a>, <a href="http://arxiv.org/find/cs/1/au:+Stappen_L/0/1/0/all/0/1">Lukas Stappen</a>, <a href="http://arxiv.org/find/cs/1/au:+Christ_L/0/1/0/all/0/1">Lukas Christ</a>, <a href="http://arxiv.org/find/cs/1/au:+Schumann_L/0/1/0/all/0/1">Lea Schumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Messner_E/0/1/0/all/0/1">Eva-Maria Me&#xdf;ner</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn W. Schuller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12964">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion is an inherently subjective psychophysiological human-state and to
produce an agreed-upon representation (gold standard) for continuous emotion
requires a time-consuming and costly training procedure of multiple human
annotators. There is strong evidence in the literature that physiological
signals are sufficient objective markers for states of emotion, particularly
arousal. In this contribution, we utilise a dataset which includes continuous
emotion and physiological signals - Heartbeats per Minute (BPM), Electrodermal
Activity (EDA), and Respiration-rate - captured during a stress induced
scenario (Trier Social Stress Test). We utilise a Long Short-Term Memory,
Recurrent Neural Network to explore the benefit of fusing these physiological
signals with arousal as the target, learning from various audio, video, and
textual based features. We utilise the state-of-the-art MuSe-Toolbox to
consider both annotation delay and inter-rater agreement weighting when fusing
the target signals. An improvement in Concordance Correlation Coefficient (CCC)
is seen across features sets when fusing EDA with arousal, compared to the
arousal only gold standard results. Additionally, BERT-based textual features&#x27;
results improved for arousal plus all physiological signals, obtaining up to
.3344 CCC compared to .2118 CCC for arousal only. Multimodal fusion also
improves overall CCC with audio plus video features obtaining up to .6157 CCC
to recognize arousal plus EDA and BPM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Dimensional Distribution Generation Through Deep Neural Networks. (arXiv:2107.12466v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perekrestenko_D/0/1/0/all/0/1">Dmytro Perekrestenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Eberhard_L/0/1/0/all/0/1">L&#xe9;andre Eberhard</a>, <a href="http://arxiv.org/find/cs/1/au:+Bolcskei_H/0/1/0/all/0/1">Helmut B&#xf6;lcskei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12466">
                                    <div class="article-summary-box-inner">
                                        <span>We show that every $d$-dimensional probability distribution of bounded
support can be generated through deep ReLU networks out of a $1$-dimensional
uniform input distribution. What is more, this is possible without incurring a
cost - in terms of approximation error measured in Wasserstein-distance -
relative to generating the $d$-dimensional target distribution from $d$
independent random variables. This is enabled by a vast generalization of the
space-filling approach discovered in (Bailey &amp; Telgarsky, 2018). The
construction we propose elicits the importance of network depth in driving the
Wasserstein distance between the target distribution and its neural network
approximation to zero. Finally, we find that, for histogram target
distributions, the number of bits needed to encode the corresponding generative
network equals the fundamental limit for encoding probability distributions as
dictated by quantization theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bayesian Optimisation for Sequential Experimental Design with Applications in Additive Manufacturing. (arXiv:2107.12809v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mimi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Parnell_A/0/1/0/all/0/1">Andrew Parnell</a>, <a href="http://arxiv.org/find/cs/1/au:+Brabazon_D/0/1/0/all/0/1">Dermot Brabazon</a>, <a href="http://arxiv.org/find/cs/1/au:+Benavoli_A/0/1/0/all/0/1">Alessio Benavoli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12809">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian optimization (BO) is an approach to globally optimizing black-box
objective functions that are expensive to evaluate. BO-powered experimental
design has found wide application in materials science, chemistry, experimental
physics, drug development, etc. This work aims to bring attention to the
benefits of applying BO in designing experiments and to provide a BO manual,
covering both methodology and software, for the convenience of anyone who wants
to apply or learn BO. In particular, we briefly explain the BO technique,
review all the applications of BO in additive manufacturing, compare and
exemplify the features of different open BO libraries, unlock new potential
applications of BO to other types of data (e.g., preferential output). This
article is aimed at readers with some understanding of Bayesian methods, but
not necessarily with knowledge of additive manufacturing; the software
performance overview and implementation instructions are instrumental for any
experimental-design practitioner. Moreover, our review in the field of additive
manufacturing highlights the current knowledge and technological trends of BO.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The social dilemma in AI development and why we have to solve it. (arXiv:2107.12977v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Strumke_I/0/1/0/all/0/1">Inga Str&#xfc;mke</a>, <a href="http://arxiv.org/find/cs/1/au:+Slavkovik_M/0/1/0/all/0/1">Marija Slavkovik</a>, <a href="http://arxiv.org/find/cs/1/au:+Madai_V/0/1/0/all/0/1">Vince Madai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12977">
                                    <div class="article-summary-box-inner">
                                        <span>While the demand for ethical artificial intelligence (AI) systems increases,
the number of unethical uses of AI accelerates, even though there is no
shortage of ethical guidelines. We argue that a main underlying cause for this
is that AI developers face a social dilemma in AI development ethics,
preventing the widespread adaptation of ethical best practices. We define the
social dilemma for AI development and describe why the current crisis in AI
development ethics cannot be solved without relieving AI developers of their
social dilemma. We argue that AI development must be professionalised to
overcome the social dilemma, and discuss how medicine can be used as a template
in this process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Autoencoders for Embedding Learning in Brain Networks and Major Depressive Disorder Identification. (arXiv:2107.12838v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Noman_F/0/1/0/all/0/1">Fuad Noman</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ting_C/0/1/0/all/0/1">Chee-Ming Ting</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kang_H/0/1/0/all/0/1">Hakmook Kang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Phan_R/0/1/0/all/0/1">Raphael C.-W. Phan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Boyd_B/0/1/0/all/0/1">Brian D. Boyd</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Taylor_W/0/1/0/all/0/1">Warren D. Taylor</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ombao_H/0/1/0/all/0/1">Hernando Ombao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12838">
                                    <div class="article-summary-box-inner">
                                        <span>Brain functional connectivity (FC) reveals biomarkers for identification of
various neuropsychiatric disorders. Recent application of deep neural networks
(DNNs) to connectome-based classification mostly relies on traditional
convolutional neural networks using input connectivity matrices on a regular
Euclidean grid. We propose a graph deep learning framework to incorporate the
non-Euclidean information about graph structure for classifying functional
magnetic resonance imaging (fMRI)- derived brain networks in major depressive
disorder (MDD). We design a novel graph autoencoder (GAE) architecture based on
the graph convolutional networks (GCNs) to embed the topological structure and
node content of large-sized fMRI networks into low-dimensional latent
representations. In network construction, we employ the Ledoit-Wolf (LDW)
shrinkage method to estimate the high-dimensional FC metrics efficiently from
fMRI data. We consider both supervised and unsupervised approaches for the
graph embedded learning. The learned embeddings are then used as feature inputs
for a deep fully-connected neural network (FCNN) to discriminate MDD from
healthy controls. Evaluated on a resting-state fMRI MDD dataset with 43
subjects, results show that the proposed GAE-FCNN model significantly
outperforms several state-of-the-art DNN methods for brain connectome
classification, achieving accuracy of 72.50% using the LDW-FC metrics as node
features. The graph embeddings of fMRI FC networks learned by the GAE also
reveal apparent group differences between MDD and HC. Our new framework
demonstrates feasibility of learning graph embeddings on brain networks to
provide discriminative information for diagnosis of brain disorders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved-Mask R-CNN: Towards an Accurate Generic MSK MRI instance segmentation platform (Data from the Osteoarthritis Initiative). (arXiv:2107.12889v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Felfeliyan_B/0/1/0/all/0/1">Banafshe Felfeliyan</a>, <a href="http://arxiv.org/find/eess/1/au:+Hareendranathan_A/0/1/0/all/0/1">Abhilash Hareendranathan</a>, <a href="http://arxiv.org/find/eess/1/au:+Kuntze_G/0/1/0/all/0/1">Gregor Kuntze</a>, <a href="http://arxiv.org/find/eess/1/au:+Jaremko_J/0/1/0/all/0/1">Jacob L. Jaremko</a>, <a href="http://arxiv.org/find/eess/1/au:+Ronsky_J/0/1/0/all/0/1">Janet L. Ronsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12889">
                                    <div class="article-summary-box-inner">
                                        <span>Objective assessment of Magnetic Resonance Imaging (MRI) scans of
osteoarthritis (OA) can address the limitation of the current OA assessment.
Segmentation of bone, cartilage, and joint fluid is necessary for the OA
objective assessment. Most of the proposed segmentation methods are not
performing instance segmentation and suffer from class imbalance problems. This
study deployed Mask R-CNN instance segmentation and improved it (improved-Mask
R-CNN (iMaskRCNN)) to obtain a more accurate generalized segmentation for
OA-associated tissues. Training and validation of the method were performed
using 500 MRI knees from the Osteoarthritis Initiative (OAI) dataset and 97 MRI
scans of patients with symptomatic hip OA. Three modifications to Mask R-CNN
yielded the iMaskRCNN: adding a 2nd ROIAligned block, adding an extra decoder
layer to the mask-header, and connecting them by a skip connection. The results
were assessed using Hausdorff distance, dice score, and coefficients of
variation (CoV). The iMaskRCNN led to improved bone and cartilage segmentation
compared to Mask RCNN as indicated with the increase in dice score from 95% to
98% for the femur, 95% to 97% for tibia, 71% to 80% for femoral cartilage, and
81% to 82% for tibial cartilage. For the effusion detection, dice improved with
iMaskRCNN 72% versus MaskRCNN 71%. The CoV values for effusion detection
between Reader1 and Mask R-CNN (0.33), Reader1 and iMaskRCNN (0.34), Reader2
and Mask R-CNN (0.22), Reader2 and iMaskRCNN (0.29) are close to CoV between
two readers (0.21), indicating a high agreement between the human readers and
both Mask R-CNN and iMaskRCNN. Mask R-CNN and iMaskRCNN can reliably and
simultaneously extract different scale articular tissues involved in OA,
forming the foundation for automated assessment of OA. The iMaskRCNN results
show that the modification improved the network performance around the edges.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Branch-and-Bound for Neural Network Verification. (arXiv:2107.12855v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jaeckle_F/0/1/0/all/0/1">Florian Jaeckle</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jingyue Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1">M. Pawan Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12855">
                                    <div class="article-summary-box-inner">
                                        <span>Many available formal verification methods have been shown to be instances of
a unified Branch-and-Bound (BaB) formulation. We propose a novel machine
learning framework that can be used for designing an effective branching
strategy as well as for computing better lower bounds. Specifically, we learn
two graph neural networks (GNN) that both directly treat the network we want to
verify as a graph input and perform forward-backward passes through the GNN
layers. We use one GNN to simulate the strong branching heuristic behaviour and
another to compute a feasible dual solution of the convex relaxation, thereby
providing a valid lower bound.

We provide a new verification dataset that is more challenging than those
used in the literature, thereby providing an effective alternative for testing
algorithmic improvements for verification. Whilst using just one of the GNNs
leads to a reduction in verification time, we get optimal performance when
combining the two GNN approaches. Our combined framework achieves a 50\%
reduction in both the number of branches and the time required for verification
on various convolutional networks when compared to several state-of-the-art
verification methods. In addition, we show that our GNN models generalize well
to harder properties on larger unseen networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Stacked Auto-Encoders for Fair Representation Learning. (arXiv:2107.12826v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kenfack_P/0/1/0/all/0/1">Patrik Joslin Kenfack</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Adil Mehmood Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussain_R/0/1/0/all/0/1">Rasheed Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazmi_S/0/1/0/all/0/1">S.M. Ahsan Kazmi</a>,
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12826">
                                    <div class="article-summary-box-inner">
                                        <span>Training machine learning models with the only accuracy as a final goal may
promote prejudices and discriminatory behaviors embedded in the data. One
solution is to learn latent representations that fulfill specific fairness
metrics. Different types of learning methods are employed to map data into the
fair representational space. The main purpose is to learn a latent
representation of data that scores well on a fairness metric while maintaining
the usability for the downstream task. In this paper, we propose a new fair
representation learning approach that leverages different levels of
representation of data to tighten the fairness bounds of the learned
representation. Our results show that stacking different auto-encoders and
enforcing fairness at different latent spaces result in an improvement of
fairness compared to other existing approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wasserstein-Splitting Gaussian Process Regression for Heterogeneous Online Bayesian Inference. (arXiv:2107.12797v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kepler_M/0/1/0/all/0/1">Michael E. Kepler</a>, <a href="http://arxiv.org/find/stat/1/au:+Koppel_A/0/1/0/all/0/1">Alec Koppel</a>, <a href="http://arxiv.org/find/stat/1/au:+Bedi_A/0/1/0/all/0/1">Amrit Singh Bedi</a>, <a href="http://arxiv.org/find/stat/1/au:+Stilwell_D/0/1/0/all/0/1">Daniel J. Stilwell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12797">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes (GPs) are a well-known nonparametric Bayesian inference
technique, but they suffer from scalability problems for large sample sizes,
and their performance can degrade for non-stationary or spatially heterogeneous
data. In this work, we seek to overcome these issues through (i) employing
variational free energy approximations of GPs operating in tandem with online
expectation propagation steps; and (ii) introducing a local splitting step
which instantiates a new GP whenever the posterior distribution changes
significantly as quantified by the Wasserstein metric over posterior
distributions. Over time, then, this yields an ensemble of sparse GPs which may
be updated incrementally, and adapts to locality, heterogeneity, and
non-stationarity in training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Deep Anomaly Detection for Multi-Sensor Time-Series Signals. (arXiv:2107.12626v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuxin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiqiang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zhiwen Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12626">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, multi-sensor technologies are applied in many fields, e.g., Health
Care (HC), Human Activity Recognition (HAR), and Industrial Control System
(ICS). These sensors can generate a substantial amount of multivariate
time-series data. Unsupervised anomaly detection on multi-sensor time-series
data has been proven critical in machine learning researches. The key challenge
is to discover generalized normal patterns by capturing spatial-temporal
correlation in multi-sensor data. Beyond this challenge, the noisy data is
often intertwined with the training data, which is likely to mislead the model
by making it hard to distinguish between the normal, abnormal, and noisy data.
Few of previous researches can jointly address these two challenges. In this
paper, we propose a novel deep learning-based anomaly detection algorithm
called Deep Convolutional Autoencoding Memory network (CAE-M). We first build a
Deep Convolutional Autoencoder to characterize spatial dependence of
multi-sensor data with a Maximum Mean Discrepancy (MMD) to better distinguish
between the noisy, normal, and abnormal data. Then, we construct a Memory
Network consisting of linear (Autoregressive Model) and non-linear predictions
(Bidirectional LSTM with Attention) to capture temporal dependence from
time-series data. Finally, CAE-M jointly optimizes these two subnetworks. We
empirically compare the proposed approach with several state-of-the-art anomaly
detection methods on HAR and HC datasets. Experimental results demonstrate that
our proposed model outperforms these existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Individual Survival Curves with Conditional Normalizing Flows. (arXiv:2107.12825v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ausset_G/0/1/0/all/0/1">Guillaume Ausset</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciffreo_T/0/1/0/all/0/1">Tom Ciffreo</a>, <a href="http://arxiv.org/find/cs/1/au:+Portier_F/0/1/0/all/0/1">Francois Portier</a>, <a href="http://arxiv.org/find/cs/1/au:+Clemencon_S/0/1/0/all/0/1">Stephan Cl&#xe9;men&#xe7;on</a>, <a href="http://arxiv.org/find/cs/1/au:+Papin_T/0/1/0/all/0/1">Timoth&#xe9;e Papin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12825">
                                    <div class="article-summary-box-inner">
                                        <span>Survival analysis, or time-to-event modelling, is a classical statistical
problem that has garnered a lot of interest for its practical use in
epidemiology, demographics or actuarial sciences. Recent advances on the
subject from the point of view of machine learning have been concerned with
precise per-individual predictions instead of population studies, driven by the
rise of individualized medicine. We introduce here a conditional normalizing
flow based estimate of the time-to-event density as a way to model highly
flexible and individualized conditional survival distributions. We use a novel
hierarchical formulation of normalizing flows to enable efficient fitting of
flexible conditional distributions without overfitting and show how the
normalizing flow formulation can be efficiently adapted to the censored
setting. We experimentally validate the proposed approach on a synthetic
dataset as well as four open medical datasets and an example of a common
financial problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convergence of Deep ReLU Networks. (arXiv:2107.12530v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yuesheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haizhang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12530">
                                    <div class="article-summary-box-inner">
                                        <span>We explore convergence of deep neural networks with the popular ReLU
activation function, as the depth of the networks tends to infinity. To this
end, we introduce the notion of activation domains and activation matrices of a
ReLU network. By replacing applications of the ReLU activation function by
multiplications with activation matrices on activation domains, we obtain an
explicit expression of the ReLU network. We then identify the convergence of
the ReLU networks as convergence of a class of infinite products of matrices.
Sufficient and necessary conditions for convergence of these infinite products
of matrices are studied. As a result, we establish necessary conditions for
ReLU networks to converge that the sequence of weight matrices converges to the
identity matrix and the sequence of the bias vectors converges to zero as the
depth of ReLU networks increases to infinity. Moreover, we obtain sufficient
conditions in terms of the weight matrices and bias vectors at hidden layers
for pointwise convergence of deep ReLU networks. These results provide
mathematical insights to the design strategy of the well-known deep residual
networks in image classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Low-Latency Energy-Efficient Deep SNNs via Attention-Guided Compression. (arXiv:2107.12445v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1">Souvik Kundu</a>, <a href="http://arxiv.org/find/cs/1/au:+Datta_G/0/1/0/all/0/1">Gourav Datta</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedram_M/0/1/0/all/0/1">Massoud Pedram</a>, <a href="http://arxiv.org/find/cs/1/au:+Beerel_P/0/1/0/all/0/1">Peter A. Beerel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12445">
                                    <div class="article-summary-box-inner">
                                        <span>Deep spiking neural networks (SNNs) have emerged as a potential alternative
to traditional deep learning frameworks, due to their promise to provide
increased compute efficiency on event-driven neuromorphic hardware. However, to
perform well on complex vision applications, most SNN training frameworks yield
large inference latency which translates to increased spike activity and
reduced energy efficiency. Hence,minimizing average spike activity while
preserving accuracy indeep SNNs remains a significant challenge and
opportunity.This paper presents a non-iterative SNN training technique
thatachieves ultra-high compression with reduced spiking activitywhile
maintaining high inference accuracy. In particular, our framework first uses
the attention-maps of an un compressed meta-model to yield compressed ANNs.
This step can be tuned to support both irregular and structured channel pruning
to leverage computational benefits over a broad range of platforms. The
framework then performs sparse-learning-based supervised SNN training using
direct inputs. During the training, it jointly optimizes the SNN weight,
threshold, and leak parameters to drastically minimize the number of time steps
required while retaining compression. To evaluate the merits of our approach,
we performed experiments with variants of VGG and ResNet, on both CIFAR-10 and
CIFAR-100, and VGG16 on Tiny-ImageNet.The SNN models generated through the
proposed technique yield SOTA compression ratios of up to 33.4x with no
significant drops in accuracy compared to baseline unpruned counterparts.
Compared to existing SNN pruning methods, we achieve up to 8.3x higher
compression with improved accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Sequence Feature Alignment for Domain Adaptive Detection Transformers. (arXiv:2107.12636v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_F/0/1/0/all/0/1">Fengxiang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zheng-Jun Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yonggang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12636">
                                    <div class="article-summary-box-inner">
                                        <span>Detection transformers have recently shown promising object detection results
and attracted increasing attention. However, how to develop effective domain
adaptation techniques to improve its cross-domain performance remains
unexplored and unclear. In this paper, we delve into this topic and empirically
find that direct feature distribution alignment on the CNN backbone only brings
limited improvements, as it does not guarantee domain-invariant sequence
features in the transformer for prediction. To address this issue, we propose a
novel Sequence Feature Alignment (SFA) method that is specially designed for
the adaptation of detection transformers. Technically, SFA consists of a domain
query-based feature alignment (DQFA) module and a token-wise feature alignment
(TDA) module. In DQFA, a novel domain query is used to aggregate and align
global context from the token sequence of both domains. DQFA reduces the domain
discrepancy in global feature representations and object relations when
deploying in the transformer encoder and decoder, respectively. Meanwhile, TDA
aligns token features in the sequence from both domains, which reduces the
domain gaps in local and instance-level feature representations in the
transformer encoder and decoder, respectively. Besides, a novel bipartite
matching consistency loss is proposed to enhance the feature discriminability
for robust object detection. Experiments on three challenging benchmarks show
that SFA outperforms state-of-the-art domain adaptive object detection methods.
Code has been made available at: https://github.com/encounter1997/SFA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finding Failures in High-Fidelity Simulation using Adaptive Stress Testing and the Backward Algorithm. (arXiv:2107.12940v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koren_M/0/1/0/all/0/1">Mark Koren</a>, <a href="http://arxiv.org/find/cs/1/au:+Nassar_A/0/1/0/all/0/1">Ahmed Nassar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1">Mykel J. Kochenderfer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12940">
                                    <div class="article-summary-box-inner">
                                        <span>Validating the safety of autonomous systems generally requires the use of
high-fidelity simulators that adequately capture the variability of real-world
scenarios. However, it is generally not feasible to exhaustively search the
space of simulation scenarios for failures. Adaptive stress testing (AST) is a
method that uses reinforcement learning to find the most likely failure of a
system. AST with a deep reinforcement learning solver has been shown to be
effective in finding failures across a range of different systems. This
approach generally involves running many simulations, which can be very
expensive when using a high-fidelity simulator. To improve efficiency, we
present a method that first finds failures in a low-fidelity simulator. It then
uses the backward algorithm, which trains a deep neural network policy using a
single expert demonstration, to adapt the low-fidelity failures to
high-fidelity. We have created a series of autonomous vehicle validation case
studies that represent some of the ways low-fidelity and high-fidelity
simulators can differ, such as time discretization. We demonstrate in a variety
of case studies that this new AST approach is able to find failures with
significantly fewer high-fidelity simulation steps than are needed when just
running AST directly in high-fidelity. As a proof of concept, we also
demonstrate AST on NVIDIA&#x27;s DriveSim simulator, an industry state-of-the-art
high-fidelity simulator for finding failures in autonomous vehicles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probing neural networks with t-SNE, class-specific projections and a guided tour. (arXiv:2107.12547v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hoyt_C/0/1/0/all/0/1">Christopher R. Hoyt</a>, <a href="http://arxiv.org/find/cs/1/au:+Owen_A/0/1/0/all/0/1">Art B. Owen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12547">
                                    <div class="article-summary-box-inner">
                                        <span>We use graphical methods to probe neural nets that classify images. Plots of
t-SNE outputs at successive layers in a network reveal increasingly organized
arrangement of the data points. They can also reveal how a network can diminish
or even forget about within-class structure as the data proceeds through
layers. We use class-specific analogues of principal components to visualize
how succeeding layers separate the classes. These allow us to sort images from
a given class from most typical to least typical (in the data) and they also
serve as very useful projection coordinates for data visualization. We find
them especially useful when defining versions guided tours for animated data
visualization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-Based Open-World Uncertainty Modeling for Confidence Calibration. (arXiv:2107.12628v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yezhen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_T/0/1/0/all/0/1">Tong Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kaiyang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1">Dongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12628">
                                    <div class="article-summary-box-inner">
                                        <span>Confidence calibration is of great importance to the reliability of decisions
made by machine learning systems. However, discriminative classifiers based on
deep neural networks are often criticized for producing overconfident
predictions that fail to reflect the true correctness likelihood of
classification accuracy. We argue that such an inability to model uncertainty
is mainly caused by the closed-world nature in softmax: a model trained by the
cross-entropy loss will be forced to classify input into one of $K$ pre-defined
categories with high probability. To address this problem, we for the first
time propose a novel $K$+1-way softmax formulation, which incorporates the
modeling of open-world uncertainty as the extra dimension. To unify the
learning of the original $K$-way classification task and the extra dimension
that models uncertainty, we propose a novel energy-based objective function,
and moreover, theoretically prove that optimizing such an objective essentially
forces the extra dimension to capture the marginal data distribution. Extensive
experiments show that our approach, Energy-based Open-World Softmax
(EOW-Softmax), is superior to existing state-of-the-art methods in improving
confidence calibration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uniformity in Heterogeneity:Diving Deep into Count Interval Partition for Crowd Counting. (arXiv:2107.12619v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qingyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Boshen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xuyi Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jilin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jiayi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12619">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the problem of inaccurate learning targets in crowd counting draws
increasing attention. Inspired by a few pioneering work, we solve this problem
by trying to predict the indices of pre-defined interval bins of counts instead
of the count values themselves. However, an inappropriate interval setting
might make the count error contributions from different intervals extremely
imbalanced, leading to inferior counting performance. Therefore, we propose a
novel count interval partition criterion called Uniform Error Partition (UEP),
which always keeps the expected counting error contributions equal for all
intervals to minimize the prediction risk. Then to mitigate the inevitably
introduced discretization errors in the count quantization process, we propose
another criterion called Mean Count Proxies (MCP). The MCP criterion selects
the best count proxy for each interval to represent its count value during
inference, making the overall expected discretization error of an image nearly
negligible. As far as we are aware, this work is the first to delve into such a
classification task and ends up with a promising solution for count interval
partition. Following the above two theoretically demonstrated criterions, we
propose a simple yet effective model termed Uniform Error Partition Network
(UEPNet), which achieves state-of-the-art performance on several challenging
datasets. The codes will be available at:
https://github.com/TencentYoutuResearch/CrowdCounting-UEPNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparing Prophet and Deep Learning to ARIMA in Forecasting Wholesale Food Prices. (arXiv:2107.12770v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Menculini_L/0/1/0/all/0/1">Lorenzo Menculini</a>, <a href="http://arxiv.org/find/cs/1/au:+Marini_A/0/1/0/all/0/1">Andrea Marini</a>, <a href="http://arxiv.org/find/cs/1/au:+Proietti_M/0/1/0/all/0/1">Massimiliano Proietti</a>, <a href="http://arxiv.org/find/cs/1/au:+Garinei_A/0/1/0/all/0/1">Alberto Garinei</a>, <a href="http://arxiv.org/find/cs/1/au:+Bozza_A/0/1/0/all/0/1">Alessio Bozza</a>, <a href="http://arxiv.org/find/cs/1/au:+Moretti_C/0/1/0/all/0/1">Cecilia Moretti</a>, <a href="http://arxiv.org/find/cs/1/au:+Marconi_M/0/1/0/all/0/1">Marcello Marconi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12770">
                                    <div class="article-summary-box-inner">
                                        <span>Setting sale prices correctly is of great importance for firms, and the study
and forecast of prices time series is therefore a relevant topic not only from
a data science perspective but also from an economic and applicative one. In
this paper we exhamine different techniques to forecast the sale prices of
three food products applied by an Italian food wholesaler, as a step towards
the automation of pricing tasks usually taken care by human workforce. We
consider ARIMA models and compare them to Prophet, a scalable forecasting tool
developed by Facebook and based on a generalized additive model, and to deep
learning models based on Long Short--Term Memory (LSTM) and Convolutional
Neural Networks (CNNs). ARIMA models are frequently used in econometric
analyses, providing a good bechmark for the problem under study. Our results
indicate that ARIMA performs similarly to LSTM neural networks for the problem
under study, while the combination of CNNs and LSTMs attains the best overall
accuracy, but requires more time to be tuned. On the contrary, Prophet is very
fast to use, but less accurate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-Enforced Modeling for Insertion Loss of Transmission Lines by Deep Neural Networks. (arXiv:2107.12527v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_L/0/1/0/all/0/1">Lesley Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12527">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we investigate data-driven parameterized modeling of insertion
loss for transmission lines with respect to design parameters. We first show
that direct application of neural networks can lead to non-physics models with
negative insertion loss. To mitigate this problem, we propose two deep learning
solutions. One solution is to add a regulation term, which represents the
passive condition, to the final loss function to enforce the negative quantity
of insertion loss. In the second method, a third-order polynomial expression is
defined first, which ensures positiveness, to approximate the insertion loss,
then DeepONet neural network structure, which was proposed recently for
function and system modeling, was employed to model the coefficients of
polynomials. The resulting neural network is applied to predict the
coefficients of the polynomial expression. The experimental results on an
open-sourced SI/PI database of a PCB design show that both methods can ensure
the positiveness for the insertion loss. Furthermore, both methods can achieve
similar prediction results, while the polynomial-based DeepONet method is
faster than DeepONet based method in training time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pointer Value Retrieval: A new benchmark for understanding the limits of neural network generalization. (arXiv:2107.12580v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chiyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghu_M/0/1/0/all/0/1">Maithra Raghu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1">Jon Kleinberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1">Samy Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12580">
                                    <div class="article-summary-box-inner">
                                        <span>The successes of deep learning critically rely on the ability of neural
networks to output meaningful predictions on unseen data -- generalization. Yet
despite its criticality, there remain fundamental open questions on how neural
networks generalize. How much do neural networks rely on memorization -- seeing
highly similar training examples -- and how much are they capable of
human-intelligence styled reasoning -- identifying abstract rules underlying
the data? In this paper we introduce a novel benchmark, Pointer Value Retrieval
(PVR) tasks, that explore the limits of neural network generalization. While
PVR tasks can consist of visual as well as symbolic inputs, each with varying
levels of difficulty, they all have a simple underlying rule. One part of the
PVR task input acts as a pointer, giving the location of a different part of
the input, which forms the value (and output). We demonstrate that this task
structure provides a rich testbed for understanding generalization, with our
empirical study showing large variations in neural network performance based on
dataset size, task complexity and model architecture. The interaction of
position, values and the pointer rule also allow the development of nuanced
tests of generalization, by introducing distribution shift and increasing
functional complexity. These reveal both subtle failures and surprising
successes, suggesting many promising directions of exploration on this
benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ENHANCE (ENriching Health data by ANnotations of Crowd and Experts): A case study for skin lesion classification. (arXiv:2107.12734v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raumanns_R/0/1/0/all/0/1">Ralf Raumanns</a>, <a href="http://arxiv.org/find/cs/1/au:+Schouten_G/0/1/0/all/0/1">Gerard Schouten</a>, <a href="http://arxiv.org/find/cs/1/au:+Joosten_M/0/1/0/all/0/1">Max Joosten</a>, <a href="http://arxiv.org/find/cs/1/au:+Pluim_J/0/1/0/all/0/1">Josien P. W. Pluim</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheplygina_V/0/1/0/all/0/1">Veronika Cheplygina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12734">
                                    <div class="article-summary-box-inner">
                                        <span>We present ENHANCE, an open dataset with multiple annotations to complement
the existing ISIC and PH2 skin lesion classification datasets. This dataset
contains annotations of visual ABC (asymmetry, border, colour) features from
non-expert annotation sources: undergraduate students, crowd workers from
Amazon MTurk and classic image processing algorithms. In this paper we first
analyse the correlations between the annotations and the diagnostic label of
the lesion, as well as study the agreement between different annotation
sources. Overall we find weak correlations of non-expert annotations with the
diagnostic label, and low agreement between different annotation sources. We
then study multi-task learning (MTL) with the annotations as additional labels,
and show that non-expert annotations can improve (ensembles of)
state-of-the-art convolutional neural networks via MTL. We hope that our
dataset can be used in further research into multiple annotations and/or MTL.
All data and models are available on Github:
https://github.com/raumannsr/ENHANCE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Self-Attentive Gated RNNs for Real-Time Speaker Separation. (arXiv:2106.13493v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kabeli_O/0/1/0/all/0/1">Ori Kabeli</a>, <a href="http://arxiv.org/find/eess/1/au:+Adi_Y/0/1/0/all/0/1">Yossi Adi</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_Z/0/1/0/all/0/1">Zhenyu Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_B/0/1/0/all/0/1">Buye Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_A/0/1/0/all/0/1">Anurag Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13493">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have recently shown great success in the task of blind
source separation, both under monaural and binaural settings. Although these
methods were shown to produce high-quality separations, they were mainly
applied under offline settings, in which the model has access to the full input
signal while separating the signal. In this study, we convert a non-causal
state-of-the-art separation model into a causal and real-time model and
evaluate its performance under both online and offline settings. We compare the
performance of the proposed model to several baseline methods under anechoic,
noisy, and noisy-reverberant recording conditions while exploring both monaural
and binaural inputs and outputs. Our findings shed light on the relative
difference between causal and non-causal models when performing separation. Our
stateful implementation for online separation leads to a minor drop in
performance compared to the offline model; 0.8dB for monaural inputs and 0.3dB
for binaural inputs while reaching a real-time factor of 0.65. Samples can be
found under the following link:
https://kwanum.github.io/sagrnnc-stream-results/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning with Neural Tangent Kernels in Near Input Sparsity Time. (arXiv:2104.00415v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zandieh_A/0/1/0/all/0/1">Amir Zandieh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00415">
                                    <div class="article-summary-box-inner">
                                        <span>The Neural Tangent Kernel (NTK) characterizes the behavior of infinitely wide
neural nets trained under least squares loss by gradient descent. However,
despite its importance, the super-quadratic runtime of kernel methods limits
the use of NTK in large-scale learning tasks. To accelerate kernel machines
with NTK, we propose a near input sparsity time algorithm that maps the input
data to a randomized low-dimensional feature space so that the inner product of
the transformed data approximates their NTK evaluation. Our transformation
works by sketching the polynomial expansions of arc-cosine kernels.
Furthermore, we propose a feature map for approximating the convolutional
counterpart of the NTK, which can transform any image using a runtime that is
only linear in the number of pixels. We show that in standard large-scale
regression and classification tasks a linear regressor trained on our features
outperforms trained Neural Nets and Nystrom approximation of NTK kernel.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PointBA: Towards Backdoor Attacks in 3D Point Cloud. (arXiv:2103.16074v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xinke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhirui Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yue Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_Z/0/1/0/all/0/1">Zekun Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yabang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_A/0/1/0/all/0/1">Andrew Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Joey Tianyi Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16074">
                                    <div class="article-summary-box-inner">
                                        <span>3D deep learning has been increasingly more popular for a variety of tasks
including many safety-critical applications. However, recently several works
raise the security issues of 3D deep nets. Although most of these works
consider adversarial attacks, we identify that backdoor attack is indeed a more
serious threat to 3D deep learning systems but remains unexplored. We present
the backdoor attacks in 3D with a unified framework that exploits the unique
properties of 3D data and networks. In particular, we design two attack
approaches: the poison-label attack and the clean-label attack. The first one
is straightforward and effective in practice, while the second one is more
sophisticated assuming there are certain data inspections. The attack
algorithms are mainly motivated and developed by 1) the recent discovery of 3D
adversarial samples which demonstrate the vulnerability of 3D deep nets under
spatial transformations; 2) the proposed feature disentanglement technique that
manipulates the feature of the data through optimization methods and its
potential to embed a new task. Extensive experiments show the efficacy of the
poison-label attack with over 95% success rate across several 3D datasets and
models, and the ability of clean-label attack against data filtering with
around 50% success rate. Our proposed backdoor attack in 3D point cloud is
expected to perform as a baseline for improving the robustness of 3D deep
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constant Random Perturbations Provide Adversarial Robustness with Minimal Effect on Accuracy. (arXiv:2103.08265v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chernyak_B/0/1/0/all/0/1">Bronya Roni Chernyak</a>, <a href="http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1">Bhiksha Raj</a>, <a href="http://arxiv.org/find/cs/1/au:+Hazan_T/0/1/0/all/0/1">Tamir Hazan</a>, <a href="http://arxiv.org/find/cs/1/au:+Keshet_J/0/1/0/all/0/1">Joseph Keshet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08265">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes an attack-independent (non-adversarial training)
technique for improving adversarial robustness of neural network models, with
minimal loss of standard accuracy. We suggest creating a neighborhood around
each training example, such that the label is kept constant for all inputs
within that neighborhood. Unlike previous work that follows a similar
principle, we apply this idea by extending the training set with multiple
perturbations for each training example, drawn from within the neighborhood.
These perturbations are model independent, and remain constant throughout the
entire training process. We analyzed our method empirically on MNIST, SVHN, and
CIFAR-10, under different attacks and conditions. Results suggest that the
proposed approach improves standard accuracy over other defenses while having
increased robustness compared to vanilla adversarial training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Co-Transport for Class-Incremental Learning. (arXiv:2107.12654v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Da-Wei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12654">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional learning systems are trained in closed-world for a fixed number
of classes, and need pre-collected datasets in advance. However, new classes
often emerge in real-world applications and should be learned incrementally.
For example, in electronic commerce, new types of products appear daily, and in
a social media community, new topics emerge frequently. Under such
circumstances, incremental models should learn several new classes at a time
without forgetting. We find a strong correlation between old and new classes in
incremental learning, which can be applied to relate and facilitate different
learning stages mutually. As a result, we propose CO-transport for class
Incremental Learning (COIL), which learns to relate across incremental tasks
with the class-wise semantic relationship. In detail, co-transport has two
aspects: prospective transport tries to augment the old classifier with optimal
transported knowledge as fast model adaptation. Retrospective transport aims to
transport new class classifiers backward as old ones to overcome forgetting.
With these transports, COIL efficiently adapts to new tasks, and stably resists
forgetting. Experiments on benchmark and real-world multimedia datasets
validate the effectiveness of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving ClusterGAN Using Self-AugmentedInformation Maximization of Disentangling LatentSpaces. (arXiv:2107.12706v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dam_T/0/1/0/all/0/1">Tanmoy Dam</a>, <a href="http://arxiv.org/find/cs/1/au:+Anavatti_S/0/1/0/all/0/1">Sreenatha G. Anavatti</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbass_H/0/1/0/all/0/1">Hussein A. Abbass</a> (Fellow, IEEESchool of Engineering and Information Technology, University of New South Wales Canberra, Australia)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12706">
                                    <div class="article-summary-box-inner">
                                        <span>The Latent Space Clustering in Generative adversarial networks (ClusterGAN)
method has been successful with high-dimensional data. However, the method
assumes uniformlydistributed priors during the generation of modes, which isa
restrictive assumption in real-world data and cause loss ofdiversity in the
generated modes. In this paper, we proposeself-augmentation information
maximization improved Clus-terGAN (SIMI-ClusterGAN) to learn the distinctive
priorsfrom the data. The proposed SIMI-ClusterGAN consists offour deep neural
networks: self-augmentation prior network,generator, discriminator and
clustering inference autoencoder.The proposed method has been validated using
seven bench-mark data sets and has shown improved performance overstate-of-the
art methods. To demonstrate the superiority ofSIMI-ClusterGAN performance on
imbalanced dataset, wehave discussed two imbalanced conditions on MNIST
datasetswith one-class imbalance and three classes imbalanced cases.The results
highlight the advantages of SIMI-ClusterGAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vision-Guided Forecasting -- Visual Context for Multi-Horizon Time Series Forecasting. (arXiv:2107.12674v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kosman_E/0/1/0/all/0/1">Eitan Kosman</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_D/0/1/0/all/0/1">Dotan Di Castro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12674">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous driving gained huge traction in recent years, due to its potential
to change the way we commute. Much effort has been put into trying to estimate
the state of a vehicle. Meanwhile, learning to forecast the state of a vehicle
ahead introduces new capabilities, such as predicting dangerous situations.
Moreover, forecasting brings new supervision opportunities by learning to
predict richer a context, expressed by multiple horizons. Intuitively, a video
stream originated from a front-facing camera is necessary because it encodes
information about the upcoming road. Besides, historical traces of the
vehicle&#x27;s states give more context. In this paper, we tackle multi-horizon
forecasting of vehicle states by fusing the two modalities. We design and
experiment with 3 end-to-end architectures that exploit 3D convolutions for
visual features extraction and 1D convolutions for features extraction from
speed and steering angle traces. To demonstrate the effectiveness of our
method, we perform extensive experiments on two publicly available real-world
datasets, Comma2k19 and the Udacity challenge. We show that we are able to
forecast a vehicle&#x27;s state to various horizons, while outperforming the current
state-of-the-art results on the related task of driving state estimation. We
examine the contribution of vision features, and find that a model fed with
vision features achieves an error that is 56.6% and 66.9% of the error of a
model that doesn&#x27;t use those features, on the Udacity and Comma2k19 datasets
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MU-MIMO Grouping For Real-time Applications. (arXiv:2106.15262v2 [cs.NI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pasandi_H/0/1/0/all/0/1">Hannaneh Barahouei Pasandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadeem_T/0/1/0/all/0/1">Tamer Nadeem</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirpour_H/0/1/0/all/0/1">Hadi Amirpour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15262">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last decade, the bandwidth expansion and MU-MIMO spectral efficiency
have promised to increase data throughput by allowing concurrent communication
between one Access Point and multiple users. However, we are still a long way
from enjoying such MU-MIMO MAC protocol improvements for bandwidth hungry
applications such as video streaming in practical WiFi network settings due to
heterogeneous channel conditions and devices, unreliable transmissions, and
lack of useful feedback exchange among the lower and upper layers&#x27;
requirements. This paper introduces MuViS, a novel dual-phase optimization
framework that proposes a Quality of Experience (QoE) aware MU-MIMO
optimization for multi-user video streaming over IEEE 802.11ac. MuViS first
employs reinforcement learning to optimize the MU-MIMO user group and mode
selection for users based on their PHY/MAC layer characteristics. The video
bitrate is then optimized based on the user&#x27;s mode (Multi-User (MU) or
Single-User (SU)). We present our design and its evaluation on smartphones and
laptops using 802.11ac WiFi. Our experimental results in various indoor
environments and configurations show a scalable framework that can support a
large number of users with streaming at high video rates and satisfying QoE
requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Learning with Neuron Activation Importance. (arXiv:2107.12657v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sohee Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seungkyu Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12657">
                                    <div class="article-summary-box-inner">
                                        <span>Continual learning is a concept of online learning with multiple sequential
tasks. One of the critical barriers of continual learning is that a network
should learn a new task keeping the knowledge of old tasks without access to
any data of the old tasks. In this paper, we propose a neuron activation
importance-based regularization method for stable continual learning regardless
of the order of tasks. We conduct comprehensive experiments on existing
benchmark data sets to evaluate not just the stability and plasticity of our
method with improved classification accuracy also the robustness of the
performance along the changes of task order.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Transfer Learning based COVID-19 Detection in Cough, Breath and Speech using Bottleneck Features. (arXiv:2104.02477v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pahar_M/0/1/0/all/0/1">Madhurananda Pahar</a>, <a href="http://arxiv.org/find/cs/1/au:+Niesler_T/0/1/0/all/0/1">Thomas Niesler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02477">
                                    <div class="article-summary-box-inner">
                                        <span>We present an experimental investigation into the automatic detection of
COVID-19 from coughs, breaths and speech as this type of screening is
non-contact, does not require specialist medical expertise or laboratory
facilities and can easily be deployed on inexpensive consumer hardware.

Smartphone recordings of cough, breath and speech from subjects around the
globe are used for classification by seven standard machine learning
classifiers using leave-$p$-out cross-validation to provide a promising
baseline performance.

Then, a diverse dataset of 10.29 hours of cough, sneeze, speech and noise
audio recordings are used to pre-train a CNN, LSTM and Resnet50 classifier and
fine tuned the model to enhance the performance even further.

We have also extracted the bottleneck features from these pre-trained models
by removing the final-two layers and used them as an input to the LR, SVM, MLP
and KNN classifiers to detect COVID-19 signature.

The highest AUC of 0.98 was achieved using a transfer learning based Resnet50
architecture on coughs from Coswara dataset.

The highest AUC of 0.94 and 0.92 was achieved from an SVM run on the
bottleneck features extracted from the breaths from Coswara dataset and speech
recordings from ComParE dataset.

We conclude that among all vocal audio, coughs carry the strongest COVID-19
signature followed by breath and speech and using transfer learning improves
the classifier performance with higher AUC and lower variance across the
cross-validation folds.

Although these signatures are not perceivable by human ear, machine learning
based COVID-19 detection is possible from vocal audio recorded via smartphone.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Estimate RIS-Aided mmWave Channels. (arXiv:2107.12631v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+He_J/0/1/0/all/0/1">Jiguang He</a>, <a href="http://arxiv.org/find/eess/1/au:+Wymeersch_H/0/1/0/all/0/1">Henk Wymeersch</a>, <a href="http://arxiv.org/find/eess/1/au:+Renzo_M/0/1/0/all/0/1">Marco Di Renzo</a>, <a href="http://arxiv.org/find/eess/1/au:+Juntti_M/0/1/0/all/0/1">Markku Juntti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12631">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by the remarkable learning and prediction performance of deep neural
networks (DNNs), we apply one special type of DNN framework, known as
model-driven deep unfolding neural network, to reconfigurable intelligent
surface (RIS)-aided millimeter wave (mmWave) single-input multiple-output
(SIMO) systems. We focus on uplink cascaded channel estimation, where known and
fixed base station combining and RIS phase control matrices are considered for
collecting observations. To boost the estimation performance and reduce the
training overhead, the inherent channel sparsity of mmWave channels is
leveraged in the deep unfolding method. It is verified that the proposed deep
unfolding network architecture can outperform the least squares (LS) method
with a relatively smaller training overhead and online computational
complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diffusion Earth Mover&#x27;s Distance and Distribution Embeddings. (arXiv:2102.12833v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tong_A/0/1/0/all/0/1">Alexander Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huguet_G/0/1/0/all/0/1">Guillaume Huguet</a>, <a href="http://arxiv.org/find/cs/1/au:+Natik_A/0/1/0/all/0/1">Amine Natik</a>, <a href="http://arxiv.org/find/cs/1/au:+MacDonald_K/0/1/0/all/0/1">Kincaid MacDonald</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuchroo_M/0/1/0/all/0/1">Manik Kuchroo</a>, <a href="http://arxiv.org/find/cs/1/au:+Coifman_R/0/1/0/all/0/1">Ronald Coifman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1">Guy Wolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishnaswamy_S/0/1/0/all/0/1">Smita Krishnaswamy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12833">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new fast method of measuring distances between large numbers of
related high dimensional datasets called the Diffusion Earth Mover&#x27;s Distance
(EMD). We model the datasets as distributions supported on common data graph
that is derived from the affinity matrix computed on the combined data. In such
cases where the graph is a discretization of an underlying Riemannian closed
manifold, we prove that Diffusion EMD is topologically equivalent to the
standard EMD with a geodesic ground distance. Diffusion EMD can be computed in
$\tilde{O}(n)$ time and is more accurate than similarly fast algorithms such as
tree-based EMDs. We also show Diffusion EMD is fully differentiable, making it
amenable to future uses in gradient-descent frameworks such as deep neural
networks. Finally, we demonstrate an application of Diffusion EMD to single
cell data collected from 210 COVID-19 patient samples at Yale New Haven
Hospital. Here, Diffusion EMD can derive distances between patients on the
manifold of cells at least two orders of magnitude faster than equally accurate
methods. This distance matrix between patients can be embedded into a higher
level patient manifold which uncovers structure and heterogeneity in patients.
More generally, Diffusion EMD is applicable to all datasets that are massively
collected in parallel in many medical and biological systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speech Resynthesis from Discrete Disentangled Self-Supervised Representations. (arXiv:2104.00355v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Polyak_A/0/1/0/all/0/1">Adam Polyak</a>, <a href="http://arxiv.org/find/cs/1/au:+Adi_Y/0/1/0/all/0/1">Yossi Adi</a>, <a href="http://arxiv.org/find/cs/1/au:+Copet_J/0/1/0/all/0/1">Jade Copet</a>, <a href="http://arxiv.org/find/cs/1/au:+Kharitonov_E/0/1/0/all/0/1">Eugene Kharitonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakhotia_K/0/1/0/all/0/1">Kushal Lakhotia</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Wei-Ning Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Abdelrahman Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1">Emmanuel Dupoux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00355">
                                    <div class="article-summary-box-inner">
                                        <span>We propose using self-supervised discrete representations for the task of
speech resynthesis. To generate disentangled representation, we separately
extract low-bitrate representations for speech content, prosodic information,
and speaker identity. This allows to synthesize speech in a controllable
manner. We analyze various state-of-the-art, self-supervised representation
learning methods and shed light on the advantages of each method while
considering reconstruction quality and disentanglement properties.
Specifically, we evaluate the F0 reconstruction, speaker identification
performance (for both resynthesis and voice conversion), recordings&#x27;
intelligibility, and overall quality using subjective human evaluation. Lastly,
we demonstrate how these representations can be used for an ultra-lightweight
speech codec. Using the obtained representations, we can get to a rate of 365
bits per second while providing better speech quality than the baseline
methods. Audio samples can be found under the following link:
speechbot.github.io/resynthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Learning Rate and Momentum for Training Deep Neural Networks. (arXiv:2106.11548v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1">Zhiyong Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yixuan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Huihua Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1">Hsiao-Dong Chiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11548">
                                    <div class="article-summary-box-inner">
                                        <span>Recent progress on deep learning relies heavily on the quality and efficiency
of training algorithms. In this paper, we develop a fast training method
motivated by the nonlinear Conjugate Gradient (CG) framework. We propose the
Conjugate Gradient with Quadratic line-search (CGQ) method. On the one hand, a
quadratic line-search determines the step size according to current loss
landscape. On the other hand, the momentum factor is dynamically updated in
computing the conjugate gradient parameter (like Polak-Ribiere). Theoretical
results to ensure the convergence of our method in strong convex settings is
developed. And experiments in image classification datasets show that our
method yields faster convergence than other local solvers and has better
generalization capability (test set accuracy). One major advantage of the paper
method is that tedious hand tuning of hyperparameters like the learning rate
and momentum is avoided.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Waveshaping Synthesis. (arXiv:2107.05050v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hayes_B/0/1/0/all/0/1">Ben Hayes</a>, <a href="http://arxiv.org/find/cs/1/au:+Saitis_C/0/1/0/all/0/1">Charalampos Saitis</a>, <a href="http://arxiv.org/find/cs/1/au:+Fazekas_G/0/1/0/all/0/1">Gy&#xf6;rgy Fazekas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05050">
                                    <div class="article-summary-box-inner">
                                        <span>We present the Neural Waveshaping Unit (NEWT): a novel, lightweight, fully
causal approach to neural audio synthesis which operates directly in the
waveform domain, with an accompanying optimisation (FastNEWT) for efficient CPU
inference. The NEWT uses time-distributed multilayer perceptrons with periodic
activations to implicitly learn nonlinear transfer functions that encode the
characteristics of a target timbre. Once trained, a NEWT can produce complex
timbral evolutions by simple affine transformations of its input and output
signals. We paired the NEWT with a differentiable noise synthesiser and reverb
and found it capable of generating realistic musical instrument performances
with only 260k total model parameters, conditioned on F0 and loudness features.
We compared our method to state-of-the-art benchmarks with a multi-stimulus
listening test and the Fr\&#x27;echet Audio Distance and found it performed
competitively across the tested timbral domains. Our method significantly
outperformed the benchmarks in terms of generation speed, and achieved
real-time performance on a consumer CPU, both with and without FastNEWT,
suggesting it is a viable basis for future creative sound design tools.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Probabilistic Logic and Deep Learning for Self-Supervised Learning. (arXiv:2107.12591v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Poon_H/0/1/0/all/0/1">Hoifung Poon</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lang_H/0/1/0/all/0/1">Hunter Lang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12591">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning has proven effective for various application tasks, but its
applicability is limited by the reliance on annotated examples. Self-supervised
learning has emerged as a promising direction to alleviate the supervision
bottleneck, but existing work focuses on leveraging co-occurrences in unlabeled
data for task-agnostic representation learning, as exemplified by masked
language model pretraining. In this chapter, we explore task-specific
self-supervision, which leverages domain knowledge to automatically annotate
noisy training examples for end applications, either by introducing labeling
functions for annotating individual instances, or by imposing constraints over
interdependent label decisions. We first present deep probabilistic logic(DPL),
which offers a unifying framework for task-specific self-supervision by
composing probabilistic logic with deep learning. DPL represents unknown labels
as latent variables and incorporates diverse self-supervision using
probabilistic logic to train a deep neural network end-to-end using variational
EM. Next, we present self-supervised self-supervision(S4), which adds to DPL
the capability to learn new self-supervision automatically. Starting from an
initial seed self-supervision, S4 iteratively uses the deep neural network to
propose new self supervision. These are either added directly (a form of
structured self-training) or verified by a human expert (as in feature-based
active learning). Experiments on real-world applications such as biomedical
machine reading and various text classification tasks show that task-specific
self-supervision can effectively leverage domain expertise and often match the
accuracy of supervised methods with a tiny fraction of human effort.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quaternion Generative Adversarial Networks. (arXiv:2104.09630v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grassucci_E/0/1/0/all/0/1">Eleonora Grassucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Cicero_E/0/1/0/all/0/1">Edoardo Cicero</a>, <a href="http://arxiv.org/find/cs/1/au:+Comminiello_D/0/1/0/all/0/1">Danilo Comminiello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09630">
                                    <div class="article-summary-box-inner">
                                        <span>Latest Generative Adversarial Networks (GANs) are gathering outstanding
results through a large-scale training, thus employing models composed of
millions of parameters requiring extensive computational capabilities. Building
such huge models undermines their replicability and increases the training
instability. Moreover, multi-channel data, such as images or audio, are usually
processed by realvalued convolutional networks that flatten and concatenate the
input, often losing intra-channel spatial relations. To address these issues
related to complexity and information loss, we propose a family of
quaternion-valued generative adversarial networks (QGANs). QGANs exploit the
properties of quaternion algebra, e.g., the Hamilton product, that allows to
process channels as a single entity and capture internal latent relations,
while reducing by a factor of 4 the overall number of parameters. We show how
to design QGANs and to extend the proposed approach even to advanced models.We
compare the proposed QGANs with real-valued counterparts on several image
generation benchmarks. Results show that QGANs are able to obtain better FID
scores than real-valued GANs and to generate visually pleasing images.
Furthermore, QGANs save up to 75% of the training parameters. We believe these
results may pave the way to novel, more accessible, GANs capable of improving
performance and saving computational resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Lode Runner Levels by Learning Player Paths with LSTMs. (arXiv:2107.12532v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sorochan_K/0/1/0/all/0/1">Kynan Sorochan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jerry Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yakun Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1">Matthew Guzdial</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12532">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning has been a popular tool in many different fields, including
procedural content generation. However, procedural content generation via
machine learning (PCGML) approaches can struggle with controllability and
coherence. In this paper, we attempt to address these problems by learning to
generate human-like paths, and then generating levels based on these paths. We
extract player path data from gameplay video, train an LSTM to generate new
paths based on this data, and then generate game levels based on this path
data. We demonstrate that our approach leads to more coherent levels for the
game Lode Runner in comparison to an existing PCGML approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical Measures For Defining Curriculum Scoring Function. (arXiv:2103.00147v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sadasivan_V/0/1/0/all/0/1">Vinu Sankar Sadasivan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dasgupta_A/0/1/0/all/0/1">Anirban Dasgupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00147">
                                    <div class="article-summary-box-inner">
                                        <span>Curriculum learning is a training strategy that sorts the training examples
by some measure of their difficulty and gradually exposes them to the learner
to improve the network performance. Motivated by our insights from implicit
curriculum ordering, we first introduce a simple curriculum learning strategy
that uses statistical measures such as standard deviation and entropy values to
score the difficulty of data points for real image classification tasks. We
empirically show its improvements in performance with convolutional and
fully-connected neural networks on multiple real image datasets. We also
propose and study the performance of a dynamic curriculum learning algorithm.
Our dynamic curriculum algorithm tries to reduce the distance between the
network weight and an optimal weight at any training step by greedily sampling
examples with gradients that are directed towards the optimal weight. Further,
we use our algorithms to discuss why curriculum learning is helpful.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MFAGAN: A Compression Framework for Memory-Efficient On-Device Super-Resolution GAN. (arXiv:2107.12679v1 [cs.AR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1">Wenlong Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mingbo Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1">Zhiling Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Shuhang Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12679">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GANs) have promoted remarkable advances in
single-image super-resolution (SR) by recovering photo-realistic images.
However, high memory consumption of GAN-based SR (usually generators) causes
performance degradation and more energy consumption, hindering the deployment
of GAN-based SR into resource-constricted mobile devices. In this paper, we
propose a novel compression framework \textbf{M}ulti-scale \textbf{F}eature
\textbf{A}ggregation Net based \textbf{GAN} (MFAGAN) for reducing the memory
access cost of the generator. First, to overcome the memory explosion of dense
connections, we utilize a memory-efficient multi-scale feature aggregation net
as the generator. Second, for faster and more stable training, our method
introduces the PatchGAN discriminator. Third, to balance the student
discriminator and the compressed generator, we distill both the generator and
the discriminator. Finally, we perform a hardware-aware neural architecture
search (NAS) to find a specialized SubGenerator for the target mobile phone.
Benefiting from these improvements, the proposed MFAGAN achieves up to
\textbf{8.3}$\times$ memory saving and \textbf{42.9}$\times$ computation
reduction, with only minor visual quality degradation, compared with ESRGAN.
Empirical studies also show $\sim$\textbf{70} milliseconds latency on Qualcomm
Snapdragon 865 chipset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning-based decentralized offloading decision making in an adversarial environment. (arXiv:2104.12827v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cho_B/0/1/0/all/0/1">Byungjin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1">Yu Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12827">
                                    <div class="article-summary-box-inner">
                                        <span>Vehicular fog computing (VFC) pushes the cloud computing capability to the
distributed fog nodes at the edge of the Internet, enabling compute-intensive
and latency-sensitive computing services for vehicles through task offloading.
However, a heterogeneous mobility environment introduces uncertainties in terms
of resource supply and demand, which are inevitable bottlenecks for the optimal
offloading decision. Also, these uncertainties bring extra challenges to task
offloading under the oblivious adversary attack and data privacy risks. In this
article, we develop a new adversarial online learning algorithm with bandit
feedback based on the adversarial multi-armed bandit theory, to enable scalable
and low-complexity offloading decision making. Specifically, we focus on
optimizing fog node selection with the aim of minimizing the offloading service
costs in terms of delay and energy. The key is to implicitly tune the
exploration bonus in the selection process and the assessment rules of the
designed algorithm, taking into account volatile resource supply and demand. We
theoretically prove that the input-size dependent selection rule allows to
choose a suitable fog node without exploring the sub-optimal actions, and also
an appropriate score patching rule allows to quickly adapt to evolving
circumstances, which reduce variance and bias simultaneously, thereby achieving
a better exploitation-exploration balance. Simulation results verify the
effectiveness and robustness of the proposed algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Voice Identity Conversion: Manipulating Voice Attributes by Adversarial Learning of Structured Disentangled Representations. (arXiv:2107.12346v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Benaroya_L/0/1/0/all/0/1">Laurent Benaroya</a>, <a href="http://arxiv.org/find/cs/1/au:+Obin_N/0/1/0/all/0/1">Nicolas Obin</a>, <a href="http://arxiv.org/find/cs/1/au:+Roebel_A/0/1/0/all/0/1">Axel Roebel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12346">
                                    <div class="article-summary-box-inner">
                                        <span>Voice conversion (VC) consists of digitally altering the voice of an
individual to manipulate part of its content, primarily its identity, while
maintaining the rest unchanged. Research in neural VC has accomplished
considerable breakthroughs with the capacity to falsify a voice identity using
a small amount of data with a highly realistic rendering. This paper goes
beyond voice identity and presents a neural architecture that allows the
manipulation of voice attributes (e.g., gender and age). Leveraging the latest
advances on adversarial learning of structured speech representation, a novel
structured neural network is proposed in which multiple auto-encoders are used
to encode speech as a set of idealistically independent linguistic and
extra-linguistic representations, which are learned adversariarly and can be
manipulated during VC. Moreover, the proposed architecture is time-synchronized
so that the original voice timing is preserved during conversion which allows
lip-sync applications. Applied to voice gender conversion on the real-world
VCTK dataset, our proposed architecture can learn successfully
gender-independent representation and convert the voice gender with a very high
efficiency and naturalness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Open-Ended Learning Leads to Generally Capable Agents. (arXiv:2107.12808v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Team_Open_Ended_Learning/0/1/0/all/0/1">Open-Ended Learning Team</a>, <a href="http://arxiv.org/find/cs/1/au:+Stooke_A/0/1/0/all/0/1">Adam Stooke</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_A/0/1/0/all/0/1">Anuj Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Barros_C/0/1/0/all/0/1">Catarina Barros</a>, <a href="http://arxiv.org/find/cs/1/au:+Deck_C/0/1/0/all/0/1">Charlie Deck</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_J/0/1/0/all/0/1">Jakob Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sygnowski_J/0/1/0/all/0/1">Jakub Sygnowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Trebacz_M/0/1/0/all/0/1">Maja Trebacz</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaderberg_M/0/1/0/all/0/1">Max Jaderberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Mathieu_M/0/1/0/all/0/1">Michael Mathieu</a>, <a href="http://arxiv.org/find/cs/1/au:+McAleese_N/0/1/0/all/0/1">Nat McAleese</a>, <a href="http://arxiv.org/find/cs/1/au:+Bradley_Schmieg_N/0/1/0/all/0/1">Nathalie Bradley-Schmieg</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_N/0/1/0/all/0/1">Nathaniel Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Porcel_N/0/1/0/all/0/1">Nicolas Porcel</a>, <a href="http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1">Roberta Raileanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hughes_Fitt_S/0/1/0/all/0/1">Steph Hughes-Fitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Dalibard_V/0/1/0/all/0/1">Valentin Dalibard</a>, <a href="http://arxiv.org/find/cs/1/au:+Czarnecki_W/0/1/0/all/0/1">Wojciech Marian Czarnecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12808">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we create agents that can perform well beyond a single,
individual task, that exhibit much wider generalisation of behaviour to a
massive, rich space of challenges. We define a universe of tasks within an
environment domain and demonstrate the ability to train agents that are
generally capable across this vast space and beyond. The environment is
natively multi-agent, spanning the continuum of competitive, cooperative, and
independent games, which are situated within procedurally generated physical 3D
worlds. The resulting space is exceptionally diverse in terms of the challenges
posed to agents, and as such, even measuring the learning progress of an agent
is an open research problem. We propose an iterative notion of improvement
between successive generations of agents, rather than seeking to maximise a
singular objective, allowing us to quantify progress despite tasks being
incomparable in terms of achievable rewards. We show that through constructing
an open-ended learning process, which dynamically changes the training task
distributions and training objectives such that the agent never stops learning,
we achieve consistent learning of new behaviours. The resulting agent is able
to score reward in every one of our humanly solvable evaluation levels, with
behaviour generalising to many held-out points in the universe of tasks.
Examples of this zero-shot generalisation include good performance on Hide and
Seek, Capture the Flag, and Tag. Through analysis and hand-authored probe tasks
we characterise the behaviour of our agent, and find interesting emergent
heuristic behaviours such as trial-and-error experimentation, simple tool use,
option switching, and cooperation. Finally, we demonstrate that the general
capabilities of this agent could unlock larger scale transfer of behaviour
through cheap finetuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CFLOW-AD: Real-Time Unsupervised Anomaly Detection with Localization via Conditional Normalizing Flows. (arXiv:2107.12571v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gudovskiy_D/0/1/0/all/0/1">Denis Gudovskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishizaka_S/0/1/0/all/0/1">Shun Ishizaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Kozuka_K/0/1/0/all/0/1">Kazuki Kozuka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12571">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised anomaly detection with localization has many practical
applications when labeling is infeasible and, moreover, when anomaly examples
are completely missing in the train data. While recently proposed models for
such data setup achieve high accuracy metrics, their complexity is a limiting
factor for real-time processing. In this paper, we propose a real-time model
and analytically derive its relationship to prior methods. Our CFLOW-AD model
is based on a conditional normalizing flow framework adopted for anomaly
detection with localization. In particular, CFLOW-AD consists of a
discriminatively pretrained encoder followed by a multi-scale generative
decoders where the latter explicitly estimate likelihood of the encoded
features. Our approach results in a computationally and memory-efficient model:
CFLOW-AD is faster and smaller by a factor of 10x than prior state-of-the-art
with the same input setting. Our experiments on the MVTec dataset show that
CFLOW-AD outperforms previous methods by 0.36% AUROC in detection task, by
1.12% AUROC and 2.5% AUPRO in localization task, respectively. We open-source
our code with fully reproducible experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Co-creative Dungeon Generation via Transfer Learning. (arXiv:2107.12533v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zisen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1">Matthew Guzdial</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12533">
                                    <div class="article-summary-box-inner">
                                        <span>Co-creative Procedural Content Generation via Machine Learning (PCGML) refers
to systems where a PCGML agent and a human work together to produce output
content. One of the limitations of co-creative PCGML is that it requires
co-creative training data for a PCGML agent to learn to interact with humans.
However, acquiring this data is a difficult and time-consuming process. In this
work, we propose approximating human-AI interaction data and employing transfer
learning to adapt learned co-creative knowledge from one game to a different
game. We explore this approach for co-creative Zelda dungeon room generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Physics-constrained Deep Learning for Robust Inverse ECG Modeling. (arXiv:2107.12780v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jianxin Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_B/0/1/0/all/0/1">Bing Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12780">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid developments in advanced sensing and imaging bring about a
data-rich environment, facilitating the effective modeling, monitoring, and
control of complex systems. For example, the body-sensor network captures
multi-channel information pertinent to the electrical activity of the heart
(i.e., electrocardiograms (ECG)), which enables medical scientists to monitor
and detect abnormal cardiac conditions. However, the high-dimensional sensing
data are generally complexly structured and realizing the full data potential
depends to a great extent on advanced analytical and predictive methods. This
paper presents a physics-constrained deep learning (P-DL) framework for
high-dimensional inverse ECG modeling. This method integrates the physical laws
of the complex system with the advanced deep learning infrastructure for
effective prediction of the system dynamics. The proposed P-DL approach is
implemented to solve the inverse ECG model and predict the time-varying
distribution of electric potentials in the heart from the ECG data measured by
the body-surface sensor network. Experimental results show that the proposed
P-DL method significantly outperforms existing methods that are commonly used
in current practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relational Boosted Regression Trees. (arXiv:2107.12373v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cromp_S/0/1/0/all/0/1">Sonia Cromp</a>, <a href="http://arxiv.org/find/cs/1/au:+Samadian_A/0/1/0/all/0/1">Alireza Samadian</a>, <a href="http://arxiv.org/find/cs/1/au:+Pruhs_K/0/1/0/all/0/1">Kirk Pruhs</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12373">
                                    <div class="article-summary-box-inner">
                                        <span>Many tasks use data housed in relational databases to train boosted
regression tree models. In this paper, we give a relational adaptation of the
greedy algorithm for training boosted regression trees. For the subproblem of
calculating the sum of squared residuals of the dataset, which dominates the
runtime of the boosting algorithm, we provide a $(1 + \epsilon)$-approximation
using the tensor sketch technique. Employing this approximation within the
relational boosted regression trees algorithm leads to learning similar model
parameters, but with asymptotically better runtime.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Sample Selection for Robust Learning under Label Noise. (arXiv:2106.15292v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patel_D/0/1/0/all/0/1">Deep Patel</a>, <a href="http://arxiv.org/find/cs/1/au:+Sastry_P/0/1/0/all/0/1">P.S. Sastry</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15292">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Networks (DNNs) have been shown to be susceptible to memorization
or overfitting in the presence of noisily labelled data. For the problem of
robust learning under such noisy data, several algorithms have been proposed. A
prominent class of algorithms rely on sample selection strategies, motivated by
curriculum learning. For example, many algorithms use the &#x60;small loss trick&#x27;
wherein a fraction of samples with loss values below a certain threshold are
selected for training. These algorithms are sensitive to such thresholds, and
it is difficult to fix or learn these thresholds. Often, these algorithms also
require information such as label noise rates which are typically unavailable
in practice. In this paper, we propose a data-dependent, adaptive sample
selection strategy that relies only on batch statistics of a given mini-batch
to provide robustness against label noise. The algorithm does not have any
additional hyperparameters for sample selection, does not need any information
on noise rates, and does not need access to separate data with clean labels. We
empirically demonstrate the effectiveness of our algorithm on benchmark
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TaikoNation: Patterning-focused Chart Generation for Rhythm Action Games. (arXiv:2107.12506v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Halina_E/0/1/0/all/0/1">Emily Halina</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1">Matthew Guzdial</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12506">
                                    <div class="article-summary-box-inner">
                                        <span>Generating rhythm game charts from songs via machine learning has been a
problem of increasing interest in recent years. However, all existing systems
struggle to replicate human-like patterning: the placement of game objects in
relation to each other to form congruent patterns based on events in the song.
Patterning is a key identifier of high quality rhythm game content, seen as a
necessary component in human rankings. We establish a new approach for chart
generation that produces charts with more congruent, human-like patterning than
seen in prior work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Reward and Rank Signals for Slate Recommendation. (arXiv:2107.12455v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aouali_I/0/1/0/all/0/1">Imad Aouali</a>, <a href="http://arxiv.org/find/cs/1/au:+Ivanov_S/0/1/0/all/0/1">Sergey Ivanov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gartrell_M/0/1/0/all/0/1">Mike Gartrell</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohde_D/0/1/0/all/0/1">David Rohde</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasile_F/0/1/0/all/0/1">Flavian Vasile</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaytsev_V/0/1/0/all/0/1">Victor Zaytsev</a>, <a href="http://arxiv.org/find/cs/1/au:+Legrand_D/0/1/0/all/0/1">Diego Legrand</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12455">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of slate recommendation, where the recommender system
presents a user with a collection or slate composed of K recommended items at
once. If the user finds the recommended items appealing then the user may click
and the recommender system receives some feedback. Two pieces of information
are available to the recommender system: was the slate clicked? (the reward),
and if the slate was clicked, which item was clicked? (rank). In this paper, we
formulate several Bayesian models that incorporate the reward signal (Reward
model), the rank signal (Rank model), or both (Full model), for
non-personalized slate recommendation. In our experiments, we analyze
performance gains of the Full model and show that it achieves significantly
lower error as the number of products in the catalog grows or as the slate size
increases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Deep Model of Learning from both Data and Queries for Cardinality Estimation. (arXiv:2107.12295v1 [cs.DB] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Peizhi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cong_G/0/1/0/all/0/1">Gao Cong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12295">
                                    <div class="article-summary-box-inner">
                                        <span>Cardinality estimation is a fundamental problem in database systems. To
capture the rich joint data distributions of a relational table, most of the
existing work either uses data as unsupervised information or uses query
workload as supervised information. Very little work has been done to use both
types of information, and cannot fully make use of both types of information to
learn the joint data distribution. In this work, we aim to close the gap
between data-driven and query-driven methods by proposing a new unified deep
autoregressive model, UAE, that learns the joint data distribution from both
the data and query workload. First, to enable using the supervised query
information in the deep autoregressive model, we develop differentiable
progressive sampling using the Gumbel-Softmax trick. Second, UAE is able to
utilize both types of information to learn the joint data distribution in a
single model. Comprehensive experimental results demonstrate that UAE achieves
single-digit multiplicative error at tail, better accuracies over
state-of-the-art methods, and is both space and time efficient.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Graph Neural Networking Challenge: A Worldwide Competition for Education in AI/ML for Networks. (arXiv:2107.12433v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suarez_Varela_J/0/1/0/all/0/1">Jos&#xe9; Su&#xe1;rez-Varela</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferriol_Galmes_M/0/1/0/all/0/1">Miquel Ferriol-Galm&#xe9;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1">Albert L&#xf3;pez</a>, <a href="http://arxiv.org/find/cs/1/au:+Almasan_P/0/1/0/all/0/1">Paul Almasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernardez_G/0/1/0/all/0/1">Guillermo Bern&#xe1;rdez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pujol_Perich_D/0/1/0/all/0/1">David Pujol-Perich</a>, <a href="http://arxiv.org/find/cs/1/au:+Rusek_K/0/1/0/all/0/1">Krzysztof Rusek</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonniot_L/0/1/0/all/0/1">Lo&#xef;ck Bonniot</a>, <a href="http://arxiv.org/find/cs/1/au:+Neumann_C/0/1/0/all/0/1">Christoph Neumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnitzler_F/0/1/0/all/0/1">Fran&#xe7;ois Schnitzler</a>, <a href="http://arxiv.org/find/cs/1/au:+Taiani_F/0/1/0/all/0/1">Fran&#xe7;ois Ta&#xef;ani</a>, <a href="http://arxiv.org/find/cs/1/au:+Happ_M/0/1/0/all/0/1">Martin Happ</a>, <a href="http://arxiv.org/find/cs/1/au:+Maier_C/0/1/0/all/0/1">Christian Maier</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1">Jia Lei Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Herlich_M/0/1/0/all/0/1">Matthias Herlich</a>, <a href="http://arxiv.org/find/cs/1/au:+Dorfinger_P/0/1/0/all/0/1">Peter Dorfinger</a>, <a href="http://arxiv.org/find/cs/1/au:+Hainke_N/0/1/0/all/0/1">Nick Vincent Hainke</a>, <a href="http://arxiv.org/find/cs/1/au:+Venz_S/0/1/0/all/0/1">Stefan Venz</a>, <a href="http://arxiv.org/find/cs/1/au:+Wegener_J/0/1/0/all/0/1">Johannes Wegener</a>, <a href="http://arxiv.org/find/cs/1/au:+Wissing_H/0/1/0/all/0/1">Henrike Wissing</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1">Shihan Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Barlet_Ros_P/0/1/0/all/0/1">Pere Barlet-Ros</a>, <a href="http://arxiv.org/find/cs/1/au:+Cabellos_Aparicio_A/0/1/0/all/0/1">Albert Cabellos-Aparicio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12433">
                                    <div class="article-summary-box-inner">
                                        <span>During the last decade, Machine Learning (ML) has increasingly become a hot
topic in the field of Computer Networks and is expected to be gradually adopted
for a plethora of control, monitoring and management tasks in real-world
deployments. This poses the need to count on new generations of students,
researchers and practitioners with a solid background in ML applied to
networks. During 2020, the International Telecommunication Union (ITU) has
organized the &quot;ITU AI/ML in 5G challenge&#x27;&#x27;, an open global competition that has
introduced to a broad audience some of the current main challenges in ML for
networks. This large-scale initiative has gathered 23 different challenges
proposed by network operators, equipment manufacturers and academia, and has
attracted a total of 1300+ participants from 60+ countries. This paper narrates
our experience organizing one of the proposed challenges: the &quot;Graph Neural
Networking Challenge 2020&#x27;&#x27;. We describe the problem presented to participants,
the tools and resources provided, some organization aspects and participation
statistics, an outline of the top-3 awarded solutions, and a summary with some
lessons learned during all this journey. As a result, this challenge leaves a
curated set of educational resources openly available to anyone interested in
the topic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LETI: Latency Estimation Tool and Investigation of Neural Networks inference on Mobile GPU. (arXiv:2010.02871v2 [cs.PF] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ponomarev_E/0/1/0/all/0/1">Evgeny Ponomarev</a>, <a href="http://arxiv.org/find/cs/1/au:+Matveev_S/0/1/0/all/0/1">Sergey Matveev</a>, <a href="http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1">Ivan Oseledets</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02871">
                                    <div class="article-summary-box-inner">
                                        <span>A lot of deep learning applications are desired to be run on mobile devices.
Both accuracy and inference time are meaningful for a lot of them. While the
number of FLOPs is usually used as a proxy for neural network latency, it may
be not the best choice. In order to obtain a better approximation of latency,
research community uses look-up tables of all possible layers for latency
calculation for the final prediction of the inference on mobile CPU. It
requires only a small number of experiments. Unfortunately, on mobile GPU this
method is not applicable in a straight-forward way and shows low precision. In
this work, we consider latency approximation on mobile GPU as a data and
hardware-specific problem. Our main goal is to construct a convenient latency
estimation tool for investigation(LETI) of neural network inference and
building robust and accurate latency prediction models for each specific task.
To achieve this goal, we build open-source tools which provide a convenient way
to conduct massive experiments on different target devices focusing on mobile
GPU. After evaluation of the dataset, we learn the regression model on
experimental data and use it for future latency prediction and analysis. We
experimentally demonstrate the applicability of such an approach on a subset of
popular NAS-Benchmark 101 dataset and also evaluate the most popular neural
network architectures for two mobile GPUs. As a result, we construct latency
prediction model with good precision on the target evaluation subset. We
consider LETI as a useful tool for neural architecture search or massive
latency evaluation. The project is available at https://github.com/leti-ai</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reinforcement Learning for L3 Slice Localization in Sarcopenia Assessment. (arXiv:2107.12800v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laousy_O/0/1/0/all/0/1">Othmane Laousy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chassagnon_G/0/1/0/all/0/1">Guillaume Chassagnon</a>, <a href="http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1">Edouard Oyallon</a>, <a href="http://arxiv.org/find/cs/1/au:+Paragios_N/0/1/0/all/0/1">Nikos Paragios</a>, <a href="http://arxiv.org/find/cs/1/au:+Revel_M/0/1/0/all/0/1">Marie-Pierre Revel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakalopoulou_M/0/1/0/all/0/1">Maria Vakalopoulou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12800">
                                    <div class="article-summary-box-inner">
                                        <span>Sarcopenia is a medical condition characterized by a reduction in muscle mass
and function. A quantitative diagnosis technique consists of localizing the CT
slice passing through the middle of the third lumbar area (L3) and segmenting
muscles at this level. In this paper, we propose a deep reinforcement learning
method for accurate localization of the L3 CT slice. Our method trains a
reinforcement learning agent by incentivizing it to discover the right
position. Specifically, a Deep Q-Network is trained to find the best policy to
follow for this problem. Visualizing the training process shows that the agent
mimics the scrolling of an experienced radiologist. Extensive experiments
against other state-of-the-art deep learning based methods for L3 localization
prove the superiority of our technique which performs well even with limited
amount of data and annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Learning to Classify Macromolecular Structures in situ for Less Supervision in Cryo-Electron Tomography. (arXiv:2102.12040v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Du_X/0/1/0/all/0/1">Xuefeng Du</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_H/0/1/0/all/0/1">Haohan Wang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenxi Zhu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zeng_X/0/1/0/all/0/1">Xiangrui Zeng</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chang_Y/0/1/0/all/0/1">Yi-Wei Chang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Xu_M/0/1/0/all/0/1">Min Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12040">
                                    <div class="article-summary-box-inner">
                                        <span>Motivation: Cryo-Electron Tomography (cryo-ET) is a 3D bioimaging tool that
visualizes the structural and spatial organization of macromolecules at a
near-native state in single cells, which has broad applications in life
science. However, the systematic structural recognition and recovery of
macromolecules captured by cryo-ET are difficult due to high structural
complexity and imaging limits. Deep learning based subtomogram classification
have played critical roles for such tasks. As supervised approaches, however,
their performance relies on sufficient and laborious annotation on a large
training dataset.

Results: To alleviate this major labeling burden, we proposed a Hybrid Active
Learning (HAL) framework for querying subtomograms for labelling from a large
unlabeled subtomogram pool. Firstly, HAL adopts uncertainty sampling to select
the subtomograms that have the most uncertain predictions. Moreover, to
mitigate the sampling bias caused by such strategy, a discriminator is
introduced to judge if a certain subtomogram is labeled or unlabeled and
subsequently the model queries the subtomogram that have higher probabilities
to be unlabeled. Additionally, HAL introduces a subset sampling strategy to
improve the diversity of the query set, so that the information overlap is
decreased between the queried batches and the algorithmic efficiency is
improved. Our experiments on subtomogram classification tasks using both
simulated and real data demonstrate that we can achieve comparable testing
performance (on average only 3% accuracy drop) by using less than 30% of the
labeled subtomograms, which shows a very promising result for subtomogram
classification task with limited labeling resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Reputation Mechanism Is All You Need: Collaborative Fairness and Adversarial Robustness in Federated Learning. (arXiv:2011.10464v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xinyi Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_L/0/1/0/all/0/1">Lingjuan Lyu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10464">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) is an emerging practical framework for effective and
scalable machine learning among multiple participants, such as end users,
organizations and companies. However, most existing FL or distributed learning
frameworks have not well addressed two important issues together: collaborative
fairness and adversarial robustness (e.g. free-riders and malicious
participants). In conventional FL, all participants receive the global model
(equal rewards), which might be unfair to the high-contributing participants.
Furthermore, due to the lack of a safeguard mechanism, free-riders or malicious
adversaries could game the system to access the global model for free or to
sabotage it. In this paper, we propose a novel Robust and Fair Federated
Learning (RFFL) framework to achieve collaborative fairness and adversarial
robustness simultaneously via a reputation mechanism. RFFL maintains a
reputation for each participant by examining their contributions via their
uploaded gradients (using vector similarity) and thus identifies
non-contributing or malicious participants to be removed. Our approach
differentiates itself by not requiring any auxiliary/validation dataset.
Extensive experiments on benchmark datasets show that RFFL can achieve high
fairness and is very robust to different types of adversaries while achieving
competitive predictive accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Circular-Symmetric Correlation Layer based on FFT. (arXiv:2107.12480v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azari_B/0/1/0/all/0/1">Bahar Azari</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdogmus_D/0/1/0/all/0/1">Deniz Erdogmus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12480">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the vast success of standard planar convolutional neural networks,
they are not the most efficient choice for analyzing signals that lie on an
arbitrarily curved manifold, such as a cylinder. The problem arises when one
performs a planar projection of these signals and inevitably causes them to be
distorted or broken where there is valuable information. We propose a
Circular-symmetric Correlation Layer (CCL) based on the formalism of
roto-translation equivariant correlation on the continuous group $S^1 \times
\mathbb{R}$, and implement it efficiently using the well-known Fast Fourier
Transform (FFT) algorithm. We showcase the performance analysis of a general
network equipped with CCL on various recognition and classification tasks and
datasets. The PyTorch package implementation of CCL is provided online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proof: Accelerating Approximate Aggregation Queries with Expensive Predicates. (arXiv:2107.12525v1 [math.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Kang_D/0/1/0/all/0/1">Daniel Kang</a>, <a href="http://arxiv.org/find/math/1/au:+Guibas_J/0/1/0/all/0/1">John Guibas</a>, <a href="http://arxiv.org/find/math/1/au:+Bailis_P/0/1/0/all/0/1">Peter Bailis</a>, <a href="http://arxiv.org/find/math/1/au:+Hashimoto_T/0/1/0/all/0/1">Tatsunori Hashimoto</a>, <a href="http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1">Yi Sun</a>, <a href="http://arxiv.org/find/math/1/au:+Zaharia_M/0/1/0/all/0/1">Matei Zaharia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12525">
                                    <div class="article-summary-box-inner">
                                        <span>Given a dataset $\mathcal{D}$, we are interested in computing the mean of a
subset of $\mathcal{D}$ which matches a predicate. \algname leverages
stratified sampling and proxy models to efficiently compute this statistic
given a sampling budget $N$. In this document, we theoretically analyze
\algname and show that the MSE of the estimate decays at rate $O(N_1^{-1} +
N_2^{-1} + N_1^{1/2}N_2^{-3/2})$, where $N&#x3D;K \cdot N_1+N_2$ for some integer
constant $K$ and $K \cdot N_1$ and $N_2$ represent the number of samples used
in Stage 1 and Stage 2 of \algname respectively. Hence, if a constant fraction
of the total sample budget $N$ is allocated to each stage, we will achieve a
mean squared error of $O(N^{-1})$ which matches the rate of mean squared error
of the optimal stratified sampling algorithm given a priori knowledge of the
predicate positive rate and standard deviation per stratum.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CKNet: A Convolutional Neural Network Based on Koopman Operator for Modeling Latent Dynamics from Pixels. (arXiv:2102.10205v2 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xiao_Y/0/1/0/all/0/1">Yongqian Xiao</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_X/0/1/0/all/0/1">Xin Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lin_Q/0/1/0/all/0/1">QianLi Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10205">
                                    <div class="article-summary-box-inner">
                                        <span>With the development of end-to-end control based on deep learning, it is
important to study new system modeling techniques to realize dynamics modeling
with high-dimensional inputs. In this paper, a novel Koopman-based deep
convolutional network, called CKNet, is proposed to identify latent dynamics
from raw pixels. CKNet learns an encoder and decoder to play the role of the
Koopman eigenfunctions and modes, respectively. The Koopman eigenvalues can be
approximated by eigenvalues of the learned state transition matrix. The
deterministic convolutional Koopman network (DCKNet) and the variational
convolutional Koopman network (VCKNet) are proposed to span some subspace for
approximating the Koopman operator respectively. Because CKNet is trained under
the constraints of the Koopman theory, the identified latent dynamics is in a
linear form and has good interpretability. Besides, the state transition and
control matrices are trained as trainable tensors so that the identified
dynamics is also time-invariant. We also design an auxiliary weight term for
reducing multi-step linearity and prediction losses. Experiments were conducted
on two offline trained and four online trained nonlinear forced dynamical
systems with continuous action spaces in Gym and Mujoco environment
respectively, and the results show that identified dynamics are adequate for
approximating the latent dynamics and generating clear images. Especially for
offline trained cases, this work confirms CKNet from a novel perspective that
we visualize the evolutionary processes of the latent states and the Koopman
eigenfunctions with DCKNet and VCKNet separately to each task based on the same
episode and results demonstrate that different approaches learn similar
features in shapes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating Parkinsonism Severity in Natural Gait Videos of Older Adults with Dementia. (arXiv:2105.03464v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sabo_A/0/1/0/all/0/1">Andrea Sabo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdizadeh_S/0/1/0/all/0/1">Sina Mehdizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Iaboni_A/0/1/0/all/0/1">Andrea Iaboni</a>, <a href="http://arxiv.org/find/cs/1/au:+Taati_B/0/1/0/all/0/1">Babak Taati</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03464">
                                    <div class="article-summary-box-inner">
                                        <span>Drug-induced parkinsonism affects many older adults with dementia, often
causing gait disturbances. New advances in vision-based human pose-estimation
have opened possibilities for frequent and unobtrusive analysis of gait in
residential settings. This work proposes novel spatial-temporal graph
convolutional network (ST-GCN) architectures and training procedures to predict
clinical scores of parkinsonism in gait from video of individuals with
dementia. We propose a two-stage training approach consisting of a
self-supervised pretraining stage that encourages the ST-GCN model to learn
about gait patterns before predicting clinical scores in the finetuning stage.
The proposed ST-GCN models are evaluated on joint trajectories extracted from
video and are compared against traditional (ordinal, linear, random forest)
regression models and temporal convolutional network baselines. Three 2D human
pose-estimation libraries (OpenPose, Detectron, AlphaPose) and the Microsoft
Kinect (2D and 3D) are used to extract joint trajectories of 4787 natural
walking bouts from 53 older adults with dementia. A subset of 399 walks from 14
participants is annotated with scores of parkinsonism severity on the gait
criteria of the Unified Parkinson&#x27;s Disease Rating Scale (UPDRS) and the
Simpson-Angus Scale (SAS). Our results demonstrate that ST-GCN models operating
on 3D joint trajectories extracted from the Kinect consistently outperform all
other models and feature sets. Prediction of parkinsonism scores in natural
walking bouts of unseen participants remains a challenging task, with the best
models achieving macro-averaged F1-scores of 0.53 +/- 0.03 and 0.40 +/- 0.02
for UPDRS-gait and SAS-gait, respectively. Pre-trained model and demo code for
this work is available:
https://github.com/TaatiTeam/stgcn_parkinsonism_prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effects of Image Size on Deep Learning. (arXiv:2101.11508v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rukundo_O/0/1/0/all/0/1">Olivier Rukundo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11508">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the evaluation of effects of image size on deep learning
performance via semantic segmentation of magnetic resonance heart images with
U-net for fully automated quantification of myocardial infarction. Both
non-extra pixel and extra pixel interpolation algorithms are used to change the
size of images in datasets of interest. Extra class labels, in interpolated
ground truth segmentation images, are removed using thresholding, median
filtering, and subtraction strategies. Common class metrics are used to
evaluate the quality of semantic segmentation with U-net against the ground
truth segmentation while arbitrary threshold, comparison of the sums, and sums
of differences between medical experts and fully automated results are options
used to estimate the relationship between medical experts-based quantification
and fully automated quantification results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Debiasing In-Sample Policy Performance for Small-Data, Large-Scale Optimization. (arXiv:2107.12438v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Gupta_V/0/1/0/all/0/1">Vishal Gupta</a>, <a href="http://arxiv.org/find/math/1/au:+Huang_M/0/1/0/all/0/1">Michael Huang</a>, <a href="http://arxiv.org/find/math/1/au:+Rusmevichientong_P/0/1/0/all/0/1">Paat Rusmevichientong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12438">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the poor performance of cross-validation in settings where data
are scarce, we propose a novel estimator of the out-of-sample performance of a
policy in data-driven optimization.Our approach exploits the optimization
problem&#x27;s sensitivity analysis to estimate the gradient of the optimal
objective value with respect to the amount of noise in the data and uses the
estimated gradient to debias the policy&#x27;s in-sample performance. Unlike
cross-validation techniques, our approach avoids sacrificing data for a test
set, utilizes all data when training and, hence, is well-suited to settings
where data are scarce. We prove bounds on the bias and variance of our
estimator for optimization problems with uncertain linear objectives but known,
potentially non-convex, feasible regions. For more specialized optimization
problems where the feasible region is &#x60;&#x60;weakly-coupled&quot; in a certain sense, we
prove stronger results. Specifically, we provide explicit high-probability
bounds on the error of our estimator that hold uniformly over a policy class
and depends on the problem&#x27;s dimension and policy class&#x27;s complexity. Our
bounds show that under mild conditions, the error of our estimator vanishes as
the dimension of the optimization problem grows, even if the amount of
available data remains small and constant. Said differently, we prove our
estimator performs well in the small-data, large-scale regime. Finally, we
numerically compare our proposed method to state-of-the-art approaches through
a case-study on dispatching emergency medical response services using real
data. Our method provides more accurate estimates of out-of-sample performance
and learns better-performing policies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerated Gradient Descent Learning over Multiple Access Fading Channels. (arXiv:2107.12452v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_R/0/1/0/all/0/1">Raz Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedman_Y/0/1/0/all/0/1">Yuval Friedman</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_K/0/1/0/all/0/1">Kobi Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12452">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a distributed learning problem in a wireless network, consisting
of N distributed edge devices and a parameter server (PS). The objective
function is a sum of the edge devices&#x27; local loss functions, who aim to train a
shared model by communicating with the PS over multiple access channels (MAC).
This problem has attracted a growing interest in distributed sensing systems,
and more recently in federated learning, known as over-the-air computation. In
this paper, we develop a novel Accelerated Gradient-descent Multiple Access
(AGMA) algorithm that uses momentum-based gradient signals over noisy fading
MAC to improve the convergence rate as compared to existing methods.
Furthermore, AGMA does not require power control or beamforming to cancel the
fading effect, which simplifies the implementation complexity. We analyze AGMA
theoretically, and establish a finite-sample bound of the error for both convex
and strongly convex loss functions with Lipschitz gradient. For the strongly
convex case, we show that AGMA approaches the best-known linear convergence
rate as the network increases. For the convex case, we show that AGMA
significantly improves the sub-linear convergence rate as compared to existing
methods. Finally, we present simulation results using real datasets that
demonstrate better performance by AGMA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constraining dark matter annihilation with cosmic ray antiprotons using neural networks. (arXiv:2107.12395v1 [astro-ph.HE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Kahlhoefer_F/0/1/0/all/0/1">Felix Kahlhoefer</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Korsmeier_M/0/1/0/all/0/1">Michael Korsmeier</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Kramer_M/0/1/0/all/0/1">Michael Kr&#xe4;mer</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Manconi_S/0/1/0/all/0/1">Silvia Manconi</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Nippel_K/0/1/0/all/0/1">Kathrin Nippel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12395">
                                    <div class="article-summary-box-inner">
                                        <span>The interpretation of data from indirect detection experiments searching for
dark matter annihilations requires computationally expensive simulations of
cosmic-ray propagation. In this work we present a new method based on Recurrent
Neural Networks that significantly accelerates simulations of secondary and
dark matter Galactic cosmic ray antiprotons while achieving excellent accuracy.
This approach allows for an efficient profiling or marginalisation over the
nuisance parameters of a cosmic ray propagation model in order to perform
parameter scans for a wide range of dark matter models. We identify importance
sampling as particularly suitable for ensuring that the network is only
evaluated in well-trained parameter regions. We present resulting constraints
using the most recent AMS-02 antiproton data on several models of Weakly
Interacting Massive Particles. The fully trained networks are released as
DarkRayNet together with this work and achieve a speed-up of the runtime by at
least two orders of magnitude compared to conventional approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Source-Agnostic Gravitational-Wave Detection with Recurrent Autoencoders. (arXiv:2107.12698v1 [gr-qc])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/gr-qc/1/au:+Moreno_E/0/1/0/all/0/1">Eric A. Moreno</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Vlimant_J/0/1/0/all/0/1">Jean-Roch Vlimant</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Spiropulu_M/0/1/0/all/0/1">Maria Spiropulu</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Borzyszkowski_B/0/1/0/all/0/1">Bartlomiej Borzyszkowski</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Pierini_M/0/1/0/all/0/1">Maurizio Pierini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12698">
                                    <div class="article-summary-box-inner">
                                        <span>We present an application of anomaly detection techniques based on deep
recurrent autoencoders to the problem of detecting gravitational wave signals
in laser interferometers. Trained on noise data, this class of algorithms could
detect signals using an unsupervised strategy, i.e., without targeting a
specific kind of source. We develop a custom architecture to analyze the data
from two interferometers. We compare the obtained performance to that obtained
with other autoencoder architectures and with a convolutional classifier. The
unsupervised nature of the proposed strategy comes with a cost in terms of
accuracy, when compared to more traditional supervised techniques. On the other
hand, there is a qualitative gain in generalizing the experimental sensitivity
beyond the ensemble of pre-computed signal templates. The recurrent autoencoder
outperforms other autoencoders based on different architectures. The class of
recurrent autoencoders presented in this paper could complement the search
strategy employed for gravitational wave detection and extend the reach of the
ongoing detection campaigns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometric Deep Learning on Molecular Representations. (arXiv:2107.12375v1 [physics.chem-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Atz_K/0/1/0/all/0/1">Kenneth Atz</a>, <a href="http://arxiv.org/find/physics/1/au:+Grisoni_F/0/1/0/all/0/1">Francesca Grisoni</a>, <a href="http://arxiv.org/find/physics/1/au:+Schneider_G/0/1/0/all/0/1">Gisbert Schneider</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12375">
                                    <div class="article-summary-box-inner">
                                        <span>Geometric deep learning (GDL), which is based on neural network architectures
that incorporate and process symmetry information, has emerged as a recent
paradigm in artificial intelligence. GDL bears particular promise in molecular
modeling applications, in which various molecular representations with
different symmetry properties and levels of abstraction exist. This review
provides a structured and harmonized overview of molecular GDL, highlighting
its applications in drug discovery, chemical synthesis prediction, and quantum
chemistry. Emphasis is placed on the relevance of the learned molecular
features and their complementarity to well-established molecular descriptors.
This review provides an overview of current challenges and opportunities, and
presents a forecast of the future of GDL for molecular sciences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Initial Foundation for Predicting Individual Earthquake&#x27;s Location and Magnitude by Using Glass-Box Physics Rule Learner. (arXiv:2107.12915v1 [physics.geo-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Cho_I/0/1/0/all/0/1">In Ho Cho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12915">
                                    <div class="article-summary-box-inner">
                                        <span>Although researchers accumulated knowledge about seismogenesis and
decades-long earthquake data, predicting imminent individual earthquakes at a
specific time and location remains a long-standing enigma. This study
hypothesizes that the observed data conceal the hidden rules which may be
unraveled by a novel glass-box (as opposed to black-box) physics rule learner
(GPRL) framework. Without any predefined earthquake-related mechanisms or
statistical laws, GPRL&#x27;s two essentials, convolved information index and
transparent link function, seek generic expressions of rules directly from
data. GPRL&#x27;s training with 10-years data appears to identify plausible rules,
suggesting a combination of the pseudo power and the pseudo vorticity of
released energy in the lithosphere. Independent feasibility test supports the
promising role of the unraveled rules in predicting earthquakes&#x27; magnitudes and
their specific locations. The identified rules and GPRL are in their infancy
requiring substantial improvement. Still, this study hints at the existence of
the data-guided hidden pathway to imminent individual earthquake prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stability &amp; Generalisation of Gradient Descent for Shallow Neural Networks without the Neural Tangent Kernel. (arXiv:2107.12723v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Richards_D/0/1/0/all/0/1">Dominic Richards</a>, <a href="http://arxiv.org/find/stat/1/au:+Kuzborskij_I/0/1/0/all/0/1">Ilja Kuzborskij</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12723">
                                    <div class="article-summary-box-inner">
                                        <span>We revisit on-average algorithmic stability of Gradient Descent (GD) for
training overparameterised shallow neural networks and prove new generalisation
and excess risk bounds without the Neural Tangent Kernel (NTK) or
Polyak-{\L}ojasiewicz (PL) assumptions. In particular, we show oracle type
bounds which reveal that the generalisation and excess risk of GD is controlled
by an interpolating network with the shortest GD path from initialisation (in a
sense, an interpolating network with the smallest relative norm). While this
was known for kernelised interpolants, our proof applies directly to networks
trained by GD without intermediate kernelisation. At the same time, by relaxing
oracle inequalities developed here we recover existing NTK-based risk bounds in
a straightforward way, which demonstrates that our analysis is tighter.
Finally, unlike most of the NTK-based analyses we focus on regression with
label noise and show that GD with early stopping is consistent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Variational Models for Collaborative Filtering-based Recommender Systems. (arXiv:2107.12677v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bobadilla_J/0/1/0/all/0/1">Jes&#xfa;s Bobadilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_F/0/1/0/all/0/1">Fernando Ortega</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_A/0/1/0/all/0/1">Abraham Guti&#xe9;rrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Prieto_A/0/1/0/all/0/1">&#xc1;ngel Gonz&#xe1;lez-Prieto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12677">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning provides accurate collaborative filtering models to improve
recommender system results. Deep matrix factorization and their related
collaborative neural networks are the state-of-art in the field; nevertheless,
both models lack the necessary stochasticity to create the robust, continuous,
and structured latent spaces that variational autoencoders exhibit. On the
other hand, data augmentation through variational autoencoder does not provide
accurate results in the collaborative filtering field due to the high sparsity
of recommender systems. Our proposed models apply the variational concept to
inject stochasticity in the latent space of the deep architecture, introducing
the variational technique in the neural collaborative filtering field. This
method does not depend on the particular model used to generate the latent
representation. In this way, this approach can be applied as a plugin to any
current and future specific models. The proposed models have been tested using
four representative open datasets, three different quality measures, and
state-of-art baselines. The results show the superiority of the proposed
approach in scenarios where the variational enrichment exceeds the injected
noise effect. Additionally, a framework is provided to enable the
reproducibility of the conducted experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EdgeNets:Edge Varying Graph Neural Networks. (arXiv:2001.07620v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Isufi_E/0/1/0/all/0/1">Elvin Isufi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gama_F/0/1/0/all/0/1">Fernando Gama</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.07620">
                                    <div class="article-summary-box-inner">
                                        <span>Driven by the outstanding performance of neural networks in the structured
Euclidean domain, recent years have seen a surge of interest in developing
neural networks for graphs and data supported on graphs. The graph is leveraged
at each layer of the neural network as a parameterization to capture detail at
the node level with a reduced number of parameters and computational
complexity. Following this rationale, this paper puts forth a general framework
that unifies state-of-the-art graph neural networks (GNNs) through the concept
of EdgeNet. An EdgeNet is a GNN architecture that allows different nodes to use
different parameters to weigh the information of different neighbors. By
extrapolating this strategy to more iterations between neighboring nodes, the
EdgeNet learns edge- and neighbor-dependent weights to capture local detail.
This is a general linear and local operation that a node can perform and
encompasses under one formulation all existing graph convolutional neural
networks (GCNNs) as well as graph attention networks (GATs). In writing
different GNN architectures with a common language, EdgeNets highlight specific
architecture advantages and limitations, while providing guidelines to improve
their capacity without compromising their local implementation. An interesting
conclusion is the unification of GCNNs and GATs -- approaches that have been so
far perceived as separate. In particular, we show that GATs are GCNNs on a
graph that is learned from the features. This particularization opens the doors
to develop alternative attention mechanisms for improving discriminatory power.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Grounding with 3D Objects. (arXiv:2107.12514v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thomason_J/0/1/0/all/0/1">Jesse Thomason</a>, <a href="http://arxiv.org/find/cs/1/au:+Shridhar_M/0/1/0/all/0/1">Mohit Shridhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1">Yonatan Bisk</a>, <a href="http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1">Chris Paxton</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12514">
                                    <div class="article-summary-box-inner">
                                        <span>Seemingly simple natural language requests to a robot are generally
underspecified, for example &quot;Can you bring me the wireless mouse?&quot; When viewing
mice on the shelf, the number of buttons or presence of a wire may not be
visible from certain angles or positions. Flat images of candidate mice may not
provide the discriminative information needed for &quot;wireless&quot;. The world, and
objects in it, are not flat images but complex 3D shapes. If a human requests
an object based on any of its basic properties, such as color, shape, or
texture, robots should perform the necessary exploration to accomplish the
task. In particular, while substantial effort and progress has been made on
understanding explicitly visual attributes like color and category,
comparatively little progress has been made on understanding language about
shapes and contours. In this work, we introduce a novel reasoning task that
targets both visual and non-visual language about 3D objects. Our new
benchmark, ShapeNet Annotated with Referring Expressions (SNARE), requires a
model to choose which of two objects is being referenced by a natural language
description. We introduce several CLIP-based models for distinguishing objects
and demonstrate that while recent advances in jointly modeling vision and
language are useful for robotic language understanding, it is still the case
that these models are weaker at understanding the 3D nature of objects --
properties which play a key role in manipulation. In particular, we find that
adding view estimation to language grounding models improves accuracy on both
SNARE and when identifying objects referred to in language on a robot platform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Experiments on Properties of Hidden Structures of Sparse Neural Networks. (arXiv:2107.12917v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stier_J/0/1/0/all/0/1">Julian Stier</a>, <a href="http://arxiv.org/find/cs/1/au:+Darji_H/0/1/0/all/0/1">Harshil Darji</a>, <a href="http://arxiv.org/find/cs/1/au:+Granitzer_M/0/1/0/all/0/1">Michael Granitzer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12917">
                                    <div class="article-summary-box-inner">
                                        <span>Sparsity in the structure of Neural Networks can lead to less energy
consumption, less memory usage, faster computation times on convenient
hardware, and automated machine learning. If sparsity gives rise to certain
kinds of structure, it can explain automatically obtained features during
learning.

We provide insights into experiments in which we show how sparsity can be
achieved through prior initialization, pruning, and during learning, and answer
questions on the relationship between the structure of Neural Networks and
their performance. This includes the first work of inducing priors from network
theory into Recurrent Neural Networks and an architectural performance
prediction during a Neural Architecture Search. Within our experiments, we show
how magnitude class blinded pruning achieves 97.5% on MNIST with 80%
compression and re-training, which is 0.5 points more than without compression,
that magnitude class uniform pruning is significantly inferior to it and how a
genetic search enhanced with performance prediction achieves 82.4% on CIFAR10.
Further, performance prediction for Recurrent Networks learning the Reber
grammar shows an $R^2$ of up to 0.81 given only structural information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information criteria for non-normalized models. (arXiv:1905.05976v5 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Matsuda_T/0/1/0/all/0/1">Takeru Matsuda</a>, <a href="http://arxiv.org/find/math/1/au:+Uehara_M/0/1/0/all/0/1">Masatoshi Uehara</a>, <a href="http://arxiv.org/find/math/1/au:+Hyvarinen_A/0/1/0/all/0/1">Aapo Hyvarinen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.05976">
                                    <div class="article-summary-box-inner">
                                        <span>Many statistical models are given in the form of non-normalized densities
with an intractable normalization constant. Since maximum likelihood estimation
is computationally intensive for these models, several estimation methods have
been developed which do not require explicit computation of the normalization
constant, such as noise contrastive estimation (NCE) and score matching.
However, model selection methods for general non-normalized models have not
been proposed so far. In this study, we develop information criteria for
non-normalized models estimated by NCE or score matching. They are
approximately unbiased estimators of discrepancy measures for non-normalized
models. Simulation results and applications to real data demonstrate that the
proposed criteria enable selection of the appropriate non-normalized model in a
data-driven manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Short-Term Electricity Price Forecasting based on Graph Convolution Network and Attention Mechanism. (arXiv:2107.12794v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuyun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1">Zhenfei Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haitao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruan_G/0/1/0/all/0/1">Guangchun Ruan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1">Haiwang Zhong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12794">
                                    <div class="article-summary-box-inner">
                                        <span>In electricity markets, locational marginal price (LMP) forecasting is
particularly important for market participants in making reasonable bidding
strategies, managing potential trading risks, and supporting efficient system
planning and operation. Unlike existing methods that only consider LMPs&#x27;
temporal features, this paper tailors a spectral graph convolutional network
(GCN) to greatly improve the accuracy of short-term LMP forecasting. A
three-branch network structure is then designed to match the structure of LMPs&#x27;
compositions. Such kind of network can extract the spatial-temporal features of
LMPs, and provide fast and high-quality predictions for all nodes
simultaneously. The attention mechanism is also implemented to assign varying
importance weights between different nodes and time slots. Case studies based
on the IEEE-118 test system and real-world data from the PJM validate that the
proposed model outperforms existing forecasting models in accuracy, and
maintains a robust performance by avoiding extreme errors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Local Recurrent Models for Human Mesh Recovery. (arXiv:2107.12847v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Runze Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Karanam_S/0/1/0/all/0/1">Srikrishna Karanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ren Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Terrence Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhanu_B/0/1/0/all/0/1">Bir Bhanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Ziyan Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12847">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of estimating frame-level full human body meshes
given a video of a person with natural motion dynamics. While much progress in
this field has been in single image-based mesh estimation, there has been a
recent uptick in efforts to infer mesh dynamics from video given its role in
alleviating issues such as depth ambiguity and occlusions. However, a key
limitation of existing work is the assumption that all the observed motion
dynamics can be modeled using one dynamical/recurrent model. While this may
work well in cases with relatively simplistic dynamics, inference with
in-the-wild videos presents many challenges. In particular, it is typically the
case that different body parts of a person undergo different dynamics in the
video, e.g., legs may move in a way that may be dynamically different from
hands (e.g., a person dancing). To address these issues, we present a new
method for video mesh recovery that divides the human mesh into several local
parts following the standard skeletal model. We then model the dynamics of each
local part with separate recurrent models, with each model conditioned
appropriately based on the known kinematic structure of the human body. This
results in a structure-informed local recurrent learning architecture that can
be trained in an end-to-end fashion with available annotations. We conduct a
variety of experiments on standard video mesh recovery benchmark datasets such
as Human3.6M, MPI-INF-3DHP, and 3DPW, demonstrating the efficacy of our design
of modeling local dynamics as well as establishing state-of-the-art results
based on standard evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information fusion between knowledge and data in Bayesian network structure learning. (arXiv:2102.00473v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Constantinou_A/0/1/0/all/0/1">Anthony C. Constantinou</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1">Zhigao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitson_N/0/1/0/all/0/1">Neville K. Kitson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00473">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian Networks (BNs) have become a powerful technology for reasoning under
uncertainty, particularly in areas that require causal assumptions that enable
us to simulate the effect of intervention. The graphical structure of these
models can be determined by causal knowledge, learnt from data, or a
combination of both. While it seems plausible that the best approach in
constructing a causal graph involves combining knowledge with machine learning,
this approach remains underused in practice. We implement and evaluate 10
knowledge approaches with application to different case studies and BN
structure learning algorithms available in the open-source Bayesys structure
learning system. The approaches enable us to specify pre-existing knowledge
that can be obtained from heterogeneous sources, to constrain or guide
structure learning. Each approach is assessed in terms of structure learning
effectiveness and efficiency, including graphical accuracy, model fitting,
complexity, and runtime; making this the first paper that provides a
comparative evaluation of a wide range of knowledge approaches for BN structure
learning. Because the value of knowledge depends on what data are available, we
illustrate the results both with limited and big data. While the overall
results show that knowledge becomes less important with big data due to higher
learning accuracy rendering knowledge less important, some of the knowledge
approaches are actually found to be more important with big data. Amongst the
main conclusions is the observation that reduced search space obtained from
knowledge does not always imply reduced computational complexity, perhaps
because the relationships implied by the data and knowledge are in tension.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Free Barrier Functions via Implicit Evading Maneuvers. (arXiv:2107.12871v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Squires_E/0/1/0/all/0/1">Eric Squires</a>, <a href="http://arxiv.org/find/cs/1/au:+Konda_R/0/1/0/all/0/1">Rohit Konda</a>, <a href="http://arxiv.org/find/cs/1/au:+Coogan_S/0/1/0/all/0/1">Samuel Coogan</a>, <a href="http://arxiv.org/find/cs/1/au:+Egerstedt_M/0/1/0/all/0/1">Magnus Egerstedt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12871">
                                    <div class="article-summary-box-inner">
                                        <span>This paper demonstrates that in some cases the safety override arising from
the use of a barrier function can be needlessly restrictive. In particular, we
examine the case of fixed wing collision avoidance and show that when using a
barrier function, there are cases where two fixed wing aircraft can come closer
to colliding than if there were no barrier function at all. In addition, we
construct cases where the barrier function labels the system as unsafe even
when the vehicles start arbitrarily far apart. In other words, the barrier
function ensures safety but with unnecessary costs to performance. We therefore
introduce model free barrier functions which take a data driven approach to
creating a barrier function. We demonstrate the effectiveness of model free
barrier functions in a collision avoidance simulation of two fixed-wing
aircraft.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COPS: Controlled Pruning Before Training Starts. (arXiv:2107.12673v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wimmer_P/0/1/0/all/0/1">Paul Wimmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehnert_J/0/1/0/all/0/1">Jens Mehnert</a>, <a href="http://arxiv.org/find/cs/1/au:+Condurache_A/0/1/0/all/0/1">Alexandru Condurache</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12673">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art deep neural network (DNN) pruning techniques, applied
one-shot before training starts, evaluate sparse architectures with the help of
a single criterion -- called pruning score. Pruning weights based on a solitary
score works well for some architectures and pruning rates but may also fail for
other ones. As a common baseline for pruning scores, we introduce the notion of
a generalized synaptic score (GSS). In this work we do not concentrate on a
single pruning criterion, but provide a framework for combining arbitrary GSSs
to create more powerful pruning strategies. These COmbined Pruning Scores
(COPS) are obtained by solving a constrained optimization problem. Optimizing
for more than one score prevents the sparse network to overly specialize on an
individual task, thus COntrols Pruning before training Starts. The
combinatorial optimization problem given by COPS is relaxed on a linear program
(LP). This LP is solved analytically and determines a solution for COPS.
Furthermore, an algorithm to compute it for two scores numerically is proposed
and evaluated. Solving COPS in such a way has lower complexity than the best
general LP solver. In our experiments we compared pruning with COPS against
state-of-the-art methods for different network architectures and image
classification tasks and obtained improved results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-Constrained Deep Learning Approaches for Inverse Problems. (arXiv:2105.12033v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Nguyen_H/0/1/0/all/0/1">Hai V. Nguyen</a>, <a href="http://arxiv.org/find/stat/1/au:+Bui_Thanh_T/0/1/0/all/0/1">Tan Bui-Thanh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12033">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Learning (DL), in particular deep neural networks (DNN), by design is
purely data-driven and in general does not require physics. This is the
strength of DL but also one of its key limitations when applied to science and
engineering problems in which underlying physical properties (such as
stability, conservation, and positivity) and desired accuracy need to be
achieved. DL methods in their original forms are not capable of respecting the
underlying mathematical models or achieving desired accuracy even in big-data
regimes. On the other hand, many data-driven science and engineering problems,
such as inverse problems, typically have limited experimental or observational
data, and DL would overfit the data in this case. Leveraging information
encoded in the underlying mathematical models, we argue, not only compensates
missing information in low data regimes but also provides opportunities to
equip DL methods with the underlying physics and hence obtaining higher
accuracy. This short communication introduces several model-constrained DL
approaches (including both feed-forward DNN and autoencoders) that are capable
of learning not only information hidden in the training data but also in the
underlying mathematical models to solve inverse problems. We present and
provide intuitions for our formulations for general nonlinear problems. For
linear inverse problems and linear networks, the first order optimality
conditions show that our model-constrained DL approaches can learn information
encoded in the underlying mathematical models, and thus can produce consistent
or equivalent inverse solutions, while naive purely data-based counterparts
cannot.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LEGATO: A LayerwisE Gradient AggregaTiOn Algorithm for Mitigating Byzantine Attacks in Federated Learning. (arXiv:2107.12490v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varma_K/0/1/0/all/0/1">Kamala Varma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yi Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Baracaldo_N/0/1/0/all/0/1">Nathalie Baracaldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwar_A/0/1/0/all/0/1">Ali Anwar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12490">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning has arisen as a mechanism to allow multiple participants
to collaboratively train a model without sharing their data. In these settings,
participants (workers) may not trust each other fully; for instance, a set of
competitors may collaboratively train a machine learning model to detect fraud.
The workers provide local gradients that a central server uses to update a
global model. This global model can be corrupted when Byzantine workers send
malicious gradients, which necessitates robust methods for aggregating
gradients that mitigate the adverse effects of Byzantine inputs. Existing
robust aggregation algorithms are often computationally expensive and only
effective under strict assumptions. In this paper, we introduce LayerwisE
Gradient AggregatTiOn (LEGATO), an aggregation algorithm that is, by contrast,
scalable and generalizable. Informed by a study of layer-specific responses of
gradients to Byzantine attacks, LEGATO employs a dynamic gradient reweighing
scheme that is novel in its treatment of gradients based on layer-specific
robustness. We show that LEGATO is more computationally efficient than multiple
state-of-the-art techniques and more generally robust across a variety of
attack settings in practice. We also demonstrate LEGATO&#x27;s benefits for gradient
descent convergence in the absence of an attack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Random Forest Classifier for Automated Game Design. (arXiv:2107.12501v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maurer_T/0/1/0/all/0/1">Thomas Maurer</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1">Matthew Guzdial</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12501">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous game design, generating games algorithmically, has been a longtime
goal within the technical games research field. However, existing autonomous
game design systems have relied in large part on human-authoring for game
design knowledge, such as fitness functions in search-based methods. In this
paper, we describe an experiment to attempt to learn a human-like fitness
function for autonomous game design in an adversarial manner. While our
experimental work did not meet our expectations, we present an analysis of our
system and results that we hope will be informative to future autonomous game
design research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Don&#x27;t Sweep your Learning Rate under the Rug: A Closer Look at Cross-modal Transfer of Pretrained Transformers. (arXiv:2107.12460v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rothermel_D/0/1/0/all/0/1">Danielle Rothermel</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Margaret Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1">Tim Rockt&#xe4;schel</a>, <a href="http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1">Jakob Foerster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12460">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised pre-training of large-scale transformer models on text
corpora followed by finetuning has achieved state-of-the-art on a number of
natural language processing tasks. Recently, Lu et al. (2021, arXiv:2103.05247)
claimed that frozen pretrained transformers (FPTs) match or outperform training
from scratch as well as unfrozen (fine-tuned) pretrained transformers in a set
of transfer tasks to other modalities. In our work, we find that this result
is, in fact, an artifact of not tuning the learning rates. After carefully
redesigning the empirical setup, we find that when tuning learning rates
properly, pretrained transformers do outperform or match training from scratch
in all of our tasks, but only as long as the entire model is finetuned. Thus,
while transfer from pretrained language models to other modalities does indeed
provide gains and hints at exciting possibilities for future work, properly
tuning hyperparameters is important for arriving at robust findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-modal estimation of the properties of containers and their content: survey and evaluation. (arXiv:2107.12719v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xompero_A/0/1/0/all/0/1">Alessio Xompero</a>, <a href="http://arxiv.org/find/cs/1/au:+Donaher_S/0/1/0/all/0/1">Santiago Donaher</a>, <a href="http://arxiv.org/find/cs/1/au:+Iashin_V/0/1/0/all/0/1">Vladimir Iashin</a>, <a href="http://arxiv.org/find/cs/1/au:+Palermo_F/0/1/0/all/0/1">Francesca Palermo</a>, <a href="http://arxiv.org/find/cs/1/au:+Solak_G/0/1/0/all/0/1">G&#xf6;khan Solak</a>, <a href="http://arxiv.org/find/cs/1/au:+Coppola_C/0/1/0/all/0/1">Claudio Coppola</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_R/0/1/0/all/0/1">Reina Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagao_Y/0/1/0/all/0/1">Yuichi Nagao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hachiuma_R/0/1/0/all/0/1">Ryo Hachiuma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1">Chuanlin Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_R/0/1/0/all/0/1">Rosa H. M. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Christmann_G/0/1/0/all/0/1">Guilherme Christmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1">Jyun-Ting Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Neeharika_G/0/1/0/all/0/1">Gonuguntla Neeharika</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1">Chinnakotla Krishna Teja Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1">Dinesh Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehman_B/0/1/0/all/0/1">Bakhtawar Ur Rehman</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallaro_A/0/1/0/all/0/1">Andrea Cavallaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12719">
                                    <div class="article-summary-box-inner">
                                        <span>Acoustic and visual sensing can support the contactless estimation of the
weight of a container and the amount of its content when the container is
manipulated by a person. However, transparencies (both of the container and of
the content) and the variability of materials, shapes and sizes make this
problem challenging. In this paper, we present an open benchmarking framework
and an in-depth comparative analysis of recent methods that estimate the
capacity of a container, as well as the type, mass, and amount of its content.
These methods use learned and handcrafted features, such as mel-frequency
cepstrum coefficients, zero-crossing rate, spectrograms, with different types
of classifiers to estimate the type and amount of the content with acoustic
data, and geometric approaches with visual data to determine the capacity of
the container. Results on a newly distributed dataset show that audio alone is
a strong modality and methods achieves a weighted average F1-score up to 81%
and 97% for content type and level classification, respectively. Estimating the
container capacity with vision-only approaches and filling mass with
multi-modal, multi-stage algorithms reaches up to 65% weighted average capacity
and mass scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Audio-to-Score Alignment Using Deep Automatic Music Transcription. (arXiv:2107.12854v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Simonetta_F/0/1/0/all/0/1">Federico Simonetta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ntalampiras_S/0/1/0/all/0/1">Stavros Ntalampiras</a>, <a href="http://arxiv.org/find/cs/1/au:+Avanzini_F/0/1/0/all/0/1">Federico Avanzini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12854">
                                    <div class="article-summary-box-inner">
                                        <span>Audio-to-score alignment (A2SA) is a multimodal task consisting in the
alignment of audio signals to music scores. Recent literature confirms the
benefits of Automatic Music Transcription (AMT) for A2SA at the frame-level. In
this work, we aim to elaborate on the exploitation of AMT Deep Learning (DL)
models for achieving alignment at the note-level. We propose a method which
benefits from HMM-based score-to-score alignment and AMT, showing a remarkable
advancement beyond the state-of-the-art. We design a systematic procedure to
take advantage of large datasets which do not offer an aligned score. Finally,
we perform a thorough comparison and extensive tests on multiple datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extraction and Analysis of Fictional Character Networks: A Survey. (arXiv:1907.02704v4 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Labatut_V/0/1/0/all/0/1">Vincent Labatut</a> (LIA), <a href="http://arxiv.org/find/cs/1/au:+Bost_X/0/1/0/all/0/1">Xavier Bost</a> (LIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.02704">
                                    <div class="article-summary-box-inner">
                                        <span>A character network is a graph extracted from a narrative, in which vertices
represent characters and edges correspond to interactions between them. A
number of narrative-related problems can be addressed automatically through the
analysis of character networks, such as summarization, classification, or role
detection. Character networks are particularly relevant when considering works
of fictions (e.g. novels, plays, movies, TV series), as their exploitation
allows developing information retrieval and recommendation systems. However,
works of fiction possess specific properties making these tasks harder. This
survey aims at presenting and organizing the scientific literature related to
the extraction of character networks from works of fiction, as well as their
analysis. We first describe the extraction process in a generic way, and
explain how its constituting steps are implemented in practice, depending on
the medium of the narrative, the goal of the network analysis, and other
factors. We then review the descriptive tools used to characterize character
networks, with a focus on the way they are interpreted in this context. We
illustrate the relevance of character networks by also providing a review of
applications derived from their analysis. Finally, we identify the limitations
of the existing approaches, and the most promising perspectives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Angel&#x27;s Girl for Blind Painters: an Efficient Painting Navigation System Validated by Multimodal Evaluation Approach. (arXiv:2107.12921v1 [cs.MM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_M/0/1/0/all/0/1">Menghan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuzhen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingli Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Simon X. Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao-Ping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12921">
                                    <div class="article-summary-box-inner">
                                        <span>For people who ardently love painting but unfortunately have visual
impairments, holding a paintbrush to create a work is a very difficult task.
People in this special group are eager to pick up the paintbrush, like Leonardo
da Vinci, to create and make full use of their own talents. Therefore, to
maximally bridge this gap, we propose a painting navigation system to assist
blind people in painting and artistic creation. The proposed system is composed
of cognitive system and guidance system. The system adopts drawing board
positioning based on QR code, brush navigation based on target detection and
bush real-time positioning. Meanwhile, this paper uses human-computer
interaction on the basis of voice and a simple but efficient position
information coding rule. In addition, we design a criterion to efficiently
judge whether the brush reaches the target or not. According to the
experimental results, the thermal curves extracted from the faces of testers
show that it is relatively well accepted by blindfolded and even blind testers.
With the prompt frequency of 1s, the painting navigation system performs best
with the completion degree of 89% with SD of 8.37% and overflow degree of 347%
with SD of 162.14%. Meanwhile, the excellent and good types of brush tip
trajectory account for 74%, and the relative movement distance is 4.21 with SD
of 2.51. This work demonstrates that it is practicable for the blind people to
feel the world through the brush in their hands. In the future, we plan to
deploy Angle&#x27;s Eyes on the phone to make it more portable. The demo video of
the proposed painting navigation system is available at:
https://doi.org/10.6084/m9.figshare.9760004.v1.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Generation of H.264 Parameter Sets to Recover Video File Fragments. (arXiv:2104.14522v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Altinisik_E/0/1/0/all/0/1">Enes Altinisik</a>, <a href="http://arxiv.org/find/cs/1/au:+Sencar_H/0/1/0/all/0/1">H&#xfc;srev Taha Sencar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14522">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of decoding video file fragments when the necessary
encoding parameters are missing. With this objective, we propose a method that
automatically generates H.264 video headers containing these parameters and
extracts coded pictures in the partially available compressed video data. To
accomplish this, we examined a very large corpus of videos to learn patterns of
encoding settings commonly used by encoders and created a parameter dictionary.
Further, to facilitate a more efficient search our method identifies
characteristics of a coded bitstream to discriminate the entropy coding mode.
It also utilizes the application logs created by the decoder to identify
correct parameter values. Evaluation of the effectiveness of the proposed
method on more than 55K videos with diverse provenance shows that it can
generate valid headers on average in 11.3 decoding trials per video. This
result represents an improvement by more than a factor of 10 over the
conventional approach of video header stitching to recover video file
fragments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-Path Convolutional Image-Text Embeddings with Instance Loss. (arXiv:1711.05535v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhedong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Liang Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Garrett_M/0/1/0/all/0/1">Michael Garrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingliang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yi-Dong Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1711.05535">
                                    <div class="article-summary-box-inner">
                                        <span>Matching images and sentences demands a fine understanding of both
modalities. In this paper, we propose a new system to discriminatively embed
the image and text to a shared visual-textual space. In this field, most
existing works apply the ranking loss to pull the positive image / text pairs
close and push the negative pairs apart from each other. However, directly
deploying the ranking loss is hard for network learning, since it starts from
the two heterogeneous features to build inter-modal relationship. To address
this problem, we propose the instance loss which explicitly considers the
intra-modal data distribution. It is based on an unsupervised assumption that
each image / text group can be viewed as a class. So the network can learn the
fine granularity from every image/text group. The experiment shows that the
instance loss offers better weight initialization for the ranking loss, so that
more discriminative embeddings can be learned. Besides, existing works usually
apply the off-the-shelf features, i.e., word2vec and fixed visual feature. So
in a minor contribution, this paper constructs an end-to-end dual-path
convolutional network to learn the image and text representations. End-to-end
learning allows the system to directly learn from the data and fully utilize
the supervision. On two generic retrieval datasets (Flickr30k and MSCOCO),
experiments demonstrate that our method yields competitive accuracy compared to
state-of-the-art methods. Moreover, in language based person retrieval, we
improve the state of the art by a large margin. The code has been made publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MU-MIMO Grouping For Real-time Applications. (arXiv:2106.15262v2 [cs.NI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pasandi_H/0/1/0/all/0/1">Hannaneh Barahouei Pasandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadeem_T/0/1/0/all/0/1">Tamer Nadeem</a>, <a href="http://arxiv.org/find/cs/1/au:+Amirpour_H/0/1/0/all/0/1">Hadi Amirpour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15262">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last decade, the bandwidth expansion and MU-MIMO spectral efficiency
have promised to increase data throughput by allowing concurrent communication
between one Access Point and multiple users. However, we are still a long way
from enjoying such MU-MIMO MAC protocol improvements for bandwidth hungry
applications such as video streaming in practical WiFi network settings due to
heterogeneous channel conditions and devices, unreliable transmissions, and
lack of useful feedback exchange among the lower and upper layers&#x27;
requirements. This paper introduces MuViS, a novel dual-phase optimization
framework that proposes a Quality of Experience (QoE) aware MU-MIMO
optimization for multi-user video streaming over IEEE 802.11ac. MuViS first
employs reinforcement learning to optimize the MU-MIMO user group and mode
selection for users based on their PHY/MAC layer characteristics. The video
bitrate is then optimized based on the user&#x27;s mode (Multi-User (MU) or
Single-User (SU)). We present our design and its evaluation on smartphones and
laptops using 802.11ac WiFi. Our experimental results in various indoor
environments and configurations show a scalable framework that can support a
large number of users with streaming at high video rates and satisfying QoE
requirements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse to Fine: Domain Adaptive Crowd Counting via Adversarial Scoring Network. (arXiv:2107.12858v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zou_Z/0/1/0/all/0/1">Zhikang Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_X/0/1/0/all/0/1">Xiaoye Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Shuangjie Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiaoqing Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jin Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12858">
                                    <div class="article-summary-box-inner">
                                        <span>Recent deep networks have convincingly demonstrated high capability in crowd
counting, which is a critical task attracting widespread attention due to its
various industrial applications. Despite such progress, trained data-dependent
models usually can not generalize well to unseen scenarios because of the
inherent domain shift. To facilitate this issue, this paper proposes a novel
adversarial scoring network (ASNet) to gradually bridge the gap across domains
from coarse to fine granularity. In specific, at the coarse-grained stage, we
design a dual-discriminator strategy to adapt source domain to be close to the
targets from the perspectives of both global and local feature space via
adversarial learning. The distributions between two domains can thus be aligned
roughly. At the fine-grained stage, we explore the transferability of source
characteristics by scoring how similar the source samples are to target ones
from multiple levels based on generative probability derived from coarse stage.
Guided by these hierarchical scores, the transferable source features are
properly selected to enhance the knowledge transfer during the adaptation
process. With the coarse-to-fine design, the generalization bottleneck induced
from the domain discrepancy can be effectively alleviated. Three sets of
migration experiments show that the proposed methods achieve state-of-the-art
counting performance compared with major unsupervised methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-27">2021-07-27</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Pretraining for Paraphrase Evaluation. (arXiv:2107.08251v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1">Jack Weston</a>, <a href="http://arxiv.org/find/cs/1/au:+Lenain_R/0/1/0/all/0/1">Raphael Lenain</a>, <a href="http://arxiv.org/find/cs/1/au:+Meepegama_U/0/1/0/all/0/1">Udeepa Meepegama</a>, <a href="http://arxiv.org/find/cs/1/au:+Fristed_E/0/1/0/all/0/1">Emil Fristed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08251">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce ParaBLEU, a paraphrase representation learning model and
evaluation metric for text generation. Unlike previous approaches, ParaBLEU
learns to understand paraphrasis using generative conditioning as a pretraining
objective. ParaBLEU correlates more strongly with human judgements than
existing metrics, obtaining new state-of-the-art results on the 2017 WMT
Metrics Shared Task. We show that our model is robust to data scarcity,
exceeding previous state-of-the-art performance using only $50\%$ of the
available training data and surpassing BLEU, ROUGE and METEOR with only $40$
labelled examples. Finally, we demonstrate that ParaBLEU can be used to
conditionally generate novel paraphrases from a single demonstration, which we
use to confirm our hypothesis that it learns abstract, generalized paraphrase
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Certified Robustness to Text Adversarial Attacks by Randomized [MASK]. (arXiv:2105.03743v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_J/0/1/0/all/0/1">Jiehang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xiaoqing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jianhan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Liping Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuanjing Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03743">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, few certified defense methods have been developed to provably
guarantee the robustness of a text classifier to adversarial synonym
substitutions. However, all existing certified defense methods assume that the
defenders are informed of how the adversaries generate synonyms, which is not a
realistic scenario. In this paper, we propose a certifiably robust defense
method by randomly masking a certain proportion of the words in an input text,
in which the above unrealistic assumption is no longer necessary. The proposed
method can defend against not only word substitution-based attacks, but also
character-level perturbations. We can certify the classifications of over 50%
texts to be robust to any perturbation of 5 words on AGNEWS, and 2 words on
SST2 dataset. The experimental results show that our randomized smoothing
method significantly outperforms recently proposed defense methods across
multiple datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dive into Deep Learning. (arXiv:2106.11342v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Aston Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1">Alexander J. Smola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11342">
                                    <div class="article-summary-box-inner">
                                        <span>This open-source book represents our attempt to make deep learning
approachable, teaching readers the concepts, the context, and the code. The
entire book is drafted in Jupyter notebooks, seamlessly integrating exposition
figures, math, and interactive examples with self-contained code. Our goal is
to offer a resource that could (i) be freely available for everyone; (ii) offer
sufficient technical depth to provide a starting point on the path to actually
becoming an applied machine learning scientist; (iii) include runnable code,
showing readers how to solve problems in practice; (iv) allow for rapid
updates, both by us and also by the community at large; (v) be complemented by
a forum for interactive discussion of technical details and to answer
questions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Math Word Problems from Equations with Topic Controlling and Commonsense Enforcement. (arXiv:2012.07379v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1">Tianyang Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1">Shuang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Songge Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansur_M/0/1/0/all/0/1">Mairgup Mansur</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1">Baobao Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07379">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen significant advancement in text generation tasks with
the help of neural language models. However, there exists a challenging task:
generating math problem text based on mathematical equations, which has made
little progress so far. In this paper, we present a novel equation-to-problem
text generation model. In our model, 1) we propose a flexible scheme to
effectively encode math equations, we then enhance the equation encoder by a
Varitional Autoen-coder (VAE) 2) given a math equation, we perform topic
selection, followed by which a dynamic topic memory mechanism is introduced to
restrict the topic distribution of the generator 3) to avoid commonsense
violation in traditional generation model, we pretrain word embedding with
background knowledge graph (KG), and we link decoded words to related words in
KG, targeted at injecting background knowledge into our model. We evaluate our
model through both automatic metrices and human evaluation, experiments
demonstrate our model outperforms baseline and previous models in both accuracy
and richness of generated problem text.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Language Identification Through Cross-Lingual Self-Supervised Learning. (arXiv:2107.04082v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tjandra_A/0/1/0/all/0/1">Andros Tjandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhury_D/0/1/0/all/0/1">Diptanu Gon Choudhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Frank Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kritika Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1">Alexei Baevski</a>, <a href="http://arxiv.org/find/cs/1/au:+Sela_A/0/1/0/all/0/1">Assaf Sela</a>, <a href="http://arxiv.org/find/cs/1/au:+Saraf_Y/0/1/0/all/0/1">Yatharth Saraf</a>, <a href="http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1">Michael Auli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04082">
                                    <div class="article-summary-box-inner">
                                        <span>Language identification greatly impacts the success of downstream tasks such
as automatic speech recognition. Recently, self-supervised speech
representations learned by wav2vec 2.0 have been shown to be very effective for
a range of speech tasks. We extend previous self-supervised work on language
identification by experimenting with pre-trained models which were learned on
real-world unconstrained speech in multiple languages and not just on English.
We show that models pre-trained on many languages perform better and enable
language identification systems that require very little labeled data to
perform well. Results on a 25 languages setup show that with only 10 minutes of
labeled data per language, a cross-lingually pre-trained model can achieve over
93% accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimum projective linearizations of trees in linear time. (arXiv:2102.03277v3 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alemany_Puig_L/0/1/0/all/0/1">Llu&#xed;s Alemany-Puig</a>, <a href="http://arxiv.org/find/cs/1/au:+Esteban_J/0/1/0/all/0/1">Juan Luis Esteban</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_i_Cancho_R/0/1/0/all/0/1">Ramon Ferrer-i-Cancho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03277">
                                    <div class="article-summary-box-inner">
                                        <span>The Minimum Linear Arrangement problem (MLA) consists of finding a mapping
$\pi$ from vertices of a graph to distinct integers that minimizes
$\sum_{\{u,v\}\in E}|\pi(u) - \pi(v)|$. In that setting, vertices are often
assumed to lie on a horizontal line and edges are drawn as semicircles above
said line. For trees, various algorithms are available to solve the problem in
polynomial time in $n&#x3D;|V|$. There exist variants of the MLA in which the
arrangements are constrained. Iordanskii, and later Hochberg and Stallmann
(HS), put forward $O(n)$-time algorithms that solve the problem when
arrangements are constrained to be planar (also known as one-page book
embeddings). We also consider linear arrangements of rooted trees that are
constrained to be projective (planar embeddings where the root is not covered
by any edge). Gildea and Temperley (GT) sketched an algorithm for projective
arrangements which they claimed runs in $O(n)$ but did not provide any
justification of its cost. In contrast, Park and Levy claimed that GT&#x27;s
algorithm runs in $O(n \log d_{max})$ where $d_{max}$ is the maximum degree but
did not provide sufficient detail. Here we correct an error in HS&#x27;s algorithm
for the planar case, show its relationship with the projective case, and derive
simple algorithms for the projective and planar cases that run undoubtlessly in
$O(n)$-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SummVis: Interactive Visual Analysis of Models, Data, and Evaluation for Text Summarization. (arXiv:2104.07605v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vig_J/0/1/0/all/0/1">Jesse Vig</a>, <a href="http://arxiv.org/find/cs/1/au:+Kryscinski_W/0/1/0/all/0/1">Wojciech Kry&#x15b;ci&#x144;ski</a>, <a href="http://arxiv.org/find/cs/1/au:+Goel_K/0/1/0/all/0/1">Karan Goel</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajani_N/0/1/0/all/0/1">Nazneen Fatema Rajani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07605">
                                    <div class="article-summary-box-inner">
                                        <span>Novel neural architectures, training strategies, and the availability of
large-scale corpora haven been the driving force behind recent progress in
abstractive text summarization. However, due to the black-box nature of neural
models, uninformative evaluation metrics, and scarce tooling for model and data
analysis, the true performance and failure modes of summarization models remain
largely unknown. To address this limitation, we introduce SummVis, an
open-source tool for visualizing abstractive summaries that enables
fine-grained analysis of the models, data, and evaluation metrics associated
with text summarization. Through its lexical and semantic visualizations, the
tools offers an easy entry point for in-depth model prediction exploration
across important dimensions such as factual consistency or abstractiveness. The
tool together with several pre-computed model outputs is available at
https://github.com/robustness-gym/summvis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Term-community-based topic detection with variable resolution. (arXiv:2103.13550v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hamm_A/0/1/0/all/0/1">Andreas Hamm</a>, <a href="http://arxiv.org/find/cs/1/au:+Odrowski_S/0/1/0/all/0/1">Simon Odrowski</a> (German Aerospace Center DLR)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13550">
                                    <div class="article-summary-box-inner">
                                        <span>Network-based procedures for topic detection in huge text collections offer
an intuitive alternative to probabilistic topic models. We present in detail a
method that is especially designed with the requirements of domain experts in
mind. Like similar methods, it employs community detection in term
co-occurrence graphs, but it is enhanced by including a resolution parameter
that can be used for changing the targeted topic granularity. We also establish
a term ranking and use semantic word-embedding for presenting term communities
in a way that facilitates their interpretation. We demonstrate the application
of our method with a widely used corpus of general news articles and show the
results of detailed social-sciences expert evaluations of detected topics at
various resolutions. A comparison with topics detected by Latent Dirichlet
Allocation is also included. Finally, we discuss factors that influence topic
interpretation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Graph Convolutional Networks for Text Classification. (arXiv:2102.09604v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Igamberdiev_T/0/1/0/all/0/1">Timour Igamberdiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Habernal_I/0/1/0/all/0/1">Ivan Habernal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09604">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolutional networks (GCNs) are a powerful architecture for
representation learning on documents that naturally occur as graphs, e.g.,
citation or social networks. However, sensitive personal information, such as
documents with people&#x27;s profiles or relationships as edges, are prone to
privacy leaks, as the trained model might reveal the original input. Although
differential privacy (DP) offers a well-founded privacy-preserving framework,
GCNs pose theoretical and practical challenges due to their training specifics.
We address these challenges by adapting differentially-private gradient-based
training to GCNs and conduct experiments using two optimizers on five NLP
datasets in two languages. We propose a simple yet efficient method based on
random graph splits that not only improves the baseline privacy bounds by a
factor of 2.7 while retaining competitive F1 scores, but also provides strong
privacy guarantees of epsilon &#x3D; 1.0. We show that, under certain modeling
choices, privacy-preserving GCNs perform up to 90% of their non-private
variants, while formally guaranteeing strong privacy measures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Examination of Community Sentiment Dynamics due to COVID-19 Pandemic: A Case Study from A State in Australia. (arXiv:2006.12185v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jianlong Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shuiqiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Chun Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1">Fang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12185">
                                    <div class="article-summary-box-inner">
                                        <span>The outbreak of the novel Coronavirus Disease 2019 (COVID-19) has caused
unprecedented impacts to people&#x27;s daily life around the world. Various measures
and policies such as lockdown and social-distancing are implemented by
governments to combat the disease during the pandemic period. These measures
and policies as well as virus itself may cause different mental health issues
to people such as depression, anxiety, sadness, etc. In this paper, we exploit
the massive text data posted by Twitter users to analyse the sentiment dynamics
of people living in the state of New South Wales (NSW) in Australia during the
pandemic period. Different from the existing work that mostly focuses the
country-level and static sentiment analysis, we analyse the sentiment dynamics
at the fine-grained local government areas (LGAs). Based on the analysis of
around 94 million tweets that posted by around 183 thousand users located at
different LGAs in NSW in five months, we found that people in NSW showed an
overall positive sentimental polarity and the COVID-19 pandemic decreased the
overall positive sentimental polarity during the pandemic period. The
fine-grained analysis of sentiment in LGAs found that despite the dominant
positive sentiment most of days during the study period, some LGAs experienced
significant sentiment changes from positive to negative. This study also
analysed the sentimental dynamics delivered by the hot topics in Twitter such
as government policies (e.g. the Australia&#x27;s JobKeeper program, lockdown,
social-distancing) as well as the focused social events (e.g. the Ruby Princess
Cruise). The results showed that the policies and events did affect people&#x27;s
overall sentiment, and they affected people&#x27;s overall sentiment differently at
different stages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning with Sparse Experience Replay for Lifelong Language Learning. (arXiv:2009.04891v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Holla_N/0/1/0/all/0/1">Nithin Holla</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1">Pushkar Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Yannakoudakis_H/0/1/0/all/0/1">Helen Yannakoudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1">Ekaterina Shutova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04891">
                                    <div class="article-summary-box-inner">
                                        <span>Lifelong learning requires models that can continuously learn from sequential
streams of data without suffering catastrophic forgetting due to shifts in data
distributions. Deep learning models have thrived in the non-sequential learning
paradigm; however, when used to learn a sequence of tasks, they fail to retain
past knowledge and learn incrementally. We propose a novel approach to lifelong
learning of language tasks based on meta-learning with sparse experience replay
that directly optimizes to prevent forgetting. We show that under the realistic
setting of performing a single pass on a stream of tasks and without any task
identifiers, our method obtains state-of-the-art results on lifelong text
classification and relation extraction. We analyze the effectiveness of our
approach and further demonstrate its low computational and space complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correcting Sociodemographic Selection Biases for Population Prediction from Social Media. (arXiv:1911.03855v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Giorgi_S/0/1/0/all/0/1">Salvatore Giorgi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lynn_V/0/1/0/all/0/1">Veronica Lynn</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_K/0/1/0/all/0/1">Keshav Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_F/0/1/0/all/0/1">Farhan Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Matz_S/0/1/0/all/0/1">Sandra Matz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ungar_L/0/1/0/all/0/1">Lyle Ungar</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1">H. Andrew Schwartz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.03855">
                                    <div class="article-summary-box-inner">
                                        <span>Social media is increasingly used for large-scale population predictions,
such as estimating community health statistics. However, social media users are
not typically a representative sample of the intended population -- a
&quot;selection bias&quot;. Within the social sciences, such a bias is typically
addressed with restratification techniques, where observations are reweighted
according to how under- or over-sampled their socio-demographic groups are.
Yet, restratifaction is rarely evaluated for improving prediction. Across four
tasks of predicting U.S. county population health statistics from Twitter, we
find standard restratification techniques provide no improvement and often
degrade prediction accuracies. The core reasons for this seems to be both
shrunken estimates (reduced variance of model predicted values) and sparse
estimates of each population&#x27;s socio-demographics. We thus develop and evaluate
three methods to address these problems: estimator redistribution to account
for shrinking, and adaptive binning and informed smoothing to handle sparse
socio-demographic estimates. We show that each of these methods significantly
outperforms the standard restratification approaches. Combining approaches, we
find substantial improvements over non-restratified models, yielding a 53.0%
increase in predictive accuracy (R^2) in the case of surveyed life
satisfaction, and a 17.8% average increase across all tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Bangla Natural Language Processing Tasks and the Utility of Transformer Models. (arXiv:2107.03844v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1">Firoj Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Arid Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1">Tanvirul Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Akib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tajrin_J/0/1/0/all/0/1">Janntatul Tajrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naira Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03844">
                                    <div class="article-summary-box-inner">
                                        <span>Bangla -- ranked as the 6th most widely spoken language across the world
(https://www.ethnologue.com/guides/ethnologue200), with 230 million native
speakers -- is still considered as a low-resource language in the natural
language processing (NLP) community. With three decades of research, Bangla NLP
(BNLP) is still lagging behind mainly due to the scarcity of resources and the
challenges that come with it. There is sparse work in different areas of BNLP;
however, a thorough survey reporting previous work and recent advances is yet
to be done. In this study, we first provide a review of Bangla NLP tasks,
resources, and tools available to the research community; we benchmark datasets
collected from various platforms for nine NLP tasks using current
state-of-the-art algorithms (i.e., transformer-based models). We provide
comparative results for the studied NLP tasks by comparing monolingual vs.
multilingual models of varying sizes. We report our results using both
individual and consolidated datasets and provide data splits for future
research. We reviewed a total of 108 papers and conducted 175 sets of
experiments. Our results show promising performance using transformer-based
models while highlighting the trade-off with computational costs. We hope that
such a comprehensive survey will motivate the community to build on and further
advance the research on Bangla NLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced Bengali Language. (arXiv:2012.14353v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1">Md. Rezaul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_S/0/1/0/all/0/1">Sumon Kanti Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1">Tanhim Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_S/0/1/0/all/0/1">Sagor Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_M/0/1/0/all/0/1">Mehadi Hasan Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_K/0/1/0/all/0/1">Kabir Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md. Azam Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_S/0/1/0/all/0/1">Stefan Decker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14353">
                                    <div class="article-summary-box-inner">
                                        <span>The exponential growths of social media and micro-blogging sites not only
provide platforms for empowering freedom of expressions and individual voices,
but also enables people to express anti-social behavior like online harassment,
cyberbullying, and hate speech. Numerous works have been proposed to utilize
textual data for social and anti-social behavior analysis, by predicting the
contexts mostly for highly-resourced languages like English. However, some
languages are under-resourced, e.g., South Asian languages like Bengali, that
lack computational resources for accurate natural language processing (NLP). In
this paper, we propose an explainable approach for hate speech detection from
the under-resourced Bengali language, which we called DeepHateExplainer.
Bengali texts are first comprehensively preprocessed, before classifying them
into political, personal, geopolitical, and religious hates using a neural
ensemble method of transformer-based neural architectures (i.e., monolingual
Bangla BERT-base, multilingual BERT-cased/uncased, and XLM-RoBERTa).
Important~(most and least) terms are then identified using sensitivity analysis
and layer-wise relevance propagation~(LRP), before providing
human-interpretable explanations. Finally, we compute comprehensiveness and
sufficiency scores to measure the quality of explanations w.r.t faithfulness.
Evaluations against machine learning~(linear and tree-based models) and neural
networks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines
yield F1-scores of 78%, 91%, 89%, and 84%, for political, personal,
geopolitical, and religious hates, respectively, outperforming both ML and DNN
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-Grained Emotion Prediction by Modeling Emotion Definitions. (arXiv:2107.12135v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1">Gargi Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Brahma_D/0/1/0/all/0/1">Dhanajit Brahma</a>, <a href="http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1">Piyush Rai</a>, <a href="http://arxiv.org/find/cs/1/au:+Modi_A/0/1/0/all/0/1">Ashutosh Modi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12135">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a new framework for fine-grained emotion prediction
in the text through emotion definition modeling. Our approach involves a
multi-task learning framework that models definitions of emotions as an
auxiliary task while being trained on the primary task of emotion prediction.
We model definitions using masked language modeling and class definition
prediction tasks. Our models outperform existing state-of-the-art for
fine-grained emotion dataset GoEmotions. We further show that this trained
model can be used for transfer learning on other benchmark datasets in emotion
prediction with varying emotion label sets, domains, and sizes. The proposed
models outperform the baselines on transfer learning experiments demonstrating
the generalization capability of the models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Lay Language Summarization of Biomedical Scientific Reviews. (arXiv:2012.12573v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yue Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1">Wei Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yizhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1">Trevor Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12573">
                                    <div class="article-summary-box-inner">
                                        <span>Health literacy has emerged as a crucial factor in making appropriate health
decisions and ensuring treatment outcomes. However, medical jargon and the
complex structure of professional language in this domain make health
information especially hard to interpret. Thus, there is an urgent unmet need
for automated methods to enhance the accessibility of the biomedical literature
to the general population. This problem can be framed as a type of translation
problem between the language of healthcare professionals, and that of the
general public. In this paper, we introduce the novel task of automated
generation of lay language summaries of biomedical scientific reviews, and
construct a dataset to support the development and evaluation of automated
methods through which to enhance the accessibility of the biomedical
literature. We conduct analyses of the various challenges in solving this task,
including not only summarization of the key points but also explanation of
background knowledge and simplification of professional language. We experiment
with state-of-the-art summarization models as well as several data augmentation
techniques, and evaluate their performance using both automated metrics and
human assessment. Results indicate that automatically generated summaries
produced using contemporary neural architectures can achieve promising quality
and readability as compared with reference summaries developed for the lay
public by experts (best ROUGE-L of 50.24 and Flesch-Kincaid readability score
of 13.30). We also discuss the limitations of the current attempt, providing
insights and directions for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact. (arXiv:2106.02359v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhijing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chauhan_G/0/1/0/all/0/1">Geeticka Chauhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tse_B/0/1/0/all/0/1">Brian Tse</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1">Mrinmaya Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02359">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen many breakthroughs in natural language processing
(NLP), transitioning it from a mostly theoretical field to one with many
real-world applications. Noting the rising number of applications of other
machine learning and AI techniques with pervasive societal impact, we
anticipate the rising importance of developing NLP technologies for social
good. Inspired by theories in moral philosophy and global priorities research,
we aim to promote a guideline for social good in the context of NLP. We lay the
foundations via the moral philosophy definition of social good, propose a
framework to evaluate the direct and indirect real-world impact of NLP tasks,
and adopt the methodology of global priorities research to identify priority
causes for NLP research. Finally, we use our theoretical framework to provide
some practical guidelines for future NLP research for social good. Our data and
code are available at this http URL In
addition, we curate a list of papers and resources on NLP for social good at
https://github.com/zhijing-jin/NLP4SocialGood_Papers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Factuality in Abstractive Summarization with FRANK: A Benchmark for Factuality Metrics. (arXiv:2104.13346v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pagnoni_A/0/1/0/all/0/1">Artidoro Pagnoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Balachandran_V/0/1/0/all/0/1">Vidhisha Balachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1">Yulia Tsvetkov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13346">
                                    <div class="article-summary-box-inner">
                                        <span>Modern summarization models generate highly fluent but often factually
unreliable outputs. This motivated a surge of metrics attempting to measure the
factuality of automatically generated summaries. Due to the lack of common
benchmarks, these metrics cannot be compared. Moreover, all these methods treat
factuality as a binary concept and fail to provide deeper insights into the
kinds of inconsistencies made by different systems. To address these
limitations, we devise a typology of factual errors and use it to collect human
annotations of generated summaries from state-of-the-art summarization systems
for the CNN/DM and XSum datasets. Through these annotations, we identify the
proportion of different categories of factual errors in various summarization
models and benchmark factuality metrics, showing their correlation with human
judgment as well as their specific strengths and weaknesses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Out of Order: How Important Is The Sequential Order of Words in a Sentence in Natural Language Understanding Tasks?. (arXiv:2012.15180v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1">Thang M. Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Trung Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Mai_L/0/1/0/all/0/1">Long Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">Anh Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15180">
                                    <div class="article-summary-box-inner">
                                        <span>Do state-of-the-art natural language understanding models care about word
order - one of the most important characteristics of a sequence? Not always! We
found 75% to 90% of the correct predictions of BERT-based classifiers, trained
on many GLUE tasks, remain constant after input words are randomly shuffled.
Despite BERT embeddings are famously contextual, the contribution of each
individual word to downstream tasks is almost unchanged even after the word&#x27;s
context is shuffled. BERT-based models are able to exploit superficial cues
(e.g. the sentiment of keywords in sentiment analysis; or the word-wise
similarity between sequence-pair inputs in natural language inference) to make
correct decisions when tokens are arranged in random orders. Encouraging
classifiers to capture word order information improves the performance on most
GLUE tasks, SQuAD 2.0 and out-of-samples. Our work suggests that many GLUE
tasks are not challenging machines to understand the meaning of a sentence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DYPLODOC: Dynamic Plots for Document Classification. (arXiv:2107.12226v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malysheva_A/0/1/0/all/0/1">Anastasia Malysheva</a>, <a href="http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1">Alexey Tikhonov</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamshchikov_I/0/1/0/all/0/1">Ivan P. Yamshchikov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12226">
                                    <div class="article-summary-box-inner">
                                        <span>Narrative generation and analysis are still on the fringe of modern natural
language processing yet are crucial in a variety of applications. This paper
proposes a feature extraction method for plot dynamics. We present a dataset
that consists of the plot descriptions for thirteen thousand TV shows alongside
meta-information on their genres and dynamic plots extracted from them. We
validate the proposed tool for plot dynamics extraction and discuss possible
applications of this method to the tasks of narrative analysis and generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dialectal Layers in West Iranian: a Hierarchical Dirichlet Process Approach to Linguistic Relationships. (arXiv:2001.05297v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cathcart_C/0/1/0/all/0/1">Chundra Aroor Cathcart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.05297">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses a series of complex and unresolved issues in the
historical phonology of West Iranian languages. The West Iranian languages
(Persian, Kurdish, Balochi, and other languages) display a high degree of
non-Lautgesetzlich behavior. Most of this irregularity is undoubtedly due to
language contact; we argue, however, that an oversimplified view of the
processes at work has prevailed in the literature on West Iranian dialectology,
with specialists assuming that deviations from an expected outcome in a given
non-Persian language are due to lexical borrowing from some chronological stage
of Persian. It is demonstrated that this qualitative approach yields at times
problematic conclusions stemming from the lack of explicit probabilistic
inferences regarding the distribution of the data: Persian may not be the sole
donor language; additionally, borrowing at the lexical level is not always the
mechanism that introduces irregularity. In many cases, the possibility that
West Iranian languages show different reflexes in different conditioning
environments remains under-explored. We employ a novel Bayesian approach
designed to overcome these problems and tease apart the different determinants
of irregularity in patterns of West Iranian sound change. Our methodology
allows us to provisionally resolve a number of outstanding questions in the
literature on West Iranian dialectology concerning the dialectal affiliation of
certain sound changes. We outline future directions for work of this sort.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Span-Level Interactions for Aspect Sentiment Triplet Extraction. (arXiv:2107.12214v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chia_Y/0/1/0/all/0/1">Yew Ken Chia</a>, <a href="http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1">Lidong Bing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12214">
                                    <div class="article-summary-box-inner">
                                        <span>Aspect Sentiment Triplet Extraction (ASTE) is the most recent subtask of ABSA
which outputs triplets of an aspect target, its associated sentiment, and the
corresponding opinion term. Recent models perform the triplet extraction in an
end-to-end manner but heavily rely on the interactions between each target word
and opinion word. Thereby, they cannot perform well on targets and opinions
which contain multiple words. Our proposed span-level approach explicitly
considers the interaction between the whole spans of targets and opinions when
predicting their sentiment relation. Thus, it can make predictions with the
semantics of whole spans, ensuring better sentiment consistency. To ease the
high computational cost caused by span enumeration, we propose a dual-channel
span pruning strategy by incorporating supervision from the Aspect Term
Extraction (ATE) and Opinion Term Extraction (OTE) tasks. This strategy not
only improves computational efficiency but also distinguishes the opinion and
target spans more properly. Our framework simultaneously achieves strong
performance for the ASTE as well as ATE and OTE tasks. In particular, our
analysis shows that our span-level approach achieves more significant
improvements over the baselines on triplets with multi-word targets or
opinions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Negation in Neural Machine Translation. (arXiv:2107.12203v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_G/0/1/0/all/0/1">Gongbo Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ronchen_P/0/1/0/all/0/1">Philipp R&#xf6;nchen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sennrich_R/0/1/0/all/0/1">Rico Sennrich</a>, <a href="http://arxiv.org/find/cs/1/au:+Nivre_J/0/1/0/all/0/1">Joakim Nivre</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12203">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we evaluate the translation of negation both automatically and
manually, in English--German (EN--DE) and English--Chinese (EN--ZH). We show
that the ability of neural machine translation (NMT) models to translate
negation has improved with deeper and more advanced networks, although the
performance varies between language pairs and translation directions. The
accuracy of manual evaluation in EN-DE, DE-EN, EN-ZH, and ZH-EN is 95.7%,
94.8%, 93.4%, and 91.7%, respectively. In addition, we show that
under-translation is the most significant error type in NMT, which contrasts
with the more diverse error profile previously observed for statistical machine
translation. To better understand the root of the under-translation of
negation, we study the model&#x27;s information flow and training data. While our
information flow analysis does not reveal any deficiencies that could be used
to detect or fix the under-translation of negation, we find that negation is
often rephrased during training, which could make it more difficult for the
model to learn a reliable link between source and target negation. We finally
conduct intrinsic analysis and extrinsic probing tasks on negation, showing
that NMT models can distinguish negation and non-negation tokens very well and
encode a lot of information about negation in hidden states but nevertheless
leave room for improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Language Model for Efficient Linguistic Steganalysis: An Empirical Study. (arXiv:2107.12168v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yi_B/0/1/0/all/0/1">Biao Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hanzhou Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_G/0/1/0/all/0/1">Guorui Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinpeng Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12168">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in linguistic steganalysis have successively applied CNNs,
RNNs, GNNs and other deep learning models for detecting secret information in
generative texts. These methods tend to seek stronger feature extractors to
achieve higher steganalysis effects. However, we have found through experiments
that there actually exists significant difference between automatically
generated steganographic texts and carrier texts in terms of the conditional
probability distribution of individual words. Such kind of statistical
difference can be naturally captured by the language model used for generating
steganographic texts, which drives us to give the classifier a priori knowledge
of the language model to enhance the steganalysis ability. To this end, we
present two methods to efficient linguistic steganalysis in this paper. One is
to pre-train a language model based on RNN, and the other is to pre-train a
sequence autoencoder. Experimental results show that the two methods have
different degrees of performance improvement when compared to the randomly
initialized RNN classifier, and the convergence speed is significantly
accelerated. Moreover, our methods have achieved the best detection results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On embedding Lambek calculus into commutative categorial grammars. (arXiv:2005.10058v3 [math.LO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Slavnov_S/0/1/0/all/0/1">Sergey Slavnov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.10058">
                                    <div class="article-summary-box-inner">
                                        <span>We consider tensor grammars, which are an example of \commutative&quot; grammars,
based on the classical (rather than intuitionistic) linear logic. They can be
seen as a surface representation of abstract categorial grammars ACG in the
sense that derivations of ACG translate to derivations of tensor grammars and
this translation is isomorphic on the level of string languages. The basic
ingredient are tensor terms, which can be seen as encoding and generalizing
proof-nets. Using tensor terms makes the syntax extremely simple and a direct
geometric meaning becomes transparent. Then we address the problem of encoding
noncommutative operations in our setting. This turns out possible after
enriching the system with new unary operators. The resulting system allows
representing both ACG and Lambek grammars as conservative fragments, while the
formalism remains, as it seems to us, rather simple and intuitive.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilingual Coreference Resolution with Harmonized Annotations. (arXiv:2107.12088v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Prazak_O/0/1/0/all/0/1">Ond&#x159;ej Pra&#x17e;&#xe1;k</a>, <a href="http://arxiv.org/find/cs/1/au:+Konopik_M/0/1/0/all/0/1">Miloslav Konop&#xed;k</a>, <a href="http://arxiv.org/find/cs/1/au:+Sido_J/0/1/0/all/0/1">Jakub Sido</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12088">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present coreference resolution experiments with a newly
created multilingual corpus CorefUD. We focus on the following languages:
Czech, Russian, Polish, German, Spanish, and Catalan. In addition to
monolingual experiments, we combine the training data in multilingual
experiments and train two joined models -- for Slavic languages and for all the
languages together. We rely on an end-to-end deep learning model that we
slightly adapted for the CorefUD corpus. Our results show that we can profit
from harmonized annotations, and using joined models helps significantly for
the languages with smaller training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Analysis of LIME for Text Data. (arXiv:2010.12487v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mardaoui_D/0/1/0/all/0/1">Dina Mardaoui</a>, <a href="http://arxiv.org/find/stat/1/au:+Garreau_D/0/1/0/all/0/1">Damien Garreau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12487">
                                    <div class="article-summary-box-inner">
                                        <span>Text data are increasingly handled in an automated fashion by machine
learning algorithms. But the models handling these data are not always
well-understood due to their complexity and are more and more often referred to
as &quot;black-boxes.&quot; Interpretability methods aim to explain how these models
operate. Among them, LIME has become one of the most popular in recent years.
However, it comes without theoretical guarantees: even for simple models, we
are not sure that LIME behaves accurately. In this paper, we provide a first
theoretical analysis of LIME for text data. As a consequence of our theoretical
findings, we show that LIME indeed provides meaningful explanations for simple
models, namely decision trees and linear models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformer-based End-to-End Speech Recognition with Local Dense Synthesizer Attention. (arXiv:2010.12155v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Menglong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shengqiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao-Lei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12155">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, several studies reported that dot-product selfattention (SA) may
not be indispensable to the state-of-theart Transformer models. Motivated by
the fact that dense synthesizer attention (DSA), which dispenses with dot
products and pairwise interactions, achieved competitive results in many
language processing tasks, in this paper, we first propose a DSA-based speech
recognition, as an alternative to SA. To reduce the computational complexity
and improve the performance, we further propose local DSA (LDSA) to restrict
the attention scope of DSA to a local range around the current central frame
for speech recognition. Finally, we combine LDSA with SA to extract the local
and global information simultaneously. Experimental results on the Ai-shell1
Mandarine speech recognition corpus show that the proposed LDSA-Transformer
achieves a character error rate (CER) of 6.49%, which is slightly better than
that of the SA-Transformer. Meanwhile, the LDSA-Transformer requires less
computation than the SATransformer. The proposed combination method not only
achieves a CER of 6.18%, which significantly outperforms the SA-Transformer,
but also has roughly the same number of parameters and computational complexity
as the latter. The implementation of the multi-head LDSA is available at
https://github.com/mlxu995/multihead-LDSA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Thought Flow Nets: From Single Predictions to Trains of Model Thought. (arXiv:2107.12220v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schuff_H/0/1/0/all/0/1">Hendrik Schuff</a>, <a href="http://arxiv.org/find/cs/1/au:+Adel_H/0/1/0/all/0/1">Heike Adel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1">Ngoc Thang Vu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12220">
                                    <div class="article-summary-box-inner">
                                        <span>When humans solve complex problems, they rarely come up with a decision
right-away. Instead, they start with an intuitive decision, reflect upon it,
spot mistakes, resolve contradictions and jump between different hypotheses.
Thus, they create a sequence of ideas and follow a train of thought that
ultimately reaches a conclusive decision. Contrary to this, today&#x27;s neural
classification models are mostly trained to map an input to one single and
fixed output. In this paper, we investigate how we can give models the
opportunity of a second, third and $k$-th thought. We take inspiration from
Hegel&#x27;s dialectics and propose a method that turns an existing classifier&#x27;s
class prediction (such as the image class forest) into a sequence of
predictions (such as forest $\rightarrow$ tree $\rightarrow$ mushroom).
Concretely, we propose a correction module that is trained to estimate the
model&#x27;s correctness as well as an iterative prediction update based on the
prediction&#x27;s gradient. Our approach results in a dynamic system over class
probability distributions $\unicode{x2014}$ the thought flow. We evaluate our
method on diverse datasets and tasks from computer vision and natural language
processing. We observe surprisingly complex but intuitive behavior and
demonstrate that our method (i) can correct misclassifications, (ii)
strengthens model performance, (iii) is robust to high levels of adversarial
attacks, (iv) can increase accuracy up to 4% in a label-distribution-shift
setting and (iv) provides a tool for model interpretability that uncovers model
knowledge which otherwise remains invisible in a single distribution
prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aligning AI With Shared Human Values. (arXiv:2008.02275v5 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1">Dan Hendrycks</a>, <a href="http://arxiv.org/find/cs/1/au:+Burns_C/0/1/0/all/0/1">Collin Burns</a>, <a href="http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1">Steven Basart</a>, <a href="http://arxiv.org/find/cs/1/au:+Critch_A/0/1/0/all/0/1">Andrew Critch</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jerry Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dawn Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1">Jacob Steinhardt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02275">
                                    <div class="article-summary-box-inner">
                                        <span>We show how to assess a language model&#x27;s knowledge of basic concepts of
morality. We introduce the ETHICS dataset, a new benchmark that spans concepts
in justice, well-being, duties, virtues, and commonsense morality. Models
predict widespread moral judgments about diverse text scenarios. This requires
connecting physical and social world knowledge to value judgements, a
capability that may enable us to steer chatbot outputs or eventually regularize
open-ended reinforcement learning agents. With the ETHICS dataset, we find that
current language models have a promising but incomplete ability to predict
basic human ethical judgements. Our work shows that progress can be made on
machine ethics today, and it provides a steppingstone toward AI that is aligned
with human values.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One Question Answering Model for Many Languages with Cross-lingual Dense Passage Retrieval. (arXiv:2107.11976v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1">Akari Asai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xinyan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasai_J/0/1/0/all/0/1">Jungo Kasai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11976">
                                    <div class="article-summary-box-inner">
                                        <span>We present CORA, a Cross-lingual Open-Retrieval Answer Generation model that
can answer questions across many languages even when language-specific
annotated data or knowledge sources are unavailable. We introduce a new dense
passage retrieval algorithm that is trained to retrieve documents across
languages for a question. Combined with a multilingual autoregressive
generation model, CORA answers directly in the target language without any
translation or in-language retrieval modules as used in prior work. We propose
an iterative training method that automatically extends annotated data
available only in high-resource languages to low-resource ones. Our results
show that CORA substantially outperforms the previous state of the art on
multilingual open question answering benchmarks across 26 languages, 9 of which
are unseen during training. Our analyses show the significance of cross-lingual
retrieval and generation in many languages, particularly under low-resource
settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Knowledge Graph and Attention Help? A Quantitative Analysis into Bag-level Relation Extraction. (arXiv:2107.12064v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zikun Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1">Yixin Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1">Lifu Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1">Tat-Seng Chua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12064">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Graph (KG) and attention mechanism have been demonstrated effective
in introducing and selecting useful information for weakly supervised methods.
However, only qualitative analysis and ablation study are provided as evidence.
In this paper, we contribute a dataset and propose a paradigm to quantitatively
evaluate the effect of attention and KG on bag-level relation extraction (RE).
We find that (1) higher attention accuracy may lead to worse performance as it
may harm the model&#x27;s ability to extract entity mention features; (2) the
performance of attention is largely influenced by various noise distribution
patterns, which is closely related to real-world datasets; (3) KG-enhanced
attention indeed improves RE performance, while not through enhanced attention
but by incorporating entity prior; and (4) attention mechanism may exacerbate
the issue of insufficient training data. Based on these findings, we show that
a straightforward variant of RE model can achieve significant improvements (6%
AUC on average) on two real-world datasets as compared with three
state-of-the-art baselines. Our codes and datasets are available at
https://github.com/zig-kwin-hu/how-KG-ATT-help.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transferable Dialogue Systems and User Simulators. (arXiv:2107.11904v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tseng_B/0/1/0/all/0/1">Bo-Hsiang Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1">Yinpei Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreyssig_F/0/1/0/all/0/1">Florian Kreyssig</a>, <a href="http://arxiv.org/find/cs/1/au:+Byrne_B/0/1/0/all/0/1">Bill Byrne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11904">
                                    <div class="article-summary-box-inner">
                                        <span>One of the difficulties in training dialogue systems is the lack of training
data. We explore the possibility of creating dialogue data through the
interaction between a dialogue system and a user simulator. Our goal is to
develop a modelling framework that can incorporate new dialogue scenarios
through self-play between the two agents. In this framework, we first pre-train
the two agents on a collection of source domain dialogues, which equips the
agents to converse with each other via natural language. With further
fine-tuning on a small amount of target domain data, the agents continue to
interact with the aim of improving their behaviors using reinforcement learning
with structured reward functions. In experiments on the MultiWOZ dataset, two
practical transfer learning problems are investigated: 1) domain adaptation and
2) single-to-multiple domain transfer. We demonstrate that the proposed
framework is highly effective in bootstrapping the performance of the two
agents in transfer learning. We also show that our method leads to improvements
in dialogue system performance on complete datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Convolutional Network with Generalized Factorized Bilinear Aggregation. (arXiv:2107.11666v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1">Piotr Koniusz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11666">
                                    <div class="article-summary-box-inner">
                                        <span>Although Graph Convolutional Networks (GCNs) have demonstrated their power in
various applications, the graph convolutional layers, as the most important
component of GCN, are still using linear transformations and a simple pooling
step. In this paper, we propose a novel generalization of Factorized Bilinear
(FB) layer to model the feature interactions in GCNs. FB performs two
matrix-vector multiplications, that is, the weight matrix is multiplied with
the outer product of the vector of hidden features from both sides. However,
the FB layer suffers from the quadratic number of coefficients, overfitting and
the spurious correlations due to correlations between channels of hidden
representations that violate the i.i.d. assumption. Thus, we propose a compact
FB layer by defining a family of summarizing operators applied over the
quadratic term. We analyze proposed pooling operators and motivate their use.
Our experimental results on multiple datasets demonstrate that the GFB-GCN is
competitive with other methods for text classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid Autoregressive Solver for Scalable Abductive Natural Language Inference. (arXiv:2107.11879v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1">Marco Valentino</a>, <a href="http://arxiv.org/find/cs/1/au:+Thayaparan_M/0/1/0/all/0/1">Mokanarangan Thayaparan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferreira_D/0/1/0/all/0/1">Deborah Ferreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1">Andr&#xe9; Freitas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11879">
                                    <div class="article-summary-box-inner">
                                        <span>Regenerating natural language explanations for science questions is a
challenging task for evaluating complex multi-hop and abductive inference
capabilities. In this setting, Transformers trained on human-annotated
explanations achieve state-of-the-art performance when adopted as cross-encoder
architectures. However, while much attention has been devoted to the quality of
the constructed explanations, the problem of performing abductive inference at
scale is still under-studied. As intrinsically not scalable, the cross-encoder
architectural paradigm is not suitable for efficient multi-hop inference on
massive facts banks. To maximise both accuracy and inference time, we propose a
hybrid abductive solver that autoregressively combines a dense bi-encoder with
a sparse model of explanatory power, computed leveraging explicit patterns in
the explanations. Our experiments demonstrate that the proposed framework can
achieve performance comparable with the state-of-the-art cross-encoder while
being $\approx 50$ times faster and scalable to corpora of millions of facts.
Moreover, we study the impact of the hybridisation on semantic drift and
science question answering without additional training, showing that it boosts
the quality of the explanations and contributes to improved downstream
inference performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-free Multi-hop Reading Comprehension: A Select-to-Guide Strategy. (arXiv:2107.11823v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bohong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hai Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11823">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-hop reading comprehension (MHRC) requires not only to predict the
correct answer span in the given passage, but also to provide a chain of
supporting evidences for reasoning interpretability. It is natural to model
such a process into graph structure by understanding multi-hop reasoning as
jumping over entity nodes, which has made graph modelling dominant on this
task. Recently, there have been dissenting voices about whether graph modelling
is indispensable due to the inconvenience of the graph building, however
existing state-of-the-art graph-free attempts suffer from huge performance gap
compared to graph-based ones. This work presents a novel graph-free alternative
which firstly outperform all graph models on MHRC. In detail, we exploit a
select-to-guide (S2G) strategy to accurately retrieve evidence paragraphs in a
coarse-to-fine manner, incorporated with two novel attention mechanisms, which
surprisingly shows conforming to the nature of multi-hop reasoning. Our
graph-free model achieves significant and consistent performance gain over
strong baselines and the current new state-of-the-art on the MHRC benchmark,
HotpotQA, among all the published works.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Controlled and Diverse Generation of Article Comments. (arXiv:2107.11781v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Linhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Houfeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11781">
                                    <div class="article-summary-box-inner">
                                        <span>Much research in recent years has focused on automatic article commenting.
However, few of previous studies focus on the controllable generation of
comments. Besides, they tend to generate dull and commonplace comments, which
further limits their practical application. In this paper, we make the first
step towards controllable generation of comments, by building a system that can
explicitly control the emotion of the generated comments. To achieve this, we
associate each kind of emotion category with an embedding and adopt a dynamic
fusion mechanism to fuse this embedding into the decoder. A sentence-level
emotion classifier is further employed to better guide the model to generate
comments expressing the desired emotion. To increase the diversity of the
generated comments, we propose a hierarchical copy mechanism that allows our
model to directly copy words from the input articles. We also propose a
restricted beam search (RBS) algorithm to increase intra-sentence diversity.
Experimental results show that our model can generate informative and diverse
comments that express the desired emotions with high accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Argumentative Dialogue System for COVID-19 Vaccine Information. (arXiv:2107.12079v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fazzinga_B/0/1/0/all/0/1">Bettina Fazzinga</a>, <a href="http://arxiv.org/find/cs/1/au:+Galassi_A/0/1/0/all/0/1">Andrea Galassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torroni_P/0/1/0/all/0/1">Paolo Torroni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12079">
                                    <div class="article-summary-box-inner">
                                        <span>Dialogue systems are widely used in AI to support timely and interactive
communication with users. We propose a general-purpose dialogue system
architecture that leverages computational argumentation and state-of-the-art
language technologies. We illustrate and evaluate the system using a COVID-19
vaccine information case study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context-aware Adversarial Training for Name Regularity Bias in Named Entity Recognition. (arXiv:2107.11610v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghaddar_A/0/1/0/all/0/1">Abbas Ghaddar</a>, <a href="http://arxiv.org/find/cs/1/au:+Langlais_P/0/1/0/all/0/1">Philippe Langlais</a>, <a href="http://arxiv.org/find/cs/1/au:+Rashid_A/0/1/0/all/0/1">Ahmad Rashid</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezagholizadeh_M/0/1/0/all/0/1">Mehdi Rezagholizadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11610">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we examine the ability of NER models to use contextual
information when predicting the type of an ambiguous entity. We introduce NRB,
a new testbed carefully designed to diagnose Name Regularity Bias of NER
models. Our results indicate that all state-of-the-art models we tested show
such a bias; BERT fine-tuned models significantly outperforming feature-based
(LSTM-CRF) ones on NRB, despite having comparable (sometimes lower) performance
on standard benchmarks.

To mitigate this bias, we propose a novel model-agnostic training method that
adds learnable adversarial noise to some entity mentions, thus enforcing models
to focus more strongly on the contextual signal, leading to significant gains
on NRB. Combining it with two other training strategies, data augmentation and
parameter freezing, leads to further gains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learn to Focus: Hierarchical Dynamic Copy Network for Dialogue State Tracking. (arXiv:2107.11778v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Linhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Houfeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11778">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, researchers have explored using the encoder-decoder framework to
tackle dialogue state tracking (DST), which is a key component of task-oriented
dialogue systems. However, they regard a multi-turn dialogue as a flat
sequence, failing to focus on useful information when the sequence is long. In
this paper, we propose a Hierarchical Dynamic Copy Network (HDCN) to facilitate
focusing on the most informative turn, making it easier to extract slot values
from the dialogue context. Based on the encoder-decoder framework, we adopt a
hierarchical copy approach that calculates two levels of attention at the word-
and turn-level, which are then renormalized to obtain the final copy
distribution. A focus loss term is employed to encourage the model to assign
the highest turn-level attention weight to the most informative turn.
Experimental results show that our model achieves 46.76% joint accuracy on the
MultiWOZ 2.1 dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preliminary Steps Towards Federated Sentiment Classification. (arXiv:2107.11956v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin-Chun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1">Yunfeng Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bingshuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shaoming Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11956">
                                    <div class="article-summary-box-inner">
                                        <span>Automatically mining sentiment tendency contained in natural language is a
fundamental research to some artificial intelligent applications, where
solutions alternate with challenges. Transfer learning and multi-task learning
techniques have been leveraged to mitigate the supervision sparsity and
collaborate multiple heterogeneous domains correspondingly. Recent years, the
sensitive nature of users&#x27; private data raises another challenge for sentiment
classification, i.e., data privacy protection. In this paper, we resort to
federated learning for multiple domain sentiment classification under the
constraint that the corpora must be stored on decentralized devices. In view of
the heterogeneous semantics across multiple parties and the peculiarities of
word embedding, we pertinently provide corresponding solutions. First, we
propose a Knowledge Transfer Enhanced Private-Shared (KTEPS) framework for
better model aggregation and personalization in federated sentiment
classification. Second, we propose KTEPS$^\star$ with the consideration of the
rich semantic and huge embedding size properties of word vectors, utilizing
Projection-based Dimension Reduction (PDR) methods for privacy protection and
efficient transmission simultaneously. We propose two federated sentiment
classification scenes based on public benchmarks, and verify the superiorities
of our proposed methods with abundant experimental investigations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stress Test Evaluation of Biomedical Word Embeddings. (arXiv:2107.11652v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Araujo_V/0/1/0/all/0/1">Vladimir Araujo</a>, <a href="http://arxiv.org/find/cs/1/au:+Carvallo_A/0/1/0/all/0/1">Andr&#xe9;s Carvallo</a>, <a href="http://arxiv.org/find/cs/1/au:+Aspillaga_C/0/1/0/all/0/1">Carlos Aspillaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Thorne_C/0/1/0/all/0/1">Camilo Thorne</a>, <a href="http://arxiv.org/find/cs/1/au:+Parra_D/0/1/0/all/0/1">Denis Parra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11652">
                                    <div class="article-summary-box-inner">
                                        <span>The success of pretrained word embeddings has motivated their use in the
biomedical domain, with contextualized embeddings yielding remarkable results
in several biomedical NLP tasks. However, there is a lack of research on
quantifying their behavior under severe &quot;stress&quot; scenarios. In this work, we
systematically evaluate three language models with adversarial examples --
automatically constructed tests that allow us to examine how robust the models
are. We propose two types of stress scenarios focused on the biomedical named
entity recognition (NER) task, one inspired by spelling errors and another
based on the use of synonyms for medical terms. Our experiments with three
benchmarks show that the performance of the original models decreases
considerably, in addition to revealing their weaknesses and strengths. Finally,
we show that adversarial training causes the models to improve their robustness
and even to exceed the original performance in some cases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for Sequences. (arXiv:2107.11906v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenhai Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1">Radu Soricut</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11906">
                                    <div class="article-summary-box-inner">
                                        <span>We describe an efficient hierarchical method to compute attention in the
Transformer architecture. The proposed attention mechanism exploits a matrix
structure similar to the Hierarchical Matrix (H-Matrix) developed by the
numerical analysis community, and has linear run time and memory complexity. We
perform extensive experiments to show that the inductive bias embodied by our
hierarchical attention is effective in capturing the hierarchical structure in
the sequences typical for natural language and vision tasks. Our method is
superior to alternative sub-quadratic proposals by over +6 points on average on
the Long Range Arena benchmark. It also sets a new SOTA test perplexity on
One-Billion Word dataset with 5x fewer model parameters than that of the
previous-best Transformer-based models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MIPE: A Metric Independent Pipeline for Effective Code-Mixed NLG Evaluation. (arXiv:2107.11534v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1">Ayush Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Kagi_S/0/1/0/all/0/1">Sammed S Kagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_V/0/1/0/all/0/1">Vivek Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1">Mayank Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11534">
                                    <div class="article-summary-box-inner">
                                        <span>Code-mixing is a phenomenon of mixing words and phrases from two or more
languages in a single utterance of speech and text. Due to the high linguistic
diversity, code-mixing presents several challenges in evaluating standard
natural language generation (NLG) tasks. Various widely popular metrics perform
poorly with the code-mixed NLG tasks. To address this challenge, we present a
metric independent evaluation pipeline MIPE that significantly improves the
correlation between evaluation metrics and human judgments on the generated
code-mixed text. As a use case, we demonstrate the performance of MIPE on the
machine-generated Hinglish (code-mixing of Hindi and English languages)
sentences from the HinGE corpus. We can extend the proposed evaluation strategy
to other code-mixed language pairs, NLG tasks, and evaluation metrics with
minimal to no effort.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Brazilian Portuguese Speech Recognition Using Wav2vec 2.0. (arXiv:2107.11414v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gris_L/0/1/0/all/0/1">Lucas Rafael Stefanel Gris</a>, <a href="http://arxiv.org/find/cs/1/au:+Casanova_E/0/1/0/all/0/1">Edresson Casanova</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_F/0/1/0/all/0/1">Frederico Santos de Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Soares_A/0/1/0/all/0/1">Anderson da Silva Soares</a>, <a href="http://arxiv.org/find/cs/1/au:+Junior_A/0/1/0/all/0/1">Arnaldo Candido Junior</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11414">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning techniques have been shown to be efficient in various tasks,
especially in the development of speech recognition systems, that is, systems
that aim to transcribe a sentence in audio in a sequence of words. Despite the
progress in the area, speech recognition can still be considered difficult,
especially for languages lacking available data, as Brazilian Portuguese. In
this sense, this work presents the development of an public Automatic Speech
Recognition system using only open available audio data, from the fine-tuning
of the Wav2vec 2.0 XLSR-53 model pre-trained in many languages over Brazilian
Portuguese data. The final model presents a Word Error Rate of 11.95% (Common
Voice Dataset). This corresponds to 13% less than the best open Automatic
Speech Recognition model for Brazilian Portuguese available according to our
best knowledge, which is a promising result for the language. In general, this
work validates the use of self-supervising learning techniques, in special, the
use of the Wav2vec 2.0 architecture in the development of robust systems, even
for languages having few available data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Similarity Based Label Smoothing For Dialogue Generation. (arXiv:2107.11481v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Sougata Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Souvik Das</a>, <a href="http://arxiv.org/find/cs/1/au:+Srihari_R/0/1/0/all/0/1">Rohini Srihari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11481">
                                    <div class="article-summary-box-inner">
                                        <span>Generative neural conversational systems are generally trained with the
objective of minimizing the entropy loss between the training &quot;hard&quot; targets
and the predicted logits. Often, performance gains and improved generalization
can be achieved by using regularization techniques like label smoothing, which
converts the training &quot;hard&quot; targets to &quot;soft&quot; targets. However, label
smoothing enforces a data independent uniform distribution on the incorrect
training targets, which leads to an incorrect assumption of equi-probable
incorrect targets for each correct target. In this paper we propose and
experiment with incorporating data dependent word similarity based weighing
methods to transforms the uniform distribution of the incorrect target
probabilities in label smoothing, to a more natural distribution based on
semantics. We introduce hyperparameters to control the incorrect target
distribution, and report significant performance gains over networks trained
using standard label smoothing based loss, on two standard open domain dialogue
corpora.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extending Challenge Sets to Uncover Gender Bias in Machine Translation: Impact of Stereotypical Verbs and Adjectives. (arXiv:2107.11584v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Troles_J/0/1/0/all/0/1">Jonas-Dario Troles</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmid_U/0/1/0/all/0/1">Ute Schmid</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11584">
                                    <div class="article-summary-box-inner">
                                        <span>Human gender bias is reflected in language and text production. Because
state-of-the-art machine translation (MT) systems are trained on large corpora
of text, mostly generated by humans, gender bias can also be found in MT. For
instance when occupations are translated from a language like English, which
mostly uses gender neutral words, to a language like German, which mostly uses
a feminine and a masculine version for an occupation, a decision must be made
by the MT System. Recent research showed that MT systems are biased towards
stereotypical translation of occupations. In 2019 the first, and so far only,
challenge set, explicitly designed to measure the extent of gender bias in MT
systems has been published. In this set measurement of gender bias is solely
based on the translation of occupations. In this paper we present an extension
of this challenge set, called WiBeMT, with gender-biased adjectives and adds
sentences with gender-biased verbs. The resulting challenge set consists of
over 70, 000 sentences and has been translated with three commercial MT
systems: DeepL Translator, Microsoft Translator, and Google Translate. Results
show a gender bias for all three MT systems. This gender bias is to a great
extent significantly influenced by adjectives and to a lesser extent by verbs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MuSe-Toolbox: The Multimodal Sentiment Analysis Continuous Annotation Fusion and Discrete Class Transformation Toolbox. (arXiv:2107.11757v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stappen_L/0/1/0/all/0/1">Lukas Stappen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schumann_L/0/1/0/all/0/1">Lea Schumann</a>, <a href="http://arxiv.org/find/cs/1/au:+Sertolli_B/0/1/0/all/0/1">Benjamin Sertolli</a>, <a href="http://arxiv.org/find/cs/1/au:+Baird_A/0/1/0/all/0/1">Alice Baird</a>, <a href="http://arxiv.org/find/cs/1/au:+Weigel_B/0/1/0/all/0/1">Benjamin Weigel</a>, <a href="http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1">Erik Cambria</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1">Bj&#xf6;rn W. Schuller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11757">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the MuSe-Toolbox - a Python-based open-source toolkit for
creating a variety of continuous and discrete emotion gold standards. In a
single framework, we unify a wide range of fusion methods and propose the novel
Rater Aligned Annotation Weighting (RAAW), which aligns the annotations in a
translation-invariant way before weighting and fusing them based on the
inter-rater agreements between the annotations. Furthermore, discrete
categories tend to be easier for humans to interpret than continuous signals.
With this in mind, the MuSe-Toolbox provides the functionality to run
exhaustive searches for meaningful class clusters in the continuous gold
standards. To our knowledge, this is the first toolkit that provides a wide
selection of state-of-the-art emotional gold standard methods and their
transformation to discrete classes. Experimental results indicate that
MuSe-Toolbox can provide promising and novel class formations which can be
better predicted than hard-coded classes boundaries with minimal human
intervention. The implementation (1) is out-of-the-box available with all
dependencies using a Docker container (2).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Joint and Domain-Adaptive Approach to Spoken Language Understanding. (arXiv:2107.11768v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Linhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yu Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shou_L/0/1/0/all/0/1">Linjun Shou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_M/0/1/0/all/0/1">Ming Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Houfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Michael Zeng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11768">
                                    <div class="article-summary-box-inner">
                                        <span>Spoken Language Understanding (SLU) is composed of two subtasks: intent
detection (ID) and slot filling (SF). There are two lines of research on SLU.
One jointly tackles these two subtasks to improve their prediction accuracy,
and the other focuses on the domain-adaptation ability of one of the subtasks.
In this paper, we attempt to bridge these two lines of research and propose a
joint and domain adaptive approach to SLU. We formulate SLU as a constrained
generation task and utilize a dynamic vocabulary based on domain-specific
ontology. We conduct experiments on the ASMixed and MTOD datasets and achieve
competitive performance with previous state-of-the-art joint models. Besides,
results show that our joint model can be effectively adapted to a new domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Allophone Graphs for Language-Universal Speech Recognition. (arXiv:2107.11628v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1">Brian Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dalmia_S/0/1/0/all/0/1">Siddharth Dalmia</a>, <a href="http://arxiv.org/find/cs/1/au:+Mortensen_D/0/1/0/all/0/1">David R. Mortensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Metze_F/0/1/0/all/0/1">Florian Metze</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11628">
                                    <div class="article-summary-box-inner">
                                        <span>Building language-universal speech recognition systems entails producing
phonological units of spoken sound that can be shared across languages. While
speech annotations at the language-specific phoneme or surface levels are
readily available, annotations at a universal phone level are relatively rare
and difficult to produce. In this work, we present a general framework to
derive phone-level supervision from only phonemic transcriptions and
phone-to-phoneme mappings with learnable weights represented using weighted
finite-state transducers, which we call differentiable allophone graphs. By
training multilingually, we build a universal phone-based speech recognition
model with interpretable probabilistic phone-to-phoneme mappings for each
language. These phone-based systems with learned allophone graphs can be used
by linguists to document new languages, build phone-based lexicons that capture
rich pronunciation variations, and re-evaluate the allophone mappings of seen
language. We demonstrate the aforementioned benefits of our proposed framework
with a system trained on 7 diverse languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clinical Utility of the Automatic Phenotype Annotation in Unstructured Clinical Notes: ICU Use Cases. (arXiv:2107.11665v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bolanos_L/0/1/0/all/0/1">Luis Bolanos</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanwar_A/0/1/0/all/0/1">Ashwani Tanwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sokol_A/0/1/0/all/0/1">Albert Sokol</a>, <a href="http://arxiv.org/find/cs/1/au:+Ive_J/0/1/0/all/0/1">Julia Ive</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1">Vibhor Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yike Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11665">
                                    <div class="article-summary-box-inner">
                                        <span>Clinical notes contain information not present elsewhere, including drug
response and symptoms, all of which are highly important when predicting key
outcomes in acute care patients. We propose the automatic annotation of
phenotypes from clinical notes as a method to capture essential information to
predict outcomes in the Intensive Care Unit (ICU). This information is
complementary to typically used vital signs and laboratory test results. We
demonstrate and validate our approach conducting experiments on the prediction
of in-hospital mortality, physiological decompensation and length of stay in
the ICU setting for over 24,000 patients. The prediction models incorporating
phenotypic information consistently outperform the baseline models leveraging
only vital signs and laboratory test results. Moreover, we conduct a thorough
interpretability study, showing that phenotypes provide valuable insights at
the patient and cohort levels. Our approach illustrates the viability of using
phenotypes to determine outcomes in the ICU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The USYD-JD Speech Translation System for IWSLT 2021. (arXiv:2107.11572v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1">Liang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11572">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the University of Sydney&amp; JD&#x27;s joint submission of the
IWSLT 2021 low resource speech translation task. We participated in the
Swahili-English direction and got the best scareBLEU (25.3) score among all the
participants. Our constrained system is based on a pipeline framework, i.e. ASR
and NMT. We trained our models with the officially provided ASR and MT
datasets. The ASR system is based on the open-sourced tool Kaldi and this work
mainly explores how to make the most of the NMT models. To reduce the
punctuation errors generated by the ASR model, we employ our previous work
SlotRefine to train a punctuation correction model. To achieve better
translation performance, we explored the most recent effective strategies,
including back translation, knowledge distillation, multi-feature reranking and
transductive finetuning. For model structure, we tried auto-regressive and
non-autoregressive models, respectively. In addition, we proposed two novel
pre-train approaches, i.e. \textit{de-noising training} and
\textit{bidirectional training} to fully exploit the data. Extensive
experiments show that adding the above techniques consistently improves the
BLEU scores, and the final submission system outperforms the baseline
(Transformer ensemble model trained with the original parallel data) by
approximately 10.8 BLEU score, achieving the SOTA performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Negation Handling in Machine Learning-Based Sentiment Classification for Colloquial Arabic. (arXiv:2107.11597v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Al_Harbi_O/0/1/0/all/0/1">Omar Al-Harbi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11597">
                                    <div class="article-summary-box-inner">
                                        <span>One crucial aspect of sentiment analysis is negation handling, where the
occurrence of negation can flip the sentiment of a sentence and negatively
affects the machine learning-based sentiment classification. The role of
negation in Arabic sentiment analysis has been explored only to a limited
extent, especially for colloquial Arabic. In this paper, the author addresses
the negation problem of machine learning-based sentiment classification for a
colloquial Arabic language. To this end, we propose a simple rule-based
algorithm for handling the problem; the rules were crafted based on observing
many cases of negation. Additionally, simple linguistic knowledge and sentiment
lexicon are used for this purpose. The author also examines the impact of the
proposed algorithm on the performance of different machine learning algorithms.
The results given by the proposed algorithm are compared with three baseline
models. The experimental results show that there is a positive impact on the
classifiers accuracy, precision and recall when the proposed algorithm is used
compared to the baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Panoptic Segmentation of Satellite Image Time Series with Convolutional Temporal Attention Networks. (arXiv:2107.07933v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garnot_V/0/1/0/all/0/1">Vivien Sainte Fare Garnot</a>, <a href="http://arxiv.org/find/cs/1/au:+Landrieu_L/0/1/0/all/0/1">Loic Landrieu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07933">
                                    <div class="article-summary-box-inner">
                                        <span>Unprecedented access to multi-temporal satellite imagery has opened new
perspectives for a variety of Earth observation tasks. Among them,
pixel-precise panoptic segmentation of agricultural parcels has major economic
and environmental implications. While researchers have explored this problem
for single images, we argue that the complex temporal patterns of crop
phenology are better addressed with temporal sequences of images. In this
paper, we present the first end-to-end, single-stage method for panoptic
segmentation of Satellite Image Time Series (SITS). This module can be combined
with our novel image sequence encoding network which relies on temporal
self-attention to extract rich and adaptive multi-scale spatio-temporal
features. We also introduce PASTIS, the first open-access SITS dataset with
panoptic annotations. We demonstrate the superiority of our encoder for
semantic segmentation against multiple competing architectures, and set up the
first state-of-the-art of panoptic segmentation of SITS. Our implementation and
PASTIS are publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UVStyle-Net: Unsupervised Few-shot Learning of 3D Style Similarity Measure for B-Reps. (arXiv:2105.02961v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meltzer_P/0/1/0/all/0/1">Peter Meltzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Shayani_H/0/1/0/all/0/1">Hooman Shayani</a>, <a href="http://arxiv.org/find/cs/1/au:+Khasahmadi_A/0/1/0/all/0/1">Amir Khasahmadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaraman_P/0/1/0/all/0/1">Pradeep Kumar Jayaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanghi_A/0/1/0/all/0/1">Aditya Sanghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lambourne_J/0/1/0/all/0/1">Joseph Lambourne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02961">
                                    <div class="article-summary-box-inner">
                                        <span>Boundary Representations (B-Reps) are the industry standard in 3D Computer
Aided Design/Manufacturing (CAD/CAM) and industrial design due to their
fidelity in representing stylistic details. However, they have been ignored in
the 3D style research. Existing 3D style metrics typically operate on meshes or
pointclouds, and fail to account for end-user subjectivity by adopting fixed
definitions of style, either through crowd-sourcing for style labels or
hand-crafted features. We propose UVStyle-Net, a style similarity measure for
B-Reps that leverages the style signals in the second order statistics of the
activations in a pre-trained (unsupervised) 3D encoder, and learns their
relative importance to a subjective end-user through few-shot learning. Our
approach differs from all existing data-driven 3D style methods since it may be
used in completely unsupervised settings, which is desirable given the lack of
publicly available labelled B-Rep datasets. More importantly, the few-shot
learning accounts for the inherent subjectivity associated with style. We show
quantitatively that our proposed method with B-Reps is able to capture stronger
style signals than alternative methods on meshes and pointclouds despite its
significantly greater computational efficiency. We also show it is able to
generate meaningful style gradients with respect to the input shape, and that
few-shot learning with as few as two positive examples selected by an end-user
is sufficient to significantly improve the style measure. Finally, we
demonstrate its efficacy on a large unlabeled public dataset of CAD models.
Source code and data will be released in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Manipulation Detection by Multi-View Multi-Scale Supervision. (arXiv:2104.06832v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinru Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_C/0/1/0/all/0/1">Chengbo Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jiaqi Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Juan Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xirong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06832">
                                    <div class="article-summary-box-inner">
                                        <span>The key challenge of image manipulation detection is how to learn
generalizable features that are sensitive to manipulations in novel data,
whilst specific to prevent false alarms on authentic images. Current research
emphasizes the sensitivity, with the specificity overlooked. In this paper we
address both aspects by multi-view feature learning and multi-scale
supervision. By exploiting noise distribution and boundary artifact surrounding
tampered regions, the former aims to learn semantic-agnostic and thus more
generalizable features. The latter allows us to learn from authentic images
which are nontrivial to be taken into account by current semantic segmentation
network based methods. Our thoughts are realized by a new network which we term
MVSS-Net. Extensive experiments on five benchmark sets justify the viability of
MVSS-Net for both pixel-level and image-level manipulation detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dive into Deep Learning. (arXiv:2106.11342v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Aston Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1">Alexander J. Smola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11342">
                                    <div class="article-summary-box-inner">
                                        <span>This open-source book represents our attempt to make deep learning
approachable, teaching readers the concepts, the context, and the code. The
entire book is drafted in Jupyter notebooks, seamlessly integrating exposition
figures, math, and interactive examples with self-contained code. Our goal is
to offer a resource that could (i) be freely available for everyone; (ii) offer
sufficient technical depth to provide a starting point on the path to actually
becoming an applied machine learning scientist; (iii) include runnable code,
showing readers how to solve problems in practice; (iv) allow for rapid
updates, both by us and also by the community at large; (v) be complemented by
a forum for interactive discussion of technical details and to answer
questions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parametric Contrastive Learning. (arXiv:2107.12028v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_J/0/1/0/all/0/1">Jiequan Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_Z/0/1/0/all/0/1">Zhisheng Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Bei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12028">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose Parametric Contrastive Learning (PaCo) to tackle
long-tailed recognition. Based on theoretical analysis, we observe supervised
contrastive loss tends to bias on high-frequency classes and thus increases the
difficulty of imbalance learning. We introduce a set of parametric class-wise
learnable centers to rebalance from an optimization perspective. Further, we
analyze our PaCo loss under a balanced setting. Our analysis demonstrates that
PaCo can adaptively enhance the intensity of pushing samples of the same class
close as more samples are pulled together with their corresponding centers and
benefit hard example learning. Experiments on long-tailed CIFAR, ImageNet,
Places, and iNaturalist 2018 manifest the new state-of-the-art for long-tailed
recognition. On full ImageNet, models trained with PaCo loss surpass supervised
contrastive learning across various ResNet backbones. Our code is available at
\url{https://github.com/jiequancui/Parametric-Contrastive-Learning}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Models as Zero-shot Visual Semantic Learners. (arXiv:2107.12021v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yue Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1">Jonathon Hare</a>, <a href="http://arxiv.org/find/cs/1/au:+Prugel_Bennett_A/0/1/0/all/0/1">Adam Pr&#xfc;gel-Bennett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12021">
                                    <div class="article-summary-box-inner">
                                        <span>Visual Semantic Embedding (VSE) models, which map images into a rich semantic
embedding space, have been a milestone in object recognition and zero-shot
learning. Current approaches to VSE heavily rely on static word em-bedding
techniques. In this work, we propose a Visual Se-mantic Embedding Probe (VSEP)
designed to probe the semantic information of contextualized word embeddings in
visual semantic understanding tasks. We show that the knowledge encoded in
transformer language models can be exploited for tasks requiring visual
semantic understanding.The VSEP with contextual representations can distinguish
word-level object representations in complicated scenes as a compositional
zero-shot learner. We further introduce a zero-shot setting with VSEPs to
evaluate a model&#x27;s ability to associate a novel word with a novel visual
category. We find that contextual representations in language mod-els
outperform static word embeddings, when the compositional chain of object is
short. We notice that current visual semantic embedding models lack a mutual
exclusivity bias which limits their performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation. (arXiv:2107.11769v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tsung-Han Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yueh-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hsin-Ying Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hung-Ting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Ping-Chia Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Winston H. Hsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11769">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of deep learning on supervised point cloud semantic
segmentation, obtaining large-scale point-by-point manual annotations is still
a significant challenge. To reduce the huge annotation burden, we propose a
Region-based and Diversity-aware Active Learning (ReDAL), a general framework
for many deep learning approaches, aiming to automatically select only
informative and diverse sub-scene regions for label acquisition. Observing that
only a small portion of annotated regions are sufficient for 3D scene
understanding with deep learning, we use softmax entropy, color discontinuity,
and structural complexity to measure the information of sub-scene regions. A
diversity-aware selection algorithm is also developed to avoid redundant
annotations resulting from selecting informative but similar regions in a
querying batch. Extensive experiments show that our method highly outperforms
previous active learning strategies, and we achieve the performance of 90%
fully supervised learning, while less than 15% and 5% annotations are required
on S3DIS and SemanticKITTI datasets, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-GGM: Graph Generative Modeling for Out-of-Distribution Generalization in Visual Question Answering. (arXiv:2107.11576v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jingjing Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yifan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nan_Z/0/1/0/all/0/1">Zhixiong Nan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11576">
                                    <div class="article-summary-box-inner">
                                        <span>Encouraging progress has been made towards Visual Question Answering (VQA) in
recent years, but it is still challenging to enable VQA models to adaptively
generalize to out-of-distribution (OOD) samples. Intuitively, recompositions of
existing visual concepts (i.e., attributes and objects) can generate unseen
compositions in the training set, which will promote VQA models to generalize
to OOD samples. In this paper, we formulate OOD generalization in VQA as a
compositional generalization problem and propose a graph generative
modeling-based training scheme (X-GGM) to handle the problem implicitly. X-GGM
leverages graph generative modeling to iteratively generate a relation matrix
and node representations for the predefined graph that utilizes
attribute-object pairs as nodes. Furthermore, to alleviate the unstable
training issue in graph generative modeling, we propose a gradient distribution
consistency loss to constrain the data distribution with adversarial
perturbations and the generated distribution. The baseline VQA model (LXMERT)
trained with the X-GGM scheme achieves state-of-the-art OOD performance on two
standard VQA OOD benchmarks, i.e., VQA-CP v2 and GQA-OOD. Extensive ablation
studies demonstrate the effectiveness of X-GGM components.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASOD60K: Audio-Induced Salient Object Detection in Panoramic Videos. (arXiv:2107.11629v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_F/0/1/0/all/0/1">Fang-Yi Chao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1">Ge-Peng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">Deng-Ping Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11629">
                                    <div class="article-summary-box-inner">
                                        <span>Exploring to what humans pay attention in dynamic panoramic scenes is useful
for many fundamental applications, including augmented reality (AR) in retail,
AR-powered recruitment, and visual language navigation. With this goal in mind,
we propose PV-SOD, a new task that aims to segment salient objects from
panoramic videos. In contrast to existing fixation-level or object-level
saliency detection tasks, we focus on multi-modal salient object detection
(SOD), which mimics human attention mechanism by segmenting salient objects
with the guidance of audio-visual cues. To support this task, we collect the
first large-scale dataset, named ASOD60K, which contains 4K-resolution video
frames annotated with a six-level hierarchy, thus distinguishing itself with
richness, diversity and quality. Specifically, each sequence is marked with
both its super-/sub-class, with objects of each sub-class being further
annotated with human eye fixations, bounding boxes, object-/instance-level
masks, and associated attributes (e.g., geometrical distortion). These
coarse-to-fine annotations enable detailed analysis for PV-SOD modeling, e.g.,
determining the major challenges for existing SOD models, and predicting
scanpaths to study the long-term eye fixation behaviors of humans. We
systematically benchmark 11 representative approaches on ASOD60K and derive
several interesting findings. We hope this study could serve as a good starting
point for advancing SOD research towards panoramic videos.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LAConv: Local Adaptive Convolution for Image Fusion. (arXiv:2107.11617v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zi-Rong Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Liang-Jian Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tai-Xiang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tian-Jing Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11617">
                                    <div class="article-summary-box-inner">
                                        <span>The convolution operation is a powerful tool for feature extraction and plays
a prominent role in the field of computer vision. However, when targeting the
pixel-wise tasks like image fusion, it would not fully perceive the
particularity of each pixel in the image if the uniform convolution kernel is
used on different patches. In this paper, we propose a local adaptive
convolution (LAConv), which is dynamically adjusted to different spatial
locations. LAConv enables the network to pay attention to every specific local
area in the learning process. Besides, the dynamic bias (DYB) is introduced to
provide more possibilities for the depiction of features and make the network
more flexible. We further design a residual structure network equipped with the
proposed LAConv and DYB modules, and apply it to two image fusion tasks.
Experiments for pansharpening and hyperspectral image super-resolution (HISR)
demonstrate the superiority of our method over other state-of-the-art methods.
It is worth mentioning that LAConv can also be competent for other
super-resolution tasks with less computation effort.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Robustness of Unsupervised Domain Adaptation in Semantic Segmentation. (arXiv:2105.10843v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinyu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunyuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+An_W/0/1/0/all/0/1">Weizhi An</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hehuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yuzhi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1">Yu Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peilin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junzhou Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10843">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies imply that deep neural networks are vulnerable to adversarial
examples -- inputs with a slight but intentional perturbation are incorrectly
classified by the network. Such vulnerability makes it risky for some
security-related applications (e.g., semantic segmentation in autonomous cars)
and triggers tremendous concerns on the model reliability. For the first time,
we comprehensively evaluate the robustness of existing UDA methods and propose
a robust UDA approach. It is rooted in two observations: (i) the robustness of
UDA methods in semantic segmentation remains unexplored, which pose a security
concern in this field; and (ii) although commonly used self-supervision (e.g.,
rotation and jigsaw) benefits image tasks such as classification and
recognition, they fail to provide the critical supervision signals that could
learn discriminative representation for segmentation tasks. These observations
motivate us to propose adversarial self-supervision UDA (or ASSUDA) that
maximizes the agreement between clean images and their adversarial examples by
a contrastive loss in the output space. Extensive empirical studies on commonly
used benchmarks demonstrate that ASSUDA is resistant to adversarial attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generalized Lottery Ticket Hypothesis. (arXiv:2107.06825v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alabdulmohsin_I/0/1/0/all/0/1">Ibrahim Alabdulmohsin</a>, <a href="http://arxiv.org/find/cs/1/au:+Markeeva_L/0/1/0/all/0/1">Larisa Markeeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1">Daniel Keysers</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1">Ilya Tolstikhin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06825">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a generalization to the lottery ticket hypothesis in which the
notion of &quot;sparsity&quot; is relaxed by choosing an arbitrary basis in the space of
parameters. We present evidence that the original results reported for the
canonical basis continue to hold in this broader setting. We describe how
structured pruning methods, including pruning units or factorizing
fully-connected layers into products of low-rank matrices, can be cast as
particular instances of this &quot;generalized&quot; lottery ticket hypothesis. The
investigations reported here are preliminary and are provided to encourage
further research along this direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Continual Learning for Multi-Domain Hippocampal Segmentation. (arXiv:2107.08751v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Memmel_M/0/1/0/all/0/1">Marius Memmel</a>, <a href="http://arxiv.org/find/eess/1/au:+Gonzalez_C/0/1/0/all/0/1">Camila Gonzalez</a>, <a href="http://arxiv.org/find/eess/1/au:+Mukhopadhyay_A/0/1/0/all/0/1">Anirban Mukhopadhyay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08751">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning for medical imaging suffers from temporal and privacy-related
restrictions on data availability. To still obtain viable models, continual
learning aims to train in sequential order, as and when data is available. The
main challenge that continual learning methods face is to prevent catastrophic
forgetting, i.e., a decrease in performance on the data encountered earlier.
This issue makes continuous training of segmentation models for medical
applications extremely difficult. Yet, often, data from at least two different
domains is available which we can exploit to train the model in a way that it
disregards domain-specific information. We propose an architecture that
leverages the simultaneous availability of two or more datasets to learn a
disentanglement between the content and domain in an adversarial fashion. The
domain-invariant content representation then lays the base for continual
semantic segmentation. Our approach takes inspiration from domain adaptation
and combines it with continual learning for hippocampal segmentation in brain
MRI. We showcase that our method reduces catastrophic forgetting and
outperforms state-of-the-art continual learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Saliency-Guided Deep Learning Network for Automatic Tumor Bed Volume Delineation in Post-operative Breast Irradiation. (arXiv:2105.02771v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kazemimoghadam_M/0/1/0/all/0/1">Mahdieh Kazemimoghadam</a>, <a href="http://arxiv.org/find/eess/1/au:+Chi_W/0/1/0/all/0/1">Weicheng Chi</a>, <a href="http://arxiv.org/find/eess/1/au:+Rahimi_A/0/1/0/all/0/1">Asal Rahimi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kim_N/0/1/0/all/0/1">Nathan Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Alluri_P/0/1/0/all/0/1">Prasanna Alluri</a>, <a href="http://arxiv.org/find/eess/1/au:+Nwachukwu_C/0/1/0/all/0/1">Chika Nwachukwu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_W/0/1/0/all/0/1">Weiguo Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gu_X/0/1/0/all/0/1">Xuejun Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02771">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient, reliable and reproducible target volume delineation is a key step
in the effective planning of breast radiotherapy. However, post-operative
breast target delineation is challenging as the contrast between the tumor bed
volume (TBV) and normal breast tissue is relatively low in CT images. In this
study, we propose to mimic the marker-guidance procedure in manual target
delineation. We developed a saliency-based deep learning segmentation (SDL-Seg)
algorithm for accurate TBV segmentation in post-operative breast irradiation.
The SDL-Seg algorithm incorporates saliency information in the form of markers&#x27;
location cues into a U-Net model. The design forces the model to encode the
location-related features, which underscores regions with high saliency levels
and suppresses low saliency regions. The saliency maps were generated by
identifying markers on CT images. Markers&#x27; locations were then converted to
probability maps using a distance-transformation coupled with a Gaussian
filter. Subsequently, the CT images and the corresponding saliency maps formed
a multi-channel input for the SDL-Seg network. Our in-house dataset was
comprised of 145 prone CT images from 29 post-operative breast cancer patients,
who received 5-fraction partial breast irradiation (PBI) regimen on GammaPod.
The performance of the proposed method was compared against basic U-Net. Our
model achieved mean (standard deviation) of 76.4 %, 6.76 mm, and 1.9 mm for
DSC, HD95, and ASD respectively on the test set with computation time of below
11 seconds per one CT volume. SDL-Seg showed superior performance relative to
basic U-Net for all the evaluation metrics while preserving low computation
cost. The findings demonstrate that SDL-Seg is a promising approach for
improving the efficiency and accuracy of the on-line treatment planning
procedure of PBI, such as GammaPod based PBI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold Matching via Deep Metric Learning for Generative Modeling. (arXiv:2106.10777v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_M/0/1/0/all/0/1">Mengyu Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hang_H/0/1/0/all/0/1">Haibin Hang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10777">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a manifold matching approach to generative models which includes a
distribution generator (or data generator) and a metric generator. In our
framework, we view the real data set as some manifold embedded in a
high-dimensional Euclidean space. The distribution generator aims at generating
samples that follow some distribution condensed around the real data manifold.
It is achieved by matching two sets of points using their geometric shape
descriptors, such as centroid and $p$-diameter, with learned distance metric;
the metric generator utilizes both real data and generated samples to learn a
distance metric which is close to some intrinsic geodesic distance on the real
data manifold. The produced distance metric is further used for manifold
matching. The two networks are learned simultaneously during the training
process. We apply the approach on both unsupervised and supervised learning
tasks: in unconditional image generation task, the proposed method obtains
competitive results compared with existing generative models; in
super-resolution task, we incorporate the framework in perception-based models
and improve visual qualities by producing samples with more natural textures.
Both theoretical analysis and real data experiments demonstrate the feasibility
and effectiveness of the proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Energy-Efficient Edge Computing Paradigm for Convolution-based Image Upsampling. (arXiv:2107.07647v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Colbert_I/0/1/0/all/0/1">Ian Colbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreutz_Delgado_K/0/1/0/all/0/1">Ken Kreutz-Delgado</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Srinjoy Das</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07647">
                                    <div class="article-summary-box-inner">
                                        <span>A novel energy-efficient edge computing paradigm is proposed for real-time
deep learning-based image upsampling applications. State-of-the-art deep
learning solutions for image upsampling are currently trained using either
resize or sub-pixel convolution to learn kernels that generate high fidelity
images with minimal artifacts. However, performing inference with these learned
convolution kernels requires memory-intensive feature map transformations that
dominate time and energy costs in real-time applications. To alleviate this
pressure on memory bandwidth, we confine the use of resize or sub-pixel
convolution to training in the cloud by transforming learned convolution
kernels to deconvolution kernels before deploying them for inference as a
functionally equivalent deconvolution. These kernel transformations, intended
as a one-time cost when shifting from training to inference, enable a systems
designer to use each algorithm in their optimal context by preserving the image
fidelity learned when training in the cloud while minimizing data transfer
penalties during inference at the edge. We also explore existing variants of
deconvolution inference algorithms and introduce a novel variant for
consideration. We analyze and compare the inference properties of
convolution-based upsampling algorithms using a quantitative model of incurred
time and energy costs and show that using deconvolution for inference at the
edge improves both system latency and energy efficiency when compared to their
sub-pixel or resize convolution counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepPlastic: A Novel Approach to Detecting Epipelagic Bound Plastic Using Deep Visual Models. (arXiv:2105.01882v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tata_G/0/1/0/all/0/1">Gautam Tata</a>, <a href="http://arxiv.org/find/cs/1/au:+Royer_S/0/1/0/all/0/1">Sarah-Jeanne Royer</a>, <a href="http://arxiv.org/find/cs/1/au:+Poirion_O/0/1/0/all/0/1">Olivier Poirion</a>, <a href="http://arxiv.org/find/cs/1/au:+Lowe_J/0/1/0/all/0/1">Jay Lowe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01882">
                                    <div class="article-summary-box-inner">
                                        <span>The quantification of positively buoyant marine plastic debris is critical to
understanding how concentrations of trash from across the world&#x27;s ocean and
identifying high concentration garbage hotspots in dire need of trash removal.
Currently, the most common monitoring method to quantify floating plastic
requires the use of a manta trawl. Techniques requiring manta trawls (or
similar surface collection devices) utilize physical removal of marine plastic
debris as the first step and then analyze collected samples as a second step.
The need for physical removal before analysis incurs high costs and requires
intensive labor preventing scalable deployment of a real-time marine plastic
monitoring service across the entirety of Earth&#x27;s ocean bodies. Without better
monitoring and sampling methods, the total impact of plastic pollution on the
environment as a whole, and details of impact within specific oceanic regions,
will remain unknown. This study presents a highly scalable workflow that
utilizes images captured within the epipelagic layer of the ocean as an input.
It produces real-time quantification of marine plastic debris for accurate
quantification and physical removal. The workflow includes creating and
preprocessing a domain-specific dataset, building an object detection model
utilizing a deep neural network, and evaluating the model&#x27;s performance.
YOLOv5-S was the best performing model, which operates at a Mean Average
Precision (mAP) of 0.851 and an F1-Score of 0.89 while maintaining
near-real-time speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RDA: Robust Domain Adaptation via Fourier Adversarial Attacking. (arXiv:2106.02874v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiaxing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1">Dayan Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">Aoran Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02874">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) involves a supervised loss in a labeled
source domain and an unsupervised loss in an unlabeled target domain, which
often faces more severe overfitting (than classical supervised learning) as the
supervised source loss has clear domain gap and the unsupervised target loss is
often noisy due to the lack of annotations. This paper presents RDA, a robust
domain adaptation technique that introduces adversarial attacking to mitigate
overfitting in UDA. We achieve robust domain adaptation by a novel Fourier
adversarial attacking (FAA) method that allows large magnitude of perturbation
noises but has minimal modification of image semantics, the former is critical
to the effectiveness of its generated adversarial samples due to the existence
of &#x27;domain gaps&#x27;. Specifically, FAA decomposes images into multiple frequency
components (FCs) and generates adversarial samples by just perturbating certain
FCs that capture little semantic information. With FAA-generated samples, the
training can continue the &#x27;random walk&#x27; and drift into an area with a flat loss
landscape, leading to more robust domain adaptation. Extensive experiments over
multiple domain adaptation tasks show that RDA can work with different computer
vision tasks with superior performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WildGait: Learning Gait Representations from Raw Surveillance Streams. (arXiv:2105.05528v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cosma_A/0/1/0/all/0/1">Adrian Cosma</a>, <a href="http://arxiv.org/find/cs/1/au:+Radoi_E/0/1/0/all/0/1">Emilian Radoi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05528">
                                    <div class="article-summary-box-inner">
                                        <span>The use of gait for person identification has important advantages such as
being non-invasive, unobtrusive, not requiring cooperation and being less
likely to be obscured compared to other biometrics. Existing methods for gait
recognition require cooperative gait scenarios, in which a single person is
walking multiple times in a straight line in front of a camera. We aim to
address the hard challenges of real-world scenarios in which camera feeds
capture multiple people, who in most cases pass in front of the camera only
once. We address privacy concerns by using only the motion information of
walking individuals, with no identifiable appearance-based information. As
such, we propose a novel weakly supervised learning framework, WildGait, which
consists of training a Spatio-Temporal Graph Convolutional Network on a large
number of automatically annotated skeleton sequences obtained from raw,
real-world, surveillance streams to learn useful gait signatures. Our results
show that, with fine-tuning, we surpass in terms of recognition accuracy the
current state-of-the-art pose-based gait recognition solutions. Our proposed
method is reliable in training gait recognition methods in unconstrained
environments, especially in settings with scarce amounts of annotated data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Facial expression and attributes recognition based on multi-task learning of lightweight neural networks. (arXiv:2103.17107v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Savchenko_A/0/1/0/all/0/1">Andrey V. Savchenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17107">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, the multi-task learning of lightweight convolutional neural
networks is studied for face identification and classification of facial
attributes (age, gender, ethnicity) trained on cropped faces without margins.
The necessity to fine-tune these networks to predict facial expressions is
highlighted. Several models are presented based on MobileNet, EfficientNet and
RexNet architectures. It was experimentally demonstrated that they lead to near
state-of-the-art results in age, gender and race recognition on the UTKFace
dataset and emotion classification on the AffectNet dataset. Moreover, it is
shown that the usage of the trained models as feature extractors of facial
regions in video frames leads to 4.5% higher accuracy than the previously known
state-of-the-art single models for the AFEW and the VGAF datasets from the
EmotiW challenges. The models and source code are publicly available at
https://github.com/HSE-asavchenko/face-emotion-recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Traversability Estimator for Mobile Robots in Unstructured Environments. (arXiv:2105.10937v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Visca_M/0/1/0/all/0/1">Marco Visca</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuutti_S/0/1/0/all/0/1">Sampo Kuutti</a>, <a href="http://arxiv.org/find/cs/1/au:+Powell_R/0/1/0/all/0/1">Roger Powell</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fallah_S/0/1/0/all/0/1">Saber Fallah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10937">
                                    <div class="article-summary-box-inner">
                                        <span>Terrain traversability analysis plays a major role in ensuring safe robotic
navigation in unstructured environments. However, real-time constraints
frequently limit the accuracy of online tests especially in scenarios where
realistic robot-terrain interactions are complex to model. In this context, we
propose a deep learning framework trained in an end-to-end fashion from
elevation maps and trajectories to estimate the occurrence of failure events.
The network is first trained and tested in simulation over synthetic maps
generated by the OpenSimplex algorithm. The prediction performance of the Deep
Learning framework is illustrated by being able to retain over 94% recall of
the original simulator at 30% of the computational time. Finally, the network
is transferred and tested on real elevation maps collected by the SEEKER
consortium during the Martian rover test trial in the Atacama desert in Chile.
We show that transferring and fine-tuning of an application-independent
pre-trained model retains better performance than training uniquely on scarcely
available real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Affect Expression Behaviour Analysis in the Wild using Consensual Collaborative Training. (arXiv:2107.05736v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gera_D/0/1/0/all/0/1">Darshan Gera</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_S/0/1/0/all/0/1">S Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05736">
                                    <div class="article-summary-box-inner">
                                        <span>Facial expression recognition (FER) in the wild is crucial for building
reliable human-computer interactive systems. However, annotations of large
scale datasets in FER has been a key challenge as these datasets suffer from
noise due to various factors like crowd sourcing, subjectivity of annotators,
poor quality of images, automatic labelling based on key word search etc. Such
noisy annotations impede the performance of FER due to the memorization ability
of deep networks. During early learning stage, deep networks fit on clean data.
Then, eventually, they start overfitting on noisy labels due to their
memorization ability, which limits FER performance. This report presents
Consensual Collaborative Training (CCT) framework used in our submission to
expression recognition track of the Affective Behaviour Analysis in-the-wild
(ABAW) 2021 competition. CCT co-trains three networks jointly using a convex
combination of supervision loss and consistency loss, without making any
assumption about the noise distribution. A dynamic transition mechanism is used
to move from supervision loss in early learning to consistency loss for
consensus of predictions among networks in the later stage. Co-training reduces
overall error, and consistency loss prevents overfitting to noisy samples. The
performance of the model is validated on challenging Aff-Wild2 dataset for
categorical expression classification. Our code is made publicly available at
https://github.com/1980x/ABAW2021DMACS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JPGNet: Joint Predictive Filtering and Generative Network for Image Inpainting. (arXiv:2107.04281v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoguang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Juefei_Xu_F/0/1/0/all/0/1">Felix Juefei-Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hongkai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+wang_S/0/1/0/all/0/1">Song wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.04281">
                                    <div class="article-summary-box-inner">
                                        <span>Image inpainting aims to restore the missing regions and make the recovery
results identical to the originally complete image, which is different from the
common generative task emphasizing the naturalness of generated images.
Nevertheless, existing works usually regard it as a pure generation problem and
employ cutting-edge generative techniques to address it. The generative
networks fill the main missing parts with realistic contents but usually
distort the local structures. In this paper, we formulate image inpainting as a
mix of two problems, i.e., predictive filtering and deep generation. Predictive
filtering is good at preserving local structures and removing artifacts but
falls short to complete the large missing regions. The deep generative network
can fill the numerous missing pixels based on the understanding of the whole
scene but hardly restores the details identical to the original ones. To make
use of their respective advantages, we propose the joint predictive filtering
and generative network (JPGNet) that contains three branches: predictive
filtering &amp; uncertainty network (PFUNet), deep generative network, and
uncertainty-aware fusion network (UAFNet). The PFUNet can adaptively predict
pixel-wise kernels for filtering-based inpainting according to the input image
and output an uncertainty map. This map indicates the pixels should be
processed by filtering or generative networks, which is further fed to the
UAFNet for a smart combination between filtering and generative results. Note
that, our method as a novel framework for the image inpainting problem can
benefit any existing generation-based methods. We validate our method on three
public datasets, i.e., Dunhuang, Places2, and CelebA, and demonstrate that our
method can enhance three state-of-the-art generative methods (i.e., StructFlow,
EdgeConnect, and RFRNet) significantly with the slightly extra time cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generalized Framework for Edge-preserving and Structure-preserving Image Smoothing. (arXiv:2107.07058v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pingping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1">Yinjie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaolin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_M/0/1/0/all/0/1">Michael Ng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07058">
                                    <div class="article-summary-box-inner">
                                        <span>Image smoothing is a fundamental procedure in applications of both computer
vision and graphics. The required smoothing properties can be different or even
contradictive among different tasks. Nevertheless, the inherent smoothing
nature of one smoothing operator is usually fixed and thus cannot meet the
various requirements of different applications. In this paper, we first
introduce the truncated Huber penalty function which shows strong flexibility
under different parameter settings. A generalized framework is then proposed
with the introduced truncated Huber penalty function. When combined with its
strong flexibility, our framework is able to achieve diverse smoothing natures
where contradictive smoothing behaviors can even be achieved. It can also yield
the smoothing behavior that can seldom be achieved by previous methods, and
superior performance is thus achieved in challenging cases. These together
enable our framework capable of a range of applications and able to outperform
the state-of-the-art approaches in several tasks, such as image detail
enhancement, clip-art compression artifacts removal, guided depth map
restoration, image texture removal, etc. In addition, an efficient numerical
solution is provided and its convergence is theoretically guaranteed even the
optimization framework is non-convex and non-smooth. A simple yet effective
approach is further proposed to reduce the computational cost of our method
while maintaining its performance. The effectiveness and superior performance
of our approach are validated through comprehensive experiments in a range of
applications. Our code is available at
https://github.com/wliusjtu/Generalized-Smoothing-Framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">G2DA: Geometry-Guided Dual-Alignment Learning for RGB-Infrared Person Re-Identification. (arXiv:2106.07853v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wan_L/0/1/0/all/0/1">Lin Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zongyuan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_Q/0/1/0/all/0/1">Qianyan Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yehansen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Lijing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhihang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07853">
                                    <div class="article-summary-box-inner">
                                        <span>RGB-Infrared (IR) person re-identification aims to retrieve
person-of-interest from heterogeneous cameras, easily suffering from large
image modality discrepancy caused by different sensing wavelength ranges.
Existing work usually minimizes such discrepancy by aligning domain
distribution of global features, while neglecting the intra-modality structural
relations between semantic parts. This could result in the network overly
focusing on local cues, without considering long-range body part dependencies,
leading to meaningless region representations. In this paper, we propose a
graph-enabled distribution matching solution, dubbed Geometry-Guided
Dual-Alignment (G2DA) learning, for RGB-IR ReID. It can jointly encourage the
cross-modal consistency between part semantics and structural relations for
fine-grained modality alignment by solving a graph matching task within a
multi-scale skeleton graph that embeds human topology information.
Specifically, we propose to build a semantic-aligned complete graph into which
all cross-modality images can be mapped via a pose-adaptive graph construction
mechanism. This graph represents extracted whole-part features by nodes and
expresses the node-wise similarities with associated edges. To achieve the
graph-based dual-alignment learning, an Optimal Transport (OT) based structured
metric is further introduced to simultaneously measure point-wise relations and
group-wise structural similarities across modalities. By minimizing the cost of
an inter-modality transport plan, G2DA can learn a consistent and
discriminative feature subspace for cross-modality image retrieval.
Furthermore, we advance a Message Fusion Attention (MFA) mechanism to
adaptively reweight the information flow of semantic propagation, effectively
strengthening the discriminability of extracted semantic features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-guided Temporally Coherent Video Object Matting. (arXiv:2105.11427v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yunke Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_M/0/1/0/all/0/1">Miaomiao Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_P/0/1/0/all/0/1">Peiran Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xuansong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xian-sheng Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1">Hujun Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qixing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Weiwei Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11427">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel deep learning-based video object matting method
that can achieve temporally coherent matting results. Its key component is an
attention-based temporal aggregation module that maximizes image matting
networks&#x27; strength for video matting networks. This module computes temporal
correlations for pixels adjacent to each other along the time axis in feature
space, which is robust against motion noises. We also design a novel loss term
to train the attention weights, which drastically boosts the video matting
performance. Besides, we show how to effectively solve the trimap generation
problem by fine-tuning a state-of-the-art video object segmentation network
with a sparse set of user-annotated keyframes. To facilitate video matting and
trimap generation networks&#x27; training, we construct a large-scale video matting
dataset with 80 training and 28 validation foreground video clips with
ground-truth alpha mattes. Experimental results show that our method can
generate high-quality alpha mattes for various videos featuring appearance
change, occlusion, and fast motion. Our code and dataset can be found at:
https://github.com/yunkezhang/TCVOM</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ST-DETR: Spatio-Temporal Object Traces Attention Detection Transformer. (arXiv:2107.05887v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohamed_E/0/1/0/all/0/1">Eslam Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Sallab_A/0/1/0/all/0/1">Ahmad El-Sallab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.05887">
                                    <div class="article-summary-box-inner">
                                        <span>We propose ST-DETR, a Spatio-Temporal Transformer-based architecture for
object detection from a sequence of temporal frames. We treat the temporal
frames as sequences in both space and time and employ the full attention
mechanisms to take advantage of the features correlations over both dimensions.
This treatment enables us to deal with frames sequence as temporal object
features traces over every location in the space. We explore two possible
approaches; the early spatial features aggregation over the temporal dimension,
and the late temporal aggregation of object query spatial features. Moreover,
we propose a novel Temporal Positional Embedding technique to encode the time
sequence information. To evaluate our approach, we choose the Moving Object
Detection (MOD)task, since it is a perfect candidate to showcase the importance
of the temporal dimension. Results show a significant 5% mAP improvement on the
KITTI MOD dataset over the 1-step spatial baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Multi-Scene Absolute Pose Regression with Transformers. (arXiv:2103.11468v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shavit_Y/0/1/0/all/0/1">Yoli Shavit</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferens_R/0/1/0/all/0/1">Ron Ferens</a>, <a href="http://arxiv.org/find/cs/1/au:+Keller_Y/0/1/0/all/0/1">Yosi Keller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11468">
                                    <div class="article-summary-box-inner">
                                        <span>Absolute camera pose regressors estimate the position and orientation of a
camera from the captured image alone. Typically, a convolutional backbone with
a multi-layer perceptron head is trained with images and pose labels to embed a
single reference scene at a time. Recently, this scheme was extended for
learning multiple scenes by replacing the MLP head with a set of fully
connected layers. In this work, we propose to learn multi-scene absolute camera
pose regression with Transformers, where encoders are used to aggregate
activation maps with self-attention and decoders transform latent features and
scenes encoding into candidate pose predictions. This mechanism allows our
model to focus on general features that are informative for localization while
embedding multiple scenes in parallel. We evaluate our method on commonly
benchmarked indoor and outdoor datasets and show that it surpasses both
multi-scene and state-of-the-art single-scene absolute pose regressors. We make
our code publicly available from
https://github.com/yolish/multi-scene-pose-transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neighbor-view Enhanced Model for Vision and Language Navigation. (arXiv:2107.07201v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+An_D/0/1/0/all/0/1">Dong An</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1">Yuankai Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_T/0/1/0/all/0/1">Tieniu Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07201">
                                    <div class="article-summary-box-inner">
                                        <span>Vision and Language Navigation (VLN) requires an agent to navigate to a
target location by following natural language instructions. Most of existing
works represent a navigation candidate by the feature of the corresponding
single view where the candidate lies in. However, an instruction may mention
landmarks out of the single view as references, which might lead to failures of
textual-visual matching of existing methods. In this work, we propose a
multi-module Neighbor-View Enhanced Model (NvEM) to adaptively incorporate
visual contexts from neighbor views for better textual-visual matching.
Specifically, our NvEM utilizes a subject module and a reference module to
collect contexts from neighbor views. The subject module fuses neighbor views
at a global level, and the reference module fuses neighbor objects at a local
level. Subjects and references are adaptively determined via attention
me&#x27;chanisms. Our model also includes an action module to utilize the strong
orientation guidance (e.g., &quot;turn left&quot;) in instructions. Each module predicts
navigation action separately and their weighted sum is used for predicting the
final action. Extensive experimental results demonstrate the effectiveness of
the proposed method on the R2R and R4R benchmarks against several
state-of-the-art navigators, and NvEM even beats some pre-training ones. Our
code is available at https://github.com/MarSaKi/NvEM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CBNetV2: A Composite Backbone Network Architecture for Object Detection. (arXiv:2107.00420v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1">Tingting Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xiaojie Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yudong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongtao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_W/0/1/0/all/0/1">Wei Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingdong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Haibin Ling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00420">
                                    <div class="article-summary-box-inner">
                                        <span>Modern top-performing object detectors depend heavily on backbone networks,
whose advances bring consistent performance gains through exploring more
effective network structures. In this paper, we propose a novel and flexible
backbone framework, namely CBNetV2, to construct high-performance detectors
using existing open-sourced pre-trained backbones under the pre-training
fine-tuning paradigm. In particular, CBNetV2 architecture groups multiple
identical backbones, which are connected through composite connections.
Specifically, it integrates the high- and low-level features of multiple
backbone networks and gradually expands the receptive field to more efficiently
perform object detection. We also propose a better training strategy with
assistant supervision for CBNet-based detectors. Without additional
pre-training of the composite backbone, CBNetV2 can be adapted to various
backbones (CNN-based vs. Transformer-based) and head designs of most mainstream
detectors (one-stage vs. two-stage, anchor-based vs. anchor-free-based).
Experiments provide strong evidence that, compared with simply increasing the
depth and width of the network, CBNetV2 introduces a more efficient, effective,
and resource-friendly way to build high-performance backbone networks.
Particularly, our Dual-Swin-L achieves 59.4% box AP and 51.6% mask AP on COCO
test-dev under the single-model and single-scale testing protocol, which is
significantly better than the state-of-the-art result (57.7% box AP and 50.2%
mask AP) achieved by Swin-L, while the training schedule is reduced by
6$\times$. With multi-scale testing, we push the current best single model
result to a new record of 60.1% box AP and 52.3% mask AP without using extra
training data. Code is available at https://github.com/VDIGPKU/CBNetV2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fit4CAD: A point cloud benchmark for fitting simple geometric primitives in CAD models. (arXiv:2105.06858v2 [cs.GR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Romanengo_C/0/1/0/all/0/1">Chiara Romanengo</a>, <a href="http://arxiv.org/find/cs/1/au:+Raffo_A/0/1/0/all/0/1">Andrea Raffo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qie_Y/0/1/0/all/0/1">Yifan Qie</a>, <a href="http://arxiv.org/find/cs/1/au:+Anwer_N/0/1/0/all/0/1">Nabil Anwer</a>, <a href="http://arxiv.org/find/cs/1/au:+Falcidieno_B/0/1/0/all/0/1">Bianca Falcidieno</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06858">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Fit4CAD, a benchmark for the evaluation and comparison of methods
for fitting simple geometric primitives in point clouds representing CAD
models. This benchmark is meant to help both method developers and those who
want to identify the best performing tools. The Fit4CAD dataset is composed by
225 high quality point clouds, each of which has been obtained by sampling a
CAD model. The way these elements were created by using existing platforms and
datasets makes the benchmark easily expandable. The dataset is already split
into a training set and a test set. To assess performance and accuracy of the
different primitive fitting methods, various measures are defined. To
demonstrate the effective use of Fit4CAD, we have tested it on two methods
belonging to two different categories of approaches to the primitive fitting
problem: a clustering method based on a primitive growing framework and a
parametric method based on the Hough transform.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Dose CT Denoising Using a Structure-Preserving Kernel Prediction Network. (arXiv:2105.14758v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xu_L/0/1/0/all/0/1">Lu Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1">Yuwei Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Ying Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1">Daoye Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_M/0/1/0/all/0/1">Mu Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Ren_J/0/1/0/all/0/1">Jimmy Ren</a>, <a href="http://arxiv.org/find/eess/1/au:+Wei_J/0/1/0/all/0/1">Jingwei Wei</a>, <a href="http://arxiv.org/find/eess/1/au:+Ye_Z/0/1/0/all/0/1">Zhaoxiang Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14758">
                                    <div class="article-summary-box-inner">
                                        <span>Low-dose CT has been a key diagnostic imaging modality to reduce the
potential risk of radiation overdose to patient health. Despite recent
advances, CNN-based approaches typically apply filters in a spatially invariant
way and adopt similar pixel-level losses, which treat all regions of the CT
image equally and can be inefficient when fine-grained structures coexist with
non-uniformly distributed noises. To address this issue, we propose a
Structure-preserving Kernel Prediction Network (StructKPN) that combines the
kernel prediction network with a structure-aware loss function that utilizes
the pixel gradient statistics and guides the model towards spatially-variant
filters that enhance noise removal, prevent over-smoothing and preserve
detailed structures for different regions in CT imaging. Extensive experiments
demonstrated that our approach achieved superior performance on both synthetic
and non-synthetic datasets, and better preserves structures that are highly
desired in clinical screening and low-dose protocol optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Sparsity for Smoothing Filters. (arXiv:2107.00627v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junqing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haihui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuechao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruzhansky_M/0/1/0/all/0/1">Michael Ruzhansky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00627">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an interesting semi-sparsity smoothing algorithm
based on a novel sparsity-inducing optimization framework. This method is
derived from the multiple observations, that is, semi-sparsity prior knowledge
is more universally applicable, especially in areas where sparsity is not fully
admitted, such as polynomial-smoothing surfaces. We illustrate that this
semi-sparsity can be identified into a generalized $L_0$-norm minimization in
higher-order gradient domains, thereby giving rise to a new &quot;feature-aware&quot;
filtering method with a powerful simultaneous-fitting ability in both sparse
features (singularities and sharpening edges) and non-sparse regions
(polynomial-smoothing surfaces). Notice that a direct solver is always
unavailable due to the non-convexity and combinatorial nature of $L_0$-norm
minimization. Instead, we solve the model based on an efficient half-quadratic
splitting minimization with fast Fourier transforms (FFTs) for acceleration. We
finally demonstrate its versatility and many benefits to a series of
signal/image processing and computer vision applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting generative self-supervised learning for the assessment of biological images with lack of annotations: a COVID-19 case-study. (arXiv:2107.07761v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mascolini_A/0/1/0/all/0/1">Alessio Mascolini</a>, <a href="http://arxiv.org/find/eess/1/au:+Cardamone_D/0/1/0/all/0/1">Dario Cardamone</a>, <a href="http://arxiv.org/find/eess/1/au:+Ponzio_F/0/1/0/all/0/1">Francesco Ponzio</a>, <a href="http://arxiv.org/find/eess/1/au:+Cataldo_S/0/1/0/all/0/1">Santa Di Cataldo</a>, <a href="http://arxiv.org/find/eess/1/au:+Ficarra_E/0/1/0/all/0/1">Elisa Ficarra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07761">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-aided analysis of biological images typically requires extensive
training on large-scale annotated datasets, which is not viable in many
situations. In this paper we present GAN-DL, a Discriminator Learner based on
the StyleGAN2 architecture, which we employ for self-supervised image
representation learning in the case of fluorescent biological images. We show
that Wasserstein Generative Adversarial Networks combined with linear Support
Vector Machines enable high-throughput compound screening based on raw images.
We demonstrate this by classifying active and inactive compounds tested for the
inhibition of SARS-CoV-2 infection in VERO and HRCE cell lines. In contrast to
previous methods, our deep learning based approach does not require any
annotation besides the one that is normally collected during the sample
preparation process. We test our technique on the RxRx19a Sars-CoV-2 image
collection. The dataset consists of fluorescent images that were generated to
assess the ability of regulatory-approved or in late-stage clinical trials
compound to modulate the in vitro infection from SARS-CoV-2 in both VERO and
HRCE cell lines. We show that our technique can be exploited not only for
classification tasks, but also to effectively derive a dose response curve for
the tested treatments, in a self-supervised manner. Lastly, we demonstrate its
generalization capabilities by successfully addressing a zero-shot learning
task, consisting in the categorization of four different cell types of the
RxRx1 fluorescent images collection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Facetron: Multi-speaker Face-to-Speech Model based on Cross-modal Latent Representations. (arXiv:2107.12003v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Um_S/0/1/0/all/0/1">Se-Yun Um</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jihyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jihyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Sangshin Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Byun_K/0/1/0/all/0/1">Kyungguen Byun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1">Hong-Goo Kang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12003">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an effective method to synthesize speaker-specific
speech waveforms by conditioning on videos of an individual&#x27;s face. Using a
generative adversarial network (GAN) with linguistic and speaker characteristic
features as auxiliary conditions, our method directly converts face images into
speech waveforms under an end-to-end training framework. The linguistic
features are extracted from lip movements using a lip-reading model, and the
speaker characteristic features are predicted from face images using
cross-modal learning with a pre-trained acoustic model. Since these two
features are uncorrelated and controlled independently, we can flexibly
synthesize speech waveforms whose speaker characteristics vary depending on the
input face images. Therefore, our method can be regarded as a multi-speaker
face-to-speech waveform model. We show the superiority of our proposed model
over conventional methods in terms of both objective and subjective evaluation
results. Specifically, we evaluate the performances of the linguistic feature
and the speaker characteristic generation modules by measuring the accuracy of
automatic speech recognition and automatic speaker/gender recognition tasks,
respectively. We also evaluate the naturalness of the synthesized speech
waveforms using a mean opinion score (MOS) test.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction. (arXiv:2102.05426v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1">Ruihao Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1">Peng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fengwei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Shi Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05426">
                                    <div class="article-summary-box-inner">
                                        <span>We study the challenging task of neural network quantization without
end-to-end retraining, called Post-training Quantization (PTQ). PTQ usually
requires a small subset of training data but produces less powerful quantized
models than Quantization-Aware Training (QAT). In this work, we propose a novel
PTQ framework, dubbed BRECQ, which pushes the limits of bitwidth in PTQ down to
INT2 for the first time. BRECQ leverages the basic building blocks in neural
networks and reconstructs them one-by-one. In a comprehensive theoretical study
of the second-order error, we show that BRECQ achieves a good balance between
cross-layer dependency and generalization error. To further employ the power of
quantization, the mixed precision technique is incorporated in our framework by
approximating the inter-layer and intra-layer sensitivity. Extensive
experiments on various handcrafted and searched neural architectures are
conducted for both image classification and object detection tasks. And for the
first time we prove that, without bells and whistles, PTQ can attain 4-bit
ResNet and MobileNetV2 comparable with QAT and enjoy 240 times faster
production of quantized models. Codes are available at
https://github.com/yhhhli/BRECQ.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGENT: A Benchmark for Core Psychological Reasoning. (arXiv:2102.12321v4 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_T/0/1/0/all/0/1">Tianmin Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhandwaldar_A/0/1/0/all/0/1">Abhishek Bhandwaldar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chuang Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1">Kevin A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shari Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutfreund_D/0/1/0/all/0/1">Dan Gutfreund</a>, <a href="http://arxiv.org/find/cs/1/au:+Spelke_E/0/1/0/all/0/1">Elizabeth Spelke</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullman_T/0/1/0/all/0/1">Tomer D. Ullman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12321">
                                    <div class="article-summary-box-inner">
                                        <span>For machine agents to successfully interact with humans in real-world
settings, they will need to develop an understanding of human mental life.
Intuitive psychology, the ability to reason about hidden mental variables that
drive observable actions, comes naturally to people: even pre-verbal infants
can tell agents from objects, expecting agents to act efficiently to achieve
goals given constraints. Despite recent interest in machine agents that reason
about other agents, it is not clear if such agents learn or hold the core
psychology principles that drive human reasoning. Inspired by cognitive
development studies on intuitive psychology, we present a benchmark consisting
of a large dataset of procedurally generated 3D animations, AGENT (Action,
Goal, Efficiency, coNstraint, uTility), structured around four scenarios (goal
preferences, action efficiency, unobserved constraints, and cost-reward
trade-offs) that probe key concepts of core intuitive psychology. We validate
AGENT with human-ratings, propose an evaluation protocol emphasizing
generalization, and compare two strong baselines built on Bayesian inverse
planning and a Theory of Mind neural network. Our results suggest that to pass
the designed tests of core intuitive psychology at human levels, a model must
acquire or have built-in representations of how agents plan, combining utility
computations and core knowledge of objects and physics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Jet Classification of Boosted Top Quarks with the CMS Open Data. (arXiv:2104.14659v2 [physics.data-an] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Andrews_M/0/1/0/all/0/1">Michael Andrews</a>, <a href="http://arxiv.org/find/physics/1/au:+Burkle_B/0/1/0/all/0/1">Bjorn Burkle</a>, <a href="http://arxiv.org/find/physics/1/au:+Chen_Y/0/1/0/all/0/1">Yi-fan Chen</a>, <a href="http://arxiv.org/find/physics/1/au:+DiCroce_D/0/1/0/all/0/1">Davide DiCroce</a>, <a href="http://arxiv.org/find/physics/1/au:+Gleyzer_S/0/1/0/all/0/1">Sergei Gleyzer</a>, <a href="http://arxiv.org/find/physics/1/au:+Heintz_U/0/1/0/all/0/1">Ulrich Heintz</a>, <a href="http://arxiv.org/find/physics/1/au:+Narain_M/0/1/0/all/0/1">Meenakshi Narain</a>, <a href="http://arxiv.org/find/physics/1/au:+Paulini_M/0/1/0/all/0/1">Manfred Paulini</a>, <a href="http://arxiv.org/find/physics/1/au:+Pervan_N/0/1/0/all/0/1">Nikolas Pervan</a>, <a href="http://arxiv.org/find/physics/1/au:+Shafi_Y/0/1/0/all/0/1">Yusef Shafi</a>, <a href="http://arxiv.org/find/physics/1/au:+Sun_W/0/1/0/all/0/1">Wei Sun</a>, <a href="http://arxiv.org/find/physics/1/au:+Usai_E/0/1/0/all/0/1">Emanuele Usai</a>, <a href="http://arxiv.org/find/physics/1/au:+Yang_K/0/1/0/all/0/1">Kun Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14659">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a novel application of the end-to-end deep learning technique to
the task of discriminating top quark-initiated jets from those originating from
the hadronization of a light quark or a gluon. The end-to-end deep learning
technique combines deep learning algorithms and low-level detector
representation of the high-energy collision event. In this study, we use
low-level detector information from the simulated CMS Open Data samples to
construct the top jet classifiers. To optimize classifier performance we
progressively add low-level information from the CMS tracking detector,
including pixel detector reconstructed hits and impact parameters, and
demonstrate the value of additional tracking information even when no new
spatial structures are added. Relying only on calorimeter energy deposits and
reconstructed pixel detector hits, the end-to-end classifier achieves an AUC
score of 0.975$\pm$0.002 for the task of classifying boosted top quark jets.
After adding derived track quantities, the classifier AUC score increases to
0.9824$\pm$0.0013, serving as the first performance benchmark for these CMS
Open Data samples. We additionally provide a timing performance comparison of
different processor unit architectures for training the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">INSTA-YOLO: Real-Time Instance Segmentation. (arXiv:2102.06777v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohamed_E/0/1/0/all/0/1">Eslam Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaker_A/0/1/0/all/0/1">Abdelrahman Shaker</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Sallab_A/0/1/0/all/0/1">Ahmad El-Sallab</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadhoud_M/0/1/0/all/0/1">Mayada Hadhoud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06777">
                                    <div class="article-summary-box-inner">
                                        <span>Instance segmentation has gained recently huge attention in various computer
vision applications. It aims at providing different IDs to different objects of
the scene, even if they belong to the same class. Instance segmentation is
usually performed as a two-stage pipeline. First, an object is detected, then
semantic segmentation within the detected box area is performed which involves
costly up-sampling. In this paper, we propose Insta-YOLO, a novel one-stage
end-to-end deep learning model for real-time instance segmentation. Instead of
pixel-wise prediction, our model predicts instances as object contours
represented by 2D points in Cartesian space. We evaluate our model on three
datasets, namely, Carvana,Cityscapes and Airbus. We compare our results to the
state-of-the-art models for instance segmentation. The results show our model
achieves competitive accuracy in terms of mAP at twice the speed on GTX-1080
GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Semantic Segmentation with Pixel-Level Contrastive Learning from a Class-wise Memory Bank. (arXiv:2104.13415v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alonso_I/0/1/0/all/0/1">Inigo Alonso</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabater_A/0/1/0/all/0/1">Alberto Sabater</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferstl_D/0/1/0/all/0/1">David Ferstl</a>, <a href="http://arxiv.org/find/cs/1/au:+Montesano_L/0/1/0/all/0/1">Luis Montesano</a>, <a href="http://arxiv.org/find/cs/1/au:+Murillo_A/0/1/0/all/0/1">Ana C. Murillo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13415">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents a novel approach for semi-supervised semantic
segmentation. The key element of this approach is our contrastive learning
module that enforces the segmentation network to yield similar pixel-level
feature representations for same-class samples across the whole dataset. To
achieve this, we maintain a memory bank continuously updated with relevant and
high-quality feature vectors from labeled data. In an end-to-end training, the
features from both labeled and unlabeled data are optimized to be similar to
same-class samples from the memory bank. Our approach outperforms the current
state-of-the-art for semi-supervised semantic segmentation and semi-supervised
domain adaptation on well-known public benchmarks, with larger improvements on
the most challenging scenarios, i.e., less available labeled data.
https://github.com/Shathe/SemiSeg-Contrastive</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransPose: Keypoint Localization via Transformer. (arXiv:2012.14214v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_Z/0/1/0/all/0/1">Zhibin Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_M/0/1/0/all/0/1">Mu Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wankou Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14214">
                                    <div class="article-summary-box-inner">
                                        <span>While CNN-based models have made remarkable progress on human pose
estimation, what spatial dependencies they capture to localize keypoints
remains unclear. In this work, we propose a model called \textbf{TransPose},
which introduces Transformer for human pose estimation. The attention layers
built in Transformer enable our model to capture long-range relationships
efficiently and also can reveal what dependencies the predicted keypoints rely
on. To predict keypoint heatmaps, the last attention layer specially acts as an
aggregator, which collects contributions from image clues and forms maximum
positions of keypoints. Such a heatmap-based localization approach via
Transformer conforms to the principle of Activation Maximization
\cite{erhan2009visualizing}. And the revealed dependencies are image-specific
and fine-grained, which also can provide evidence of how the model handles
special cases, e.g., occlusion. The experiments show that TransPose achieves
75.8 AP and 75.0 AP on COCO validation and test-dev sets with 256 $\times$ 192
input resolution, while being more lightweight and faster than mainstream CNN
architectures. The TransPose model also transfers very well on MPII benchmark,
yielding 93.9\% accuracy on test set when fine-tuned with small training costs.
Code and pre-trained models are publicly available at
\url{https://github.com/yangsenius/TransPose}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On-Device Content Moderation. (arXiv:2107.11845v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pandey_A/0/1/0/all/0/1">Anchal Pandey</a>, <a href="http://arxiv.org/find/cs/1/au:+Moharana_S/0/1/0/all/0/1">Sukumar Moharana</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohanty_D/0/1/0/all/0/1">Debi Prasanna Mohanty</a>, <a href="http://arxiv.org/find/cs/1/au:+Panwar_A/0/1/0/all/0/1">Archit Panwar</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_D/0/1/0/all/0/1">Dewang Agarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Thota_S/0/1/0/all/0/1">Siva Prasad Thota</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11845">
                                    <div class="article-summary-box-inner">
                                        <span>With the advent of internet, not safe for work(NSFW) content moderation is a
major problem today. Since,smartphones are now part of daily life of billions
of people,it becomes even more important to have a solution which coulddetect
and suggest user about potential NSFW content present ontheir phone. In this
paper we present a novel on-device solutionfor detecting NSFW images. In
addition to conventional porno-graphic content moderation, we have also
included semi-nudecontent moderation as it is still NSFW in a large
demography.We have curated a dataset comprising of three major
categories,namely nude, semi-nude and safe images. We have created anensemble
of object detector and classifier for filtering of nudeand semi-nude contents.
The solution provides unsafe body partannotations along with identification of
semi-nude images. Weextensively tested our proposed solution on several public
datasetand also on our custom dataset. The model achieves F1 scoreof 0.91 with
95% precision and 88% recall on our customNSFW16k dataset and 0.92 MAP on NPDI
dataset. Moreover itachieves average 0.002 false positive rate on a collection
of safeimage open datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HRegNet: A Hierarchical Network for Large-scale Outdoor LiDAR Point Cloud Registration. (arXiv:2107.11992v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_F/0/1/0/all/0/1">Fan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yinlong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lijun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_S/0/1/0/all/0/1">Sanqing Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_R/0/1/0/all/0/1">Rongqi Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11992">
                                    <div class="article-summary-box-inner">
                                        <span>Point cloud registration is a fundamental problem in 3D computer vision.
Outdoor LiDAR point clouds are typically large-scale and complexly distributed,
which makes the registration challenging. In this paper, we propose an
efficient hierarchical network named HRegNet for large-scale outdoor LiDAR
point cloud registration. Instead of using all points in the point clouds,
HRegNet performs registration on hierarchically extracted keypoints and
descriptors. The overall framework combines the reliable features in deeper
layer and the precise position information in shallower layers to achieve
robust and precise registration. We present a correspondence network to
generate correct and accurate keypoints correspondences. Moreover, bilateral
consensus and neighborhood consensus are introduced for keypoints matching and
novel similarity features are designed to incorporate them into the
correspondence network, which significantly improves the registration
performance. Besides, the whole network is also highly efficient since only a
small number of keypoints are used for registration. Extensive experiments are
conducted on two large-scale outdoor LiDAR point cloud datasets to demonstrate
the high accuracy and efficiency of the proposed HRegNet. The project website
is https://ispc-group.github.io/hregnet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to See Through Obstructions with Layered Decomposition. (arXiv:2008.04902v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yu-Lun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1">Wei-Sheng Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1">Ming-Hsuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yung-Yu Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jia-Bin Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.04902">
                                    <div class="article-summary-box-inner">
                                        <span>We present a learning-based approach for removing unwanted obstructions, such
as window reflections, fence occlusions, or adherent raindrops, from a short
sequence of images captured by a moving camera. Our method leverages motion
differences between the background and obstructing elements to recover both
layers. Specifically, we alternate between estimating dense optical flow fields
of the two layers and reconstructing each layer from the flow-warped images via
a deep convolutional neural network. This learning-based layer reconstruction
module facilitates accommodating potential errors in the flow estimation and
brittle assumptions, such as brightness consistency. We show that the proposed
approach learned from synthetically generated data performs well to real
images. Experimental results on numerous challenging scenarios of reflection
and fence removal demonstrate the effectiveness of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributional Shifts in Automated Diabetic Retinopathy Screening. (arXiv:2107.11822v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nandy_J/0/1/0/all/0/1">Jay Nandy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Wynne Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Mong Li Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11822">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based models are developed to automatically detect if a retina
image is &#x60;referable&#x27; in diabetic retinopathy (DR) screening. However, their
classification accuracy degrades as the input images distributionally shift
from their training distribution. Further, even if the input is not a retina
image, a standard DR classifier produces a high confident prediction that the
image is &#x60;referable&#x27;. Our paper presents a Dirichlet Prior Network-based
framework to address this issue. It utilizes an out-of-distribution (OOD)
detector model and a DR classification model to improve generalizability by
identifying OOD images. Experiments on real-world datasets indicate that the
proposed framework can eliminate the unknown non-retina images and identify the
distributionally shifted retina images for human intervention.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MagFace: A Universal Representation for Face Recognition and Quality Assessment. (arXiv:2103.06627v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1">Qiang Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1">Shichao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhida Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Feng Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06627">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of face recognition system degrades when the variability of
the acquired faces increases. Prior work alleviates this issue by either
monitoring the face quality in pre-processing or predicting the data
uncertainty along with the face feature. This paper proposes MagFace, a
category of losses that learn a universal feature embedding whose magnitude can
measure the quality of the given face. Under the new loss, it can be proven
that the magnitude of the feature embedding monotonically increases if the
subject is more likely to be recognized. In addition, MagFace introduces an
adaptive mechanism to learn a wellstructured within-class feature distributions
by pulling easy samples to class centers while pushing hard samples away. This
prevents models from overfitting on noisy low-quality samples and improves face
recognition in the wild. Extensive experiments conducted on face recognition,
quality assessments as well as clustering demonstrate its superiority over
state-of-the-arts. The code is available at
https://github.com/IrvingMeng/MagFace.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Light Field Salient Object Detection: A Review and Benchmark. (arXiv:2010.04968v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_K/0/1/0/all/0/1">Keren Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1">Ge-Peng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tao Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qijun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">Deng-Ping Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04968">
                                    <div class="article-summary-box-inner">
                                        <span>Salient object detection (SOD) is a long-standing research topic in computer
vision and has drawn an increasing amount of research interest in the past
decade. This paper provides the first comprehensive review and benchmark for
light field SOD, which has long been lacking in the saliency community.
Firstly, we introduce preliminary knowledge on light fields, including theory
and data forms, and then review existing studies on light field SOD, covering
ten traditional models, seven deep learning-based models, one comparative
study, and one brief review. Existing datasets for light field SOD are also
summarized with detailed information and statistical analyses. Secondly, we
benchmark nine representative light field SOD models together with several
cutting-edge RGB-D SOD models on four widely used light field datasets, from
which insightful discussions and analyses, including a comparison between light
field SOD and RGB-D SOD models, are achieved. Besides, due to the inconsistency
of datasets in their current forms, we further generate complete data and
supplement focal stacks, depth maps and multi-view images for the inconsistent
datasets, making them consistent and unified. Our supplemental data makes a
universal benchmark possible. Lastly, because light field SOD is quite a
special problem attributed to its diverse data representations and high
dependency on acquisition hardware, making it differ greatly from other
saliency detection tasks, we provide nine hints into the challenges and future
directions, and outline several open issues. We hope our review and
benchmarking could help advance research in this field. All the materials
including collected models, datasets, benchmarking results, and supplemented
light field datasets will be publicly available on our project site
https://github.com/kerenfu/LFSOD-Survey.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers. (arXiv:2012.15840v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Sixiao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiachen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Hengshuang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiatian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zekun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jianfeng Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tao Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Li Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15840">
                                    <div class="article-summary-box-inner">
                                        <span>Most recent semantic segmentation methods adopt a fully-convolutional network
(FCN) with an encoder-decoder architecture. The encoder progressively reduces
the spatial resolution and learns more abstract/semantic visual concepts with
larger receptive fields. Since context modeling is critical for segmentation,
the latest efforts have been focused on increasing the receptive field, through
either dilated/atrous convolutions or inserting attention modules. However, the
encoder-decoder based FCN architecture remains unchanged. In this paper, we aim
to provide an alternative perspective by treating semantic segmentation as a
sequence-to-sequence prediction task. Specifically, we deploy a pure
transformer (ie, without convolution and resolution reduction) to encode an
image as a sequence of patches. With the global context modeled in every layer
of the transformer, this encoder can be combined with a simple decoder to
provide a powerful segmentation model, termed SEgmentation TRansformer (SETR).
Extensive experiments show that SETR achieves new state of the art on ADE20K
(50.28% mIoU), Pascal Context (55.83% mIoU) and competitive results on
Cityscapes. Particularly, we achieve the first position in the highly
competitive ADE20K test server leaderboard on the day of submission.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MOGAN: Morphologic-structure-aware Generative Learning from a Single Image. (arXiv:2103.02997v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jinshu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1">Qihui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Q/0/1/0/all/0/1">Qi Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">MengChu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02997">
                                    <div class="article-summary-box-inner">
                                        <span>In most interactive image generation tasks, given regions of interest (ROI)
by users, the generated results are expected to have adequate diversities in
appearance while maintaining correct and reasonable structures in original
images. Such tasks become more challenging if only limited data is available.
Recently proposed generative models complete training based on only one image.
They pay much attention to the monolithic feature of the sample while ignoring
the actual semantic information of different objects inside the sample. As a
result, for ROI-based generation tasks, they may produce inappropriate samples
with excessive randomicity and without maintaining the related objects&#x27; correct
structures. To address this issue, this work introduces a
MOrphologic-structure-aware Generative Adversarial Network named MOGAN that
produces random samples with diverse appearances and reliable structures based
on only one image. For training for ROI, we propose to utilize the data coming
from the original image being augmented and bring in a novel module to
transform such augmented data into knowledge containing both structures and
appearances, thus enhancing the model&#x27;s comprehension of the sample. To learn
the rest areas other than ROI, we employ binary masks to ensure the generation
isolated from ROI. Finally, we set parallel and hierarchical branches of the
mentioned learning process. Compared with other single image GAN schemes, our
approach focuses on internal features including the maintenance of rational
structures and variation on appearance. Experiments confirm a better capacity
of our model on ROI-based image generation tasks than its competitive peers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth Completion with Twin Surface Extrapolation at Occlusion Boundaries. (arXiv:2104.02253v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Imran_S/0/1/0/all/0/1">Saif Imran</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_D/0/1/0/all/0/1">Daniel Morris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02253">
                                    <div class="article-summary-box-inner">
                                        <span>Depth completion starts from a sparse set of known depth values and estimates
the unknown depths for the remaining image pixels. Most methods model this as
depth interpolation and erroneously interpolate depth pixels into the empty
space between spatially distinct objects, resulting in depth-smearing across
occlusion boundaries. Here we propose a multi-hypothesis depth representation
that explicitly models both foreground and background depths in the difficult
occlusion-boundary regions. Our method can be thought of as performing
twin-surface extrapolation, rather than interpolation, in these regions. Next
our method fuses these extrapolated surfaces into a single depth image
leveraging the image data. Key to our method is the use of an asymmetric loss
function that operates on a novel twin-surface representation. This enables us
to train a network to simultaneously do surface extrapolation and surface
fusion. We characterize our loss function and compare with other common losses.
Finally, we validate our method on three different datasets; KITTI, an outdoor
real-world dataset, NYU2, indoor real-world depth dataset and Virtual KITTI, a
photo-realistic synthetic dataset with dense groundtruth, and demonstrate
improvement over the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Action Recognition on Heterogeneous Embedded Devices. (arXiv:2107.12147v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Pranjal Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Goenka_S/0/1/0/all/0/1">Shreyas Goenka</a>, <a href="http://arxiv.org/find/cs/1/au:+Bagchi_S/0/1/0/all/0/1">Saurabh Bagchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_B/0/1/0/all/0/1">Biplab Banerjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaterji_S/0/1/0/all/0/1">Somali Chaterji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12147">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning allows a large number of devices to jointly learn a model
without sharing data. In this work, we enable clients with limited computing
power to perform action recognition, a computationally heavy task. We first
perform model compression at the central server through knowledge distillation
on a large dataset. This allows the model to learn complex features and serves
as an initialization for model fine-tuning. The fine-tuning is required because
the limited data present in smaller datasets is not adequate for action
recognition models to learn complex spatio-temporal features. Because the
clients present are often heterogeneous in their computing resources, we use an
asynchronous federated optimization and we further show a convergence bound. We
compare our approach to two baseline approaches: fine-tuning at the central
server (no clients) and fine-tuning using (heterogeneous) clients using
synchronous federated averaging. We empirically show on a testbed of
heterogeneous embedded devices that we can perform action recognition with
comparable accuracy to the two baselines above, while our asynchronous learning
strategy reduces the training time by 40%, relative to synchronous learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Video Transformer Network. (arXiv:2102.00719v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neimark_D/0/1/0/all/0/1">Daniel Neimark</a>, <a href="http://arxiv.org/find/cs/1/au:+Bar_O/0/1/0/all/0/1">Omri Bar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zohar_M/0/1/0/all/0/1">Maya Zohar</a>, <a href="http://arxiv.org/find/cs/1/au:+Asselmann_D/0/1/0/all/0/1">Dotan Asselmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00719">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents VTN, a transformer-based framework for video recognition.
Inspired by recent developments in vision transformers, we ditch the standard
approach in video action recognition that relies on 3D ConvNets and introduce a
method that classifies actions by attending to the entire video sequence
information. Our approach is generic and builds on top of any given 2D spatial
network. In terms of wall runtime, it trains $16.1\times$ faster and runs
$5.1\times$ faster during inference while maintaining competitive accuracy
compared to other state-of-the-art methods. It enables whole video analysis,
via a single end-to-end pass, while requiring $1.5\times$ fewer GFLOPs. We
report competitive results on Kinetics-400 and present an ablation study of VTN
properties and the trade-off between accuracy and inference speed. We hope our
approach will serve as a new baseline and start a fresh line of research in the
video recognition domain. Code and models are available at:
https://github.com/bomri/SlowFast/blob/master/projects/vtn/README.md</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Self-supervised Correspondence Learning: A Video Frame-level Similarity Perspective. (arXiv:2103.17263v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiarui Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaolong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17263">
                                    <div class="article-summary-box-inner">
                                        <span>Learning a good representation for space-time correspondence is the key for
various computer vision tasks, including tracking object bounding boxes and
performing video object pixel segmentation. To learn generalizable
representation for correspondence in large-scale, a variety of self-supervised
pretext tasks are proposed to explicitly perform object-level or patch-level
similarity learning. Instead of following the previous literature, we propose
to learn correspondence using Video Frame-level Similarity (VFS) learning, i.e,
simply learning from comparing video frames. Our work is inspired by the recent
success in image-level contrastive learning and similarity learning for visual
recognition. Our hypothesis is that if the representation is good for
recognition, it requires the convolutional features to find correspondence
between similar objects or parts. Our experiments show surprising results that
VFS surpasses state-of-the-art self-supervised approaches for both OTB visual
object tracking and DAVIS video object segmentation. We perform detailed
analysis on what matters in VFS and reveals new properties on image and frame
level similarity learning. Project page is available at https://jerryxu.net/VFS</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Error Diffusion Halftoning Against Adversarial Examples. (arXiv:2101.09451v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1">Shao-Yuan Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09451">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial examples contain carefully crafted perturbations that can fool
deep neural networks (DNNs) into making wrong predictions. Enhancing the
adversarial robustness of DNNs has gained considerable interest in recent
years. Although image transformation-based defenses were widely considered at
an earlier time, most of them have been defeated by adaptive attacks. In this
paper, we propose a new image transformation defense based on error diffusion
halftoning, and combine it with adversarial training to defend against
adversarial examples. Error diffusion halftoning projects an image into a 1-bit
space and diffuses quantization error to neighboring pixels. This process can
remove adversarial perturbations from a given image while maintaining
acceptable image quality in the meantime in favor of recognition. Experimental
results demonstrate that the proposed method is able to improve adversarial
robustness even under advanced adaptive attacks, while most of the other image
transformation-based defenses do not. We show that a proper image
transformation can still be an effective defense approach. Code:
https://github.com/shaoyuanlo/Halftoning-Defense</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Automated Diagnosis of COVID-19 Based on Scanning Images. (arXiv:2006.05245v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_D/0/1/0/all/0/1">Delong Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Ji_S/0/1/0/all/0/1">Shunhui Ji</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1">Fan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1">Zewen Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1">Xinyu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05245">
                                    <div class="article-summary-box-inner">
                                        <span>The pandemic of COVID-19 has caused millions of infections, which has led to
a great loss all over the world, socially and economically. Due to the
false-negative rate and the time-consuming of the conventional Reverse
Transcription Polymerase Chain Reaction (RT-PCR) tests, diagnosing based on
X-ray images and Computed Tomography (CT) images has been widely adopted.
Therefore, researchers of the computer vision area have developed many
automatic diagnosing models based on machine learning or deep learning to
assist the radiologists and improve the diagnosing accuracy. In this paper, we
present a review of these recently emerging automatic diagnosing models. 70
models proposed from February 14, 2020, to July 21, 2020, are involved. We
analyzed the models from the perspective of preprocessing, feature extraction,
classification, and evaluation. Based on the limitation of existing models, we
pointed out that domain adaption in transfer learning and interpretability
promotion would be the possible future directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-frame Feature Aggregation for Real-time Instrument Segmentation in Endoscopic Video. (arXiv:2011.08752v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_F/0/1/0/all/0/1">Fangbo Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Haonan Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Bly_R/0/1/0/all/0/1">Randall A. Bly</a>, <a href="http://arxiv.org/find/cs/1/au:+Moe_K/0/1/0/all/0/1">Kris S. Moe</a>, <a href="http://arxiv.org/find/cs/1/au:+Hannaford_B/0/1/0/all/0/1">Blake Hannaford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08752">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based methods have achieved promising results on surgical
instrument segmentation. However, the high computation cost may limit the
application of deep models to time-sensitive tasks such as online surgical
video analysis for robotic-assisted surgery. Moreover, current methods may
still suffer from challenging conditions in surgical images such as various
lighting conditions and the presence of blood. We propose a novel Multi-frame
Feature Aggregation (MFFA) module to aggregate video frame features temporally
and spatially in a recurrent mode. By distributing the computation load of deep
feature extraction over sequential frames, we can use a lightweight encoder to
reduce the computation costs at each time step. Moreover, public surgical
videos usually are not labeled frame by frame, so we develop a method that can
randomly synthesize a surgical frame sequence from a single labeled frame to
assist network training. We demonstrate that our approach achieves superior
performance to corresponding deeper segmentation models on two public surgery
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PDE-based Group Equivariant Convolutional Neural Networks. (arXiv:2001.09046v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Smets_B/0/1/0/all/0/1">Bart Smets</a>, <a href="http://arxiv.org/find/cs/1/au:+Portegies_J/0/1/0/all/0/1">Jim Portegies</a>, <a href="http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1">Erik Bekkers</a>, <a href="http://arxiv.org/find/cs/1/au:+Duits_R/0/1/0/all/0/1">Remco Duits</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.09046">
                                    <div class="article-summary-box-inner">
                                        <span>We present a PDE-based framework that generalizes Group equivariant
Convolutional Neural Networks (G-CNNs). In this framework, a network layer is
seen as a set of PDE-solvers where geometrically meaningful PDE-coefficients
become the layer&#x27;s trainable weights. Formulating our PDEs on homogeneous
spaces allows these networks to be designed with built-in symmetries such as
rotation in addition to the standard translation equivariance of CNNs.

Having all the desired symmetries included in the design obviates the need to
include them by means of costly techniques such as data augmentation. We will
discuss our PDE-based G-CNNs (PDE-G-CNNs) in a general homogeneous space
setting while also going into the specifics of our primary case of interest:
roto-translation equivariance.

We solve the PDE of interest by a combination of linear group convolutions
and non-linear morphological group convolutions with analytic kernel
approximations that we underpin with formal theorems. Our kernel approximations
allow for fast GPU-implementation of the PDE-solvers, we release our
implementation with this article. Just like for linear convolution a
morphological convolution is specified by a kernel that we train in our
PDE-G-CNNs. In PDE-G-CNNs we do not use non-linearities such as max/min-pooling
and ReLUs as they are already subsumed by morphological convolutions.

We present a set of experiments to demonstrate the strength of the proposed
PDE-G-CNNs in increasing the performance of deep learning based imaging
applications with far fewer parameters than traditional CNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overcoming Barriers to Data Sharing with Medical Image Generation: A Comprehensive Evaluation. (arXiv:2012.03769v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Schutte_A/0/1/0/all/0/1">August DuMont Sch&#xfc;tte</a>, <a href="http://arxiv.org/find/eess/1/au:+Hetzel_J/0/1/0/all/0/1">J&#xfc;rgen Hetzel</a>, <a href="http://arxiv.org/find/eess/1/au:+Gatidis_S/0/1/0/all/0/1">Sergios Gatidis</a>, <a href="http://arxiv.org/find/eess/1/au:+Hepp_T/0/1/0/all/0/1">Tobias Hepp</a>, <a href="http://arxiv.org/find/eess/1/au:+Dietz_B/0/1/0/all/0/1">Benedikt Dietz</a>, <a href="http://arxiv.org/find/eess/1/au:+Bauer_S/0/1/0/all/0/1">Stefan Bauer</a>, <a href="http://arxiv.org/find/eess/1/au:+Schwab_P/0/1/0/all/0/1">Patrick Schwab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03769">
                                    <div class="article-summary-box-inner">
                                        <span>Privacy concerns around sharing personally identifiable information are a
major practical barrier to data sharing in medical research. However, in many
cases, researchers have no interest in a particular individual&#x27;s information
but rather aim to derive insights at the level of cohorts. Here, we utilize
Generative Adversarial Networks (GANs) to create derived medical imaging
datasets consisting entirely of synthetic patient data. The synthetic images
ideally have, in aggregate, similar statistical properties to those of a source
dataset but do not contain sensitive personal information. We assess the
quality of synthetic data generated by two GAN models for chest radiographs
with 14 different radiology findings and brain computed tomography (CT) scans
with six types of intracranial hemorrhages. We measure the synthetic image
quality by the performance difference of predictive models trained on either
the synthetic or the real dataset. We find that synthetic data performance
disproportionately benefits from a reduced number of unique label combinations.
Our open-source benchmark also indicates that at low number of samples per
class, label overfitting effects start to dominate GAN training. We
additionally conducted a reader study in which trained radiologists do not
perform better than random on discriminating between synthetic and real medical
images for intermediate levels of resolutions. In accordance with our benchmark
results, the classification accuracy of radiologists increases at higher
spatial resolution levels. Our study offers valuable guidelines and outlines
practical conditions under which insights derived from synthetic medical images
are similar to those that would have been derived from real imaging data. Our
results indicate that synthetic data sharing may be an attractive and
privacy-preserving alternative to sharing real patient-level data in the right
settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BASAR:Black-box Attack on Skeletal Action Recognition. (arXiv:2103.05266v6 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diao_Y/0/1/0/all/0/1">Yunfeng Diao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_T/0/1/0/all/0/1">Tianjia Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yong-Liang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Kun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">He Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05266">
                                    <div class="article-summary-box-inner">
                                        <span>Skeletal motion plays a vital role in human activity recognition as either an
independent data source or a complement. The robustness of skeleton-based
activity recognizers has been questioned recently, which shows that they are
vulnerable to adversarial attacks when the full-knowledge of the recognizer is
accessible to the attacker. However, this white-box requirement is overly
restrictive in most scenarios and the attack is not truly threatening. In this
paper, we show that such threats do exist under black-box settings too. To this
end, we propose the first black-box adversarial attack method BASAR. Through
BASAR, we show that adversarial attack is not only truly a threat but also can
be extremely deceitful, because on-manifold adversarial samples are rather
common in skeletal motions, in contrast to the common belief that adversarial
samples only exist off-manifold. Through exhaustive evaluation and comparison,
we show that BASAR can deliver successful attacks across models, data, and
attack modes. Through harsh perceptual studies, we show that it achieves
effective yet imperceptible attacks. By analyzing the attack on different
activity recognizers, BASAR helps identify the potential causes of their
vulnerability and provides insights on what classifiers are likely to be more
robust against attack. Code is available at
https://github.com/realcrane/BASAR-Black-box-Attack-on-Skeletal-Action-Recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiscale Sparsifying Transform Learning for Image Denoising. (arXiv:2003.11265v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abbasi_A/0/1/0/all/0/1">Ashkan Abbasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Monadjemi_A/0/1/0/all/0/1">Amirhassan Monadjemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1">Leyuan Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabbani_H/0/1/0/all/0/1">Hossein Rabbani</a>, <a href="http://arxiv.org/find/cs/1/au:+Noormohammadi_N/0/1/0/all/0/1">Neda Noormohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.11265">
                                    <div class="article-summary-box-inner">
                                        <span>The data-driven sparse methods such as synthesis dictionary learning (e.g.,
K-SVD) and sparsifying transform learning have been proven effective in image
denoising. However, they are intrinsically single-scale which can lead to
suboptimal results. We propose two methods developed based on wavelet subbands
mixing to efficiently combine the merits of both single and multiscale methods.
We show that an efficient multiscale method can be devised without the need for
denoising detail subbands which substantially reduces the runtime. The proposed
methods are initially derived within the framework of sparsifying transform
learning denoising, and then, they are generalized to propose our multiscale
extensions for the well-known K-SVD and SAIST image denoising methods. We
analyze and assess the studied methods thoroughly and compare them with the
well-known and state-of-the-art methods. The experiments show that our methods
are able to offer good trade-offs between performance and complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tensor optimal transport, distance between sets of measures and tensor scaling. (arXiv:2005.00945v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Friedland_S/0/1/0/all/0/1">Shmuel Friedland</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00945">
                                    <div class="article-summary-box-inner">
                                        <span>We study the optimal transport problem for $d&gt;2$ discrete measures. This is a
linear programming problem on $d$-tensors. It gives a way to compute a
&quot;distance&quot; between two sets of discrete measures. We introduce an entropic
regularization term, which gives rise to a scaling of tensors. We give a
variation of the celebrated Sinkhorn scaling algorithm. We show that this
algorithm can be viewed as a partial minimization algorithm of a strictly
convex function. Under appropriate conditions the rate of convergence is
geometric and we estimate the rate. Our results are generalizations of known
results for the classical case of two discrete measures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Multisensor Change Detection. (arXiv:2103.05102v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Sudipan Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Ebel_P/0/1/0/all/0/1">Patrick Ebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiao Xiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05102">
                                    <div class="article-summary-box-inner">
                                        <span>Most change detection methods assume that pre-change and post-change images
are acquired by the same sensor. However, in many real-life scenarios, e.g.,
natural disaster, it is more practical to use the latest available images
before and after the occurrence of incidence, which may be acquired using
different sensors. In particular, we are interested in the combination of the
images acquired by optical and Synthetic Aperture Radar (SAR) sensors. SAR
images appear vastly different from the optical images even when capturing the
same scene. Adding to this, change detection methods are often constrained to
use only target image-pair, no labeled data, and no additional unlabeled data.
Such constraints limit the scope of traditional supervised machine learning and
unsupervised generative approaches for multi-sensor change detection. Recent
rapid development of self-supervised learning methods has shown that some of
them can even work with only few images. Motivated by this, in this work we
propose a method for multi-sensor change detection using only the unlabeled
target bi-temporal images that are used for training a network in
self-supervised fashion by using deep clustering and contrastive learning. The
proposed method is evaluated on four multi-modal bi-temporal scenes showing
change and the benefits of our self-supervised approach are demonstrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating Bi-Level Optimization for Learning and Vision from a Unified Perspective: A Survey and Beyond. (arXiv:2101.11517v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Risheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jiaxin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1">Deyu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhouchen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11517">
                                    <div class="article-summary-box-inner">
                                        <span>Bi-Level Optimization (BLO) is originated from the area of economic game
theory and then introduced into the optimization community. BLO is able to
handle problems with a hierarchical structure, involving two levels of
optimization tasks, where one task is nested inside the other. In machine
learning and computer vision fields, despite the different motivations and
mechanisms, a lot of complex problems, such as hyper-parameter optimization,
multi-task and meta-learning, neural architecture search, adversarial learning
and deep reinforcement learning, actually all contain a series of closely
related subproblms. In this paper, we first uniformly express these complex
learning and vision problems from the perspective of BLO. Then we construct a
best-response-based single-level reformulation and establish a unified
algorithmic framework to understand and formulate mainstream gradient-based BLO
methodologies, covering aspects ranging from fundamental automatic
differentiation schemes to various accelerations, simplifications, extensions
and their convergence and complexity properties. Last but not least, we discuss
the potentials of our unified BLO framework for designing new algorithms and
point out some promising directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from 2D: Contrastive Pixel-to-Point Knowledge Transfer for 3D Pretraining. (arXiv:2104.04687v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yueh-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1">Hung-Yueh Chiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hung-Ting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhe-Yu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chin-Tang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_C/0/1/0/all/0/1">Ching-Yu Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Winston H. Hsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04687">
                                    <div class="article-summary-box-inner">
                                        <span>Most 3D neural networks are trained from scratch owing to the lack of
large-scale labeled datasets. In this paper, we present a novel 3D pretraining
method by leveraging 2D networks learned from rich 2D datasets. We propose the
contrastive pixel-to-point knowledge transfer to effectively utilize the 2D
information by mapping the pixel-level and point-level features into the same
embedding space. Due to the heterogeneous nature between 2D and 3D networks, we
introduce the back-projection function to align the features between 2D and 3D
to make the transfer possible. Additionally, we devise an upsampling feature
projection layer to increase the spatial resolution of high-level 2D feature
maps, which helps learning fine-grained 3D representations. With a pretrained
2D network, the proposed pretraining process requires no additional 2D or 3D
labeled data, further alleviating the expansive 3D data annotation cost. To the
best of our knowledge, we are the first to exploit existing 2D trained weights
to pretrain 3D deep neural networks. Our intensive experiments show that the 3D
models pretrained with 2D knowledge boost the performances across various
real-world 3D downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Fully Spiking Hybrid Neural Network for Energy-Efficient Object Detection. (arXiv:2104.10719v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_B/0/1/0/all/0/1">Biswadeep Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+She_X/0/1/0/all/0/1">Xueyuan She</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_S/0/1/0/all/0/1">Saibal Mukhopadhyay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10719">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a Fully Spiking Hybrid Neural Network (FSHNN) for
energy-efficient and robust object detection in resource-constrained platforms.
The network architecture is based on Convolutional SNN using
leaky-integrate-fire neuron models. The model combines unsupervised Spike
Time-Dependent Plasticity (STDP) learning with back-propagation (STBP) learning
methods and also uses Monte Carlo Dropout to get an estimate of the uncertainty
error. FSHNN provides better accuracy compared to DNN based object detectors
while being 150X energy-efficient. It also outperforms these object detectors,
when subjected to noisy input data and less labeled training data with a lower
uncertainty error.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">P-KDGAN: Progressive Knowledge Distillation with GANs for One-class Novelty Detection. (arXiv:2007.06963v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shifeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lei Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06963">
                                    <div class="article-summary-box-inner">
                                        <span>One-class novelty detection is to identify anomalous instances that do not
conform to the expected normal instances. In this paper, the Generative
Adversarial Networks (GANs) based on encoder-decoder-encoder pipeline are used
for detection and achieve state-of-the-art performance. However, deep neural
networks are too over-parameterized to deploy on resource-limited devices.
Therefore, Progressive Knowledge Distillation with GANs (PKDGAN) is proposed to
learn compact and fast novelty detection networks. The P-KDGAN is a novel
attempt to connect two standard GANs by the designed distillation loss for
transferring knowledge from the teacher to the student. The progressive
learning of knowledge distillation is a two-step approach that continuously
improves the performance of the student GAN and achieves better performance
than single step methods. In the first step, the student GAN learns the basic
knowledge totally from the teacher via guiding of the pretrained teacher GAN
with fixed weights. In the second step, joint fine-training is adopted for the
knowledgeable teacher and student GANs to further improve the performance and
stability. The experimental results on CIFAR-10, MNIST, and FMNIST show that
our method improves the performance of the student GAN by 2.44%, 1.77%, and
1.73% when compressing the computation at ratios of 24.45:1, 311.11:1, and
700:1, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain-Aware SE Network for Sketch-based Image Retrieval with Multiplicative Euclidean Margin Softmax. (arXiv:1812.04275v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Peng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hangyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wenming Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1">Guodong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1812.04275">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel approach for Sketch-Based Image Retrieval (SBIR),
for which the key is to bridge the gap between sketches and photos in terms of
the data representation. Inspired by channel-wise attention explored in recent
years, we present a Domain-Aware Squeeze-and-Excitation (DASE) network, which
seamlessly incorporates the prior knowledge of sample sketch or photo into SE
module and make the SE module capable of emphasizing appropriate channels
according to domain signal. Accordingly, the proposed network can switch its
mode to achieve a better domain feature with lower intra-class discrepancy.
Moreover, while previous works simply focus on minimizing intra-class distance
and maximizing inter-class distance, we introduce a loss function, named
Multiplicative Euclidean Margin Softmax (MEMS), which introduces multiplicative
Euclidean margin into feature space and ensure that the maximum intra-class
distance is smaller than the minimum inter-class distance. This facilitates
learning a highly discriminative feature space and ensures a more accurate
image retrieval result. Extensive experiments are conducted on two widely used
SBIR benchmark datasets. Our approach achieves better results on both datasets,
surpassing the state-of-the-art methods by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Better Compression with Deep Pre-Editing. (arXiv:2002.00113v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Talebi_H/0/1/0/all/0/1">Hossein Talebi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kelly_D/0/1/0/all/0/1">Damien Kelly</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_X/0/1/0/all/0/1">Xiyang Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Dorado_I/0/1/0/all/0/1">Ignacio Garcia Dorado</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_F/0/1/0/all/0/1">Feng Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Milanfar_P/0/1/0/all/0/1">Peyman Milanfar</a>, <a href="http://arxiv.org/find/eess/1/au:+Elad_M/0/1/0/all/0/1">Michael Elad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00113">
                                    <div class="article-summary-box-inner">
                                        <span>Could we compress images via standard codecs while avoiding visible
artifacts? The answer is obvious -- this is doable as long as the bit budget is
generous enough. What if the allocated bit-rate for compression is
insufficient? Then unfortunately, artifacts are a fact of life. Many attempts
were made over the years to fight this phenomenon, with various degrees of
success. In this work we aim to break the unholy connection between bit-rate
and image quality, and propose a way to circumvent compression artifacts by
pre-editing the incoming image and modifying its content to fit the given bits.
We design this editing operation as a learned convolutional neural network, and
formulate an optimization problem for its training. Our loss takes into account
a proximity between the original image and the edited one, a bit-budget penalty
over the proposed image, and a no-reference image quality measure for forcing
the outcome to be visually pleasing. The proposed approach is demonstrated on
the popular JPEG compression, showing savings in bits and/or improvements in
visual quality, obtained with intricate editing effects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image compression optimized for 3D reconstruction by utilizing deep neural networks. (arXiv:2003.12618v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Golts_A/0/1/0/all/0/1">Alex Golts</a>, <a href="http://arxiv.org/find/eess/1/au:+Schechner_Y/0/1/0/all/0/1">Yoav Y. Schechner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.12618">
                                    <div class="article-summary-box-inner">
                                        <span>Computer vision tasks are often expected to be executed on compressed images.
Classical image compression standards like JPEG 2000 are widely used. However,
they do not account for the specific end-task at hand. Motivated by works on
recurrent neural network (RNN)-based image compression and three-dimensional
(3D) reconstruction, we propose unified network architectures to solve both
tasks jointly. These joint models provide image compression tailored for the
specific task of 3D reconstruction. Images compressed by our proposed models,
yield 3D reconstruction performance superior as compared to using JPEG 2000
compression. Our models significantly extend the range of compression rates for
which 3D reconstruction is possible. We also show that this can be done highly
efficiently at almost no additional cost to obtain compression on top of the
computation already required for performing the 3D reconstruction task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vehicle-Rear: A New Dataset to Explore Feature Fusion for Vehicle Identification Using Convolutional Neural Networks. (arXiv:1911.05541v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oliveira_I/0/1/0/all/0/1">Icaro O. de Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Laroca_R/0/1/0/all/0/1">Rayson Laroca</a>, <a href="http://arxiv.org/find/cs/1/au:+Menotti_D/0/1/0/all/0/1">David Menotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Fonseca_K/0/1/0/all/0/1">Keiko V. O. Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Minetto_R/0/1/0/all/0/1">Rodrigo Minetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.05541">
                                    <div class="article-summary-box-inner">
                                        <span>This work addresses the problem of vehicle identification through
non-overlapping cameras. As our main contribution, we introduce a novel dataset
for vehicle identification, called Vehicle-Rear, that contains more than three
hours of high-resolution videos, with accurate information about the make,
model, color and year of nearly 3,000 vehicles, in addition to the position and
identification of their license plates. To explore our dataset we design a
two-stream CNN that simultaneously uses two of the most distinctive and
persistent features available: the vehicle&#x27;s appearance and its license plate.
This is an attempt to tackle a major problem: false alarms caused by vehicles
with similar designs or by very close license plate identifiers. In the first
network stream, shape similarities are identified by a Siamese CNN that uses a
pair of low-resolution vehicle patches recorded by two different cameras. In
the second stream, we use a CNN for OCR to extract textual information,
confidence scores, and string similarities from a pair of high-resolution
license plate patches. Then, features from both streams are merged by a
sequence of fully connected layers for decision. In our experiments, we
compared the two-stream network against several well-known CNN architectures
using single or multiple vehicle features. The architectures, trained models,
and dataset are publicly available at https://github.com/icarofua/vehicle-rear.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Fusion Using Deep Learning Applied to Driver&#x27;s Referencing of Outside-Vehicle Objects. (arXiv:2107.12167v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aftab_A/0/1/0/all/0/1">Abdul Rafey Aftab</a>, <a href="http://arxiv.org/find/cs/1/au:+Beeck_M/0/1/0/all/0/1">Michael von der Beeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrhirsch_S/0/1/0/all/0/1">Steven Rohrhirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Diotte_B/0/1/0/all/0/1">Benoit Diotte</a>, <a href="http://arxiv.org/find/cs/1/au:+Feld_M/0/1/0/all/0/1">Michael Feld</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12167">
                                    <div class="article-summary-box-inner">
                                        <span>There is a growing interest in more intelligent natural user interaction with
the car. Hand gestures and speech are already being applied for driver-car
interaction. Moreover, multimodal approaches are also showing promise in the
automotive industry. In this paper, we utilize deep learning for a multimodal
fusion network for referencing objects outside the vehicle. We use features
from gaze, head pose and finger pointing simultaneously to precisely predict
the referenced objects in different car poses. We demonstrate the practical
limitations of each modality when used for a natural form of referencing,
specifically inside the car. As evident from our results, we overcome the
modality specific limitations, to a large extent, by the addition of other
modalities. This work highlights the importance of multimodal sensing,
especially when moving towards natural user interaction. Furthermore, our user
based analysis shows noteworthy differences in recognition of user behavior
depending upon the vehicle pose.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CPF: Learning a Contact Potential Field to Model the Hand-object Interaction. (arXiv:2012.00924v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lixin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1">Xinyu Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kailin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wenqiang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiefeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Cewu Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00924">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling the hand-object (HO) interaction not only requires estimation of the
HO pose, but also pays attention to the contact due to their interaction.
Significant progress has been made in estimating hand and object separately
with deep learning methods, simultaneous HO pose estimation and contact
modeling has not yet been fully explored. In this paper, we present an explicit
contact representation namely Contact Potential Field (CPF), and a
learning-fitting hybrid framework namely MIHO to Modeling the Interaction of
Hand and Object. In CPF, we treat each contacting HO vertex pair as a
spring-mass system. Hence the whole system forms a potential field with minimal
elastic energy at the grasp position. Extensive experiments on the two commonly
used benchmarks have demonstrated that our method can achieve state-of-the-art
in several reconstruction metrics, and allow us to produce more physically
plausible HO pose even when the ground-truth exhibits severe interpenetration
or disjointedness. Our code is available at https://github.com/lixiny/CPF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization. (arXiv:2006.16241v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1">Dan Hendrycks</a>, <a href="http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1">Steven Basart</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_N/0/1/0/all/0/1">Norman Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1">Saurav Kadavath</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Frank Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dorundo_E/0/1/0/all/0/1">Evan Dorundo</a>, <a href="http://arxiv.org/find/cs/1/au:+Desai_R/0/1/0/all/0/1">Rahul Desai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1">Tyler Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Parajuli_S/0/1/0/all/0/1">Samyak Parajuli</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mike Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dawn Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1">Jacob Steinhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilmer_J/0/1/0/all/0/1">Justin Gilmer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16241">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce four new real-world distribution shift datasets consisting of
changes in image style, image blurriness, geographic location, camera
operation, and more. With our new datasets, we take stock of previously
proposed methods for improving out-of-distribution robustness and put them to
the test. We find that using larger models and artificial data augmentations
can improve robustness on real-world distribution shifts, contrary to claims in
prior work. We find improvements in artificial robustness benchmarks can
transfer to real-world distribution shifts, contrary to claims in prior work.
Motivated by our observation that data augmentations can help with real-world
distribution shifts, we also introduce a new data augmentation method which
advances the state-of-the-art and outperforms models pretrained with 1000 times
more labeled data. Overall we find that some methods consistently help with
distribution shifts in texture and local image statistics, but these methods do
not help with some other distribution shifts like geographic changes. Our
results show that future research must study multiple distribution shifts
simultaneously, as we demonstrate that no evaluated method consistently
improves robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PlenoptiCam v1.0: A light-field imaging framework. (arXiv:2010.11687v5 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hahne_C/0/1/0/all/0/1">Christopher Hahne</a>, <a href="http://arxiv.org/find/eess/1/au:+Aggoun_A/0/1/0/all/0/1">Amar Aggoun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11687">
                                    <div class="article-summary-box-inner">
                                        <span>Light-field cameras play a vital role for rich 3-D information retrieval in
narrow range depth sensing applications. The key obstacle in composing
light-fields from exposures taken by a plenoptic camera is to computationally
calibrate, align and rearrange four-dimensional image data. Several attempts
have been proposed to enhance the overall image quality by tailoring pipelines
dedicated to particular plenoptic cameras and improving the consistency across
viewpoints at the expense of high computational loads. The framework presented
herein advances prior outcomes thanks to its novel micro image scale-space
analysis for generic camera calibration independent of the lens specifications
and its parallax-invariant, cost-effective viewpoint color equalization from
optimal transport theory. Artifacts from the sensor and micro lens grid are
compensated in an innovative way to enable superior quality in sub-aperture
image extraction, computational refocusing and Scheimpflug rendering with
sub-sampling capabilities. Benchmark comparisons using established image
metrics suggest that our proposed pipeline outperforms state-of-the-art tool
chains in the majority of cases. Results from a Wasserstein distance further
show that our color transfer outdoes the existing transport methods. Our
algorithms are released under an open-source license, offer cross-platform
compatibility with few dependencies and different user interfaces. This makes
the reproduction of results and experimentation with plenoptic camera
technology convenient for peer researchers, developers, photographers, data
scientists and others working in this field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ARM: A Confidence-Based Adversarial Reweighting Module for Coarse Semantic Segmentation. (arXiv:2009.05205v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingchao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Ye Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1">Zehua Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qingjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.05205">
                                    <div class="article-summary-box-inner">
                                        <span>Coarsely-labeled semantic segmentation annotations are easy to obtain, but
therefore bear the risk of losing edge details and introducing background
pixels. Impeded by the inherent noise, existing coarse annotations are only
taken as a bonus for model pre-training. In this paper, we try to exploit their
potentials with a confidence-based reweighting strategy. To expand, loss-based
reweighting strategies usually take the high loss value to identify two
completely different types of pixels, namely, valuable pixels in noise-free
annotations and mislabeled pixels in noisy annotations. This makes it
impossible to perform two tasks of mining valuable pixels and suppressing
mislabeled pixels at the same time. However, with the help of the prediction
confidence, we successfully solve this dilemma and simultaneously perform two
subtasks with a single reweighting strategy. Furthermore, we generalize this
strategy into an Adversarial Reweighting Module (ARM) and prove its convergence
strictly. Experiments on standard datasets shows our ARM can bring consistent
improvements for both coarse annotations and fine annotations. Specifically,
built on top of DeepLabv3+, ARM improves the mIoU on the coarsely-labeled
Cityscapes by a considerable margin and increases the mIoU on the ADE20K
dataset to 47.50.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Data Set and a Convolutional Model for Iconography Classification in Paintings. (arXiv:2010.11697v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Milani_F/0/1/0/all/0/1">Federico Milani</a>, <a href="http://arxiv.org/find/cs/1/au:+Fraternali_P/0/1/0/all/0/1">Piero Fraternali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11697">
                                    <div class="article-summary-box-inner">
                                        <span>Iconography in art is the discipline that studies the visual content of
artworks to determine their motifs and themes andto characterize the way these
are represented. It is a subject of active research for a variety of purposes,
including the interpretation of meaning, the investigation of the origin and
diffusion in time and space of representations, and the study of influences
across artists and art works. With the proliferation of digital archives of art
images, the possibility arises of applying Computer Vision techniques to the
analysis of art images at an unprecedented scale, which may support iconography
research and education. In this paper we introduce a novel paintings data set
for iconography classification and present the quantitativeand qualitative
results of applying a Convolutional Neural Network (CNN) classifier to the
recognition of the iconography of artworks. The proposed classifier achieves
good performances (71.17% Precision, 70.89% Recall, 70.25% F1-Score and 72.73%
Average Precision) in the task of identifying saints in Christian religious
paintings, a task made difficult by the presence of classes with very similar
visual features. Qualitative analysis of the results shows that the CNN focuses
on the traditional iconic motifs that characterize the representation of each
saint and exploits such hints to attain correct identification. The ultimate
goal of our work is to enable the automatic extraction, decomposition, and
comparison of iconography elements to support iconographic studies and
automatic art work annotation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Channel-wise Topology Refinement Graph Convolution for Skeleton-Based Action Recognition. (arXiv:2107.12213v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziqi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_C/0/1/0/all/0/1">Chunfeng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Ying Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weiming Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12213">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolutional networks (GCNs) have been widely used and achieved
remarkable results in skeleton-based action recognition. In GCNs, graph
topology dominates feature aggregation and therefore is the key to extracting
representative features. In this work, we propose a novel Channel-wise Topology
Refinement Graph Convolution (CTR-GC) to dynamically learn different topologies
and effectively aggregate joint features in different channels for
skeleton-based action recognition. The proposed CTR-GC models channel-wise
topologies through learning a shared topology as a generic prior for all
channels and refining it with channel-specific correlations for each channel.
Our refinement method introduces few extra parameters and significantly reduces
the difficulty of modeling channel-wise topologies. Furthermore, via
reformulating graph convolutions into a unified form, we find that CTR-GC
relaxes strict constraints of graph convolutions, leading to stronger
representation capability. Combining CTR-GC with temporal modeling modules, we
develop a powerful graph convolutional network named CTR-GCN which notably
outperforms state-of-the-art methods on the NTU RGB+D, NTU RGB+D 120, and
NW-UCLA datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What does LIME really see in images?. (arXiv:2102.06307v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garreau_D/0/1/0/all/0/1">Damien Garreau</a>, <a href="http://arxiv.org/find/cs/1/au:+Mardaoui_D/0/1/0/all/0/1">Dina Mardaoui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06307">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of modern algorithms on certain computer vision tasks such as
object recognition is now close to that of humans. This success was achieved at
the price of complicated architectures depending on millions of parameters and
it has become quite challenging to understand how particular predictions are
made. Interpretability methods propose to give us this understanding. In this
paper, we study LIME, perhaps one of the most popular. On the theoretical side,
we show that when the number of generated examples is large, LIME explanations
are concentrated around a limit explanation for which we give an explicit
expression. We further this study for elementary shape detectors and linear
models. As a consequence of this analysis, we uncover a connection between LIME
and integrated gradients, another explanation method. More precisely, the LIME
explanations are similar to the sum of integrated gradients over the
superpixels used in the preprocessing step of LIME.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Thought Flow Nets: From Single Predictions to Trains of Model Thought. (arXiv:2107.12220v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schuff_H/0/1/0/all/0/1">Hendrik Schuff</a>, <a href="http://arxiv.org/find/cs/1/au:+Adel_H/0/1/0/all/0/1">Heike Adel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1">Ngoc Thang Vu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12220">
                                    <div class="article-summary-box-inner">
                                        <span>When humans solve complex problems, they rarely come up with a decision
right-away. Instead, they start with an intuitive decision, reflect upon it,
spot mistakes, resolve contradictions and jump between different hypotheses.
Thus, they create a sequence of ideas and follow a train of thought that
ultimately reaches a conclusive decision. Contrary to this, today&#x27;s neural
classification models are mostly trained to map an input to one single and
fixed output. In this paper, we investigate how we can give models the
opportunity of a second, third and $k$-th thought. We take inspiration from
Hegel&#x27;s dialectics and propose a method that turns an existing classifier&#x27;s
class prediction (such as the image class forest) into a sequence of
predictions (such as forest $\rightarrow$ tree $\rightarrow$ mushroom).
Concretely, we propose a correction module that is trained to estimate the
model&#x27;s correctness as well as an iterative prediction update based on the
prediction&#x27;s gradient. Our approach results in a dynamic system over class
probability distributions $\unicode{x2014}$ the thought flow. We evaluate our
method on diverse datasets and tasks from computer vision and natural language
processing. We observe surprisingly complex but intuitive behavior and
demonstrate that our method (i) can correct misclassifications, (ii)
strengthens model performance, (iii) is robust to high levels of adversarial
attacks, (iv) can increase accuracy up to 4% in a label-distribution-shift
setting and (iv) provides a tool for model interpretability that uncovers model
knowledge which otherwise remains invisible in a single distribution
prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">REVISE: A Tool for Measuring and Mitigating Bias in Visual Datasets. (arXiv:2004.07999v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Angelina Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Alexander Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ryan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleiman_A/0/1/0/all/0/1">Anat Kleiman</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_L/0/1/0/all/0/1">Leslie Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dora Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shirai_I/0/1/0/all/0/1">Iroha Shirai</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_A/0/1/0/all/0/1">Arvind Narayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Russakovsky_O/0/1/0/all/0/1">Olga Russakovsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.07999">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models are known to perpetuate and even amplify the biases
present in the data. However, these data biases frequently do not become
apparent until after the models are deployed. Our work tackles this issue and
enables the preemptive analysis of large-scale datasets. REVISE (REvealing
VIsual biaSEs) is a tool that assists in the investigation of a visual dataset,
surfacing potential biases along three dimensions: (1) object-based, (2)
person-based, and (3) geography-based. Object-based biases relate to the size,
context, or diversity of the depicted objects. Person-based metrics focus on
analyzing the portrayal of people within the dataset. Geography-based analyses
consider the representation of different geographic locations. These three
dimensions are deeply intertwined in how they interact to bias a dataset, and
REVISE sheds light on this; the responsibility then lies with the user to
consider the cultural and historical context, and to determine which of the
revealed biases may be problematic. The tool further assists the user by
suggesting actionable steps that may be taken to mitigate the revealed biases.
Overall, the key aim of our work is to tackle the machine learning bias problem
early in the pipeline. REVISE is available at
https://github.com/princetonvisualai/revise-tool</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dilated Residual Hierarchically Fashioned Segmentation Framework for Extracting Gleason Tissues and Grading Prostate Cancer from Whole Slide Images. (arXiv:2011.00527v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassan_T/0/1/0/all/0/1">Taimur Hassan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassan_B/0/1/0/all/0/1">Bilal Hassan</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Baz_A/0/1/0/all/0/1">Ayman El-Baz</a>, <a href="http://arxiv.org/find/cs/1/au:+Werghi_N/0/1/0/all/0/1">Naoufel Werghi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00527">
                                    <div class="article-summary-box-inner">
                                        <span>Prostate cancer (PCa) is the second deadliest form of cancer in males, and it
can be clinically graded by examining the structural representations of Gleason
tissues. This paper proposes \RV{a new method} for segmenting the Gleason
tissues \RV{(patch-wise) in order to grade PCa from the whole slide images
(WSI).} Also, the proposed approach encompasses two main contributions: 1) A
synergy of hybrid dilation factors and hierarchical decomposition of latent
space representation for effective Gleason tissues extraction, and 2) A
three-tiered loss function which can penalize different semantic segmentation
models for accurately extracting the highly correlated patterns. In addition to
this, the proposed framework has been extensively evaluated on a large-scale
PCa dataset containing 10,516 whole slide scans (with around 71.7M patches),
where it outperforms state-of-the-art schemes by 3.22% (in terms of mean
intersection-over-union) for extracting the Gleason tissues and 6.91% (in terms
of F1 score) for grading the progression of PCa.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">StainNet: a fast and robust stain normalization network. (arXiv:2012.12535v6 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kang_H/0/1/0/all/0/1">Hongtao Kang</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_D/0/1/0/all/0/1">Die Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Feng_W/0/1/0/all/0/1">Weihua Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_J/0/1/0/all/0/1">Junbo Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Zeng_S/0/1/0/all/0/1">Shaoqun Zeng</a>, <a href="http://arxiv.org/find/eess/1/au:+Quan_T/0/1/0/all/0/1">Tingwei Quan</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xiuli Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12535">
                                    <div class="article-summary-box-inner">
                                        <span>Stain normalization often refers to transferring the color distribution of
the source image to that of the target image and has been widely used in
biomedical image analysis. The conventional stain normalization is regarded as
constructing a pixel-by-pixel color mapping model, which only depends on one
reference image, and can not accurately achieve the style transformation
between image datasets. In principle, this style transformation can be well
solved by the deep learning-based methods due to its complicated network
structure, whereas, its complicated structure results in the low computational
efficiency and artifacts in the style transformation, which has restricted the
practical application. Here, we use distillation learning to reduce the
complexity of deep learning methods and a fast and robust network called
StainNet to learn the color mapping between the source image and target image.
StainNet can learn the color mapping relationship from a whole dataset and
adjust the color value in a pixel-to-pixel manner. The pixel-to-pixel manner
restricts the network size and avoids artifacts in the style transformation.
The results on the cytopathology and histopathology datasets show that StainNet
can achieve comparable performance to the deep learning-based methods.
Computation results demonstrate StainNet is more than 40 times faster than
StainGAN and can normalize a 100,000x100,000 whole slide image in 40 seconds.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Large Scale Inlier Voting for Geometric Vision Problems. (arXiv:2107.11810v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aiger_D/0/1/0/all/0/1">Dror Aiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Lynen_S/0/1/0/all/0/1">Simon Lynen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosang_J/0/1/0/all/0/1">Jan Hosang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeisl_B/0/1/0/all/0/1">Bernhard Zeisl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11810">
                                    <div class="article-summary-box-inner">
                                        <span>Outlier rejection and equivalently inlier set optimization is a key
ingredient in numerous applications in computer vision such as filtering
point-matches in camera pose estimation or plane and normal estimation in point
clouds. Several approaches exist, yet at large scale we face a combinatorial
explosion of possible solutions and state-of-the-art methods like RANSAC, Hough
transform or Branch\&amp;Bound require a minimum inlier ratio or prior knowledge to
remain practical. In fact, for problems such as camera posing in very large
scenes these approaches become useless as they have exponential runtime growth
if these conditions aren&#x27;t met. To approach the problem we present a efficient
and general algorithm for outlier rejection based on &quot;intersecting&quot;
$k$-dimensional surfaces in $R^d$. We provide a recipe for casting a variety of
geometric problems as finding a point in $R^d$ which maximizes the number of
nearby surfaces (and thus inliers). The resulting algorithm has linear
worst-case complexity with a better runtime dependency in the approximation
factor than competing algorithms while not requiring domain specific bounds.
This is achieved by introducing a space decomposition scheme that bounds the
number of computations by successively rounding and grouping samples. Our
recipe (and open-source code) enables anybody to derive such fast approaches to
new problems across a wide range of domains. We demonstrate the versatility of
the approach on several camera posing problems with a high number of matches at
low inlier ratio achieving state-of-the-art results at significantly lower
processing times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Insect Pest Classification Using Multiple Convolutional Neural Network Based Models. (arXiv:2107.12189v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ung_H/0/1/0/all/0/1">Hieu T. Ung</a>, <a href="http://arxiv.org/find/cs/1/au:+Ung_H/0/1/0/all/0/1">Huy Q. Ung</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Binh T. Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12189">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate insect pest recognition is significant to protect the crop or take
the early treatment on the infected yield, and it helps reduce the loss for the
agriculture economy. Design an automatic pest recognition system is necessary
because manual recognition is slow, time-consuming, and expensive. The
Image-based pest classifier using the traditional computer vision method is not
efficient due to the complexity. Insect pest classification is a difficult task
because of various kinds, scales, shapes, complex backgrounds in the field, and
high appearance similarity among insect species. With the rapid development of
deep learning technology, the CNN-based method is the best way to develop a
fast and accurate insect pest classifier. We present different convolutional
neural network-based models in this work, including attention, feature pyramid,
and fine-grained models. We evaluate our methods on two public datasets: the
large-scale insect pest dataset, the IP102 benchmark dataset, and a smaller
dataset, namely D0 in terms of the macro-average precision (MPre), the
macro-average recall (MRec), the macro-average F1- score (MF1), the accuracy
(Acc), and the geometric mean (GM). The experimental results show that
combining these convolutional neural network-based models can better perform
than the state-of-the-art methods on these two datasets. For instance, the
highest accuracy we obtained on IP102 and D0 is $74.13\%$ and $99.78\%$,
respectively, bypassing the corresponding state-of-the-art accuracy: $67.1\%$
(IP102) and $98.8\%$ (D0). We also publish our codes for contributing to the
current research related to the insect pest classification problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image-Based Parking Space Occupancy Classification: Dataset and Baseline. (arXiv:2107.12207v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marek_M/0/1/0/all/0/1">Martin Marek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12207">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new dataset for image-based parking space occupancy
classification: ACPDS. Unlike in prior datasets, each image is taken from a
unique view, systematically annotated, and the parking lots in the train,
validation, and test sets are unique. We use this dataset to propose a simple
baseline model for parking space occupancy classification, which achieves 98%
accuracy on unseen parking lots, significantly outperforming existing models.
We share our dataset, code, and trained models under the MIT license.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Video Object Segmentation with Compressed Video. (arXiv:2107.12192v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kai Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1">Angela Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12192">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an efficient inference framework for semi-supervised video object
segmentation by exploiting the temporal redundancy of the video. Our method
performs inference on selected keyframes and makes predictions for other frames
via propagation based on motion vectors and residuals from the compressed video
bitstream. Specifically, we propose a new motion vector-based warping method
for propagating segmentation masks from keyframes to other frames in a
multi-reference manner. Additionally, we propose a residual-based refinement
module that can correct and add detail to the block-wise propagated
segmentation masks. Our approach is flexible and can be added on top of
existing video object segmentation algorithms. With STM with top-k filtering as
our base model, we achieved highly competitive results on DAVIS16 and
YouTube-VOS with substantial speedups of up to 4.9X with little loss in
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Early Diagnosis of Lung Cancer Using Computer Aided Detection via Lung Segmentation Approach. (arXiv:2107.12205v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bhandary_A/0/1/0/all/0/1">Abhir Bhandary</a>, <a href="http://arxiv.org/find/eess/1/au:+G_A/0/1/0/all/0/1">Ananth Prabhu G</a>, <a href="http://arxiv.org/find/eess/1/au:+Basthikodi_M/0/1/0/all/0/1">Mustafa Basthikodi</a>, <a href="http://arxiv.org/find/eess/1/au:+M_C/0/1/0/all/0/1">Chaitra K M</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12205">
                                    <div class="article-summary-box-inner">
                                        <span>Lung cancer begins in the lungs and leading to the reason of cancer demise
amid population in the creation. According to the American Cancer Society,
which estimates about 27% of the deaths because of cancer. In the early phase
of its evolution, lung cancer does not cause any symptoms usually. Many of the
patients have been diagnosed in a developed phase where symptoms become more
prominent, that results in poor curative treatment and high mortality rate.
Computer Aided Detection systems are used to achieve greater accuracies for the
lung cancer diagnosis. In this research exertion, we proposed a novel
methodology for lung Segmentation on the basis of Fuzzy C-Means Clustering,
Adaptive Thresholding, and Segmentation of Active Contour Model. The
experimental results are analysed and presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multiple-Instance Learning Approach for the Assessment of Gallbladder Vascularity from Laparoscopic Images. (arXiv:2107.12093v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Loukas_C/0/1/0/all/0/1">C. Loukas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gazis_A/0/1/0/all/0/1">A. Gazis</a>, <a href="http://arxiv.org/find/cs/1/au:+Schizas_D/0/1/0/all/0/1">D. Schizas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12093">
                                    <div class="article-summary-box-inner">
                                        <span>An important task at the onset of a laparoscopic cholecystectomy (LC)
operation is the inspection of gallbladder (GB) to evaluate the thickness of
its wall, presence of inflammation and extent of fat. Difficulty in
visualization of the GB wall vessels may be due to the previous factors,
potentially as a result of chronic inflammation or other diseases. In this
paper we propose a multiple-instance learning (MIL) technique for assessment of
the GB wall vascularity via computer-vision analysis of images from LC
operations. The bags correspond to a labeled (low vs. high) vascularity dataset
of 181 GB images, from 53 operations. The instances correspond to unlabeled
patches extracted from these images. Each patch is represented by a vector with
color, texture and statistical features. We compare various state-of-the-art
MIL and single-instance learning approaches, as well as a proposed MIL
technique based on variational Bayesian inference. The methods were compared
for two experimental tasks: image-based and video-based (i.e. patient-based)
classification. The proposed approach presents the best performance with
accuracy 92.1% and 90.3% for the first and second task, respectively. A
significant advantage of the proposed technique is that it does not require the
time-consuming task of manual labelling the instances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Unbiased Visual Emotion Recognition via Causal Intervention. (arXiv:2107.12096v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuedong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cham_T/0/1/0/all/0/1">Tat-Jen Cham</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12096">
                                    <div class="article-summary-box-inner">
                                        <span>Although much progress has been made in visual emotion recognition,
researchers have realized that modern deep networks tend to exploit dataset
characteristics to learn spurious statistical associations between the input
and the target. Such dataset characteristics are usually treated as dataset
bias, which damages the robustness and generalization performance of these
recognition systems. In this work, we scrutinize this problem from the
perspective of causal inference, where such dataset characteristic is termed as
a confounder which misleads the system to learn the spurious correlation. To
alleviate the negative effects brought by the dataset bias, we propose a novel
Interventional Emotion Recognition Network (IERN) to achieve the backdoor
adjustment, which is one fundamental deconfounding technique in causal
inference. A series of designed tests validate the effectiveness of IERN, and
experiments on three emotion benchmarks demonstrate that IERN outperforms other
state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Perceptually Validated Precise Local Editing for Facial Action Units with StyleGAN. (arXiv:2107.12143v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zindancioglu_A/0/1/0/all/0/1">Alara Zindanc&#x131;o&#x11f;lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sezgin_T/0/1/0/all/0/1">T. Metin Sezgin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12143">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to edit facial expressions has a wide range of applications in
computer graphics. The ideal facial expression editing algorithm needs to
satisfy two important criteria. First, it should allow precise and targeted
editing of individual facial actions. Second, it should generate high fidelity
outputs without artifacts. We build a solution based on StyleGAN, which has
been used extensively for semantic manipulation of faces. As we do so, we add
to our understanding of how various semantic attributes are encoded in
StyleGAN. In particular, we show that a naive strategy to perform editing in
the latent space results in undesired coupling between certain action units,
even if they are conceptually distinct. For example, although brow lowerer and
lip tightener are distinct action units, they appear correlated in the training
data. Hence, StyleGAN has difficulty in disentangling them. We allow
disentangled editing of such action units by computing detached regions of
influence for each action unit, and restrict editing to these regions. We
validate the effectiveness of our local editing method through perception
experiments conducted with 23 subjects. The results show that our method
provides higher control over local editing and produces images with superior
fidelity compared to the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AA3DNet: Attention Augmented Real Time 3D Object Detection. (arXiv:2107.12137v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12137">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects using
point cloud data. We present anchor design along with custom loss functions
used in this work. A combination of spatial and channel wise attention module
is used in this work. We use the Kitti 3D Birds Eye View dataset for
benchmarking and validating our results. Our method surpasses previous state of
the art in this domain both in terms of average precision and speed running at
&gt; 30 FPS. Finally, we present the ablation study to demonstrate that the
performance of our network is generalizable. This makes it a feasible option to
be deployed in real time applications like self driving cars.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D AGSE-VNet: An Automatic Brain Tumor MRI Data Segmentation Framework. (arXiv:2107.12046v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1">Xi Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jianming Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Weiji Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaomei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weiwei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_X/0/1/0/all/0/1">Xiaobo Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12046">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Glioma is the most common brain malignant tumor, with a high
morbidity rate and a mortality rate of more than three percent, which seriously
endangers human health. The main method of acquiring brain tumors in the clinic
is MRI. Segmentation of brain tumor regions from multi-modal MRI scan images is
helpful for treatment inspection, post-diagnosis monitoring, and effect
evaluation of patients. However, the common operation in clinical brain tumor
segmentation is still manual segmentation, lead to its time-consuming and large
performance difference between different operators, a consistent and accurate
automatic segmentation method is urgently needed. Methods: To meet the above
challenges, we propose an automatic brain tumor MRI data segmentation framework
which is called AGSE-VNet. In our study, the Squeeze and Excite (SE) module is
added to each encoder, the Attention Guide Filter (AG) module is added to each
decoder, using the channel relationship to automatically enhance the useful
information in the channel to suppress the useless information, and use the
attention mechanism to guide the edge information and remove the influence of
irrelevant information such as noise. Results: We used the BraTS2020 challenge
online verification tool to evaluate our approach. The focus of verification is
that the Dice scores of the whole tumor (WT), tumor core (TC) and enhanced
tumor (ET) are 0.68, 0.85 and 0.70, respectively. Conclusion: Although MRI
images have different intensities, AGSE-VNet is not affected by the size of the
tumor, and can more accurately extract the features of the three regions, it
has achieved impressive results and made outstanding contributions to the
clinical diagnosis and treatment of brain tumor patients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HANet: Hierarchical Alignment Networks for Video-Text Retrieval. (arXiv:2107.12059v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_P/0/1/0/all/0/1">Peng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangteng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_M/0/1/0/all/0/1">Mingqian Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1">Yiliang Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12059">
                                    <div class="article-summary-box-inner">
                                        <span>Video-text retrieval is an important yet challenging task in vision-language
understanding, which aims to learn a joint embedding space where related video
and text instances are close to each other. Most current works simply measure
the video-text similarity based on video-level and text-level embeddings.
However, the neglect of more fine-grained or local information causes the
problem of insufficient representation. Some works exploit the local details by
disentangling sentences, but overlook the corresponding videos, causing the
asymmetry of video-text representation. To address the above limitations, we
propose a Hierarchical Alignment Network (HANet) to align different level
representations for video-text matching. Specifically, we first decompose video
and text into three semantic levels, namely event (video and text), action
(motion and verb), and entity (appearance and noun). Based on these, we
naturally construct hierarchical representations in the individual-local-global
manner, where the individual level focuses on the alignment between frame and
word, local level focuses on the alignment between video clip and textual
context, and global level focuses on the alignment between the whole video and
text. Different level alignments capture fine-to-coarse correlations between
video and text, as well as take the advantage of the complementary information
among three semantic levels. Besides, our HANet is also richly interpretable by
explicitly learning key semantic concepts. Extensive experiments on two public
datasets, namely MSR-VTT and VATEX, show the proposed HANet outperforms other
state-of-the-art methods, which demonstrates the effectiveness of hierarchical
representation and alignment. Our code is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Remains of Visual Semantic Embeddings. (arXiv:2107.11991v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yue Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1">Jonathon Hare</a>, <a href="http://arxiv.org/find/cs/1/au:+Prugel_Bennett_A/0/1/0/all/0/1">Adam Pr&#xfc;gel-Bennett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11991">
                                    <div class="article-summary-box-inner">
                                        <span>Zero shot learning (ZSL) has seen a surge in interest over the decade for its
tight links with the mechanism making young children recognize novel objects.
Although different paradigms of visual semantic embedding models are designed
to align visual features and distributed word representations, it is unclear to
what extent current ZSL models encode semantic information from distributed
word representations. In this work, we introduce the split of tiered-ImageNet
to the ZSL task, in order to avoid the structural flaws in the standard
ImageNet benchmark. We build a unified framework for ZSL with contrastive
learning as pre-training, which guarantees no semantic information leakage and
encourages linearly separable visual features. Our work makes it fair for
evaluating visual semantic embedding models on a ZSL setting in which semantic
inference is decisive. With this framework, we show that current ZSL models
struggle with encoding semantic relationships from word analogy and word
hierarchy. Our analyses provide motivation for exploring the role of context
language representations in ZSL tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Generative Video Compression. (arXiv:2107.12038v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mentzer_F/0/1/0/all/0/1">Fabian Mentzer</a>, <a href="http://arxiv.org/find/eess/1/au:+Agustsson_E/0/1/0/all/0/1">Eirikur Agustsson</a>, <a href="http://arxiv.org/find/eess/1/au:+Balle_J/0/1/0/all/0/1">Johannes Ball&#xe9;</a>, <a href="http://arxiv.org/find/eess/1/au:+Minnen_D/0/1/0/all/0/1">David Minnen</a>, <a href="http://arxiv.org/find/eess/1/au:+Johnston_N/0/1/0/all/0/1">Nick Johnston</a>, <a href="http://arxiv.org/find/eess/1/au:+Toderici_G/0/1/0/all/0/1">George Toderici</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12038">
                                    <div class="article-summary-box-inner">
                                        <span>We present a neural video compression method based on generative adversarial
networks (GANs) that outperforms previous neural video compression methods and
is comparable to HEVC in a user study. We propose a technique to mitigate
temporal error accumulation caused by recursive frame compression that uses
randomized shifting and un-shifting, motivated by a spectral analysis. We
present in detail the network design choices, their relative importance, and
elaborate on the challenges of evaluating video compression methods in user
studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Log-Polar Space Convolution for Convolutional Neural Networks. (arXiv:2107.11943v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_B/0/1/0/all/0/1">Bing Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11943">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks use regular quadrilateral convolution kernels
to extract features. Since the number of parameters increases quadratically
with the size of the convolution kernel, many popular models use small
convolution kernels, resulting in small local receptive fields in lower layers.
This paper proposes a novel log-polar space convolution (LPSC) method, where
the convolution kernel is elliptical and adaptively divides its local receptive
field into different regions according to the relative directions and
logarithmic distances. The local receptive field grows exponentially with the
number of distance levels. Therefore, the proposed LPSC not only naturally
encodes local spatial structures, but also greatly increases the single-layer
receptive field while maintaining the number of parameters. We show that LPSC
can be implemented with conventional convolution via log-polar space pooling
and can be applied in any network architecture to replace conventional
convolutions. Experiments on different tasks and datasets demonstrate the
effectiveness of the proposed LPSC. Code is available at
https://github.com/BingSu12/Log-Polar-Space-Convolution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-FDMixup: Cross-Domain Few-Shot Learning Guided by Labeled Target Data. (arXiv:2107.11978v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yuqian Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu-Gang Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11978">
                                    <div class="article-summary-box-inner">
                                        <span>A recent study finds that existing few-shot learning methods, trained on the
source domain, fail to generalize to the novel target domain when a domain gap
is observed. This motivates the task of Cross-Domain Few-Shot Learning
(CD-FSL). In this paper, we realize that the labeled target data in CD-FSL has
not been leveraged in any way to help the learning process. Thus, we advocate
utilizing few labeled target data to guide the model learning. Technically, a
novel meta-FDMixup network is proposed. We tackle this problem mainly from two
aspects. Firstly, to utilize the source and the newly introduced target data of
two different class sets, a mixup module is re-proposed and integrated into the
meta-learning mechanism. Secondly, a novel disentangle module together with a
domain classifier is proposed to extract the disentangled domain-irrelevant and
domain-specific features. These two modules together enable our model to narrow
the domain gap thus generalizing well to the target datasets. Additionally, a
detailed feasibility and pilot study is conducted to reflect the intuitive
understanding of CD-FSL under our new setting. Experimental results show the
effectiveness of our new setting and the proposed method. Codes and models are
available at https://github.com/lovelyqian/Meta-FDMixup.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards the Unseen: Iterative Text Recognition by Distilling from Errors. (arXiv:2107.12081v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhunia_A/0/1/0/all/0/1">Ayan Kumar Bhunia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_P/0/1/0/all/0/1">Pinaki Nath Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Sain_A/0/1/0/all/0/1">Aneeshan Sain</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Zhe Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12081">
                                    <div class="article-summary-box-inner">
                                        <span>Visual text recognition is undoubtedly one of the most extensively researched
topics in computer vision. Great progress have been made to date, with the
latest models starting to focus on the more practical &quot;in-the-wild&quot; setting.
However, a salient problem still hinders practical deployment -- prior arts
mostly struggle with recognising unseen (or rarely seen) character sequences.
In this paper, we put forward a novel framework to specifically tackle this
&quot;unseen&quot; problem. Our framework is iterative in nature, in that it utilises
predicted knowledge of character sequences from a previous iteration, to
augment the main network in improving the next prediction. Key to our success
is a unique cross-modal variational autoencoder to act as a feedback module,
which is trained with the presence of textual error distribution data. This
module importantly translate a discrete predicted character space, to a
continuous affine transformation parameter space used to condition the visual
feature map at next iteration. Experiments on common datasets have shown
competitive performance over state-of-the-arts under the conventional setting.
Most importantly, under the new disjoint setup where train-test labels are
mutually exclusive, ours offers the best performance thus showcasing the
capability of generalising onto unseen words.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lung Cancer Risk Estimation with Incomplete Data: A Joint Missing Imputation Perspective. (arXiv:2107.11882v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gao_R/0/1/0/all/0/1">Riqiang Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_Y/0/1/0/all/0/1">Yucheng Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_K/0/1/0/all/0/1">Kaiwen Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1">Ho Hin Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Deppen_S/0/1/0/all/0/1">Steve Deppen</a>, <a href="http://arxiv.org/find/eess/1/au:+Sandler_K/0/1/0/all/0/1">Kim Sandler</a>, <a href="http://arxiv.org/find/eess/1/au:+Massion_P/0/1/0/all/0/1">Pierre Massion</a>, <a href="http://arxiv.org/find/eess/1/au:+Lasko_T/0/1/0/all/0/1">Thomas A. Lasko</a>, <a href="http://arxiv.org/find/eess/1/au:+Huo_Y/0/1/0/all/0/1">Yuankai Huo</a>, <a href="http://arxiv.org/find/eess/1/au:+Landman_B/0/1/0/all/0/1">Bennett A. Landman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11882">
                                    <div class="article-summary-box-inner">
                                        <span>Data from multi-modality provide complementary information in clinical
prediction, but missing data in clinical cohorts limits the number of subjects
in multi-modal learning context. Multi-modal missing imputation is challenging
with existing methods when 1) the missing data span across heterogeneous
modalities (e.g., image vs. non-image); or 2) one modality is largely missing.
In this paper, we address imputation of missing data by modeling the joint
distribution of multi-modal data. Motivated by partial bidirectional generative
adversarial net (PBiGAN), we propose a new Conditional PBiGAN (C-PBiGAN) method
that imputes one modality combining the conditional knowledge from another
modality. Specifically, C-PBiGAN introduces a conditional latent space in a
missing imputation framework that jointly encodes the available multi-modal
data, along with a class regularization loss on imputed data to recover
discriminative information. To our knowledge, it is the first generative
adversarial model that addresses multi-modal missing imputation by modeling the
joint distribution of image and non-image data. We validate our model with both
the national lung screening trial (NLST) dataset and an external clinical
validation cohort. The proposed C-PBiGAN achieves significant improvements in
lung cancer risk estimation compared with representative imputation methods
(e.g., AUC values increase in both NLST (+2.9\%) and in-house dataset (+4.3\%)
compared with PBiGAN, p$&lt;$0.05).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting Entity-aware Image Captioning with Multi-modal Knowledge Graph. (arXiv:2107.11970v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wentian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Heda Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xinxiao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11970">
                                    <div class="article-summary-box-inner">
                                        <span>Entity-aware image captioning aims to describe named entities and events
related to the image by utilizing the background knowledge in the associated
article. This task remains challenging as it is difficult to learn the
association between named entities and visual cues due to the long-tail
distribution of named entities. Furthermore, the complexity of the article
brings difficulty in extracting fine-grained relationships between entities to
generate informative event descriptions about the image. To tackle these
challenges, we propose a novel approach that constructs a multi-modal knowledge
graph to associate the visual objects with named entities and capture the
relationship between entities simultaneously with the help of external
knowledge collected from the web. Specifically, we build a text sub-graph by
extracting named entities and their relationships from the article, and build
an image sub-graph by detecting the objects in the image. To connect these two
sub-graphs, we propose a cross-modal entity matching module trained using a
knowledge base that contains Wikipedia entries and the corresponding images.
Finally, the multi-modal knowledge graph is integrated into the captioning
model via a graph attention mechanism. Extensive experiments on both GoodNews
and NYTimes800k datasets demonstrate the effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Synthetic Corruptions to Measure Robustness to Natural Distribution Shifts. (arXiv:2107.12052v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Laugros_A/0/1/0/all/0/1">Alfred Laugros</a>, <a href="http://arxiv.org/find/cs/1/au:+Caplier_A/0/1/0/all/0/1">Alice Caplier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ospici_M/0/1/0/all/0/1">Matthieu Ospici</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12052">
                                    <div class="article-summary-box-inner">
                                        <span>Synthetic corruptions gathered into a benchmark are frequently used to
measure neural network robustness to distribution shifts. However, robustness
to synthetic corruption benchmarks is not always predictive of robustness to
distribution shifts encountered in real-world applications. In this paper, we
propose a methodology to build synthetic corruption benchmarks that make
robustness estimations more correlated with robustness to real-world
distribution shifts. Using the overlapping criterion, we split synthetic
corruptions into categories that help to better understand neural network
robustness. Based on these categories, we identify three parameters that are
relevant to take into account when constructing a corruption benchmark: number
of represented categories, balance among categories and size of benchmarks.
Applying the proposed methodology, we build a new benchmark called
ImageNet-Syn2Nat to predict image classifier robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CP-loss: Connectivity-preserving Loss for Road Curb Detection in Autonomous Driving with Aerial Images. (arXiv:2107.11920v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhenhua Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yuxiang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lujia Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Ming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11920">
                                    <div class="article-summary-box-inner">
                                        <span>Road curb detection is important for autonomous driving. It can be used to
determine road boundaries to constrain vehicles on roads, so that potential
accidents could be avoided. Most of the current methods detect road curbs
online using vehicle-mounted sensors, such as cameras or 3-D Lidars. However,
these methods usually suffer from severe occlusion issues. Especially in
highly-dynamic traffic environments, most of the field of view is occupied by
dynamic objects. To alleviate this issue, we detect road curbs offline using
high-resolution aerial images in this paper. Moreover, the detected road curbs
can be used to create high-definition (HD) maps for autonomous vehicles.
Specifically, we first predict the pixel-wise segmentation map of road curbs,
and then conduct a series of post-processing steps to extract the graph
structure of road curbs. To tackle the disconnectivity issue in the
segmentation maps, we propose an innovative connectivity-preserving loss
(CP-loss) to improve the segmentation performance. The experimental results on
a public dataset demonstrate the effectiveness of our proposed loss function.
This paper is accompanied with a demonstration video and a supplementary
document, which are available at
\texttt{\url{https://sites.google.com/view/cp-loss}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transductive Maximum Margin Classifier for Few-Shot Learning. (arXiv:2107.11975v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1">Fei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunlei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jie Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yanwen Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11975">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning aims to train a classifier that can generalize well when
just a small number of labeled samples per class are given. We introduce
Transductive Maximum Margin Classifier (TMMC) for few-shot learning. The basic
idea of the classical maximum margin classifier is to solve an optimal
prediction function that the corresponding separating hyperplane can correctly
divide the training data and the resulting classifier has the largest geometric
margin. In few-shot learning scenarios, the training samples are scarce, not
enough to find a separating hyperplane with good generalization ability on
unseen data. TMMC is constructed using a mixture of the labeled support set and
the unlabeled query set in a given task. The unlabeled samples in the query set
can adjust the separating hyperplane so that the prediction function is optimal
on both the labeled and unlabeled samples. Furthermore, we leverage an
efficient and effective quasi-Newton algorithm, the L-BFGS method to optimize
TMMC. Experimental results on three standard few-shot learning benchmarks
including miniImagenet, tieredImagenet and CUB suggest that our TMMC achieves
state-of-the-art accuracies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Hyper-GAN Model for Unpaired Multi-contrast MR Image Translation. (arXiv:2107.11945v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yang_H/0/1/0/all/0/1">Heran Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Jian Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_L/0/1/0/all/0/1">Liwei Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_Z/0/1/0/all/0/1">Zongben Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11945">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-contrast image translation is an important task for completing missing
contrasts in clinical diagnosis. However, most existing methods learn separate
translator for each pair of contrasts, which is inefficient due to many
possible contrast pairs in real scenarios. In this work, we propose a unified
Hyper-GAN model for effectively and efficiently translating between different
contrast pairs. Hyper-GAN consists of a pair of hyper-encoder and hyper-decoder
to first map from the source contrast to a common feature space, and then
further map to the target contrast image. To facilitate the translation between
different contrast pairs, contrast-modulators are designed to tune the
hyper-encoder and hyper-decoder adaptive to different contrasts. We also design
a common space loss to enforce that multi-contrast images of a subject share a
common feature space, implicitly modeling the shared underlying anatomical
structures. Experiments on two datasets of IXI and BraTS 2019 show that our
Hyper-GAN achieves state-of-the-art results in both accuracy and efficiency,
e.g., improving more than 1.47 and 1.09 dB in PSNR on two datasets with less
than half the amount of parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benign Adversarial Attack: Tricking Algorithm for Goodness. (arXiv:2107.11986v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xian Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiaming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhiyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1">Jitao Sang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11986">
                                    <div class="article-summary-box-inner">
                                        <span>In spite of the successful application in many fields, machine learning
algorithms today suffer from notorious problems like vulnerability to
adversarial examples. Beyond falling into the cat-and-mouse game between
adversarial attack and defense, this paper provides alternative perspective to
consider adversarial example and explore whether we can exploit it in benign
applications. We first propose a novel taxonomy of visual information along
task-relevance and semantic-orientation. The emergence of adversarial example
is attributed to algorithm&#x27;s utilization of task-relevant non-semantic
information. While largely ignored in classical machine learning mechanisms,
task-relevant non-semantic information enjoys three interesting characteristics
as (1) exclusive to algorithm, (2) reflecting common weakness, and (3)
utilizable as features. Inspired by this, we present brave new idea called
benign adversarial attack to exploit adversarial examples for goodness in three
directions: (1) adversarial Turing test, (2) rejecting malicious algorithm, and
(3) adversarial data augmentation. Each direction is positioned with motivation
elaboration, justification analysis and prototype applications to showcase its
potential.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Adversarially Blur Visual Object Tracking. (arXiv:2107.12085v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qing Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Ziyi Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Juefei_Xu_F/0/1/0/all/0/1">Felix Juefei-Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1">Lei Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xiaofei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jianjun Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12085">
                                    <div class="article-summary-box-inner">
                                        <span>Motion blur caused by the moving of the object or camera during the exposure
can be a key challenge for visual object tracking, affecting tracking accuracy
significantly. In this work, we explore the robustness of visual object
trackers against motion blur from a new angle, i.e., adversarial blur attack
(ABA). Our main objective is to online transfer input frames to their natural
motion-blurred counterparts while misleading the state-of-the-art trackers
during the tracking process. To this end, we first design the motion blur
synthesizing method for visual tracking based on the generation principle of
motion blur, considering the motion information and the light accumulation
process. With this synthetic method, we propose \textit{optimization-based ABA
(OP-ABA)} by iteratively optimizing an adversarial objective function against
the tracking w.r.t. the motion and light accumulation parameters. The OP-ABA is
able to produce natural adversarial examples but the iteration can cause heavy
time cost, making it unsuitable for attacking real-time trackers. To alleviate
this issue, we further propose \textit{one-step ABA (OS-ABA)} where we design
and train a joint adversarial motion and accumulation predictive network
(JAMANet) with the guidance of OP-ABA, which is able to efficiently estimate
the adversarial motion and accumulation parameters in a one-step way. The
experiments on four popular datasets (\eg, OTB100, VOT2018, UAV123, and LaSOT)
demonstrate that our methods are able to cause significant accuracy drops on
four state-of-the-art trackers with high transferability. Please find the
source code at https://github.com/tsingqguo/ABA</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Visual Semantic Reasoning: Multi-Stage Decoder for Text Recognition. (arXiv:2107.12090v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhunia_A/0/1/0/all/0/1">Ayan Kumar Bhunia</a>, <a href="http://arxiv.org/find/cs/1/au:+Sain_A/0/1/0/all/0/1">Aneeshan Sain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Amandeep Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghose_S/0/1/0/all/0/1">Shuvozit Ghose</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_P/0/1/0/all/0/1">Pinaki Nath Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Zhe Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12090">
                                    <div class="article-summary-box-inner">
                                        <span>Although text recognition has significantly evolved over the years,
state-of-the-art (SOTA) models still struggle in the wild scenarios due to
complex backgrounds, varying fonts, uncontrolled illuminations, distortions and
other artefacts. This is because such models solely depend on visual
information for text recognition, thus lacking semantic reasoning capabilities.
In this paper, we argue that semantic information offers a complementary role
in addition to visual only. More specifically, we additionally utilize semantic
information by proposing a multi-stage multi-scale attentional decoder that
performs joint visual-semantic reasoning. Our novelty lies in the intuition
that for text recognition, the prediction should be refined in a stage-wise
manner. Therefore our key contribution is in designing a stage-wise unrolling
attentional decoder where non-differentiability, invoked by discretely
predicted character labels, needs to be bypassed for end-to-end training. While
the first stage predicts using visual features, subsequent stages refine on top
of it using joint visual-semantic information. Additionally, we introduce
multi-scale 2D attention along with dense and residual connections between
different stages to deal with varying scales of character sizes, for better
performance and faster convergence during training. Experimental results show
our approach to outperform existing SOTA methods by a considerable margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Augmentation Pathways Network for Visual Recognition. (arXiv:2107.11990v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yalong Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mohan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxiang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1">Tao Mei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11990">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation is practically helpful for visual recognition, especially
at the time of data scarcity. However, such success is only limited to quite a
few light augmentations (e.g., random crop, flip). Heavy augmentations (e.g.,
gray, grid shuffle) are either unstable or show adverse effects during
training, owing to the big gap between the original and augmented images. This
paper introduces a novel network design, noted as Augmentation Pathways (AP),
to systematically stabilize training on a much wider range of augmentation
policies. Notably, AP tames heavy data augmentations and stably boosts
performance without a careful selection among augmentation policies. Unlike
traditional single pathway, augmented images are processed in different neural
paths. The main pathway handles light augmentations, while other pathways focus
on heavy augmentations. By interacting with multiple paths in a dependent
manner, the backbone network robustly learns from shared visual patterns among
augmentations, and suppresses noisy patterns at the same time. Furthermore, we
extend AP to a homogeneous version and a heterogeneous version for high-order
scenarios, demonstrating its robustness and flexibility in practical usage.
Experimental results on ImageNet benchmarks demonstrate the compatibility and
effectiveness on a much wider range of augmentations (e.g., Crop, Gray, Grid
Shuffle, RandAugment), while consuming fewer parameters and lower computational
costs at inference time. Source code:https://github.com/ap-conv/ap-net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Attention Model for RV StrainClassification from volumetric CTPA Scans. (arXiv:2107.12009v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cahan_N/0/1/0/all/0/1">Noa Cahan</a>, <a href="http://arxiv.org/find/eess/1/au:+Marom_E/0/1/0/all/0/1">Edith M. Marom</a>, <a href="http://arxiv.org/find/eess/1/au:+Soffer_S/0/1/0/all/0/1">Shelly Soffer</a>, <a href="http://arxiv.org/find/eess/1/au:+Barash_Y/0/1/0/all/0/1">Yiftach Barash</a>, <a href="http://arxiv.org/find/eess/1/au:+Konen_E/0/1/0/all/0/1">Eli Konen</a>, <a href="http://arxiv.org/find/eess/1/au:+Klang_E/0/1/0/all/0/1">Eyal Klang</a>, <a href="http://arxiv.org/find/eess/1/au:+Greenspan_H/0/1/0/all/0/1">Hayit Greenspan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12009">
                                    <div class="article-summary-box-inner">
                                        <span>Pulmonary embolus (PE) refers to obstruction of pulmonary arteries by blood
clots. PE accounts for approximately 100,000 deaths per year in the United
States alone. The clinical presentation of PE is often nonspecific, making the
diagnosis challenging. Thus, rapid and accurate risk stratification is of
paramount importance. High-risk PE is caused by right ventricular (RV)
dysfunction from acute pressure overload, which in return can help identify
which patients require more aggressive therapy. Reconstructed four-chamber
views of the heart on chest CT can detect right ventricular enlargement. CT
pulmonary angiography (CTPA) is the golden standard in the diagnostic workup of
suspected PE. Therefore, it can link between diagnosis and risk stratification
strategies. We developed a weakly supervised deep learning algorithm, with an
emphasis on a novel attention mechanism, to automatically classify RV strain on
CTPA. Our method is a 3D DenseNet model with integrated 3D residual attention
blocks. We evaluated our model on a dataset of CTPAs of emergency department
(ED) PE patients. This model achieved an area under the receiver operating
characteristic curve (AUC) of 0.88 for classifying RV strain. The model showed
a sensitivity of 87% and specificity of 83.7%. Our solution outperforms
state-of-the-art 3D CNN networks. The proposed design allows for a fully
automated network that can be trained easily in an end-to-end manner without
requiring computationally intensive and time-consuming preprocessing or
strenuous labeling of the data.We infer that unmarked CTPAs can be used for
effective RV strain classification. This could be used as a second reader,
alerting for high-risk PE patients. To the best of our knowledge, there are no
previous deep learning-based studies that attempted to solve this problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Synthetic Periocular Iris PAI from a Small Set of Near-Infrared-Images. (arXiv:2107.12014v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maureira_J/0/1/0/all/0/1">Jose Maureira</a>, <a href="http://arxiv.org/find/cs/1/au:+Tapia_J/0/1/0/all/0/1">Juan Tapia</a>, <a href="http://arxiv.org/find/cs/1/au:+Arellano_C/0/1/0/all/0/1">Claudia Arellano</a>, <a href="http://arxiv.org/find/cs/1/au:+Busch_C/0/1/0/all/0/1">Christoph Busch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12014">
                                    <div class="article-summary-box-inner">
                                        <span>Biometric has been increasing in relevance these days since it can be used
for several applications such as access control for instance. Unfortunately,
with the increased deployment of biometric applications, we observe an increase
of attacks. Therefore, algorithms to detect such attacks (Presentation Attack
Detection (PAD)) have been increasing in relevance. The LivDet-2020 competition
which focuses on Presentation Attacks Detection (PAD) algorithms have shown
still open problems, specially for unknown attacks scenarios. In order to
improve the robustness of biometric systems, it is crucial to improve PAD
methods. This can be achieved by augmenting the number of presentation attack
instruments (PAI) and bona fide images that are used to train such algorithms.
Unfortunately, the capture and creation of presentation attack instruments and
even the capture of bona fide images is sometimes complex to achieve. This
paper proposes a novel PAI synthetically created (SPI-PAI) using four
state-of-the-art GAN algorithms (cGAN, WGAN, WGAN-GP, and StyleGAN2) and a
small set of periocular NIR images. A benchmark between GAN algorithms is
performed using the Frechet Inception Distance (FID) between the generated
images and the original images used for training. The best PAD algorithm
reported by the LivDet-2020 competition was tested for us using the synthetic
PAI which was obtained with the StyleGAN2 algorithm. Surprisingly, The PAD
algorithm was not able to detect the synthetic images as a Presentation Attack,
categorizing all of them as bona fide. Such results demonstrated the
feasibility of synthetic images to fool presentation attacks detection
algorithms and the need for such algorithms to be constantly updated and
trained with a larger number of images and PAI scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Text is Text, No Matter What: Unifying Text Recognition using Knowledge Distillation. (arXiv:2107.12087v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhunia_A/0/1/0/all/0/1">Ayan Kumar Bhunia</a>, <a href="http://arxiv.org/find/cs/1/au:+Sain_A/0/1/0/all/0/1">Aneeshan Sain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_P/0/1/0/all/0/1">Pinaki Nath Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yi-Zhe Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12087">
                                    <div class="article-summary-box-inner">
                                        <span>Text recognition remains a fundamental and extensively researched topic in
computer vision, largely owing to its wide array of commercial applications.
The challenging nature of the very problem however dictated a fragmentation of
research efforts: Scene Text Recognition (STR) that deals with text in everyday
scenes, and Handwriting Text Recognition (HTR) that tackles hand-written text.
In this paper, for the first time, we argue for their unification -- we aim for
a single model that can compete favourably with two separate state-of-the-art
STR and HTR models. We first show that cross-utilisation of STR and HTR models
trigger significant performance drops due to differences in their inherent
challenges. We then tackle their union by introducing a knowledge distillation
(KD) based framework. This is however non-trivial, largely due to the
variable-length and sequential nature of text sequences, which renders
off-the-shelf KD techniques that mostly works with global fixed-length data
inadequate. For that, we propose three distillation losses all of which are
specifically designed to cope with the aforementioned unique characteristics of
text recognition. Empirical evidence suggests that our proposed unified model
performs on par with individual models, even surpassing them in certain cases.
Ablative studies demonstrate that naive baselines such as a two-stage
framework, and domain adaption/generalisation alternatives do not work as well,
further verifying the appropriateness of our design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatio-Temporal Representation Factorization for Video-based Person Re-Identification. (arXiv:2107.11878v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aich_A/0/1/0/all/0/1">Abhishek Aich</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_M/0/1/0/all/0/1">Meng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Karanam_S/0/1/0/all/0/1">Srikrishna Karanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Terrence Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_Chowdhury_A/0/1/0/all/0/1">Amit K. Roy-Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Ziyan Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11878">
                                    <div class="article-summary-box-inner">
                                        <span>Despite much recent progress in video-based person re-identification (re-ID),
the current state-of-the-art still suffers from common real-world challenges
such as appearance similarity among various people, occlusions, and frame
misalignment. To alleviate these problems, we propose Spatio-Temporal
Representation Factorization module (STRF), a flexible new computational unit
that can be used in conjunction with most existing 3D convolutional neural
network architectures for re-ID. The key innovations of STRF over prior work
include explicit pathways for learning discriminative temporal and spatial
features, with each component further factorized to capture complementary
person-specific appearance and motion information. Specifically, temporal
factorization comprises two branches, one each for static features (e.g., the
color of clothes) that do not change much over time, and dynamic features
(e.g., walking patterns) that change over time. Further, spatial factorization
also comprises two branches to learn both global (coarse segments) as well as
local (finer segments) appearance features, with the local features
particularly useful in cases of occlusion or spatial misalignment. These two
factorization operations taken together result in a modular architecture for
our parameter-wise economic STRF unit that can be plugged in between any two 3D
convolutional layers, resulting in an end-to-end learning framework. We
empirically show that STRF improves performance of various existing baseline
architectures while demonstrating new state-of-the-art results using standard
person re-identification evaluation protocols on three benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Alignment Prediction for Few-Shot Video Classification. (arXiv:2107.11960v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_F/0/1/0/all/0/1">Fei Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chunlei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jie Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yanwen Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11960">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of few-shot video classification is to learn a classification model
with good generalization ability when trained with only a few labeled videos.
However, it is difficult to learn discriminative feature representations for
videos in such a setting. In this paper, we propose Temporal Alignment
Prediction (TAP) based on sequence similarity learning for few-shot video
classification. In order to obtain the similarity of a pair of videos, we
predict the alignment scores between all pairs of temporal positions in the two
videos with the temporal alignment prediction function. Besides, the inputs to
this function are also equipped with the context information in the temporal
domain. We evaluate TAP on two video classification benchmarks including
Kinetics and Something-Something V2. The experimental results verify the
effectiveness of TAP and show its superiority over state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ICDAR 2021 Competition on Scene Video Text Spotting. (arXiv:2107.11919v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1">Zhanzhan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_B/0/1/0/all/0/1">Baorui Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuigeng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11919">
                                    <div class="article-summary-box-inner">
                                        <span>Scene video text spotting (SVTS) is a very important research topic because
of many real-life applications. However, only a little effort has put to
spotting scene video text, in contrast to massive studies of scene text
spotting in static images. Due to various environmental interferences like
motion blur, spotting scene video text becomes very challenging. To promote
this research area, this competition introduces a new challenge dataset
containing 129 video clips from 21 natural scenarios in full annotations. The
competition containts three tasks, that is, video text detection (Task 1),
video text tracking (Task 2) and end-to-end video text spotting (Task3). During
the competition period (opened on 1st March, 2021 and closed on 11th April,
2021), a total of 24 teams participated in the three proposed tasks with 46
valid submissions, respectively. This paper includes dataset descriptions, task
definitions, evaluation protocols and results summaries of the ICDAR 2021 on
SVTS competition. Thanks to the healthy number of teams as well as submissions,
we consider that the SVTS competition has been successfully held, drawing much
attention from the community and promoting the field research and its
development.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Robot Localisation by Ignoring Visual Distraction. (arXiv:2107.11857v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mendez_O/0/1/0/all/0/1">Oscar Mendez</a>, <a href="http://arxiv.org/find/cs/1/au:+Vowels_M/0/1/0/all/0/1">Matthew Vowels</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowden_R/0/1/0/all/0/1">Richard Bowden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11857">
                                    <div class="article-summary-box-inner">
                                        <span>Attention is an important component of modern deep learning. However, less
emphasis has been put on its inverse: ignoring distraction. Our daily lives
require us to explicitly avoid giving attention to salient visual features that
confound the task we are trying to accomplish. This visual prioritisation
allows us to concentrate on important tasks while ignoring visual distractors.

In this work, we introduce Neural Blindness, which gives an agent the ability
to completely ignore objects or classes that are deemed distractors. More
explicitly, we aim to render a neural network completely incapable of
representing specific chosen classes in its latent space. In a very real sense,
this makes the network &quot;blind&quot; to certain classes, allowing and agent to focus
on what is important for a given task, and demonstrates how this can be used to
improve localisation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Will Multi-modal Data Improves Few-shot Learning?. (arXiv:2107.11853v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zilun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shihao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yichun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11853">
                                    <div class="article-summary-box-inner">
                                        <span>Most few-shot learning models utilize only one modality of data. We would
like to investigate qualitatively and quantitatively how much will the model
improve if we add an extra modality (i.e. text description of the image), and
how it affects the learning procedure. To achieve this goal, we propose four
types of fusion method to combine the image feature and text feature. To verify
the effectiveness of improvement, we test the fusion methods with two classical
few-shot learning models - ProtoNet and MAML, with image feature extractors
such as ConvNet and ResNet12. The attention-based fusion method works best,
which improves the classification accuracy by a large margin around 30%
comparing to the baseline result.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Recursive Circle Framework for Fine-grained Action Recognition. (arXiv:2107.11813v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1">Hanxi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xinxiao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiebo Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11813">
                                    <div class="article-summary-box-inner">
                                        <span>How to model fine-grained spatial-temporal dynamics in videos has been a
challenging problem for action recognition. It requires learning deep and rich
features with superior distinctiveness for the subtle and abstract motions.
Most existing methods generate features of a layer in a pure feedforward
manner, where the information moves in one direction from inputs to outputs.
And they rely on stacking more layers to obtain more powerful features,
bringing extra non-negligible overheads. In this paper, we propose an Adaptive
Recursive Circle (ARC) framework, a fine-grained decorator for pure feedforward
layers. It inherits the operators and parameters of the original layer but is
slightly different in the use of those operators and parameters. Specifically,
the input of the layer is treated as an evolving state, and its update is
alternated with the feature generation. At each recursive step, the input state
is enriched by the previously generated features and the feature generation is
made with the newly updated input state. We hope the ARC framework can
facilitate fine-grained action recognition by introducing deeply refined
features and multi-scale receptive fields at a low cost. Significant
improvements over feedforward baselines are observed on several benchmarks. For
example, an ARC-equipped TSM-ResNet18 outperforms TSM-ResNet50 with 48% fewer
FLOPs and 52% model parameters on Something-Something V1 and Diving48.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transcript to Video: Efficient Clip Sequencing from Texts. (arXiv:2107.11851v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1">Yu Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Heilbron_F/0/1/0/all/0/1">Fabian Caba Heilbron</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_D/0/1/0/all/0/1">Dahua Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11851">
                                    <div class="article-summary-box-inner">
                                        <span>Among numerous videos shared on the web, well-edited ones always attract more
attention. However, it is difficult for inexperienced users to make well-edited
videos because it requires professional expertise and immense manual labor. To
meet the demands for non-experts, we present Transcript-to-Video -- a
weakly-supervised framework that uses texts as input to automatically create
video sequences from an extensive collection of shots. Specifically, we propose
a Content Retrieval Module and a Temporal Coherent Module to learn
visual-language representations and model shot sequencing styles, respectively.
For fast inference, we introduce an efficient search strategy for real-time
video clip sequencing. Quantitative results and user studies demonstrate
empirically that the proposed learning framework can retrieve content-relevant
shots while creating plausible video sequences in terms of style. Besides, the
run-time performance analysis shows that our framework can support real-world
applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bangla sign language recognition using concatenated BdSL network. (arXiv:2107.11818v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abedin_T/0/1/0/all/0/1">Thasin Abedin</a>, <a href="http://arxiv.org/find/cs/1/au:+Prottoy_K/0/1/0/all/0/1">Khondokar S. S. Prottoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshruba_A/0/1/0/all/0/1">Ayana Moshruba</a>, <a href="http://arxiv.org/find/cs/1/au:+Hakim_S/0/1/0/all/0/1">Safayat Bin Hakim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11818">
                                    <div class="article-summary-box-inner">
                                        <span>Sign language is the only medium of communication for the hearing impaired
and the deaf and dumb community. Communication with the general mass is thus
always a challenge for this minority group. Especially in Bangla sign language
(BdSL), there are 38 alphabets with some having nearly identical symbols. As a
result, in BdSL recognition, the posture of hand is an important factor in
addition to visual features extracted from traditional Convolutional Neural
Network (CNN). In this paper, a novel architecture &quot;Concatenated BdSL Network&quot;
is proposed which consists of a CNN based image network and a pose estimation
network. While the image network gets the visual features, the relative
positions of hand keypoints are taken by the pose estimation network to obtain
the additional features to deal with the complexity of the BdSL symbols. A
score of 91.51% was achieved by this novel approach in test set and the
effectiveness of the additional pose estimation network is suggested by the
experimental results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Auxiliary Tasks with Affinity Learning for Weakly Supervised Semantic Segmentation. (arXiv:2107.11787v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lian Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1">Mohammed Bennamoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Boussaid_F/0/1/0/all/0/1">Farid Boussaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohel_F/0/1/0/all/0/1">Ferdous Sohel</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dan Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11787">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation is a challenging task in the absence of densely
labelled data. Only relying on class activation maps (CAM) with image-level
labels provides deficient segmentation supervision. Prior works thus consider
pre-trained models to produce coarse saliency maps to guide the generation of
pseudo segmentation labels. However, the commonly used off-line heuristic
generation process cannot fully exploit the benefits of these coarse saliency
maps. Motivated by the significant inter-task correlation, we propose a novel
weakly supervised multi-task framework termed as AuxSegNet, to leverage
saliency detection and multi-label image classification as auxiliary tasks to
improve the primary task of semantic segmentation using only image-level
ground-truth labels. Inspired by their similar structured semantics, we also
propose to learn a cross-task global pixel-level affinity map from the saliency
and segmentation representations. The learned cross-task affinity can be used
to refine saliency predictions and propagate CAM maps to provide improved
pseudo labels for both tasks. The mutual boost between pseudo label updating
and cross-task affinity learning enables iterative improvements on segmentation
performance. Extensive experiments demonstrate the effectiveness of the
proposed auxiliary learning network structure and the cross-task affinity
learning method. The proposed approach achieves state-of-the-art weakly
supervised segmentation performance on the challenging PASCAL VOC 2012 and MS
COCO benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comprehensive Studies for Arbitrary-shape Scene Text Detection. (arXiv:2107.11800v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_P/0/1/0/all/0/1">Pengwen Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xiaochun Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11800">
                                    <div class="article-summary-box-inner">
                                        <span>Numerous scene text detection methods have been proposed in recent years.
Most of them declare they have achieved state-of-the-art performances. However,
the performance comparison is unfair, due to lots of inconsistent settings
(e.g., training data, backbone network, multi-scale feature fusion, evaluation
protocols, etc.). These various settings would dissemble the pros and cons of
the proposed core techniques. In this paper, we carefully examine and analyze
the inconsistent settings, and propose a unified framework for the bottom-up
based scene text detection methods. Under the unified framework, we ensure the
consistent settings for non-core modules, and mainly investigate the
representations of describing arbitrary-shape scene texts, e.g., regressing
points on text contours, clustering pixels with predicted auxiliary
information, grouping connected components with learned linkages, etc. With the
comprehensive investigations and elaborate analyses, it not only cleans up the
obstacle of understanding the performance differences between existing methods
but also reveals the advantages and disadvantages of previous models under fair
comparisons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Denoising and Segmentation of Epigraphical Scripts. (arXiv:2107.11801v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Preethi_P/0/1/0/all/0/1">P Preethi</a>, <a href="http://arxiv.org/find/cs/1/au:+Viswanath_H/0/1/0/all/0/1">Hrishikesh Viswanath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11801">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is a presentation of a new method for denoising images using
Haralick features and further segmenting the characters using artificial neural
networks. The image is divided into kernels, each of which is converted to a
GLCM (Gray Level Co-Occurrence Matrix) on which a Haralick Feature generation
function is called, the result of which is an array with fourteen elements
corresponding to fourteen features The Haralick values and the corresponding
noise/text classification form a dictionary, which is then used to de-noise the
image through kernel comparison. Segmentation is the process of extracting
characters from a document and can be used when letters are separated by white
space, which is an explicit boundary marker. Segmentation is the first step in
many Natural Language Processing problems. This paper explores the process of
segmentation using Neural Networks. While there have been numerous methods to
segment characters of a document, this paper is only concerned with the
accuracy of doing so using neural networks. It is imperative that the
characters be segmented correctly, for failing to do so will lead to incorrect
recognition by Natural language processing tools. Artificial Neural Networks
was used to attain accuracy of upto 89%. This method is suitable for languages
where the characters are delimited by white space. However, this method will
fail to provide acceptable results when the language heavily uses connected
letters. An example would be the Devanagari script, which is predominantly used
in northern India.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Character Spotting Using Machine Learning Techniques. (arXiv:2107.11795v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Preethi_P/0/1/0/all/0/1">P Preethi</a>, <a href="http://arxiv.org/find/cs/1/au:+Viswanath_H/0/1/0/all/0/1">Hrishikesh Viswanath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11795">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents a comparison of machine learning algorithms that are
implemented to segment the characters of text presented as an image. The
algorithms are designed to work on degraded documents with text that is not
aligned in an organized fashion. The paper investigates the use of Support
Vector Machines, K-Nearest Neighbor algorithm and an Encoder Network to perform
the operation of character spotting. Character Spotting involves extracting
potential characters from a stream of text by selecting regions bound by white
space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning-based Frozen Section to FFPE Translation. (arXiv:2107.11786v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ozyoruk_K/0/1/0/all/0/1">Kutsev Bengisu Ozyoruk</a>, <a href="http://arxiv.org/find/eess/1/au:+Can_S/0/1/0/all/0/1">Sermet Can</a>, <a href="http://arxiv.org/find/eess/1/au:+Gokceler_G/0/1/0/all/0/1">Guliz Irem Gokceler</a>, <a href="http://arxiv.org/find/eess/1/au:+Basak_K/0/1/0/all/0/1">Kayhan Basak</a>, <a href="http://arxiv.org/find/eess/1/au:+Demir_D/0/1/0/all/0/1">Derya Demir</a>, <a href="http://arxiv.org/find/eess/1/au:+Serin_G/0/1/0/all/0/1">Gurdeniz Serin</a>, <a href="http://arxiv.org/find/eess/1/au:+Hacisalihoglu_U/0/1/0/all/0/1">Uguray Payam Hacisalihoglu</a>, <a href="http://arxiv.org/find/eess/1/au:+Darbaz_B/0/1/0/all/0/1">Berkan Darbaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_M/0/1/0/all/0/1">Ming Y. Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_T/0/1/0/all/0/1">Tiffany Y. Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Williamson_D/0/1/0/all/0/1">Drew F. K. Williamson</a>, <a href="http://arxiv.org/find/eess/1/au:+Yilmaz_F/0/1/0/all/0/1">Funda Yilmaz</a>, <a href="http://arxiv.org/find/eess/1/au:+Mahmood_F/0/1/0/all/0/1">Faisal Mahmood</a>, <a href="http://arxiv.org/find/eess/1/au:+Turan_M/0/1/0/all/0/1">Mehmet Turan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11786">
                                    <div class="article-summary-box-inner">
                                        <span>Frozen sectioning (FS) is the preparation method of choice for microscopic
evaluation of tissues during surgical operations. The high speed of procedure
allows pathologists to rapidly assess the key microscopic features, such as
tumor margins and malignant status to guide surgical decision-making and
minimise disruptions to the course of the operation. However, FS is prone to
introducing many misleading artificial structures (histological artefacts),
such as nuclear ice crystals, compression, and cutting artefacts, hindering
timely and accurate diagnostic judgement of the pathologist. On the other hand,
the gold standard tissue preparation technique of formalin-fixation and
paraffin-embedding (FFPE) provides significantly superior image quality, but is
a very time-consuming process (12-48 hours), making it unsuitable for
intra-operative use. In this paper, we propose an artificial intelligence (AI)
method that improves FS image quality by computationally transforming
frozen-sectioned whole-slide images (FS-WSIs) into whole-slide FFPE-style
images in minutes. AI-FFPE rectifies FS artefacts with the guidance of an
attention-mechanism that puts a particular emphasis on artefacts while
utilising a self-regularization mechanism established between FS input image
and synthesized FFPE-style image that preserves clinically relevant features.
As a result, AI-FFPE method successfully generates FFPE-style images without
significantly extending tissue processing time and consequently improves
diagnostic accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Uncertainty-Aware Deep Learning Framework for Defect Detection in Casting Products. (arXiv:2107.11643v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Habibpour_M/0/1/0/all/0/1">Maryam Habibpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Gharoun_H/0/1/0/all/0/1">Hassan Gharoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Tajally_A/0/1/0/all/0/1">AmirReza Tajally</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamsi_A/0/1/0/all/0/1">Afshar Shamsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Asgharnezhad_H/0/1/0/all/0/1">Hamzeh Asgharnezhad</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosravi_A/0/1/0/all/0/1">Abbas Khosravi</a>, <a href="http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1">Saeid Nahavandi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11643">
                                    <div class="article-summary-box-inner">
                                        <span>Defects are unavoidable in casting production owing to the complexity of the
casting process. While conventional human-visual inspection of casting products
is slow and unproductive in mass productions, an automatic and reliable defect
detection not just enhances the quality control process but positively improves
productivity. However, casting defect detection is a challenging task due to
diversity and variation in defects&#x27; appearance. Convolutional neural networks
(CNNs) have been widely applied in both image classification and defect
detection tasks. Howbeit, CNNs with frequentist inference require a massive
amount of data to train on and still fall short in reporting beneficial
estimates of their predictive uncertainty. Accordingly, leveraging the transfer
learning paradigm, we first apply four powerful CNN-based models (VGG16,
ResNet50, DenseNet121, and InceptionResNetV2) on a small dataset to extract
meaningful features. Extracted features are then processed by various machine
learning algorithms to perform the classification task. Simulation results
demonstrate that linear support vector machine (SVM) and multi-layer perceptron
(MLP) show the finest performance in defect detection of casting images.
Secondly, to achieve a reliable classification and to measure epistemic
uncertainty, we employ an uncertainty quantification (UQ) technique (ensemble
of MLP models) using features extracted from four pre-trained CNNs. UQ
confusion matrix and uncertainty accuracy metric are also utilized to evaluate
the predictive uncertainty estimates. Comprehensive comparisons reveal that UQ
method based on VGG16 outperforms others to fetch uncertainty. We believe an
uncertainty-aware automatic defect detection solution will reinforce casting
productions quality assurance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Go Wider Instead of Deeper. (arXiv:2107.11817v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1">Fuzhao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Ziji Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1">Yuxuan Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yang You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11817">
                                    <div class="article-summary-box-inner">
                                        <span>The transformer has recently achieved impressive results on various tasks. To
further improve the effectiveness and efficiency of the transformer, there are
two trains of thought among existing works: (1) going wider by scaling to more
trainable parameters; (2) going shallower by parameter sharing or model
compressing along with the depth. However, larger models usually do not scale
well when fewer tokens are available to train, and advanced parallelisms are
required when the model is extremely large. Smaller models usually achieve
inferior performance compared to the original transformer model due to the loss
of representation power. In this paper, to achieve better performance with
fewer trainable parameters, we propose a framework to deploy trainable
parameters efficiently, by going wider instead of deeper. Specially, we scale
along model width by replacing feed-forward network (FFN) with
mixture-of-experts (MoE). We then share the MoE layers across transformer
blocks using individual layer normalization. Such deployment plays the role to
transform various semantic representations, which makes the model more
parameter-efficient and effective. To evaluate our framework, we design WideNet
and evaluate it on ImageNet-1K. Our best model outperforms Vision Transformer
(ViT) by $1.46\%$ with $0.72 \times$ trainable parameters. Using $0.46 \times$
and $0.13 \times$ parameters, our WideNet can still surpass ViT and ViT-MoE by
$0.83\%$ and $2.08\%$, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Machine Learning Based Egyptian Vehicle License Plate Recognition Systems. (arXiv:2107.11640v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shehata_M/0/1/0/all/0/1">Mohamed Shehata</a>, <a href="http://arxiv.org/find/cs/1/au:+Abou_Kreisha_M/0/1/0/all/0/1">Mohamed Taha Abou-Kreisha</a>, <a href="http://arxiv.org/find/cs/1/au:+Elnashar_H/0/1/0/all/0/1">Hany Elnashar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11640">
                                    <div class="article-summary-box-inner">
                                        <span>Automated Vehicle License Plate (VLP) detection and recognition have ended up
being a significant research issue as of late. VLP localization and recognition
are some of the most essential techniques for managing traffic using digital
techniques. In this paper, four smart systems are developed to recognize
Egyptian vehicles license plates. Two systems are based on character
recognition, which are (System1, Characters Recognition with Classical Machine
Learning) and (System2, Characters Recognition with Deep Machine Learning). The
other two systems are based on the whole plate recognition which are (System3,
Whole License Plate Recognition with Classical Machine Learning) and (System4,
Whole License Plate Recognition with Deep Machine Learning). We use object
detection algorithms, and machine learning based object recognition algorithms.
The performance of the developed systems has been tested on real images, and
the experimental results demonstrate that the best detection accuracy rate for
VLP is provided by using the deep learning method. Where the VLP detection
accuracy rate is better than the classical system by 32%. However, the best
detection accuracy rate for Vehicle License Plate Arabic Character (VLPAC) is
provided by using the classical method. Where VLPAC detection accuracy rate is
better than the deep learning-based system by 6%. Also, the results show that
deep learning is better than the classical technique used in VLP recognition
processes. Where the recognition accuracy rate is better than the classical
system by 8%. Finally, the paper output recommends a robust VLP recognition
system based on both statistical and deep machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two Headed Dragons: Multimodal Fusion and Cross Modal Transactions. (arXiv:2107.11585v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bose_R/0/1/0/all/0/1">Rupak Bose</a>, <a href="http://arxiv.org/find/cs/1/au:+Pande_S/0/1/0/all/0/1">Shivam Pande</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_B/0/1/0/all/0/1">Biplab Banerjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11585">
                                    <div class="article-summary-box-inner">
                                        <span>As the field of remote sensing is evolving, we witness the accumulation of
information from several modalities, such as multispectral (MS), hyperspectral
(HSI), LiDAR etc. Each of these modalities possess its own distinct
characteristics and when combined synergistically, perform very well in the
recognition and classification tasks. However, fusing multiple modalities in
remote sensing is cumbersome due to highly disparate domains. Furthermore, the
existing methods do not facilitate cross-modal interactions. To this end, we
propose a novel transformer based fusion method for HSI and LiDAR modalities.
The model is composed of stacked auto encoders that harness the cross key-value
pairs for HSI and LiDAR, thus establishing a communication between the two
modalities, while simultaneously using the CNNs to extract the spectral and
spatial information from HSI and LiDAR. We test our model on Houston (Data
Fusion Contest - 2013) and MUUFL Gulfport datasets and achieve competitive
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Conditioned Probabilistic Learning of Video Rescaling. (arXiv:2107.11639v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuan Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1">Guo Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Min_X/0/1/0/all/0/1">Xiongkuo Min</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1">Zhaohui Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_G/0/1/0/all/0/1">Guodong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zhiyong Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11639">
                                    <div class="article-summary-box-inner">
                                        <span>Bicubic downscaling is a prevalent technique used to reduce the video storage
burden or to accelerate the downstream processing speed. However, the inverse
upscaling step is non-trivial, and the downscaled video may also deteriorate
the performance of downstream tasks. In this paper, we propose a
self-conditioned probabilistic framework for video rescaling to learn the
paired downscaling and upscaling procedures simultaneously. During the
training, we decrease the entropy of the information lost in the downscaling by
maximizing its probability conditioned on the strong spatial-temporal prior
information within the downscaled video. After optimization, the downscaled
video by our framework preserves more meaningful information, which is
beneficial for both the upscaling step and the downstream tasks, e.g., video
action recognition task. We further extend the framework to a lossy video
compression system, in which a gradient estimator for non-differential
industrial lossy codecs is proposed for the end-to-end training of the whole
system. Extensive experimental results demonstrate the superiority of our
approach on video rescaling, video compression, and efficient action
recognition tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Echo LiDAR for 3D Object Detection. (arXiv:2107.11470v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Man_Y/0/1/0/all/0/1">Yunze Man</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_X/0/1/0/all/0/1">Xinshuo Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivakuma_P/0/1/0/all/0/1">Prasanna Kumar Sivakuma</a>, <a href="http://arxiv.org/find/cs/1/au:+OToole_M/0/1/0/all/0/1">Matthew O&#x27;Toole</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1">Kris Kitani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11470">
                                    <div class="article-summary-box-inner">
                                        <span>LiDAR sensors can be used to obtain a wide range of measurement signals other
than a simple 3D point cloud, and those signals can be leveraged to improve
perception tasks like 3D object detection. A single laser pulse can be
partially reflected by multiple objects along its path, resulting in multiple
measurements called echoes. Multi-echo measurement can provide information
about object contours and semi-transparent surfaces which can be used to better
identify and locate objects. LiDAR can also measure surface reflectance
(intensity of laser pulse return), as well as ambient light of the scene
(sunlight reflected by objects). These signals are already available in
commercial LiDAR devices but have not been used in most LiDAR-based detection
models. We present a 3D object detection model which leverages the full
spectrum of measurement signals provided by LiDAR. First, we propose a
multi-signal fusion (MSF) module to combine (1) the reflectance and ambient
features extracted with a 2D CNN, and (2) point cloud features extracted using
a 3D graph neural network (GNN). Second, we propose a multi-echo aggregation
(MEA) module to combine the information encoded in different set of echo
points. Compared with traditional single echo point cloud methods, our proposed
Multi-Signal LiDAR Detector (MSLiD) extracts richer context information from a
wider range of sensing measurements and achieves more accurate 3D object
detection. Experiments show that by incorporating the multi-modality of LiDAR,
our method outperforms the state-of-the-art by up to 9.1%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Sentence Temporal and Semantic Relations in Video Activity Localisation. (arXiv:2107.11443v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiabo Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_S/0/1/0/all/0/1">Shaogang Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Hailin Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11443">
                                    <div class="article-summary-box-inner">
                                        <span>Video activity localisation has recently attained increasing attention due to
its practical values in automatically localising the most salient visual
segments corresponding to their language descriptions (sentences) from
untrimmed and unstructured videos. For supervised model training, a temporal
annotation of both the start and end time index of each video segment for a
sentence (a video moment) must be given. This is not only very expensive but
also sensitive to ambiguity and subjective annotation bias, a much harder task
than image labelling. In this work, we develop a more accurate
weakly-supervised solution by introducing Cross-Sentence Relations Mining (CRM)
in video moment proposal generation and matching when only a paragraph
description of activities without per-sentence temporal annotation is
available. Specifically, we explore two cross-sentence relational constraints:
(1) Temporal ordering and (2) semantic consistency among sentences in a
paragraph description of video activities. Existing weakly-supervised
techniques only consider within-sentence video segment correlations in training
without considering cross-sentence paragraph context. This can mislead due to
ambiguous expressions of individual sentences with visually indiscriminate
video moment proposals in isolation. Experiments on two publicly available
activity localisation datasets show the advantages of our approach over the
state-of-the-art weakly supervised methods, especially so when the video
activity descriptions become more complex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Free Hyperbolic Neural Networks with Limited Radii. (arXiv:2107.11472v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yunhui Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xudong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yubei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Stella X. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11472">
                                    <div class="article-summary-box-inner">
                                        <span>Non-Euclidean geometry with constant negative curvature, i.e., hyperbolic
space, has attracted sustained attention in the community of machine learning.
Hyperbolic space, owing to its ability to embed hierarchical structures
continuously with low distortion, has been applied for learning data with
tree-like structures. Hyperbolic Neural Networks (HNNs) that operate directly
in hyperbolic space have also been proposed recently to further exploit the
potential of hyperbolic representations. While HNNs have achieved better
performance than Euclidean neural networks (ENNs) on datasets with implicit
hierarchical structure, they still perform poorly on standard classification
benchmarks such as CIFAR and ImageNet. The traditional wisdom is that it is
critical for the data to respect the hyperbolic geometry when applying HNNs. In
this paper, we first conduct an empirical study showing that the inferior
performance of HNNs on standard recognition datasets can be attributed to the
notorious vanishing gradient problem. We further discovered that this problem
stems from the hybrid architecture of HNNs. Our analysis leads to a simple yet
effective solution called Feature Clipping, which regularizes the hyperbolic
embedding whenever its norm exceeding a given threshold. Our thorough
experiments show that the proposed method can successfully avoid the vanishing
gradient problem when training HNNs with backpropagation. The improved HNNs are
able to achieve comparable performance with ENNs on standard image recognition
datasets including MNIST, CIFAR10, CIFAR100 and ImageNet, while demonstrating
more adversarial robustness and stronger out-of-distribution detection
capability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Based Cardiac MRI Segmentation: Do We Need Experts?. (arXiv:2107.11447v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Skandarani_Y/0/1/0/all/0/1">Youssef Skandarani</a>, <a href="http://arxiv.org/find/cs/1/au:+Jodoin_P/0/1/0/all/0/1">Pierre-Marc Jodoin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lalande_A/0/1/0/all/0/1">Alain Lalande</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11447">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning methods are the de-facto solutions to a multitude of medical
image analysis tasks. Cardiac MRI segmentation is one such application which,
like many others, requires a large number of annotated data so a trained
network can generalize well. Unfortunately, the process of having a large
number of manually curated images by medical experts is both slow and utterly
expensive. In this paper, we set out to explore whether expert knowledge is a
strict requirement for the creation of annotated datasets that machine learning
can successfully train on. To do so, we gauged the performance of three
segmentation models, namely U-Net, Attention U-Net, and ENet, trained with
different loss functions on expert and non-expert groundtruth for cardiac
cine-MRI segmentation. Evaluation was done with classic segmentation metrics
(Dice index and Hausdorff distance) as well as clinical measurements, such as
the ventricular ejection fractions and the myocardial mass. Results reveal that
generalization performances of a segmentation neural network trained on
non-expert groundtruth data is, to all practical purposes, as good as on expert
groundtruth data, in particular when the non-expert gets a decent level of
training, highlighting an opportunity for the efficient and cheap creation of
annotations for cardiac datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crosslink-Net: Double-branch Encoder Segmentation Network via Fusing Vertical and Horizontal Convolutions. (arXiv:2107.11517v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_L/0/1/0/all/0/1">Lei Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Luping Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Yilong Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yinghuan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wuzhang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11517">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate image segmentation plays a crucial role in medical image analysis,
yet it faces great challenges of various shapes, diverse sizes, and blurry
boundaries. To address these difficulties, square kernel-based encoder-decoder
architecture has been proposed and widely used, but its performance remains
still unsatisfactory. To further cope with these challenges, we present a novel
double-branch encoder architecture. Our architecture is inspired by two
observations: 1) Since the discrimination of features learned via square
convolutional kernels needs to be further improved, we propose to utilize
non-square vertical and horizontal convolutional kernels in the double-branch
encoder, so features learned by the two branches can be expected to complement
each other. 2) Considering that spatial attention can help models to better
focus on the target region in a large-sized image, we develop an attention loss
to further emphasize the segmentation on small-sized targets. Together, the
above two schemes give rise to a novel double-branch encoder segmentation
framework for medical image segmentation, namely Crosslink-Net. The experiments
validate the effectiveness of our model on four datasets. The code is released
at https://github.com/Qianyu1226/Crosslink-Net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Label Image Classification with Contrastive Learning. (arXiv:2107.11626v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dao_S/0/1/0/all/0/1">Son D.Dao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_E/0/1/0/all/0/1">Ethan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Phung_D/0/1/0/all/0/1">Dinh Phung</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11626">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, as an effective way of learning latent representations, contrastive
learning has been increasingly popular and successful in various domains. The
success of constrastive learning in single-label classifications motivates us
to leverage this learning framework to enhance distinctiveness for better
performance in multi-label image classification. In this paper, we show that a
direct application of contrastive learning can hardly improve in multi-label
cases. Accordingly, we propose a novel framework for multi-label classification
with contrastive learning in a fully supervised setting, which learns multiple
representations of an image under the context of different labels. This
facilities a simple yet intuitive adaption of contrastive learning into our
model to boost its performance in multi-label image classification. Extensive
experiments on two benchmark datasets show that the proposed framework achieves
state-of-the-art performance in the comparison with the advanced methods in
multi-label classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cycled Compositional Learning between Images and Text. (arXiv:2107.11509v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jongseok Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youngjae Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Seunghwan Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+GunheeKim/0/1/0/all/0/1">GunheeKim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11509">
                                    <div class="article-summary-box-inner">
                                        <span>We present an approach named the Cycled Composition Network that can measure
the semantic distance of the composition of image-text embedding. First, the
Composition Network transit a reference image to target image in an embedding
space using relative caption. Second, the Correction Network calculates a
difference between reference and retrieved target images in the embedding space
and match it with a relative caption. Our goal is to learn a Composition
mapping with the Composition Network. Since this one-way mapping is highly
under-constrained, we couple it with an inverse relation learning with the
Correction Network and introduce a cycled relation for given Image We
participate in Fashion IQ 2020 challenge and have won the first place with the
ensemble of our model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Explainability: A Tutorial on Gradient-Based Attribution Methods for Deep Neural Networks. (arXiv:2107.11400v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nielsen_I/0/1/0/all/0/1">Ian E. Nielsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasool_G/0/1/0/all/0/1">Ghulam Rasool</a>, <a href="http://arxiv.org/find/cs/1/au:+Dera_D/0/1/0/all/0/1">Dimah Dera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouaynaya_N/0/1/0/all/0/1">Nidhal Bouaynaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_R/0/1/0/all/0/1">Ravi P. Ramachandran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11400">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of deep neural networks, the challenge of explaining the
predictions of these networks has become increasingly recognized. While many
methods for explaining the decisions of deep neural networks exist, there is
currently no consensus on how to evaluate them. On the other hand, robustness
is a popular topic for deep learning research; however, it is hardly talked
about in explainability until very recently. In this tutorial paper, we start
by presenting gradient-based interpretability methods. These techniques use
gradient signals to assign the burden of the decision on the input features.
Later, we discuss how gradient-based methods can be evaluated for their
robustness and the role that adversarial robustness plays in having meaningful
explanations. We also discuss the limitations of gradient-based methods.
Finally, we present the best practices and attributes that should be examined
before choosing an explainability method. We conclude with the future
directions for research in the area at the convergence of robustness and
explainability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerating Atmospheric Turbulence Simulation via Learned Phase-to-Space Transform. (arXiv:2107.11627v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mao_Z/0/1/0/all/0/1">Zhiyuan Mao</a>, <a href="http://arxiv.org/find/eess/1/au:+Chimitt_N/0/1/0/all/0/1">Nicholas Chimitt</a>, <a href="http://arxiv.org/find/eess/1/au:+Chan_S/0/1/0/all/0/1">Stanley H. Chan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11627">
                                    <div class="article-summary-box-inner">
                                        <span>Fast and accurate simulation of imaging through atmospheric turbulence is
essential for developing turbulence mitigation algorithms. Recognizing the
limitations of previous approaches, we introduce a new concept known as the
phase-to-space (P2S) transform to significantly speed up the simulation. P2S is
build upon three ideas: (1) reformulating the spatially varying convolution as
a set of invariant convolutions with basis functions, (2) learning the basis
function via the known turbulence statistics models, (3) implementing the P2S
transform via a light-weight network that directly convert the phase
representation to spatial representation. The new simulator offers 300x --
1000x speed up compared to the mainstream split-step simulators while
preserving the essential turbulence statistics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reconstructing Images of Two Adjacent Objects through Scattering Medium Using Generative Adversarial Network. (arXiv:2107.11574v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lai_X/0/1/0/all/0/1">Xuetian Lai</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Q/0/1/0/all/0/1">Qiongyao Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1">Ziyang Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Shao_X/0/1/0/all/0/1">Xiaopeng Shao</a>, <a href="http://arxiv.org/find/eess/1/au:+Pu_J/0/1/0/all/0/1">Jixiong Pu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11574">
                                    <div class="article-summary-box-inner">
                                        <span>Reconstruction of image by using convolutional neural networks (CNNs) has
been vigorously studied in the last decade. Until now, there have being
developed several techniques for imaging of a single object through scattering
medium by using neural networks, however how to reconstruct images of more than
one object simultaneously seems hard to realize. In this paper, we demonstrate
an approach by using generative adversarial network (GAN) to reconstruct images
of two adjacent objects through scattering media. We construct an imaging
system for imaging of two adjacent objects behind the scattering media. In
general, as the light field of two adjacent object images pass through the
scattering slab, a speckle pattern is obtained. The designed adversarial
network, which is called as YGAN, is employed to reconstruct the images
simultaneously. It is shown that based on the trained YGAN, we can reconstruct
images of two adjacent objects from one speckle pattern with high fidelity. In
addition, we study the influence of the object image types, and the distance
between the two adjacent objects on the fidelity of the reconstructed images.
Moreover even if another scattering medium is inserted between the two objects,
we can also reconstruct the images of two objects from a speckle with high
quality. The technique presented in this work can be used for applications in
areas of medical image analysis, such as medical image classification,
segmentation, and studies of multi-object scattering imaging etc.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic-guided Pixel Sampling for Cloth-Changing Person Re-identification. (arXiv:2107.11522v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_X/0/1/0/all/0/1">Xiujun Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Ge Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruan_W/0/1/0/all/0/1">Weijian Ruan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11522">
                                    <div class="article-summary-box-inner">
                                        <span>Cloth-changing person re-identification (re-ID) is a new rising research
topic that aims at retrieving pedestrians whose clothes are changed. This task
is quite challenging and has not been fully studied to date. Current works
mainly focus on body shape or contour sketch, but they are not robust enough
due to view and posture variations. The key to this task is to exploit
cloth-irrelevant cues. This paper proposes a semantic-guided pixel sampling
approach for the cloth-changing person re-ID task. We do not explicitly define
which feature to extract but force the model to automatically learn
cloth-irrelevant cues. Specifically, we first recognize the pedestrian&#x27;s upper
clothes and pants, then randomly change them by sampling pixels from other
pedestrians. The changed samples retain the identity labels but exchange the
pixels of clothes or pants among different pedestrians. Besides, we adopt a
loss function to constrain the learned features to keep consistent before and
after changes. In this way, the model is forced to learn cues that are
irrelevant to upper clothes and pants. We conduct extensive experiments on the
latest released PRCC dataset. Our method achieved 65.8% on Rank1 accuracy,
which outperforms previous methods with a large margin. The code is available
at https://github.com/shuxjweb/pixel_sampling.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Going Deeper into Semi-supervised Person Re-identification. (arXiv:2107.11566v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moskvyak_O/0/1/0/all/0/1">Olga Moskvyak</a>, <a href="http://arxiv.org/find/cs/1/au:+Maire_F/0/1/0/all/0/1">Frederic Maire</a>, <a href="http://arxiv.org/find/cs/1/au:+Dayoub_F/0/1/0/all/0/1">Feras Dayoub</a>, <a href="http://arxiv.org/find/cs/1/au:+Baktashmotlagh_M/0/1/0/all/0/1">Mahsa Baktashmotlagh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11566">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification is the challenging task of identifying a person
across different camera views. Training a convolutional neural network (CNN)
for this task requires annotating a large dataset, and hence, it involves the
time-consuming manual matching of people across cameras. To reduce the need for
labeled data, we focus on a semi-supervised approach that requires only a
subset of the training data to be labeled. We conduct a comprehensive survey in
the area of person re-identification with limited labels. Existing works in
this realm are limited in the sense that they utilize features from multiple
CNNs and require the number of identities in the unlabeled data to be known. To
overcome these limitations, we propose to employ part-based features from a
single CNN without requiring the knowledge of the label space (i.e., the number
of identities). This makes our approach more suitable for practical scenarios,
and it significantly reduces the need for computational resources. We also
propose a PartMixUp loss that improves the discriminative ability of learned
part-based features for pseudo-labeling in semi-supervised settings. Our method
outperforms the state-of-the-art results on three large-scale person re-id
datasets and achieves the same level of performance as fully supervised methods
with only one-third of labeled identities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual-Attention Enhanced BDense-UNet for Liver Lesion Segmentation. (arXiv:2107.11645v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cao_W/0/1/0/all/0/1">Wenming Cao</a>, <a href="http://arxiv.org/find/eess/1/au:+Yu_P/0/1/0/all/0/1">Philip L.H. Yu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lui_G/0/1/0/all/0/1">Gilbert C.S. Lui</a>, <a href="http://arxiv.org/find/eess/1/au:+Chiu_K/0/1/0/all/0/1">Keith W.H. Chiu</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheng_H/0/1/0/all/0/1">Ho-Ming Cheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Fang_Y/0/1/0/all/0/1">Yanwen Fang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yuen_M/0/1/0/all/0/1">Man-Fung Yuen</a>, <a href="http://arxiv.org/find/eess/1/au:+Seto_W/0/1/0/all/0/1">Wai-Kay Seto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11645">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose a new segmentation network by integrating DenseUNet
and bidirectional LSTM together with attention mechanism, termed as
DA-BDense-UNet. DenseUNet allows learning enough diverse features and enhancing
the representative power of networks by regulating the information flow.
Bidirectional LSTM is responsible to explore the relationships between the
encoded features and the up-sampled features in the encoding and decoding
paths. Meanwhile, we introduce attention gates (AG) into DenseUNet to diminish
responses of unrelated background regions and magnify responses of salient
regions progressively. Besides, the attention in bidirectional LSTM takes into
account the contribution differences of the encoded features and the up-sampled
features in segmentation improvement, which can in turn adjust proper weights
for these two kinds of features. We conduct experiments on liver CT image data
sets collected from multiple hospitals by comparing them with state-of-the-art
segmentation models. Experimental results indicate that our proposed method
DA-BDense-UNet has achieved comparative performance in terms of dice
coefficient, which demonstrates its effectiveness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TinyAction Challenge: Recognizing Real-world Low-resolution Activities in Videos. (arXiv:2107.11494v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tirupattur_P/0/1/0/all/0/1">Praveen Tirupattur</a>, <a href="http://arxiv.org/find/cs/1/au:+Rana_A/0/1/0/all/0/1">Aayush J Rana</a>, <a href="http://arxiv.org/find/cs/1/au:+Sangam_T/0/1/0/all/0/1">Tushar Sangam</a>, <a href="http://arxiv.org/find/cs/1/au:+Vyas_S/0/1/0/all/0/1">Shruti Vyas</a>, <a href="http://arxiv.org/find/cs/1/au:+Rawat_Y/0/1/0/all/0/1">Yogesh S Rawat</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Mubarak Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11494">
                                    <div class="article-summary-box-inner">
                                        <span>This paper summarizes the TinyAction challenge which was organized in
ActivityNet workshop at CVPR 2021. This challenge focuses on recognizing
real-world low-resolution activities present in videos. Action recognition task
is currently focused around classifying the actions from high-quality videos
where the actors and the action is clearly visible. While various approaches
have been shown effective for recognition task in recent works, they often do
not deal with videos of lower resolution where the action is happening in a
tiny region. However, many real world security videos often have the actual
action captured in a small resolution, making action recognition in a tiny
region a challenging task. In this work, we propose a benchmark dataset,
TinyVIRAT-v2, which is comprised of naturally occuring low-resolution actions.
This is an extension of the TinyVIRAT dataset and consists of actions with
multiple labels. The videos are extracted from security videos which makes them
realistic and more challenging. We use current state-of-the-art action
recognition methods on the dataset as a benchmark, and propose the TinyAction
Challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Clustering by Maximizing Mutual Information Across Views. (arXiv:2107.11635v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Do_K/0/1/0/all/0/1">Kien Do</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1">Truyen Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1">Svetha Venkatesh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11635">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel framework for image clustering that incorporates joint
representation learning and clustering. Our method consists of two heads that
share the same backbone network - a &quot;representation learning&quot; head and a
&quot;clustering&quot; head. The &quot;representation learning&quot; head captures fine-grained
patterns of objects at the instance level which serve as clues for the
&quot;clustering&quot; head to extract coarse-grain information that separates objects
into clusters. The whole model is trained in an end-to-end manner by minimizing
the weighted sum of two sample-oriented contrastive losses applied to the
outputs of the two heads. To ensure that the contrastive loss corresponding to
the &quot;clustering&quot; head is optimal, we introduce a novel critic function called
&quot;log-of-dot-product&quot;. Extensive experimental results demonstrate that our
method significantly outperforms state-of-the-art single-stage clustering
methods across a variety of image datasets, improving over the best baseline by
about 5-7% in accuracy on CIFAR10/20, STL10, and ImageNet-Dogs. Further, the
&quot;two-stage&quot; variant of our method also achieves better results than baselines
on three challenging ImageNet subsets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using a Cross-Task Grid of Linear Probes to Interpret CNN Model Predictions On Retinal Images. (arXiv:2107.11468v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blumer_K/0/1/0/all/0/1">Katy Blumer</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopalan_S/0/1/0/all/0/1">Subhashini Venugopalan</a>, <a href="http://arxiv.org/find/cs/1/au:+Brenner_M/0/1/0/all/0/1">Michael P. Brenner</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1">Jon Kleinberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11468">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze a dataset of retinal images using linear probes: linear regression
models trained on some &quot;target&quot; task, using embeddings from a deep
convolutional (CNN) model trained on some &quot;source&quot; task as input. We use this
method across all possible pairings of 93 tasks in the UK Biobank dataset of
retinal images, leading to ~164k different models. We analyze the performance
of these linear probes by source and target task and by layer depth. We observe
that representations from the middle layers of the network are more
generalizable. We find that some target tasks are easily predicted irrespective
of the source task, and that some other target tasks are more accurately
predicted from correlated source tasks than from embeddings trained on the same
task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compressing Neural Networks: Towards Determining the Optimal Layer-wise Decomposition. (arXiv:2107.11442v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liebenwein_L/0/1/0/all/0/1">Lucas Liebenwein</a>, <a href="http://arxiv.org/find/cs/1/au:+Maalouf_A/0/1/0/all/0/1">Alaa Maalouf</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_O/0/1/0/all/0/1">Oren Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_D/0/1/0/all/0/1">Dan Feldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1">Daniela Rus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11442">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel global compression framework for deep neural networks that
automatically analyzes each layer to identify the optimal per-layer compression
ratio, while simultaneously achieving the desired overall compression. Our
algorithm hinges on the idea of compressing each convolutional (or
fully-connected) layer by slicing its channels into multiple groups and
decomposing each group via low-rank decomposition. At the core of our algorithm
is the derivation of layer-wise error bounds from the Eckart Young Mirsky
theorem. We then leverage these bounds to frame the compression problem as an
optimization problem where we wish to minimize the maximum compression error
across layers and propose an efficient algorithm towards a solution. Our
experiments indicate that our method outperforms existing low-rank compression
approaches across a wide range of networks and data sets. We believe that our
results open up new avenues for future research into the global
performance-size trade-offs of modern neural networks. Our code is available at
https://github.com/lucaslie/torchprune.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Variational Autoencoder based Out-of-Distribution Detection for Embedded Real-time Applications. (arXiv:2107.11750v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yeli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_D/0/1/0/all/0/1">Daniel Jun Xian Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Easwaran_A/0/1/0/all/0/1">Arvind Easwaran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11750">
                                    <div class="article-summary-box-inner">
                                        <span>Uncertainties in machine learning are a significant roadblock for its
application in safety-critical cyber-physical systems (CPS). One source of
uncertainty arises from distribution shifts in the input data between training
and test scenarios. Detecting such distribution shifts in real-time is an
emerging approach to address the challenge. The high dimensional input space in
CPS applications involving imaging adds extra difficulty to the task.
Generative learning models are widely adopted for the task, namely
out-of-distribution (OoD) detection. To improve the state-of-the-art, we
studied existing proposals from both machine learning and CPS fields. In the
latter, safety monitoring in real-time for autonomous driving agents has been a
focus. Exploiting the spatiotemporal correlation of motion in videos, we can
robustly detect hazardous motion around autonomous driving agents. Inspired by
the latest advances in the Variational Autoencoder (VAE) theory and practice,
we tapped into the prior knowledge in data to further boost OoD detection&#x27;s
robustness. Comparison studies over nuScenes and Synthia data sets show our
methods significantly improve detection capabilities of OoD factors unique to
driving scenarios, 42% better than state-of-the-art approaches. Our model also
generalized near-perfectly, 97% better than the state-of-the-art across the
real-world and simulation driving data sets experimented. Finally, we
customized one proposed method into a twin-encoder model that can be deployed
to resource limited embedded devices for real-time OoD detection. Its execution
time was reduced over four times in low-precision 8-bit integer inference,
while detection capability is comparable to its corresponding floating-point
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting Video Captioning with Dynamic Loss Network. (arXiv:2107.11707v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nasibullah/0/1/0/all/0/1">Nasibullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohanta_P/0/1/0/all/0/1">Partha Pratim Mohanta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11707">
                                    <div class="article-summary-box-inner">
                                        <span>Video captioning is one of the challenging problems at the intersection of
vision and language, having many real-life applications in video retrieval,
video surveillance, assisting visually challenged people, Human-machine
interface, and many more. Recent deep learning-based methods have shown
promising results but are still on the lower side than other vision tasks (such
as image classification, object detection). A significant drawback with
existing video captioning methods is that they are optimized over cross-entropy
loss function, which is uncorrelated to the de facto evaluation metrics (BLEU,
METEOR, CIDER, ROUGE).In other words, cross-entropy is not a proper surrogate
of the true loss function for video captioning. This paper addresses the
drawback by introducing a dynamic loss network (DLN), which provides an
additional feedback signal that directly reflects the evaluation metrics. Our
results on Microsoft Research Video Description Corpus (MSVD) and MSR-Video to
Text (MSRVTT) datasets outperform previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Action be Imitated? Learn to Reconstruct and Transfer Human Dynamics from Videos. (arXiv:2107.11756v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yuqian Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu-Gang Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11756">
                                    <div class="article-summary-box-inner">
                                        <span>Given a video demonstration, can we imitate the action contained in this
video? In this paper, we introduce a novel task, dubbed mesh-based action
imitation. The goal of this task is to enable an arbitrary target human mesh to
perform the same action shown on the video demonstration. To achieve this, a
novel Mesh-based Video Action Imitation (M-VAI) method is proposed by us. M-VAI
first learns to reconstruct the meshes from the given source image frames, then
the initial recovered mesh sequence is fed into mesh2mesh, a mesh sequence
smooth module proposed by us, to improve the temporal consistency. Finally, we
imitate the actions by transferring the pose from the constructed human body to
our target identity mesh. High-quality and detailed human body meshes can be
generated by using our M-VAI. Extensive experiments demonstrate the feasibility
of our task and the effectiveness of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal-wise Attention Spiking Neural Networks for Event Streams Classification. (arXiv:2107.11711v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_M/0/1/0/all/0/1">Man Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_H/0/1/0/all/0/1">Huanhuan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guangshe Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dingheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yihan Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhaoxu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guoqi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11711">
                                    <div class="article-summary-box-inner">
                                        <span>How to effectively and efficiently deal with spatio-temporal event streams,
where the events are generally sparse and non-uniform and have the microsecond
temporal resolution, is of great value and has various real-life applications.
Spiking neural network (SNN), as one of the brain-inspired event-triggered
computing models, has the potential to extract effective spatio-temporal
features from the event streams. However, when aggregating individual events
into frames with a new higher temporal resolution, existing SNN models do not
attach importance to that the serial frames have different signal-to-noise
ratios since event streams are sparse and non-uniform. This situation
interferes with the performance of existing SNNs. In this work, we propose a
temporal-wise attention SNN (TA-SNN) model to learn frame-based representation
for processing event streams. Concretely, we extend the attention concept to
temporal-wise input to judge the significance of frames for the final decision
at the training stage, and discard the irrelevant frames at the inference
stage. We demonstrate that TA-SNN models improve the accuracy of event streams
classification tasks. We also study the impact of multiple-scale temporal
resolutions for frame-based representation. Our approach is tested on three
different classification tasks: gesture recognition, image classification, and
spoken digit recognition. We report the state-of-the-art results on these
tasks, and get the essential improvement of accuracy (almost 19\%) for gesture
recognition with only 60 ms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Attention and Scale Complementary Network for Instance Segmentation in Remote Sensing Images. (arXiv:2107.11758v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiangrong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1">Peng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Licheng Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11758">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we focus on the challenging multicategory instance
segmentation problem in remote sensing images (RSIs), which aims at predicting
the categories of all instances and localizing them with pixel-level masks.
Although many landmark frameworks have demonstrated promising performance in
instance segmentation, the complexity in the background and scale variability
instances still remain challenging for instance segmentation of RSIs. To
address the above problems, we propose an end-to-end multi-category instance
segmentation model, namely Semantic Attention and Scale Complementary Network,
which mainly consists of a Semantic Attention (SEA) module and a Scale
Complementary Mask Branch (SCMB). The SEA module contains a simple fully
convolutional semantic segmentation branch with extra supervision to strengthen
the activation of interest instances on the feature map and reduce the
background noise&#x27;s interference. To handle the under-segmentation of geospatial
instances with large varying scales, we design the SCMB that extends the
original single mask branch to trident mask branches and introduces
complementary mask supervision at different scales to sufficiently leverage the
multi-scale information. We conduct comprehensive experiments to evaluate the
effectiveness of our proposed method on the iSAID dataset and the NWPU Instance
Segmentation dataset and achieve promising performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial training may be a double-edged sword. (arXiv:2107.11671v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahmati_A/0/1/0/all/0/1">Ali Rahmati</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosavi_Dezfooli_S/0/1/0/all/0/1">Seyed-Mohsen Moosavi-Dezfooli</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Huaiyu Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11671">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training has been shown as an effective approach to improve the
robustness of image classifiers against white-box attacks. However, its
effectiveness against black-box attacks is more nuanced. In this work, we
demonstrate that some geometric consequences of adversarial training on the
decision boundary of deep networks give an edge to certain types of black-box
attacks. In particular, we define a metric called robustness gain to show that
while adversarial training is an effective method to dramatically improve the
robustness in white-box scenarios, it may not provide such a good robustness
gain against the more realistic decision-based black-box attacks. Moreover, we
show that even the minimal perturbation white-box attacks can converge faster
against adversarially-trained neural networks compared to the regular ones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PoseFace: Pose-Invariant Features and Pose-Adaptive Loss for Face Recognition. (arXiv:2107.11721v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1">Qiang Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaqing Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaobo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yang Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Y/0/1/0/all/0/1">Yunxiao Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zezheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1">Chenxu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_F/0/1/0/all/0/1">Feng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1">Zhen Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11721">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the great success achieved by deep learning methods in face
recognition, severe performance drops are observed for large pose variations in
unconstrained environments (e.g., in cases of surveillance and photo-tagging).
To address it, current methods either deploy pose-specific models or frontalize
faces by additional modules. Still, they ignore the fact that identity
information should be consistent across poses and are not realizing the data
imbalance between frontal and profile face images during training. In this
paper, we propose an efficient PoseFace framework which utilizes the facial
landmarks to disentangle the pose-invariant features and exploits a
pose-adaptive loss to handle the imbalance issue adaptively. Extensive
experimental results on the benchmarks of Multi-PIE, CFP, CPLFW and IJB have
demonstrated the superiority of our method over the state-of-the-arts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hand Image Understanding via Deep Multi-Task Learning. (arXiv:2107.11646v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1">Zhang Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Hongsheng_H/0/1/0/all/0/1">Huang Hongsheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jianchao_T/0/1/0/all/0/1">Tan Jianchao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hongmin_X/0/1/0/all/0/1">Xu Hongmin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yang Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guozhu_P/0/1/0/all/0/1">Peng Guozhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_W/0/1/0/all/0/1">Wang Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1">Liu Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11646">
                                    <div class="article-summary-box-inner">
                                        <span>Analyzing and understanding hand information from multimedia materials like
images or videos is important for many real world applications and remains
active in research community. There are various works focusing on recovering
hand information from single image, however, they usually solve a single task,
for example, hand mask segmentation, 2D/3D hand pose estimation, or hand mesh
reconstruction and perform not well in challenging scenarios. To further
improve the performance of these tasks, we propose a novel Hand Image
Understanding (HIU) framework to extract comprehensive information of the hand
object from a single RGB image, by jointly considering the relationships
between these tasks. To achieve this goal, a cascaded multi-task learning (MTL)
backbone is designed to estimate the 2D heat maps, to learn the segmentation
mask, and to generate the intermediate 3D information encoding, followed by a
coarse-to-fine learning paradigm and a self-supervised learning strategy.
Qualitative experiments demonstrate that our approach is capable of recovering
reasonable mesh representations even in challenging situations. Quantitatively,
our method significantly outperforms the state-of-the-art approaches on various
widely-used datasets, in terms of diverse evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Real Use Case of Semi-Supervised Learning for Mammogram Classification in a Local Clinic of Costa Rica. (arXiv:2107.11696v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Calderon_Ramirez_S/0/1/0/all/0/1">Saul Calderon-Ramirez</a>, <a href="http://arxiv.org/find/eess/1/au:+Murillo_Hernandez_D/0/1/0/all/0/1">Diego Murillo-Hernandez</a>, <a href="http://arxiv.org/find/eess/1/au:+Rojas_Salazar_K/0/1/0/all/0/1">Kevin Rojas-Salazar</a>, <a href="http://arxiv.org/find/eess/1/au:+Elizondo_D/0/1/0/all/0/1">David Elizondo</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_S/0/1/0/all/0/1">Shengxiang Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Molina_Cabello_M/0/1/0/all/0/1">Miguel Molina-Cabello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11696">
                                    <div class="article-summary-box-inner">
                                        <span>The implementation of deep learning based computer aided diagnosis systems
for the classification of mammogram images can help in improving the accuracy,
reliability, and cost of diagnosing patients. However, training a deep learning
model requires a considerable amount of labeled images, which can be expensive
to obtain as time and effort from clinical practitioners is required. A number
of publicly available datasets have been built with data from different
hospitals and clinics. However, using models trained on these datasets for
later work on images sampled from a different hospital or clinic might result
in lower performance. This is due to the distribution mismatch of the datasets,
which include different patient populations and image acquisition protocols.
The scarcity of labeled data can also bring a challenge towards the application
of transfer learning with models trained using these source datasets. In this
work, a real world scenario is evaluated where a novel target dataset sampled
from a private Costa Rican clinic is used, with few labels and heavily
imbalanced data. The use of two popular and publicly available datasets
(INbreast and CBIS-DDSM) as source data, to train and test the models on the
novel target dataset, is evaluated. The use of the semi-supervised deep
learning approach known as MixMatch, to leverage the usage of unlabeled data
from the target dataset, is proposed and evaluated. In the tests, the
performance of models is extensively measured, using different metrics to
assess the performance of a classifier under heavy data imbalance conditions.
It is shown that the use of semi-supervised deep learning combined with
fine-tuning can provide a meaningful advantage when using scarce labeled
observations. We make available the novel dataset for the benefit of the
community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rank &amp; Sort Loss for Object Detection and Instance Segmentation. (arXiv:2107.11669v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oksuz_K/0/1/0/all/0/1">Kemal Oksuz</a>, <a href="http://arxiv.org/find/cs/1/au:+Cam_B/0/1/0/all/0/1">Baris Can Cam</a>, <a href="http://arxiv.org/find/cs/1/au:+Akbas_E/0/1/0/all/0/1">Emre Akbas</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalkan_S/0/1/0/all/0/1">Sinan Kalkan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11669">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Rank &amp; Sort (RS) Loss, as a ranking-based loss function to train
deep object detection and instance segmentation methods (i.e. visual
detectors). RS Loss supervises the classifier, a sub-network of these methods,
to rank each positive above all negatives as well as to sort positives among
themselves with respect to (wrt.) their continuous localisation qualities (e.g.
Intersection-over-Union - IoU). To tackle the non-differentiable nature of
ranking and sorting, we reformulate the incorporation of error-driven update
with backpropagation as Identity Update, which enables us to model our novel
sorting error among positives. With RS Loss, we significantly simplify
training: (i) Thanks to our sorting objective, the positives are prioritized by
the classifier without an additional auxiliary head (e.g. for centerness, IoU,
mask-IoU), (ii) due to its ranking-based nature, RS Loss is robust to class
imbalance, and thus, no sampling heuristic is required, and (iii) we address
the multi-task nature of visual detectors using tuning-free task-balancing
coefficients. Using RS Loss, we train seven diverse visual detectors only by
tuning the learning rate, and show that it consistently outperforms baselines:
e.g. our RS Loss improves (i) Faster R-CNN by ~ 3 box AP and aLRP Loss
(ranking-based baseline) by ~ 2 box AP on COCO dataset, (ii) Mask R-CNN with
repeat factor sampling (RFS) by 3.5 mask AP (~ 7 AP for rare classes) on LVIS
dataset; and also outperforms all counterparts. Code available at
https://github.com/kemaloksuz/RankSortLoss</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ContextNet: A Click-Through Rate Prediction Framework Using Contextual information to Refine Feature Embedding. (arXiv:2107.12025v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qingyun She</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">PengTao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junlin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12025">
                                    <div class="article-summary-box-inner">
                                        <span>Click-through rate (CTR) estimation is a fundamental task in personalized
advertising and recommender systems and it&#x27;s important for ranking models to
effectively capture complex high-order features.Inspired by the success of ELMO
and Bert in NLP field, which dynamically refine word embedding according to the
context sentence information where the word appears, we think it&#x27;s also
important to dynamically refine each feature&#x27;s embedding layer by layer
according to the context information contained in input instance in CTR
estimation tasks. We can effectively capture the useful feature interactions
for each feature in this way. In this paper, We propose a novel CTR Framework
named ContextNet that implicitly models high-order feature interactions by
dynamically refining each feature&#x27;s embedding according to the input context.
Specifically, ContextNet consists of two key components: contextual embedding
module and ContextNet block. Contextual embedding module aggregates contextual
information for each feature from input instance and ContextNet block maintains
each feature&#x27;s embedding layer by layer and dynamically refines its
representation by merging contextual high-order interaction information into
feature embedding. To make the framework specific, we also propose two
models(ContextNet-PFFN and ContextNet-SFFN) under this framework by introducing
linear contextual embedding network and two non-linear mapping sub-network in
ContextNet block. We conduct extensive experiments on four real-world datasets
and the experiment results demonstrate that our proposed ContextNet-PFFN and
ContextNet-SFFN model outperform state-of-the-art models such as DeepFM and
xDeepFM significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Form 10-Q Itemization. (arXiv:2104.11783v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yanci Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_T/0/1/0/all/0/1">Tianming Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yujie Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Donohue_L/0/1/0/all/0/1">Lawrence Donohue</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_R/0/1/0/all/0/1">Rui Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11783">
                                    <div class="article-summary-box-inner">
                                        <span>The quarterly financial statement, or Form 10-Q, is one of the most
frequently required filings for US public companies to disclose financial and
other important business information. Due to the massive volume of 10-Q filings
and the enormous variations in the reporting format, it has been a
long-standing challenge to retrieve item-specific information from 10-Q filings
that lack machine-readable hierarchy. This paper presents a solution for
itemizing 10-Q files by complementing a rule-based algorithm with a
Convolutional Neural Network (CNN) image classifier. This solution demonstrates
a pipeline that can be generalized to a rapid data retrieval solution among a
large volume of textual data using only typographic items. The extracted
textual data can be used as unlabeled content-specific data to train
transformer models (e.g., BERT) or fit into various field-focus natural
language processing (NLP) applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leaf-FM: A Learnable Feature Generation Factorization Machine for Click-Through Rate Prediction. (arXiv:2107.12024v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qingyun She</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junlin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12024">
                                    <div class="article-summary-box-inner">
                                        <span>Click-through rate (CTR) prediction plays important role in personalized
advertising and recommender systems. Though many models have been proposed such
as FM, FFM and DeepFM in recent years, feature engineering is still a very
important way to improve the model performance in many applications because
using raw features can rarely lead to optimal results. For example, the
continuous features are usually transformed to the power forms by adding a new
feature to allow it to easily form non-linear functions of the feature.
However, this kind of feature engineering heavily relies on peoples experience
and it is both time consuming and labor consuming. On the other side, concise
CTR model with both fast online serving speed and good model performance is
critical for many real life applications. In this paper, we propose LeafFM
model based on FM to generate new features from the original feature embedding
by learning the transformation functions automatically. We also design three
concrete Leaf-FM models according to the different strategies of combing the
original and the generated features. Extensive experiments are conducted on
three real-world datasets and the results show Leaf-FM model outperforms
standard FMs by a large margin. Compared with FFMs, Leaf-FM can achieve
significantly better performance with much less parameters. In Avazu and
Malware dataset, add version Leaf-FM achieves comparable performance with some
deep learning based models such as DNN and AutoInt. As an improved FM model,
Leaf-FM has the same computation complexity with FM in online serving phase and
it means Leaf-FM is applicable in many industry applications because of its
better performance and high computation efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MaskNet: Introducing Feature-Wise Multiplication to CTR Ranking Models by Instance-Guided Mask. (arXiv:2102.07619v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiqiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qingyun She</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junlin Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07619">
                                    <div class="article-summary-box-inner">
                                        <span>Click-Through Rate(CTR) estimation has become one of the most fundamental
tasks in many real-world applications and it&#x27;s important for ranking models to
effectively capture complex high-order features. Shallow feed-forward network
is widely used in many state-of-the-art DNN models such as FNN, DeepFM and
xDeepFM to implicitly capture high-order feature interactions. However, some
research has proved that addictive feature interaction, particular feed-forward
neural networks, is inefficient in capturing common feature interaction. To
resolve this problem, we introduce specific multiplicative operation into DNN
ranking system by proposing instance-guided mask which performs element-wise
product both on the feature embedding and feed-forward layers guided by input
instance. We also turn the feed-forward layer in DNN model into a mixture of
addictive and multiplicative feature interactions by proposing MaskBlock in
this paper. MaskBlock combines the layer normalization, instance-guided mask,
and feed-forward layer and it is a basic building block to be used to design
new ranking model under various configurations. The model consisting of
MaskBlock is called MaskNet in this paper and two new MaskNet models are
proposed to show the effectiveness of MaskBlock as basic building block for
composing high performance ranking systems. The experiment results on three
real-world datasets demonstrate that our proposed MaskNet models outperform
state-of-the-art models such as DeepFM and xDeepFM significantly, which implies
MaskBlock is an effective basic building unit for composing new high
performance ranking systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Argumentative Dialogue System for COVID-19 Vaccine Information. (arXiv:2107.12079v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fazzinga_B/0/1/0/all/0/1">Bettina Fazzinga</a>, <a href="http://arxiv.org/find/cs/1/au:+Galassi_A/0/1/0/all/0/1">Andrea Galassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torroni_P/0/1/0/all/0/1">Paolo Torroni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12079">
                                    <div class="article-summary-box-inner">
                                        <span>Dialogue systems are widely used in AI to support timely and interactive
communication with users. We propose a general-purpose dialogue system
architecture that leverages computational argumentation and state-of-the-art
language technologies. We illustrate and evaluate the system using a COVID-19
vaccine information case study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid Autoregressive Solver for Scalable Abductive Natural Language Inference. (arXiv:2107.11879v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Valentino_M/0/1/0/all/0/1">Marco Valentino</a>, <a href="http://arxiv.org/find/cs/1/au:+Thayaparan_M/0/1/0/all/0/1">Mokanarangan Thayaparan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferreira_D/0/1/0/all/0/1">Deborah Ferreira</a>, <a href="http://arxiv.org/find/cs/1/au:+Freitas_A/0/1/0/all/0/1">Andr&#xe9; Freitas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11879">
                                    <div class="article-summary-box-inner">
                                        <span>Regenerating natural language explanations for science questions is a
challenging task for evaluating complex multi-hop and abductive inference
capabilities. In this setting, Transformers trained on human-annotated
explanations achieve state-of-the-art performance when adopted as cross-encoder
architectures. However, while much attention has been devoted to the quality of
the constructed explanations, the problem of performing abductive inference at
scale is still under-studied. As intrinsically not scalable, the cross-encoder
architectural paradigm is not suitable for efficient multi-hop inference on
massive facts banks. To maximise both accuracy and inference time, we propose a
hybrid abductive solver that autoregressively combines a dense bi-encoder with
a sparse model of explanatory power, computed leveraging explicit patterns in
the explanations. Our experiments demonstrate that the proposed framework can
achieve performance comparable with the state-of-the-art cross-encoder while
being $\approx 50$ times faster and scalable to corpora of millions of facts.
Moreover, we study the impact of the hybridisation on semantic drift and
science question answering without additional training, showing that it boosts
the quality of the explanations and contributes to improved downstream
inference performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Recommend Items to Wikidata Editors. (arXiv:2107.06423v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+AlGhamdi_K/0/1/0/all/0/1">Kholoud AlGhamdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1">Miaojing Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Simperl_E/0/1/0/all/0/1">Elena Simperl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06423">
                                    <div class="article-summary-box-inner">
                                        <span>Wikidata is an open knowledge graph built by a global community of
volunteers. As it advances in scale, it faces substantial challenges around
editor engagement. These challenges are in terms of both attracting new editors
to keep up with the sheer amount of work and retaining existing editors.
Experience from other online communities and peer-production systems, including
Wikipedia, suggests that personalised recommendations could help, especially
newcomers, who are sometimes unsure about how to contribute best to an ongoing
effort. For this reason, we propose a recommender system WikidataRec for
Wikidata items. The system uses a hybrid of content-based and collaborative
filtering techniques to rank items for editors relying on both item features
and item-editor previous interaction. A neural network, named a neural mixture
of representations, is designed to learn fine weights for the combination of
item-based representations and optimize them with editor-based representation
by item-editor interaction. To facilitate further research in this space, we
also create two benchmark datasets, a general-purpose one with 220,000 editors
responsible for 14 million interactions with 4 million items and a second one
focusing on the contributions of more than 8,000 more active editors. We
perform an offline evaluation of the system on both datasets with promising
results. Our code and datasets are available at
https://github.com/WikidataRec-developer/Wikidata_Recommender.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Bangla Natural Language Processing Tasks and the Utility of Transformer Models. (arXiv:2107.03844v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1">Firoj Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Arid Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1">Tanvirul Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Akib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tajrin_J/0/1/0/all/0/1">Janntatul Tajrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naira Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03844">
                                    <div class="article-summary-box-inner">
                                        <span>Bangla -- ranked as the 6th most widely spoken language across the world
(https://www.ethnologue.com/guides/ethnologue200), with 230 million native
speakers -- is still considered as a low-resource language in the natural
language processing (NLP) community. With three decades of research, Bangla NLP
(BNLP) is still lagging behind mainly due to the scarcity of resources and the
challenges that come with it. There is sparse work in different areas of BNLP;
however, a thorough survey reporting previous work and recent advances is yet
to be done. In this study, we first provide a review of Bangla NLP tasks,
resources, and tools available to the research community; we benchmark datasets
collected from various platforms for nine NLP tasks using current
state-of-the-art algorithms (i.e., transformer-based models). We provide
comparative results for the studied NLP tasks by comparing monolingual vs.
multilingual models of varying sizes. We report our results using both
individual and consolidated datasets and provide data splits for future
research. We reviewed a total of 108 papers and conducted 175 sets of
experiments. Our results show promising performance using transformer-based
models while highlighting the trade-off with computational costs. We hope that
such a comprehensive survey will motivate the community to build on and further
advance the research on Bangla NLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Content-based Music Recommendation: Evolution, State of the Art, and Challenges. (arXiv:2107.11803v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deldjoo_Y/0/1/0/all/0/1">Yashar Deldjoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Schedl_M/0/1/0/all/0/1">Markus Schedl</a>, <a href="http://arxiv.org/find/cs/1/au:+Knees_P/0/1/0/all/0/1">Peter Knees</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11803">
                                    <div class="article-summary-box-inner">
                                        <span>The music domain is among the most important ones for adopting recommender
systems technology. In contrast to most other recommendation domains, which
predominantly rely on collaborative filtering (CF) techniques, music
recommenders have traditionally embraced content-based (CB) approaches. In the
past years, music recommendation models that leverage collaborative and content
data -- which we refer to as content-driven models -- have been replacing pure
CF or CB models.

In this survey, we review 47 articles on content-driven music recommendation.
Based on a thorough literature analysis, we first propose an onion model
comprising five layers, each of which corresponds to a category of music
content we identified: signal, embedded metadata, expert-generated content,
user-generated content, and derivative content. We provide a detailed
characterization of each category along several dimensions. Second, we identify
six overarching challenges, according to which we organize our main discussion:
increasing recommendation diversity and novelty, providing transparency and
explanations, accomplishing context-awareness, recommending sequences of music,
improving scalability and efficiency, and alleviating cold start. Each article
addressing one or more of these challenges is categorized according to the
content layers of our onion model, the article&#x27;s goal(s), and main
methodological choices. Furthermore, articles are discussed in temporal order
to shed light on the evolution of content-driven music recommendation
strategies. Finally, we provide our personal selection of the persisting grand
challenges, which are still waiting to be solved in future research endeavors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can the Crowd Judge Truthfulness? A Longitudinal Study on Recent Misinformation about COVID-19. (arXiv:2107.11755v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roitero_K/0/1/0/all/0/1">Kevin Roitero</a>, <a href="http://arxiv.org/find/cs/1/au:+Soprano_M/0/1/0/all/0/1">Michael Soprano</a>, <a href="http://arxiv.org/find/cs/1/au:+Portelli_B/0/1/0/all/0/1">Beatrice Portelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Luise_M/0/1/0/all/0/1">Massimiliano De Luise</a>, <a href="http://arxiv.org/find/cs/1/au:+Spina_D/0/1/0/all/0/1">Damiano Spina</a>, <a href="http://arxiv.org/find/cs/1/au:+Mea_V/0/1/0/all/0/1">Vincenzo Della Mea</a>, <a href="http://arxiv.org/find/cs/1/au:+Serra_G/0/1/0/all/0/1">Giuseppe Serra</a>, <a href="http://arxiv.org/find/cs/1/au:+Mizzaro_S/0/1/0/all/0/1">Stefano Mizzaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Demartini_G/0/1/0/all/0/1">Gianluca Demartini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11755">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the misinformation problem has been addressed with a
crowdsourcing-based approach: to assess the truthfulness of a statement,
instead of relying on a few experts, a crowd of non-expert is exploited. We
study whether crowdsourcing is an effective and reliable method to assess
truthfulness during a pandemic, targeting statements related to COVID-19, thus
addressing (mis)information that is both related to a sensitive and personal
issue and very recent as compared to when the judgment is done. In our
experiments, crowd workers are asked to assess the truthfulness of statements,
and to provide evidence for the assessments. Besides showing that the crowd is
able to accurately judge the truthfulness of the statements, we report results
on workers behavior, agreement among workers, effect of aggregation functions,
of scales transformations, and of workers background and bias. We perform a
longitudinal study by re-launching the task multiple times with both novice and
experienced workers, deriving important insights on how the behavior and
quality change over time. Our results show that: workers are able to detect and
objectively categorize online (mis)information related to COVID-19; both
crowdsourced and expert judgments can be transformed and aggregated to improve
quality; worker background and other signals (e.g., source of information,
behavior) impact the quality of the data. The longitudinal study demonstrates
that the time-span has a major effect on the quality of the judgments, for both
novice and experienced workers. Finally, we provide an extensive failure
analysis of the statements misjudged by the crowd-workers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generalized Framework for Edge-preserving and Structure-preserving Image Smoothing. (arXiv:2107.07058v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pingping Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1">Yinjie Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaolin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jie Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_M/0/1/0/all/0/1">Michael Ng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07058">
                                    <div class="article-summary-box-inner">
                                        <span>Image smoothing is a fundamental procedure in applications of both computer
vision and graphics. The required smoothing properties can be different or even
contradictive among different tasks. Nevertheless, the inherent smoothing
nature of one smoothing operator is usually fixed and thus cannot meet the
various requirements of different applications. In this paper, we first
introduce the truncated Huber penalty function which shows strong flexibility
under different parameter settings. A generalized framework is then proposed
with the introduced truncated Huber penalty function. When combined with its
strong flexibility, our framework is able to achieve diverse smoothing natures
where contradictive smoothing behaviors can even be achieved. It can also yield
the smoothing behavior that can seldom be achieved by previous methods, and
superior performance is thus achieved in challenging cases. These together
enable our framework capable of a range of applications and able to outperform
the state-of-the-art approaches in several tasks, such as image detail
enhancement, clip-art compression artifacts removal, guided depth map
restoration, image texture removal, etc. In addition, an efficient numerical
solution is provided and its convergence is theoretically guaranteed even the
optimization framework is non-convex and non-smooth. A simple yet effective
approach is further proposed to reduce the computational cost of our method
while maintaining its performance. The effectiveness and superior performance
of our approach are validated through comprehensive experiments in a range of
applications. Our code is available at
https://github.com/wliusjtu/Generalized-Smoothing-Framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Continual Learning for Multi-Domain Hippocampal Segmentation. (arXiv:2107.08751v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Memmel_M/0/1/0/all/0/1">Marius Memmel</a>, <a href="http://arxiv.org/find/eess/1/au:+Gonzalez_C/0/1/0/all/0/1">Camila Gonzalez</a>, <a href="http://arxiv.org/find/eess/1/au:+Mukhopadhyay_A/0/1/0/all/0/1">Anirban Mukhopadhyay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08751">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning for medical imaging suffers from temporal and privacy-related
restrictions on data availability. To still obtain viable models, continual
learning aims to train in sequential order, as and when data is available. The
main challenge that continual learning methods face is to prevent catastrophic
forgetting, i.e., a decrease in performance on the data encountered earlier.
This issue makes continuous training of segmentation models for medical
applications extremely difficult. Yet, often, data from at least two different
domains is available which we can exploit to train the model in a way that it
disregards domain-specific information. We propose an architecture that
leverages the simultaneous availability of two or more datasets to learn a
disentanglement between the content and domain in an adversarial fashion. The
domain-invariant content representation then lays the base for continual
semantic segmentation. Our approach takes inspiration from domain adaptation
and combines it with continual learning for hippocampal segmentation in brain
MRI. We showcase that our method reduces catastrophic forgetting and
outperforms state-of-the-art continual learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finite-time Analysis of Globally Nonstationary Multi-Armed Bandits. (arXiv:2107.11419v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Komiyama_J/0/1/0/all/0/1">Junpei Komiyama</a>, <a href="http://arxiv.org/find/stat/1/au:+Fouche_E/0/1/0/all/0/1">Edouard Fouch&#xe9;</a>, <a href="http://arxiv.org/find/stat/1/au:+Honda_J/0/1/0/all/0/1">Junya Honda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11419">
                                    <div class="article-summary-box-inner">
                                        <span>We consider nonstationary multi-armed bandit problems where the model
parameters of the arms change over time. We introduce the adaptive resetting
bandit (ADR-bandit), which is a class of bandit algorithms that leverages
adaptive windowing techniques from the data stream community. We first provide
new guarantees on the quality of estimators resulting from adaptive windowing
techniques, which are of independent interest in the data mining community.
Furthermore, we conduct a finite-time analysis of ADR-bandit in two typical
environments: an abrupt environment where changes occur instantaneously and a
gradual environment where changes occur progressively. We demonstrate that
ADR-bandit has nearly optimal performance when the abrupt or global changes
occur in a coordinated manner that we call global changes. We demonstrate that
forced exploration is unnecessary when we restrict the interest to the global
changes. Unlike the existing nonstationary bandit algorithms, ADR-bandit has
optimal performance in stationary environments as well as nonstationary
environments with global changes. Our experiments show that the proposed
algorithms outperform the existing approaches in synthetic and real-world
environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Data-driven Software Vulnerability Assessment and Prioritization. (arXiv:2107.08364v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1">Triet H. M. Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Huaming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Babar_M/0/1/0/all/0/1">M. Ali Babar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08364">
                                    <div class="article-summary-box-inner">
                                        <span>Software Vulnerabilities (SVs) are increasing in complexity and scale, posing
great security risks to many software systems. Given the limited resources in
practice, SV assessment and prioritization help practitioners devise optimal SV
mitigation plans based on various SV characteristics. The surge in SV data
sources and data-driven techniques such as Machine Learning and Deep Learning
have taken SV assessment and prioritization to the next level. Our survey
provides a taxonomy of the past research efforts and highlights the best
practices for data-driven SV assessment and prioritization. We also discuss the
current limitations and propose potential solutions to address such issues.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Bangla Natural Language Processing Tasks and the Utility of Transformer Models. (arXiv:2107.03844v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alam_F/0/1/0/all/0/1">Firoj Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasan_A/0/1/0/all/0/1">Arid Hasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Alam_T/0/1/0/all/0/1">Tanvirul Alam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1">Akib Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tajrin_J/0/1/0/all/0/1">Janntatul Tajrin</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naira Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1">Shammur Absar Chowdhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03844">
                                    <div class="article-summary-box-inner">
                                        <span>Bangla -- ranked as the 6th most widely spoken language across the world
(https://www.ethnologue.com/guides/ethnologue200), with 230 million native
speakers -- is still considered as a low-resource language in the natural
language processing (NLP) community. With three decades of research, Bangla NLP
(BNLP) is still lagging behind mainly due to the scarcity of resources and the
challenges that come with it. There is sparse work in different areas of BNLP;
however, a thorough survey reporting previous work and recent advances is yet
to be done. In this study, we first provide a review of Bangla NLP tasks,
resources, and tools available to the research community; we benchmark datasets
collected from various platforms for nine NLP tasks using current
state-of-the-art algorithms (i.e., transformer-based models). We provide
comparative results for the studied NLP tasks by comparing monolingual vs.
multilingual models of varying sizes. We report our results using both
individual and consolidated datasets and provide data splits for future
research. We reviewed a total of 108 papers and conducted 175 sets of
experiments. Our results show promising performance using transformer-based
models while highlighting the trade-off with computational costs. We hope that
such a comprehensive survey will motivate the community to build on and further
advance the research on Bangla NLP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Pretraining for Paraphrase Evaluation. (arXiv:2107.08251v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1">Jack Weston</a>, <a href="http://arxiv.org/find/cs/1/au:+Lenain_R/0/1/0/all/0/1">Raphael Lenain</a>, <a href="http://arxiv.org/find/cs/1/au:+Meepegama_U/0/1/0/all/0/1">Udeepa Meepegama</a>, <a href="http://arxiv.org/find/cs/1/au:+Fristed_E/0/1/0/all/0/1">Emil Fristed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08251">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce ParaBLEU, a paraphrase representation learning model and
evaluation metric for text generation. Unlike previous approaches, ParaBLEU
learns to understand paraphrasis using generative conditioning as a pretraining
objective. ParaBLEU correlates more strongly with human judgements than
existing metrics, obtaining new state-of-the-art results on the 2017 WMT
Metrics Shared Task. We show that our model is robust to data scarcity,
exceeding previous state-of-the-art performance using only $50\%$ of the
available training data and surpassing BLEU, ROUGE and METEOR with only $40$
labelled examples. Finally, we demonstrate that ParaBLEU can be used to
conditionally generate novel paraphrases from a single demonstration, which we
use to confirm our hypothesis that it learns abstract, generalized paraphrase
representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Energy-Efficient Edge Computing Paradigm for Convolution-based Image Upsampling. (arXiv:2107.07647v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Colbert_I/0/1/0/all/0/1">Ian Colbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreutz_Delgado_K/0/1/0/all/0/1">Ken Kreutz-Delgado</a>, <a href="http://arxiv.org/find/cs/1/au:+Das_S/0/1/0/all/0/1">Srinjoy Das</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07647">
                                    <div class="article-summary-box-inner">
                                        <span>A novel energy-efficient edge computing paradigm is proposed for real-time
deep learning-based image upsampling applications. State-of-the-art deep
learning solutions for image upsampling are currently trained using either
resize or sub-pixel convolution to learn kernels that generate high fidelity
images with minimal artifacts. However, performing inference with these learned
convolution kernels requires memory-intensive feature map transformations that
dominate time and energy costs in real-time applications. To alleviate this
pressure on memory bandwidth, we confine the use of resize or sub-pixel
convolution to training in the cloud by transforming learned convolution
kernels to deconvolution kernels before deploying them for inference as a
functionally equivalent deconvolution. These kernel transformations, intended
as a one-time cost when shifting from training to inference, enable a systems
designer to use each algorithm in their optimal context by preserving the image
fidelity learned when training in the cloud while minimizing data transfer
penalties during inference at the edge. We also explore existing variants of
deconvolution inference algorithms and introduce a novel variant for
consideration. We analyze and compare the inference properties of
convolution-based upsampling algorithms using a quantitative model of incurred
time and energy costs and show that using deconvolution for inference at the
edge improves both system latency and energy efficiency when compared to their
sub-pixel or resize convolution counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimising quantifier variance under prior probability shift. (arXiv:2107.08209v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tasche_D/0/1/0/all/0/1">Dirk Tasche</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08209">
                                    <div class="article-summary-box-inner">
                                        <span>For the binary prevalence quantification problem under prior probability
shift, we determine the asymptotic variance of the maximum likelihood
estimator. We find that it is a function of the Brier score for the regression
of the class label against the features under the test data set distribution.
This observation suggests that optimising the accuracy of a base classifier on
the training data set helps to reduce the variance of the related quantifier on
the test data set. Therefore, we also point out training criteria for the base
classifier that imply optimisation of both of the Brier scores on the training
and the test data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Robustness of Deep Reinforcement Learning in IRS-Aided Wireless Communications Systems. (arXiv:2107.08293v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feriani_A/0/1/0/all/0/1">Amal Feriani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mezghani_A/0/1/0/all/0/1">Amine Mezghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_E/0/1/0/all/0/1">Ekram Hossain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08293">
                                    <div class="article-summary-box-inner">
                                        <span>We consider an Intelligent Reflecting Surface (IRS)-aided multiple-input
single-output (MISO) system for downlink transmission. We compare the
performance of Deep Reinforcement Learning (DRL) and conventional optimization
methods in finding optimal phase shifts of the IRS elements to maximize the
user signal-to-noise (SNR) ratio. Furthermore, we evaluate the robustness of
these methods to channel impairments and changes in the system. We demonstrate
numerically that DRL solutions show more robustness to noisy channels and user
mobility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Graph Auto-Encoder Models for Attributed Graph Clustering. (arXiv:2107.08562v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mrabah_N/0/1/0/all/0/1">Nairouz Mrabah</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouguessa_M/0/1/0/all/0/1">Mohamed Bouguessa</a>, <a href="http://arxiv.org/find/cs/1/au:+Touati_M/0/1/0/all/0/1">Mohamed Fawzi Touati</a>, <a href="http://arxiv.org/find/cs/1/au:+Ksantini_R/0/1/0/all/0/1">Riadh Ksantini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08562">
                                    <div class="article-summary-box-inner">
                                        <span>Most recent graph clustering methods have resorted to Graph Auto-Encoders
(GAEs) to perform joint clustering and embedding learning. However, two
critical issues have been overlooked. First, the accumulative error, inflicted
by learning with noisy clustering assignments, degrades the effectiveness and
robustness of the clustering model. This problem is called Feature Randomness.
Second, reconstructing the adjacency matrix sets the model to learn irrelevant
similarities for the clustering task. This problem is called Feature Drift.
Interestingly, the theoretical relation between the aforementioned problems has
not yet been investigated. We study these issues from two aspects: (1) there is
a trade-off between Feature Randomness and Feature Drift when clustering and
reconstruction are performed at the same level, and (2) the problem of Feature
Drift is more pronounced for GAE models, compared with vanilla auto-encoder
models, due to the graph convolutional operation and the graph decoding design.
Motivated by these findings, we reformulate the GAE-based clustering
methodology. Our solution is two-fold. First, we propose a sampling operator
$\Xi$ that triggers a protection mechanism against the noisy clustering
assignments. Second, we propose an operator $\Upsilon$ that triggers a
correction mechanism against Feature Drift by gradually transforming the
reconstructed graph into a clustering-oriented one. As principal advantages,
our solution grants a considerable improvement in clustering effectiveness and
robustness and can be easily tailored to existing GAE models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GDI: Rethinking What Makes Reinforcement Learning Different From Supervised Learning. (arXiv:2106.06232v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Jiajun Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Changnan Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yue Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06232">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Q Network (DQN) firstly kicked the door of deep reinforcement learning
(DRL) via combining deep learning (DL) with reinforcement learning (RL), which
has noticed that the distribution of the acquired data would change during the
training process. DQN found this property might cause instability for training,
so it proposed effective methods to handle the downside of the property.
Instead of focusing on the unfavourable aspects, we find it critical for RL to
ease the gap between the estimated data distribution and the ground truth data
distribution while supervised learning (SL) fails to do so. From this new
perspective, we extend the basic paradigm of RL called the Generalized Policy
Iteration (GPI) into a more generalized version, which is called the
Generalized Data Distribution Iteration (GDI). We see massive RL algorithms and
techniques can be unified into the GDI paradigm, which can be considered as one
of the special cases of GDI. We provide theoretical proof of why GDI is better
than GPI and how it works. Several practical algorithms based on GDI have been
proposed to verify the effectiveness and extensiveness of it. Empirical
experiments prove our state-of-the-art (SOTA) performance on Arcade Learning
Environment (ALE), wherein our algorithm has achieved 9620.98% mean human
normalized score (HNS), 1146.39% median HNS and 22 human world record
breakthroughs (HWRB) using only 200M training frames. Our work aims to lead the
RL research to step into the journey of conquering the human world records and
seek real superhuman agents on both performance and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessing putative bias in prediction of anti-microbial resistance from real-world genotyping data under explicit causal assumptions. (arXiv:2107.03383v2 [q-bio.GN] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Prosperi_M/0/1/0/all/0/1">Mattia Prosperi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Marini_S/0/1/0/all/0/1">Simone Marini</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Boucher_C/0/1/0/all/0/1">Christina Boucher</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Bian_J/0/1/0/all/0/1">Jiang Bian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03383">
                                    <div class="article-summary-box-inner">
                                        <span>Whole genome sequencing (WGS) is quickly becoming the customary means for
identification of antimicrobial resistance (AMR) due to its ability to obtain
high resolution information about the genes and mechanisms that are causing
resistance and driving pathogen mobility. By contrast, traditional phenotypic
(antibiogram) testing cannot easily elucidate such information. Yet development
of AMR prediction tools from genotype-phenotype data can be biased, since
sampling is non-randomized. Sample provenience, period of collection, and
species representation can confound the association of genetic traits with AMR.
Thus, prediction models can perform poorly on new data with sampling
distribution shifts. In this work -- under an explicit set of causal
assumptions -- we evaluate the effectiveness of propensity-based rebalancing
and confounding adjustment on AMR prediction using genotype-phenotype AMR data
from the Pathosystems Resource Integration Center (PATRIC). We select bacterial
genotypes (encoded as k-mer signatures, i.e. DNA fragments of length k),
country, year, species, and AMR phenotypes for the tetracycline drug class,
preparing test data with recent genomes coming from a single country. We test
boosted logistic regression (BLR) and random forests (RF) with/without
bias-handling. On 10,936 instances, we find evidence of species, location and
year imbalance with respect to the AMR phenotype. The crude versus
bias-adjusted change in effect of genetic signatures on AMR varies but only
moderately (selecting the top 20,000 out of 40+ million k-mers). The area under
the receiver operating characteristic (AUROC) of the RF (0.95) is comparable to
that of BLR (0.94) on both out-of-bag samples from bootstrap and the external
test (n&#x3D;1,085), where AUROCs do not decrease. We observe a 1%-5% gain in AUROC
with bias-handling compared to the sole use of genetic signatures. ...</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Graph Convolutional Networks for Text Classification. (arXiv:2102.09604v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Igamberdiev_T/0/1/0/all/0/1">Timour Igamberdiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Habernal_I/0/1/0/all/0/1">Ivan Habernal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09604">
                                    <div class="article-summary-box-inner">
                                        <span>Graph convolutional networks (GCNs) are a powerful architecture for
representation learning on documents that naturally occur as graphs, e.g.,
citation or social networks. However, sensitive personal information, such as
documents with people&#x27;s profiles or relationships as edges, are prone to
privacy leaks, as the trained model might reveal the original input. Although
differential privacy (DP) offers a well-founded privacy-preserving framework,
GCNs pose theoretical and practical challenges due to their training specifics.
We address these challenges by adapting differentially-private gradient-based
training to GCNs and conduct experiments using two optimizers on five NLP
datasets in two languages. We propose a simple yet efficient method based on
random graph splits that not only improves the baseline privacy bounds by a
factor of 2.7 while retaining competitive F1 scores, but also provides strong
privacy guarantees of epsilon &#x3D; 1.0. We show that, under certain modeling
choices, privacy-preserving GCNs perform up to 90% of their non-private
variants, while formally guaranteeing strong privacy measures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Geometric convergence of elliptical slice sampling. (arXiv:2105.03308v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Natarovskii_V/0/1/0/all/0/1">Viacheslav Natarovskii</a>, <a href="http://arxiv.org/find/stat/1/au:+Rudolf_D/0/1/0/all/0/1">Daniel Rudolf</a>, <a href="http://arxiv.org/find/stat/1/au:+Sprungk_B/0/1/0/all/0/1">Bj&#xf6;rn Sprungk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03308">
                                    <div class="article-summary-box-inner">
                                        <span>For Bayesian learning, given likelihood function and Gaussian prior, the
elliptical slice sampler, introduced by Murray, Adams and MacKay 2010, provides
a tool for the construction of a Markov chain for approximate sampling of the
underlying posterior distribution. Besides of its wide applicability and
simplicity its main feature is that no tuning is necessary. Under weak
regularity assumptions on the posterior density we show that the corresponding
Markov chain is geometrically ergodic and therefore yield qualitative
convergence guarantees. We illustrate our result for Gaussian posteriors as
they appear in Gaussian process regression, as well as in a setting of a
multi-modal distribution. Remarkably, our numerical experiments indicate a
dimension-independent performance of elliptical slice sampling even in
situations where our ergodicity result does not apply.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CHEF: A Cheap and Fast Pipeline for Iteratively Cleaning Label Uncertainties (Technical Report). (arXiv:2107.08588v2 [cs.DB] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yinjun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Weimer_J/0/1/0/all/0/1">James Weimer</a>, <a href="http://arxiv.org/find/cs/1/au:+Davidson_S/0/1/0/all/0/1">Susan B. Davidson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08588">
                                    <div class="article-summary-box-inner">
                                        <span>High-quality labels are expensive to obtain for many machine learning tasks,
such as medical image classification tasks. Therefore, probabilistic (weak)
labels produced by weak supervision tools are used to seed a process in which
influential samples with weak labels are identified and cleaned by several
human annotators to improve the model performance. To lower the overall cost
and computational overhead of this process, we propose a solution called CHEF
(CHEap and Fast label cleaning), which consists of the following three
components. First, to reduce the cost of human annotators, we use Infl, which
prioritizes the most influential training samples for cleaning and provides
cleaned labels to save the cost of one human annotator. Second, to accelerate
the sample selector phase and the model constructor phase, we use Increm-Infl
to incrementally produce influential samples, and DeltaGrad-L to incrementally
update the model. Third, we redesign the typical label cleaning pipeline so
that human annotators iteratively clean smaller batch of samples rather than
one big batch of samples. This yields better over all model performance and
enables possible early termination when the expected model performance has been
achieved. Extensive experiments show that our approach gives good model
prediction performance while achieving significant speed-ups.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Demonstration of Panda: A Weakly Supervised Entity Matching System. (arXiv:2106.10821v2 [cs.DB] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_R/0/1/0/all/0/1">Renzhi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sakala_P/0/1/0/all/0/1">Prem Sakala</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1">Xu Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yeye He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10821">
                                    <div class="article-summary-box-inner">
                                        <span>Entity matching (EM) refers to the problem of identifying tuple pairs in one
or more relations that refer to the same real world entities. Supervised
machine learning (ML) approaches, and deep learning based approaches in
particular, typically achieve state-of-the-art matching results. However, these
approaches require many labeled examples, in the form of matching and
non-matching pairs, which are expensive and time-consuming to label. In this
paper, we introduce Panda, a weakly supervised system specifically designed for
EM. Panda uses the same labeling function abstraction as Snorkel, where
labeling functions (LF) are user-provided programs that can generate large
amounts of (somewhat noisy) labels quickly and cheaply, which can then be
combined via a labeling model to generate accurate final predictions. To
support users developing LFs for EM, Panda provides an integrated development
environment (IDE) that lives in a modern browser architecture. Panda&#x27;s IDE
facilitates the development, debugging, and life-cycle management of LFs in the
context of EM tasks, similar to how IDEs such as Visual Studio or Eclipse excel
in general-purpose programming. Panda&#x27;s IDE includes many novel features
purpose-built for EM, such as smart data sampling, a builtin library of EM
utility functions, automatically generated LFs, visual debugging of LFs, and
finally, an EM-specific labeling model. We show in this demo that Panda IDE can
greatly accelerate the development of high-quality EM solutions using weak
supervision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Efficiency of Various Deep Transfer Learning Models in Glitch Waveform Detection in Gravitational-Wave Data. (arXiv:2107.01863v3 [gr-qc] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/gr-qc/1/au:+Mesuga_R/0/1/0/all/0/1">Reymond Mesuga</a>, <a href="http://arxiv.org/find/gr-qc/1/au:+Bayanay_B/0/1/0/all/0/1">Brian James Bayanay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.01863">
                                    <div class="article-summary-box-inner">
                                        <span>LIGO is considered the most sensitive and complicated gravitational
experiment ever built. Its main objective is to detect the gravitational wave
from the strongest events in the universe by observing if the length of its
4-kilometer arms change by a distance 10,000 times smaller than the diameter of
a proton. Due to its sensitivity, LIGO is prone to the disturbance of external
noises which affects the data being collected to detect the gravitational wave.
These noises are commonly called by the LIGO community as glitches. The
objective of this study is to evaluate the effeciency of various deep trasnfer
learning models namely VGG19, ResNet50V2, VGG16 and ResNet101 to detect glitch
waveform in gravitational wave data. The accuracy achieved by the said models
are 98.98%, 98.35%, 97.56% and 94.73% respectively. Even though the models
achieved fairly high accuracy, it is observed that all of the model suffered
from the lack of data for certain classes which is the main concern found in
the experiment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Calibrating sufficiently. (arXiv:2105.07283v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tasche_D/0/1/0/all/0/1">Dirk Tasche</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07283">
                                    <div class="article-summary-box-inner">
                                        <span>When probabilistic classifiers are trained and calibrated, the so-called
grouping loss component of the calibration loss can easily be overlooked.
Grouping loss refers to the gap between observable information and information
actually exploited in the calibration exercise. We investigate the relation
between grouping loss and the concept of sufficiency, identifying
comonotonicity as a useful criterion for sufficiency. We revisit the probing
reduction approach of Langford &amp; Zadrozny (2005) and find that it produces an
estimator of probabilistic classifiers that reduces grouping loss. Finally, we
discuss Brier curves as tools to support training and &#x27;sufficient&#x27; calibration
of probabilistic classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Jet Classification of Boosted Top Quarks with the CMS Open Data. (arXiv:2104.14659v2 [physics.data-an] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Andrews_M/0/1/0/all/0/1">Michael Andrews</a>, <a href="http://arxiv.org/find/physics/1/au:+Burkle_B/0/1/0/all/0/1">Bjorn Burkle</a>, <a href="http://arxiv.org/find/physics/1/au:+Chen_Y/0/1/0/all/0/1">Yi-fan Chen</a>, <a href="http://arxiv.org/find/physics/1/au:+DiCroce_D/0/1/0/all/0/1">Davide DiCroce</a>, <a href="http://arxiv.org/find/physics/1/au:+Gleyzer_S/0/1/0/all/0/1">Sergei Gleyzer</a>, <a href="http://arxiv.org/find/physics/1/au:+Heintz_U/0/1/0/all/0/1">Ulrich Heintz</a>, <a href="http://arxiv.org/find/physics/1/au:+Narain_M/0/1/0/all/0/1">Meenakshi Narain</a>, <a href="http://arxiv.org/find/physics/1/au:+Paulini_M/0/1/0/all/0/1">Manfred Paulini</a>, <a href="http://arxiv.org/find/physics/1/au:+Pervan_N/0/1/0/all/0/1">Nikolas Pervan</a>, <a href="http://arxiv.org/find/physics/1/au:+Shafi_Y/0/1/0/all/0/1">Yusef Shafi</a>, <a href="http://arxiv.org/find/physics/1/au:+Sun_W/0/1/0/all/0/1">Wei Sun</a>, <a href="http://arxiv.org/find/physics/1/au:+Usai_E/0/1/0/all/0/1">Emanuele Usai</a>, <a href="http://arxiv.org/find/physics/1/au:+Yang_K/0/1/0/all/0/1">Kun Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14659">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a novel application of the end-to-end deep learning technique to
the task of discriminating top quark-initiated jets from those originating from
the hadronization of a light quark or a gluon. The end-to-end deep learning
technique combines deep learning algorithms and low-level detector
representation of the high-energy collision event. In this study, we use
low-level detector information from the simulated CMS Open Data samples to
construct the top jet classifiers. To optimize classifier performance we
progressively add low-level information from the CMS tracking detector,
including pixel detector reconstructed hits and impact parameters, and
demonstrate the value of additional tracking information even when no new
spatial structures are added. Relying only on calorimeter energy deposits and
reconstructed pixel detector hits, the end-to-end classifier achieves an AUC
score of 0.975$\pm$0.002 for the task of classifying boosted top quark jets.
After adding derived track quantities, the classifier AUC score increases to
0.9824$\pm$0.0013, serving as the first performance benchmark for these CMS
Open Data samples. We additionally provide a timing performance comparison of
different processor unit architectures for training the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DIPS-Plus: The Enhanced Database of Interacting Protein Structures for Interface Prediction. (arXiv:2106.04362v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Morehead_A/0/1/0/all/0/1">Alex Morehead</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Sedova_A/0/1/0/all/0/1">Ada Sedova</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cheng_J/0/1/0/all/0/1">Jianlin Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04362">
                                    <div class="article-summary-box-inner">
                                        <span>How and where proteins interface with one another can ultimately impact the
proteins&#x27; functions along with a range of other biological processes. As such,
precise computational methods for protein interface prediction (PIP) come
highly sought after as they could yield significant advances in drug discovery
and design as well as protein function analysis. However, the traditional
benchmark dataset for this task, Docking Benchmark 5 (DB5), contains only a
modest 230 complexes for training, validating, and testing different machine
learning algorithms. In this work, we expand on a dataset recently introduced
for this task, the Database of Interacting Protein Structures (DIPS), to
present DIPS-Plus, an enhanced, feature-rich dataset of 42,112 complexes for
geometric deep learning of protein interfaces. The previous version of DIPS
contains only the Cartesian coordinates and types of the atoms comprising a
given protein complex, whereas DIPS-Plus now includes a plethora of new
residue-level features including protrusion indices, half-sphere amino acid
compositions, and new profile hidden Markov model (HMM)-based sequence features
for each amino acid, giving researchers a large, well-curated feature bank for
training protein interface prediction methods. We demonstrate through rigorous
benchmarks that training an existing state-of-the-art (SOTA) model for PIP on
DIPS-Plus yields SOTA results, surpassing the performance of all other models
trained on residue-level and atom-level encodings of protein complexes to date.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Convolutional Neural Network based Cascade Reconstruction for the IceCube Neutrino Observatory. (arXiv:2101.11589v2 [hep-ex] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-ex/1/au:+Abbasi_R/0/1/0/all/0/1">R. Abbasi</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Ackermann_M/0/1/0/all/0/1">M. Ackermann</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Adams_J/0/1/0/all/0/1">J. Adams</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Aguilar_J/0/1/0/all/0/1">J. A. Aguilar</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Ahlers_M/0/1/0/all/0/1">M. Ahlers</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Ahrens_M/0/1/0/all/0/1">M. Ahrens</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Alispach_C/0/1/0/all/0/1">C. Alispach</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Alves_A/0/1/0/all/0/1">A. A. Alves Jr.</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Amin_N/0/1/0/all/0/1">N. M. Amin</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+An_R/0/1/0/all/0/1">R. An</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Andeen_K/0/1/0/all/0/1">K. Andeen</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Anderson_T/0/1/0/all/0/1">T. Anderson</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Ansseau_I/0/1/0/all/0/1">I. Ansseau</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Anton_G/0/1/0/all/0/1">G. Anton</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Arguelles_C/0/1/0/all/0/1">C. Arg&#xfc;elles</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Axani_S/0/1/0/all/0/1">S. Axani</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bai_X/0/1/0/all/0/1">X. Bai</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+V%2E_A/0/1/0/all/0/1">A. Balagopal V.</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Barbano_A/0/1/0/all/0/1">A. Barbano</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Barwick_S/0/1/0/all/0/1">S. W. Barwick</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bastian_B/0/1/0/all/0/1">B. Bastian</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Basu_V/0/1/0/all/0/1">V. Basu</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Baum_V/0/1/0/all/0/1">V. Baum</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Baur_S/0/1/0/all/0/1">S. Baur</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bay_R/0/1/0/all/0/1">R. Bay</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Beatty_J/0/1/0/all/0/1">J. J. Beatty</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Becker_K/0/1/0/all/0/1">K.-H. Becker</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Tjus_J/0/1/0/all/0/1">J. Becker Tjus</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bellenghi_C/0/1/0/all/0/1">C. Bellenghi</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+BenZvi_S/0/1/0/all/0/1">S. BenZvi</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Berley_D/0/1/0/all/0/1">D. Berley</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bernardini_E/0/1/0/all/0/1">E. Bernardini</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Besson_D/0/1/0/all/0/1">D. Z. Besson</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Binder_G/0/1/0/all/0/1">G. Binder</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bindig_D/0/1/0/all/0/1">D. Bindig</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Blaufuss_E/0/1/0/all/0/1">E. Blaufuss</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Blot_S/0/1/0/all/0/1">S. Blot</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Boser_S/0/1/0/all/0/1">S. B&#xf6;ser</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Botner_O/0/1/0/all/0/1">O. Botner</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bottcher_J/0/1/0/all/0/1">J. B&#xf6;ttcher</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bourbeau_E/0/1/0/all/0/1">E. Bourbeau</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bourbeau_J/0/1/0/all/0/1">J. Bourbeau</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bradascio_F/0/1/0/all/0/1">F. Bradascio</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Braun_J/0/1/0/all/0/1">J. Braun</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Bron_S/0/1/0/all/0/1">S. Bron</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Brostean_Kaiser_J/0/1/0/all/0/1">J. Brostean-Kaiser</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Burgman_A/0/1/0/all/0/1">A. Burgman</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Busse_R/0/1/0/all/0/1">R. S. Busse</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Campana_M/0/1/0/all/0/1">M. A. Campana</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Chen_C/0/1/0/all/0/1">C. Chen</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Chirkin_D/0/1/0/all/0/1">D. Chirkin</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Choi_S/0/1/0/all/0/1">S. Choi</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Clark_B/0/1/0/all/0/1">B. A. Clark</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Clark_K/0/1/0/all/0/1">K. Clark</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Classen_L/0/1/0/all/0/1">L. Classen</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Coleman_A/0/1/0/all/0/1">A. Coleman</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Collin_G/0/1/0/all/0/1">G. H. Collin</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Conrad_J/0/1/0/all/0/1">J. M. Conrad</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Coppin_P/0/1/0/all/0/1">P. Coppin</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Correa_P/0/1/0/all/0/1">P. Correa</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Cowen_D/0/1/0/all/0/1">D. F. Cowen</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Cross_R/0/1/0/all/0/1">R. Cross</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Dave_P/0/1/0/all/0/1">P. Dave</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+Clercq_C/0/1/0/all/0/1">C. De Clercq</a>, <a href="http://arxiv.org/find/hep-ex/1/au:+DeLaunay_J/0/1/0/all/0/1">J. J. DeLaunay</a>, et al. (303 additional authors not shown)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11589">
                                    <div class="article-summary-box-inner">
                                        <span>Continued improvements on existing reconstruction methods are vital to the
success of high-energy physics experiments, such as the IceCube Neutrino
Observatory. In IceCube, further challenges arise as the detector is situated
at the geographic South Pole where computational resources are limited.
However, to perform real-time analyses and to issue alerts to telescopes around
the world, powerful and fast reconstruction methods are desired. Deep neural
networks can be extremely powerful, and their usage is computationally
inexpensive once the networks are trained. These characteristics make a deep
learning-based approach an excellent candidate for the application in IceCube.
A reconstruction method based on convolutional architectures and hexagonally
shaped kernels is presented. The presented method is robust towards systematic
uncertainties in the simulation and has been tested on experimental data. In
comparison to standard reconstruction methods in IceCube, it can improve upon
the reconstruction accuracy, while reducing the time necessary to run the
reconstruction by two to three orders of magnitude.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discovering nonlinear resonances through physics-informed machine learning. (arXiv:2104.13471v2 [physics.comp-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Barmparis_G/0/1/0/all/0/1">G. D. Barmparis</a>, <a href="http://arxiv.org/find/physics/1/au:+Tsironis_G/0/1/0/all/0/1">G. P. Tsironis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13471">
                                    <div class="article-summary-box-inner">
                                        <span>For an ensemble of nonlinear systems that model, for instance, molecules or
photonic systems, we propose a method that finds efficiently the configuration
that has prescribed transfer properties. Specifically, we use physics-informed
machine-learning (PIML) techniques to find the parameters for the efficient
transfer of an electron (or photon) to a targeted state in a non-linear dimer.
We create a machine learning model containing two variables, $\chi_D$, and
$\chi_A$, representing the non-linear terms in the donor and acceptor target
system states. We then introduce a data-free physics-informed loss function as
$1.0 - P_j$, where $P_j$ is the probability, the electron being in the targeted
state, $j$. By minimizing the loss function, we maximize the occupation
probability to the targeted state. The method recovers known results in the
Targeted Energy Transfer (TET) model, and it is then applied to a more complex
system with an additional intermediate state. In this trimer configuration, the
PIML approach discovers desired resonant paths from the donor to acceptor
units. The proposed PIML method is general and may be used in the chemical
design of molecular complexes or engineering design of quantum or photonic
systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Fly -- a Gym Environment with PyBullet Physics for Reinforcement Learning of Multi-agent Quadcopter Control. (arXiv:2103.02142v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Panerati_J/0/1/0/all/0/1">Jacopo Panerati</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1">Hehui Zheng</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">SiQi Zhou</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">James Xu</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Prorok_A/0/1/0/all/0/1">Amanda Prorok</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Schoellig_A/0/1/0/all/0/1">Angela P. Schoellig</a> (1 and 2) ((1) University of Toronto Institute for Aerospace Studies, (2) Vector Institute for Artificial Intelligence, (3) University of Cambridge)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02142">
                                    <div class="article-summary-box-inner">
                                        <span>Robotic simulators are crucial for academic research and education as well as
the development of safety-critical applications. Reinforcement learning
environments -- simple simulations coupled with a problem specification in the
form of a reward function -- are also important to standardize the development
(and benchmarking) of learning algorithms. Yet, full-scale simulators typically
lack portability and parallelizability. Vice versa, many reinforcement learning
environments trade-off realism for high sample throughputs in toy-like
problems. While public data sets have greatly benefited deep learning and
computer vision, we still lack the software tools to simultaneously develop --
and fairly compare -- control theory and reinforcement learning approaches. In
this paper, we propose an open-source OpenAI Gym-like environment for multiple
quadcopters based on the Bullet physics engine. Its multi-agent and vision
based reinforcement learning interfaces, as well as the support of realistic
collisions and aerodynamic effects, make it, to the best of our knowledge, a
first of its kind. We demonstrate its use through several examples, either for
control (trajectory tracking with PID control, multi-robot flight with
downwash, etc.) or reinforcement learning (single and multi-agent stabilization
tasks), hoping to inspire future research that combines control theory and
machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning low-rank latent mesoscale structures in networks. (arXiv:2102.06984v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lyu_H/0/1/0/all/0/1">Hanbaek Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kureh_Y/0/1/0/all/0/1">Yacoub H. Kureh</a>, <a href="http://arxiv.org/find/cs/1/au:+Vendrow_J/0/1/0/all/0/1">Joshua Vendrow</a>, <a href="http://arxiv.org/find/cs/1/au:+Porter_M/0/1/0/all/0/1">Mason A. Porter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06984">
                                    <div class="article-summary-box-inner">
                                        <span>It is common to use networks to encode the architecture of interactions
between entities in complex systems in the physical, biological, social, and
information sciences. Moreover, to study the large-scale behavior of complex
systems, it is important to study mesoscale structures in networks as building
blocks that influence such behavior. In this paper, we present a new approach
for describing low-rank mesoscale structure in networks, and we illustrate our
approach using several synthetic network models and empirical friendship,
collaboration, and protein--protein interaction (PPI) networks. We find that
these networks possess a relatively small number of &#x60;latent motifs&#x27; that
together can successfully approximate most subnetworks at a fixed mesoscale. We
use an algorithm that we call &quot;network dictionary learning&quot; (NDL), which
combines a network sampling method and nonnegative matrix factorization, to
learn the latent motifs of a given network. The ability to encode a network
using a set of latent motifs has a wide range of applications to
network-analysis tasks, such as comparison, denoising, and edge inference.
Additionally, using our new network denoising and reconstruction (NDR)
algorithm, we demonstrate how to denoise a corrupted network by using only the
latent motifs that one learns directly from the corrupted networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Axiomatic Theory of Provably-Fair Welfare-Centric Machine Learning. (arXiv:2104.14504v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cousins_C/0/1/0/all/0/1">Cyrus Cousins</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14504">
                                    <div class="article-summary-box-inner">
                                        <span>We address an inherent difficulty in welfare-theoretic fair machine learning
by proposing an equivalently axiomatically-justified alternative and studying
the resulting computational and statistical learning questions. Welfare metrics
quantify overall wellbeing across a population of one or more groups, and
welfare-based objectives and constraints have recently been proposed to
incentivize fair machine learning methods to produce satisfactory solutions
that consider the diverse needs of multiple groups. Unfortunately, many
machine-learning problems are more naturally cast as loss minimization tasks,
rather than utility maximization, which complicates direct application of
welfare-centric methods to fair machine learning. In this work, we define a
complementary measure, termed malfare, measuring overall societal harm (rather
than wellbeing), with axiomatic justification via the standard axioms of
cardinal welfare. We then cast fair machine learning as malfare minimization
over the risk values (expected losses) of each group. Surprisingly, the axioms
of cardinal welfare (malfare) dictate that this is not equivalent to simply
defining utility as negative loss. Building upon these concepts, we define
fair-PAC (FPAC) learning, where an FPAC learner is an algorithm that learns an
$\varepsilon$-$\delta$ malfare-optimal model with bounded sample complexity,
for any data distribution, and for any (axiomatically justified) malfare
concept. Finally, we show broad conditions under which, with appropriate
modifications, standard PAC-learners may be converted to FPAC learners. This
places FPAC learning on firm theoretical ground, as it yields statistical and
computational efficiency guarantees for many well-studied machine-learning
models, and is also practically relevant, as it democratizes fair ML by
providing concrete training algorithms and rigorous generalization guarantees
for these models</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Edgeless-GNN: Unsupervised Inductive Edgeless Network Embedding. (arXiv:2104.05225v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1">Yong-Min Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1">Cong Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_W/0/1/0/all/0/1">Won-Yong Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1">Xin Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05225">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of embedding edgeless nodes such as users who newly
enter the underlying network, while using graph neural networks (GNNs) widely
studied for effective representation learning of graphs thanks to its highly
expressive capability via message passing. Our study is motivated by the fact
that existing GNNs cannot be adopted for our problem since message passing to
such edgeless nodes having no connections is impossible. To tackle this
challenge, we propose Edgeless-GNN, a new framework that enables GNNs to
generate node embeddings even for edgeless nodes through unsupervised inductive
learning. Specifically, we start by constructing a $k$-nearest neighbor graph
($k$NNG) based on the similarity of node attributes to replace the GNN&#x27;s
computation graph defined by the neighborhood-based aggregation of each node.
As our main contributions, the known network structure is used to train model
parameters, while a new loss function is established using energy-based
learning in such a way that our model learns the network structure. For the
edgeless nodes, we inductively infer embeddings for the edgeless nodes by using
edges via $k$NNG construction as a computation graph. By evaluating the
performance of various downstream machine learning (ML) tasks, we empirically
demonstrate that Edgeless-GNN consistently outperforms state-of-the-art methods
of inductive network embedding. Moreover, our findings corroborate the
effectiveness of Edgeless-GNN in judiciously combining the replaced computation
graph with our newly designed loss. Our framework is GNN-model-agnostic; thus,
GNN models can be appropriately chosen according to ones&#x27; needs and ML tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provable Guarantees for Self-Supervised Deep Learning with Spectral Contrastive Loss. (arXiv:2106.04156v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+HaoChen_J/0/1/0/all/0/1">Jeff Z. HaoChen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1">Colin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaidon_A/0/1/0/all/0/1">Adrien Gaidon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04156">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works in self-supervised learning have advanced the state-of-the-art
by relying on the contrastive learning paradigm, which learns representations
by pushing positive pairs, or similar examples from the same class, closer
together while keeping negative pairs far apart. Despite the empirical
successes, theoretical foundations are limited -- prior analyses assume
conditional independence of the positive pairs given the same class label, but
recent empirical applications use heavily correlated positive pairs (i.e., data
augmentations of the same image). Our work analyzes contrastive learning
without assuming conditional independence of positive pairs using a novel
concept of the augmentation graph on data. Edges in this graph connect
augmentations of the same data, and ground-truth classes naturally form
connected sub-graphs. We propose a loss that performs spectral decomposition on
the population augmentation graph and can be succinctly written as a
contrastive learning objective on neural net representations. Minimizing this
objective leads to features with provable accuracy guarantees under linear
probe evaluation. By standard generalization bounds, these accuracy guarantees
also hold when minimizing the training contrastive loss. Empirically, the
features learned by our objective can match or outperform several strong
baselines on benchmark vision datasets. In all, this work provides the first
provable analysis for contrastive learning where guarantees for linear probe
evaluation can apply to realistic empirical settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Dynamic Personalized Pricing with Demand Learning. (arXiv:2009.12920v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Simchi_Levi_D/0/1/0/all/0/1">David Simchi-Levi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yining Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12920">
                                    <div class="article-summary-box-inner">
                                        <span>The prevalence of e-commerce has made detailed customers&#x27; personal
information readily accessible to retailers, and this information has been
widely used in pricing decisions. When involving personalized information, how
to protect the privacy of such information becomes a critical issue in
practice. In this paper, we consider a dynamic pricing problem over $T$ time
periods with an \emph{unknown} demand function of posted price and personalized
information. At each time $t$, the retailer observes an arriving customer&#x27;s
personal information and offers a price. The customer then makes the purchase
decision, which will be utilized by the retailer to learn the underlying demand
function. There is potentially a serious privacy concern during this process: a
third party agent might infer the personalized information and purchase
decisions from price changes from the pricing system. Using the fundamental
framework of differential privacy from computer science, we develop a
privacy-preserving dynamic pricing policy, which tries to maximize the retailer
revenue while avoiding information leakage of individual customer&#x27;s information
and purchasing decisions. To this end, we first introduce a notion of
\emph{anticipating} $(\varepsilon, \delta)$-differential privacy that is
tailored to dynamic pricing problem. Our policy achieves both the privacy
guarantee and the performance guarantee in terms of regret. Roughly speaking,
for $d$-dimensional personalized information, our algorithm achieves the
expected regret at the order of $\tilde{O}(\varepsilon^{-1} \sqrt{d^3 T})$,
when the customers&#x27; information is adversarially chosen. For stochastic
personalized information, the regret bound can be further improved to
$\tilde{O}(\sqrt{d^2T} + \varepsilon^{-2} d^2)$</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural message passing for joint paratope-epitope prediction. (arXiv:2106.00757v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Vecchio_A/0/1/0/all/0/1">Alice Del Vecchio</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Deac_A/0/1/0/all/0/1">Andreea Deac</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lio_P/0/1/0/all/0/1">Pietro Li&#xf2;</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Velickovic_P/0/1/0/all/0/1">Petar Veli&#x10d;kovi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00757">
                                    <div class="article-summary-box-inner">
                                        <span>Antibodies are proteins in the immune system which bind to antigens to detect
and neutralise them. The binding sites in an antibody-antigen interaction are
known as the paratope and epitope, respectively, and the prediction of these
regions is key to vaccine and synthetic antibody development. Contrary to prior
art, we argue that paratope and epitope predictors require asymmetric
treatment, and propose distinct neural message passing architectures that are
geared towards the specific aspects of paratope and epitope prediction,
respectively. We obtain significant improvements on both tasks, setting the new
state-of-the-art and recovering favourable qualitative predictions on antigens
of relevance to COVID-19.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Sampling Density for Nonparametric Regression. (arXiv:2105.11990v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Panknin_D/0/1/0/all/0/1">Danny Panknin</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1">Klaus Robert M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakajima_S/0/1/0/all/0/1">Shinichi Nakajima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11990">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel active learning strategy for regression, which is
model-agnostic, robust against model mismatch, and interpretable. Assuming that
a small number of initial samples are available, we derive the optimal training
density that minimizes the generalization error of local polynomial smoothing
(LPS) with its kernel bandwidth tuned locally: We adopt the mean integrated
squared error (MISE) as a generalization criterion, and use the asymptotic
behavior of the MISE as well as the locally optimal bandwidths (LOB) - the
bandwidth function that minimizes MISE in the asymptotic limit. The asymptotic
expression of our objective then reveals the dependence of the MISE on the
training density, enabling analytic minimization. As a result,we obtain the
optimal training density in a closed-form. The almost model-free nature of our
approach thus helps to encode the essential properties of the target problem,
providing a robust and model-agnostic active learning strategy. Furthermore,
the obtained training density factorizes the influence of local function
complexity, noise level and test density in a transparent and interpretable
way. We validate our theory in numerical simulations, and show that the
proposed active learning method outperforms the existing state-of-the-art
model-agnostic approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UVStyle-Net: Unsupervised Few-shot Learning of 3D Style Similarity Measure for B-Reps. (arXiv:2105.02961v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meltzer_P/0/1/0/all/0/1">Peter Meltzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Shayani_H/0/1/0/all/0/1">Hooman Shayani</a>, <a href="http://arxiv.org/find/cs/1/au:+Khasahmadi_A/0/1/0/all/0/1">Amir Khasahmadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jayaraman_P/0/1/0/all/0/1">Pradeep Kumar Jayaraman</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanghi_A/0/1/0/all/0/1">Aditya Sanghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lambourne_J/0/1/0/all/0/1">Joseph Lambourne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02961">
                                    <div class="article-summary-box-inner">
                                        <span>Boundary Representations (B-Reps) are the industry standard in 3D Computer
Aided Design/Manufacturing (CAD/CAM) and industrial design due to their
fidelity in representing stylistic details. However, they have been ignored in
the 3D style research. Existing 3D style metrics typically operate on meshes or
pointclouds, and fail to account for end-user subjectivity by adopting fixed
definitions of style, either through crowd-sourcing for style labels or
hand-crafted features. We propose UVStyle-Net, a style similarity measure for
B-Reps that leverages the style signals in the second order statistics of the
activations in a pre-trained (unsupervised) 3D encoder, and learns their
relative importance to a subjective end-user through few-shot learning. Our
approach differs from all existing data-driven 3D style methods since it may be
used in completely unsupervised settings, which is desirable given the lack of
publicly available labelled B-Rep datasets. More importantly, the few-shot
learning accounts for the inherent subjectivity associated with style. We show
quantitatively that our proposed method with B-Reps is able to capture stronger
style signals than alternative methods on meshes and pointclouds despite its
significantly greater computational efficiency. We also show it is able to
generate meaningful style gradients with respect to the input shape, and that
few-shot learning with as few as two positive examples selected by an end-user
is sufficient to significantly improve the style measure. Finally, we
demonstrate its efficacy on a large unlabeled public dataset of CAD models.
Source code and data will be released in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AGENT: A Benchmark for Core Psychological Reasoning. (arXiv:2102.12321v4 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_T/0/1/0/all/0/1">Tianmin Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhandwaldar_A/0/1/0/all/0/1">Abhishek Bhandwaldar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chuang Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_K/0/1/0/all/0/1">Kevin A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shari Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gutfreund_D/0/1/0/all/0/1">Dan Gutfreund</a>, <a href="http://arxiv.org/find/cs/1/au:+Spelke_E/0/1/0/all/0/1">Elizabeth Spelke</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Ullman_T/0/1/0/all/0/1">Tomer D. Ullman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12321">
                                    <div class="article-summary-box-inner">
                                        <span>For machine agents to successfully interact with humans in real-world
settings, they will need to develop an understanding of human mental life.
Intuitive psychology, the ability to reason about hidden mental variables that
drive observable actions, comes naturally to people: even pre-verbal infants
can tell agents from objects, expecting agents to act efficiently to achieve
goals given constraints. Despite recent interest in machine agents that reason
about other agents, it is not clear if such agents learn or hold the core
psychology principles that drive human reasoning. Inspired by cognitive
development studies on intuitive psychology, we present a benchmark consisting
of a large dataset of procedurally generated 3D animations, AGENT (Action,
Goal, Efficiency, coNstraint, uTility), structured around four scenarios (goal
preferences, action efficiency, unobserved constraints, and cost-reward
trade-offs) that probe key concepts of core intuitive psychology. We validate
AGENT with human-ratings, propose an evaluation protocol emphasizing
generalization, and compare two strong baselines built on Bayesian inverse
planning and a Theory of Mind neural network. Our results suggest that to pass
the designed tests of core intuitive psychology at human levels, a model must
acquire or have built-in representations of how agents plan, combining utility
computations and core knowledge of objects and physics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual analytics of set data for knowledge discovery and member selection support. (arXiv:2104.09231v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Watanabe_R/0/1/0/all/0/1">Ryuji Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishibashi_H/0/1/0/all/0/1">Hideaki Ishibashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Furukawa_T/0/1/0/all/0/1">Tetsuo Furukawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09231">
                                    <div class="article-summary-box-inner">
                                        <span>Visual analytics (VA) is a visually assisted exploratory analysis approach in
which knowledge discovery is executed interactively between the user and system
in a human-centered manner. The purpose of this study is to develop a method
for the VA of set data aimed at supporting knowledge discovery and member
selection. A typical target application is a visual support system for team
analysis and member selection, by which users can analyze past teams and
examine candidate lineups for new teams. Because there are several
difficulties, such as the combinatorial explosion problem, developing a VA
system of set data is challenging. In this study, we first define the
requirements that the target system should satisfy and clarify the accompanying
challenges. Then we propose a method for the VA of set data, which satisfies
the requirements. The key idea is to model the generation process of sets and
their outputs using a manifold network model. The proposed method visualizes
the relevant factors as a set of topographic maps on which various information
is visualized. Furthermore, using the topographic maps as a bidirectional
interface, users can indicate their targets of interest in the system on these
maps. We demonstrate the proposed method by applying it to basketball teams,
and compare with a benchmark system for outcome prediction and lineup
reconstruction tasks. Because the method can be adapted to individual
application cases by extending the network structure, it can be a general
method by which practical systems can be built.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact. (arXiv:2106.02359v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhijing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chauhan_G/0/1/0/all/0/1">Geeticka Chauhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tse_B/0/1/0/all/0/1">Brian Tse</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1">Mrinmaya Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02359">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen many breakthroughs in natural language processing
(NLP), transitioning it from a mostly theoretical field to one with many
real-world applications. Noting the rising number of applications of other
machine learning and AI techniques with pervasive societal impact, we
anticipate the rising importance of developing NLP technologies for social
good. Inspired by theories in moral philosophy and global priorities research,
we aim to promote a guideline for social good in the context of NLP. We lay the
foundations via the moral philosophy definition of social good, propose a
framework to evaluate the direct and indirect real-world impact of NLP tasks,
and adopt the methodology of global priorities research to identify priority
causes for NLP research. Finally, we use our theoretical framework to provide
some practical guidelines for future NLP research for social good. Our data and
code are available at this http URL In
addition, we curate a list of papers and resources on NLP for social good at
https://github.com/zhijing-jin/NLP4SocialGood_Papers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FERMI: Fair Empirical Risk Minimization via Exponential R\&#x27;enyi Mutual Information. (arXiv:2102.12586v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lowy_A/0/1/0/all/0/1">Andrew Lowy</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavan_R/0/1/0/all/0/1">Rakesh Pavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Baharlouei_S/0/1/0/all/0/1">Sina Baharlouei</a>, <a href="http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1">Meisam Razaviyayn</a>, <a href="http://arxiv.org/find/cs/1/au:+Beirami_A/0/1/0/all/0/1">Ahmad Beirami</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12586">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of large-scale empirical risk minimization (ERM) at
achieving high accuracy across a variety of machine learning tasks, fair ERM is
hindered by the incompatibility of fairness constraints with stochastic
optimization. In this paper, we propose the fair empirical risk minimization
via exponential R\&#x27;enyi mutual information (FERMI) framework. FERMI is built on
a stochastic estimator for exponential R\&#x27;enyi mutual information (ERMI), an
information divergence measuring the degree of the dependence of predictions on
sensitive attributes. Theoretically, we show that ERMI upper bounds existing
popular fairness violation metrics, thus controlling ERMI provides guarantees
on other commonly used violations, such as $L_\infty$. We derive an unbiased
estimator for ERMI, which we use to derive the FERMI algorithm. We prove that
FERMI converges for demographic parity, equalized odds, and equal opportunity
notions of fairness in stochastic optimization. Empirically, we show that FERMI
is amenable to large-scale problems with multiple (non-binary) sensitive
attributes and non-binary targets. Extensive experiments show that FERMI
achieves the most favorable tradeoffs between fairness violation and test
accuracy across all tested setups compared with state-of-the-art baselines for
demographic parity, equalized odds, equal opportunity. These benefits are
especially significant for non-binary classification with large sensitive sets
and small batch sizes, showcasing the effectiveness of the FERMI objective and
the developed stochastic algorithm for solving it.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilayer Network Analysis for Improved Credit Risk Prediction. (arXiv:2010.09559v4 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oskarsdottir_M/0/1/0/all/0/1">Mar&#xed;a &#xd3;skarsd&#xf3;ttir</a>, <a href="http://arxiv.org/find/cs/1/au:+Bravo_C/0/1/0/all/0/1">Cristi&#xe1;n Bravo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09559">
                                    <div class="article-summary-box-inner">
                                        <span>We present a multilayer network model for credit risk assessment. Our model
accounts for multiple connections between borrowers (such as their geographic
location and their economic activity) and allows for explicitly modelling the
interaction between connected borrowers. We develop a multilayer personalized
PageRank algorithm that allows quantifying the strength of the default exposure
of any borrower in the network. We test our methodology in an agricultural
lending framework, where it has been suspected for a long time default
correlates between borrowers when they are subject to the same structural
risks. Our results show there are significant predictive gains just by
including centrality multilayer network information in the model, and these
gains are increased by more complex information such as the multilayer PageRank
variables. The results suggest default risk is highest when an individual is
connected to many defaulters, but this risk is mitigated by the size of the
neighbourhood of the individual, showing both default risk and financial
stability propagate throughout the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fed-EINI: An Efficient and Interpretable Inference Framework for Decision Tree Ensembles in Federated Learning. (arXiv:2105.09540v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaolin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shuai Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1">Hao Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1">Zejin Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongji Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09540">
                                    <div class="article-summary-box-inner">
                                        <span>The increasing concerns about data privacy and security drive an emerging
field of studying privacy-preserving machine learning from isolated data
sources, i.e., federated learning. A class of federated learning, vertical
federated learning, where different parties hold different features for common
users, has a great potential of driving a more variety of business cooperation
among enterprises in many fields. In machine learning, decision tree ensembles
such as gradient boosting decision tree (GBDT) and random forest are widely
applied powerful models with high interpretability and modeling efficiency.
However, the interpretability is compromised in state-of-the-art vertical
federated learning frameworks such as SecureBoost with anonymous features to
avoid possible data breaches. To address this issue in the inference process,
in this paper, we propose Fed-EINI to protect data privacy and allow the
disclosure of feature meaning by concealing decision paths with a
communication-efficient secure computation method for inference outputs. The
advantages of Fed-EINI will be demonstrated through both theoretical analysis
and extensive numerical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Quantum Classifiers Through the Lens of the Hessian. (arXiv:2105.10162v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Sen_P/0/1/0/all/0/1">Pinaki Sen</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Bhatia_A/0/1/0/all/0/1">Amandeep Singh Bhatia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10162">
                                    <div class="article-summary-box-inner">
                                        <span>In quantum computing, the variational quantum algorithms (VQAs) are well
suited for finding optimal combinations of things in specific applications
ranging from chemistry all the way to finance. The training of VQAs with
gradient descent optimization algorithm has shown a good convergence. At an
early stage, the simulation of variational quantum circuits on noisy
intermediate-scale quantum (NISQ) devices suffers from noisy outputs. Just like
classical deep learning, it also suffers from vanishing gradient problems. It
is a realistic goal to study the topology of loss landscape, to visualize the
curvature information and trainability of these circuits in the existence of
vanishing gradients. In this paper, we calculated the Hessian and visualized
the loss landscape of variational quantum classifiers at different points in
parameter space. The curvature information of variational quantum classifiers
(VQC) is interpreted and the loss function&#x27;s convergence is shown. It helps us
better understand the behavior of variational quantum circuits to tackle
optimization problems efficiently. We investigated the variational quantum
classifiers via Hessian on quantum computers, started with a simple 4-bit
parity problem to gain insight into the practical behavior of Hessian, then
thoroughly analyzed the behavior of Hessian&#x27;s eigenvalues on training the
variational quantum classifier for the Diabetes dataset. Finally, we show that
how the adaptive Hessian learning rate can influence the convergence while
training the variational circuits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning for Individual Heterogeneity: An Automatic Inference Framework. (arXiv:2010.14694v2 [econ.EM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/econ/1/au:+Farrell_M/0/1/0/all/0/1">Max H. Farrell</a>, <a href="http://arxiv.org/find/econ/1/au:+Liang_T/0/1/0/all/0/1">Tengyuan Liang</a>, <a href="http://arxiv.org/find/econ/1/au:+Misra_S/0/1/0/all/0/1">Sanjog Misra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14694">
                                    <div class="article-summary-box-inner">
                                        <span>We develop methodology for estimation and inference using machine learning to
enrich economic models. Our framework takes a standard economic model and
recasts the parameters as fully flexible nonparametric functions, to capture
the rich heterogeneity based on potentially high dimensional or complex
observable characteristics. These &quot;parameter functions&quot; retain the
interpretability, economic meaning, and discipline of classical parameters.
Deep learning is particularly well-suited to structured modeling of
heterogeneity in economics. We show how to design the network architecture to
match the structure of the economic model, delivering novel methodology that
moves deep learning beyond prediction. We prove convergence rates for the
estimated parameter functions. These functions are the key inputs into the
finite-dimensional parameter of inferential interest. We obtain inference based
on a novel influence function calculation that covers any second-stage
parameter and any machine-learning-enriched model that uses a smooth
per-observation loss function. No additional derivations are required. The
score can be taken directly to data, using automatic differentiation if needed.
The researcher need only define the original model and define the parameter of
interest. A key insight is that we need not write down the influence function
in order to evaluate it on the data. Our framework gives new results for a host
of contexts, covering such diverse examples as price elasticities,
willingness-to-pay, and surplus measures in binary or multinomial choice
models, effects of continuous treatment variables, fractional outcome models,
count data, heterogeneous production functions, and more. We apply our
methodology to a large scale advertising experiment for short-term loans. We
show how economically meaningful estimates and inferences can be made that
would be unavailable without our results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Out of Order: How Important Is The Sequential Order of Words in a Sentence in Natural Language Understanding Tasks?. (arXiv:2012.15180v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1">Thang M. Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Trung Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Mai_L/0/1/0/all/0/1">Long Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_A/0/1/0/all/0/1">Anh Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15180">
                                    <div class="article-summary-box-inner">
                                        <span>Do state-of-the-art natural language understanding models care about word
order - one of the most important characteristics of a sequence? Not always! We
found 75% to 90% of the correct predictions of BERT-based classifiers, trained
on many GLUE tasks, remain constant after input words are randomly shuffled.
Despite BERT embeddings are famously contextual, the contribution of each
individual word to downstream tasks is almost unchanged even after the word&#x27;s
context is shuffled. BERT-based models are able to exploit superficial cues
(e.g. the sentiment of keywords in sentiment analysis; or the word-wise
similarity between sequence-pair inputs in natural language inference) to make
correct decisions when tokens are arranged in random orders. Encouraging
classifiers to capture word order information improves the performance on most
GLUE tasks, SQuAD 2.0 and out-of-samples. Our work suggests that many GLUE
tasks are not challenging machines to understand the meaning of a sentence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What does LIME really see in images?. (arXiv:2102.06307v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Garreau_D/0/1/0/all/0/1">Damien Garreau</a>, <a href="http://arxiv.org/find/cs/1/au:+Mardaoui_D/0/1/0/all/0/1">Dina Mardaoui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06307">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of modern algorithms on certain computer vision tasks such as
object recognition is now close to that of humans. This success was achieved at
the price of complicated architectures depending on millions of parameters and
it has become quite challenging to understand how particular predictions are
made. Interpretability methods propose to give us this understanding. In this
paper, we study LIME, perhaps one of the most popular. On the theoretical side,
we show that when the number of generated examples is large, LIME explanations
are concentrated around a limit explanation for which we give an explicit
expression. We further this study for elementary shape detectors and linear
models. As a consequence of this analysis, we uncover a connection between LIME
and integrated gradients, another explanation method. More precisely, the LIME
explanations are similar to the sum of integrated gradients over the
superpixels used in the preprocessing step of LIME.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">D-Cliques: Compensating NonIIDness in Decentralized Federated Learning with Topology. (arXiv:2104.07365v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bellet_A/0/1/0/all/0/1">Aur&#xe9;lien Bellet</a>, <a href="http://arxiv.org/find/cs/1/au:+Kermarrec_A/0/1/0/all/0/1">Anne-Marie Kermarrec</a>, <a href="http://arxiv.org/find/cs/1/au:+Lavoie_E/0/1/0/all/0/1">Erick Lavoie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07365">
                                    <div class="article-summary-box-inner">
                                        <span>The convergence speed of machine learning models trained with Federated
Learning is significantly affected by non-independent and identically
distributed (non-IID) data partitions, even more so in a fully decentralized
setting without a central server. In this paper, we show that the impact of
local class bias, an important type of data non-IIDness, can be significantly
reduced by carefully designing the underlying communication topology. We
present D-Cliques, a novel topology that reduces gradient bias by grouping
nodes in interconnected cliques such that the local joint distribution in a
clique is representative of the global class distribution. We also show how to
adapt the updates of decentralized SGD to obtain unbiased gradients and
implement an effective momentum with D-Cliques. Our empirical evaluation on
MNIST and CIFAR10 demonstrates that our approach provides similar convergence
speed as a fully-connected topology with a significant reduction in the number
of edges and messages. In a 1000-node topology, D-Cliques requires 98% less
edges and 96% less total messages, with further possible gains using a
small-world topology across cliques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Multisensor Change Detection. (arXiv:2103.05102v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Sudipan Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Ebel_P/0/1/0/all/0/1">Patrick Ebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiao Xiang Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05102">
                                    <div class="article-summary-box-inner">
                                        <span>Most change detection methods assume that pre-change and post-change images
are acquired by the same sensor. However, in many real-life scenarios, e.g.,
natural disaster, it is more practical to use the latest available images
before and after the occurrence of incidence, which may be acquired using
different sensors. In particular, we are interested in the combination of the
images acquired by optical and Synthetic Aperture Radar (SAR) sensors. SAR
images appear vastly different from the optical images even when capturing the
same scene. Adding to this, change detection methods are often constrained to
use only target image-pair, no labeled data, and no additional unlabeled data.
Such constraints limit the scope of traditional supervised machine learning and
unsupervised generative approaches for multi-sensor change detection. Recent
rapid development of self-supervised learning methods has shown that some of
them can even work with only few images. Motivated by this, in this work we
propose a method for multi-sensor change detection using only the unlabeled
target bi-temporal images that are used for training a network in
self-supervised fashion by using deep clustering and contrastive learning. The
proposed method is evaluated on four multi-modal bi-temporal scenes showing
change and the benefits of our self-supervised approach are demonstrated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active multi-fidelity Bayesian online changepoint detection. (arXiv:2103.14224v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gundersen_G/0/1/0/all/0/1">Gregory W. Gundersen</a>, <a href="http://arxiv.org/find/stat/1/au:+Cai_D/0/1/0/all/0/1">Diana Cai</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhou_C/0/1/0/all/0/1">Chuteng Zhou</a>, <a href="http://arxiv.org/find/stat/1/au:+Engelhardt_B/0/1/0/all/0/1">Barbara E. Engelhardt</a>, <a href="http://arxiv.org/find/stat/1/au:+Adams_R/0/1/0/all/0/1">Ryan P. Adams</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14224">
                                    <div class="article-summary-box-inner">
                                        <span>Online algorithms for detecting changepoints, or abrupt shifts in the
behavior of a time series, are often deployed with limited resources, e.g., to
edge computing settings such as mobile phones or industrial sensors. In these
scenarios it may be beneficial to trade the cost of collecting an environmental
measurement against the quality or &quot;fidelity&quot; of this measurement and how the
measurement affects changepoint estimation. For instance, one might decide
between inertial measurements or GPS to determine changepoints for motion. A
Bayesian approach to changepoint detection is particularly appealing because we
can represent our posterior uncertainty about changepoints and make active,
cost-sensitive decisions about data fidelity to reduce this posterior
uncertainty. Moreover, the total cost could be dramatically lowered through
active fidelity switching, while remaining robust to changes in data
distribution. We propose a multi-fidelity approach that makes cost-sensitive
decisions about which data fidelity to collect based on maximizing information
gain with respect to changepoints. We evaluate this framework on synthetic,
video, and audio data and show that this information-based approach results in
accurate predictions while reducing total cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining the Adaptive Generalisation Gap. (arXiv:2011.08181v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Granziol_D/0/1/0/all/0/1">Diego Granziol</a>, <a href="http://arxiv.org/find/stat/1/au:+Wan_X/0/1/0/all/0/1">Xingchen Wan</a>, <a href="http://arxiv.org/find/stat/1/au:+Albanie_S/0/1/0/all/0/1">Samuel Albanie</a>, <a href="http://arxiv.org/find/stat/1/au:+Roberts_S/0/1/0/all/0/1">Stephen Roberts</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08181">
                                    <div class="article-summary-box-inner">
                                        <span>We conjecture that the inherent difference in generalisation between adaptive
and non-adaptive gradient methods stems from the increased estimation noise in
the flattest directions of the true loss surface. We demonstrate that typical
schedules used for adaptive methods (with low numerical stability or damping
constants) serve to bias relative movement towards flat directions relative to
sharp directions, effectively amplifying the noise-to-signal ratio and harming
generalisation. We further demonstrate that the numerical stability/damping
constant used in these methods can be decomposed into a learning rate reduction
and linear shrinkage of the estimated curvature matrix. We then demonstrate
significant generalisation improvements by increasing the shrinkage
coefficient, closing the generalisation gap entirely in both Logistic
Regression and Deep Neural Network experiments. Finally, we show that other
popular modifications to adaptive methods, such as decoupled weight decay and
partial adaptivity can be shown to calibrate parameter updates to make better
use of sharper, more reliable directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Action Redundancy in Reinforcement Learning. (arXiv:2102.11329v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baram_N/0/1/0/all/0/1">Nir Baram</a>, <a href="http://arxiv.org/find/cs/1/au:+Tennenholtz_G/0/1/0/all/0/1">Guy Tennenholtz</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11329">
                                    <div class="article-summary-box-inner">
                                        <span>Maximum Entropy (MaxEnt) reinforcement learning is a powerful learning
paradigm which seeks to maximize return under entropy regularization. However,
action entropy does not necessarily coincide with state entropy, e.g., when
multiple actions produce the same transition. Instead, we propose to maximize
the transition entropy, i.e., the entropy of next states. We show that
transition entropy can be described by two terms; namely, model-dependent
transition entropy and action redundancy. Particularly, we explore the latter
in both deterministic and stochastic settings and develop tractable
approximation methods in a near model-free setup. We construct algorithms to
minimize action redundancy and demonstrate their effectiveness on a synthetic
environment with multiple redundant actions as well as contemporary benchmarks
in Atari and Mujoco. Our results suggest that action redundancy is a
fundamental problem in reinforcement learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Design Space for Graph Neural Networks. (arXiv:2011.08843v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jiaxuan You</a>, <a href="http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1">Rex Ying</a>, <a href="http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1">Jure Leskovec</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08843">
                                    <div class="article-summary-box-inner">
                                        <span>The rapid evolution of Graph Neural Networks (GNNs) has led to a growing
number of new architectures as well as novel applications. However, current
research focuses on proposing and evaluating specific architectural designs of
GNNs, as opposed to studying the more general design space of GNNs that
consists of a Cartesian product of different design dimensions, such as the
number of layers or the type of the aggregation function. Additionally, GNN
designs are often specialized to a single task, yet few efforts have been made
to understand how to quickly find the best GNN design for a novel task or a
novel dataset. Here we define and systematically study the architectural design
space for GNNs which consists of 315,000 different designs over 32 different
predictive tasks. Our approach features three key innovations: (1) A general
GNN design space; (2) a GNN task space with a similarity metric, so that for a
given novel task/dataset, we can quickly identify/transfer the best performing
architecture; (3) an efficient and effective design space evaluation method
which allows insights to be distilled from a huge number of model-task
combinations. Our key results include: (1) A comprehensive set of guidelines
for designing well-performing GNNs; (2) while best GNN designs for different
tasks vary significantly, the GNN task space allows for transferring the best
designs across different tasks; (3) models discovered using our design space
achieve state-of-the-art performance. Overall, our work offers a principled and
scalable approach to transition from studying individual GNN designs for
specific tasks, to systematically studying the GNN design space and the task
space. Finally, we release GraphGym, a powerful platform for exploring
different GNN designs and tasks. GraphGym features modularized GNN
implementation, standardized GNN evaluation, and reproducible and scalable
experiment management.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Online Reward Shaping in Sparse-Reward Environments. (arXiv:2103.04529v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Memarian_F/0/1/0/all/0/1">Farzan Memarian</a>, <a href="http://arxiv.org/find/cs/1/au:+Goo_W/0/1/0/all/0/1">Wonjoon Goo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lioutikov_R/0/1/0/all/0/1">Rudolf Lioutikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>, <a href="http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04529">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Self-supervised Online Reward Shaping (SORS), which aims to
improve the sample efficiency of any RL algorithm in sparse-reward environments
by automatically densifying rewards. The proposed framework alternates between
classification-based reward inference and policy update steps -- the original
sparse reward provides a self-supervisory signal for reward inference by
ranking trajectories that the agent observes, while the policy update is
performed with the newly inferred, typically dense reward function. We
introduce theory that shows that, under certain conditions, this alteration of
the reward function will not change the optimal policy of the original MDP,
while potentially increasing learning speed significantly. Experimental results
on several sparse-reward environments demonstrate that, across multiple
domains, the proposed algorithm is not only significantly more sample efficient
than a standard RL baseline using sparse rewards, but, at times, also achieves
similar sample efficiency compared to when hand-designed dense reward functions
are used.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predictive Monitoring with Logic-Calibrated Uncertainty for Cyber-Physical Systems. (arXiv:2011.00384v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Meiyi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Stankovic_J/0/1/0/all/0/1">John Stankovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartocci_E/0/1/0/all/0/1">Ezio Bartocci</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_L/0/1/0/all/0/1">Lu Feng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00384">
                                    <div class="article-summary-box-inner">
                                        <span>Predictive monitoring -- making predictions about future states and
monitoring if the predicted states satisfy requirements -- offers a promising
paradigm in supporting the decision making of Cyber-Physical Systems (CPS).
Existing works of predictive monitoring mostly focus on monitoring individual
predictions rather than sequential predictions. We develop a novel approach for
monitoring sequential predictions generated from Bayesian Recurrent Neural
Networks (RNNs) that can capture the inherent uncertainty in CPS, drawing on
insights from our study of real-world CPS datasets. We propose a new logic
named \emph{Signal Temporal Logic with Uncertainty} (STL-U) to monitor a
flowpipe containing an infinite set of uncertain sequences predicted by
Bayesian RNNs. We define STL-U strong and weak satisfaction semantics based on
if all or some sequences contained in a flowpipe satisfy the requirement. We
also develop methods to compute the range of confidence levels under which a
flowpipe is guaranteed to strongly (weakly) satisfy an STL-U formula.
Furthermore, we develop novel criteria that leverage STL-U monitoring results
to calibrate the uncertainty estimation in Bayesian RNNs. Finally, we evaluate
the proposed approach via experiments with real-world datasets and a simulated
smart city case study, which show very encouraging results of STL-U based
predictive monitoring approach outperforming baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximation Theory Based Methods for RKHS Bandits. (arXiv:2010.12167v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Takemori_S/0/1/0/all/0/1">Sho Takemori</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_M/0/1/0/all/0/1">Masahiro Sato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12167">
                                    <div class="article-summary-box-inner">
                                        <span>The RKHS bandit problem (also called kernelized multi-armed bandit problem)
is an online optimization problem of non-linear functions with noisy feedback.
Although the problem has been extensively studied, there are unsatisfactory
results for some problems compared to the well-studied linear bandit case.
Specifically, there is no general algorithm for the adversarial RKHS bandit
problem. In addition, high computational complexity of existing algorithms
hinders practical application. We address these issues by considering a novel
amalgamation of approximation theory and the misspecified linear bandit
problem. Using an approximation method, we propose efficient algorithms for the
stochastic RKHS bandit problem and the first general algorithm for the
adversarial RKHS bandit problem. Furthermore, we empirically show that one of
our proposed methods has comparable cumulative regret to IGP-UCB and its
running time is much shorter.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Closer Look at Codistillation for Distributed Training. (arXiv:2010.02838v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sodhani_S/0/1/0/all/0/1">Shagun Sodhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Delalleau_O/0/1/0/all/0/1">Olivier Delalleau</a>, <a href="http://arxiv.org/find/cs/1/au:+Assran_M/0/1/0/all/0/1">Mahmoud Assran</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_K/0/1/0/all/0/1">Koustuv Sinha</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1">Nicolas Ballas</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1">Michael Rabbat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02838">
                                    <div class="article-summary-box-inner">
                                        <span>Codistillation has been proposed as a mechanism to share knowledge among
concurrently trained models by encouraging them to represent the same function
through an auxiliary loss. This contrasts with the more commonly used
fully-synchronous data-parallel stochastic gradient descent methods, where
different model replicas average their gradients (or parameters) at every
iteration and thus maintain identical parameters. We investigate codistillation
in a distributed training setup, complementing previous work which focused on
extremely large batch sizes. Surprisingly, we find that even at moderate batch
sizes, models trained with codistillation can perform as well as models trained
with synchronous data-parallel methods, despite using a much weaker
synchronization mechanism. These findings hold across a range of batch sizes
and learning rate schedules, as well as different kinds of models and datasets.
Obtaining this level of accuracy, however, requires properly accounting for the
regularization effect of codistillation, which we highlight through several
empirical observations. Overall, this work contributes to a better
understanding of codistillation and how to best take advantage of it in a
distributed computing environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Multiple-Instance Data Classification with Costly Features. (arXiv:1911.08756v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Janisch_J/0/1/0/all/0/1">Jarom&#xed;r Janisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Pevny_T/0/1/0/all/0/1">Tom&#xe1;&#x161; Pevn&#xfd;</a>, <a href="http://arxiv.org/find/cs/1/au:+Lisy_V/0/1/0/all/0/1">Viliam Lis&#xfd;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.08756">
                                    <div class="article-summary-box-inner">
                                        <span>We extend the framework of Classification with Costly Features (CwCF) that
works with samples of fixed dimensions to trees of varying depth and breadth
(similar to a JSON/XML file). In this setting, the sample is a tree - sets of
sets of features. Individually for each sample, the task is to sequentially
select informative features that help the classification. Each feature has a
real-valued cost, and the objective is to maximize accuracy while minimizing
the total cost. The process is modeled as an MDP where the states represent the
acquired features, and the actions select unknown features. We present a
specialized neural network architecture trained through deep reinforcement
learning that naturally fits the data and directly selects features in the
tree. We demonstrate our method in seven datasets and compare it to two
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Lay Language Summarization of Biomedical Scientific Reviews. (arXiv:2012.12573v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yue Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_W/0/1/0/all/0/1">Wei Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yizhong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1">Trevor Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12573">
                                    <div class="article-summary-box-inner">
                                        <span>Health literacy has emerged as a crucial factor in making appropriate health
decisions and ensuring treatment outcomes. However, medical jargon and the
complex structure of professional language in this domain make health
information especially hard to interpret. Thus, there is an urgent unmet need
for automated methods to enhance the accessibility of the biomedical literature
to the general population. This problem can be framed as a type of translation
problem between the language of healthcare professionals, and that of the
general public. In this paper, we introduce the novel task of automated
generation of lay language summaries of biomedical scientific reviews, and
construct a dataset to support the development and evaluation of automated
methods through which to enhance the accessibility of the biomedical
literature. We conduct analyses of the various challenges in solving this task,
including not only summarization of the key points but also explanation of
background knowledge and simplification of professional language. We experiment
with state-of-the-art summarization models as well as several data augmentation
techniques, and evaluate their performance using both automated metrics and
human assessment. Results indicate that automatically generated summaries
produced using contemporary neural architectures can achieve promising quality
and readability as compared with reference summaries developed for the lay
public by experts (best ROUGE-L of 50.24 and Flesch-Kincaid readability score
of 13.30). We also discuss the limitations of the current attempt, providing
insights and directions for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning with Sparse Experience Replay for Lifelong Language Learning. (arXiv:2009.04891v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Holla_N/0/1/0/all/0/1">Nithin Holla</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_P/0/1/0/all/0/1">Pushkar Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Yannakoudakis_H/0/1/0/all/0/1">Helen Yannakoudakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1">Ekaterina Shutova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04891">
                                    <div class="article-summary-box-inner">
                                        <span>Lifelong learning requires models that can continuously learn from sequential
streams of data without suffering catastrophic forgetting due to shifts in data
distributions. Deep learning models have thrived in the non-sequential learning
paradigm; however, when used to learn a sequence of tasks, they fail to retain
past knowledge and learn incrementally. We propose a novel approach to lifelong
learning of language tasks based on meta-learning with sparse experience replay
that directly optimizes to prevent forgetting. We show that under the realistic
setting of performing a single pass on a stream of tasks and without any task
identifiers, our method obtains state-of-the-art results on lifelong text
classification and relation extraction. We analyze the effectiveness of our
approach and further demonstrate its low computational and space complexity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image compression optimized for 3D reconstruction by utilizing deep neural networks. (arXiv:2003.12618v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Golts_A/0/1/0/all/0/1">Alex Golts</a>, <a href="http://arxiv.org/find/eess/1/au:+Schechner_Y/0/1/0/all/0/1">Yoav Y. Schechner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.12618">
                                    <div class="article-summary-box-inner">
                                        <span>Computer vision tasks are often expected to be executed on compressed images.
Classical image compression standards like JPEG 2000 are widely used. However,
they do not account for the specific end-task at hand. Motivated by works on
recurrent neural network (RNN)-based image compression and three-dimensional
(3D) reconstruction, we propose unified network architectures to solve both
tasks jointly. These joint models provide image compression tailored for the
specific task of 3D reconstruction. Images compressed by our proposed models,
yield 3D reconstruction performance superior as compared to using JPEG 2000
compression. Our models significantly extend the range of compression rates for
which 3D reconstruction is possible. We also show that this can be done highly
efficiently at almost no additional cost to obtain compression on top of the
computation already required for performing the 3D reconstruction task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Settling the Robust Learnability of Mixtures of Gaussians. (arXiv:2011.03622v3 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Allen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1">Ankur Moitra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.03622">
                                    <div class="article-summary-box-inner">
                                        <span>This work represents a natural coalescence of two important lines of work:
learning mixtures of Gaussians and algorithmic robust statistics. In particular
we give the first provably robust algorithm for learning mixtures of any
constant number of Gaussians. We require only mild assumptions on the mixing
weights (bounded fractionality) and that the total variation distance between
components is bounded away from zero. At the heart of our algorithm is a new
method for proving dimension-independent polynomial identifiability through
applying a carefully chosen sequence of differential operations to certain
generating functions that not only encode the parameters we would like to learn
but also the system of polynomial equations we would like to solve. We show how
the symbolic identities we derive can be directly used to analyze a natural
sum-of-squares relaxation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Trust Intervals for Out of Distribution Detection. (arXiv:2102.01336v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_G/0/1/0/all/0/1">Gagandeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_D/0/1/0/all/0/1">Deepak Mishra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01336">
                                    <div class="article-summary-box-inner">
                                        <span>Building neural network classifiers with an ability to distinguish between in
and out-of distribution inputs is an important step towards faithful deep
learning systems. Some of the successful approaches for this, resort to
architectural novelties, such as ensembles, with increased complexities in
terms of the number of parameters and training procedures. Whereas some other
approaches make use of surrogate samples, which are easy to create and work as
proxies for actual out-of-distribution (OOD) samples, to train the networks for
OOD detection. In this paper, we propose a very simple approach for enhancing
the ability of a pretrained network to detect OOD inputs without even altering
the original parameter values. We define a probabilistic trust interval for
each weight parameter of the network and optimize its size according to the
in-distribution (ID) inputs. It allows the network to sample additional weight
values along with the original values at the time of inference and use the
observed disagreement among the corresponding outputs for OOD detection. In
order to capture the disagreement effectively, we also propose a measure and
establish its suitability using empirical evidence. Our approach outperforms
the existing state-of-the-art methods on various OOD datasets by considerable
margins without using any real or surrogate OOD samples. We also analyze the
performance of our approach on adversarial and corrupted inputs such as
CIFAR-10-C and demonstrate its ability to clearly distinguish such inputs as
well. By using fundamental theorem of calculus on neural networks, we explain
why our technique doesn&#x27;t need to observe OOD samples during training to
achieve results better than the previous works.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Analysis of LIME for Text Data. (arXiv:2010.12487v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mardaoui_D/0/1/0/all/0/1">Dina Mardaoui</a>, <a href="http://arxiv.org/find/stat/1/au:+Garreau_D/0/1/0/all/0/1">Damien Garreau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12487">
                                    <div class="article-summary-box-inner">
                                        <span>Text data are increasingly handled in an automated fashion by machine
learning algorithms. But the models handling these data are not always
well-understood due to their complexity and are more and more often referred to
as &quot;black-boxes.&quot; Interpretability methods aim to explain how these models
operate. Among them, LIME has become one of the most popular in recent years.
However, it comes without theoretical guarantees: even for simple models, we
are not sure that LIME behaves accurately. In this paper, we provide a first
theoretical analysis of LIME for text data. As a consequence of our theoretical
findings, we show that LIME indeed provides meaningful explanations for simple
models, namely decision trees and linear models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Automated Diagnosis of COVID-19 Based on Scanning Images. (arXiv:2006.05245v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Chen_D/0/1/0/all/0/1">Delong Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Ji_S/0/1/0/all/0/1">Shunhui Ji</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_F/0/1/0/all/0/1">Fan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1">Zewen Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1">Xinyu Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05245">
                                    <div class="article-summary-box-inner">
                                        <span>The pandemic of COVID-19 has caused millions of infections, which has led to
a great loss all over the world, socially and economically. Due to the
false-negative rate and the time-consuming of the conventional Reverse
Transcription Polymerase Chain Reaction (RT-PCR) tests, diagnosing based on
X-ray images and Computed Tomography (CT) images has been widely adopted.
Therefore, researchers of the computer vision area have developed many
automatic diagnosing models based on machine learning or deep learning to
assist the radiologists and improve the diagnosing accuracy. In this paper, we
present a review of these recently emerging automatic diagnosing models. 70
models proposed from February 14, 2020, to July 21, 2020, are involved. We
analyzed the models from the perspective of preprocessing, feature extraction,
classification, and evaluation. Based on the limitation of existing models, we
pointed out that domain adaption in transfer learning and interpretability
promotion would be the possible future directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Dark (and Bright) Side of IoT: Attacks and Countermeasures for Identifying Smart Home Devices and Services. (arXiv:2009.07672v4 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hussain_A/0/1/0/all/0/1">Ahmed Mohamed Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Oligeri_G/0/1/0/all/0/1">Gabriele Oligeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Voigt_T/0/1/0/all/0/1">Thiemo Voigt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07672">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new machine learning-based attack that exploits network patterns
to detect the presence of smart IoT devices and running services in the WiFi
radio spectrum. We perform an extensive measurement campaign of data
collection, and we build up a model describing the traffic patterns
characterizing three popular IoT smart home devices, i.e., Google Nest Mini,
Amazon Echo, and Amazon Echo Dot. We prove that it is possible to detect and
identify with overwhelming probability their presence and the services running
by the aforementioned devices in a crowded WiFi scenario. This work proves that
standard encryption techniques alone are not sufficient to protect the privacy
of the end-user, since the network traffic itself exposes the presence of both
the device and the associated service. While more work is required to prevent
non-trusted third parties to detect and identify the user&#x27;s devices, we
introduce Eclipse, a technique to mitigate these types of attacks, which
reshapes the traffic making the identification of the devices and the
associated services similar to the random classification baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sim2Sim Evaluation of a Novel Data-Efficient Differentiable Physics Engine for Tensegrity Robots. (arXiv:2011.04929v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Aanjaneya_M/0/1/0/all/0/1">Mridul Aanjaneya</a>, <a href="http://arxiv.org/find/cs/1/au:+Bekris_K/0/1/0/all/0/1">Kostas Bekris</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04929">
                                    <div class="article-summary-box-inner">
                                        <span>Learning policies in simulation is promising for reducing human effort when
training robot controllers. This is especially true for soft robots that are
more adaptive and safe but also more difficult to accurately model and control.
The sim2real gap is the main barrier to successfully transfer policies from
simulation to a real robot. System identification can be applied to reduce this
gap but traditional identification methods require a lot of manual tuning.
Data-driven alternatives can tune dynamical models directly from data but are
often data hungry, which also incorporates human effort in collecting data.
This work proposes a data-driven, end-to-end differentiable simulator focused
on the exciting but challenging domain of tensegrity robots. To the best of the
authors&#x27; knowledge, this is the first differentiable physics engine for
tensegrity robots that supports cable, contact, and actuation modeling. The aim
is to develop a reasonably simplified, data-driven simulation, which can learn
approximate dynamics with limited ground truth data. The dynamics must be
accurate enough to generate policies that can be transferred back to the
ground-truth system. As a first step in this direction, the current work
demonstrates sim2sim transfer, where the unknown physical model of MuJoCo acts
as a ground truth system. Two different tensegrity robots are used for
evaluation and learning of locomotion policies, a 6-bar and a 3-bar tensegrity.
The results indicate that only 0.25\% of ground truth data are needed to train
a policy that works on the ground truth system when the differentiable engine
is used for training against training the policy directly on the ground truth
system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">INSTA-YOLO: Real-Time Instance Segmentation. (arXiv:2102.06777v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohamed_E/0/1/0/all/0/1">Eslam Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaker_A/0/1/0/all/0/1">Abdelrahman Shaker</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Sallab_A/0/1/0/all/0/1">Ahmad El-Sallab</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadhoud_M/0/1/0/all/0/1">Mayada Hadhoud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06777">
                                    <div class="article-summary-box-inner">
                                        <span>Instance segmentation has gained recently huge attention in various computer
vision applications. It aims at providing different IDs to different objects of
the scene, even if they belong to the same class. Instance segmentation is
usually performed as a two-stage pipeline. First, an object is detected, then
semantic segmentation within the detected box area is performed which involves
costly up-sampling. In this paper, we propose Insta-YOLO, a novel one-stage
end-to-end deep learning model for real-time instance segmentation. Instead of
pixel-wise prediction, our model predicts instances as object contours
represented by 2D points in Cartesian space. We evaluate our model on three
datasets, namely, Carvana,Cityscapes and Airbus. We compare our results to the
state-of-the-art models for instance segmentation. The results show our model
achieves competitive accuracy in terms of mAP at twice the speed on GTX-1080
GPU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PDE-based Group Equivariant Convolutional Neural Networks. (arXiv:2001.09046v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Smets_B/0/1/0/all/0/1">Bart Smets</a>, <a href="http://arxiv.org/find/cs/1/au:+Portegies_J/0/1/0/all/0/1">Jim Portegies</a>, <a href="http://arxiv.org/find/cs/1/au:+Bekkers_E/0/1/0/all/0/1">Erik Bekkers</a>, <a href="http://arxiv.org/find/cs/1/au:+Duits_R/0/1/0/all/0/1">Remco Duits</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.09046">
                                    <div class="article-summary-box-inner">
                                        <span>We present a PDE-based framework that generalizes Group equivariant
Convolutional Neural Networks (G-CNNs). In this framework, a network layer is
seen as a set of PDE-solvers where geometrically meaningful PDE-coefficients
become the layer&#x27;s trainable weights. Formulating our PDEs on homogeneous
spaces allows these networks to be designed with built-in symmetries such as
rotation in addition to the standard translation equivariance of CNNs.

Having all the desired symmetries included in the design obviates the need to
include them by means of costly techniques such as data augmentation. We will
discuss our PDE-based G-CNNs (PDE-G-CNNs) in a general homogeneous space
setting while also going into the specifics of our primary case of interest:
roto-translation equivariance.

We solve the PDE of interest by a combination of linear group convolutions
and non-linear morphological group convolutions with analytic kernel
approximations that we underpin with formal theorems. Our kernel approximations
allow for fast GPU-implementation of the PDE-solvers, we release our
implementation with this article. Just like for linear convolution a
morphological convolution is specified by a kernel that we train in our
PDE-G-CNNs. In PDE-G-CNNs we do not use non-linearities such as max/min-pooling
and ReLUs as they are already subsumed by morphological convolutions.

We present a set of experiments to demonstrate the strength of the proposed
PDE-G-CNNs in increasing the performance of deep learning based imaging
applications with far fewer parameters than traditional CNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Data Set and a Convolutional Model for Iconography Classification in Paintings. (arXiv:2010.11697v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Milani_F/0/1/0/all/0/1">Federico Milani</a>, <a href="http://arxiv.org/find/cs/1/au:+Fraternali_P/0/1/0/all/0/1">Piero Fraternali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11697">
                                    <div class="article-summary-box-inner">
                                        <span>Iconography in art is the discipline that studies the visual content of
artworks to determine their motifs and themes andto characterize the way these
are represented. It is a subject of active research for a variety of purposes,
including the interpretation of meaning, the investigation of the origin and
diffusion in time and space of representations, and the study of influences
across artists and art works. With the proliferation of digital archives of art
images, the possibility arises of applying Computer Vision techniques to the
analysis of art images at an unprecedented scale, which may support iconography
research and education. In this paper we introduce a novel paintings data set
for iconography classification and present the quantitativeand qualitative
results of applying a Convolutional Neural Network (CNN) classifier to the
recognition of the iconography of artworks. The proposed classifier achieves
good performances (71.17% Precision, 70.89% Recall, 70.25% F1-Score and 72.73%
Average Precision) in the task of identifying saints in Christian religious
paintings, a task made difficult by the presence of classes with very similar
visual features. Qualitative analysis of the results shows that the CNN focuses
on the traditional iconic motifs that characterize the representation of each
saint and exploits such hints to attain correct identification. The ultimate
goal of our work is to enable the automatic extraction, decomposition, and
comparison of iconography elements to support iconographic studies and
automatic art work annotation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit bias of gradient descent for mean squared error regression with wide neural networks. (arXiv:2006.07356v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Jin_H/0/1/0/all/0/1">Hui Jin</a>, <a href="http://arxiv.org/find/stat/1/au:+Montufar_G/0/1/0/all/0/1">Guido Mont&#xfa;far</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07356">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate gradient descent training of wide neural networks and the
corresponding implicit bias in function space. For univariate regression, we
show that the solution of training a width-$n$ shallow ReLU network is within
$n^{- 1/2}$ of the function which fits the training data and whose difference
from the initial function has the smallest 2-norm of the second derivative
weighted by a curvature penalty that depends on the probability distribution
that is used to initialize the network parameters. We compute the curvature
penalty function explicitly for various common initialization procedures. For
instance, asymmetric initialization with a uniform distribution yields a
constant curvature penalty, and thence the solution function is the natural
cubic spline interpolation of the training data. We obtain a similar result for
different activation functions. For multivariate regression we show an
analogous result, whereby the second derivative is replaced by the Radon
transform of a fractional Laplacian. For initialization schemes that yield a
constant penalty function, the solutions are polyharmonic splines. Moreover, we
show that the training trajectories are captured by trajectories of smoothing
splines with decreasing regularization strength.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AA3DNet: Attention Augmented Real Time 3D Object Detection. (arXiv:2107.12137v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sagar_A/0/1/0/all/0/1">Abhinav Sagar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12137">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we address the problem of 3D object detection from point cloud
data in real time. For autonomous vehicles to work, it is very important for
the perception component to detect the real world objects with both high
accuracy and fast inference. We propose a novel neural network architecture
along with the training and optimization details for detecting 3D objects using
point cloud data. We present anchor design along with custom loss functions
used in this work. A combination of spatial and channel wise attention module
is used in this work. We use the Kitti 3D Birds Eye View dataset for
benchmarking and validating our results. Our method surpasses previous state of
the art in this domain both in terms of average precision and speed running at
&gt; 30 FPS. Finally, we present the ablation study to demonstrate that the
performance of our network is generalizable. This makes it a feasible option to
be deployed in real time applications like self driving cars.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Trade When Opportunity Comes: Price Movement Forecasting via Locality-Aware Attention and Adaptive Refined Labeling. (arXiv:2107.11972v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1">Liang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_H/0/1/0/all/0/1">Hui Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruchen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1">Zhonghao Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_D/0/1/0/all/0/1">Dewei Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Ling Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11972">
                                    <div class="article-summary-box-inner">
                                        <span>Price movement forecasting aims at predicting the future trends of financial
assets based on the current market conditions and other relevant information.
Recently, machine learning(ML) methods have become increasingly popular and
achieved promising results for price movement forecasting in both academia and
industry. Most existing ML solutions formulate the forecasting problem as a
classification(to predict the direction) or a regression(to predict the return)
problem in the entire set of training data. However, due to the extremely low
signal-to-noise ratio and stochastic nature of financial data, good trading
opportunities are extremely scarce. As a result, without careful selection of
potentially profitable samples, such ML methods are prone to capture the
patterns of noises instead of real signals. To address the above issues, we
propose a novel framework-LARA(Locality-Aware Attention and Adaptive Refined
Labeling), which contains the following three components: 1)Locality-aware
attention automatically extracts the potentially profitable samples by
attending to their label information in order to construct a more accurate
classifier on these selected samples. 2)Adaptive refined labeling further
iteratively refines the labels, alleviating the noise of samples. 3)Equipped
with metric learning techniques, Locality-aware attention enjoys task-specific
distance metrics and distributes attention on potentially profitable samples in
a more effective way. To validate our method, we conduct comprehensive
experiments on three real-world financial markets: ETFs, the China&#x27;s A-share
stock market, and the cryptocurrency market. LARA achieves superior performance
compared with the time-series analysis methods and a set of machine learning
based competitors on the Qlib platform. Extensive ablation studies and
experiments demonstrate that LARA indeed captures more reliable trading
opportunities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalization Bounds in the Predict-then-Optimize Framework. (arXiv:1905.11488v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balghiti_O/0/1/0/all/0/1">Othman El Balghiti</a>, <a href="http://arxiv.org/find/cs/1/au:+Elmachtoub_A/0/1/0/all/0/1">Adam N. Elmachtoub</a>, <a href="http://arxiv.org/find/cs/1/au:+Grigas_P/0/1/0/all/0/1">Paul Grigas</a>, <a href="http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1">Ambuj Tewari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.11488">
                                    <div class="article-summary-box-inner">
                                        <span>The predict-then-optimize framework is fundamental in many practical
settings: predict the unknown parameters of an optimization problem, and then
solve the problem using the predicted values of the parameters. A natural loss
function in this environment is to consider the cost of the decisions induced
by the predicted parameters, in contrast to the prediction error of the
parameters. This loss function was recently introduced in Elmachtoub and Grigas
(2017) and referred to as the Smart Predict-then-Optimize (SPO) loss. In this
work, we seek to provide bounds on how well the performance of a prediction
model fit on training data generalizes out-of-sample, in the context of the SPO
loss. Since the SPO loss is non-convex and non-Lipschitz, standard results for
deriving generalization bounds do not apply.

We first derive bounds based on the Natarajan dimension that, in the case of
a polyhedral feasible region, scale at most logarithmically in the number of
extreme points, but, in the case of a general convex feasible region, have
linear dependence on the decision dimension. By exploiting the structure of the
SPO loss function and a key property of the feasible region, which we denote as
the strength property, we can dramatically improve the dependence on the
decision and feature dimensions. Our approach and analysis rely on placing a
margin around problematic predictions that do not yield unique optimal
solutions, and then providing generalization bounds in the context of a
modified margin SPO loss function that is Lipschitz continuous. Finally, we
characterize the strength property and show that the modified SPO loss can be
computed efficiently for both strongly convex bodies and polytopes with an
explicit extreme point representation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Study on Speech Enhancement Based on Diffusion Probabilistic Model. (arXiv:2107.11876v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lu_Y/0/1/0/all/0/1">Yen-Ju Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Tsao_Y/0/1/0/all/0/1">Yu Tsao</a>, <a href="http://arxiv.org/find/eess/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11876">
                                    <div class="article-summary-box-inner">
                                        <span>Diffusion probabilistic models have demonstrated an outstanding capability to
model natural images and raw audio waveforms through a paired diffusion and
reverse processes. The unique property of the reverse process (namely,
eliminating non-target signals from the Gaussian noise and noisy signals) could
be utilized to restore clean signals. Based on this property, we propose a
diffusion probabilistic model-based speech enhancement (DiffuSE) model that
aims to recover clean speech signals from noisy signals. The fundamental
architecture of the proposed DiffuSE model is similar to that of DiffWave--a
high-quality audio waveform generation model that has a relatively low
computational cost and footprint. To attain better enhancement performance, we
designed an advanced reverse process, termed the supportive reverse process,
which adds noisy speech in each time-step to the predicted speech. The
experimental results show that DiffuSE yields performance that is comparable to
related audio generative models on the standardized Voice Bank corpus SE task.
Moreover, relative to the generally suggested full sampling schedule, the
proposed supportive reverse process especially improved the fast sampling,
taking few steps to yield better enhancement results over the conventional full
step inference process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Federated Learning: Balancing Communication and Computing Costs. (arXiv:2107.12048v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenyi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12048">
                                    <div class="article-summary-box-inner">
                                        <span>Decentralized federated learning (DFL) is a powerful framework of distributed
machine learning and decentralized stochastic gradient descent (SGD) is a
driving engine for DFL. The performance of decentralized SGD is jointly
influenced by communication-efficiency and convergence rate. In this paper, we
propose a general decentralized federated learning framework to strike a
balance between communication-efficiency and convergence performance. The
proposed framework performs both multiple local updates and multiple inter-node
communications periodically, unifying traditional decentralized SGD methods. We
establish strong convergence guarantees for the proposed DFL algorithm without
the assumption of convex objective function. The balance of communication and
computation rounds is essential to optimize decentralized federated learning
under constrained communication and computation resources. For further
improving communication-efficiency of DFL, compressed communication is applied
to DFL, named DFL with compressed communication (C-DFL). The proposed C-DFL
exhibits linear convergence for strongly convex objectives. Experiment results
based on MNIST and CIFAR-10 datasets illustrate the superiority of DFL over
traditional decentralized SGD methods and show that C-DFL further enhances
communication-efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedGroup: Efficient Clustered Federated Learning via Decomposed Data-Driven Measure. (arXiv:2010.06870v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Duan_M/0/1/0/all/0/1">Moming Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Duo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1">Xinyuan Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Renping Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_L/0/1/0/all/0/1">Liang Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xianzhang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1">Yujuan Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06870">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) enables the multiple participating devices to
collaboratively contribute to a global neural network model while keeping the
training data locally. Unlike the centralized training setting, the non-IID and
imbalanced (statistical heterogeneity) training data of FL is distributed in
the federated network, which will increase the divergences between the local
models and global model, further degrading performance. In this paper, we
propose a novel clustered federated learning (CFL) framework FedGroup, in which
we 1) group the training of clients based on the similarities between the
clients&#x27; optimization directions for high training performance; 2) construct a
new data-driven distance measure to improve the efficiency of the client
clustering procedure. 3) implement a newcomer device cold start mechanism based
on the auxiliary global model for framework scalability and practicality.

FedGroup can achieve improvements by dividing joint optimization into groups
of sub-optimization and can be combined with FL optimizer FedProx. The
convergence and complexity are analyzed to demonstrate the efficiency of our
proposed framework. We also evaluate FedGroup and FedGrouProx (combined with
FedProx) on several open datasets and made comparisons with related CFL
frameworks. The results show that FedGroup can significantly improve absolute
test accuracy by +14.1% on FEMNIST compared to FedAvg. +3.4% on Sentiment140
compared to FedProx, +6.9% on MNIST compared to FeSEM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Argumentative Dialogue System for COVID-19 Vaccine Information. (arXiv:2107.12079v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fazzinga_B/0/1/0/all/0/1">Bettina Fazzinga</a>, <a href="http://arxiv.org/find/cs/1/au:+Galassi_A/0/1/0/all/0/1">Andrea Galassi</a>, <a href="http://arxiv.org/find/cs/1/au:+Torroni_P/0/1/0/all/0/1">Paolo Torroni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12079">
                                    <div class="article-summary-box-inner">
                                        <span>Dialogue systems are widely used in AI to support timely and interactive
communication with users. We propose a general-purpose dialogue system
architecture that leverages computational argumentation and state-of-the-art
language technologies. We illustrate and evaluate the system using a COVID-19
vaccine information case study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GCExplainer: Human-in-the-Loop Concept-based Explanations for Graph Neural Networks. (arXiv:2107.11889v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Magister_L/0/1/0/all/0/1">Lucie Charlotte Magister</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazhdan_D/0/1/0/all/0/1">Dmitry Kazhdan</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1">Vikash Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lio_P/0/1/0/all/0/1">Pietro Li&#xf2;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11889">
                                    <div class="article-summary-box-inner">
                                        <span>While graph neural networks (GNNs) have been shown to perform well on
graph-based data from a variety of fields, they suffer from a lack of
transparency and accountability, which hinders trust and consequently the
deployment of such models in high-stake and safety-critical scenarios. Even
though recent research has investigated methods for explaining GNNs, these
methods are limited to single-instance explanations, also known as local
explanations. Motivated by the aim of providing global explanations, we adapt
the well-known Automated Concept-based Explanation approach (Ghorbani et al.,
2019) to GNN node and graph classification, and propose GCExplainer.
GCExplainer is an unsupervised approach for post-hoc discovery and extraction
of global concept-based explanations for GNNs, which puts the human in the
loop. We demonstrate the success of our technique on five node classification
datasets and two graph classification datasets, showing that we are able to
discover and extract high-quality concept representations by putting the human
in the loop. We achieve a maximum completeness score of 1 and an average
completeness score of 0.753 across the datasets. Finally, we show that the
concept-based explanations provide an improved insight into the datasets and
GNN models compared to the state-of-the-art explanations produced by
GNNExplainer (Ying et al., 2019).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Fusion Using Deep Learning Applied to Driver&#x27;s Referencing of Outside-Vehicle Objects. (arXiv:2107.12167v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aftab_A/0/1/0/all/0/1">Abdul Rafey Aftab</a>, <a href="http://arxiv.org/find/cs/1/au:+Beeck_M/0/1/0/all/0/1">Michael von der Beeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohrhirsch_S/0/1/0/all/0/1">Steven Rohrhirsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Diotte_B/0/1/0/all/0/1">Benoit Diotte</a>, <a href="http://arxiv.org/find/cs/1/au:+Feld_M/0/1/0/all/0/1">Michael Feld</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12167">
                                    <div class="article-summary-box-inner">
                                        <span>There is a growing interest in more intelligent natural user interaction with
the car. Hand gestures and speech are already being applied for driver-car
interaction. Moreover, multimodal approaches are also showing promise in the
automotive industry. In this paper, we utilize deep learning for a multimodal
fusion network for referencing objects outside the vehicle. We use features
from gaze, head pose and finger pointing simultaneously to precisely predict
the referenced objects in different car poses. We demonstrate the practical
limitations of each modality when used for a natural form of referencing,
specifically inside the car. As evident from our results, we overcome the
modality specific limitations, to a large extent, by the addition of other
modalities. This work highlights the importance of multimodal sensing,
especially when moving towards natural user interaction. Furthermore, our user
based analysis shows noteworthy differences in recognition of user behavior
depending upon the vehicle pose.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Certify Machine Learning Based Safety-critical Systems? A Systematic Literature Review. (arXiv:2107.12045v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tambon_F/0/1/0/all/0/1">Florian Tambon</a>, <a href="http://arxiv.org/find/cs/1/au:+Laberge_G/0/1/0/all/0/1">Gabriel Laberge</a>, <a href="http://arxiv.org/find/cs/1/au:+An_L/0/1/0/all/0/1">Le An</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikanjam_A/0/1/0/all/0/1">Amin Nikanjam</a>, <a href="http://arxiv.org/find/cs/1/au:+Mindom_P/0/1/0/all/0/1">Paulina Stevia Nouwou Mindom</a>, <a href="http://arxiv.org/find/cs/1/au:+Pequignot_Y/0/1/0/all/0/1">Yann Pequignot</a>, <a href="http://arxiv.org/find/cs/1/au:+Khomh_F/0/1/0/all/0/1">Foutse Khomh</a>, <a href="http://arxiv.org/find/cs/1/au:+Antoniol_G/0/1/0/all/0/1">Giulio Antoniol</a>, <a href="http://arxiv.org/find/cs/1/au:+Merlo_E/0/1/0/all/0/1">Ettore Merlo</a>, <a href="http://arxiv.org/find/cs/1/au:+Laviolette_F/0/1/0/all/0/1">Fran&#xe7;ois Laviolette</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12045">
                                    <div class="article-summary-box-inner">
                                        <span>Context: Machine Learning (ML) has been at the heart of many innovations over
the past years. However, including it in so-called &#x27;safety-critical&#x27; systems
such as automotive or aeronautic has proven to be very challenging, since the
shift in paradigm that ML brings completely changes traditional certification
approaches.

Objective: This paper aims to elucidate challenges related to the
certification of ML-based safety-critical systems, as well as the solutions
that are proposed in the literature to tackle them, answering the question &#x27;How
to Certify Machine Learning Based Safety-critical Systems?&#x27;.

Method: We conduct a Systematic Literature Review (SLR) of research papers
published between 2015 to 2020, covering topics related to the certification of
ML systems. In total, we identified 229 papers covering topics considered to be
the main pillars of ML certification: Robustness, Uncertainty, Explainability,
Verification, Safe Reinforcement Learning, and Direct Certification. We
analyzed the main trends and problems of each sub-field and provided summaries
of the papers extracted.

Results: The SLR results highlighted the enthusiasm of the community for this
subject, as well as the lack of diversity in terms of datasets and type of
models. It also emphasized the need to further develop connections between
academia and industries to deepen the domain study. Finally, it also
illustrated the necessity to build connections between the above mention main
pillars that are for now mainly studied separately.

Conclusion: We highlighted current efforts deployed to enable the
certification of ML based software systems, and discuss some future research
directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepHateExplainer: Explainable Hate Speech Detection in Under-resourced Bengali Language. (arXiv:2012.14353v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karim_M/0/1/0/all/0/1">Md. Rezaul Karim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dey_S/0/1/0/all/0/1">Sumon Kanti Dey</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_T/0/1/0/all/0/1">Tanhim Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarker_S/0/1/0/all/0/1">Sagor Sarker</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_M/0/1/0/all/0/1">Mehadi Hasan Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_K/0/1/0/all/0/1">Kabir Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarthi_B/0/1/0/all/0/1">Bharathi Raja Chakravarthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_M/0/1/0/all/0/1">Md. Azam Hossain</a>, <a href="http://arxiv.org/find/cs/1/au:+Decker_S/0/1/0/all/0/1">Stefan Decker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14353">
                                    <div class="article-summary-box-inner">
                                        <span>The exponential growths of social media and micro-blogging sites not only
provide platforms for empowering freedom of expressions and individual voices,
but also enables people to express anti-social behavior like online harassment,
cyberbullying, and hate speech. Numerous works have been proposed to utilize
textual data for social and anti-social behavior analysis, by predicting the
contexts mostly for highly-resourced languages like English. However, some
languages are under-resourced, e.g., South Asian languages like Bengali, that
lack computational resources for accurate natural language processing (NLP). In
this paper, we propose an explainable approach for hate speech detection from
the under-resourced Bengali language, which we called DeepHateExplainer.
Bengali texts are first comprehensively preprocessed, before classifying them
into political, personal, geopolitical, and religious hates using a neural
ensemble method of transformer-based neural architectures (i.e., monolingual
Bangla BERT-base, multilingual BERT-cased/uncased, and XLM-RoBERTa).
Important~(most and least) terms are then identified using sensitivity analysis
and layer-wise relevance propagation~(LRP), before providing
human-interpretable explanations. Finally, we compute comprehensiveness and
sufficiency scores to measure the quality of explanations w.r.t faithfulness.
Evaluations against machine learning~(linear and tree-based models) and neural
networks (i.e., CNN, Bi-LSTM, and Conv-LSTM with word embeddings) baselines
yield F1-scores of 78%, 91%, 89%, and 84%, for political, personal,
geopolitical, and religious hates, respectively, outperforming both ML and DNN
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Membership Inference Attack and Defense for Wireless Signal Classifiers with Deep Learning. (arXiv:2107.12173v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yi Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sagduyu_Y/0/1/0/all/0/1">Yalin E. Sagduyu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12173">
                                    <div class="article-summary-box-inner">
                                        <span>An over-the-air membership inference attack (MIA) is presented to leak
private information from a wireless signal classifier. Machine learning (ML)
provides powerful means to classify wireless signals, e.g., for PHY-layer
authentication. As an adversarial machine learning attack, the MIA infers
whether a signal of interest has been used in the training data of a target
classifier. This private information incorporates waveform, channel, and device
characteristics, and if leaked, can be exploited by an adversary to identify
vulnerabilities of the underlying ML model (e.g., to infiltrate the PHY-layer
authentication). One challenge for the over-the-air MIA is that the received
signals and consequently the RF fingerprints at the adversary and the intended
receiver differ due to the discrepancy in channel conditions. Therefore, the
adversary first builds a surrogate classifier by observing the spectrum and
then launches the black-box MIA on this classifier. The MIA results show that
the adversary can reliably infer signals (and potentially the radio and channel
information) used to build the target classifier. Therefore, a proactive
defense is developed against the MIA by building a shadow MIA model and fooling
the adversary. This defense can successfully reduce the MIA accuracy and
prevent information leakage from the wireless signal classifier.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining Local, Global, And Higher-Order Interactions In Deep Learning. (arXiv:2006.08601v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lerman_S/0/1/0/all/0/1">Samuel Lerman</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chenliang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Venuto_C/0/1/0/all/0/1">Charles Venuto</a>, <a href="http://arxiv.org/find/cs/1/au:+Kautz_H/0/1/0/all/0/1">Henry Kautz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08601">
                                    <div class="article-summary-box-inner">
                                        <span>We present a simple yet highly generalizable method for explaining
interacting parts within a neural network&#x27;s reasoning process. First, we design
an algorithm based on cross derivatives for computing statistical interaction
effects between individual features, which is generalized to both 2-way and
higher-order (3-way or more) interactions. We present results side by side with
a weight-based attribution technique, corroborating that cross derivatives are
a superior metric for both 2-way and higher-order interaction detection.
Moreover, we extend the use of cross derivatives as an explanatory device in
neural networks to the computer vision setting by expanding Grad-CAM, a popular
gradient-based explanatory tool for CNNs, to the higher order. While Grad-CAM
can only explain the importance of individual objects in images, our method,
which we call Taylor-CAM, can explain a neural network&#x27;s relational reasoning
across multiple objects. We show the success of our explanations both
qualitatively and quantitatively, including with a user study. We will release
all code as a tool package to facilitate explainable deep learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Maximum-Likelihood with Deep Learning for Event Reconstruction in IceCube. (arXiv:2107.12110v1 [astro-ph.HE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Hunnefeld_M/0/1/0/all/0/1">Mirco H&#xfc;nnefeld</a> (for the IceCube Collaboration)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12110">
                                    <div class="article-summary-box-inner">
                                        <span>The field of deep learning has become increasingly important for particle
physics experiments, yielding a multitude of advances, predominantly in event
classification and reconstruction tasks. Many of these applications have been
adopted from other domains. However, data in the field of physics are unique in
the context of machine learning, insofar as their generation process and the
laws and symmetries they abide by are usually well understood. Most commonly
used deep learning architectures fail at utilizing this available information.
In contrast, more traditional likelihood-based methods are capable of
exploiting domain knowledge, but they are often limited by computational
complexity. In this contribution, a hybrid approach is presented that utilizes
generative neural networks to approximate the likelihood, which may then be
used in a traditional maximum-likelihood setting. Domain knowledge, such as
invariances and detector characteristics, can easily be incorporated in this
approach. The hybrid approach is illustrated by the example of event
reconstruction in IceCube.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Error Diffusion Halftoning Against Adversarial Examples. (arXiv:2101.09451v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1">Shao-Yuan Lo</a>, <a href="http://arxiv.org/find/cs/1/au:+Patel_V/0/1/0/all/0/1">Vishal M. Patel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09451">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial examples contain carefully crafted perturbations that can fool
deep neural networks (DNNs) into making wrong predictions. Enhancing the
adversarial robustness of DNNs has gained considerable interest in recent
years. Although image transformation-based defenses were widely considered at
an earlier time, most of them have been defeated by adaptive attacks. In this
paper, we propose a new image transformation defense based on error diffusion
halftoning, and combine it with adversarial training to defend against
adversarial examples. Error diffusion halftoning projects an image into a 1-bit
space and diffuses quantization error to neighboring pixels. This process can
remove adversarial perturbations from a given image while maintaining
acceptable image quality in the meantime in favor of recognition. Experimental
results demonstrate that the proposed method is able to improve adversarial
robustness even under advanced adaptive attacks, while most of the other image
transformation-based defenses do not. We show that a proper image
transformation can still be an effective defense approach. Code:
https://github.com/shaoyuanlo/Halftoning-Defense</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Picket: Guarding Against Corrupted Data in Tabular Data during Learning and Inference. (arXiv:2006.04730v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zifan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhechun Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekatsinas_T/0/1/0/all/0/1">Theodoros Rekatsinas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04730">
                                    <div class="article-summary-box-inner">
                                        <span>Data corruption is an impediment to modern machine learning deployments.
Corrupted data can severely bias the learned model and can also lead to invalid
inferences. We present, Picket, a simple framework to safeguard against data
corruptions during both training and deployment of machine learning models over
tabular data. For the training stage, Picket identifies and removes corrupted
data points from the training data to avoid obtaining a biased model. For the
deployment stage, Picket flags, in an online manner, corrupted query points to
a trained machine learning model that due to noise will result in incorrect
predictions. To detect corrupted data, Picket uses a self-supervised deep
learning model for mixed-type tabular data, which we call PicketNet. To
minimize the burden of deployment, learning a PicketNet model does not require
any human-labeled data. Picket is designed as a plugin that can increase the
robustness of any machine learning pipeline. We evaluate Picket on a diverse
array of real-world data considering different corruption models that include
systematic and adversarial noise during both training and testing. We show that
Picket consistently safeguards against corrupted data during both training and
deployment of various models ranging from SVMs to neural networks, beating a
diverse array of competing methods that span from data quality validation
models to robust outlier-detection models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D AGSE-VNet: An Automatic Brain Tumor MRI Data Segmentation Framework. (arXiv:2107.12046v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1">Xi Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jianming Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Weiji Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaomei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weiwei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_X/0/1/0/all/0/1">Xiaobo Lai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12046">
                                    <div class="article-summary-box-inner">
                                        <span>Background: Glioma is the most common brain malignant tumor, with a high
morbidity rate and a mortality rate of more than three percent, which seriously
endangers human health. The main method of acquiring brain tumors in the clinic
is MRI. Segmentation of brain tumor regions from multi-modal MRI scan images is
helpful for treatment inspection, post-diagnosis monitoring, and effect
evaluation of patients. However, the common operation in clinical brain tumor
segmentation is still manual segmentation, lead to its time-consuming and large
performance difference between different operators, a consistent and accurate
automatic segmentation method is urgently needed. Methods: To meet the above
challenges, we propose an automatic brain tumor MRI data segmentation framework
which is called AGSE-VNet. In our study, the Squeeze and Excite (SE) module is
added to each encoder, the Attention Guide Filter (AG) module is added to each
decoder, using the channel relationship to automatically enhance the useful
information in the channel to suppress the useless information, and use the
attention mechanism to guide the edge information and remove the influence of
irrelevant information such as noise. Results: We used the BraTS2020 challenge
online verification tool to evaluate our approach. The focus of verification is
that the Dice scores of the whole tumor (WT), tumor core (TC) and enhanced
tumor (ET) are 0.68, 0.85 and 0.70, respectively. Conclusion: Although MRI
images have different intensities, AGSE-VNet is not affected by the size of the
tumor, and can more accurately extract the features of the three regions, it
has achieved impressive results and made outstanding contributions to the
clinical diagnosis and treatment of brain tumor patients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aligning AI With Shared Human Values. (arXiv:2008.02275v5 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1">Dan Hendrycks</a>, <a href="http://arxiv.org/find/cs/1/au:+Burns_C/0/1/0/all/0/1">Collin Burns</a>, <a href="http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1">Steven Basart</a>, <a href="http://arxiv.org/find/cs/1/au:+Critch_A/0/1/0/all/0/1">Andrew Critch</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jerry Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dawn Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1">Jacob Steinhardt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02275">
                                    <div class="article-summary-box-inner">
                                        <span>We show how to assess a language model&#x27;s knowledge of basic concepts of
morality. We introduce the ETHICS dataset, a new benchmark that spans concepts
in justice, well-being, duties, virtues, and commonsense morality. Models
predict widespread moral judgments about diverse text scenarios. This requires
connecting physical and social world knowledge to value judgements, a
capability that may enable us to steer chatbot outputs or eventually regularize
open-ended reinforcement learning agents. With the ETHICS dataset, we find that
current language models have a promising but incomplete ability to predict
basic human ethical judgements. Our work shows that progress can be made on
machine ethics today, and it provides a steppingstone toward AI that is aligned
with human values.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A vector-contraction inequality for Rademacher complexities using $p$-stable variables. (arXiv:1912.10136v2 [math.PR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Zatarain_Vera_O/0/1/0/all/0/1">Oscar Zatarain-Vera</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.10136">
                                    <div class="article-summary-box-inner">
                                        <span>Andreas Maurer in the paper &quot;A vector-contraction inequality for Rademacher
complexities&quot; extended the contraction inequality for Rademacher averages to
Lipschitz functions with vector-valued domains; He did it replacing the
Rademacher variables in the bounding expression by arbitrary idd symmetric and
sub-gaussian variables. We will see how to extend this work when we replace
sub-gaussian variables by $p$-stable variables for $1&lt;p&lt;2$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Regularized Locality Preserving Indexing for Fiedler Vector Estimation. (arXiv:2107.12070v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tastan_A/0/1/0/all/0/1">Aylin Tastan</a>, <a href="http://arxiv.org/find/eess/1/au:+Muma_M/0/1/0/all/0/1">Michael Muma</a>, <a href="http://arxiv.org/find/eess/1/au:+Zoubir_A/0/1/0/all/0/1">Abdelhak M. Zoubir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12070">
                                    <div class="article-summary-box-inner">
                                        <span>The Fiedler vector of a connected graph is the eigenvector associated with
the algebraic connectivity of the graph Laplacian and it provides substantial
information to learn the latent structure of a graph. In real-world
applications, however, the data may be subject to heavy-tailed noise and
outliers which results in deteriorations in the structure of the Fiedler vector
estimate. We design a Robust Regularized Locality Preserving Indexing (RRLPI)
method for Fiedler vector estimation that aims to approximate the nonlinear
manifold structure of the Laplace Beltrami operator while minimizing the
negative impact of outliers. First, an analysis of the effects of two
fundamental outlier types on the eigen-decomposition for block affinity
matrices which are essential in cluster analysis is conducted. Then, an error
model is formulated and a robust Fiedler vector estimation algorithm is
developed. An unsupervised penalty parameter selection algorithm is proposed
that leverages the geometric structure of the projection space to perform
robust regularized Fiedler estimation. The performance of RRLPI is benchmarked
against existing competitors in terms of detection probability, partitioning
quality, image segmentation capability, robustness and computation time using a
large variety of synthetic and real data experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Symbolic Relational Deep Reinforcement Learning based on Graph Neural Networks. (arXiv:2009.12462v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Janisch_J/0/1/0/all/0/1">Jarom&#xed;r Janisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Pevny_T/0/1/0/all/0/1">Tom&#xe1;&#x161; Pevn&#xfd;</a>, <a href="http://arxiv.org/find/cs/1/au:+Lisy_V/0/1/0/all/0/1">Viliam Lis&#xfd;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.12462">
                                    <div class="article-summary-box-inner">
                                        <span>We focus on reinforcement learning (RL) in relational problems that are
naturally defined in terms of objects, their relations, and manipulations.
These problems are characterized by variable state and action spaces, and
finding a fixed-length representation, required by most existing RL methods, is
difficult, if not impossible. We present a deep RL framework based on graph
neural networks and auto-regressive policy decomposition that naturally works
with these problems and is completely domain-independent. We demonstrate the
framework in three very distinct domains and we report the method&#x27;s competitive
performance and impressive zero-shot generalization over different problem
sizes. In goal-oriented BlockWorld, we demonstrate multi-parameter actions with
pre-conditions. In SysAdmin, we show how to select multiple objects
simultaneously. In the classical planning domain of Sokoban, the method trained
exclusively on 10x10 problems with three boxes solves 89% of 15x15 problems
with five boxes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization. (arXiv:2006.16241v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1">Dan Hendrycks</a>, <a href="http://arxiv.org/find/cs/1/au:+Basart_S/0/1/0/all/0/1">Steven Basart</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_N/0/1/0/all/0/1">Norman Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kadavath_S/0/1/0/all/0/1">Saurav Kadavath</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Frank Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dorundo_E/0/1/0/all/0/1">Evan Dorundo</a>, <a href="http://arxiv.org/find/cs/1/au:+Desai_R/0/1/0/all/0/1">Rahul Desai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1">Tyler Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Parajuli_S/0/1/0/all/0/1">Samyak Parajuli</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mike Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1">Dawn Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1">Jacob Steinhardt</a>, <a href="http://arxiv.org/find/cs/1/au:+Gilmer_J/0/1/0/all/0/1">Justin Gilmer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16241">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce four new real-world distribution shift datasets consisting of
changes in image style, image blurriness, geographic location, camera
operation, and more. With our new datasets, we take stock of previously
proposed methods for improving out-of-distribution robustness and put them to
the test. We find that using larger models and artificial data augmentations
can improve robustness on real-world distribution shifts, contrary to claims in
prior work. We find improvements in artificial robustness benchmarks can
transfer to real-world distribution shifts, contrary to claims in prior work.
Motivated by our observation that data augmentations can help with real-world
distribution shifts, we also introduce a new data augmentation method which
advances the state-of-the-art and outperforms models pretrained with 1000 times
more labeled data. Overall we find that some methods consistently help with
distribution shifts in texture and local image statistics, but these methods do
not help with some other distribution shifts like geographic changes. Our
results show that future research must study multiple distribution shifts
simultaneously, as we demonstrate that no evaluated method consistently
improves robustness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic social learning under graph constraints. (arXiv:2007.03983v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Avrachenkov_K/0/1/0/all/0/1">Konstantin Avrachenkov</a>, <a href="http://arxiv.org/find/math/1/au:+Borkar_V/0/1/0/all/0/1">Vivek S. Borkar</a>, <a href="http://arxiv.org/find/math/1/au:+Moharir_S/0/1/0/all/0/1">Sharayu Moharir</a>, <a href="http://arxiv.org/find/math/1/au:+Shah_S/0/1/0/all/0/1">Suhail M. Shah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03983">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a model of graph-constrained dynamic choice with reinforcement
modeled by positively $\alpha$-homogeneous rewards. We show that its empirical
process, which can be written as a stochastic approximation recursion with
Markov noise, has the same probability law as a certain vertex reinforced
random walk. We use this equivalence to show that for $\alpha &gt; 0$, the
asymptotic outcome concentrates around the optimum in a certain limiting sense
when &#x60;annealed&#x27; by letting $\alpha\uparrow\infty$ slowly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">6DCNN with roto-translational convolution filters for volumetric data processing. (arXiv:2107.12078v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Zhemchuzhnikov_D/0/1/0/all/0/1">Dmitrii Zhemchuzhnikov</a> (DAO), <a href="http://arxiv.org/find/q-bio/1/au:+Igashov_I/0/1/0/all/0/1">Ilia Igashov</a> (DAO), <a href="http://arxiv.org/find/q-bio/1/au:+Grudinin_S/0/1/0/all/0/1">Sergei Grudinin</a> (DAO)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12078">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce 6D Convolutional Neural Network (6DCNN) designed
to tackle the problem of detecting relative positions and orientations of local
patterns when processing three-dimensional volumetric data. 6DCNN also includes
SE(3)-equivariant message-passing and nonlinear activation operations
constructed in the Fourier space. Working in the Fourier space allows
significantly reducing the computational complexity of our operations. We
demonstrate the properties of the 6D convolution and its efficiency in the
recognition of spatial patterns. We also assess the 6DCNN model on several
datasets from the recent CASP protein structure prediction challenges. Here,
6DCNN improves over the baseline architecture and also outperforms the state of
the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hindsight Value Function for Variance Reduction in Stochastic Dynamic Environment. (arXiv:2107.12216v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jiaming Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xishan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_S/0/1/0/all/0/1">Shaohui Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1">Qi Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Z/0/1/0/all/0/1">Zidong Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xing Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yunji Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12216">
                                    <div class="article-summary-box-inner">
                                        <span>Policy gradient methods are appealing in deep reinforcement learning but
suffer from high variance of gradient estimate. To reduce the variance, the
state value function is applied commonly. However, the effect of the state
value function becomes limited in stochastic dynamic environments, where the
unexpected state dynamics and rewards will increase the variance. In this
paper, we propose to replace the state value function with a novel hindsight
value function, which leverages the information from the future to reduce the
variance of the gradient estimate for stochastic dynamic environments.

Particularly, to obtain an ideally unbiased gradient estimate, we propose an
information-theoretic approach, which optimizes the embeddings of the future to
be independent of previous actions. In our experiments, we apply the proposed
hindsight value function in stochastic dynamic environments, including
discrete-action environments and continuous-action environments. Compared with
the standard state value function, the proposed hindsight value function
consistently reduces the variance, stabilizes the training, and improves the
eventual policy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On The Impact of Client Sampling on Federated Learning Convergence. (arXiv:2107.12211v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fraboni_Y/0/1/0/all/0/1">Yann Fraboni</a>, <a href="http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1">Richard Vidal</a>, <a href="http://arxiv.org/find/cs/1/au:+Kameni_L/0/1/0/all/0/1">Laetitia Kameni</a>, <a href="http://arxiv.org/find/cs/1/au:+Lorenzi_M/0/1/0/all/0/1">Marco Lorenzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12211">
                                    <div class="article-summary-box-inner">
                                        <span>While clients&#x27; sampling is a central operation of current state-of-the-art
federated learning (FL) approaches, the impact of this procedure on the
convergence and speed of FL remains to date under-investigated. In this work we
introduce a novel decomposition theorem for the convergence of FL, allowing to
clearly quantify the impact of client sampling on the global model update.
Contrarily to previous convergence analyses, our theorem provides the exact
decomposition of a given convergence step, thus enabling accurate
considerations about the role of client sampling and heterogeneity. First, we
provide a theoretical ground for previously reported results on the
relationship between FL convergence and the variance of the aggregation
weights. Second, we prove for the first time that the quality of FL convergence
is also impacted by the resulting covariance between aggregation weights.
Third, we establish that the sum of the aggregation weights is another source
of slow-down and should be equal to 1 to improve FL convergence speed. Our
theory is general, and is here applied to Multinomial Distribution (MD) and
Uniform sampling, the two default client sampling in FL, and demonstrated
through a series of experiments in non-iid and unbalanced scenarios. Our
results suggest that MD sampling should be used as default sampling scheme, due
to the resilience to the changes in data ratio during the learning process,
while Uniform sampling is superior only in the special case when clients have
the same amount of data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decision-forest voting scheme for classification of rare classes in network intrusion detection. (arXiv:2107.11862v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brabec_J/0/1/0/all/0/1">Jan Brabec</a>, <a href="http://arxiv.org/find/cs/1/au:+Machlica_L/0/1/0/all/0/1">Lukas Machlica</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11862">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, Bayesian based aggregation of decision trees in an ensemble
(decision forest) is investigated. The focus is laid on multi-class
classification with number of samples significantly skewed toward one of the
classes. The algorithm leverages out-of-bag datasets to estimate prediction
errors of individual trees, which are then used in accordance with the Bayes
rule to refine the decision of the ensemble. The algorithm takes prevalence of
individual classes into account and does not require setting of any additional
parameters related to class weights or decision-score thresholds. Evaluation is
based on publicly available datasets as well as on an proprietary dataset
comprising network traffic telemetry from hundreds of enterprise networks with
over a million of users overall. The aim is to increase the detection
capabilities of an operating malware detection system. While we were able to
keep precision of the system higher than 94\%, that is only 6 out of 100
detections shown to the network administrator are false alarms, we were able to
achieve increase of approximately 7\% in the number of detections. The
algorithm effectively handles large amounts of data, and can be used in
conjunction with most of the state-of-the-art algorithms used to train decision
forests.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Brain Inspired Computing Approach for the Optimization of the Thin Film Thickness of Polystyrene on the Glass Substrates. (arXiv:2107.12156v1 [cond-mat.mtrl-sci])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Mishra_A/0/1/0/all/0/1">Akshansh Mishra</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Dixit_D/0/1/0/all/0/1">Devarrishi Dixit</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12156">
                                    <div class="article-summary-box-inner">
                                        <span>Advent in machine learning is leaving a deep impact on various sectors
including the material science domain. The present paper highlights the
application of various supervised machine learning regression algorithms such
as polynomial regression, decision tree regression algorithm, random forest
algorithm, support vector regression algorithm, and artificial neural network
algorithm to determine the thin film thickness of Polystyrene on the glass
substrates. The results showed that the polynomial regression machine learning
algorithm outperforms all other machine learning models by yielding the
coefficient of determination of 0.96 approximately and mean square error of
0.04 respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stable Dynamic Mode Decomposition Algorithm for Noisy Pressure-Sensitive Paint Measurement Data. (arXiv:2107.11999v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ohmichi_Y/0/1/0/all/0/1">Yuya Ohmichi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugioka_Y/0/1/0/all/0/1">Yosuke Sugioka</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakakita_K/0/1/0/all/0/1">Kazuyuki Nakakita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11999">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, we proposed the truncated total least squares dynamic mode
decomposition (T-TLS DMD) algorithm, which can perform DMD analysis of noisy
data. By adding truncation regularization to the conventional TLS DMD
algorithm, T-TLS DMD improves the stability of the computation while
maintaining the accuracy of TLS DMD. The effectiveness of the proposed method
was evaluated by the analysis of the wake behind a cylinder and
pressure-sensitive paint (PSP) data for the buffet cell phenomenon. The results
showed the importance of regularization in the DMD algorithm. With respect to
the eigenvalues, T-TLS DMD was less affected by noise, and accurate eigenvalues
could be obtained stably, whereas the eigenvalues of TLS and subspace DMD
varied greatly due to noise. It was also observed that the eigenvalues of the
standard and exact DMD had the problem of shifting to the damping side, as
reported in previous studies. With respect to eigenvectors, T-TLS and exact DMD
captured the characteristic flow patterns clearly even in the presence of
noise, whereas TLS and subspace DMD were not able to capture them clearly due
to noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EGGS: Eigen-Gap Guided Search\\ Making Subspace Clustering Easy. (arXiv:2107.12183v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Jicong Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Y/0/1/0/all/0/1">Yiheng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mingbo Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12183">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of spectral clustering heavily relies on the quality of
affinity matrix. A variety of affinity-matrix-construction methods have been
proposed but they have hyper-parameters to determine beforehand, which requires
strong experience and lead to difficulty in real applications especially when
the inter-cluster similarity is high or/and the dataset is large. On the other
hand, we often have to determine to use a linear model or a nonlinear model,
which still depends on experience. To solve these two problems, in this paper,
we present an eigen-gap guided search method for subspace clustering. The main
idea is to find the most reliable affinity matrix among a set of candidates
constructed by linear and kernel regressions, where the reliability is
quantified by the \textit{relative-eigen-gap} of graph Laplacian defined in
this paper. We show, theoretically and numerically, that the Laplacian matrix
with a larger relative-eigen-gap often yields a higher clustering accuracy and
stability. Our method is able to automatically search the best model and
hyper-parameters in a pre-defined space. The search space is very easy to
determine and can be arbitrarily large, though a relatively compact search
space can reduce the highly unnecessary computation. Our method has high
flexibility and convenience in real applications, and also has low
computational cost because the affinity matrix is not computed by iterative
optimization. We extend the method to large-scale datasets such as MNIST, on
which the time cost is less than 90s and the clustering accuracy is
state-of-the-art. Extensive experiments of natural image clustering show that
our method is more stable, accurate, and efficient than baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Workpiece Image-based Tool Wear Classification in Blanking Processes Using Deep Convolutional Neural Networks. (arXiv:2107.12034v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Molitor_D/0/1/0/all/0/1">Dirk Alexander Molitor</a>, <a href="http://arxiv.org/find/cs/1/au:+Kubik_C/0/1/0/all/0/1">Christian Kubik</a>, <a href="http://arxiv.org/find/cs/1/au:+Hetfleisch_R/0/1/0/all/0/1">Ruben Helmut Hetfleisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Groche_P/0/1/0/all/0/1">Peter Groche</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12034">
                                    <div class="article-summary-box-inner">
                                        <span>Blanking processes belong to the most widely used manufacturing techniques
due to their economic efficiency. Their economic viability depends to a large
extent on the resulting product quality and the associated customer
satisfaction as well as on possible downtimes. In particular, the occurrence of
increased tool wear reduces the product quality and leads to downtimes, which
is why considerable research has been carried out in recent years with regard
to wear detection. While processes have widely been monitored based on force
and acceleration signals, a new approach is pursued in this paper. Blanked
workpieces manufactured by punches with 16 different wear states are
photographed and then used as inputs for Deep Convolutional Neural Networks to
classify wear states. The results show that wear states can be predicted with
surprisingly high accuracy, opening up new possibilities and research
opportunities for tool wear monitoring of blanking processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Influential Higher-Order Patterns in Temporal Network Data. (arXiv:2107.12100v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gote_C/0/1/0/all/0/1">Christoph Gote</a>, <a href="http://arxiv.org/find/cs/1/au:+Perri_V/0/1/0/all/0/1">Vincenzo Perri</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholtes_I/0/1/0/all/0/1">Ingo Scholtes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12100">
                                    <div class="article-summary-box-inner">
                                        <span>Networks are frequently used to model complex systems comprised of
interacting elements. While links capture the topology of direct interactions,
the true complexity of many systems originates from higher-order patterns in
paths by which nodes can indirectly influence each other. Path data,
representing ordered sequences of consecutive direct interactions, can be used
to model these patterns. However, to avoid overfitting, such models should only
consider those higher-order patterns for which the data provide sufficient
statistical evidence. On the other hand, we hypothesise that network models,
which capture only direct interactions, underfit higher-order patterns present
in data. Consequently, both approaches are likely to misidentify influential
nodes in complex networks. We contribute to this issue by proposing eight
centrality measures based on MOGen, a multi-order generative model that
accounts for all paths up to a maximum distance but disregards paths at higher
distances. We compare MOGen-based centralities to equivalent measures for
network models and path data in a prediction experiment where we aim to
identify influential nodes in out-of-sample data. Our results show strong
evidence supporting our hypothesis. MOGen consistently outperforms both the
network model and path-based prediction. We further show that the performance
difference between MOGen and the path-based approach disappears if we have
sufficient observations, confirming that the error is due to overfitting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compensation Learning. (arXiv:2107.11921v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_R/0/1/0/all/0/1">Rujing Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mengyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_O/0/1/0/all/0/1">Ou Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11921">
                                    <div class="article-summary-box-inner">
                                        <span>Weighting strategy prevails in machine learning. For example, a common
approach in robust machine learning is to exert lower weights on samples which
are likely to be noisy or hard. This study reveals another undiscovered
strategy, namely, compensating, that has also been widely used in machine
learning. Learning with compensating is called compensation learning and a
systematic taxonomy is constructed for it in this study. In our taxonomy,
compensation learning is divided on the basis of the compensation targets,
inference manners, and granularity levels. Many existing learning algorithms
including some classical ones can be seen as a special case of compensation
learning or partially leveraging compensating. Furthermore, a family of new
learning algorithms can be obtained by plugging the compensation learning into
existing learning algorithms. Specifically, three concrete new learning
algorithms are proposed for robust machine learning. Extensive experiments on
text sentiment analysis, image classification, and graph classification verify
the effectiveness of the three new algorithms. Compensation learning can also
be used in various learning scenarios, such as imbalance learning, clustering,
regression, and so on.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">H-Transformer-1D: Fast One-Dimensional Hierarchical Attention for Sequences. (arXiv:2107.11906v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhenhai Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1">Radu Soricut</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11906">
                                    <div class="article-summary-box-inner">
                                        <span>We describe an efficient hierarchical method to compute attention in the
Transformer architecture. The proposed attention mechanism exploits a matrix
structure similar to the Hierarchical Matrix (H-Matrix) developed by the
numerical analysis community, and has linear run time and memory complexity. We
perform extensive experiments to show that the inductive bias embodied by our
hierarchical attention is effective in capturing the hierarchical structure in
the sequences typical for natural language and vision tasks. Our method is
superior to alternative sub-quadratic proposals by over +6 points on average on
the Long Range Arena benchmark. It also sets a new SOTA test perplexity on
One-Billion Word dataset with 5x fewer model parameters than that of the
previous-best Transformer-based models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Shallow Ritz Method for elliptic problems with Singular Sources. (arXiv:2107.12013v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Lai_M/0/1/0/all/0/1">Ming-Chih Lai</a>, <a href="http://arxiv.org/find/math/1/au:+Chang_C/0/1/0/all/0/1">Che-Chia Chang</a>, <a href="http://arxiv.org/find/math/1/au:+Lin_W/0/1/0/all/0/1">Wei-Syuan Lin</a>, <a href="http://arxiv.org/find/math/1/au:+Hu_W/0/1/0/all/0/1">Wei-Fan Hu</a>, <a href="http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1">Te-Sheng Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12013">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, a shallow Ritz-type neural network for solving elliptic
problems with delta function singular sources on an interface is developed.
There are three novel features in the present work; namely, (i) the delta
function singularity is naturally removed, (ii) level set function is
introduced as a feather input, (iii) it is completely shallow consisting of
only one hidden layer. We first introduce the energy functional of the problem
and then transform the contribution of singular sources to a regular surface
integral along the interface. In such a way the delta function singularity can
be naturally removed without the introduction of discrete delta function that
is commonly used in traditional regularization methods such as the well-known
immersed boundary method. The original problem is then reformulated as a
minimization problem. We propose a shallow Ritz-type neural network with one
hidden layer to approximate the global minimizer of the energy functional. As a
result, the network is trained by minimizing the loss function that is a
discrete version of the energy. In addition, we include the level set function
of the interface as a feature input and find that it significantly improves the
training efficiency and accuracy. We perform a series of numerical tests to
demonstrate the accuracy of the present network as well as its capability for
problems in irregular domains and in higher dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logspace Reducibility From Secret Leakage Planted Clique. (arXiv:2107.11886v1 [cs.CC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mardia_J/0/1/0/all/0/1">Jay Mardia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11886">
                                    <div class="article-summary-box-inner">
                                        <span>The planted clique problem is well-studied in the context of observing,
explaining, and predicting interesting computational phenomena associated with
statistical problems. When equating computational efficiency with the existence
of polynomial time algorithms, the computational hardness of (some variant of)
the planted clique problem can be used to infer the computational hardness of a
host of other statistical problems.

Is this ability to transfer computational hardness from (some variant of) the
planted clique problem to other statistical problems robust to changing our
notion of computational efficiency to space efficiency?

We answer this question affirmatively for three different statistical
problems, namely Sparse PCA, submatrix detection, and testing almost k-wise
independence. The key challenge is that space efficient randomized reductions
need to repeatedly access the randomness they use. Known reductions to these
problems are all randomized and need polynomially many random bits to
implement. Since we can not store polynomially many random bits in memory, it
is unclear how to implement these existing reductions space efficiently. There
are two ideas involved in circumventing this issue and implementing known
reductions to these problems space efficiently.

1. When solving statistical problems, we can use parts of the input itself as
randomness.

2. Secret leakage variants of the planted clique problem with appropriate
secret leakage can be more useful than the standard planted clique problem when
we want to use parts of the input as randomness.

(abstract shortened due to arxiv constraints)</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Attention Model for RV StrainClassification from volumetric CTPA Scans. (arXiv:2107.12009v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Cahan_N/0/1/0/all/0/1">Noa Cahan</a>, <a href="http://arxiv.org/find/eess/1/au:+Marom_E/0/1/0/all/0/1">Edith M. Marom</a>, <a href="http://arxiv.org/find/eess/1/au:+Soffer_S/0/1/0/all/0/1">Shelly Soffer</a>, <a href="http://arxiv.org/find/eess/1/au:+Barash_Y/0/1/0/all/0/1">Yiftach Barash</a>, <a href="http://arxiv.org/find/eess/1/au:+Konen_E/0/1/0/all/0/1">Eli Konen</a>, <a href="http://arxiv.org/find/eess/1/au:+Klang_E/0/1/0/all/0/1">Eyal Klang</a>, <a href="http://arxiv.org/find/eess/1/au:+Greenspan_H/0/1/0/all/0/1">Hayit Greenspan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12009">
                                    <div class="article-summary-box-inner">
                                        <span>Pulmonary embolus (PE) refers to obstruction of pulmonary arteries by blood
clots. PE accounts for approximately 100,000 deaths per year in the United
States alone. The clinical presentation of PE is often nonspecific, making the
diagnosis challenging. Thus, rapid and accurate risk stratification is of
paramount importance. High-risk PE is caused by right ventricular (RV)
dysfunction from acute pressure overload, which in return can help identify
which patients require more aggressive therapy. Reconstructed four-chamber
views of the heart on chest CT can detect right ventricular enlargement. CT
pulmonary angiography (CTPA) is the golden standard in the diagnostic workup of
suspected PE. Therefore, it can link between diagnosis and risk stratification
strategies. We developed a weakly supervised deep learning algorithm, with an
emphasis on a novel attention mechanism, to automatically classify RV strain on
CTPA. Our method is a 3D DenseNet model with integrated 3D residual attention
blocks. We evaluated our model on a dataset of CTPAs of emergency department
(ED) PE patients. This model achieved an area under the receiver operating
characteristic curve (AUC) of 0.88 for classifying RV strain. The model showed
a sensitivity of 87% and specificity of 83.7%. Our solution outperforms
state-of-the-art 3D CNN networks. The proposed design allows for a fully
automated network that can be trained easily in an end-to-end manner without
requiring computationally intensive and time-consuming preprocessing or
strenuous labeling of the data.We infer that unmarked CTPAs can be used for
effective RV strain classification. This could be used as a second reader,
alerting for high-risk PE patients. To the best of our knowledge, there are no
previous deep learning-based studies that attempted to solve this problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Representation Learning on Tissue-Specific Multi-Omics. (arXiv:2107.11856v1 [q-bio.GN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Amor_A/0/1/0/all/0/1">Amine Amor</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Lio_P/0/1/0/all/0/1">Pietro Lio&#x27;</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Singh_V/0/1/0/all/0/1">Vikash Singh</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Torne_R/0/1/0/all/0/1">Ramon Vi&#xf1;as Torn&#xe9;</a> (1), <a href="http://arxiv.org/find/q-bio/1/au:+Terre_H/0/1/0/all/0/1">Helena Andres Terre</a> (1)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11856">
                                    <div class="article-summary-box-inner">
                                        <span>Combining different modalities of data from human tissues has been critical
in advancing biomedical research and personalised medical care. In this study,
we leverage a graph embedding model (i.e VGAE) to perform link prediction on
tissue-specific Gene-Gene Interaction (GGI) networks. Through ablation
experiments, we prove that the combination of multiple biological modalities
(i.e multi-omics) leads to powerful embeddings and better link prediction
performances. Our evaluation shows that the integration of gene methylation
profiles and RNA-sequencing data significantly improves the link prediction
performance. Overall, the combination of RNA-sequencing and gene methylation
data leads to a link prediction accuracy of 71% on GGI networks. By harnessing
graph representation learning on multi-omics data, our work brings novel
insights to the current literature on multi-omics integration in
bioinformatics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Risk-aware Costmaps for Traversability in Challenging Environments. (arXiv:2107.11722v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1">David D. Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Agha_mohammadi_A/0/1/0/all/0/1">Ali-akbar Agha-mohammadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1">Evangelos A. Theodorou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11722">
                                    <div class="article-summary-box-inner">
                                        <span>One of the main challenges in autonomous robotic exploration and navigation
in unknown and unstructured environments is determining where the robot can or
cannot safely move. A significant source of difficulty in this determination
arises from stochasticity and uncertainty, coming from localization error,
sensor sparsity and noise, difficult-to-model robot-ground interactions, and
disturbances to the motion of the vehicle. Classical approaches to this problem
rely on geometric analysis of the surrounding terrain, which can be prone to
modeling errors and can be computationally expensive. Moreover, modeling the
distribution of uncertain traversability costs is a difficult task, compounded
by the various error sources mentioned above. In this work, we take a
principled learning approach to this problem. We introduce a neural network
architecture for robustly learning the distribution of traversability costs.
Because we are motivated by preserving the life of the robot, we tackle this
learning problem from the perspective of learning tail-risks, i.e. the
Conditional Value-at-Risk (CVaR). We show that this approach reliably learns
the expected tail risk given a desired probability risk threshold between 0 and
1, producing a traversability costmap which is more robust to outliers, more
accurately captures tail risks, and is more computationally efficient, when
compared against baselines. We validate our method on data collected a legged
robot navigating challenging, unstructured environments including an abandoned
subway, limestone caves, and lava tube caves.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Circuit Synthesis from Specification Patterns. (arXiv:2107.11864v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schmitt_F/0/1/0/all/0/1">Frederik Schmitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hahn_C/0/1/0/all/0/1">Christopher Hahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabe_M/0/1/0/all/0/1">Markus N. Rabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Finkbeiner_B/0/1/0/all/0/1">Bernd Finkbeiner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11864">
                                    <div class="article-summary-box-inner">
                                        <span>We train hierarchical Transformers on the task of synthesizing hardware
circuits directly out of high-level logical specifications in linear-time
temporal logic (LTL). The LTL synthesis problem is a well-known algorithmic
challenge with a long history and an annual competition is organized to track
the improvement of algorithms and tooling over time. New approaches using
machine learning might open a lot of possibilities in this area, but suffer
from the lack of sufficient amounts of training data. In this paper, we
consider a method to generate large amounts of additional training data, i.e.,
pairs of specifications and circuits implementing them. We ensure that this
synthetic data is sufficiently close to human-written specifications by mining
common patterns from the specifications used in the synthesis competitions. We
show that hierarchical Transformers trained on this synthetic data solve a
significant portion of problems from the synthesis competitions, and even
out-of-distribution examples from a recent case study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Power of human-algorithm collaboration in solving combinatorial optimization problems. (arXiv:2107.11784v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Toivonen_T/0/1/0/all/0/1">Tapani Toivonen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11784">
                                    <div class="article-summary-box-inner">
                                        <span>Many combinatorial optimization problems are often considered intractable to
solve exactly or by approximation. An example of such problem is maximum clique
which -- under standard assumptions in complexity theory -- cannot be solved in
sub-exponential time or be approximated within polynomial factor efficiently.
We show that if a polynomial time algorithm can query informative Gaussian
priors from an expert $poly(n)$ times, then a class of combinatorial
optimization problems can be solved efficiently in expectation up to a
multiplicative factor $\epsilon$ where $\epsilon$ is arbitrary constant. While
our proposed methods are merely theoretical, they cast new light on how to
approach solving these problems that have been usually considered intractable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient inference of interventional distributions. (arXiv:2107.11712v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattacharyya_A/0/1/0/all/0/1">Arnab Bhattacharyya</a>, <a href="http://arxiv.org/find/cs/1/au:+Gayen_S/0/1/0/all/0/1">Sutanu Gayen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kandasamy_S/0/1/0/all/0/1">Saravanan Kandasamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Raval_V/0/1/0/all/0/1">Vedant Raval</a>, <a href="http://arxiv.org/find/cs/1/au:+Vinodchandran_N/0/1/0/all/0/1">N. V. Vinodchandran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11712">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of efficiently inferring interventional distributions
in a causal Bayesian network from a finite number of observations. Let
$\mathcal{P}$ be a causal model on a set $\mathbf{V}$ of observable variables
on a given causal graph $G$. For sets $\mathbf{X},\mathbf{Y}\subseteq
\mathbf{V}$, and setting ${\bf x}$ to $\mathbf{X}$, let $P_{\bf x}(\mathbf{Y})$
denote the interventional distribution on $\mathbf{Y}$ with respect to an
intervention ${\bf x}$ to variables ${\bf x}$. Shpitser and Pearl (AAAI 2006),
building on the work of Tian and Pearl (AAAI 2001), gave an exact
characterization of the class of causal graphs for which the interventional
distribution $P_{\bf x}({\mathbf{Y}})$ can be uniquely determined. We give the
first efficient version of the Shpitser-Pearl algorithm. In particular, under
natural assumptions, we give a polynomial-time algorithm that on input a causal
graph $G$ on observable variables $\mathbf{V}$, a setting ${\bf x}$ of a set
$\mathbf{X} \subseteq \mathbf{V}$ of bounded size, outputs succinct
descriptions of both an evaluator and a generator for a distribution $\hat{P}$
that is $\varepsilon$-close (in total variation distance) to $P_{\bf
x}({\mathbf{Y}})$ where $Y&#x3D;\mathbf{V}\setminus \mathbf{X}$, if $P_{\bf
x}(\mathbf{Y})$ is identifiable. We also show that when $\mathbf{Y}$ is an
arbitrary set, there is no efficient algorithm that outputs an evaluator of a
distribution that is $\varepsilon$-close to $P_{\bf x}({\mathbf{Y}})$ unless
all problems that have statistical zero-knowledge proofs, including the Graph
Isomorphism problem, have efficient randomized algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Character Spotting Using Machine Learning Techniques. (arXiv:2107.11795v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Preethi_P/0/1/0/all/0/1">P Preethi</a>, <a href="http://arxiv.org/find/cs/1/au:+Viswanath_H/0/1/0/all/0/1">Hrishikesh Viswanath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11795">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents a comparison of machine learning algorithms that are
implemented to segment the characters of text presented as an image. The
algorithms are designed to work on degraded documents with text that is not
aligned in an organized fashion. The paper investigates the use of Support
Vector Machines, K-Nearest Neighbor algorithm and an Encoder Network to perform
the operation of character spotting. Character Spotting involves extracting
potential characters from a stream of text by selecting regions bound by white
space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Restless Bandits with Many Arms: Beating the Central Limit Theorem. (arXiv:2107.11911v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Zhang_X/0/1/0/all/0/1">Xiangyu Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Frazier_P/0/1/0/all/0/1">Peter I. Frazier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11911">
                                    <div class="article-summary-box-inner">
                                        <span>We consider finite-horizon restless bandits with multiple pulls per period,
which play an important role in recommender systems, active learning, revenue
management, and many other areas. While an optimal policy can be computed, in
principle, using dynamic programming, the computation required scales
exponentially in the number of arms $N$. Thus, there is substantial value in
understanding the performance of index policies and other policies that can be
computed efficiently for large $N$. We study the growth of the optimality gap,
i.e., the loss in expected performance compared to an optimal policy, for such
policies in a classical asymptotic regime proposed by Whittle in which $N$
grows while holding constant the fraction of arms that can be pulled per
period. Intuition from the Central Limit Theorem and the tightest previous
theoretical bounds suggest that this optimality gap should grow like
$O(\sqrt{N})$. Surprisingly, we show that it is possible to outperform this
bound. We characterize a non-degeneracy condition and a wide class of novel
practically-computable policies, called fluid-priority policies, in which the
optimality gap is $O(1)$. These include most widely-used index policies. When
this non-degeneracy condition does not hold, we show that fluid-priority
policies nevertheless have an optimality gap that is $O(\sqrt{N})$,
significantly generalizing the class of policies for which convergence rates
are known. We demonstrate that fluid-priority policies offer state-of-the-art
performance on a collection of restless bandit problems in numerical
experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforced Imitation Learning by Free Energy Principle. (arXiv:2107.11811v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ogishima_R/0/1/0/all/0/1">Ryoya Ogishima</a>, <a href="http://arxiv.org/find/cs/1/au:+Karino_I/0/1/0/all/0/1">Izumi Karino</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuniyoshi_Y/0/1/0/all/0/1">Yasuo Kuniyoshi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11811">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement Learning (RL) requires a large amount of exploration especially
in sparse-reward settings. Imitation Learning (IL) can learn from expert
demonstrations without exploration, but it never exceeds the expert&#x27;s
performance and is also vulnerable to distributional shift between
demonstration and execution. In this paper, we radically unify RL and IL based
on Free Energy Principle (FEP). FEP is a unified Bayesian theory of the brain
that explains perception, action and model learning by a common fundamental
principle. We present a theoretical extension of FEP and derive an algorithm in
which an agent learns the world model that internalizes expert demonstrations
and at the same time uses the model to infer the current and future states and
actions that maximize rewards. The algorithm thus reduces exploration costs by
partially imitating experts as well as maximizing its return in a seamless way,
resulting in a higher performance than the suboptimal expert. Our experimental
results show that this approach is promising in visual control tasks especially
in sparse-reward environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lung Cancer Risk Estimation with Incomplete Data: A Joint Missing Imputation Perspective. (arXiv:2107.11882v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gao_R/0/1/0/all/0/1">Riqiang Gao</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_Y/0/1/0/all/0/1">Yucheng Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_K/0/1/0/all/0/1">Kaiwen Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_H/0/1/0/all/0/1">Ho Hin Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Deppen_S/0/1/0/all/0/1">Steve Deppen</a>, <a href="http://arxiv.org/find/eess/1/au:+Sandler_K/0/1/0/all/0/1">Kim Sandler</a>, <a href="http://arxiv.org/find/eess/1/au:+Massion_P/0/1/0/all/0/1">Pierre Massion</a>, <a href="http://arxiv.org/find/eess/1/au:+Lasko_T/0/1/0/all/0/1">Thomas A. Lasko</a>, <a href="http://arxiv.org/find/eess/1/au:+Huo_Y/0/1/0/all/0/1">Yuankai Huo</a>, <a href="http://arxiv.org/find/eess/1/au:+Landman_B/0/1/0/all/0/1">Bennett A. Landman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11882">
                                    <div class="article-summary-box-inner">
                                        <span>Data from multi-modality provide complementary information in clinical
prediction, but missing data in clinical cohorts limits the number of subjects
in multi-modal learning context. Multi-modal missing imputation is challenging
with existing methods when 1) the missing data span across heterogeneous
modalities (e.g., image vs. non-image); or 2) one modality is largely missing.
In this paper, we address imputation of missing data by modeling the joint
distribution of multi-modal data. Motivated by partial bidirectional generative
adversarial net (PBiGAN), we propose a new Conditional PBiGAN (C-PBiGAN) method
that imputes one modality combining the conditional knowledge from another
modality. Specifically, C-PBiGAN introduces a conditional latent space in a
missing imputation framework that jointly encodes the available multi-modal
data, along with a class regularization loss on imputed data to recover
discriminative information. To our knowledge, it is the first generative
adversarial model that addresses multi-modal missing imputation by modeling the
joint distribution of image and non-image data. We validate our model with both
the national lung screening trial (NLST) dataset and an external clinical
validation cohort. The proposed C-PBiGAN achieves significant improvements in
lung cancer risk estimation compared with representative imputation methods
(e.g., AUC values increase in both NLST (+2.9\%) and in-house dataset (+4.3\%)
compared with PBiGAN, p$&lt;$0.05).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A brief note on understanding neural networks as Gaussian processes. (arXiv:2107.11892v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Mengwu Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11892">
                                    <div class="article-summary-box-inner">
                                        <span>As a generalization of the work in [Lee et al., 2017], this note briefly
discusses when the prior of a neural network output follows a Gaussian process,
and how a neural-network-induced Gaussian process is formulated. The posterior
mean functions of such a Gaussian process regression lie in the reproducing
kernel Hilbert space defined by the neural-network-induced kernel. In the case
of two-layer neural networks, the induced Gaussian processes provide an
interpretation of the reproducing kernel Hilbert spaces whose union forms a
Barron space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dissecting FLOPs along input dimensions for GreenAI cost estimations. (arXiv:2107.11949v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asperti_A/0/1/0/all/0/1">Andrea Asperti</a>, <a href="http://arxiv.org/find/cs/1/au:+Evangelista_D/0/1/0/all/0/1">Davide Evangelista</a>, <a href="http://arxiv.org/find/cs/1/au:+Marzolla_M/0/1/0/all/0/1">Moreno Marzolla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11949">
                                    <div class="article-summary-box-inner">
                                        <span>The term GreenAI refers to a novel approach to Deep Learning, that is more
aware of the ecological impact and the computational efficiency of its methods.
The promoters of GreenAI suggested the use of Floating Point Operations (FLOPs)
as a measure of the computational cost of Neural Networks; however, that
measure does not correlate well with the energy consumption of hardware
equipped with massively parallel processing units like GPUs or TPUs. In this
article, we propose a simple refinement of the formula used to compute floating
point operations for convolutional layers, called {\alpha}-FLOPs, explaining
and correcting the traditional discrepancy with respect to different layers,
and closer to reality. The notion of {\alpha}-FLOPs relies on the crucial
insight that, in case of inputs with multiple dimensions, there is no reason to
believe that the speedup offered by parallelism will be uniform along all
different axes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Variational Autoencoder based Out-of-Distribution Detection for Embedded Real-time Applications. (arXiv:2107.11750v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yeli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_D/0/1/0/all/0/1">Daniel Jun Xian Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Easwaran_A/0/1/0/all/0/1">Arvind Easwaran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11750">
                                    <div class="article-summary-box-inner">
                                        <span>Uncertainties in machine learning are a significant roadblock for its
application in safety-critical cyber-physical systems (CPS). One source of
uncertainty arises from distribution shifts in the input data between training
and test scenarios. Detecting such distribution shifts in real-time is an
emerging approach to address the challenge. The high dimensional input space in
CPS applications involving imaging adds extra difficulty to the task.
Generative learning models are widely adopted for the task, namely
out-of-distribution (OoD) detection. To improve the state-of-the-art, we
studied existing proposals from both machine learning and CPS fields. In the
latter, safety monitoring in real-time for autonomous driving agents has been a
focus. Exploiting the spatiotemporal correlation of motion in videos, we can
robustly detect hazardous motion around autonomous driving agents. Inspired by
the latest advances in the Variational Autoencoder (VAE) theory and practice,
we tapped into the prior knowledge in data to further boost OoD detection&#x27;s
robustness. Comparison studies over nuScenes and Synthia data sets show our
methods significantly improve detection capabilities of OoD factors unique to
driving scenarios, 42% better than state-of-the-art approaches. Our model also
generalized near-perfectly, 97% better than the state-of-the-art across the
real-world and simulation driving data sets experimented. Finally, we
customized one proposed method into a twin-encoder model that can be deployed
to resource limited embedded devices for real-time OoD detection. Its execution
time was reduced over four times in low-precision 8-bit integer inference,
while detection capability is comparable to its corresponding floating-point
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Explicit Differentiable Predictive Control Laws for Buildings. (arXiv:2107.11843v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Drgona_J/0/1/0/all/0/1">Jan Drgona</a>, <a href="http://arxiv.org/find/eess/1/au:+Tuor_A/0/1/0/all/0/1">Aaron Tuor</a>, <a href="http://arxiv.org/find/eess/1/au:+Vasisht_S/0/1/0/all/0/1">Soumya Vasisht</a>, <a href="http://arxiv.org/find/eess/1/au:+Skomski_E/0/1/0/all/0/1">Elliott Skomski</a>, <a href="http://arxiv.org/find/eess/1/au:+Vrabie_D/0/1/0/all/0/1">Draguna Vrabie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11843">
                                    <div class="article-summary-box-inner">
                                        <span>We present a differentiable predictive control (DPC) methodology for learning
constrained control laws for unknown nonlinear systems. DPC poses an
approximate solution to multiparametric programming problems emerging from
explicit nonlinear model predictive control (MPC). Contrary to approximate MPC,
DPC does not require supervision by an expert controller. Instead, a system
dynamics model is learned from the observed system&#x27;s dynamics, and the neural
control law is optimized offline by leveraging the differentiable closed-loop
system model. The combination of a differentiable closed-loop system and
penalty methods for constraint handling of system outputs and inputs allows us
to optimize the control law&#x27;s parameters directly by backpropagating economic
MPC loss through the learned system model. The control performance of the
proposed DPC method is demonstrated in simulation using learned model of
multi-zone building thermal dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ReDAL: Region-based and Diversity-aware Active Learning for Point Cloud Semantic Segmentation. (arXiv:2107.11769v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Tsung-Han Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yueh-Cheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Kai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hsin-Ying Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hung-Ting Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Ping-Chia Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Winston H. Hsu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11769">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of deep learning on supervised point cloud semantic
segmentation, obtaining large-scale point-by-point manual annotations is still
a significant challenge. To reduce the huge annotation burden, we propose a
Region-based and Diversity-aware Active Learning (ReDAL), a general framework
for many deep learning approaches, aiming to automatically select only
informative and diverse sub-scene regions for label acquisition. Observing that
only a small portion of annotated regions are sufficient for 3D scene
understanding with deep learning, we use softmax entropy, color discontinuity,
and structural complexity to measure the information of sub-scene regions. A
diversity-aware selection algorithm is also developed to avoid redundant
annotations resulting from selecting informative but similar regions in a
querying batch. Extensive experiments show that our method highly outperforms
previous active learning strategies, and we achieve the performance of 90%
fully supervised learning, while less than 15% and 5% annotations are required
on S3DIS and SemanticKITTI datasets, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring Ethics in AI with AI: A Methodology and Dataset Construction. (arXiv:2107.11913v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Avelar_P/0/1/0/all/0/1">Pedro H.C. Avelar</a>, <a href="http://arxiv.org/find/cs/1/au:+Audibert_R/0/1/0/all/0/1">Rafael B. Audibert</a>, <a href="http://arxiv.org/find/cs/1/au:+Tavares_A/0/1/0/all/0/1">Anderson R. Tavares</a>, <a href="http://arxiv.org/find/cs/1/au:+Lamb_L/0/1/0/all/0/1">Lu&#xed;s C. Lamb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11913">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the use of sound measures and metrics in Artificial Intelligence
has become the subject of interest of academia, government, and industry.
Efforts towards measuring different phenomena have gained traction in the AI
community, as illustrated by the publication of several influential field
reports and policy documents. These metrics are designed to help decision
takers to inform themselves about the fast-moving and impacting influences of
key advances in Artificial Intelligence in general and Machine Learning in
particular. In this paper we propose to use such newfound capabilities of AI
technologies to augment our AI measuring capabilities. We do so by training a
model to classify publications related to ethical issues and concerns. In our
methodology we use an expert, manually curated dataset as the training set and
then evaluate a large set of research papers. Finally, we highlight the
implications of AI metrics, in particular their contribution towards developing
trustful and fair AI-based tools and technologies. Keywords: AI Ethics; AI
Fairness; AI Measurement. Ethics in Computer Science.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Boosting Video Captioning with Dynamic Loss Network. (arXiv:2107.11707v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nasibullah/0/1/0/all/0/1">Nasibullah</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohanta_P/0/1/0/all/0/1">Partha Pratim Mohanta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11707">
                                    <div class="article-summary-box-inner">
                                        <span>Video captioning is one of the challenging problems at the intersection of
vision and language, having many real-life applications in video retrieval,
video surveillance, assisting visually challenged people, Human-machine
interface, and many more. Recent deep learning-based methods have shown
promising results but are still on the lower side than other vision tasks (such
as image classification, object detection). A significant drawback with
existing video captioning methods is that they are optimized over cross-entropy
loss function, which is uncorrelated to the de facto evaluation metrics (BLEU,
METEOR, CIDER, ROUGE).In other words, cross-entropy is not a proper surrogate
of the true loss function for video captioning. This paper addresses the
drawback by introducing a dynamic loss network (DLN), which provides an
additional feedback signal that directly reflects the evaluation metrics. Our
results on Microsoft Research Video Description Corpus (MSVD) and MSR-Video to
Text (MSRVTT) datasets outperform previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Go Wider Instead of Deeper. (arXiv:2107.11817v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1">Fuzhao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Ziji Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_Y/0/1/0/all/0/1">Yuxuan Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yang You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11817">
                                    <div class="article-summary-box-inner">
                                        <span>The transformer has recently achieved impressive results on various tasks. To
further improve the effectiveness and efficiency of the transformer, there are
two trains of thought among existing works: (1) going wider by scaling to more
trainable parameters; (2) going shallower by parameter sharing or model
compressing along with the depth. However, larger models usually do not scale
well when fewer tokens are available to train, and advanced parallelisms are
required when the model is extremely large. Smaller models usually achieve
inferior performance compared to the original transformer model due to the loss
of representation power. In this paper, to achieve better performance with
fewer trainable parameters, we propose a framework to deploy trainable
parameters efficiently, by going wider instead of deeper. Specially, we scale
along model width by replacing feed-forward network (FFN) with
mixture-of-experts (MoE). We then share the MoE layers across transformer
blocks using individual layer normalization. Such deployment plays the role to
transform various semantic representations, which makes the model more
parameter-efficient and effective. To evaluate our framework, we design WideNet
and evaluate it on ImageNet-1K. Our best model outperforms Vision Transformer
(ViT) by $1.46\%$ with $0.72 \times$ trainable parameters. Using $0.46 \times$
and $0.13 \times$ parameters, our WideNet can still surpass ViT and ViT-MoE by
$0.83\%$ and $2.08\%$, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imbalanced Big Data Oversampling: Taxonomy, Algorithms, Software, Guidelines and Future Directions. (arXiv:2107.11508v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sleeman_W/0/1/0/all/0/1">William C. Sleeman IV</a>, <a href="http://arxiv.org/find/cs/1/au:+Krawczyk_B/0/1/0/all/0/1">Bartosz Krawczyk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11508">
                                    <div class="article-summary-box-inner">
                                        <span>Learning from imbalanced data is among the most challenging areas in
contemporary machine learning. This becomes even more difficult when considered
the context of big data that calls for dedicated architectures capable of
high-performance processing. Apache Spark is a highly efficient and popular
architecture, but it poses specific challenges for algorithms to be implemented
for it. While oversampling algorithms are an effective way for handling class
imbalance, they have not been designed for distributed environments. In this
paper, we propose a holistic look on oversampling algorithms for imbalanced big
data. We discuss the taxonomy of oversampling algorithms and their mechanisms
used to handle skewed class distributions. We introduce a Spark library with 14
state-of-the-art oversampling algorithms implemented and evaluate their
efficacy via extensive experimental study. Using binary and multi-class massive
data sets, we analyze the effectiveness of oversampling algorithms and their
relationships with different types of classifiers. We evaluate the trade-off
between accuracy and time complexity of oversampling algorithms, as well as
their scalability when increasing the size of data. This allows us to gain
insight into the usefulness of specific components of oversampling algorithms
for big data, as well as formulate guidelines and recommendations for designing
future resampling approaches for massive imbalanced data. Our library can be
downloaded from https://github.com/fsleeman/spark-class-balancing.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial training may be a double-edged sword. (arXiv:2107.11671v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahmati_A/0/1/0/all/0/1">Ali Rahmati</a>, <a href="http://arxiv.org/find/cs/1/au:+Moosavi_Dezfooli_S/0/1/0/all/0/1">Seyed-Mohsen Moosavi-Dezfooli</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Huaiyu Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11671">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial training has been shown as an effective approach to improve the
robustness of image classifiers against white-box attacks. However, its
effectiveness against black-box attacks is more nuanced. In this work, we
demonstrate that some geometric consequences of adversarial training on the
decision boundary of deep networks give an edge to certain types of black-box
attacks. In particular, we define a metric called robustness gain to show that
while adversarial training is an effective method to dramatically improve the
robustness in white-box scenarios, it may not provide such a good robustness
gain against the more realistic decision-based black-box attacks. Moreover, we
show that even the minimal perturbation white-box attacks can converge faster
against adversarially-trained neural networks compared to the regular ones.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Online Learning and Offline Learning for Contextual Bandits with Deficient Support. (arXiv:2107.11533v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tran_The_H/0/1/0/all/0/1">Hung Tran-The</a>, <a href="http://arxiv.org/find/stat/1/au:+Gupta_S/0/1/0/all/0/1">Sunil Gupta</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_Tang_T/0/1/0/all/0/1">Thanh Nguyen-Tang</a>, <a href="http://arxiv.org/find/stat/1/au:+Rana_S/0/1/0/all/0/1">Santu Rana</a>, <a href="http://arxiv.org/find/stat/1/au:+Venkatesh_S/0/1/0/all/0/1">Svetha Venkatesh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11533">
                                    <div class="article-summary-box-inner">
                                        <span>We address policy learning with logged data in contextual bandits. Current
offline-policy learning algorithms are mostly based on inverse propensity score
(IPS) weighting requiring the logging policy to have \emph{full support} i.e. a
non-zero probability for any context/action of the evaluation policy. However,
many real-world systems do not guarantee such logging policies, especially when
the action space is large and many actions have poor or missing rewards. With
such \emph{support deficiency}, the offline learning fails to find optimal
policies. We propose a novel approach that uses a hybrid of offline learning
with online exploration. The online exploration is used to explore unsupported
actions in the logged data whilst offline learning is used to exploit supported
actions from the logged data avoiding unnecessary explorations. Our approach
determines an optimal policy with theoretical guarantees using the minimal
number of online explorations. We demonstrate our algorithms&#x27; effectiveness
empirically on a diverse collection of datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Two Headed Dragons: Multimodal Fusion and Cross Modal Transactions. (arXiv:2107.11585v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bose_R/0/1/0/all/0/1">Rupak Bose</a>, <a href="http://arxiv.org/find/cs/1/au:+Pande_S/0/1/0/all/0/1">Shivam Pande</a>, <a href="http://arxiv.org/find/cs/1/au:+Banerjee_B/0/1/0/all/0/1">Biplab Banerjee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11585">
                                    <div class="article-summary-box-inner">
                                        <span>As the field of remote sensing is evolving, we witness the accumulation of
information from several modalities, such as multispectral (MS), hyperspectral
(HSI), LiDAR etc. Each of these modalities possess its own distinct
characteristics and when combined synergistically, perform very well in the
recognition and classification tasks. However, fusing multiple modalities in
remote sensing is cumbersome due to highly disparate domains. Furthermore, the
existing methods do not facilitate cross-modal interactions. To this end, we
propose a novel transformer based fusion method for HSI and LiDAR modalities.
The model is composed of stacked auto encoders that harness the cross key-value
pairs for HSI and LiDAR, thus establishing a communication between the two
modalities, while simultaneously using the CNNs to extract the spectral and
spatial information from HSI and LiDAR. We test our model on Houston (Data
Fusion Contest - 2013) and MUUFL Gulfport datasets and achieve competitive
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Combining Graph Neural Networks with Expert Knowledge for Smart Contract Vulnerability Detection. (arXiv:2107.11598v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenguang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_P/0/1/0/all/0/1">Peng Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_Y/0/1/0/all/0/1">Yuan Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1">Lin Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11598">
                                    <div class="article-summary-box-inner">
                                        <span>Smart contract vulnerability detection draws extensive attention in recent
years due to the substantial losses caused by hacker attacks. Existing efforts
for contract security analysis heavily rely on rigid rules defined by experts,
which are labor-intensive and non-scalable. More importantly, expert-defined
rules tend to be error-prone and suffer the inherent risk of being cheated by
crafty attackers. Recent researches focus on the symbolic execution and formal
analysis of smart contracts for vulnerability detection, yet to achieve a
precise and scalable solution. Although several methods have been proposed to
detect vulnerabilities in smart contracts, there is still a lack of effort that
considers combining expert-defined security patterns with deep neural networks.
In this paper, we explore using graph neural networks and expert knowledge for
smart contract vulnerability detection. Specifically, we cast the rich control-
and data- flow semantics of the source code into a contract graph. To highlight
the critical nodes in the graph, we further design a node elimination phase to
normalize the graph. Then, we propose a novel temporal message propagation
network to extract the graph feature from the normalized graph, and combine the
graph feature with designed expert patterns to yield a final detection system.
Extensive experiments are conducted on all the smart contracts that have source
code in Ethereum and VNT Chain platforms. Empirical results show significant
accuracy improvements over the state-of-the-art methods on three types of
vulnerabilities, where the detection accuracy of our method reaches 89.15%,
89.02%, and 83.21% for reentrancy, timestamp dependence, and infinite loop
vulnerabilities, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Repairing Neural Networks: Provable Safety for Deep Networks via Dynamic Repair. (arXiv:2107.11445v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leino_K/0/1/0/all/0/1">Klas Leino</a>, <a href="http://arxiv.org/find/cs/1/au:+Fromherz_A/0/1/0/all/0/1">Aymeric Fromherz</a>, <a href="http://arxiv.org/find/cs/1/au:+Mangal_R/0/1/0/all/0/1">Ravi Mangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1">Matt Fredrikson</a>, <a href="http://arxiv.org/find/cs/1/au:+Parno_B/0/1/0/all/0/1">Bryan Parno</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasareanu_C/0/1/0/all/0/1">Corina P&#x103;s&#x103;reanu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11445">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are increasingly being deployed in contexts where safety is a
critical concern. In this work, we propose a way to construct neural network
classifiers that dynamically repair violations of non-relational safety
constraints called safe ordering properties. Safe ordering properties relate
requirements on the ordering of a network&#x27;s output indices to conditions on
their input, and are sufficient to express most useful notions of
non-relational safety for classifiers. Our approach is based on a novel
self-repairing layer, which provably yields safe outputs regardless of the
characteristics of its input. We compose this layer with an existing network to
construct a self-repairing network (SR-Net), and show that in addition to
providing safe outputs, the SR-Net is guaranteed to preserve the accuracy of
the original network. Notably, our approach is independent of the size and
architecture of the network being repaired, depending only on the specified
property and the dimension of the network&#x27;s output; thus it is scalable to
large state-of-the-art networks. We show that our approach can be implemented
using vectorized computations that execute efficiently on a GPU, introducing
run-time overhead of less than one millisecond on current hardware -- even on
large, widely-used networks containing hundreds of thousands of neurons and
millions of parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedLab: A Flexible Federated Learning Framework. (arXiv:2107.11621v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_D/0/1/0/all/0/1">Dun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1">Siqi Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiangjing Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11621">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) is a solution for privacy challenge, which allows
multiparty to train a shared model without violating privacy protection
regulations. Many excellent works of FL have been proposed in recent years. To
help researchers verify their ideas in FL, we designed and developed FedLab, a
flexible and modular FL framework based on PyTorch. In this paper, we will
introduce architecture and features of FedLab. For current popular research
points: optimization and communication compression, FedLab provides functional
interfaces and a series of baseline implementation are available, making
researchers quickly implement ideas. In addition, FedLab is scale-able in both
client simulation and distributed communication.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-based micro-data reinforcement learning: what are the crucial model properties and which model to choose?. (arXiv:2107.11587v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kegl_B/0/1/0/all/0/1">Bal&#xe1;zs K&#xe9;gl</a>, <a href="http://arxiv.org/find/cs/1/au:+Hurtado_G/0/1/0/all/0/1">Gabriel Hurtado</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_A/0/1/0/all/0/1">Albert Thomas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11587">
                                    <div class="article-summary-box-inner">
                                        <span>We contribute to micro-data model-based reinforcement learning (MBRL) by
rigorously comparing popular generative models using a fixed (random shooting)
control agent. We find that on an environment that requires multimodal
posterior predictives, mixture density nets outperform all other models by a
large margin. When multimodality is not required, our surprising finding is
that we do not need probabilistic posterior predictives: deterministic models
are on par, in fact they consistently (although non-significantly) outperform
their probabilistic counterparts. We also found that heteroscedasticity at
training time, perhaps acting as a regularizer, improves predictions at longer
horizons. At the methodological side, we design metrics and an experimental
protocol which can be used to evaluate the various models, predicting their
asymptotic performance when using them on the control problem. Using this
framework, we improve the state-of-the-art sample complexity of MBRL on Acrobot
by two to four folds, using an aggressive training schedule which is outside of
the hyperparameter interval usually considered</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete Denoising Flows. (arXiv:2107.11625v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lindt_A/0/1/0/all/0/1">Alexandra Lindt</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1">Emiel Hoogeboom</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11625">
                                    <div class="article-summary-box-inner">
                                        <span>Discrete flow-based models are a recently proposed class of generative models
that learn invertible transformations for discrete random variables. Since they
do not require data dequantization and maximize an exact likelihood objective,
they can be used in a straight-forward manner for lossless compression. In this
paper, we introduce a new discrete flow-based model for categorical random
variables: Discrete Denoising Flows (DDFs). In contrast with other discrete
flow-based models, our model can be locally trained without introducing
gradient bias. We show that DDFs outperform Discrete Flows on modeling a toy
example, binary MNIST and Cityscapes segmentation maps, measured in
log-likelihood.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HierMUD: Hierarchical Multi-task Unsupervised Domain Adaptation between Bridges for Drive-by Damage Diagnosis. (arXiv:2107.11435v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingxiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1">Susu Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Berges_M/0/1/0/all/0/1">Mario Berg&#xe9;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Noh_H/0/1/0/all/0/1">Hae Young Noh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11435">
                                    <div class="article-summary-box-inner">
                                        <span>Monitoring bridge health using vibrations of drive-by vehicles has various
benefits, such as no need for directly installing and maintaining sensors on
the bridge. However, many of the existing drive-by monitoring approaches are
based on supervised learning models that require labeled data from every bridge
of interest, which is expensive and time-consuming, if not impossible, to
obtain. To this end, we introduce a new framework that transfers the model
learned from one bridge to diagnose damage in another bridge without any labels
from the target bridge. Our framework trains a hierarchical neural network
model in an adversarial way to extract task-shared and task-specific features
that are informative to multiple diagnostic tasks and invariant across multiple
bridges. We evaluate our framework on experimental data collected from 2
bridges and 3 vehicles. We achieve accuracies of 95% for damage detection, 93%
for localization, and up to 72% for quantification, which are ~2 times
improvements from baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Free Hyperbolic Neural Networks with Limited Radii. (arXiv:2107.11472v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yunhui Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xudong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yubei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Stella X. Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11472">
                                    <div class="article-summary-box-inner">
                                        <span>Non-Euclidean geometry with constant negative curvature, i.e., hyperbolic
space, has attracted sustained attention in the community of machine learning.
Hyperbolic space, owing to its ability to embed hierarchical structures
continuously with low distortion, has been applied for learning data with
tree-like structures. Hyperbolic Neural Networks (HNNs) that operate directly
in hyperbolic space have also been proposed recently to further exploit the
potential of hyperbolic representations. While HNNs have achieved better
performance than Euclidean neural networks (ENNs) on datasets with implicit
hierarchical structure, they still perform poorly on standard classification
benchmarks such as CIFAR and ImageNet. The traditional wisdom is that it is
critical for the data to respect the hyperbolic geometry when applying HNNs. In
this paper, we first conduct an empirical study showing that the inferior
performance of HNNs on standard recognition datasets can be attributed to the
notorious vanishing gradient problem. We further discovered that this problem
stems from the hybrid architecture of HNNs. Our analysis leads to a simple yet
effective solution called Feature Clipping, which regularizes the hyperbolic
embedding whenever its norm exceeding a given threshold. Our thorough
experiments show that the proposed method can successfully avoid the vanishing
gradient problem when training HNNs with backpropagation. The improved HNNs are
able to achieve comparable performance with ENNs on standard image recognition
datasets including MNIST, CIFAR10, CIFAR100 and ImageNet, while demonstrating
more adversarial robustness and stronger out-of-distribution detection
capability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compressing Neural Networks: Towards Determining the Optimal Layer-wise Decomposition. (arXiv:2107.11442v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liebenwein_L/0/1/0/all/0/1">Lucas Liebenwein</a>, <a href="http://arxiv.org/find/cs/1/au:+Maalouf_A/0/1/0/all/0/1">Alaa Maalouf</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_O/0/1/0/all/0/1">Oren Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_D/0/1/0/all/0/1">Dan Feldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1">Daniela Rus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11442">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel global compression framework for deep neural networks that
automatically analyzes each layer to identify the optimal per-layer compression
ratio, while simultaneously achieving the desired overall compression. Our
algorithm hinges on the idea of compressing each convolutional (or
fully-connected) layer by slicing its channels into multiple groups and
decomposing each group via low-rank decomposition. At the core of our algorithm
is the derivation of layer-wise error bounds from the Eckart Young Mirsky
theorem. We then leverage these bounds to frame the compression problem as an
optimization problem where we wish to minimize the maximum compression error
across layers and propose an efficient algorithm towards a solution. Our
experiments indicate that our method outperforms existing low-rank compression
approaches across a wide range of networks and data sets. We believe that our
results open up new avenues for future research into the global
performance-size trade-offs of modern neural networks. Our code is available at
https://github.com/lucaslie/torchprune.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Adversarial Examples Is (Nearly) As Hard As Classifying Them. (arXiv:2107.11630v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tramer_F/0/1/0/all/0/1">Florian Tram&#xe8;r</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11630">
                                    <div class="article-summary-box-inner">
                                        <span>Making classifiers robust to adversarial examples is hard. Thus, many
defenses tackle the seemingly easier task of detecting perturbed inputs. We
show a barrier towards this goal. We prove a general hardness reduction between
detection and classification of adversarial examples: given a robust detector
for attacks at distance {\epsilon} (in some metric), we can build a similarly
robust (but inefficient) classifier for attacks at distance {\epsilon}/2. Our
reduction is computationally inefficient, and thus cannot be used to build
practical classifiers. Instead, it is a useful sanity check to test whether
empirical detection results imply something much stronger than the authors
presumably anticipated. To illustrate, we revisit 13 detector defenses. For
11/13 cases, we show that the claimed detection results would imply an
inefficient classifier with robustness far beyond the state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Perspective Content Delivery Networks Security Framework Using Optimized Unsupervised Anomaly Detection. (arXiv:2107.11514v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Li Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Moubayed_A/0/1/0/all/0/1">Abdallah Moubayed</a>, <a href="http://arxiv.org/find/cs/1/au:+Shami_A/0/1/0/all/0/1">Abdallah Shami</a>, <a href="http://arxiv.org/find/cs/1/au:+Heidari_P/0/1/0/all/0/1">Parisa Heidari</a>, <a href="http://arxiv.org/find/cs/1/au:+Boukhtouta_A/0/1/0/all/0/1">Amine Boukhtouta</a>, <a href="http://arxiv.org/find/cs/1/au:+Larabi_A/0/1/0/all/0/1">Adel Larabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Brunner_R/0/1/0/all/0/1">Richard Brunner</a>, <a href="http://arxiv.org/find/cs/1/au:+Preda_S/0/1/0/all/0/1">Stere Preda</a>, <a href="http://arxiv.org/find/cs/1/au:+Migault_D/0/1/0/all/0/1">Daniel Migault</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11514">
                                    <div class="article-summary-box-inner">
                                        <span>Content delivery networks (CDNs) provide efficient content distribution over
the Internet. CDNs improve the connectivity and efficiency of global
communications, but their caching mechanisms may be breached by
cyber-attackers. Among the security mechanisms, effective anomaly detection
forms an important part of CDN security enhancement. In this work, we propose a
multi-perspective unsupervised learning framework for anomaly detection in
CDNs. In the proposed framework, a multi-perspective feature engineering
approach, an optimized unsupervised anomaly detection model that utilizes an
isolation forest and a Gaussian mixture model, and a multi-perspective
validation method, are developed to detect abnormal behaviors in CDNs mainly
from the client Internet Protocol (IP) and node perspectives, therefore to
identify the denial of service (DoS) and cache pollution attack (CPA) patterns.
Experimental results are presented based on the analytics of eight days of
real-world CDN log data provided by a major CDN operator. Through experiments,
the abnormal contents, compromised nodes, malicious IPs, as well as their
corresponding attack types, are identified effectively by the proposed
framework and validated by multiple cybersecurity experts. This shows the
effectiveness of the proposed method when applied to real-world CDN data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Sample Complexity of Privately Learning Axis-Aligned Rectangles. (arXiv:2107.11526v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sadigurschi_M/0/1/0/all/0/1">Menachem Sadigurschi</a>, <a href="http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1">Uri Stemmer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11526">
                                    <div class="article-summary-box-inner">
                                        <span>We revisit the fundamental problem of learning Axis-Aligned-Rectangles over a
finite grid $X^d\subseteq{\mathbb{R}}^d$ with differential privacy. Existing
results show that the sample complexity of this problem is at most $\min\left\{
d{\cdot}\log|X| \;,\; d^{1.5}{\cdot}\left(\log^*|X| \right)^{1.5}\right\}$.
That is, existing constructions either require sample complexity that grows
linearly with $\log|X|$, or else it grows super linearly with the dimension
$d$. We present a novel algorithm that reduces the sample complexity to only
$\tilde{O}\left\{d{\cdot}\left(\log^*|X|\right)^{1.5}\right\}$, attaining a
dimensionality optimal dependency without requiring the sample complexity to
grow with $\log|X|$.The technique used in order to attain this improvement
involves the deletion of &quot;exposed&quot; data-points on the go, in a fashion designed
to avoid the cost of the adaptive composition theorems. The core of this
technique may be of individual interest, introducing a new method for
constructing statistically-efficient private algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">$\mu$DARTS: Model Uncertainty-Aware Differentiable Architecture Search. (arXiv:2107.11500v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_B/0/1/0/all/0/1">Biswadeep Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukhopadhyay_S/0/1/0/all/0/1">Saibal Mukhopadhyay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11500">
                                    <div class="article-summary-box-inner">
                                        <span>We present a Model Uncertainty-aware Differentiable ARchiTecture Search
($\mu$DARTS) that optimizes neural networks to simultaneously achieve high
accuracy and low uncertainty. We introduce concrete dropout within DARTS cells
and include a Monte-Carlo regularizer within the training loss to optimize the
concrete dropout probabilities. A predictive variance term is introduced in the
validation loss to enable searching for architecture with minimal model
uncertainty. The experiments on CIFAR10, CIFAR100, SVHN, and ImageNet verify
the effectiveness of $\mu$DARTS in improving accuracy and reducing uncertainty
compared to existing DARTS methods. Moreover, the final architecture obtained
from $\mu$DARTS shows higher robustness to noise at the input image and model
parameters compared to the architecture obtained from existing DARTS methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training multi-objective/multi-task collocation physics-informed neural network with student/teachers transfer learnings. (arXiv:2107.11496v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bahmani_B/0/1/0/all/0/1">Bahador Bahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">WaiChing Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11496">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a PINN training framework that employs (1) pre-training
steps that accelerates and improve the robustness of the training of
physics-informed neural network with auxiliary data stored in point clouds, (2)
a net-to-net knowledge transfer algorithm that improves the weight
initialization of the neural network and (3) a multi-objective optimization
algorithm that may improve the performance of a physical-informed neural
network with competing constraints. We consider the training and transfer and
multi-task learning of physics-informed neural network (PINN) as
multi-objective problems where the physics constraints such as the governing
equation, boundary conditions, thermodynamic inequality, symmetry, and
invariant properties, as well as point cloud used for pre-training can
sometimes lead to conflicts and necessitating the seek of the Pareto optimal
solution. In these situations, weighted norms commonly used to handle multiple
constraints may lead to poor performance, while other multi-objective
algorithms may scale poorly with increasing dimensionality. To overcome this
technical barrier, we adopt the concept of vectorized objective function and
modify a gradient descent approach to handle the issue of conflicting
gradients. Numerical experiments are compared the benchmark boundary value
problems solved via PINN. The performance of the proposed paradigm is compared
against the classical equal-weighted norm approach. Our numerical experiments
indicate that the brittleness and lack of robustness demonstrated in some PINN
implementations can be overcome with the proposed strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A general sample complexity analysis of vanilla policy gradient. (arXiv:2107.11433v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_R/0/1/0/all/0/1">Rui Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gower_R/0/1/0/all/0/1">Robert M. Gower</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazaric_A/0/1/0/all/0/1">Alessandro Lazaric</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11433">
                                    <div class="article-summary-box-inner">
                                        <span>The policy gradient (PG) is one of the most popular methods for solving
reinforcement learning (RL) problems. However, a solid theoretical
understanding of even the &quot;vanilla&quot; PG has remained elusive for long time. In
this paper, we apply recent tools developed for the analysis of SGD in
non-convex optimization to obtain convergence guarantees for both REINFORCE and
GPOMDP under smoothness assumption on the objective function and weak
conditions on the second moment of the norm of the estimated gradient. When
instantiated under common assumptions on the policy space, our general result
immediately recovers existing $\widetilde{\mathcal{O}}(\epsilon^{-4})$ sample
complexity guarantees, but for wider ranges of parameters (e.g., step size and
batch size $m$) with respect to previous literature. Notably, our result
includes the single trajectory case (i.e., $m&#x3D;1$) and it provides a more
accurate analysis of the dependency on problem-specific parameters by fixing
previous results available in the literature. We believe that the integration
of state-of-the-art tools from non-convex optimization may lead to identify a
much broader range of problems where PG methods enjoy strong theoretical
guarantees.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using a Cross-Task Grid of Linear Probes to Interpret CNN Model Predictions On Retinal Images. (arXiv:2107.11468v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blumer_K/0/1/0/all/0/1">Katy Blumer</a>, <a href="http://arxiv.org/find/cs/1/au:+Venugopalan_S/0/1/0/all/0/1">Subhashini Venugopalan</a>, <a href="http://arxiv.org/find/cs/1/au:+Brenner_M/0/1/0/all/0/1">Michael P. Brenner</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1">Jon Kleinberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11468">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze a dataset of retinal images using linear probes: linear regression
models trained on some &quot;target&quot; task, using embeddings from a deep
convolutional (CNN) model trained on some &quot;source&quot; task as input. We use this
method across all possible pairings of 93 tasks in the UK Biobank dataset of
retinal images, leading to ~164k different models. We analyze the performance
of these linear probes by source and target task and by layer depth. We observe
that representations from the middle layers of the network are more
generalizable. We find that some target tasks are easily predicted irrespective
of the source task, and that some other target tasks are more accurately
predicted from correlated source tasks than from embeddings trained on the same
task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-Free Non-Stationary RL: Near-Optimal Regret and Applications in Multi-Agent RL and Inventory Control. (arXiv:2010.03161v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_W/0/1/0/all/0/1">Weichao Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaiqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1">Ruihao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Simchi_Levi_D/0/1/0/all/0/1">David Simchi-Levi</a>, <a href="http://arxiv.org/find/cs/1/au:+Basar_T/0/1/0/all/0/1">Tamer Ba&#x15f;ar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.03161">
                                    <div class="article-summary-box-inner">
                                        <span>We consider model-free reinforcement learning (RL) in non-stationary Markov
decision processes. Both the reward functions and the state transition
functions are allowed to vary arbitrarily over time as long as their cumulative
variations do not exceed certain variation budgets. We propose Restarted
Q-Learning with Upper Confidence Bounds (RestartQ-UCB), the first model-free
algorithm for non-stationary RL, and show that it outperforms existing
solutions in terms of dynamic regret. Specifically, RestartQ-UCB with
Freedman-type bonus terms achieves a dynamic regret bound of
$\widetilde{O}(S^{\frac{1}{3}} A^{\frac{1}{3}} \Delta^{\frac{1}{3}} H
T^{\frac{2}{3}})$, where $S$ and $A$ are the numbers of states and actions,
respectively, $\Delta&gt;0$ is the variation budget, $H$ is the number of time
steps per episode, and $T$ is the total number of time steps. We further
present a parameter-free algorithm named Double-Restart Q-UCB that does not
require prior knowledge of the variation budget. We show that our algorithms
are \emph{nearly optimal} by establishing an information-theoretical lower
bound of $\Omega(S^{\frac{1}{3}} A^{\frac{1}{3}} \Delta^{\frac{1}{3}}
H^{\frac{2}{3}} T^{\frac{2}{3}})$, the first lower bound in non-stationary RL.
Numerical experiments validate the advantages of RestartQ-UCB in terms of both
cumulative rewards and computational efficiency. We demonstrate the power of
our results in examples of multi-agent RL and inventory control across related
products.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic selection of inducing points in sparse Gaussian processes. (arXiv:2010.09370v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Uhrenholt_A/0/1/0/all/0/1">Anders Kirk Uhrenholt</a>, <a href="http://arxiv.org/find/cs/1/au:+Charvet_V/0/1/0/all/0/1">Valentin Charvet</a>, <a href="http://arxiv.org/find/cs/1/au:+Jensen_B/0/1/0/all/0/1">Bj&#xf8;rn Sand Jensen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09370">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse Gaussian processes and various extensions thereof are enabled through
inducing points, that simultaneously bottleneck the predictive capacity and act
as the main contributor towards model complexity. However, the number of
inducing points is generally not associated with uncertainty which prevents us
from applying the apparatus of Bayesian reasoning for identifying an
appropriate trade-off. In this work we place a point process prior on the
inducing points and approximate the associated posterior through stochastic
variational inference. By letting the prior encourage a moderate number of
inducing points, we enable the model to learn which and how many points to
utilise. We experimentally show that fewer inducing points are preferred by the
model as the points become less informative, and further demonstrate how the
method can be employed in deep Gaussian processes and latent variable
modelling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-Optimal Algorithms for Minimax Optimization. (arXiv:2002.02417v6 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1">Tianyi Lin</a>, <a href="http://arxiv.org/find/math/1/au:+Jin_C/0/1/0/all/0/1">Chi Jin</a>, <a href="http://arxiv.org/find/math/1/au:+Jordan_M/0/1/0/all/0/1">Michael. I. Jordan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.02417">
                                    <div class="article-summary-box-inner">
                                        <span>This paper resolves a longstanding open question pertaining to the design of
near-optimal first-order algorithms for smooth and
strongly-convex-strongly-concave minimax problems. Current state-of-the-art
first-order algorithms find an approximate Nash equilibrium using
$\tilde{O}(\kappa_{\mathbf x}+\kappa_{\mathbf y})$ or
$\tilde{O}(\min\{\kappa_{\mathbf x}\sqrt{\kappa_{\mathbf y}},
\sqrt{\kappa_{\mathbf x}}\kappa_{\mathbf y}\})$ gradient evaluations, where
$\kappa_{\mathbf x}$ and $\kappa_{\mathbf y}$ are the condition numbers for the
strong-convexity and strong-concavity assumptions. A gap still remains between
these results and the best existing lower bound
$\tilde{\Omega}(\sqrt{\kappa_{\mathbf x}\kappa_{\mathbf y}})$. This paper
presents the first algorithm with $\tilde{O}(\sqrt{\kappa_{\mathbf
x}\kappa_{\mathbf y}})$ gradient complexity, matching the lower bound up to
logarithmic factors. Our algorithm is designed based on an accelerated proximal
point method and an accelerated solver for minimax proximal steps. It can be
easily extended to the settings of strongly-convex-concave, convex-concave,
nonconvex-strongly-concave, and nonconvex-concave functions. This paper also
presents algorithms that match or outperform all existing methods in these
settings in terms of gradient complexity, up to logarithmic factors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Approximate Natural Gradient Descent in a Kronecker-factored Eigenbasis. (arXiv:1806.03884v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+George_T/0/1/0/all/0/1">Thomas George</a>, <a href="http://arxiv.org/find/cs/1/au:+Laurent_C/0/1/0/all/0/1">C&#xe9;sar Laurent</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouthillier_X/0/1/0/all/0/1">Xavier Bouthillier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1">Nicolas Ballas</a>, <a href="http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1">Pascal Vincent</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1806.03884">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization algorithms that leverage gradient covariance information, such
as variants of natural gradient descent (Amari, 1998), offer the prospect of
yielding more effective descent directions. For models with many parameters,
the covariance matrix they are based on becomes gigantic, making them
inapplicable in their original form. This has motivated research into both
simple diagonal approximations and more sophisticated factored approximations
such as KFAC (Heskes, 2000; Martens &amp; Grosse, 2015; Grosse &amp; Martens, 2016). In
the present work we draw inspiration from both to propose a novel approximation
that is provably better than KFAC and amendable to cheap partial updates. It
consists in tracking a diagonal variance, not in parameter coordinates, but in
a Kronecker-factored eigenbasis, in which the diagonal approximation is likely
to be more effective. Experiments show improvements over KFAC in optimization
speed for several deep network architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local2Global: Scaling global representation learning on graphs via local training. (arXiv:2107.12224v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jeub_L/0/1/0/all/0/1">Lucas G. S. Jeub</a>, <a href="http://arxiv.org/find/cs/1/au:+Colavizza_G/0/1/0/all/0/1">Giovanni Colavizza</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xiaowen Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Bazzi_M/0/1/0/all/0/1">Marya Bazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucuringu_M/0/1/0/all/0/1">Mihai Cucuringu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12224">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a decentralised &quot;local2global&quot; approach to graph representation
learning, that one can a-priori use to scale any embedding technique. Our
local2global approach proceeds by first dividing the input graph into
overlapping subgraphs (or &quot;patches&quot;) and training local representations for
each patch independently. In a second step, we combine the local
representations into a globally consistent representation by estimating the set
of rigid motions that best align the local representations using information
from the patch overlaps, via group synchronization. A key distinguishing
feature of local2global relative to existing work is that patches are trained
independently without the need for the often costly parameter synchronisation
during distributed training. This allows local2global to scale to large-scale
industrial applications, where the input graph may not even fit into memory and
may be stored in a distributed manner. Preliminary results on medium-scale data
sets (up to $\sim$7K nodes and $\sim$200K edges) are promising, with a graph
reconstruction performance for local2global that is comparable to that of
globally trained embeddings. A thorough evaluation of local2global on large
scale data and applications to downstream tasks, such as node classification
and link prediction, constitutes ongoing work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction-Centric Learning of Independent Cascade Dynamics from Partial Observations. (arXiv:2007.06557v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wilinski_M/0/1/0/all/0/1">Mateusz Wilinski</a>, <a href="http://arxiv.org/find/cs/1/au:+Lokhov_A/0/1/0/all/0/1">Andrey Y. Lokhov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06557">
                                    <div class="article-summary-box-inner">
                                        <span>Spreading processes play an increasingly important role in modeling for
diffusion networks, information propagation, marketing and opinion setting. We
address the problem of learning of a spreading model such that the predictions
generated from this model are accurate and could be subsequently used for the
optimization, and control of diffusion dynamics. We focus on a challenging
setting where full observations of the dynamics are not available, and standard
approaches such as maximum likelihood quickly become intractable for large
network instances. We introduce a computationally efficient algorithm, based on
a scalable dynamic message-passing approach, which is able to learn parameters
of the effective spreading model given only limited information on the
activation times of nodes in the network. The popular Independent Cascade model
is used to illustrate our approach. We show that tractable inference from the
learned model generates a better prediction of marginal probabilities compared
to the original model. We develop a systematic procedure for learning a mixture
of models which further improves the prediction quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Protein-RNA interaction prediction with deep learning: Structure matters. (arXiv:2107.12243v1 [q-bio.BM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Wei_J/0/1/0/all/0/1">Junkang Wei</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_S/0/1/0/all/0/1">Siyuan Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Zong_L/0/1/0/all/0/1">Licheng Zong</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Gao_X/0/1/0/all/0/1">Xin Gao</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12243">
                                    <div class="article-summary-box-inner">
                                        <span>Protein-RNA interactions are of vital importance to a variety of cellular
activities. Both experimental and computational techniques have been developed
to study the interactions. Due to the limitation of the previous database,
especially the lack of protein structure data, most of the existing
computational methods rely heavily on the sequence data, with only a small
portion of the methods utilizing the structural information. Recently,
AlphaFold has revolutionized the entire protein and biology field. Foreseeably,
the protein-RNA interaction prediction will also be promoted significantly in
the upcoming years. In this work, we give a thorough review of this field,
surveying both the binding site and binding preference prediction problems and
covering the commonly used datasets, features, and models. We also point out
the potential challenges and opportunities in this field. This survey
summarizes the development of the RBP-RNA interaction field in the past and
foresees its future development in the post-AlphaFold era.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Denoising and Segmentation of Epigraphical Scripts. (arXiv:2107.11801v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Preethi_P/0/1/0/all/0/1">P Preethi</a>, <a href="http://arxiv.org/find/cs/1/au:+Viswanath_H/0/1/0/all/0/1">Hrishikesh Viswanath</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11801">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is a presentation of a new method for denoising images using
Haralick features and further segmenting the characters using artificial neural
networks. The image is divided into kernels, each of which is converted to a
GLCM (Gray Level Co-Occurrence Matrix) on which a Haralick Feature generation
function is called, the result of which is an array with fourteen elements
corresponding to fourteen features The Haralick values and the corresponding
noise/text classification form a dictionary, which is then used to de-noise the
image through kernel comparison. Segmentation is the process of extracting
characters from a document and can be used when letters are separated by white
space, which is an explicit boundary marker. Segmentation is the first step in
many Natural Language Processing problems. This paper explores the process of
segmentation using Neural Networks. While there have been numerous methods to
segment characters of a document, this paper is only concerned with the
accuracy of doing so using neural networks. It is imperative that the
characters be segmented correctly, for failing to do so will lead to incorrect
recognition by Natural language processing tools. Artificial Neural Networks
was used to attain accuracy of upto 89%. This method is suitable for languages
where the characters are delimited by white space. However, this method will
fail to provide acceptable results when the language heavily uses connected
letters. An example would be the Devanagari script, which is predominantly used
in northern India.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A binary variant of gravitational search algorithm and its application to windfarm layout optimization problem. (arXiv:2107.11844v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1">Susheel Kumar Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_J/0/1/0/all/0/1">Jagdish Chand Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11844">
                                    <div class="article-summary-box-inner">
                                        <span>In the binary search space, GSA framework encounters the shortcomings of
stagnation, diversity loss, premature convergence and high time complexity. To
address these issues, a novel binary variant of GSA called &#x60;A novel
neighbourhood archives embedded gravitational constant in GSA for binary search
space (BNAGGSA)&#x27; is proposed in this paper. In BNAGGSA, the novel
fitness-distance based social interaction strategy produces a self-adaptive
step size mechanism through which the agent moves towards the optimal direction
with the optimal step size, as per its current search requirement. The
performance of the proposed algorithm is compared with the two binary variants
of GSA over 23 well-known benchmark test problems. The experimental results and
statistical analyses prove the supremacy of BNAGGSA over the compared
algorithms. Furthermore, to check the applicability of the proposed algorithm
in solving real-world applications, a windfarm layout optimization problem is
considered. Two case studies with two different wind data sets of two different
wind sites is considered for experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributional Shifts in Automated Diabetic Retinopathy Screening. (arXiv:2107.11822v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nandy_J/0/1/0/all/0/1">Jay Nandy</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1">Wynne Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Mong Li Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11822">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based models are developed to automatically detect if a retina
image is &#x60;referable&#x27; in diabetic retinopathy (DR) screening. However, their
classification accuracy degrades as the input images distributionally shift
from their training distribution. Further, even if the input is not a retina
image, a standard DR classifier produces a high confident prediction that the
image is &#x60;referable&#x27;. Our paper presents a Dirichlet Prior Network-based
framework to address this issue. It utilizes an out-of-distribution (OOD)
detector model and a DR classification model to improve generalizability by
identifying OOD images. Experiments on real-world datasets indicate that the
proposed framework can eliminate the unknown non-retina images and identify the
distributionally shifted retina images for human intervention.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Detection Of Noise Events at Shooting Range Using Machine Learning. (arXiv:2107.11453v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nordby_J/0/1/0/all/0/1">Jon Nordby</a>, <a href="http://arxiv.org/find/cs/1/au:+Nemazi_F/0/1/0/all/0/1">Fabian Nemazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieber_D/0/1/0/all/0/1">Dag Rieber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11453">
                                    <div class="article-summary-box-inner">
                                        <span>Outdoor shooting ranges are subject to noise regulations from local and
national authorities. Restrictions found in these regulations may include
limits on times of activities, the overall number of noise events, as well as
limits on number of events depending on the class of noise or activity. A noise
monitoring system may be used to track overall sound levels, but rarely provide
the ability to detect activity or count the number of events, required to
compare directly with such regulations. This work investigates the feasibility
and performance of an automatic detection system to count noise events. An
empirical evaluation was done by collecting data at a newly constructed
shooting range and training facility. The data includes tests of multiple
weapon configurations from small firearms to high caliber rifles and
explosives, at multiple source positions, and collected on multiple different
days. Several alternative machine learning models are tested, using as inputs
time-series of standard acoustic indicators such as A-weighted sound levels and
1/3 octave spectrogram, and classifiers such as Logistic Regression and
Convolutional Neural Networks. Performance for the various alternatives are
reported in terms of the False Positive Rate and False Negative Rate. The
detection performance was found to be satisfactory for use in automatic logging
of time-periods with training activity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aggregate or Not? Exploring Where to Privatize in DNN Based Federated Learning Under Different Non-IID Scenes. (arXiv:2107.11954v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin-Chun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1">Le Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1">Yunfeng Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bingshuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shaoming Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11954">
                                    <div class="article-summary-box-inner">
                                        <span>Although federated learning (FL) has recently been proposed for efficient
distributed training and data privacy protection, it still encounters many
obstacles. One of these is the naturally existing statistical heterogeneity
among clients, making local data distributions non independently and
identically distributed (i.e., non-iid), which poses challenges for model
aggregation and personalization. For FL with a deep neural network (DNN),
privatizing some layers is a simple yet effective solution for non-iid
problems. However, which layers should we privatize to facilitate the learning
process? Do different categories of non-iid scenes have preferred privatization
ways? Can we automatically learn the most appropriate privatization way during
FL? In this paper, we answer these questions via abundant experimental studies
on several FL benchmarks. First, we present the detailed statistics of these
benchmarks and categorize them into covariate and label shift non-iid scenes.
Then, we investigate both coarse-grained and fine-grained network splits and
explore whether the preferred privatization ways have any potential relations
to the specific category of a non-iid scene. Our findings are exciting, e.g.,
privatizing the base layers could boost the performances even in label shift
non-iid scenes, which are inconsistent with some natural conjectures. We also
find that none of these privatization ways could improve the performances on
the Shakespeare benchmark, and we guess that Shakespeare may not be a seriously
non-iid scene. Finally, we propose several approaches to automatically learn
where to aggregate via cross-stitch, soft attention, and hard selection. We
advocate the proposed methods could serve as a preliminary try to explore where
to privatize for a novel non-iid scene.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Facetron: Multi-speaker Face-to-Speech Model based on Cross-modal Latent Representations. (arXiv:2107.12003v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Um_S/0/1/0/all/0/1">Se-Yun Um</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Jihyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jihyun Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1">Sangshin Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Byun_K/0/1/0/all/0/1">Kyungguen Byun</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_H/0/1/0/all/0/1">Hong-Goo Kang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12003">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an effective method to synthesize speaker-specific
speech waveforms by conditioning on videos of an individual&#x27;s face. Using a
generative adversarial network (GAN) with linguistic and speaker characteristic
features as auxiliary conditions, our method directly converts face images into
speech waveforms under an end-to-end training framework. The linguistic
features are extracted from lip movements using a lip-reading model, and the
speaker characteristic features are predicted from face images using
cross-modal learning with a pre-trained acoustic model. Since these two
features are uncorrelated and controlled independently, we can flexibly
synthesize speech waveforms whose speaker characteristics vary depending on the
input face images. Therefore, our method can be regarded as a multi-speaker
face-to-speech waveform model. We show the superiority of our proposed model
over conventional methods in terms of both objective and subjective evaluation
results. Specifically, we evaluate the performances of the linguistic feature
and the speaker characteristic generation modules by measuring the accuracy of
automatic speech recognition and automatic speaker/gender recognition tasks,
respectively. We also evaluate the naturalness of the synthesized speech
waveforms using a mean opinion score (MOS) test.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep-learning-driven Reliable Single-pixel Imaging with Uncertainty Approximation. (arXiv:2107.11678v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shang_R/0/1/0/all/0/1">Ruibo Shang</a>, <a href="http://arxiv.org/find/eess/1/au:+OBrien_M/0/1/0/all/0/1">Mikaela A. O&#x27;Brien</a>, <a href="http://arxiv.org/find/eess/1/au:+Luke_G/0/1/0/all/0/1">Geoffrey P. Luke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11678">
                                    <div class="article-summary-box-inner">
                                        <span>Single-pixel imaging (SPI) has the advantages of high-speed acquisition over
a broad wavelength range and system compactness, which are difficult to achieve
by conventional imaging sensors. However, a common challenge is low image
quality arising from undersampling. Deep learning (DL) is an emerging and
powerful tool in computational imaging for many applications and researchers
have applied DL in SPI to achieve higher image quality than conventional
reconstruction approaches. One outstanding challenge, however, is that the
accuracy of DL predictions in SPI cannot be assessed in practical applications
where the ground truths are unknown. Here, we propose the use of the Bayesian
convolutional neural network (BCNN) to approximate the uncertainty (coming from
finite training data and network model) of the DL predictions in SPI. Each
pixel in the predicted result from BCNN represents the parameter of a
probability distribution rather than the image intensity value. Then, the
uncertainty can be approximated with BCNN by minimizing a negative
log-likelihood loss function in the training stage and Monte Carlo dropout in
the prediction stage. The results show that the BCNN can reliably approximate
the uncertainty of the DL predictions in SPI with varying compression ratios
and noise levels. The predicted uncertainty from BCNN in SPI reveals that most
of the reconstruction errors in deep-learning-based SPI come from the edges of
the image features. The results show that the proposed BCNN can provide a
reliable tool to approximate the uncertainty of DL predictions in SPI and can
be widely used in many applications of SPI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">P-KDGAN: Progressive Knowledge Distillation with GANs for One-class Novelty Detection. (arXiv:2007.06963v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shifeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1">Lei Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06963">
                                    <div class="article-summary-box-inner">
                                        <span>One-class novelty detection is to identify anomalous instances that do not
conform to the expected normal instances. In this paper, the Generative
Adversarial Networks (GANs) based on encoder-decoder-encoder pipeline are used
for detection and achieve state-of-the-art performance. However, deep neural
networks are too over-parameterized to deploy on resource-limited devices.
Therefore, Progressive Knowledge Distillation with GANs (PKDGAN) is proposed to
learn compact and fast novelty detection networks. The P-KDGAN is a novel
attempt to connect two standard GANs by the designed distillation loss for
transferring knowledge from the teacher to the student. The progressive
learning of knowledge distillation is a two-step approach that continuously
improves the performance of the student GAN and achieves better performance
than single step methods. In the first step, the student GAN learns the basic
knowledge totally from the teacher via guiding of the pretrained teacher GAN
with fixed weights. In the second step, joint fine-training is adopted for the
knowledgeable teacher and student GANs to further improve the performance and
stability. The experimental results on CIFAR-10, MNIST, and FMNIST show that
our method improves the performance of the student GAN by 2.44%, 1.77%, and
1.73% when compressing the computation at ratios of 24.45:1, 311.11:1, and
700:1, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerating Federated Edge Learning via Optimized Probabilistic Device Scheduling. (arXiv:2107.11588v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Maojun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1">Guangxu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiamo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_C/0/1/0/all/0/1">Caijun Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11588">
                                    <div class="article-summary-box-inner">
                                        <span>The popular federated edge learning (FEEL) framework allows
privacy-preserving collaborative model training via frequent learning-updates
exchange between edge devices and server. Due to the constrained bandwidth,
only a subset of devices can upload their updates at each communication round.
This has led to an active research area in FEEL studying the optimal device
scheduling policy for minimizing communication time. However, owing to the
difficulty in quantifying the exact communication time, prior work in this area
can only tackle the problem partially by considering either the communication
rounds or per-round latency, while the total communication time is determined
by both metrics. To close this gap, we make the first attempt in this paper to
formulate and solve the communication time minimization problem. We first
derive a tight bound to approximate the communication time through
cross-disciplinary effort involving both learning theory for convergence
analysis and communication theory for per-round latency analysis. Building on
the analytical result, an optimized probabilistic scheduling policy is derived
in closed-form by solving the approximate communication time minimization
problem. It is found that the optimized policy gradually turns its priority
from suppressing the remaining communication rounds to reducing per-round
latency as the training process evolves. The effectiveness of the proposed
scheme is demonstrated via a use case on collaborative 3D objective detection
in autonomous driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ROD: Reception-aware Online Distillation for Sparse Graphs. (arXiv:2107.11789v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wentao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuezihan Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Z/0/1/0/all/0/1">Zeang Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_X/0/1/0/all/0/1">Xupeng Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Liang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1">Bin Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11789">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) have been widely used in many graph-based tasks
such as node classification, link prediction, and node clustering. However,
GNNs gain their performance benefits mainly from performing the feature
propagation and smoothing across the edges of the graph, thus requiring
sufficient connectivity and label information for effective propagation.
Unfortunately, many real-world networks are sparse in terms of both edges and
labels, leading to sub-optimal performance of GNNs. Recent interest in this
sparse problem has focused on the self-training approach, which expands
supervised signals with pseudo labels. Nevertheless, the self-training approach
inherently cannot realize the full potential of refining the learning
performance on sparse graphs due to the unsatisfactory quality and quantity of
pseudo labels.

In this paper, we propose ROD, a novel reception-aware online knowledge
distillation approach for sparse graph learning. We design three supervision
signals for ROD: multi-scale reception-aware graph knowledge, task-based
supervision, and rich distilled knowledge, allowing online knowledge transfer
in a peer-teaching manner. To extract knowledge concealed in the multi-scale
reception fields, ROD explicitly requires individual student models to preserve
different levels of locality information. For a given task, each student would
predict based on its reception-scale knowledge, while simultaneously a strong
teacher is established on-the-fly by combining multi-scale knowledge. Our
approach has been extensively evaluated on 9 datasets and a variety of
graph-based tasks, including node classification, link prediction, and node
clustering. The result demonstrates that ROD achieves state-of-art performance
and is more robust for the graph sparsity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Direction and Proximity Classification of Overlapping Sound Events from Binaural Audio. (arXiv:2107.12033v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krause_D/0/1/0/all/0/1">Daniel Aleksander Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Politis_A/0/1/0/all/0/1">Archontis Politis</a>, <a href="http://arxiv.org/find/cs/1/au:+Mesaros_A/0/1/0/all/0/1">Annamaria Mesaros</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12033">
                                    <div class="article-summary-box-inner">
                                        <span>Sound source proximity and distance estimation are of great interest in many
practical applications, since they provide significant information for acoustic
scene analysis. As both tasks share complementary qualities, ensuring efficient
interaction between these two is crucial for a complete picture of an aural
environment. In this paper, we aim to investigate several ways of performing
joint proximity and direction estimation from binaural recordings, both defined
as coarse classification problems based on Deep Neural Networks (DNNs).
Considering the limitations of binaural audio, we propose two methods of
splitting the sphere into angular areas in order to obtain a set of directional
classes. For each method we study different model types to acquire information
about the direction-of-arrival (DoA). Finally, we propose various ways of
combining the proximity and direction estimation problems into a joint task
providing temporal information about the onsets and offsets of the appearing
sources. Experiments are performed for a synthetic reverberant binaural dataset
consisting of up to two overlapping sound events.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tail of Distribution GAN (TailGAN): Generative- Adversarial-Network-Based Boundary Formation. (arXiv:2107.11658v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dionelis_N/0/1/0/all/0/1">Nikolaos Dionelis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11658">
                                    <div class="article-summary-box-inner">
                                        <span>Generative Adversarial Networks (GAN) are a powerful methodology and can be
used for unsupervised anomaly detection, where current techniques have
limitations such as the accurate detection of anomalies near the tail of a
distribution. GANs generally do not guarantee the existence of a probability
density and are susceptible to mode collapse, while few GANs use likelihood to
reduce mode collapse. In this paper, we create a GAN-based tail formation model
for anomaly detection, the Tail of distribution GAN (TailGAN), to generate
samples on the tail of the data distribution and detect anomalies near the
support boundary. Using TailGAN, we leverage GANs for anomaly detection and use
maximum entropy regularization. Using GANs that learn the probability of the
underlying distribution has advantages in improving the anomaly detection
methodology by allowing us to devise a generator for boundary samples, and use
this model to characterize anomalies. TailGAN addresses supports with disjoint
components and achieves competitive performance on images. We evaluate TailGAN
for identifying Out-of-Distribution (OoD) data and its performance evaluated on
MNIST, CIFAR-10, Baggage X-Ray, and OoD data shows competitiveness compared to
methods from the literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably Accelerated Decentralized Gradient Method Over Unbalanced Directed Graphs. (arXiv:2107.12065v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1">Zhuoqing Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_L/0/1/0/all/0/1">Lei Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1">Shi Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1">Ming Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12065">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we consider the decentralized optimization problem in which a
network of $n$ agents, each possessing a smooth and convex objective function,
wish to collaboratively minimize the average of all the objective functions
through peer-to-peer communication in a directed graph. To solve the problem,
we propose two accelerated Push-DIGing methods termed APD and APD-SC for
minimizing non-strongly convex objective functions and strongly convex ones,
respectively. We show that APD and APD-SC respectively converge at the rates
$O\left(\frac{1}{k^2}\right)$ and $O\left(\left(1 -
C\sqrt{\frac{\mu}{L}}\right)^k\right)$ up to constant factors depending only on
the mixing matrix. To the best of our knowledge, APD and APD-SC are the first
decentralized methods to achieve provable acceleration over unbalanced directed
graphs. Numerical experiments demonstrate the effectiveness of both methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Model-Agnostic Algorithm for Bayes Error Determination in Binary Classification. (arXiv:2107.11609v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Michelucci_U/0/1/0/all/0/1">Umberto Michelucci</a>, <a href="http://arxiv.org/find/cs/1/au:+Sperti_M/0/1/0/all/0/1">Michela Sperti</a>, <a href="http://arxiv.org/find/cs/1/au:+Piga_D/0/1/0/all/0/1">Dario Piga</a>, <a href="http://arxiv.org/find/cs/1/au:+Venturini_F/0/1/0/all/0/1">Francesca Venturini</a>, <a href="http://arxiv.org/find/cs/1/au:+Deriu_M/0/1/0/all/0/1">Marco A. Deriu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11609">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the intrinsic limit determination algorithm (ILD
Algorithm), a novel technique to determine the best possible performance,
measured in terms of the AUC (area under the ROC curve) and accuracy, that can
be obtained from a specific dataset in a binary classification problem with
categorical features {\sl regardless} of the model used. This limit, namely the
Bayes error, is completely independent of any model used and describes an
intrinsic property of the dataset. The ILD algorithm thus provides important
information regarding the prediction limits of any binary classification
algorithm when applied to the considered dataset. In this paper the algorithm
is described in detail, its entire mathematical framework is presented and the
pseudocode is given to facilitate its implementation. Finally, an example with
a real dataset is given.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-intrusive reduced order modeling of natural convection in porous media using convolutional autoencoders: comparison with linear subspace techniques. (arXiv:2107.11460v1 [cs.CE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kadeethum_T/0/1/0/all/0/1">T. Kadeethum</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballarin_F/0/1/0/all/0/1">F. Ballarin</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_Y/0/1/0/all/0/1">Y. Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+OMalley_D/0/1/0/all/0/1">D. O&#x27;Malley</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoon_H/0/1/0/all/0/1">H. Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouklas_N/0/1/0/all/0/1">N. Bouklas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11460">
                                    <div class="article-summary-box-inner">
                                        <span>Natural convection in porous media is a highly nonlinear multiphysical
problem relevant to many engineering applications (e.g., the process of
$\mathrm{CO_2}$ sequestration). Here, we present a non-intrusive reduced order
model of natural convection in porous media employing deep convolutional
autoencoders for the compression and reconstruction and either radial basis
function (RBF) interpolation or artificial neural networks (ANNs) for mapping
parameters of partial differential equations (PDEs) on the corresponding
nonlinear manifolds. To benchmark our approach, we also describe linear
compression and reconstruction processes relying on proper orthogonal
decomposition (POD) and ANNs. We present comprehensive comparisons among
different models through three benchmark problems. The reduced order models,
linear and nonlinear approaches, are much faster than the finite element model,
obtaining a maximum speed-up of $7 \times 10^{6}$ because our framework is not
bound by the Courant-Friedrichs-Lewy condition; hence, it could deliver
quantities of interest at any given time contrary to the finite element model.
Our model&#x27;s accuracy still lies within a mean squared error of 0.07 (two-order
of magnitude lower than the maximum value of the finite element results) in the
worst-case scenario. We illustrate that, in specific settings, the nonlinear
approach outperforms its linear counterpart and vice versa. We hypothesize that
a visual comparison between principal component analysis (PCA) or t-Distributed
Stochastic Neighbor Embedding (t-SNE) could indicate which method will perform
better prior to employing any specific compression strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Machine Learning to Emulate Agent-Based Simulations. (arXiv:2005.02077v2 [cs.MA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Angione_C/0/1/0/all/0/1">Claudio Angione</a>, <a href="http://arxiv.org/find/cs/1/au:+Silverman_E/0/1/0/all/0/1">Eric Silverman</a>, <a href="http://arxiv.org/find/cs/1/au:+Yaneske_E/0/1/0/all/0/1">Elisabeth Yaneske</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.02077">
                                    <div class="article-summary-box-inner">
                                        <span>In this proof-of-concept work, we evaluate the performance of multiple
machine-learning methods as statistical emulators for use in the analysis of
agent-based models (ABMs). Analysing ABM outputs can be challenging, as the
relationships between input parameters can be non-linear or even chaotic even
in relatively simple models, and each model run can require significant CPU
time. Statistical emulation, in which a statistical model of the ABM is
constructed to facilitate detailed model analyses, has been proposed as an
alternative to computationally costly Monte Carlo methods. Here we compare
multiple machine-learning methods for ABM emulation in order to determine the
approaches best suited to emulating the complex behaviour of ABMs. Our results
suggest that, in most scenarios, artificial neural networks (ANNs) and
gradient-boosted trees outperform Gaussian process emulators, currently the
most commonly used method for the emulation of complex computational models.
ANNs produced the most accurate model replications in scenarios with high
numbers of model runs, although training times were longer than the other
methods. We propose that agent-based modelling would benefit from using
machine-learning methods for emulation, as this can facilitate more robust
sensitivity analyses for the models while also reducing CPU time consumption
when calibrating and analysing the simulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying the fragment structure of the organic compounds by deeply learning the original NMR data. (arXiv:2107.11740v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Li_C/0/1/0/all/0/1">Chongcan Li</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Cong_Y/0/1/0/all/0/1">Yong Cong</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Deng_W/0/1/0/all/0/1">Weihua Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11740">
                                    <div class="article-summary-box-inner">
                                        <span>We preprocess the raw NMR spectrum and extract key characteristic features by
using two different methodologies, called equidistant sampling and peak
sampling for subsequent substructure pattern recognition; meanwhile may provide
the alternative strategy to address the imbalance issue of the NMR dataset
frequently encountered in dataset collection of statistical modeling and
establish two conventional SVM and KNN models to assess the capability of two
feature selection, respectively. Our results in this study show that the models
using the selected features of peak sampling outperform the ones using the
other. Then we build the Recurrent Neural Network (RNN) model trained by Data B
collected from peak sampling. Furthermore, we illustrate the easier
optimization of hyper parameters and the better generalization ability of the
RNN deep learning model by comparison with traditional machine learning SVM and
KNN models in detail.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning with Fair Worker Selection: A Multi-Round Submodular Maximization Approach. (arXiv:2107.11728v1 [cs.GT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1">Fengjiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_B/0/1/0/all/0/1">Bo Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11728">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the problem of fair worker selection in Federated
Learning systems, where fairness serves as an incentive mechanism that
encourages more workers to participate in the federation. Considering the
achieved training accuracy of the global model as the utility of the selected
workers, which is typically a monotone submodular function, we formulate the
worker selection problem as a new multi-round monotone submodular maximization
problem with cardinality and fairness constraints. The objective is to maximize
the time-average utility over multiple rounds subject to an additional fairness
requirement that each worker must be selected for a certain fraction of time.
While the traditional submodular maximization with a cardinality constraint is
already a well-known NP-Hard problem, the fairness constraint in the
multi-round setting adds an extra layer of difficulty. To address this novel
challenge, we propose three algorithms: Fair Continuous Greedy (FairCG1 and
FairCG2) and Fair Discrete Greedy (FairDG), all of which satisfy the fairness
requirement whenever feasible. Moreover, we prove nontrivial lower bounds on
the achieved time-average utility under FairCG1 and FairCG2. In addition, by
giving a higher priority to fairness, FairDG ensures a stronger short-term
fairness guarantee, which holds in every round. Finally, we perform extensive
simulations to verify the effectiveness of the proposed algorithms in terms of
the time-average utility and fairness satisfaction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inference of collective Gaussian hidden Markov models. (arXiv:2107.11662v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Singh_R/0/1/0/all/0/1">Rahul Singh</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1">Yongxin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11662">
                                    <div class="article-summary-box-inner">
                                        <span>We consider inference problems for a class of continuous state collective
hidden Markov models, where the data is recorded in aggregate (collective) form
generated by a large population of individuals following the same dynamics. We
propose an aggregate inference algorithm called collective Gaussian
forward-backward algorithm, extending recently proposed Sinkhorn belief
propagation algorithm to models characterized by Gaussian densities. Our
algorithm enjoys convergence guarantee. In addition, it reduces to the standard
Kalman filter when the observations are generated by a single individual. The
efficacy of the proposed algorithm is demonstrated through multiple
experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invariance-based Multi-Clustering of Latent Space Embeddings for Equivariant Learning. (arXiv:2107.11717v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bajaj_C/0/1/0/all/0/1">Chandrajit Bajaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1">Avik Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Haoran Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11717">
                                    <div class="article-summary-box-inner">
                                        <span>Variational Autoencoders (VAEs) have been shown to be remarkably effective in
recovering model latent spaces for several computer vision tasks. However,
currently trained VAEs, for a number of reasons, seem to fall short in learning
invariant and equivariant clusters in latent space. Our work focuses on
providing solutions to this problem and presents an approach to disentangle
equivariance feature maps in a Lie group manifold by enforcing deep,
group-invariant learning. Simultaneously implementing a novel separation of
semantic and equivariant variables of the latent space representation, we
formulate a modified Evidence Lower BOund (ELBO) by using a mixture model pdf
like Gaussian mixtures for invariant cluster embeddings that allows superior
unsupervised variational clustering. Our experiments show that this model
effectively learns to disentangle the invariant and equivariant representations
with significant improvements in the learning rate and an observably superior
image recognition and canonical state reconstruction compared to the currently
best deep learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WiP Abstract : Robust Out-of-distribution Motion Detection and Localization in Autonomous CPS. (arXiv:2107.11736v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yeli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Easwaran_A/0/1/0/all/0/1">Arvind Easwaran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11736">
                                    <div class="article-summary-box-inner">
                                        <span>Highly complex deep learning models are increasingly integrated into modern
cyber-physical systems (CPS), many of which have strict safety requirements.
One problem arising from this is that deep learning lacks interpretability,
operating as a black box. The reliability of deep learning is heavily impacted
by how well the model training data represents runtime test data, especially
when the input space dimension is high as natural images. In response, we
propose a robust out-of-distribution (OOD) detection framework. Our approach
detects unusual movements from driving video in real-time by combining
classical optic flow operation with representation learning via variational
autoencoder (VAE). We also design a method to locate OOD factors in images.
Evaluation on a driving simulation data set shows that our approach is
statistically more robust than related works.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Impact of Negative Sampling on Contrastive Structured World Models. (arXiv:2107.11676v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biza_O/0/1/0/all/0/1">Ondrej Biza</a>, <a href="http://arxiv.org/find/cs/1/au:+Pol_E/0/1/0/all/0/1">Elise van der Pol</a>, <a href="http://arxiv.org/find/cs/1/au:+Kipf_T/0/1/0/all/0/1">Thomas Kipf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11676">
                                    <div class="article-summary-box-inner">
                                        <span>World models trained by contrastive learning are a compelling alternative to
autoencoder-based world models, which learn by reconstructing pixel states. In
this paper, we describe three cases where small changes in how we sample
negative states in the contrastive loss lead to drastic changes in model
performance. In previously studied Atari datasets, we show that leveraging time
step correlations can double the performance of the Contrastive Structured
World Model. We also collect a full version of the datasets to study
contrastive learning under a more diverse set of experiences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Machine Learning Based Egyptian Vehicle License Plate Recognition Systems. (arXiv:2107.11640v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shehata_M/0/1/0/all/0/1">Mohamed Shehata</a>, <a href="http://arxiv.org/find/cs/1/au:+Abou_Kreisha_M/0/1/0/all/0/1">Mohamed Taha Abou-Kreisha</a>, <a href="http://arxiv.org/find/cs/1/au:+Elnashar_H/0/1/0/all/0/1">Hany Elnashar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11640">
                                    <div class="article-summary-box-inner">
                                        <span>Automated Vehicle License Plate (VLP) detection and recognition have ended up
being a significant research issue as of late. VLP localization and recognition
are some of the most essential techniques for managing traffic using digital
techniques. In this paper, four smart systems are developed to recognize
Egyptian vehicles license plates. Two systems are based on character
recognition, which are (System1, Characters Recognition with Classical Machine
Learning) and (System2, Characters Recognition with Deep Machine Learning). The
other two systems are based on the whole plate recognition which are (System3,
Whole License Plate Recognition with Classical Machine Learning) and (System4,
Whole License Plate Recognition with Deep Machine Learning). We use object
detection algorithms, and machine learning based object recognition algorithms.
The performance of the developed systems has been tested on real images, and
the experimental results demonstrate that the best detection accuracy rate for
VLP is provided by using the deep learning method. Where the VLP detection
accuracy rate is better than the classical system by 32%. However, the best
detection accuracy rate for Vehicle License Plate Arabic Character (VLPAC) is
provided by using the classical method. Where VLPAC detection accuracy rate is
better than the deep learning-based system by 6%. Also, the results show that
deep learning is better than the classical technique used in VLP recognition
processes. Where the recognition accuracy rate is better than the classical
system by 8%. Finally, the paper output recommends a robust VLP recognition
system based on both statistical and deep machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SGD May Never Escape Saddle Points. (arXiv:2107.11774v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1">Liu Ziyin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Botao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1">Masahito Ueda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11774">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic gradient descent (SGD) has been deployed to solve highly
non-linear and non-convex machine learning problems such as the training of
deep neural networks. However, previous works on SGD often rely on highly
restrictive and unrealistic assumptions about the nature of noise in SGD. In
this work, we mathematically construct examples that defy previous
understandings of SGD. For example, our constructions show that: (1) SGD may
converge to a local maximum; (2) SGD may escape a saddle point arbitrarily
slowly; (3) SGD may prefer sharp minima over the flat ones; and (4) AMSGrad may
converge to a local maximum. Our result suggests that the noise structure of
SGD might be more important than the loss landscape in neural network training
and that future research should focus on deriving the actual noise structure in
deep learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Convolutional Network with Generalized Factorized Bilinear Aggregation. (arXiv:2107.11666v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Koniusz_P/0/1/0/all/0/1">Piotr Koniusz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11666">
                                    <div class="article-summary-box-inner">
                                        <span>Although Graph Convolutional Networks (GCNs) have demonstrated their power in
various applications, the graph convolutional layers, as the most important
component of GCN, are still using linear transformations and a simple pooling
step. In this paper, we propose a novel generalization of Factorized Bilinear
(FB) layer to model the feature interactions in GCNs. FB performs two
matrix-vector multiplications, that is, the weight matrix is multiplied with
the outer product of the vector of hidden features from both sides. However,
the FB layer suffers from the quadratic number of coefficients, overfitting and
the spurious correlations due to correlations between channels of hidden
representations that violate the i.i.d. assumption. Thus, we propose a compact
FB layer by defining a family of summarizing operators applied over the
quadratic term. We analyze proposed pooling operators and motivate their use.
Our experimental results on multiple datasets demonstrate that the GFB-GCN is
competitive with other methods for text classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Causal Inference in Heterogeneous Observational Data. (arXiv:2107.11732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1">Ruoxuan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Koenecke_A/0/1/0/all/0/1">Allison Koenecke</a>, <a href="http://arxiv.org/find/cs/1/au:+Powell_M/0/1/0/all/0/1">Michael Powell</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zhu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vogelstein_J/0/1/0/all/0/1">Joshua T. Vogelstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1">Susan Athey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11732">
                                    <div class="article-summary-box-inner">
                                        <span>Analyzing observational data from multiple sources can be useful for
increasing statistical power to detect a treatment effect; however, practical
constraints such as privacy considerations may restrict individual-level
information sharing across data sets. This paper develops federated methods
that only utilize summary-level information from heterogeneous data sets. Our
federated methods provide doubly-robust point estimates of treatment effects as
well as variance estimates. We derive the asymptotic distributions of our
federated estimators, which are shown to be asymptotically equivalent to the
corresponding estimators from the combined, individual-level data. We show that
to achieve these properties, federated methods should be adjusted based on
conditions such as whether models are correctly specified and stable across
heterogeneous data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DR2L: Surfacing Corner Cases to Robustify Autonomous Driving via Domain Randomization Reinforcement Learning. (arXiv:2107.11762v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_H/0/1/0/all/0/1">Haoyi Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jianming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1">Zheyu Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11762">
                                    <div class="article-summary-box-inner">
                                        <span>How to explore corner cases as efficiently and thoroughly as possible has
long been one of the top concerns in the context of deep reinforcement learning
(DeepRL) autonomous driving. Training with simulated data is less costly and
dangerous than utilizing real-world data, but the inconsistency of parameter
distribution and the incorrect system modeling in simulators always lead to an
inevitable Sim2real gap, which probably accounts for the underperformance in
novel, anomalous and risky cases that simulators can hardly generate. Domain
Randomization(DR) is a methodology that can bridge this gap with little or no
real-world data. Consequently, in this research, an adversarial model is put
forward to robustify DeepRL-based autonomous vehicles trained in simulation to
gradually surfacing harder events, so that the models could readily transfer to
the real world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BubbleNet: Inferring micro-bubble dynamics with semi-physics-informed deep learning. (arXiv:2105.07179v2 [physics.flu-dyn] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Zhai_H/0/1/0/all/0/1">Hanfeng Zhai</a>, <a href="http://arxiv.org/find/physics/1/au:+Hu_G/0/1/0/all/0/1">Guohui Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07179">
                                    <div class="article-summary-box-inner">
                                        <span>Micro-bubbles and bubbly flows are widely observed and applied in chemical
engineering, medicine, involves deformation, rupture, and collision of bubbles,
phase mixture, etc. We study bubble dynamics by setting up two numerical
simulation cases: bubbly flow with a single bubble and multiple bubbles, both
confined in the microchannel, with parameters corresponding to their medical
backgrounds. Both the cases have their medical background applications.
Multiphase flow simulation requires high computation accuracy due to possible
component losses that may be caused by sparse meshing during the computation.
Hence, data-driven methods can be adopted as an useful tool. Based on
physics-informed neural networks (PINNs), we propose a novel deep learning
framework BubbleNet, which entails three main parts: deep neural networks (DNN)
with sub nets for predicting different physics fields; the
semi-physics-informed part, with only the fluid continuum condition and the
pressure Poisson equation $\mathcal{P}$ encoded within; the time discretized
normalizer (TDN), an algorithm to normalize field data per time step before
training. We apply the traditional DNN and our BubbleNet to train the coarsened
simulation data and predict the physics fields of both the two bubbly flow
cases. The BubbleNets are trained for both with and without $\mathcal{P}$, from
which we conclude that the &#x27;physics-informed&#x27; part can serve as inner
supervision. Results indicate our framework can predict the physics fields more
accurately, estimating the prediction absolute errors. Our deep learning
predictions outperform traditional numerical methods computed with similar data
density meshing. The proposed network can potentially be applied to many other
engineering fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MuseMorphose: Full-Song and Fine-Grained Music Style Transfer with One Transformer VAE. (arXiv:2105.04090v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shih-Lun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04090">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers and variational autoencoders (VAE) have been extensively
employed for symbolic (e.g., MIDI) domain music generation. While the former
boast an impressive capability in modeling long sequences, the latter allow
users to willingly exert control over different parts (e.g., bars) of the music
to be generated. In this paper, we are interested in bringing the two together
to construct a single model that exhibits both strengths. The task is split
into two steps. First, we equip Transformer decoders with the ability to accept
segment-level, time-varying conditions during sequence generation.
Subsequently, we combine the developed and tested in-attention decoder with a
Transformer encoder, and train the resulting MuseMorphose model with the VAE
objective to achieve style transfer of long musical pieces, in which users can
specify musical attributes including rhythmic intensity and polyphony (i.e.,
harmonic fullness) they desire, down to the bar level. Experiments show that
MuseMorphose outperforms recurrent neural network (RNN) based baselines on
numerous widely-used metrics for style transfer tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Learning Rates for Stochastic Optimization: Two Theoretical Viewpoints. (arXiv:2107.08686v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaojie Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08686">
                                    <div class="article-summary-box-inner">
                                        <span>Generalization performance of stochastic optimization stands a central place
in learning theory. In this paper, we investigate the excess risk performance
and towards improved learning rates for two popular approaches of stochastic
optimization: empirical risk minimization (ERM) and stochastic gradient descent
(SGD). Although there exists plentiful generalization analysis of ERM and SGD
for supervised learning, current theoretical understandings of ERM and SGD
either have stronger assumptions in convex learning, e.g., strong convexity, or
show slow rates and less studied in nonconvex learning. Motivated by these
problems, we aim to provide improved rates under milder assumptions in convex
learning and derive faster rates in nonconvex learning. It is notable that our
analysis span two popular theoretical viewpoints: \emph{stability} and
\emph{uniform convergence}. Specifically, in stability regime, we present high
probability learning rates of order $\mathcal{O} (1/n)$ w.r.t. the sample size
$n$ for ERM and SGD with milder assumptions in convex learning and similar high
probability rates of order $\mathcal{O} (1/n)$ in nonconvex learning, rather
than in expectation. Furthermore, this type of learning rate is improved to
faster order $\mathcal{O} (1/n^2)$ in uniform convergence regime. To our best
knowledge, for ERM and SGD, the learning rates presented in this paper are all
state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BRECQ: Pushing the Limit of Post-Training Quantization by Block Reconstruction. (arXiv:2102.05426v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1">Ruihao Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1">Peng Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fengwei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Shi Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05426">
                                    <div class="article-summary-box-inner">
                                        <span>We study the challenging task of neural network quantization without
end-to-end retraining, called Post-training Quantization (PTQ). PTQ usually
requires a small subset of training data but produces less powerful quantized
models than Quantization-Aware Training (QAT). In this work, we propose a novel
PTQ framework, dubbed BRECQ, which pushes the limits of bitwidth in PTQ down to
INT2 for the first time. BRECQ leverages the basic building blocks in neural
networks and reconstructs them one-by-one. In a comprehensive theoretical study
of the second-order error, we show that BRECQ achieves a good balance between
cross-layer dependency and generalization error. To further employ the power of
quantization, the mixed precision technique is incorporated in our framework by
approximating the inter-layer and intra-layer sensitivity. Extensive
experiments on various handcrafted and searched neural architectures are
conducted for both image classification and object detection tasks. And for the
first time we prove that, without bells and whistles, PTQ can attain 4-bit
ResNet and MobileNetV2 comparable with QAT and enjoy 240 times faster
production of quantized models. Codes are available at
https://github.com/yhhhli/BRECQ.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Repulsive Deep Ensembles are Bayesian. (arXiv:2106.11642v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DAngelo_F/0/1/0/all/0/1">Francesco D&#x27;Angelo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fortuin_V/0/1/0/all/0/1">Vincent Fortuin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11642">
                                    <div class="article-summary-box-inner">
                                        <span>Deep ensembles have recently gained popularity in the deep learning community
for their conceptual simplicity and efficiency. However, maintaining functional
diversity between ensemble members that are independently trained with gradient
descent is challenging. This can lead to pathologies when adding more ensemble
members, such as a saturation of the ensemble performance, which converges to
the performance of a single model. Moreover, this does not only affect the
quality of its predictions, but even more so the uncertainty estimates of the
ensemble, and thus its performance on out-of-distribution data. We hypothesize
that this limitation can be overcome by discouraging different ensemble members
from collapsing to the same function. To this end, we introduce a kernelized
repulsive term in the update rule of the deep ensembles. We show that this
simple modification not only enforces and maintains diversity among the members
but, even more importantly, transforms the maximum a posteriori inference into
proper Bayesian inference. Namely, we show that the training dynamics of our
proposed repulsive ensembles follow a Wasserstein gradient flow of the KL
divergence with the true posterior. We study repulsive terms in weight and
function space and empirically compare their performance to standard ensembles
and Bayesian baselines on synthetic and real-world prediction tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Investigating Bi-Level Optimization for Learning and Vision from a Unified Perspective: A Survey and Beyond. (arXiv:2101.11517v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1">Risheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jiaxin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1">Deyu Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhouchen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11517">
                                    <div class="article-summary-box-inner">
                                        <span>Bi-Level Optimization (BLO) is originated from the area of economic game
theory and then introduced into the optimization community. BLO is able to
handle problems with a hierarchical structure, involving two levels of
optimization tasks, where one task is nested inside the other. In machine
learning and computer vision fields, despite the different motivations and
mechanisms, a lot of complex problems, such as hyper-parameter optimization,
multi-task and meta-learning, neural architecture search, adversarial learning
and deep reinforcement learning, actually all contain a series of closely
related subproblms. In this paper, we first uniformly express these complex
learning and vision problems from the perspective of BLO. Then we construct a
best-response-based single-level reformulation and establish a unified
algorithmic framework to understand and formulate mainstream gradient-based BLO
methodologies, covering aspects ranging from fundamental automatic
differentiation schemes to various accelerations, simplifications, extensions
and their convergence and complexity properties. Last but not least, we discuss
the potentials of our unified BLO framework for designing new algorithms and
point out some promising directions for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Traversability Estimator for Mobile Robots in Unstructured Environments. (arXiv:2105.10937v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Visca_M/0/1/0/all/0/1">Marco Visca</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuutti_S/0/1/0/all/0/1">Sampo Kuutti</a>, <a href="http://arxiv.org/find/cs/1/au:+Powell_R/0/1/0/all/0/1">Roger Powell</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fallah_S/0/1/0/all/0/1">Saber Fallah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10937">
                                    <div class="article-summary-box-inner">
                                        <span>Terrain traversability analysis plays a major role in ensuring safe robotic
navigation in unstructured environments. However, real-time constraints
frequently limit the accuracy of online tests especially in scenarios where
realistic robot-terrain interactions are complex to model. In this context, we
propose a deep learning framework trained in an end-to-end fashion from
elevation maps and trajectories to estimate the occurrence of failure events.
The network is first trained and tested in simulation over synthetic maps
generated by the OpenSimplex algorithm. The prediction performance of the Deep
Learning framework is illustrated by being able to retain over 94% recall of
the original simulator at 30% of the computational time. Finally, the network
is transferred and tested on real elevation maps collected by the SEEKER
consortium during the Martian rover test trial in the Atacama desert in Chile.
We show that transferring and fine-tuning of an application-independent
pre-trained model retains better performance than training uniquely on scarcely
available real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Multi-Agent Reinforcement Learning for Task Offloading Under Uncertainty. (arXiv:2107.08114v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yuanchao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feriani_A/0/1/0/all/0/1">Amal Feriani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hossain_E/0/1/0/all/0/1">Ekram Hossain</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08114">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-Agent Reinforcement Learning (MARL) is a challenging subarea of
Reinforcement Learning due to the non-stationarity of the environments and the
large dimensionality of the combined action space. Deep MARL algorithms have
been applied to solve different task offloading problems. However, in
real-world applications, information required by the agents (i.e. rewards and
states) are subject to noise and alterations. The stability and the robustness
of deep MARL to practical challenges is still an open research problem. In this
work, we apply state-of-the art MARL algorithms to solve task offloading with
reward uncertainty. We show that perturbations in the reward signal can induce
decrease in the performance compared to learning with perfect rewards. We
expect this paper to stimulate more research in studying and addressing the
practical challenges of deploying deep MARL solutions in wireless
communications systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Approximation Rate of ReLU Networks in terms of Width and Depth. (arXiv:2103.00502v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Zuowei Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haizhao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shijun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00502">
                                    <div class="article-summary-box-inner">
                                        <span>This paper concentrates on the approximation power of deep feed-forward
neural networks in terms of width and depth. It is proved by construction that
ReLU networks with width $\mathcal{O}\big(\max\{d\lfloor N^{1/d}\rfloor,\,
N+2\}\big)$ and depth $\mathcal{O}(L)$ can approximate a H\&quot;older continuous
function on $[0,1]^d$ with an approximation rate
$\mathcal{O}\big(\lambda\sqrt{d} (N^2L^2\ln N)^{-\alpha/d}\big)$, where
$\alpha\in (0,1]$ and $\lambda&gt;0$ are H\&quot;older order and constant,
respectively. Such a rate is optimal up to a constant in terms of width and
depth separately, while existing results are only nearly optimal without the
logarithmic factor in the approximation rate. More generally, for an arbitrary
continuous function $f$ on $[0,1]^d$, the approximation rate becomes
$\mathcal{O}\big(\,\sqrt{d}\,\omega_f\big( (N^2L^2\ln N)^{-1/d}\big)\,\big)$,
where $\omega_f(\cdot)$ is the modulus of continuity. We also extend our
analysis to any continuous function $f$ on a bounded set. Particularly, if ReLU
networks with depth $31$ and width $\mathcal{O}(N)$ are used to approximate
one-dimensional Lipschitz continuous functions on $[0,1]$ with a Lipschitz
constant $\lambda&gt;0$, the approximation rate in terms of the total number of
parameters, $W&#x3D;\mathcal{O}(N^2)$, becomes $\mathcal{O}(\tfrac{\lambda}{W\ln
W})$, which has not been discovered in the literature for fixed-depth ReLU
networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proceedings of ICML 2021 Workshop on Theoretic Foundation, Criticism, and Application Trend of Explainable AI. (arXiv:2107.08821v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Quanshi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1">Tian Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1">Lixin Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhanxing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Ying Nian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jie Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08821">
                                    <div class="article-summary-box-inner">
                                        <span>This is the Proceedings of ICML 2021 Workshop on Theoretic Foundation,
Criticism, and Application Trend of Explainable AI. Deep neural networks (DNNs)
have undoubtedly brought great success to a wide range of applications in
computer vision, computational linguistics, and AI. However, foundational
principles underlying the DNNs&#x27; success and their resilience to adversarial
attacks are still largely missing. Interpreting and theorizing the internal
mechanisms of DNNs becomes a compelling yet controversial topic. This workshop
pays a special interest in theoretic foundations, limitations, and new
application trends in the scope of XAI. These issues reflect new bottlenecks in
the future development of XAI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dive into Deep Learning. (arXiv:2106.11342v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Aston Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Mu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1">Alexander J. Smola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.11342">
                                    <div class="article-summary-box-inner">
                                        <span>This open-source book represents our attempt to make deep learning
approachable, teaching readers the concepts, the context, and the code. The
entire book is drafted in Jupyter notebooks, seamlessly integrating exposition
figures, math, and interactive examples with self-contained code. Our goal is
to offer a resource that could (i) be freely available for everyone; (ii) offer
sufficient technical depth to provide a starting point on the path to actually
becoming an applied machine learning scientist; (iii) include runnable code,
showing readers how to solve problems in practice; (iv) allow for rapid
updates, both by us and also by the community at large; (v) be complemented by
a forum for interactive discussion of technical details and to answer
questions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generalized Lottery Ticket Hypothesis. (arXiv:2107.06825v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alabdulmohsin_I/0/1/0/all/0/1">Ibrahim Alabdulmohsin</a>, <a href="http://arxiv.org/find/cs/1/au:+Markeeva_L/0/1/0/all/0/1">Larisa Markeeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Keysers_D/0/1/0/all/0/1">Daniel Keysers</a>, <a href="http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1">Ilya Tolstikhin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.06825">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a generalization to the lottery ticket hypothesis in which the
notion of &quot;sparsity&quot; is relaxed by choosing an arbitrary basis in the space of
parameters. We present evidence that the original results reported for the
canonical basis continue to hold in this broader setting. We describe how
structured pruning methods, including pruning units or factorizing
fully-connected layers into products of low-rank matrices, can be cast as
particular instances of this &quot;generalized&quot; lottery ticket hypothesis. The
investigations reported here are preliminary and are provided to encourage
further research along this direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CSIT-Free Model Aggregation for Federated Edge Learning via Reconfigurable Intelligent Surface. (arXiv:2102.10749v3 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1">Xiaojun Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Ying-Jun Angela Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10749">
                                    <div class="article-summary-box-inner">
                                        <span>We study over-the-air model aggregation in federated edge learning (FEEL)
systems, where channel state information at the transmitters (CSIT) is assumed
to be unavailable. We leverage the reconfigurable intelligent surface (RIS)
technology to align the cascaded channel coefficients for CSIT-free model
aggregation. To this end, we jointly optimize the RIS and the receiver by
minimizing the aggregation error under the channel alignment constraint. We
then develop a difference-of-convex algorithm for the resulting non-convex
optimization. Numerical experiments on image classification show that the
proposed method is able to achieve a similar learning accuracy as the
state-of-the-art CSIT-based solution, demonstrating the efficiency of our
approach in combating the lack of CSIT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Canonical Correlation Alignment for Sensor Signals. (arXiv:2106.03637v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schutz_N/0/1/0/all/0/1">Narayan Sch&#xfc;tz</a>, <a href="http://arxiv.org/find/cs/1/au:+Botros_A/0/1/0/all/0/1">Angela Botros</a>, <a href="http://arxiv.org/find/cs/1/au:+Single_M/0/1/0/all/0/1">Michael Single</a>, <a href="http://arxiv.org/find/cs/1/au:+Naef_A/0/1/0/all/0/1">Aileen C. Naef</a>, <a href="http://arxiv.org/find/cs/1/au:+Buluschek_P/0/1/0/all/0/1">Philipp Buluschek</a>, <a href="http://arxiv.org/find/cs/1/au:+Nef_T/0/1/0/all/0/1">Tobias Nef</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.03637">
                                    <div class="article-summary-box-inner">
                                        <span>Sensor technologies are becoming increasingly prevalent in the biomedical
field, with applications ranging from telemonitoring of people at risk, to
using sensor derived information as objective endpoints in clinical trials. To
fully utilize sensor information, signals from distinct sensors often have to
be temporally aligned. However, due to imperfect oscillators and significant
noise, commonly encountered with biomedical signals, temporal alignment of raw
signals is an all but trivial problem, with, to-date, no generally applicable
solution. In this work, we present Deep Canonical Correlation Alignment (DCCA),
a novel, generally applicable solution for the temporal alignment of raw
(biomedical) sensor signals. DCCA allows practitioners to directly align raw
signals, from distinct sensors, without requiring deep domain knowledge. On a
selection of artificial and real datasets, we demonstrate the performance and
utility of DCCA under a variety of conditions. We compare the DCCA algorithm to
other warping based methods, DCCA outperforms dynamic time warping and cross
correlation based methods by an order of magnitude in terms of alignment error.
DCCA performs especially well on almost periodic biomedical signals such as
heart-beats and breathing patterns. In comparison to existing approaches, that
are not tailored towards raw sensor data, DCCA is not only fast enough to work
on signals with billions of data points but also provides automatic filtering
and transformation functionalities, allowing it to deal with very noisy and
even morphologically distinct signals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Gradient Descent Ascent for Nonconvex-Concave Minimax Problems. (arXiv:1906.00331v7 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1">Tianyi Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Chi Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1906.00331">
                                    <div class="article-summary-box-inner">
                                        <span>We consider nonconvex-concave minimax problems, $\min_{\mathbf{x}}
\max_{\mathbf{y} \in \mathcal{Y}} f(\mathbf{x}, \mathbf{y})$, where $f$ is
nonconvex in $\mathbf{x}$ but concave in $\mathbf{y}$ and $\mathcal{Y}$ is a
convex and bounded set. One of the most popular algorithms for solving this
problem is the celebrated gradient descent ascent (GDA) algorithm, which has
been widely used in machine learning, control theory and economics. Despite the
extensive convergence results for the convex-concave setting, GDA with equal
stepsize can converge to limit cycles or even diverge in a general setting. In
this paper, we present the complexity results on two-time-scale GDA for solving
nonconvex-concave minimax problems, showing that the algorithm can find a
stationary point of the function $\Phi(\cdot) :&#x3D; \max_{\mathbf{y} \in
\mathcal{Y}} f(\cdot, \mathbf{y})$ efficiently. To the best our knowledge, this
is the first nonasymptotic analysis for two-time-scale GDA in this setting,
shedding light on its superior practical performance in training generative
adversarial networks (GANs) and other real applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anomalous diffusion dynamics of learning in deep neural networks. (arXiv:2009.10588v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guozhang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qu_C/0/1/0/all/0/1">Cheng Kevin Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_P/0/1/0/all/0/1">Pulin Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10588">
                                    <div class="article-summary-box-inner">
                                        <span>Learning in deep neural networks (DNNs) is implemented through minimizing a
highly non-convex loss function, typically by a stochastic gradient descent
(SGD) method. This learning process can effectively find good wide minima
without being trapped in poor local ones. We present a novel account of how
such effective deep learning emerges through the interactions of the SGD and
the geometrical structure of the loss landscape. Rather than being a normal
diffusion process (i.e. Brownian motion) as often assumed, we find that the SGD
exhibits rich, complex dynamics when navigating through the loss landscape;
initially, the SGD exhibits anomalous superdiffusion, which attenuates
gradually and changes to subdiffusion at long times when the solution is
reached. Such learning dynamics happen ubiquitously in different DNNs such as
ResNet and VGG-like networks and are insensitive to batch size and learning
rate. The anomalous superdiffusion process during the initial learning phase
indicates that the motion of SGD along the loss landscape possesses
intermittent, big jumps; this non-equilibrium property enables the SGD to
escape from sharp local minima. By adapting the methods developed for studying
energy landscapes in complex physical systems, we find that such superdiffusive
learning dynamics are due to the interactions of the SGD and the fractal-like
structure of the loss landscape. We further develop a simple model to
demonstrate the mechanistic role of the fractal loss landscape in enabling the
SGD to effectively find global minima. Our results thus reveal the
effectiveness of deep learning from a novel perspective and have implications
for designing efficient deep neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On generalization in moment-based domain adaptation. (arXiv:2002.08260v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zellinger_W/0/1/0/all/0/1">Werner Zellinger</a>, <a href="http://arxiv.org/find/stat/1/au:+Moser_B/0/1/0/all/0/1">Bernhard A Moser</a>, <a href="http://arxiv.org/find/stat/1/au:+Saminger_Platz_S/0/1/0/all/0/1">Susanne Saminger-Platz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.08260">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation algorithms are designed to minimize the misclassification
risk of a discriminative model for a target domain with little training data by
adapting a model from a source domain with a large amount of training data.
Standard approaches measure the adaptation discrepancy based on distance
measures between the empirical probability distributions in the source and
target domain. In this setting, we address the problem of deriving
generalization bounds under practice-oriented general conditions on the
underlying probability distributions. As a result, we obtain generalization
bounds for domain adaptation based on finitely many moments and smoothness
conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Vehicle-Rear: A New Dataset to Explore Feature Fusion for Vehicle Identification Using Convolutional Neural Networks. (arXiv:1911.05541v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oliveira_I/0/1/0/all/0/1">Icaro O. de Oliveira</a>, <a href="http://arxiv.org/find/cs/1/au:+Laroca_R/0/1/0/all/0/1">Rayson Laroca</a>, <a href="http://arxiv.org/find/cs/1/au:+Menotti_D/0/1/0/all/0/1">David Menotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Fonseca_K/0/1/0/all/0/1">Keiko V. O. Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Minetto_R/0/1/0/all/0/1">Rodrigo Minetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.05541">
                                    <div class="article-summary-box-inner">
                                        <span>This work addresses the problem of vehicle identification through
non-overlapping cameras. As our main contribution, we introduce a novel dataset
for vehicle identification, called Vehicle-Rear, that contains more than three
hours of high-resolution videos, with accurate information about the make,
model, color and year of nearly 3,000 vehicles, in addition to the position and
identification of their license plates. To explore our dataset we design a
two-stream CNN that simultaneously uses two of the most distinctive and
persistent features available: the vehicle&#x27;s appearance and its license plate.
This is an attempt to tackle a major problem: false alarms caused by vehicles
with similar designs or by very close license plate identifiers. In the first
network stream, shape similarities are identified by a Siamese CNN that uses a
pair of low-resolution vehicle patches recorded by two different cameras. In
the second stream, we use a CNN for OCR to extract textual information,
confidence scores, and string similarities from a pair of high-resolution
license plate patches. Then, features from both streams are merged by a
sequence of fully connected layers for decision. In our experiments, we
compared the two-stream network against several well-known CNN architectures
using single or multiple vehicle features. The architectures, trained models,
and dataset are publicly available at https://github.com/icarofua/vehicle-rear.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Black-Box Diagnosis and Calibration on GAN Intra-Mode Collapse: A Pilot Study. (arXiv:2107.12202v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhenyu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhaowen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Ye Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1">Hailin Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12202">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GANs) nowadays are capable of producing
images of incredible realism. One concern raised is whether the
state-of-the-art GAN&#x27;s learned distribution still suffers from mode collapse,
and what to do if so. Existing diversity tests of samples from GANs are usually
conducted qualitatively on a small scale, and/or depends on the access to
original training data as well as the trained model parameters. This paper
explores to diagnose GAN intra-mode collapse and calibrate that, in a novel
black-box setting: no access to training data, nor the trained model
parameters, is assumed. The new setting is practically demanded, yet rarely
explored and significantly more challenging. As a first stab, we devise a set
of statistical tools based on sampling, that can visualize, quantify, and
rectify intra-mode collapse. We demonstrate the effectiveness of our proposed
diagnosis and calibration techniques, via extensive simulations and
experiments, on unconditional GAN image generation (e.g., face and vehicle).
Our study reveals that the intra-mode collapse is still a prevailing problem in
state-of-the-art GANs and the mode collapse is diagnosable and calibratable in
black-box settings. Our codes are available at:
https://github.com/VITA-Group/BlackBoxGANCollapse.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Thought Flow Nets: From Single Predictions to Trains of Model Thought. (arXiv:2107.12220v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schuff_H/0/1/0/all/0/1">Hendrik Schuff</a>, <a href="http://arxiv.org/find/cs/1/au:+Adel_H/0/1/0/all/0/1">Heike Adel</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_N/0/1/0/all/0/1">Ngoc Thang Vu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12220">
                                    <div class="article-summary-box-inner">
                                        <span>When humans solve complex problems, they rarely come up with a decision
right-away. Instead, they start with an intuitive decision, reflect upon it,
spot mistakes, resolve contradictions and jump between different hypotheses.
Thus, they create a sequence of ideas and follow a train of thought that
ultimately reaches a conclusive decision. Contrary to this, today&#x27;s neural
classification models are mostly trained to map an input to one single and
fixed output. In this paper, we investigate how we can give models the
opportunity of a second, third and $k$-th thought. We take inspiration from
Hegel&#x27;s dialectics and propose a method that turns an existing classifier&#x27;s
class prediction (such as the image class forest) into a sequence of
predictions (such as forest $\rightarrow$ tree $\rightarrow$ mushroom).
Concretely, we propose a correction module that is trained to estimate the
model&#x27;s correctness as well as an iterative prediction update based on the
prediction&#x27;s gradient. Our approach results in a dynamic system over class
probability distributions $\unicode{x2014}$ the thought flow. We evaluate our
method on diverse datasets and tasks from computer vision and natural language
processing. We observe surprisingly complex but intuitive behavior and
demonstrate that our method (i) can correct misclassifications, (ii)
strengthens model performance, (iii) is robust to high levels of adversarial
attacks, (iv) can increase accuracy up to 4% in a label-distribution-shift
setting and (iv) provides a tool for model interpretability that uncovers model
knowledge which otherwise remains invisible in a single distribution
prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preliminary Steps Towards Federated Sentiment Classification. (arXiv:2107.11956v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xin-Chun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_Y/0/1/0/all/0/1">Yunfeng Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bingshuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shaoming Song</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11956">
                                    <div class="article-summary-box-inner">
                                        <span>Automatically mining sentiment tendency contained in natural language is a
fundamental research to some artificial intelligent applications, where
solutions alternate with challenges. Transfer learning and multi-task learning
techniques have been leveraged to mitigate the supervision sparsity and
collaborate multiple heterogeneous domains correspondingly. Recent years, the
sensitive nature of users&#x27; private data raises another challenge for sentiment
classification, i.e., data privacy protection. In this paper, we resort to
federated learning for multiple domain sentiment classification under the
constraint that the corpora must be stored on decentralized devices. In view of
the heterogeneous semantics across multiple parties and the peculiarities of
word embedding, we pertinently provide corresponding solutions. First, we
propose a Knowledge Transfer Enhanced Private-Shared (KTEPS) framework for
better model aggregation and personalization in federated sentiment
classification. Second, we propose KTEPS$^\star$ with the consideration of the
rich semantic and huge embedding size properties of word vectors, utilizing
Projection-based Dimension Reduction (PDR) methods for privacy protection and
efficient transmission simultaneously. We propose two federated sentiment
classification scenes based on public benchmarks, and verify the superiorities
of our proposed methods with abundant experimental investigations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Deep Learning Techniques and Inferential Speech Statistics for AI Synthesised Speech Recognition. (arXiv:2107.11412v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Arun Kumar Singh</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Priyanka Singh</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Nathwani_K/0/1/0/all/0/1">Karan Nathwani</a> (1) ((1) Indian Institute of Technology Jammu, (2) Dhirubhai Ambani Institute of Information and Communication Technology)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11412">
                                    <div class="article-summary-box-inner">
                                        <span>The recent developments in technology have re-warded us with amazing audio
synthesis models like TACOTRON and WAVENETS. On the other side, it poses
greater threats such as speech clones and deep fakes, that may go undetected.
To tackle these alarming situations, there is an urgent need to propose models
that can help discriminate a synthesized speech from an actual human speech and
also identify the source of such a synthesis. Here, we propose a model based on
Convolutional Neural Network (CNN) and Bidirectional Recurrent Neural Network
(BiRNN) that helps to achieve both the aforementioned objectives. The temporal
dependencies present in AI synthesized speech are exploited using Bidirectional
RNN and CNN. The model outperforms the state-of-the-art approaches by
classifying the AI synthesized audio from real human speech with an error rate
of 1.9% and detecting the underlying architecture with an accuracy of 97%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Device Scheduling and Update Aggregation Policies for Asynchronous Federated Learning. (arXiv:2107.11415v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_C/0/1/0/all/0/1">Chung-Hsuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zheng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Larsson_E/0/1/0/all/0/1">Erik G. Larsson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11415">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) is a newly emerged decentralized machine learning
(ML) framework that combines on-device local training with server-based model
synchronization to train a centralized ML model over distributed nodes. In this
paper, we propose an asynchronous FL framework with periodic aggregation to
eliminate the straggler issue in FL systems. For the proposed model, we
investigate several device scheduling and update aggregation policies and
compare their performances when the devices have heterogeneous computation
capabilities and training data distributions. From the simulation results, we
conclude that the scheduling and aggregation design for asynchronous FL can be
rather different from the synchronous case. For example, a norm-based
significance-aware scheduling policy might not be efficient in an asynchronous
FL setting, and an appropriate &quot;age-aware&quot; weighting design for the model
aggregation can greatly improve the learning performance of such systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Realistic Simulation Framework for Learning with Label Noise. (arXiv:2107.11413v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_K/0/1/0/all/0/1">Keren Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Masotto_X/0/1/0/all/0/1">Xander Masotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Bachani_V/0/1/0/all/0/1">Vandana Bachani</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1">Balaji Lakshminarayanan</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikodem_J/0/1/0/all/0/1">Jack Nikodem</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1">Dong Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11413">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a simulation framework for generating realistic instance-dependent
noisy labels via a pseudo-labeling paradigm. We show that this framework
generates synthetic noisy labels that exhibit important characteristics of the
label noise in practical settings via comparison with the CIFAR10-H dataset.
Equipped with controllable label noise, we study the negative impact of noisy
labels across a few realistic settings to understand when label noise is more
problematic. We also benchmark several existing algorithms for learning with
noisy labels and compare their behavior on our synthetic datasets and on the
datasets with independent random label noise. Additionally, with the
availability of annotator information from our simulation framework, we propose
a new technique, Label Quality Model (LQM), that leverages annotator features
to predict and correct against noisy labels. We show that by adding LQM as a
label correction step before applying existing noisy label techniques, we can
further improve the models&#x27; performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TargetNet: Functional microRNA Target Prediction with Deep Neural Networks. (arXiv:2107.11381v1 [q-bio.GN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Min_S/0/1/0/all/0/1">Seonwoo Min</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lee_B/0/1/0/all/0/1">Byunghan Lee</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Yoon_S/0/1/0/all/0/1">Sungroh Yoon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11381">
                                    <div class="article-summary-box-inner">
                                        <span>MicroRNAs (miRNAs) play pivotal roles in gene expression regulation by
binding to target sites of messenger RNAs (mRNAs). While identifying functional
targets of miRNAs is of utmost importance, their prediction remains a great
challenge. Previous computational algorithms have major limitations. They use
conservative candidate target site (CTS) selection criteria mainly focusing on
canonical site types, rely on laborious and time-consuming manual feature
extraction, and do not fully capitalize on the information underlying miRNA-CTS
interactions. In this paper, we introduce TargetNet, a novel deep
learning-based algorithm for functional miRNA target prediction. To address the
limitations of previous approaches, TargetNet has three key components: (1)
relaxed CTS selection criteria accommodating irregularities in the seed region,
(2) a novel miRNA-CTS sequence encoding scheme incorporating extended seed
region alignments, and (3) a deep residual network-based prediction model. The
proposed model was trained with miRNA-CTS pair datasets and evaluated with
miRNA-mRNA pair datasets. TargetNet advances the previous state-of-the-art
algorithms used in functional miRNA target classification. Furthermore, it
demonstrates great potential for distinguishing high-functional miRNA targets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Explainability: A Tutorial on Gradient-Based Attribution Methods for Deep Neural Networks. (arXiv:2107.11400v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nielsen_I/0/1/0/all/0/1">Ian E. Nielsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rasool_G/0/1/0/all/0/1">Ghulam Rasool</a>, <a href="http://arxiv.org/find/cs/1/au:+Dera_D/0/1/0/all/0/1">Dimah Dera</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouaynaya_N/0/1/0/all/0/1">Nidhal Bouaynaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_R/0/1/0/all/0/1">Ravi P. Ramachandran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11400">
                                    <div class="article-summary-box-inner">
                                        <span>With the rise of deep neural networks, the challenge of explaining the
predictions of these networks has become increasingly recognized. While many
methods for explaining the decisions of deep neural networks exist, there is
currently no consensus on how to evaluate them. On the other hand, robustness
is a popular topic for deep learning research; however, it is hardly talked
about in explainability until very recently. In this tutorial paper, we start
by presenting gradient-based interpretability methods. These techniques use
gradient signals to assign the burden of the decision on the input features.
Later, we discuss how gradient-based methods can be evaluated for their
robustness and the role that adversarial robustness plays in having meaningful
explanations. We also discuss the limitations of gradient-based methods.
Finally, we present the best practices and attributes that should be examined
before choosing an explainability method. We conclude with the future
directions for research in the area at the convergence of robustness and
explainability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Content-based Music Recommendation: Evolution, State of the Art, and Challenges. (arXiv:2107.11803v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deldjoo_Y/0/1/0/all/0/1">Yashar Deldjoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Schedl_M/0/1/0/all/0/1">Markus Schedl</a>, <a href="http://arxiv.org/find/cs/1/au:+Knees_P/0/1/0/all/0/1">Peter Knees</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11803">
                                    <div class="article-summary-box-inner">
                                        <span>The music domain is among the most important ones for adopting recommender
systems technology. In contrast to most other recommendation domains, which
predominantly rely on collaborative filtering (CF) techniques, music
recommenders have traditionally embraced content-based (CB) approaches. In the
past years, music recommendation models that leverage collaborative and content
data -- which we refer to as content-driven models -- have been replacing pure
CF or CB models.

In this survey, we review 47 articles on content-driven music recommendation.
Based on a thorough literature analysis, we first propose an onion model
comprising five layers, each of which corresponds to a category of music
content we identified: signal, embedded metadata, expert-generated content,
user-generated content, and derivative content. We provide a detailed
characterization of each category along several dimensions. Second, we identify
six overarching challenges, according to which we organize our main discussion:
increasing recommendation diversity and novelty, providing transparency and
explanations, accomplishing context-awareness, recommending sequences of music,
improving scalability and efficiency, and alleviating cold start. Each article
addressing one or more of these challenges is categorized according to the
content layers of our onion model, the article&#x27;s goal(s), and main
methodological choices. Furthermore, articles are discussed in temporal order
to shed light on the evolution of content-driven music recommendation
strategies. Finally, we provide our personal selection of the persisting grand
challenges, which are still waiting to be solved in future research endeavors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Action be Imitated? Learn to Reconstruct and Transfer Human Dynamics from Videos. (arXiv:2107.11756v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yuqian Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yu-Gang Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11756">
                                    <div class="article-summary-box-inner">
                                        <span>Given a video demonstration, can we imitate the action contained in this
video? In this paper, we introduce a novel task, dubbed mesh-based action
imitation. The goal of this task is to enable an arbitrary target human mesh to
perform the same action shown on the video demonstration. To achieve this, a
novel Mesh-based Video Action Imitation (M-VAI) method is proposed by us. M-VAI
first learns to reconstruct the meshes from the given source image frames, then
the initial recovered mesh sequence is fed into mesh2mesh, a mesh sequence
smooth module proposed by us, to improve the temporal consistency. Finally, we
imitate the actions by transferring the pose from the constructed human body to
our target identity mesh. High-quality and detailed human body meshes can be
generated by using our M-VAI. Extensive experiments demonstrate the feasibility
of our task and the effectiveness of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MuseMorphose: Full-Song and Fine-Grained Music Style Transfer with One Transformer VAE. (arXiv:2105.04090v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shih-Lun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi-Hsuan Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04090">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers and variational autoencoders (VAE) have been extensively
employed for symbolic (e.g., MIDI) domain music generation. While the former
boast an impressive capability in modeling long sequences, the latter allow
users to willingly exert control over different parts (e.g., bars) of the music
to be generated. In this paper, we are interested in bringing the two together
to construct a single model that exhibits both strengths. The task is split
into two steps. First, we equip Transformer decoders with the ability to accept
segment-level, time-varying conditions during sequence generation.
Subsequently, we combine the developed and tested in-attention decoder with a
Transformer encoder, and train the resulting MuseMorphose model with the VAE
objective to achieve style transfer of long musical pieces, in which users can
specify musical attributes including rhythmic intensity and polyphony (i.e.,
harmonic fullness) they desire, down to the bar level. Experiments show that
MuseMorphose outperforms recurrent neural network (RNN) based baselines on
numerous widely-used metrics for style transfer tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PARIMA: Viewport Adaptive 360-Degree Video Streaming. (arXiv:2103.00981v2 [cs.MM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chopra_L/0/1/0/all/0/1">Lovish Chopra</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Sarthak Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Mondal_A/0/1/0/all/0/1">Abhijit Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1">Sandip Chakraborty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00981">
                                    <div class="article-summary-box-inner">
                                        <span>With increasing advancements in technologies for capturing 360{\deg} videos,
advances in streaming such videos have become a popular research topic.
However, streaming 360{\deg} videos require high bandwidth, thus escalating the
need for developing optimized streaming algorithms. Researchers have proposed
various methods to tackle the problem, considering the network bandwidth or
attempt to predict future viewports in advance. However, most of the existing
works either (1) do not consider video contents to predict user viewport, or
(2) do not adapt to user preferences dynamically, or (3) require a lot of
training data for new videos, thus making them potentially unfit for video
streaming purposes. We develop PARIMA, a fast and efficient online viewport
prediction model that uses past viewports of users along with the trajectories
of prime objects as a representative of video content to predict future
viewports. We claim that the head movement of a user majorly depends upon the
trajectories of the prime objects in the video. We employ a pyramid-based
bitrate allocation scheme and perform a comprehensive evaluation of the
performance of PARIMA. In our evaluation, we show that PARIMA outperforms
state-of-the-art approaches, improving the Quality of Experience by over 30\%
while maintaining a short response time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-GGM: Graph Generative Modeling for Out-of-Distribution Generalization in Visual Question Answering. (arXiv:2107.11576v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jingjing Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yifan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Nan_Z/0/1/0/all/0/1">Zhixiong Nan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1">Nanning Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11576">
                                    <div class="article-summary-box-inner">
                                        <span>Encouraging progress has been made towards Visual Question Answering (VQA) in
recent years, but it is still challenging to enable VQA models to adaptively
generalize to out-of-distribution (OOD) samples. Intuitively, recompositions of
existing visual concepts (i.e., attributes and objects) can generate unseen
compositions in the training set, which will promote VQA models to generalize
to OOD samples. In this paper, we formulate OOD generalization in VQA as a
compositional generalization problem and propose a graph generative
modeling-based training scheme (X-GGM) to handle the problem implicitly. X-GGM
leverages graph generative modeling to iteratively generate a relation matrix
and node representations for the predefined graph that utilizes
attribute-object pairs as nodes. Furthermore, to alleviate the unstable
training issue in graph generative modeling, we propose a gradient distribution
consistency loss to constrain the data distribution with adversarial
perturbations and the generated distribution. The baseline VQA model (LXMERT)
trained with the X-GGM scheme achieves state-of-the-art OOD performance on two
standard VQA OOD benchmarks, i.e., VQA-CP v2 and GQA-OOD. Extensive ablation
studies demonstrate the effectiveness of X-GGM components.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Language Model for Efficient Linguistic Steganalysis: An Empirical Study. (arXiv:2107.12168v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yi_B/0/1/0/all/0/1">Biao Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hanzhou Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_G/0/1/0/all/0/1">Guorui Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinpeng Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.12168">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in linguistic steganalysis have successively applied CNNs,
RNNs, GNNs and other deep learning models for detecting secret information in
generative texts. These methods tend to seek stronger feature extractors to
achieve higher steganalysis effects. However, we have found through experiments
that there actually exists significant difference between automatically
generated steganographic texts and carrier texts in terms of the conditional
probability distribution of individual words. Such kind of statistical
difference can be naturally captured by the language model used for generating
steganographic texts, which drives us to give the classifier a priori knowledge
of the language model to enhance the steganalysis ability. To this end, we
present two methods to efficient linguistic steganalysis in this paper. One is
to pre-train a language model based on RNN, and the other is to pre-train a
sequence autoencoder. Experimental results show that the two methods have
different degrees of performance improvement when compared to the randomly
initialized RNN classifier, and the convergence speed is significantly
accelerated. Moreover, our methods have achieved the best detection results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Deep Learning Techniques and Inferential Speech Statistics for AI Synthesised Speech Recognition. (arXiv:2107.11412v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Arun Kumar Singh</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1">Priyanka Singh</a> (2), <a href="http://arxiv.org/find/cs/1/au:+Nathwani_K/0/1/0/all/0/1">Karan Nathwani</a> (1) ((1) Indian Institute of Technology Jammu, (2) Dhirubhai Ambani Institute of Information and Communication Technology)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11412">
                                    <div class="article-summary-box-inner">
                                        <span>The recent developments in technology have re-warded us with amazing audio
synthesis models like TACOTRON and WAVENETS. On the other side, it poses
greater threats such as speech clones and deep fakes, that may go undetected.
To tackle these alarming situations, there is an urgent need to propose models
that can help discriminate a synthesized speech from an actual human speech and
also identify the source of such a synthesis. Here, we propose a model based on
Convolutional Neural Network (CNN) and Bidirectional Recurrent Neural Network
(BiRNN) that helps to achieve both the aforementioned objectives. The temporal
dependencies present in AI synthesized speech are exploited using Bidirectional
RNN and CNN. The model outperforms the state-of-the-art approaches by
classifying the AI synthesized audio from real human speech with an error rate
of 1.9% and detecting the underlying architecture with an accuracy of 97%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-07-26">2021-07-26</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Explicit Prosody Models and Deep Speaker Embeddings for Atypical Voice Conversion. (arXiv:2011.01678v2 [eess.AS] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1">Disong Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_S/0/1/0/all/0/1">Songxiang Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_L/0/1/0/all/0/1">Lifa Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1">Xixin Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xunying Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Meng_H/0/1/0/all/0/1">Helen Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01678">
                                    <div class="article-summary-box-inner">
                                        <span>Though significant progress has been made for the voice conversion (VC) of
typical speech, VC for atypical speech, e.g., dysarthric and second-language
(L2) speech, remains a challenge, since it involves correcting for atypical
prosody while maintaining speaker identity. To address this issue, we propose a
VC system with explicit prosodic modelling and deep speaker embedding (DSE)
learning. First, a speech-encoder strives to extract robust phoneme embeddings
from atypical speech. Second, a prosody corrector takes in phoneme embeddings
to infer typical phoneme duration and pitch values. Third, a conversion model
takes phoneme embeddings and typical prosody features as inputs to generate the
converted speech, conditioned on the target DSE that is learned via speaker
encoder or speaker adaptation. Extensive experiments demonstrate that speaker
adaptation can achieve higher speaker similarity, and the speaker encoder based
conversion model can greatly reduce dysarthric and non-native pronunciation
patterns with improved speech intelligibility. A comparison of speech
recognition results between the original dysarthric speech and converted speech
show that absolute reduction of 47.6% character error rate (CER) and 29.3% word
error rate (WER) can be achieved.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study of the 2019 Indian Election on WhatsApp. (arXiv:2106.04726v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1">Ashkan Kazemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1">Kiran Garimella</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1">Gautam Kishore Shahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1">Devin Gaffney</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04726">
                                    <div class="article-summary-box-inner">
                                        <span>There is currently no easy way to fact-check content on WhatsApp and other
end-to-end encrypted platforms at scale. In this paper, we analyze the
usefulness of a crowd-sourced &quot;tipline&quot; through which users can submit content
(&quot;tips&quot;) that they want fact-checked. We compare the tips sent to a WhatsApp
tipline run during the 2019 Indian national elections with the messages
circulating in large, public groups on WhatsApp and other social media
platforms during the same period. We find that tiplines are a very useful lens
into WhatsApp conversations: a significant fraction of messages and images sent
to the tipline match with the content being shared on public WhatsApp groups
and other social media. Our analysis also shows that tiplines cover the most
popular content well, and a majority of such content is often shared to the
tipline before appearing in large, public WhatsApp groups. Overall, our
findings suggest tiplines can be an effective source for discovering content to
fact-check.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Neural Speech Synthesis. (arXiv:2106.15561v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/eess/1/au:+Soong_F/0/1/0/all/0/1">Frank Soong</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15561">
                                    <div class="article-summary-box-inner">
                                        <span>Text to speech (TTS), or speech synthesis, which aims to synthesize
intelligible and natural speech given text, is a hot research topic in speech,
language, and machine learning communities and has broad applications in the
industry. As the development of deep learning and artificial intelligence,
neural network-based TTS has significantly improved the quality of synthesized
speech in recent years. In this paper, we conduct a comprehensive survey on
neural TTS, aiming to provide a good understanding of current research and
future trends. We focus on the key components in neural TTS, including text
analysis, acoustic models and vocoders, and several advanced topics, including
fast TTS, low-resource TTS, robust TTS, expressive TTS, and adaptive TTS, etc.
We further summarize resources related to TTS (e.g., datasets, opensource
implementations) and discuss future research directions. This survey can serve
both academic researchers and industry practitioners working on TTS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OLR 2021 Challenge: Datasets, Rules and Baselines. (arXiv:2107.11113v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Binling Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wenxuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhi_Y/0/1/0/all/0/1">Yiming Zhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Q/0/1/0/all/0/1">Qingyang Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Liming Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11113">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the sixth Oriental Language Recognition (OLR) 2021
Challenge, which intends to improve the performance of language recognition
systems and speech recognition systems within multilingual scenarios. The data
profile, four tasks, two baselines, and the evaluation principles are
introduced in this paper. In addition to the Language Identification (LID)
tasks, multilingual Automatic Speech Recognition (ASR) tasks are introduced to
OLR 2021 Challenge for the first time. The challenge this year focuses on more
practical and challenging problems, with four tasks: (1) constrained LID, (2)
unconstrained LID, (3) constrained multilingual ASR, (4) unconstrained
multilingual ASR. Baselines for LID tasks and multilingual ASR tasks are
provided, respectively. The LID baseline system is an extended TDNN x-vector
model constructed with Pytorch. A transformer-based end-to-end model is
provided as the multilingual ASR baseline system. These recipes will be online
published, and available for participants to construct their own LID or ASR
systems. The baseline results demonstrate that those tasks are rather
challenging and deserve more effort to achieve better performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anticipating Safety Issues in E2E Conversational AI: Framework and Tooling. (arXiv:2107.03451v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dinan_E/0/1/0/all/0/1">Emily Dinan</a>, <a href="http://arxiv.org/find/cs/1/au:+Abercrombie_G/0/1/0/all/0/1">Gavin Abercrombie</a>, <a href="http://arxiv.org/find/cs/1/au:+Bergman_A/0/1/0/all/0/1">A. Stevie Bergman</a>, <a href="http://arxiv.org/find/cs/1/au:+Spruit_S/0/1/0/all/0/1">Shannon Spruit</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_D/0/1/0/all/0/1">Dirk Hovy</a>, <a href="http://arxiv.org/find/cs/1/au:+Boureau_Y/0/1/0/all/0/1">Y-Lan Boureau</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieser_V/0/1/0/all/0/1">Verena Rieser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03451">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last several years, end-to-end neural conversational agents have
vastly improved in their ability to carry a chit-chat conversation with humans.
However, these models are often trained on large datasets from the internet,
and as a result, may learn undesirable behaviors from this data, such as toxic
or otherwise harmful language. Researchers must thus wrestle with the issue of
how and when to release these models. In this paper, we survey the problem
landscape for safety for end-to-end conversational AI and discuss recent and
related work. We highlight tensions between values, potential positive impact
and potential harms, and provide a framework for making decisions about whether
and how to release these models, following the tenets of value-sensitive
design. We additionally provide a suite of tools to enable researchers to make
better-informed decisions about training and releasing end-to-end
conversational AI models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using CollGram to Compare Formulaic Language in Human and Neural Machine Translation. (arXiv:2107.03625v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bestgen_Y/0/1/0/all/0/1">Yves Bestgen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.03625">
                                    <div class="article-summary-box-inner">
                                        <span>A comparison of formulaic sequences in human and neural machine translation
of quality newspaper articles shows that neural machine translations contain
less lower-frequency, but strongly-associated formulaic sequences, and more
high-frequency formulaic sequences. These differences were statistically
significant and the effect sizes were almost always medium or large. These
observations can be related to the differences between second language learners
of various levels and between translated and untranslated texts. The comparison
between the neural machine translation systems indicates that some systems
produce more formulaic sequences of both types than other systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Domain Adaptation for Dysarthric Speech Detection via Domain Adversarial Training and Mutual Information Minimization. (arXiv:2106.10127v1 [eess.AS] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_D/0/1/0/all/0/1">Disong Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Deng_L/0/1/0/all/0/1">Liqun Deng</a>, <a href="http://arxiv.org/find/eess/1/au:+Yeung_Y/0/1/0/all/0/1">Yu Ting Yeung</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1">Xiao Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xunying Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Meng_H/0/1/0/all/0/1">Helen Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.10127">
                                    <div class="article-summary-box-inner">
                                        <span>Dysarthric speech detection (DSD) systems aim to detect characteristics of
the neuromotor disorder from speech. Such systems are particularly susceptible
to domain mismatch where the training and testing data come from the source and
target domains respectively, but the two domains may differ in terms of speech
stimuli, disease etiology, etc. It is hard to acquire labelled data in the
target domain, due to high costs of annotating sizeable datasets. This paper
makes a first attempt to formulate cross-domain DSD as an unsupervised domain
adaptation (UDA) problem. We use labelled source-domain data and unlabelled
target-domain data, and propose a multi-task learning strategy, including
dysarthria presence classification (DPC), domain adversarial training (DAT) and
mutual information minimization (MIM), which aim to learn
dysarthria-discriminative and domain-invariant biomarker embeddings.
Specifically, DPC helps biomarker embeddings capture critical indicators of
dysarthria; DAT forces biomarker embeddings to be indistinguishable in source
and target domains; and MIM further reduces the correlation between biomarker
embeddings and domain-related cues. By treating the UASPEECH and TORGO corpora
respectively as the source and target domains, experiments show that the
incorporation of UDA attains absolute increases of 22.2% and 20.0% respectively
in utterance-level weighted average recall and speaker-level accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Differentiable Language Model Adversarial Attack on Text Classifiers. (arXiv:2107.11275v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fursov_I/0/1/0/all/0/1">Ivan Fursov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1">Alexey Zaytsev</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnyshev_P/0/1/0/all/0/1">Pavel Burnyshev</a>, <a href="http://arxiv.org/find/cs/1/au:+Dmitrieva_E/0/1/0/all/0/1">Ekaterina Dmitrieva</a>, <a href="http://arxiv.org/find/cs/1/au:+Klyuchnikov_N/0/1/0/all/0/1">Nikita Klyuchnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kravchenko_A/0/1/0/all/0/1">Andrey Kravchenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Artemova_E/0/1/0/all/0/1">Ekaterina Artemova</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1">Evgeny Burnaev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11275">
                                    <div class="article-summary-box-inner">
                                        <span>Robustness of huge Transformer-based models for natural language processing
is an important issue due to their capabilities and wide adoption. One way to
understand and improve robustness of these models is an exploration of an
adversarial attack scenario: check if a small perturbation of an input can fool
a model.

Due to the discrete nature of textual data, gradient-based adversarial
methods, widely used in computer vision, are not applicable per~se. The
standard strategy to overcome this issue is to develop token-level
transformations, which do not take the whole sentence into account.

In this paper, we propose a new black-box sentence-level attack. Our method
fine-tunes a pre-trained language model to generate adversarial examples. A
proposed differentiable loss function depends on a substitute classifier score
and an approximate edit distance computed via a deep learning model.

We show that the proposed attack outperforms competitors on a diverse set of
NLP problems for both computed metrics and human evaluation. Moreover, due to
the usage of the fine-tuned language model, the generated adversarial examples
are hard to detect, thus current models are not robust. Hence, it is difficult
to defend from the proposed attack, which is not the case for other attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-Based Learning for Stock Movement Prediction with Textual and Relational Data. (arXiv:2107.10941v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qinkai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Robert_C/0/1/0/all/0/1">Christian-Yann Robert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10941">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting stock prices from textual information is a challenging task due to
the uncertainty of the market and the difficulty understanding the natural
language from a machine&#x27;s perspective. Previous researches focus mostly on
sentiment extraction based on single news. However, the stocks on the financial
market can be highly correlated, one news regarding one stock can quickly
impact the prices of other stocks. To take this effect into account, we propose
a new stock movement prediction framework: Multi-Graph Recurrent Network for
Stock Forecasting (MGRN). This architecture allows to combine the textual
sentiment from financial news and multiple relational information extracted
from other financial data. Through an accuracy test and a trading simulation on
the stocks in the STOXX Europe 600 index, we demonstrate a better performance
from our model than other benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Don&#x27;t Take It Literally: An Edit-Invariant Sequence Loss for Text Generation. (arXiv:2106.15078v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zichao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_T/0/1/0/all/0/1">Tianhua Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bowen Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1">Zhiting Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15078">
                                    <div class="article-summary-box-inner">
                                        <span>Neural text generation models are typically trained by maximizing
log-likelihood with the sequence cross entropy loss, which encourages an exact
token-by-token match between a target sequence with a generated sequence. Such
training objective is sub-optimal when the target sequence not perfect, e.g.,
when the target sequence is corrupted with noises, or when only weak sequence
supervision is available. To address this challenge, we propose a novel
Edit-Invariant Sequence Loss (EISL), which computes the matching loss of a
target n-gram with all n-grams in the generated sequence. EISL draws
inspirations from convolutional networks (ConvNets) which are shift-invariant
to images, hence is robust to the shift of n-grams to tolerate edits in the
target sequences. Moreover, the computation of EISL is essentially a
convolution operation with target n-grams as kernels, which is easy to
implement with existing libraries. To demonstrate the effectiveness of EISL, we
conduct experiments on three tasks: machine translation with noisy target
sequences, unsupervised text style transfer, and non-autoregressive machine
translation. Experimental results show our method significantly outperforms
cross entropy loss on these three tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Language Specific Sub-network for Multilingual Machine Translation. (arXiv:2105.09259v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zehui Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1">Liwei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.09259">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual neural machine translation aims at learning a single translation
model for multiple languages. These jointly trained models often suffer from
performance degradation on rich-resource language pairs. We attribute this
degeneration to parameter interference. In this paper, we propose LaSS to
jointly train a single unified multilingual MT model. LaSS learns Language
Specific Sub-network (LaSS) for each language pair to counter parameter
interference. Comprehensive experiments on IWSLT and WMT datasets with various
Transformer architectures show that LaSS obtains gains on 36 language pairs by
up to 1.2 BLEU. Besides, LaSS shows its strong generalization performance at
easy extension to new language pairs and zero-shot translation.LaSS boosts
zero-shot translation with an average of 8.3 BLEU on 30 language pairs. Codes
and trained models are available at https://github.com/NLP-Playground/LaSS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Speech Recognition in Sanskrit: A New Speech Corpus and Modelling Insights. (arXiv:2106.05852v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Adiga_D/0/1/0/all/0/1">Devaraja Adiga</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_R/0/1/0/all/0/1">Rishabh Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Krishna_A/0/1/0/all/0/1">Amrith Krishna</a>, <a href="http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>, <a href="http://arxiv.org/find/eess/1/au:+Goyal_P/0/1/0/all/0/1">Pawan Goyal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05852">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the
various linguistic peculiarities present in the language. The Sanskrit language
is lexically productive, undergoes euphonic assimilation of phones at the word
boundaries and exhibits variations in spelling conventions and in
pronunciations. In this work, we propose the first large scale study of
automatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact
of unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR
dataset for Sanskrit, which faithfully captures several of the linguistic
characteristics expressed by the language. We investigate the role of different
acoustic model and language model units in ASR systems for Sanskrit. We also
propose a new modelling unit, inspired by the syllable level unit selection,
that captures character sequences from one vowel in the word to the next vowel.
We also highlight the importance of choosing graphemic representations for
Sanskrit and show the impact of this choice on word error rates (WER). Finally,
we extend these insights from Sanskrit ASR for building ASR systems in two
other Indic languages, Gujarati and Telugu. For both these languages, our
experimental results show that the use of phonetic based graphemic
representations in ASR results in performance improvements as compared to ASR
systems that use native scripts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Biomedical Word Embeddings in the Transformer Era. (arXiv:2012.11808v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Noh_J/0/1/0/all/0/1">Jiho Noh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kavuluru_R/0/1/0/all/0/1">Ramakanth Kavuluru</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11808">
                                    <div class="article-summary-box-inner">
                                        <span>Biomedical word embeddings are usually pre-trained on free text corpora with
neural methods that capture local and global distributional properties. They
are leveraged in downstream tasks using various neural architectures that are
designed to optimize task-specific objectives that might further tune such
embeddings. Since 2018, however, there is a marked shift from these static
embeddings to contextual embeddings motivated by language models (e.g., ELMo,
transformers such as BERT, and ULMFiT). These dynamic embeddings have the added
benefit of being able to distinguish homonyms and acronyms given their context.
However, static embeddings are still relevant in low resource settings (e.g.,
smart devices, IoT elements) and to study lexical semantics from a
computational linguistics perspective. In this paper, we jointly learn word and
concept embeddings by first using the skip-gram method and further fine-tuning
them with correlational information manifesting in co-occurring Medical Subject
Heading (MeSH) concepts in biomedical citations. This fine-tuning is
accomplished with the BERT transformer architecture in the two-sentence input
mode with a classification objective that captures MeSH pair co-occurrence. In
essence, we repurpose a transformer architecture (typically used to generate
dynamic embeddings) to improve static embeddings using concept correlations. We
conduct evaluations of these tuned static embeddings using multiple datasets
for word relatedness developed by previous efforts. Without selectively culling
concepts and terms (as was pursued by previous efforts), we believe we offer
the most exhaustive evaluation of static embeddings to date with clear
performance improvements across the board. We provide our code and embeddings
for public use for downstream applications and research endeavors:
https://github.com/bionlproc/BERT-CRel-Embeddings</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Powering Effective Climate Communication with a Climate Knowledge Base. (arXiv:2107.11351v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rodrigues_K/0/1/0/all/0/1">Kameron B. Rodrigues</a>, <a href="http://arxiv.org/find/cs/1/au:+Khushu_S/0/1/0/all/0/1">Shweta Khushu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_M/0/1/0/all/0/1">Mukut Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Banister_A/0/1/0/all/0/1">Andrew Banister</a>, <a href="http://arxiv.org/find/cs/1/au:+Hevia_A/0/1/0/all/0/1">Anthony Hevia</a>, <a href="http://arxiv.org/find/cs/1/au:+Duddu_S/0/1/0/all/0/1">Sampath Duddu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhutani_N/0/1/0/all/0/1">Nikita Bhutani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11351">
                                    <div class="article-summary-box-inner">
                                        <span>While many accept climate change and its growing impacts, few converse about
it well, limiting the adoption speed of societal changes necessary to address
it. In order to make effective climate communication easier, we aim to build a
system that presents to any individual the climate information predicted to
best motivate and inspire them to take action given their unique set of
personal values. To alleviate the cold-start problem, the system relies on a
knowledge base (ClimateKB) of causes and effects of climate change, and their
associations to personal values. Since no such comprehensive ClimateKB exists,
we revisit knowledge base construction techniques and build a ClimateKB from
free text. We plan to open source the ClimateKB and associated code to
encourage future research and applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SUPERB: Speech processing Universal PERformance Benchmark. (arXiv:2105.01051v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shu-wen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_P/0/1/0/all/0/1">Po-Han Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chuang_Y/0/1/0/all/0/1">Yung-Sung Chuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_C/0/1/0/all/0/1">Cheng-I Jeff Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakhotia_K/0/1/0/all/0/1">Kushal Lakhotia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yist Y. Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Andy T. Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1">Jiatong Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_X/0/1/0/all/0/1">Xuankai Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guan-Ting Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1">Tzu-Hsien Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_W/0/1/0/all/0/1">Wei-Cheng Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Ko-tik Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Da-Rong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zili Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_S/0/1/0/all/0/1">Shuyan Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shang-Wen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Watanabe_S/0/1/0/all/0/1">Shinji Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Abdelrahman Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hung-yi Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.01051">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning (SSL) has proven vital for advancing research in
natural language processing (NLP) and computer vision (CV). The paradigm
pretrains a shared model on large volumes of unlabeled data and achieves
state-of-the-art (SOTA) for various tasks with minimal adaptation. However, the
speech processing community lacks a similar setup to systematically explore the
paradigm. To bridge this gap, we introduce Speech processing Universal
PERformance Benchmark (SUPERB). SUPERB is a leaderboard to benchmark the
performance of a shared model across a wide range of speech processing tasks
with minimal architecture changes and labeled data. Among multiple usages of
the shared model, we especially focus on extracting the representation learned
from SSL due to its preferable re-usability. We present a simple framework to
solve SUPERB tasks by learning task-specialized lightweight prediction heads on
top of the frozen shared model. Our results demonstrate that the framework is
promising as SSL representations show competitive generalizability and
accessibility across SUPERB tasks. We release SUPERB as a challenge with a
leaderboard and a benchmark toolkit to fuel the research in representation
learning and general speech processing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Did the Cat Drink the Coffee? Challenging Transformers with Generalized Event Knowledge. (arXiv:2107.10922v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pedinotti_P/0/1/0/all/0/1">Paolo Pedinotti</a>, <a href="http://arxiv.org/find/cs/1/au:+Rambelli_G/0/1/0/all/0/1">Giulia Rambelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Chersoni_E/0/1/0/all/0/1">Emmanuele Chersoni</a>, <a href="http://arxiv.org/find/cs/1/au:+Santus_E/0/1/0/all/0/1">Enrico Santus</a>, <a href="http://arxiv.org/find/cs/1/au:+Lenci_A/0/1/0/all/0/1">Alessandro Lenci</a>, <a href="http://arxiv.org/find/cs/1/au:+Blache_P/0/1/0/all/0/1">Philippe Blache</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10922">
                                    <div class="article-summary-box-inner">
                                        <span>Prior research has explored the ability of computational models to predict a
word semantic fit with a given predicate. While much work has been devoted to
modeling the typicality relation between verbs and arguments in isolation, in
this paper we take a broader perspective by assessing whether and to what
extent computational approaches have access to the information about the
typicality of entire events and situations described in language (Generalized
Event Knowledge). Given the recent success of Transformers Language Models
(TLMs), we decided to test them on a benchmark for the \textit{dynamic
estimation of thematic fit}. The evaluation of these models was performed in
comparison with SDM, a framework specifically designed to integrate events in
sentence meaning representations, and we conducted a detailed error analysis to
investigate which factors affect their behavior. Our results show that TLMs can
reach performances that are comparable to those achieved by SDM. However,
additional analysis consistently suggests that TLMs do not capture important
aspects of event knowledge, and their predictions often depend on surface
linguistic features, such as frequent words, collocations and syntactic
patterns, thereby showing sub-optimal generalization abilities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Early Sepsis Prediction with Multi Modal Learning. (arXiv:2107.11094v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_F/0/1/0/all/0/1">Fred Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Madan_V/0/1/0/all/0/1">Vivek Madan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratan_U/0/1/0/all/0/1">Ujjwal Ratan</a>, <a href="http://arxiv.org/find/cs/1/au:+Karnin_Z/0/1/0/all/0/1">Zohar Karnin</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapoor_V/0/1/0/all/0/1">Vishaal Kapoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhatia_P/0/1/0/all/0/1">Parminder Bhatia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kass_Hout_T/0/1/0/all/0/1">Taha Kass-Hout</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11094">
                                    <div class="article-summary-box-inner">
                                        <span>Sepsis is a life-threatening disease with high morbidity, mortality and
healthcare costs. The early prediction and administration of antibiotics and
intravenous fluids is considered crucial for the treatment of sepsis and can
save potentially millions of lives and billions in health care costs.
Professional clinical care practitioners have proposed clinical criterion which
aid in early detection of sepsis; however, performance of these criterion is
often limited. Clinical text provides essential information to estimate the
severity of the sepsis in addition to structured clinical data. In this study,
we explore how clinical text can complement structured data towards early
sepsis prediction task. In this paper, we propose multi modal model which
incorporates both structured data in the form of patient measurements as well
as textual notes on the patient. We employ state-of-the-art NLP models such as
BERT and a highly specialized NLP model in Amazon Comprehend Medical to
represent the text. On the MIMIC-III dataset containing records of ICU
admissions, we show that by using these notes, one achieves an improvement of
6.07 points in a standard utility score for Sepsis prediction and 2.89% in
AUROC score. Our methods significantly outperforms a clinical criteria
suggested by experts, qSOFA, as well as the winning model of the PhysioNet
Computing in Cardiology Challenge for predicting Sepsis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CONDA: a CONtextual Dual-Annotated dataset for in-game toxicity understanding and detection. (arXiv:2106.06213v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Weld_H/0/1/0/all/0/1">Henry Weld</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Guanghao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jean Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tongshu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kunze Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1">Xinghong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_S/0/1/0/all/0/1">Siqu Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Poon_J/0/1/0/all/0/1">Josiah Poon</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Soyeon Caren Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06213">
                                    <div class="article-summary-box-inner">
                                        <span>Traditional toxicity detection models have focused on the single utterance
level without deeper understanding of context. We introduce CONDA, a new
dataset for in-game toxic language detection enabling joint intent
classification and slot filling analysis, which is the core task of Natural
Language Understanding (NLU). The dataset consists of 45K utterances from 12K
conversations from the chat logs of 1.9K completed Dota 2 matches. We propose a
robust dual semantic-level toxicity framework, which handles utterance and
token-level patterns, and rich contextual chatting history. Accompanying the
dataset is a thorough in-game toxicity analysis, which provides comprehensive
understanding of context at utterance, token, and dual levels. Inspired by NLU,
we also apply its metrics to the toxicity detection tasks for assessing
toxicity and game-specific aspects. We evaluate strong NLU models on CONDA,
providing fine-grained results for different intent classes and slot classes.
Furthermore, we examine the coverage of toxicity nature in our dataset by
comparing it with other toxicity datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modelling Latent Translations for Cross-Lingual Transfer. (arXiv:2107.11353v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1">Edoardo Maria Ponti</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1">Julia Kreutzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1">Siva Reddy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11353">
                                    <div class="article-summary-box-inner">
                                        <span>While achieving state-of-the-art results in multiple tasks and languages,
translation-based cross-lingual transfer is often overlooked in favour of
massively multilingual pre-trained encoders. Arguably, this is due to its main
limitations: 1) translation errors percolating to the classification phase and
2) the insufficient expressiveness of the maximum-likelihood translation. To
remedy this, we propose a new technique that integrates both steps of the
traditional pipeline (translation and classification) into a single model, by
treating the intermediate translations as a latent random variable. As a
result, 1) the neural machine translation system can be fine-tuned with a
variant of Minimum Risk Training where the reward is the accuracy of the
downstream task classifier. Moreover, 2) multiple samples can be drawn to
approximate the expected loss across all possible translations during
inference. We evaluate our novel latent translation-based model on a series of
multilingual NLU tasks, including commonsense reasoning, paraphrase
identification, and natural language inference. We report gains for both
zero-shot and few-shot learning setups, up to 2.7 accuracy points on average,
which are even more prominent for low-resource languages (e.g., Haitian
Creole). Finally, we carry out in-depth analyses comparing different underlying
NMT models and assessing the impact of alternative translations on the
downstream performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When a crisis strikes: Emotion analysis and detection during COVID-19. (arXiv:2107.11020v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tekle_A/0/1/0/all/0/1">Alexander Tekle</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_C/0/1/0/all/0/1">Chau Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Caragea_C/0/1/0/all/0/1">Cornelia Caragea</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junyi Jessy Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11020">
                                    <div class="article-summary-box-inner">
                                        <span>Crises such as natural disasters, global pandemics, and social unrest
continuously threaten our world and emotionally affect millions of people
worldwide in distinct ways. Understanding emotions that people express during
large-scale crises helps inform policy makers and first responders about the
emotional states of the population as well as provide emotional support to
those who need such support. We present CovidEmo, ~1K tweets labeled with
emotions. We examine how well large pre-trained language models generalize
across domains and crises in the task of perceived emotion prediction in the
context of COVID-19. Our results show that existing models do not directly
transfer from one disaster type to another but using labeled emotional corpora
for domain adaptation is beneficial.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FrameAxis: Characterizing Microframe Bias and Intensity with Word Embedding. (arXiv:2002.08608v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kwak_H/0/1/0/all/0/1">Haewoon Kwak</a>, <a href="http://arxiv.org/find/cs/1/au:+An_J/0/1/0/all/0/1">Jisun An</a>, <a href="http://arxiv.org/find/cs/1/au:+Jing_E/0/1/0/all/0/1">Elise Jing</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_Y/0/1/0/all/0/1">Yong-Yeol Ahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.08608">
                                    <div class="article-summary-box-inner">
                                        <span>Framing is a process of emphasizing a certain aspect of an issue over the
others, nudging readers or listeners towards different positions on the issue
even without making a biased argument. {Here, we propose FrameAxis, a method
for characterizing documents by identifying the most relevant semantic axes
(&quot;microframes&quot;) that are overrepresented in the text using word embedding. Our
unsupervised approach can be readily applied to large datasets because it does
not require manual annotations. It can also provide nuanced insights by
considering a rich set of semantic axes. FrameAxis is designed to
quantitatively tease out two important dimensions of how microframes are used
in the text. \textit{Microframe bias} captures how biased the text is on a
certain microframe, and \textit{microframe intensity} shows how actively a
certain microframe is used. Together, they offer a detailed characterization of
the text. We demonstrate that microframes with the highest bias and intensity
well align with sentiment, topic, and partisan spectrum by applying FrameAxis
to multiple datasets from restaurant reviews to political news.} The existing
domain knowledge can be incorporated into FrameAxis {by using custom
microframes and by using FrameAxis as an iterative exploratory analysis
instrument.} Additionally, we propose methods for explaining the results of
FrameAxis at the level of individual words and documents. Our method may
accelerate scalable and sophisticated computational analyses of framing across
disciplines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Bilingual Conversational Characteristics for Neural Chat Translation. (arXiv:2107.11164v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yunlong Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_F/0/1/0/all/0/1">Fandong Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yufeng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jinan Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11164">
                                    <div class="article-summary-box-inner">
                                        <span>Neural chat translation aims to translate bilingual conversational text,
which has a broad application in international exchanges and cooperation.
Despite the impressive performance of sentence-level and context-aware Neural
Machine Translation (NMT), there still remain challenges to translate bilingual
conversational text due to its inherent characteristics such as role
preference, dialogue coherence, and translation consistency. In this paper, we
aim to promote the translation quality of conversational text by modeling the
above properties. Specifically, we design three latent variational modules to
learn the distributions of bilingual conversational characteristics. Through
sampling from these learned distributions, the latent variables, tailored for
role preference, dialogue coherence, and translation consistency, are
incorporated into the NMT model for better translation. We evaluate our
approach on the benchmark dataset BConTrasT (English-German) and a
self-collected bilingual dialogue corpus, named BMELD (English-Chinese).
Extensive experiments show that our approach notably boosts the performance
over strong baselines by a large margin and significantly surpasses some
state-of-the-art context-aware NMT models in terms of BLEU and TER.
Additionally, we make the BMELD dataset publicly available for the research
community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Reinforced Instruction Attacker for Robust Vision-Language Navigation. (arXiv:2107.11252v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bingqian Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yanxin Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qixiang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11252">
                                    <div class="article-summary-box-inner">
                                        <span>Language instruction plays an essential role in the natural language grounded
navigation tasks. However, navigators trained with limited human-annotated
instructions may have difficulties in accurately capturing key information from
the complicated instruction at different timesteps, leading to poor navigation
performance. In this paper, we exploit to train a more robust navigator which
is capable of dynamically extracting crucial factors from the long instruction,
by using an adversarial attacking paradigm. Specifically, we propose a Dynamic
Reinforced Instruction Attacker (DR-Attacker), which learns to mislead the
navigator to move to the wrong target by destroying the most instructive
information in instructions at different timesteps. By formulating the
perturbation generation as a Markov Decision Process, DR-Attacker is optimized
by the reinforcement learning algorithm to generate perturbed instructions
sequentially during the navigation, according to a learnable attack score.
Then, the perturbed instructions, which serve as hard samples, are used for
improving the robustness of the navigator with an effective adversarial
training strategy and an auxiliary self-supervised reasoning task. Experimental
results on both Vision-and-Language Navigation (VLN) and Navigation from Dialog
History (NDH) tasks show the superiority of our proposed method over
state-of-the-art methods. Moreover, the visualization analysis shows the
effectiveness of the proposed DR-Attacker, which can successfully attack
crucial information in the instructions at different timesteps. Code is
available at https://github.com/expectorlin/DR-Attacker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Including Signed Languages in Natural Language Processing. (arXiv:2105.05222v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1">Kayo Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Moryossef_A/0/1/0/all/0/1">Amit Moryossef</a>, <a href="http://arxiv.org/find/cs/1/au:+Hochgesang_J/0/1/0/all/0/1">Julie Hochgesang</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1">Yoav Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Alikhani_M/0/1/0/all/0/1">Malihe Alikhani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05222">
                                    <div class="article-summary-box-inner">
                                        <span>Signed languages are the primary means of communication for many deaf and
hard of hearing individuals. Since signed languages exhibit all the fundamental
linguistic properties of natural language, we believe that tools and theories
of Natural Language Processing (NLP) are crucial towards its modeling. However,
existing research in Sign Language Processing (SLP) seldom attempt to explore
and leverage the linguistic organization of signed languages. This position
paper calls on the NLP community to include signed languages as a research area
with high social and scientific impact. We first discuss the linguistic
properties of signed languages to consider during their modeling. Then, we
review the limitations of current SLP models and identify the open challenges
to extend NLP to signed languages. Finally, we urge (1) the adoption of an
efficient tokenization method; (2) the development of linguistically-informed
models; (3) the collection of real-world signed language data; (4) the
inclusion of local signed language communities as an active and leading voice
in the direction of research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FNetAR: Mixing Tokens with Autoregressive Fourier Transforms. (arXiv:2107.10932v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lou_T/0/1/0/all/0/1">Tim Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1">Michael Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramezanali_M/0/1/0/all/0/1">Mohammad Ramezanali</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_V/0/1/0/all/0/1">Vincent Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10932">
                                    <div class="article-summary-box-inner">
                                        <span>In this note we examine the autoregressive generalization of the FNet
algorithm, in which self-attention layers from the standard Transformer
architecture are substituted with a trivial sparse-uniformsampling procedure
based on Fourier transforms. Using the Wikitext-103 benchmark, we
demonstratethat FNetAR retains state-of-the-art performance (25.8 ppl) on the
task of causal language modelingcompared to a Transformer-XL baseline (24.2
ppl) with only half the number self-attention layers,thus providing further
evidence for the superfluity of deep neural networks with heavily
compoundedattention mechanisms. The autoregressive Fourier transform could
likely be used for parameterreduction on most Transformer-based time-series
prediction models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diagonal Attention and Style-based GAN for Content-Style Disentanglement in Image Generation and Translation. (arXiv:2103.16146v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kwon_G/0/1/0/all/0/1">Gihyun Kwon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jong Chul Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16146">
                                    <div class="article-summary-box-inner">
                                        <span>One of the important research topics in image generative models is to
disentangle the spatial contents and styles for their separate control.
Although StyleGAN can generate content feature vectors from random noises, the
resulting spatial content control is primarily intended for minor spatial
variations, and the disentanglement of global content and styles is by no means
complete. Inspired by a mathematical understanding of normalization and
attention, here we present a novel hierarchical adaptive Diagonal spatial
ATtention (DAT) layers to separately manipulate the spatial contents from
styles in a hierarchical manner. Using DAT and AdaIN, our method enables
coarse-to-fine level disentanglement of spatial contents and styles. In
addition, our generator can be easily integrated into the GAN inversion
framework so that the content and style of translated images from multi-domain
image translation tasks can be flexibly controlled. By using various datasets,
we confirm that the proposed method not only outperforms the existing models in
disentanglement scores, but also provides more flexible control over spatial
features in the generated images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Instance Pose Networks: Rethinking Top-Down Pose Estimation. (arXiv:2101.11223v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khirodkar_R/0/1/0/all/0/1">Rawal Khirodkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Chari_V/0/1/0/all/0/1">Visesh Chari</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Amit Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Tyagi_A/0/1/0/all/0/1">Ambrish Tyagi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11223">
                                    <div class="article-summary-box-inner">
                                        <span>A key assumption of top-down human pose estimation approaches is their
expectation of having a single person/instance present in the input bounding
box. This often leads to failures in crowded scenes with occlusions. We propose
a novel solution to overcome the limitations of this fundamental assumption.
Our Multi-Instance Pose Network (MIPNet) allows for predicting multiple 2D pose
instances within a given bounding box. We introduce a Multi-Instance Modulation
Block (MIMB) that can adaptively modulate channel-wise feature responses for
each instance and is parameter efficient. We demonstrate the efficacy of our
approach by evaluating on COCO, CrowdPose, and OCHuman datasets. Specifically,
we achieve 70.0 AP on CrowdPose and 42.5 AP on OCHuman test sets, a significant
improvement of 2.4 AP and 6.5 AP over the prior art, respectively. When using
ground truth bounding boxes for inference, MIPNet achieves an improvement of
0.7 AP on COCO, 0.9 AP on CrowdPose, and 9.1 AP on OCHuman validation sets
compared to HRNet. Interestingly, when fewer, high confidence bounding boxes
are used, HRNet&#x27;s performance degrades (by 5 AP) on OCHuman, whereas MIPNet
maintains a relatively stable performance (drop of 1 AP) for the same inputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised asymmetric deep hashing with margin-scalable constraint. (arXiv:2012.03820v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhengyang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Song Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_Z/0/1/0/all/0/1">Zhihao Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Bakker_E/0/1/0/all/0/1">Erwin M.Bakker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03820">
                                    <div class="article-summary-box-inner">
                                        <span>Due to its effectivity and efficiency, deep hashing approaches are widely
used for large-scale visual search. However, it is still challenging to produce
compact and discriminative hash codes for images associated with multiple
semantics for two main reasons, 1) similarity constraints designed in most of
the existing methods are based upon an oversimplified similarity
assignment(i.e., 0 for instance pairs sharing no label, 1 for instance pairs
sharing at least 1 label), 2) the exploration in multi-semantic relevance are
insufficient or even neglected in many of the existing methods. These problems
significantly limit the discrimination of generated hash codes. In this paper,
we propose a novel self-supervised asymmetric deep hashing method with a
margin-scalable constraint(SADH) approach to cope with these problems. SADH
implements a self-supervised network to sufficiently preserve semantic
information in a semantic feature dictionary and a semantic code dictionary for
the semantics of the given dataset, which efficiently and precisely guides a
feature learning network to preserve multilabel semantic information using an
asymmetric learning strategy. By further exploiting semantic dictionaries, a
new margin-scalable constraint is employed for both precise similarity
searching and robust hash code generation. Extensive empirical research on four
popular benchmarks validates the proposed method and shows it outperforms
several state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Content-Aware Convolutional Neural Networks. (arXiv:2106.15797v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yong Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yaofo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15797">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) have achieved great success due to the
powerful feature learning ability of convolution layers. Specifically, the
standard convolution traverses the input images/features using a sliding window
scheme to extract features. However, not all the windows contribute equally to
the prediction results of CNNs. In practice, the convolutional operation on
some of the windows (e.g., smooth windows that contain very similar pixels) can
be very redundant and may introduce noises into the computation. Such
redundancy may not only deteriorate the performance but also incur the
unnecessary computational cost. Thus, it is important to reduce the
computational redundancy of convolution to improve the performance. To this
end, we propose a Content-aware Convolution (CAC) that automatically detects
the smooth windows and applies a 1x1 convolutional kernel to replace the
original large kernel. In this sense, we are able to effectively avoid the
redundant computation on similar pixels. By replacing the standard convolution
in CNNs with our CAC, the resultant models yield significantly better
performance and lower computational cost than the baseline models with the
standard convolution. More critically, we are able to dynamically allocate
suitable computation resources according to the data smoothness of different
images, making it possible for content-aware computation. Extensive experiments
on various computer vision tasks demonstrate the superiority of our method over
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autonomous Vehicles that Alert Humans to Take-Over Controls: Modeling with Real-World Data. (arXiv:2104.11489v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rangesh_A/0/1/0/all/0/1">Akshay Rangesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Deo_N/0/1/0/all/0/1">Nachiket Deo</a>, <a href="http://arxiv.org/find/cs/1/au:+Greer_R/0/1/0/all/0/1">Ross Greer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunaratne_P/0/1/0/all/0/1">Pujitha Gunaratne</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_M/0/1/0/all/0/1">Mohan M. Trivedi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11489">
                                    <div class="article-summary-box-inner">
                                        <span>With increasing automation in passenger vehicles, the study of safe and
smooth occupant-vehicle interaction and control transitions is key. In this
study, we focus on the development of contextual, semantically meaningful
representations of the driver state, which can then be used to determine the
appropriate timing and conditions for transfer of control between driver and
vehicle. To this end, we conduct a large-scale real-world controlled data study
where participants are instructed to take-over control from an autonomous agent
under different driving conditions while engaged in a variety of distracting
activities. These take-over events are captured using multiple driver-facing
cameras, which when labelled result in a dataset of control transitions and
their corresponding take-over times (TOTs). We then develop and train TOT
models that operate sequentially on mid to high-level features produced by
computer vision algorithms operating on different driver-facing camera views.
The proposed TOT model produces continuous predictions of take-over times
without delay, and shows promising qualitative and quantitative results in
complex real-world scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Classifying bacteria clones using attention-based deep multiple instance learning interpreted by persistence homology. (arXiv:2012.01189v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Borowa_A/0/1/0/all/0/1">Adriana Borowa</a>, <a href="http://arxiv.org/find/cs/1/au:+Rymarczyk_D/0/1/0/all/0/1">Dawid Rymarczyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Ochonska_D/0/1/0/all/0/1">Dorota Ocho&#x144;ska</a>, <a href="http://arxiv.org/find/cs/1/au:+Brzychczy_Wloch_M/0/1/0/all/0/1">Monika Brzychczy-W&#x142;och</a>, <a href="http://arxiv.org/find/cs/1/au:+Zielinski_B/0/1/0/all/0/1">Bartosz Zieli&#x144;ski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01189">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we analyze if it is possible to distinguish between different
clones of the same bacteria species (Klebsiella pneumoniae) based only on
microscopic images. It is a challenging task, previously considered impossible
due to the high clones similarity. For this purpose, we apply a multi-step
algorithm with attention-based multiple instance learning. Except for obtaining
accuracy at the level of 0.9, we introduce extensive interpretability based on
CellProfiler and persistence homology, increasing the understandability and
trust in the model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An effective and friendly tool for seed image analysis. (arXiv:2103.17213v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Loddo_A/0/1/0/all/0/1">Andrea Loddo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruberto_C/0/1/0/all/0/1">Cecilia Di Ruberto</a>, <a href="http://arxiv.org/find/cs/1/au:+Vale_A/0/1/0/all/0/1">A.M.P.G. Vale</a>, <a href="http://arxiv.org/find/cs/1/au:+Ucchesu_M/0/1/0/all/0/1">Mariano Ucchesu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soares_J/0/1/0/all/0/1">J.M. Soares</a>, <a href="http://arxiv.org/find/cs/1/au:+Bacchetta_G/0/1/0/all/0/1">Gianluigi Bacchetta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17213">
                                    <div class="article-summary-box-inner">
                                        <span>Image analysis is an essential field for several topics in the life sciences,
such as biology or botany. In particular, the analysis of seeds (e.g. fossil
research) can provide significant information on their evolution, the history
of agriculture, plant domestication and knowledge of diets in ancient times.
This work aims to present software that performs image analysis for feature
extraction and classification from images containing seeds through a novel and
unique framework. In detail, we propose two plugins \emph{ImageJ}, one able to
extract morphological, textual and colour features from seed images, and
another to classify seeds into categories using the extracted features. The
experimental results demonstrated the correctness and validity of both the
extracted features and the classification predictions. The proposed tool is
easily extendable to other fields of image analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Model for Fingerprint Authentication and Presentation Attack Detection. (arXiv:2104.03255v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Popli_A/0/1/0/all/0/1">Additya Popli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tandon_S/0/1/0/all/0/1">Saraansh Tandon</a>, <a href="http://arxiv.org/find/cs/1/au:+Engelsma_J/0/1/0/all/0/1">Joshua J. Engelsma</a>, <a href="http://arxiv.org/find/cs/1/au:+Onoe_N/0/1/0/all/0/1">Naoyuki Onoe</a>, <a href="http://arxiv.org/find/cs/1/au:+Okubo_A/0/1/0/all/0/1">Atsushi Okubo</a>, <a href="http://arxiv.org/find/cs/1/au:+Namboodiri_A/0/1/0/all/0/1">Anoop Namboodiri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03255">
                                    <div class="article-summary-box-inner">
                                        <span>Typical fingerprint recognition systems are comprised of a spoof detection
module and a subsequent recognition module, running one after the other. In
this paper, we reformulate the workings of a typical fingerprint recognition
system. In particular, we posit that both spoof detection and fingerprint
recognition are correlated tasks. Therefore, rather than performing the two
tasks separately, we propose a joint model for spoof detection and matching to
simultaneously perform both tasks without compromising the accuracy of either
task. We demonstrate the capability of our joint model to obtain an
authentication accuracy (1:1 matching) of TAR &#x3D; 100% @ FAR &#x3D; 0.1% on the FVC
2006 DB2A dataset while achieving a spoof detection ACE of 1.44% on the LiveDet
2015 dataset, both maintaining the performance of stand-alone methods. In
practice, this reduces the time and memory requirements of the fingerprint
recognition system by 50% and 40%, respectively; a significant advantage for
recognition systems running on resource-constrained devices and communication
channels. The project page for our work is available at
https://www.bit.ly/ijcb2021-unified .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mining Data Impressions from Deep Models as Substitute for the Unavailable Training Data. (arXiv:2101.06069v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1">Gaurav Kumar Nayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Mopuri_K/0/1/0/all/0/1">Konda Reddy Mopuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saksham Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1">Anirban Chakraborty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06069">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained deep models hold their learnt knowledge in the form of model
parameters. These parameters act as &quot;memory&quot; for the trained models and help
them generalize well on unseen data. However, in absence of training data, the
utility of a trained model is merely limited to either inference or better
initialization towards a target task. In this paper, we go further and extract
synthetic data by leveraging the learnt model parameters. We dub them &quot;Data
Impressions&quot;, which act as proxy to the training data and can be used to
realize a variety of tasks. These are useful in scenarios where only the
pretrained models are available and the training data is not shared (e.g., due
to privacy or sensitivity concerns). We show the applicability of data
impressions in solving several computer vision tasks such as unsupervised
domain adaptation, continual learning as well as knowledge distillation. We
also study the adversarial robustness of lightweight models trained via
knowledge distillation using these data impressions. Further, we demonstrate
the efficacy of data impressions in generating data-free Universal Adversarial
Perturbations (UAPs) with better fooling rates. Extensive experiments performed
on benchmark datasets demonstrate competitive performance achieved using data
impressions in absence of original training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rigging the Lottery: Making All Tickets Winners. (arXiv:1911.11134v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Evci_U/0/1/0/all/0/1">Utku Evci</a>, <a href="http://arxiv.org/find/cs/1/au:+Gale_T/0/1/0/all/0/1">Trevor Gale</a>, <a href="http://arxiv.org/find/cs/1/au:+Menick_J/0/1/0/all/0/1">Jacob Menick</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_P/0/1/0/all/0/1">Pablo Samuel Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Elsen_E/0/1/0/all/0/1">Erich Elsen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.11134">
                                    <div class="article-summary-box-inner">
                                        <span>Many applications require sparse neural networks due to space or inference
time restrictions. There is a large body of work on training dense networks to
yield sparse networks for inference, but this limits the size of the largest
trainable sparse model to that of the largest trainable dense model. In this
paper we introduce a method to train sparse neural networks with a fixed
parameter count and a fixed computational cost throughout training, without
sacrificing accuracy relative to existing dense-to-sparse training methods. Our
method updates the topology of the sparse network during training by using
parameter magnitudes and infrequent gradient calculations. We show that this
approach requires fewer floating-point operations (FLOPs) to achieve a given
level of accuracy compared to prior techniques. We demonstrate state-of-the-art
sparse training results on a variety of networks and datasets, including
ResNet-50, MobileNets on Imagenet-2012, and RNNs on WikiText-103. Finally, we
provide some insights into why allowing the topology to change during the
optimization can overcome local minima encountered when the topology remains
static. Code used in our work can be found in github.com/google-research/rigl.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human Action Recognition from Various Data Modalities: A Review. (arXiv:2012.11866v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zehua Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_Q/0/1/0/all/0/1">Qiuhong Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmani_H/0/1/0/all/0/1">Hossein Rahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1">Mohammed Bennamoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11866">
                                    <div class="article-summary-box-inner">
                                        <span>Human Action Recognition (HAR) aims to understand human behavior and assign a
label to each action. It has a wide range of applications, and therefore has
been attracting increasing attention in the field of computer vision. Human
actions can be represented using various data modalities, such as RGB,
skeleton, depth, infrared, point cloud, event stream, audio, acceleration,
radar, and WiFi signal, which encode different sources of useful yet distinct
information and have various advantages depending on the application scenarios.
Consequently, lots of existing works have attempted to investigate different
types of approaches for HAR using various modalities. In this paper, we present
a comprehensive survey of recent progress in deep learning methods for HAR
based on the type of input data modality. Specifically, we review the current
mainstream deep learning methods for single data modalities and multiple data
modalities, including the fusion-based and the co-learning-based frameworks. We
also present comparative results on several benchmark datasets for HAR,
together with insightful observations and inspiring future research directions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Automated Classroom Observation: Multimodal Machine Learning to Estimate CLASS Positive Climate and Negative Climate. (arXiv:2005.09525v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_A/0/1/0/all/0/1">Anand Ramakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zylich_B/0/1/0/all/0/1">Brian Zylich</a>, <a href="http://arxiv.org/find/cs/1/au:+Ottmar_E/0/1/0/all/0/1">Erin Ottmar</a>, <a href="http://arxiv.org/find/cs/1/au:+LoCasale_Crouch_J/0/1/0/all/0/1">Jennifer LoCasale-Crouch</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitehill_J/0/1/0/all/0/1">Jacob Whitehill</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.09525">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we present a multi-modal machine learning-based system, which we
call ACORN, to analyze videos of school classrooms for the Positive Climate
(PC) and Negative Climate (NC) dimensions of the CLASS observation protocol
that is widely used in educational research. ACORN uses convolutional neural
networks to analyze spectral audio features, the faces of teachers and
students, and the pixels of each image frame, and then integrates this
information over time using Temporal Convolutional Networks. The audiovisual
ACORN&#x27;s PC and NC predictions have Pearson correlations of $0.55$ and $0.63$
with ground-truth scores provided by expert CLASS coders on the UVA Toddler
dataset (cross-validation on $n&#x3D;300$ 15-min video segments), and a purely
auditory ACORN predicts PC and NC with correlations of $0.36$ and $0.41$ on the
MET dataset (test set of $n&#x3D;2000$ videos segments). These numbers are similar
to inter-coder reliability of human coders. Finally, using Graph Convolutional
Networks we make early strides (AUC&#x3D;$0.70$) toward predicting the specific
moments (45-90sec clips) when the PC is particularly weak/strong. Our findings
inform the design of automatic classroom observation and also more general
video activity recognition and summary recognition systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Aware Wavelet-based Detection of Morphed Face Images. (arXiv:2106.15686v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aghdaie_P/0/1/0/all/0/1">Poorya Aghdaie</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_B/0/1/0/all/0/1">Baaria Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1">Sobhan Soleymani</a>, <a href="http://arxiv.org/find/cs/1/au:+Dawson_J/0/1/0/all/0/1">Jeremy Dawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1">Nasser M. Nasrabadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15686">
                                    <div class="article-summary-box-inner">
                                        <span>Morphed images have exploited loopholes in the face recognition checkpoints,
e.g., Credential Authentication Technology (CAT), used by Transportation
Security Administration (TSA), which is a non-trivial security concern. To
overcome the risks incurred due to morphed presentations, we propose a
wavelet-based morph detection methodology which adopts an end-to-end trainable
soft attention mechanism . Our attention-based deep neural network (DNN)
focuses on the salient Regions of Interest (ROI) which have the most spatial
support for morph detector decision function, i.e, morph class binary softmax
output. A retrospective of morph synthesizing procedure aids us to speculate
the ROI as regions around facial landmarks , particularly for the case of
landmark-based morphing techniques. Moreover, our attention-based DNN is
adapted to the wavelet space, where inputs of the network are coarse-to-fine
spectral representations, 48 stacked wavelet sub-bands to be exact. We evaluate
performance of the proposed framework using three datasets, VISAPP17, LMA, and
MorGAN. In addition, as attention maps can be a robust indicator whether a
probe image under investigation is genuine or counterfeit, we analyze the
estimated attention maps for both a bona fide image and its corresponding
morphed image. Finally, we present an ablation study on the efficacy of
utilizing attention mechanism for the sake of morph detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Handgun detection using combined human pose and weapon appearance. (arXiv:2010.13753v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruiz_Santaquiteria_J/0/1/0/all/0/1">Jesus Ruiz-Santaquiteria</a>, <a href="http://arxiv.org/find/cs/1/au:+Velasco_Mata_A/0/1/0/all/0/1">Alberto Velasco-Mata</a>, <a href="http://arxiv.org/find/cs/1/au:+Vallez_N/0/1/0/all/0/1">Noelia Vallez</a>, <a href="http://arxiv.org/find/cs/1/au:+Bueno_G/0/1/0/all/0/1">Gloria Bueno</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_Garcia_J/0/1/0/all/0/1">Juan A. &#xc1;lvarez-Garc&#xed;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Deniz_O/0/1/0/all/0/1">Oscar Deniz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13753">
                                    <div class="article-summary-box-inner">
                                        <span>Closed-circuit television (CCTV) systems are essential nowadays to prevent
security threats or dangerous situations, in which early detection is crucial.
Novel deep learning-based methods have allowed to develop automatic weapon
detectors with promising results. However, these approaches are mainly based on
visual weapon appearance only. For handguns, body pose may be a useful cue,
especially in cases where the gun is barely visible. In this work, a novel
method is proposed to combine, in a single architecture, both weapon appearance
and human pose information. First, pose keypoints are estimated to extract hand
regions and generate binary pose images, which are the model inputs. Then, each
input is processed in different subnetworks and combined to produce the handgun
bounding box. Results obtained show that the combined model improves the
handgun detection state of the art, achieving from 4.23 to 18.9 AP points more
than the best previous approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DetCo: Unsupervised Contrastive Learning for Object Detection. (arXiv:2102.04803v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1">Jian Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_X/0/1/0/all/0/1">Xiaohang Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Hang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_P/0/1/0/all/0/1">Peize Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04803">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised contrastive learning achieves great success in learning image
representations with CNN. Unlike most recent methods that focused on improving
accuracy of image classification, we present a novel contrastive learning
approach, named DetCo, which fully explores the contrasts between global image
and local image patches to learn discriminative representations for object
detection. DetCo has several appealing benefits. (1) It is carefully designed
by investigating the weaknesses of current self-supervised methods, which
discard important representations for object detection. (2) DetCo builds
hierarchical intermediate contrastive losses between global image and local
patches to improve object detection, while maintaining global representations
for image recognition. Theoretical analysis shows that the local patches
actually remove the contextual information of an image, improving the lower
bound of mutual information for better contrastive learning. (3) Extensive
experiments on PASCAL VOC, COCO and Cityscapes demonstrate that DetCo not only
outperforms state-of-the-art methods on object detection, but also on
segmentation, pose estimation, and 3D shape prediction, while it is still
competitive on image classification. For example, on PASCAL VOC, DetCo-100ep
achieves 57.4 mAP, which is on par with the result of MoCov2-800ep. Moreover,
DetCo consistently outperforms supervised method by 1.6/1.2/1.0 AP on Mask
RCNN-C4/FPN/RetinaNet with 1x schedule. Code will be released at
\href{https://github.com/xieenze/DetCo}{\color{blue}{\tt
github.com/xieenze/DetCo}}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepLesionBrain: Towards a broader deep-learning generalization for multiple sclerosis lesion segmentation. (arXiv:2012.07950v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kamraoui_R/0/1/0/all/0/1">Reda Abdellah Kamraoui</a>, <a href="http://arxiv.org/find/eess/1/au:+Ta_V/0/1/0/all/0/1">Vinh-Thong Ta</a>, <a href="http://arxiv.org/find/eess/1/au:+Tourdias_T/0/1/0/all/0/1">Thomas Tourdias</a>, <a href="http://arxiv.org/find/eess/1/au:+Mansencal_B/0/1/0/all/0/1">Boris Mansencal</a>, <a href="http://arxiv.org/find/eess/1/au:+Manjon_J/0/1/0/all/0/1">Jos&#xe9; V Manjon</a>, <a href="http://arxiv.org/find/eess/1/au:+Coupe_P/0/1/0/all/0/1">Pierrick Coup&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07950">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, segmentation methods based on Convolutional Neural Networks (CNNs)
showed promising performance in automatic Multiple Sclerosis (MS) lesions
segmentation. These techniques have even outperformed human experts in
controlled evaluation conditions such as Longitudinal MS Lesion Segmentation
Challenge (ISBI Challenge). However state-of-the-art approaches trained to
perform well on highly-controlled datasets fail to generalize on clinical data
from unseen datasets. Instead of proposing another improvement of the
segmentation accuracy, we propose a novel method robust to domain shift and
performing well on unseen datasets, called DeepLesionBrain (DLB). This
generalization property results from three main contributions. First, DLB is
based on a large group of compact 3D CNNs. This spatially distributed strategy
ensures a robust prediction despite the risk of generalization failure of some
individual networks. Second, DLB includes a new image quality data augmentation
to reduce dependency to training data specificity (e.g., acquisition protocol).
Finally, to learn a more generalizable representation of MS lesions, we propose
a hierarchical specialization learning (HSL). HSL is performed by pre-training
a generic network over the whole brain, before using its weights as
initialization to locally specialized networks. By this end, DLB learns both
generic features extracted at global image level and specific features
extracted at local image level. DLB generalization was validated in
cross-dataset experiments on MSSEG&#x27;16, ISBI challenge, and in-house datasets.
During experiments, DLB showed higher segmentation accuracy, better
segmentation consistency and greater generalization performance compared to
state-of-the-art methods. Therefore, DLB offers a robust framework well-suited
for clinical practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FcaNet: Frequency Channel Attention Networks. (arXiv:2012.11879v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zequn Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Pengyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11879">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanism, especially channel attention, has gained great success
in the computer vision field. Many works focus on how to design efficient
channel attention mechanisms while ignoring a fundamental problem, i.e.,
channel attention mechanism uses scalar to represent channel, which is
difficult due to massive information loss. In this work, we start from a
different view and regard the channel representation problem as a compression
process using frequency analysis. Based on the frequency analysis, we
mathematically prove that the conventional global average pooling is a special
case of the feature decomposition in the frequency domain. With the proof, we
naturally generalize the compression of the channel attention mechanism in the
frequency domain and propose our method with multi-spectral channel attention,
termed as FcaNet. FcaNet is simple but effective. We can change a few lines of
code in the calculation to implement our method within existing channel
attention methods. Moreover, the proposed method achieves state-of-the-art
results compared with other channel attention methods on image classification,
object detection, and instance segmentation tasks. Our method could
consistently outperform the baseline SENet, with the same number of parameters
and the same computational cost. Our code and models will are publicly
available at https://github.com/cfzd/FcaNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mixed SIGNals: Sign Language Production via a Mixture of Motion Primitives. (arXiv:2107.11317v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saunders_B/0/1/0/all/0/1">Ben Saunders</a>, <a href="http://arxiv.org/find/cs/1/au:+Camgoz_N/0/1/0/all/0/1">Necati Cihan Camgoz</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowden_R/0/1/0/all/0/1">Richard Bowden</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11317">
                                    <div class="article-summary-box-inner">
                                        <span>It is common practice to represent spoken languages at their phonetic level.
However, for sign languages, this implies breaking motion into its constituent
motion primitives. Avatar based Sign Language Production (SLP) has
traditionally done just this, building up animation from sequences of hand
motions, shapes and facial expressions. However, more recent deep learning
based solutions to SLP have tackled the problem using a single network that
estimates the full skeletal structure.

We propose splitting the SLP task into two distinct jointly-trained
sub-tasks. The first translation sub-task translates from spoken language to a
latent sign language representation, with gloss supervision. Subsequently, the
animation sub-task aims to produce expressive sign language sequences that
closely resemble the learnt spatio-temporal representation. Using a progressive
transformer for the translation sub-task, we propose a novel Mixture of Motion
Primitives (MoMP) architecture for sign language animation. A set of distinct
motion primitives are learnt during training, that can be temporally combined
at inference to animate continuous sign language sequences.

We evaluate on the challenging RWTH-PHOENIX-Weather-2014T(PHOENIX14T)
dataset, presenting extensive ablation studies and showing that MoMP
outperforms baselines in user evaluations. We achieve state-of-the-art back
translation performance with an 11% improvement over competing results.
Importantly, and for the first time, we showcase stronger performance for a
full translation pipeline going from spoken language to sign, than from gloss
to sign.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why Approximate Matrix Square Root Outperforms Accurate SVD in Global Covariance Pooling?. (arXiv:2105.02498v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yue Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02498">
                                    <div class="article-summary-box-inner">
                                        <span>Global covariance pooling (GCP) aims at exploiting the second-order
statistics of the convolutional feature. Its effectiveness has been
demonstrated in boosting the classification performance of Convolutional Neural
Networks (CNNs). Singular Value Decomposition (SVD) is used in GCP to compute
the matrix square root. However, the approximate matrix square root calculated
using Newton-Schulz iteration \cite{li2018towards} outperforms the accurate one
computed via SVD \cite{li2017second}. We empirically analyze the reason behind
the performance gap from the perspectives of data precision and gradient
smoothness. Various remedies for computing smooth SVD gradients are
investigated. Based on our observation and analyses, a hybrid training protocol
is proposed for SVD-based GCP meta-layers such that competitive performances
can be achieved against Newton-Schulz iteration. Moreover, we propose a new GCP
meta-layer that uses SVD in the forward pass, and Pad\&#x27;e Approximants in the
backward propagation to compute the gradients. The proposed meta-layer has been
integrated into different CNN models and achieves state-of-the-art performances
on both large-scale and fine-grained datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning A Single Network for Scale-Arbitrary Super-Resolution. (arXiv:2004.03791v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Longguang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yingqian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zaiping Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jungang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+An_W/0/1/0/all/0/1">Wei An</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yulan Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.03791">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, the performance of single image super-resolution (SR) has been
significantly improved with powerful networks. However, these networks are
developed for image SR with a single specific integer scale (e.g., x2;x3,x4),
and cannot be used for non-integer and asymmetric SR. In this paper, we propose
to learn a scale-arbitrary image SR network from scale-specific networks.
Specifically, we propose a plug-in module for existing SR networks to perform
scale-arbitrary SR, which consists of multiple scale-aware feature adaption
blocks and a scale-aware upsampling layer. Moreover, we introduce a scale-aware
knowledge transfer paradigm to transfer knowledge from scale-specific networks
to the scale-arbitrary network. Our plug-in module can be easily adapted to
existing networks to achieve scale-arbitrary SR. These networks plugged with
our module can achieve promising results for non-integer and asymmetric SR
while maintaining state-of-the-art performance for SR with integer scale
factors. Besides, the additional computational and memory cost of our module is
very small.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Domain Adaptive 3D Detection with Multi-Level Consistency. (arXiv:2107.11355v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhipeng Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_Z/0/1/0/all/0/1">Zhongang Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Changqing Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gongjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Haiyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Shuai Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shanghang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11355">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning-based 3D object detection has achieved unprecedented success
with the advent of large-scale autonomous driving datasets. However, drastic
performance degradation remains a critical challenge for cross-domain
deployment. In addition, existing 3D domain adaptive detection methods often
assume prior access to the target domain annotations, which is rarely feasible
in the real world. To address this challenge, we study a more realistic
setting, unsupervised 3D domain adaptive detection, which only utilizes source
domain annotations. 1) We first comprehensively investigate the major
underlying factors of the domain gap in 3D detection. Our key insight is that
geometric mismatch is the key factor of domain shift. 2) Then, we propose a
novel and unified framework, Multi-Level Consistency Network (MLC-Net), which
employs a teacher-student paradigm to generate adaptive and reliable
pseudo-targets. MLC-Net exploits point-, instance- and neural statistics-level
consistency to facilitate cross-domain transfer. Extensive experiments
demonstrate that MLC-Net outperforms existing state-of-the-art methods
(including those using additional target domain information) on standard
benchmarks. Notably, our approach is detector-agnostic, which achieves
consistent gains on both single- and two-stage 3D detectors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dense Supervision Propagation for Weakly Supervised Semantic Segmentation on 3D Point Clouds. (arXiv:2107.11267v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jiacheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guosheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yap_K/0/1/0/all/0/1">Kim-Hui Yap</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Fayao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hung_T/0/1/0/all/0/1">Tzu-Yi Hung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11267">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic segmentation on 3D point clouds is an important task for 3D scene
understanding. While dense labeling on 3D data is expensive and time-consuming,
only a few works address weakly supervised semantic point cloud segmentation
methods to relieve the labeling cost by learning from simpler and cheaper
labels. Meanwhile, there are still huge performance gaps between existing
weakly supervised methods and state-of-the-art fully supervised methods. In
this paper, we train a semantic point cloud segmentation network with only a
small portion of points being labeled. We argue that we can better utilize the
limited supervision information as we densely propagate the supervision signal
from the labeled points to other points within and across the input samples.
Specifically, we propose a cross-sample feature reallocating module to transfer
similar features and therefore re-route the gradients across two samples with
common classes and an intra-sample feature redistribution module to propagate
supervision signals on unlabeled points across and within point cloud samples.
We conduct extensive experiments on public datasets S3DIS and ScanNet. Our
weakly supervised method with only 10\% and 1\% of labels can produce
compatible results with the fully supervised counterpart.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study of the 2019 Indian Election on WhatsApp. (arXiv:2106.04726v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1">Ashkan Kazemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1">Kiran Garimella</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahi_G/0/1/0/all/0/1">Gautam Kishore Shahi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1">Devin Gaffney</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.04726">
                                    <div class="article-summary-box-inner">
                                        <span>There is currently no easy way to fact-check content on WhatsApp and other
end-to-end encrypted platforms at scale. In this paper, we analyze the
usefulness of a crowd-sourced &quot;tipline&quot; through which users can submit content
(&quot;tips&quot;) that they want fact-checked. We compare the tips sent to a WhatsApp
tipline run during the 2019 Indian national elections with the messages
circulating in large, public groups on WhatsApp and other social media
platforms during the same period. We find that tiplines are a very useful lens
into WhatsApp conversations: a significant fraction of messages and images sent
to the tipline match with the content being shared on public WhatsApp groups
and other social media. Our analysis also shows that tiplines cover the most
popular content well, and a majority of such content is often shared to the
tipline before appearing in large, public WhatsApp groups. Overall, our
findings suggest tiplines can be an effective source for discovering content to
fact-check.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessing bikeability with street view imagery and computer vision. (arXiv:2105.08499v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ito_K/0/1/0/all/0/1">Koichi Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Biljecki_F/0/1/0/all/0/1">Filip Biljecki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08499">
                                    <div class="article-summary-box-inner">
                                        <span>Studies evaluating bikeability usually compute spatial indicators shaping
cycling conditions and conflate them in a quantitative index. Much research
involves site visits or conventional geospatial approaches, and few studies
have leveraged street view imagery (SVI) for conducting virtual audits. These
have assessed a limited range of aspects, and not all have been automated using
computer vision (CV). Furthermore, studies have not yet zeroed in on gauging
the usability of these technologies thoroughly. We investigate, with
experiments at a fine spatial scale and across multiple geographies (Singapore
and Tokyo), whether we can use SVI and CV to assess bikeability
comprehensively. Extending related work, we develop an exhaustive index of
bikeability composed of 34 indicators. The results suggest that SVI and CV are
adequate to evaluate bikeability in cities comprehensively. As they
outperformed non-SVI counterparts by a wide margin, SVI indicators are also
found to be superior in assessing urban bikeability, and potentially can be
used independently, replacing traditional techniques. However, the paper
exposes some limitations, suggesting that the best way forward is combining
both SVI and non-SVI approaches. The new bikeability index presents a
contribution in transportation and urban analytics, and it is scalable to
assess cycling appeal widely.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human Pose Regression with Residual Log-likelihood Estimation. (arXiv:2107.11291v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiefeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_S/0/1/0/all/0/1">Siyuan Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Ailing Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Can Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1">Bo Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wentao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Cewu Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11291">
                                    <div class="article-summary-box-inner">
                                        <span>Heatmap-based methods dominate in the field of human pose estimation by
modelling the output distribution through likelihood heatmaps. In contrast,
regression-based methods are more efficient but suffer from inferior
performance. In this work, we explore maximum likelihood estimation (MLE) to
develop an efficient and effective regression-based methods. From the
perspective of MLE, adopting different regression losses is making different
assumptions about the output density function. A density function closer to the
true distribution leads to a better regression performance. In light of this,
we propose a novel regression paradigm with Residual Log-likelihood Estimation
(RLE) to capture the underlying output distribution. Concretely, RLE learns the
change of the distribution instead of the unreferenced underlying distribution
to facilitate the training process. With the proposed reparameterization
design, our method is compatible with off-the-shelf flow models. The proposed
method is effective, efficient and flexible. We show its potential in various
human pose estimation tasks with comprehensive experiments. Compared to the
conventional regression paradigm, regression with RLE bring 12.4 mAP
improvement on MSCOCO without any test-time overhead. Moreover, for the first
time, especially on multi-person pose estimation, our regression method is
superior to the heatmap-based methods. Our code is available at
https://github.com/Jeff-sjtu/res-loglikelihood-regression</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SurfaceNet: Adversarial SVBRDF Estimation from a Single Image. (arXiv:2107.11298v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vecchio_G/0/1/0/all/0/1">Giuseppe Vecchio</a>, <a href="http://arxiv.org/find/cs/1/au:+Palazzo_S/0/1/0/all/0/1">Simone Palazzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Spampinato_C/0/1/0/all/0/1">Concetto Spampinato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11298">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present SurfaceNet, an approach for estimating
spatially-varying bidirectional reflectance distribution function (SVBRDF)
material properties from a single image. We pose the problem as an image
translation task and propose a novel patch-based generative adversarial network
(GAN) that is able to produce high-quality, high-resolution surface reflectance
maps. The employment of the GAN paradigm has a twofold objective: 1) allowing
the model to recover finer details than standard translation models; 2)
reducing the domain shift between synthetic and real data distributions in an
unsupervised way. An extensive evaluation, carried out on a public benchmark of
synthetic and real images under different illumination conditions, shows that
SurfaceNet largely outperforms existing SVBRDF reconstruction methods, both
quantitatively and qualitatively. Furthermore, SurfaceNet exhibits a remarkable
ability in generating high-quality maps from real samples without any
supervision at training time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Longitudinal Quantitative Assessment of COVID-19 Infection Progression from Chest CTs. (arXiv:2103.07240v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kim_S/0/1/0/all/0/1">Seong Tae Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Goli_L/0/1/0/all/0/1">Leili Goli</a>, <a href="http://arxiv.org/find/eess/1/au:+Paschali_M/0/1/0/all/0/1">Magdalini Paschali</a>, <a href="http://arxiv.org/find/eess/1/au:+Khakzar_A/0/1/0/all/0/1">Ashkan Khakzar</a>, <a href="http://arxiv.org/find/eess/1/au:+Keicher_M/0/1/0/all/0/1">Matthias Keicher</a>, <a href="http://arxiv.org/find/eess/1/au:+Czempiel_T/0/1/0/all/0/1">Tobias Czempiel</a>, <a href="http://arxiv.org/find/eess/1/au:+Burian_E/0/1/0/all/0/1">Egon Burian</a>, <a href="http://arxiv.org/find/eess/1/au:+Braren_R/0/1/0/all/0/1">Rickmer Braren</a>, <a href="http://arxiv.org/find/eess/1/au:+Navab_N/0/1/0/all/0/1">Nassir Navab</a>, <a href="http://arxiv.org/find/eess/1/au:+Wendler_T/0/1/0/all/0/1">Thomas Wendler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07240">
                                    <div class="article-summary-box-inner">
                                        <span>Chest computed tomography (CT) has played an essential diagnostic role in
assessing patients with COVID-19 by showing disease-specific image features
such as ground-glass opacity and consolidation. Image segmentation methods have
proven to help quantify the disease burden and even help predict the outcome.
The availability of longitudinal CT series may also result in an efficient and
effective method to reliably assess the progression of COVID-19, monitor the
healing process and the response to different therapeutic strategies. In this
paper, we propose a new framework to identify infection at a voxel level
(identification of healthy lung, consolidation, and ground-glass opacity) and
visualize the progression of COVID-19 using sequential low-dose non-contrast CT
scans. In particular, we devise a longitudinal segmentation network that
utilizes the reference scan information to improve the performance of disease
identification. Experimental results on a clinical longitudinal dataset
collected in our institution show the effectiveness of the proposed method
compared to the static deep neural networks for disease quantification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ax-BxP: Approximate Blocked Computation for Precision-Reconfigurable Deep Neural Network Acceleration. (arXiv:2011.13000v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elangovan_R/0/1/0/all/0/1">Reena Elangovan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Shubham Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1">Anand Raghunathan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13000">
                                    <div class="article-summary-box-inner">
                                        <span>Precision scaling has emerged as a popular technique to optimize the compute
and storage requirements of Deep Neural Networks (DNNs). Efforts toward
creating ultra-low-precision (sub-8-bit) DNNs suggest that the minimum
precision required to achieve a given network-level accuracy varies
considerably across networks, and even across layers within a network,
requiring support for variable precision in DNN hardware. Previous proposals
such as bit-serial hardware incur high overheads, significantly diminishing the
benefits of lower precision. To efficiently support precision
re-configurability in DNN accelerators, we introduce an approximate computing
method wherein DNN computations are performed block-wise (a block is a group of
bits) and re-configurability is supported at the granularity of blocks. Results
of block-wise computations are composed in an approximate manner to enable
efficient re-configurability. We design a DNN accelerator that embodies
approximate blocked computation and propose a method to determine a suitable
approximation configuration for a given DNN. By varying the approximation
configurations across DNNs, we achieve 1.17x-1.73x and 1.02x-2.04x improvement
in system energy and performance respectively, over an 8-bit fixed-point (FxP8)
baseline, with negligible loss in classification accuracy. Further, by varying
the approximation configurations across layers and data-structures within DNNs,
we achieve 1.25x-2.42x and 1.07x-2.95x improvement in system energy and
performance respectively, with negligible accuracy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Standardized Max Logits: A Simple yet Effective Approach for Identifying Unexpected Road Obstacles in Urban-Scene Segmentation. (arXiv:2107.11264v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jung_S/0/1/0/all/0/1">Sanghun Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jungsoo Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Gwak_D/0/1/0/all/0/1">Daehoon Gwak</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1">Sungha Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jaegul Choo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11264">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying unexpected objects on roads in semantic segmentation (e.g.,
identifying dogs on roads) is crucial in safety-critical applications. Existing
approaches use images of unexpected objects from external datasets or require
additional training (e.g., retraining segmentation networks or training an
extra network), which necessitate a non-trivial amount of labor intensity or
lengthy inference time. One possible alternative is to use prediction scores of
a pre-trained network such as the max logits (i.e., maximum values among
classes before the final softmax layer) for detecting such objects. However,
the distribution of max logits of each predicted class is significantly
different from each other, which degrades the performance of identifying
unexpected objects in urban-scene segmentation. To address this issue, we
propose a simple yet effective approach that standardizes the max logits in
order to align the different distributions and reflect the relative meanings of
max logits within each predicted class. Moreover, we consider the local regions
from two different perspectives based on the intuition that neighboring pixels
share similar semantic information. In contrast to previous approaches, our
method does not utilize any external datasets or require additional training,
which makes our method widely applicable to existing pre-trained segmentation
models. Such a straightforward approach achieves a new state-of-the-art
performance on the publicly available Fishyscapes Lost &amp; Found leaderboard with
a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tackling the Overestimation of Forest Carbon with Deep Learning and Aerial Imagery. (arXiv:2107.11320v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reiersen_G/0/1/0/all/0/1">Gyri Reiersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dao_D/0/1/0/all/0/1">David Dao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1">Bj&#xf6;rn L&#xfc;tjens</a>, <a href="http://arxiv.org/find/cs/1/au:+Klemmer_K/0/1/0/all/0/1">Konstantin Klemmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoxiang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11320">
                                    <div class="article-summary-box-inner">
                                        <span>Forest carbon offsets are increasingly popular and can play a significant
role in financing climate mitigation, forest conservation, and reforestation.
Measuring how much carbon is stored in forests is, however, still largely done
via expensive, time-consuming, and sometimes unaccountable field measurements.
To overcome these limitations, many verification bodies are leveraging machine
learning (ML) algorithms to estimate forest carbon from satellite or aerial
imagery. Aerial imagery allows for tree species or family classification, which
improves the satellite imagery-based forest type classification. However,
aerial imagery is significantly more expensive to collect and it is unclear by
how much the higher resolution improves the forest carbon estimation. This
proposal paper describes the first systematic comparison of forest carbon
estimation from aerial imagery, satellite imagery, and ground-truth field
measurements via deep learning-based algorithms for a tropical reforestation
project. Our initial results show that forest carbon estimates from satellite
imagery can overestimate above-ground biomass by more than 10-times for
tropical reforestation projects. The significant difference between aerial and
satellite-derived forest carbon measurements shows the potential for aerial
imagery-based ML algorithms and raises the importance to extend this study to a
global benchmark between options for carbon measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provident Vehicle Detection at Night for Advanced Driver Assistance Systems. (arXiv:2107.11302v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ewecker_L/0/1/0/all/0/1">Lukas Ewecker</a>, <a href="http://arxiv.org/find/cs/1/au:+Asan_E/0/1/0/all/0/1">Ebubekir Asan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ohnemus_L/0/1/0/all/0/1">Lars Ohnemus</a>, <a href="http://arxiv.org/find/cs/1/au:+Saralajew_S/0/1/0/all/0/1">Sascha Saralajew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11302">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, computer vision algorithms have become more and more
powerful, which enabled technologies such as autonomous driving to evolve with
rapid pace. However, current algorithms mainly share one limitation: They rely
on directly visible objects. This is a major drawback compared to human
behavior, where indirect visual cues caused by the actual object (e.g.,
shadows) are already used intuitively to retrieve information or anticipate
occurring objects. While driving at night, this performance deficit becomes
even more obvious: Humans already process the light artifacts caused by
oncoming vehicles to assume their future appearance, whereas current object
detection systems rely on the oncoming vehicle&#x27;s direct visibility. Based on
previous work in this subject, we present with this paper a complete system
capable of solving the task to providently detect oncoming vehicles at
nighttime based on their caused light artifacts. For that, we outline the full
algorithm architecture ranging from the detection of light artifacts in the
image space, localizing the objects in the three-dimensional space, and
verifying the objects over time. To demonstrate the applicability, we deploy
the system in a test vehicle and use the information of providently detected
vehicles to control the glare-free high beam system proactively. Using this
experimental setting, we quantify the time benefit that the provident vehicle
detection system provides compared to an in-production computer vision system.
Additionally, the glare-free high beam use case provides a real-time and
real-world visualization interface of the detection results. With this
contribution, we want to put awareness on the unconventional sensing task of
provident object detection and further close the performance gap between human
behavior and computer vision algorithms in order to bring autonomous and
automated driving a step forward.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Re-distributing Biased Pseudo Labels for Semi-supervised Semantic Segmentation: A Baseline Investigation. (arXiv:2107.11279v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_R/0/1/0/all/0/1">Ruifei He</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jihan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_X/0/1/0/all/0/1">Xiaojuan Qi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11279">
                                    <div class="article-summary-box-inner">
                                        <span>While self-training has advanced semi-supervised semantic segmentation, it
severely suffers from the long-tailed class distribution on real-world semantic
segmentation datasets that make the pseudo-labeled data bias toward majority
classes. In this paper, we present a simple and yet effective Distribution
Alignment and Random Sampling (DARS) method to produce unbiased pseudo labels
that match the true class distribution estimated from the labeled data.
Besides, we also contribute a progressive data augmentation and labeling
strategy to facilitate model training with pseudo-labeled data. Experiments on
both Cityscapes and PASCAL VOC 2012 datasets demonstrate the effectiveness of
our approach. Albeit simple, our method performs favorably in comparison with
state-of-the-art approaches. Code will be available at
https://github.com/CVMI-Lab/DARS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image-to-Image Translation with Low Resolution Conditioning. (arXiv:2107.11262v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abid_M/0/1/0/all/0/1">Mohamed Abderrahmen Abid</a>, <a href="http://arxiv.org/find/cs/1/au:+Hedhli_I/0/1/0/all/0/1">Ihsen Hedhli</a>, <a href="http://arxiv.org/find/cs/1/au:+Lalonde_J/0/1/0/all/0/1">Jean-Fran&#xe7;ois Lalonde</a>, <a href="http://arxiv.org/find/cs/1/au:+Gagne_C/0/1/0/all/0/1">Christian Gagne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11262">
                                    <div class="article-summary-box-inner">
                                        <span>Most image-to-image translation methods focus on learning mappings across
domains with the assumption that images share content (e.g., pose) but have
their own domain-specific information known as style. When conditioned on a
target image, such methods aim to extract the style of the target and combine
it with the content of the source image. In this work, we consider the scenario
where the target image has a very low resolution. More specifically, our
approach aims at transferring fine details from a high resolution (HR) source
image to fit a coarse, low resolution (LR) image representation of the target.
We therefore generate HR images that share features from both HR and LR inputs.
This differs from previous methods that focus on translating a given image
style into a target content, our translation approach being able to
simultaneously imitate the style and merge the structural information of the LR
target. Our approach relies on training the generative model to produce HR
target images that both 1) share distinctive information of the associated
source image; 2) correctly match the LR target image when downscaled. We
validate our method on the CelebA-HQ and AFHQ datasets by demonstrating
improvements in terms of visual quality, diversity and coverage. Qualitative
and quantitative results show that when dealing with intra-domain image
translation, our method generates more realistic samples compared to
state-of-the-art methods such as Stargan-v2</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Reinforced Instruction Attacker for Robust Vision-Language Navigation. (arXiv:2107.11252v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bingqian Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yanxin Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qixiang Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1">Liang Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11252">
                                    <div class="article-summary-box-inner">
                                        <span>Language instruction plays an essential role in the natural language grounded
navigation tasks. However, navigators trained with limited human-annotated
instructions may have difficulties in accurately capturing key information from
the complicated instruction at different timesteps, leading to poor navigation
performance. In this paper, we exploit to train a more robust navigator which
is capable of dynamically extracting crucial factors from the long instruction,
by using an adversarial attacking paradigm. Specifically, we propose a Dynamic
Reinforced Instruction Attacker (DR-Attacker), which learns to mislead the
navigator to move to the wrong target by destroying the most instructive
information in instructions at different timesteps. By formulating the
perturbation generation as a Markov Decision Process, DR-Attacker is optimized
by the reinforcement learning algorithm to generate perturbed instructions
sequentially during the navigation, according to a learnable attack score.
Then, the perturbed instructions, which serve as hard samples, are used for
improving the robustness of the navigator with an effective adversarial
training strategy and an auxiliary self-supervised reasoning task. Experimental
results on both Vision-and-Language Navigation (VLN) and Navigation from Dialog
History (NDH) tasks show the superiority of our proposed method over
state-of-the-art methods. Moreover, the visualization analysis shows the
effectiveness of the proposed DR-Attacker, which can successfully attack
crucial information in the instructions at different timesteps. Code is
available at https://github.com/expectorlin/DR-Attacker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human Pose Estimation from Sparse Inertial Measurements through Recurrent Graph Convolution. (arXiv:2107.11214v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puchert_P/0/1/0/all/0/1">Patrik Puchert</a>, <a href="http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1">Timo Ropinski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11214">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the adjacency adaptive graph convolutional long-short term memory
network (AAGC-LSTM) for human pose estimation from sparse inertial
measurements, obtained from only 6 measurement units. The AAGC-LSTM combines
both spatial and temporal dependency in a single network operation. This is
made possible by equipping graph convolutions with adjacency adaptivity, which
also allows for learning unknown dependencies of the human body joints. To
further boost accuracy, we propose longitudinal loss weighting to consider
natural movement patterns, as well as body-aware contralateral data
augmentation. By combining these contributions, we are able to utilize the
inherent graph nature of the human body, and can thus outperform the state of
the art for human pose estimation from sparse inertial measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Deep Registration Latent Spaces. (arXiv:2107.11238v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Estienne_T/0/1/0/all/0/1">Th&#xe9;o Estienne</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakalopoulou_M/0/1/0/all/0/1">Maria Vakalopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Christodoulidis_S/0/1/0/all/0/1">Stergios Christodoulidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Battistella_E/0/1/0/all/0/1">Enzo Battistella</a>, <a href="http://arxiv.org/find/cs/1/au:+Henry_T/0/1/0/all/0/1">Th&#xe9;ophraste Henry</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerousseau_M/0/1/0/all/0/1">Marvin Lerousseau</a>, <a href="http://arxiv.org/find/cs/1/au:+Leroy_A/0/1/0/all/0/1">Amaury Leroy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chassagnon_G/0/1/0/all/0/1">Guillaume Chassagnon</a>, <a href="http://arxiv.org/find/cs/1/au:+Revel_M/0/1/0/all/0/1">Marie-Pierre Revel</a>, <a href="http://arxiv.org/find/cs/1/au:+Paragios_N/0/1/0/all/0/1">Nikos Paragios</a>, <a href="http://arxiv.org/find/cs/1/au:+Deutsch_E/0/1/0/all/0/1">Eric Deutsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11238">
                                    <div class="article-summary-box-inner">
                                        <span>Explainability of deep neural networks is one of the most challenging and
interesting problems in the field. In this study, we investigate the topic
focusing on the interpretability of deep learning-based registration methods.
In particular, with the appropriate model architecture and using a simple
linear projection, we decompose the encoding space, generating a new basis, and
we empirically show that this basis captures various decomposed anatomically
aware geometrical transformations. We perform experiments using two different
datasets focusing on lungs and hippocampus MRI. We show that such an approach
can decompose the highly convoluted latent spaces of registration pipelines in
an orthogonal space with several interesting properties. We hope that this work
could shed some light on a better understanding of deep learning-based
registration methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Modal Pedestrian Detection with Large Misalignment Based on Modal-Wise Regression and Multi-Modal IoU. (arXiv:2107.11196v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wanchaitanawong_N/0/1/0/all/0/1">Napat Wanchaitanawong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_M/0/1/0/all/0/1">Masayuki Tanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Shibata_T/0/1/0/all/0/1">Takashi Shibata</a>, <a href="http://arxiv.org/find/cs/1/au:+Okutomi_M/0/1/0/all/0/1">Masatoshi Okutomi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11196">
                                    <div class="article-summary-box-inner">
                                        <span>The combined use of multiple modalities enables accurate pedestrian detection
under poor lighting conditions by using the high visibility areas from these
modalities together. The vital assumption for the combination use is that there
is no or only a weak misalignment between the two modalities. In general,
however, this assumption often breaks in actual situations. Due to this
assumption&#x27;s breakdown, the position of the bounding boxes does not match
between the two modalities, resulting in a significant decrease in detection
accuracy, especially in regions where the amount of misalignment is large. In
this paper, we propose a multi-modal Faster-RCNN that is robust against large
misalignment. The keys are 1) modal-wise regression and 2) multi-modal IoU for
mini-batch sampling. To deal with large misalignment, we perform bounding box
regression for both the RPN and detection-head with both modalities. We also
propose a new sampling strategy called &quot;multi-modal mini-batch sampling&quot; that
integrates the IoU for both modalities. We demonstrate that the proposed
method&#x27;s performance is much better than that of the state-of-the-art methods
for data with large misalignment through actual image experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LARGE: Latent-Based Regression through GAN Semantics. (arXiv:2107.11186v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nitzan_Y/0/1/0/all/0/1">Yotam Nitzan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_R/0/1/0/all/0/1">Rinon Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Brenner_O/0/1/0/all/0/1">Ofir Brenner</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1">Daniel Cohen-Or</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11186">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel method for solving regression tasks using few-shot or weak
supervision. At the core of our method is the fundamental observation that GANs
are incredibly successful at encoding semantic information within their latent
space, even in a completely unsupervised setting. For modern generative
frameworks, this semantic encoding manifests as smooth, linear directions which
affect image attributes in a disentangled manner. These directions have been
widely used in GAN-based image editing. We show that such directions are not
only linear, but that the magnitude of change induced on the respective
attribute is approximately linear with respect to the distance traveled along
them. By leveraging this observation, our method turns a pre-trained GAN into a
regression model, using as few as two labeled samples. This enables solving
regression tasks on datasets and attributes which are difficult to produce
quality supervision for. Additionally, we show that the same latent-distances
can be used to sort collections of images by the strength of given attributes,
even in the absence of explicit supervision. Extensive experimental evaluations
demonstrate that our method can be applied across a wide range of domains,
leverage multiple latent direction discovery frameworks, and achieve
state-of-the-art results in few-shot and low-supervision settings, even when
compared to methods designed to tackle a single task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularising Inverse Problems with Generative Machine Learning Models. (arXiv:2107.11191v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Duff_M/0/1/0/all/0/1">Margaret Duff</a>, <a href="http://arxiv.org/find/eess/1/au:+Campbell_N/0/1/0/all/0/1">Neill D. F. Campbell</a>, <a href="http://arxiv.org/find/eess/1/au:+Ehrhardt_M/0/1/0/all/0/1">Matthias J. Ehrhardt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11191">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural network approaches to inverse imaging problems have produced
impressive results in the last few years. In this paper, we consider the use of
generative models in a variational regularisation approach to inverse problems.
The considered regularisers penalise images that are far from the range of a
generative model that has learned to produce images similar to a training
dataset. We name this family \textit{generative regularisers}. The success of
generative regularisers depends on the quality of the generative model and so
we propose a set of desired criteria to assess models and guide future
research. In our numerical experiments, we evaluate three common generative
models, autoencoders, variational autoencoders and generative adversarial
networks, against our desired criteria. We also test three different generative
regularisers on the inverse problems of deblurring, deconvolution, and
tomography. We show that the success of solutions restricted to lie exactly in
the range of the generator is highly dependent on the ability of the generative
model but that allowing small deviations from the range of the generator
produces more consistent results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Developing efficient transfer learning strategies for robust scene recognition in mobile robotics using pre-trained convolutional neural networks. (arXiv:2107.11187v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baumgartl_H/0/1/0/all/0/1">Hermann Baumgartl</a>, <a href="http://arxiv.org/find/cs/1/au:+Buettner_R/0/1/0/all/0/1">Ricardo Buettner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11187">
                                    <div class="article-summary-box-inner">
                                        <span>We present four different robust transfer learning and data augmentation
strategies for robust mobile scene recognition. By training three mobile-ready
(EfficientNetB0, MobileNetV2, MobileNetV3) and two large-scale baseline (VGG16,
ResNet50) convolutional neural network architectures on the widely available
Event8, Scene15, Stanford40, and MIT67 datasets, we show the generalization
ability of our transfer learning strategies. Furthermore, we tested the
robustness of our transfer learning strategies under viewpoint and lighting
changes using the KTH-Idol2 database. Also, the impact of inference
optimization techniques on the general performance and the robustness under
different transfer learning strategies is evaluated. Experimental results show
that when employing transfer learning, Fine-Tuning in combination with
extensive data augmentation improves the general accuracy and robustness in
mobile scene recognition. We achieved state-of-the-art results using various
baseline convolutional neural networks and showed the robustness against
lighting and viewpoint changes in challenging mobile robot place recognition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias Loss for Mobile Neural Networks. (arXiv:2107.11170v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abrahamyan_L/0/1/0/all/0/1">Lusine Abrahamyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziatchin_V/0/1/0/all/0/1">Valentin Ziatchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deligiannis_N/0/1/0/all/0/1">Nikos Deligiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11170">
                                    <div class="article-summary-box-inner">
                                        <span>Compact convolutional neural networks (CNNs) have witnessed exceptional
improvements in performance in recent years. However, they still fail to
provide the same predictive power as CNNs with a large number of parameters.
The diverse and even abundant features captured by the layers is an important
characteristic of these successful CNNs. However, differences in this
characteristic between large CNNs and their compact counterparts have rarely
been investigated. In compact CNNs, due to the limited number of parameters,
abundant features are unlikely to be obtained, and feature diversity becomes an
essential characteristic. Diverse features present in the activation maps
derived from a data point during model inference may indicate the presence of a
set of unique descriptors necessary to distinguish between objects of different
classes. In contrast, data points with low feature diversity may not provide a
sufficient amount of unique descriptors to make a valid prediction; we refer to
them as random predictions. Random predictions can negatively impact the
optimization process and harm the final performance. This paper proposes
addressing the problem raised by random predictions by reshaping the standard
cross-entropy to make it biased toward data points with a limited number of
unique descriptive features. Our novel Bias Loss focuses the training on a set
of valuable data points and prevents the vast number of samples with poor
learning features from misleading the optimization process. Furthermore, to
show the importance of diversity, we present a family of SkipNet models whose
architectures are brought to boost the number of unique descriptors in the last
layers. Our Skipnet-M can achieve 1% higher classification accuracy than
MobileNetV3 Large.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RGB Image Classification with Quantum Convolutional Ansaetze. (arXiv:2107.11099v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Jing_Y/0/1/0/all/0/1">Yu Jing</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yang_Y/0/1/0/all/0/1">Yang Yang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wu_C/0/1/0/all/0/1">Chonghang Wu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Fu_W/0/1/0/all/0/1">Wenbing Fu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Li_X/0/1/0/all/0/1">Xiaogang Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Xu_H/0/1/0/all/0/1">Hua Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11099">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid growth of qubit numbers and coherence times in quantum
hardware technology, implementing shallow neural networks on the so-called
Noisy Intermediate-Scale Quantum (NISQ) devices has attracted a lot of
interest. Many quantum (convolutional) circuit ansaetze are proposed for
grayscale images classification tasks with promising empirical results.
However, when applying these ansaetze on RGB images, the intra-channel
information that is useful for vision tasks is not extracted effectively. In
this paper, we propose two types of quantum circuit ansaetze to simulate
convolution operations on RGB images, which differ in the way how inter-channel
and intra-channel information are extracted. To the best of our knowledge, this
is the first work of a quantum convolutional circuit to deal with RGB images
effectively, with a higher test accuracy compared to the purely classical CNNs.
We also investigate the relationship between the size of quantum circuit ansatz
and the learnability of the hybrid quantum-classical convolutional neural
network. Through experiments based on CIFAR-10 and MNIST datasets, we
demonstrate that a larger size of the quantum circuit ansatz improves
predictive performance in multiclass classification tasks, providing useful
insights for near term quantum algorithm developments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unrealistic Feature Suppression for Generative Adversarial Networks. (arXiv:2107.11047v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sanghun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">SeungKyu Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11047">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the unstable nature of minimax game between generator and
discriminator, improving the performance of GANs is a challenging task. Recent
studies have shown that selected high-quality samples in training improve the
performance of GANs. However, sampling approaches which discard samples show
limitations in some aspects such as the speed of training and optimality of the
networks. In this paper we propose unrealistic feature suppression (UFS) module
that keeps high-quality features and suppresses unrealistic features. UFS
module keeps the training stability of networks and improves the quality of
generated images. We demonstrate the effectiveness of UFS module on various
models such as WGAN-GP, SNGAN, and BigGAN. By using UFS module, we achieved
better Frechet inception distance and inception score compared to various
baseline models. We also visualize how effectively our UFS module suppresses
unrealistic features through class activation maps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WaveFill: A Wavelet-based Generation Network for Image Inpainting. (arXiv:2107.11027v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yingchen Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1">Fangneng Zhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1">Jianxiong Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1">Feiying Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xuansong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Chunyan Miao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11027">
                                    <div class="article-summary-box-inner">
                                        <span>Image inpainting aims to complete the missing or corrupted regions of images
with realistic contents. The prevalent approaches adopt a hybrid objective of
reconstruction and perceptual quality by using generative adversarial networks.
However, the reconstruction loss and adversarial loss focus on synthesizing
contents of different frequencies and simply applying them together often leads
to inter-frequency conflicts and compromised inpainting. This paper presents
WaveFill, a wavelet-based inpainting network that decomposes images into
multiple frequency bands and fills the missing regions in each frequency band
separately and explicitly. WaveFill decomposes images by using discrete wavelet
transform (DWT) that preserves spatial information naturally. It applies L1
reconstruction loss to the decomposed low-frequency bands and adversarial loss
to high-frequency bands, hence effectively mitigate inter-frequency conflicts
while completing images in spatial domain. To address the inpainting
inconsistency in different frequency bands and fuse features with distinct
statistics, we design a novel normalization scheme that aligns and fuses the
multi-frequency features effectively. Extensive experiments over multiple
datasets show that WaveFill achieves superior image inpainting qualitatively
and quantitatively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Discriminative Representations for Multi-Label Image Recognition. (arXiv:2107.11159v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hassanin_M/0/1/0/all/0/1">Mohammed Hassanin</a>, <a href="http://arxiv.org/find/cs/1/au:+Radwan_I/0/1/0/all/0/1">Ibrahim Radwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tahtali_M/0/1/0/all/0/1">Murat Tahtali</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11159">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-label recognition is a fundamental, and yet is a challenging task in
computer vision. Recently, deep learning models have achieved great progress
towards learning discriminative features from input images. However,
conventional approaches are unable to model the inter-class discrepancies among
features in multi-label images, since they are designed to work for image-level
feature discrimination. In this paper, we propose a unified deep network to
learn discriminative features for the multi-label task. Given a multi-label
image, the proposed method first disentangles features corresponding to
different classes. Then, it discriminates between these classes via increasing
the inter-class distance while decreasing the intra-class differences in the
output space. By regularizing the whole network with the proposed loss, the
performance of applying the wellknown ResNet-101 is improved significantly.
Extensive experiments have been performed on COCO-2014, VOC2007 and VOC2012
datasets, which demonstrate that the proposed method outperforms
state-of-the-art approaches by a significant margin of 3:5% on large-scale COCO
dataset. Moreover, analysis of the discriminative feature learning approach
shows that it can be plugged into various types of multi-label methods as a
general module.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Domain Adaptation for Video Semantic Segmentation. (arXiv:2107.11052v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shin_I/0/1/0/all/0/1">Inkyu Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1">Kwanyong Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_S/0/1/0/all/0/1">Sanghyun Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11052">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised Domain Adaptation for semantic segmentation has gained immense
popularity since it can transfer knowledge from simulation to real (Sim2Real)
by largely cutting out the laborious per pixel labeling efforts at real. In
this work, we present a new video extension of this task, namely Unsupervised
Domain Adaptation for Video Semantic Segmentation. As it became easy to obtain
large-scale video labels through simulation, we believe attempting to maximize
Sim2Real knowledge transferability is one of the promising directions for
resolving the fundamental data-hungry issue in the video. To tackle this new
problem, we present a novel two-phase adaptation scheme. In the first step, we
exhaustively distill source domain knowledge using supervised loss functions.
Simultaneously, video adversarial training (VAT) is employed to align the
features from source to target utilizing video context. In the second step, we
apply video self-training (VST), focusing only on the target data. To construct
robust pseudo labels, we exploit the temporal information in the video, which
has been rarely explored in the previous image-based self-training approaches.
We set strong baseline scores on &#x27;VIPER to CityscapeVPS&#x27; adaptation scenario.
We show that our proposals significantly outperform previous image-based UDA
methods both on image-level (mIoU) and video-level (VPQ) evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cardiac CT segmentation based on distance regularized level set. (arXiv:2107.11119v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wu_X/0/1/0/all/0/1">Xinyang Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11119">
                                    <div class="article-summary-box-inner">
                                        <span>Before analy z ing the CT image, it is very important to segment the heart
image, and the left ve ntricular (LV) inner and outer membrane segmentation is
one of the most important contents. However, manual segmentation is tedious and
time consuming. In order to facilitate doctors to focus on high tech tasks such
as disease analysis and diagnosis, it is crucial to develop a fast and accurate
segmentation method [1]. In view of this phenomenon, this paper uses distance
regularized level set (DRL SE) to explore the segmentation effect of epicardium
and endocardium 2 ]], which includes a distance regula riz ed t erm and an
external energy term. Finally, five CT images are used to verify the proposed
method, and image quality evaluation indexes such as dice score and Hausdorff
distance are used to evaluate the segmentation effect. The results showed that
the me tho d could separate the inner and outer membrane very well (endocardium
dice &#x3D; 0.9253, Hausdorff &#x3D; 7.8740; epicardium Hausdorff &#x3D; 0.9687, Hausdorff &#x3D; 6 .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Radar Velocity Maps for Uncertain Dynamic Environments. (arXiv:2107.11039v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Senanayake_R/0/1/0/all/0/1">Ransalu Senanayake</a>, <a href="http://arxiv.org/find/cs/1/au:+Hatch_K/0/1/0/all/0/1">Kyle Beltran Hatch</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1">Jason Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1">Mykel J. Kochenderfer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11039">
                                    <div class="article-summary-box-inner">
                                        <span>Future urban transportation concepts include a mixture of ground and air
vehicles with varying degrees of autonomy in a congested environment. In such
dynamic environments, occupancy maps alone are not sufficient for safe path
planning. Safe and efficient transportation requires reasoning about the 3D
flow of traffic and properly modeling uncertainty. Several different approaches
can be taken for developing 3D velocity maps. This paper explores a Bayesian
approach that captures our uncertainty in the map given training data. The
approach involves projecting spatial coordinates into a high-dimensional
feature space and then applying Bayesian linear regression to make predictions
and quantify uncertainty in our estimates. On a collection of air and ground
datasets, we demonstrate that this approach is effective and more scalable than
several alternative approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven deep density estimation. (arXiv:2107.11085v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puchert_P/0/1/0/all/0/1">Patrik Puchert</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermosilla_P/0/1/0/all/0/1">Pedro Hermosilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Ritschel_T/0/1/0/all/0/1">Tobias Ritschel</a>, <a href="http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1">Timo Ropinski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11085">
                                    <div class="article-summary-box-inner">
                                        <span>Density estimation plays a crucial role in many data analysis tasks, as it
infers a continuous probability density function (PDF) from discrete samples.
Thus, it is used in tasks as diverse as analyzing population data, spatial
locations in 2D sensor readings, or reconstructing scenes from 3D scans. In
this paper, we introduce a learned, data-driven deep density estimation (DDE)
to infer PDFs in an accurate and efficient manner, while being independent of
domain dimensionality or sample size. Furthermore, we do not require access to
the original PDF during estimation, neither in parametric form, nor as priors,
or in the form of many samples. This is enabled by training an unstructured
convolutional neural network on an infinite stream of synthetic PDFs, as
unbound amounts of synthetic training data generalize better across a deck of
natural PDFs than any natural finite training data will do. Thus, we hope that
our publicly available DDE method will be beneficial in many areas of data
analysis, where continuous models are to be estimated from discrete
observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Generalization of Meta-learning on Unseen Domains via Adversarial Shift. (arXiv:2107.11056v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_P/0/1/0/all/0/1">Pinzhuo Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yao Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11056">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning provides a promising way for learning to efficiently learn and
achieves great success in many applications. However, most meta-learning
literature focuses on dealing with tasks from a same domain, making it brittle
to generalize to tasks from the other unseen domains. In this work, we address
this problem by simulating tasks from the other unseen domains to improve the
generalization and robustness of meta-learning method. Specifically, we propose
a model-agnostic shift layer to learn how to simulate the domain shift and
generate pseudo tasks, and develop a new adversarial learning-to-learn
mechanism to train it. Based on the pseudo tasks, the meta-learning model can
learn cross-domain meta-knowledge, which can generalize well on unseen domains.
We conduct extensive experiments under the domain generalization setting.
Experimental results demonstrate that the proposed shift layer is applicable to
various meta-learning frameworks. Moreover, our method also leads to
state-of-the-art performance on different cross-domain few-shot classification
benchmarks and produces good results on cross-domain few-shot regression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Class-Incremental Domain Adaptation with Smoothing and Calibration for Surgical Report Generation. (arXiv:2107.11091v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mengya Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Mobarakol Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_C/0/1/0/all/0/1">Chwee Ming Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1">Hongliang Ren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11091">
                                    <div class="article-summary-box-inner">
                                        <span>Generating surgical reports aimed at surgical scene understanding in
robot-assisted surgery can contribute to documenting entry tasks and
post-operative analysis. Despite the impressive outcome, the deep learning
model degrades the performance when applied to different domains encountering
domain shifts. In addition, there are new instruments and variations in
surgical tissues appeared in robotic surgery. In this work, we propose
class-incremental domain adaptation (CIDA) with a multi-layer transformer-based
model to tackle the new classes and domain shift in the target domain to
generate surgical reports during robotic surgery. To adapt incremental classes
and extract domain invariant features, a class-incremental (CI) learning method
with supervised contrastive (SupCon) loss is incorporated with a feature
extractor. To generate caption from the extracted feature, curriculum by
one-dimensional gaussian smoothing (CBS) is integrated with a multi-layer
transformer-based caption prediction model. CBS smoothes the features embedding
using anti-aliasing and helps the model to learn domain invariant features. We
also adopt label smoothing (LS) to calibrate prediction probability and obtain
better feature representation with both feature extractor and captioning model.
The proposed techniques are empirically evaluated by using the datasets of two
surgical domains, such as nephrectomy operations and transoral robotic surgery.
We observe that domain invariant feature learning and the well-calibrated
network improves the surgical report generation performance in both source and
target domain under domain shift and unseen classes in the manners of one-shot
and few-shot learning. The code is publicly available at
https://github.com/XuMengyaAmy/CIDACaptioning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reservoir Computing Approach for Gray Images Segmentation. (arXiv:2107.11077v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koprinkova_Hristova_P/0/1/0/all/0/1">Petia Koprinkova-Hristova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11077">
                                    <div class="article-summary-box-inner">
                                        <span>The paper proposes a novel approach for gray scale images segmentation. It is
based on multiple features extraction from single feature per image pixel,
namely its intensity value, using Echo state network. The newly extracted
features -- reservoir equilibrium states -- reveal hidden image characteristics
that improve its segmentation via a clustering algorithm. Moreover, it was
demonstrated that the intrinsic plasticity tuning of reservoir fits its
equilibrium states to the original image intensity distribution thus allowing
for its better segmentation. The proposed approach is tested on the benchmark
image Lena.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Label Distribution Amendment with Emotional Semantic Correlations for Facial Expression Recognition. (arXiv:2107.11061v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mao_S/0/1/0/all/0/1">Shasha Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_G/0/1/0/all/0/1">Guanghui Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Licheng Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gou_S/0/1/0/all/0/1">Shuiping Gou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yangyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Lin Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1">Boxin Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11061">
                                    <div class="article-summary-box-inner">
                                        <span>By utilizing label distribution learning, a probability distribution is
assigned for a facial image to express a compound emotion, which effectively
improves the problem of label uncertainties and noises occurred in one-hot
labels. In practice, it is observed that correlations among emotions are
inherently different, such as surprised and happy emotions are more possibly
synchronized than surprised and neutral. It indicates the correlation may be
crucial for obtaining a reliable label distribution. Based on this, we propose
a new method that amends the label distribution of each facial image by
leveraging correlations among expressions in the semantic space. Inspired by
inherently diverse correlations among word2vecs, the topological information
among facial expressions is firstly explored in the semantic space, and each
image is embedded into the semantic space. Specially, a class-relation graph is
constructed to transfer the semantic correlation among expressions into the
task space. By comparing semantic and task class-relation graphs of each image,
the confidence of its label distribution is evaluated. Based on the confidence,
the label distribution is amended by enhancing samples with higher confidence
and weakening samples with lower confidence. Experimental results demonstrate
the proposed method is more effective than compared state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transporting Causal Mechanisms for Unsupervised Domain Adaptation. (arXiv:2107.11055v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yue_Z/0/1/0/all/0/1">Zhongqi Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanwang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1">Qianru Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xian-Sheng Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11055">
                                    <div class="article-summary-box-inner">
                                        <span>Existing Unsupervised Domain Adaptation (UDA) literature adopts the covariate
shift and conditional shift assumptions, which essentially encourage models to
learn common features across domains. However, due to the lack of supervision
in the target domain, they suffer from the semantic loss: the feature will
inevitably lose non-discriminative semantics in source domain, which is however
discriminative in target domain. We use a causal view -- transportability
theory -- to identify that such loss is in fact a confounding effect, which can
only be removed by causal intervention. However, the theoretical solution
provided by transportability is far from practical for UDA, because it requires
the stratification and representation of an unobserved confounder that is the
cause of the domain gap. To this end, we propose a practical solution:
Transporting Causal Mechanisms (TCM), to identify the confounder stratum and
representations by using the domain-invariant disentangled causal mechanisms,
which are discovered in an unsupervised fashion. Our TCM is both theoretically
and empirically grounded. Extensive experiments show that TCM achieves
state-of-the-art performance on three challenging UDA benchmarks: ImageCLEF-DA,
Office-Home, and VisDA-2017. Codes are available in Appendix.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Brain Reconstruction by Hierarchical Shape-Perception Network from a Single Incomplete Image. (arXiv:2107.11010v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hu_B/0/1/0/all/0/1">Bowen Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lei_B/0/1/0/all/0/1">Baiying Lei</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_Y/0/1/0/all/0/1">Yong Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Gan_M/0/1/0/all/0/1">Min Gan</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_B/0/1/0/all/0/1">Bingchuan Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_S/0/1/0/all/0/1">Shuqiang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11010">
                                    <div class="article-summary-box-inner">
                                        <span>3D shape reconstruction is essential in the navigation of minimally-invasive
and auto robot-guided surgeries whose operating environments are indirect and
narrow, and there have been some works that focused on reconstructing the 3D
shape of the surgical organ through limited 2D information available. However,
the lack and incompleteness of such information caused by intraoperative
emergencies (such as bleeding) and risk control conditions have not been
considered. In this paper, a novel hierarchical shape-perception network (HSPN)
is proposed to reconstruct the 3D point clouds (PCs) of specific brains from
one single incomplete image with low latency. A tree-structured predictor and
several hierarchical attention pipelines are constructed to generate point
clouds that accurately describe the incomplete images and then complete these
point clouds with high quality. Meanwhile, attention gate blocks (AGBs) are
designed to efficiently aggregate geometric local features of incomplete PCs
transmitted by hierarchical attention pipelines and internal features of
reconstructing point clouds. With the proposed HSPN, 3D shape perception and
completion can be achieved spontaneously. Comprehensive results measured by
Chamfer distance and PC-to-PC error demonstrate that the performance of the
proposed HSPN outperforms other competitive methods in terms of qualitative
displays, quantitative experiment, and classification evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MCDAL: Maximum Classifier Discrepancy for Active Learning. (arXiv:2107.11049v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jae Won Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong-Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_Y/0/1/0/all/0/1">Yunjae Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11049">
                                    <div class="article-summary-box-inner">
                                        <span>Recent state-of-the-art active learning methods have mostly leveraged
Generative Adversarial Networks (GAN) for sample acquisition; however, GAN is
usually known to suffer from instability and sensitivity to hyper-parameters.
In contrast to these methods, we propose in this paper a novel active learning
framework that we call Maximum Classifier Discrepancy for Active Learning
(MCDAL) which takes the prediction discrepancies between multiple classifiers.
In particular, we utilize two auxiliary classification layers that learn
tighter decision boundaries by maximizing the discrepancies among them.
Intuitively, the discrepancies in the auxiliary classification layers&#x27;
predictions indicate the uncertainty in the prediction. In this regard, we
propose a novel method to leverage the classifier discrepancies for the
acquisition function for active learning. We also provide an interpretation of
our idea in relation to existing GAN based active learning methods and domain
adaptation frameworks. Moreover, we empirically demonstrate the utility of our
approach where the performance of our approach exceeds the state-of-the-art
methods on several image classification and semantic segmentation datasets in
active learning setups.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AD-GAN: End-to-end Unsupervised Nuclei Segmentation with Aligned Disentangling Training. (arXiv:2107.11022v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yao_K/0/1/0/all/0/1">Kai Yao</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Jie Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Jude_C/0/1/0/all/0/1">Curran Jude</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11022">
                                    <div class="article-summary-box-inner">
                                        <span>We consider unsupervised cell nuclei segmentation in this paper. Exploiting
the recently-proposed unpaired image-to-image translation between cell nuclei
images and randomly synthetic masks, existing approaches, e.g., CycleGAN, have
achieved encouraging results. However, these methods usually take a two-stage
pipeline and fail to learn end-to-end in cell nuclei images. More seriously,
they could lead to the lossy transformation problem, i.e., the content
inconsistency between the original images and the corresponding segmentation
output. To address these limitations, we propose a novel end-to-end
unsupervised framework called Aligned Disentangling Generative Adversarial
Network (AD-GAN). Distinctively, AD-GAN introduces representation
disentanglement to separate content representation (the underling spatial
structure) from style representation (the rendering of the structure). With
this framework, spatial structure can be preserved explicitly, enabling a
significant reduction of macro-level lossy transformation. We also propose a
novel training algorithm able to align the disentangled content in the latent
space to reduce micro-level lossy transformation. Evaluations on real-world 2D
and 3D datasets show that AD-GAN substantially outperforms the other comparison
methods and the professional software both quantitatively and qualitatively.
Specifically, the proposed AD-GAN leads to significant improvement over the
current best unsupervised methods by an average 17.8% relatively (w.r.t. the
metric DICE) on four cell nuclei datasets. As an unsupervised method, AD-GAN
even performs competitive with the best supervised models, taking a further
leap towards end-to-end unsupervised nuclei segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Integrating Deep Learning and Augmented Reality to Enhance Situational Awareness in Firefighting Environments. (arXiv:2107.11043v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhattarai_M/0/1/0/all/0/1">Manish Bhattarai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11043">
                                    <div class="article-summary-box-inner">
                                        <span>We present a new four-pronged approach to build firefighter&#x27;s situational
awareness for the first time in the literature. We construct a series of deep
learning frameworks built on top of one another to enhance the safety,
efficiency, and successful completion of rescue missions conducted by
firefighters in emergency first response settings. First, we used a deep
Convolutional Neural Network (CNN) system to classify and identify objects of
interest from thermal imagery in real-time. Next, we extended this CNN
framework for object detection, tracking, segmentation with a Mask RCNN
framework, and scene description with a multimodal natural language
processing(NLP) framework. Third, we built a deep Q-learning-based agent,
immune to stress-induced disorientation and anxiety, capable of making clear
navigation decisions based on the observed and stored facts in live-fire
environments. Finally, we used a low computational unsupervised learning
technique called tensor decomposition to perform meaningful feature extraction
for anomaly detection in real-time. With these ad-hoc deep learning structures,
we built the artificial intelligence system&#x27;s backbone for firefighters&#x27;
situational awareness. To bring the designed system into usage by firefighters,
we designed a physical structure where the processed results are used as inputs
in the creation of an augmented reality capable of advising firefighters of
their location and key features around them, which are vital to the rescue
operation at hand, as well as a path planning feature that acts as a virtual
guide to assist disoriented first responders in getting back to safety. When
combined, these four approaches present a novel approach to information
understanding, transfer, and synthesis that could dramatically improve
firefighter response and efficacy and reduce life loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RewriteNet: Realistic Scene Text Image Generation via Editing Text in Real-world Image. (arXiv:2107.11041v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Junyeop Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Yoonsik Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seonghyeon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Yim_M/0/1/0/all/0/1">Moonbin Yim</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_S/0/1/0/all/0/1">Seung Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Gayoung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sungrae Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11041">
                                    <div class="article-summary-box-inner">
                                        <span>Scene text editing (STE), which converts a text in a scene image into the
desired text while preserving an original style, is a challenging task due to a
complex intervention between text and style. To address this challenge, we
propose a novel representational learning-based STE model, referred to as
RewriteNet that employs textual information as well as visual information. We
assume that the scene text image can be decomposed into content and style
features where the former represents the text information and style represents
scene text characteristics such as font, alignment, and background. Under this
assumption, we propose a method to separately encode content and style features
of the input image by introducing the scene text recognizer that is trained by
text information. Then, a text-edited image is generated by combining the style
feature from the original image and the content feature from the target text.
Unlike previous works that are only able to use synthetic images in the
training phase, we also exploit real-world images by proposing a
self-supervised training scheme, which bridges the domain gap between synthetic
and real data. Our experiments demonstrate that RewriteNet achieves better
quantitative and qualitative performance than other comparisons. Moreover, we
validate that the use of text information and the self-supervised training
scheme improves text switching performance. The implementation and dataset will
be publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Proximal Unrolling Network for Compressive Sensing Imaging. (arXiv:2107.11007v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1">Yixiao Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Tao_R/0/1/0/all/0/1">Ran Tao</a>, <a href="http://arxiv.org/find/eess/1/au:+Wei_K/0/1/0/all/0/1">Kaixuan Wei</a>, <a href="http://arxiv.org/find/eess/1/au:+Fu_Y/0/1/0/all/0/1">Ying Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11007">
                                    <div class="article-summary-box-inner">
                                        <span>Recovering an underlying image from under-sampled measurements, Compressive
Sensing Imaging (CSI) is a challenging problem and has many practical
applications. Recently, deep neural networks have been applied to this problem
with promising results, owing to its implicitly learned prior to alleviate the
ill-poseness of CSI. However, existing neural network approaches require
separate models for each imaging parameter like sampling ratios, leading to
training difficulties and overfitting to specific settings. In this paper, we
present a dynamic proximal unrolling network (dubbed DPUNet), which can handle
a variety of measurement matrices via one single model without retraining.
Specifically, DPUNet can exploit both embedded physical model via gradient
descent and imposing image prior with learned dynamic proximal mapping leading
to joint reconstruction. A key component of DPUNet is a dynamic proximal
mapping module, whose parameters can be dynamically adjusted at inference stage
and make it adapt to any given imaging setting. Experimental results
demonstrate that the proposed DPUNet can effectively handle multiple CSI
modalities under varying sampling ratios and noise levels with only one model,
and outperform the state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Signed Directional Distance Function for Object Shape Representation. (arXiv:2107.11024v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zobeidi_E/0/1/0/all/0/1">Ehsan Zobeidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Atanasov_N/0/1/0/all/0/1">Nikolay Atanasov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11024">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks that map 3D coordinates to signed distance function (SDF) or
occupancy values have enabled high-fidelity implicit representations of object
shape. This paper develops a new shape model that allows synthesizing novel
distance views by optimizing a continuous signed directional distance function
(SDDF). Similar to deep SDF models, our SDDF formulation can represent whole
categories of shapes and complete or interpolate across shapes from partial
input data. Unlike an SDF, which measures distance to the nearest surface in
any direction, an SDDF measures distance in a given direction. This allows
training an SDDF model without 3D shape supervision, using only distance
measurements, readily available from depth camera or Lidar sensors. Our model
also removes post-processing steps like surface extraction or rendering by
directly predicting distance at arbitrary locations and viewing directions.
Unlike deep view-synthesis techniques, such as Neural Radiance Fields, which
train high-capacity black-box models, our model encodes by construction the
property that SDDF values decrease linearly along the viewing direction. This
structure constraint not only results in dimensionality reduction but also
provides analytical confidence about the accuracy of SDDF predictions,
regardless of the distance to the object surface.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Photon-Starved Scene Inference using Single Photon Cameras. (arXiv:2107.11001v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Goyal_B/0/1/0/all/0/1">Bhavya Goyal</a>, <a href="http://arxiv.org/find/eess/1/au:+Gupta_M/0/1/0/all/0/1">Mohit Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11001">
                                    <div class="article-summary-box-inner">
                                        <span>Scene understanding under low-light conditions is a challenging problem. This
is due to the small number of photons captured by the camera and the resulting
low signal-to-noise ratio (SNR). Single-photon cameras (SPCs) are an emerging
sensing modality that are capable of capturing images with high sensitivity.
Despite having minimal read-noise, images captured by SPCs in photon-starved
conditions still suffer from strong shot noise, preventing reliable scene
inference. We propose photon scale-space a collection of high-SNR images
spanning a wide range of photons-per-pixel (PPP) levels (but same scene
content) as guides to train inference model on low photon flux images. We
develop training techniques that push images with different illumination levels
closer to each other in feature representation space. The key idea is that
having a spectrum of different brightness levels during training enables
effective guidance, and increases robustness to shot noise even in extreme
noise cases. Based on the proposed approach, we demonstrate, via simulations
and real experiments with a SPAD camera, high-performance on various inference
tasks such as image classification and monocular depth estimation under ultra
low-light, down to &lt; 1 PPP.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SuperCaustics: Real-time, open-source simulation of transparent objects for deep learning applications. (arXiv:2107.11008v1 [cs.GR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mousavi_M/0/1/0/all/0/1">Mehdi Mousavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Estrada_R/0/1/0/all/0/1">Rolando Estrada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11008">
                                    <div class="article-summary-box-inner">
                                        <span>Transparent objects are a very challenging problem in computer vision. They
are hard to segment or classify due to their lack of precise boundaries, and
there is limited data available for training deep neural networks. As such,
current solutions for this problem employ rigid synthetic datasets, which lack
flexibility and lead to severe performance degradation when deployed on
real-world scenarios. In particular, these synthetic datasets omit features
such as refraction, dispersion and caustics due to limitations in the rendering
pipeline. To address this issue, we present SuperCaustics, a real-time,
open-source simulation of transparent objects designed for deep learning
applications. SuperCaustics features extensive modules for stochastic
environment creation; uses hardware ray-tracing to support caustics,
dispersion, and refraction; and enables generating massive datasets with
multi-modal, pixel-perfect ground truth annotations. To validate our proposed
system, we trained a deep neural network from scratch to segment transparent
objects in difficult lighting scenarios. Our neural network achieved
performance comparable to the state-of-the-art on a real-world dataset using
only 10% of the training data and in a fraction of the training time. Further
experiments show that a model trained with SuperCaustics can segment different
types of caustics, even in images with multiple overlapping transparent
objects. To the best of our knowledge, this is the first such result for a
model trained on synthetic data. Both our open-source code and experimental
data are freely available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptive Video Segmentation via Temporal Consistency Regularization. (arXiv:2107.11004v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1">Dayan Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiaxing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">Aoran Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11004">
                                    <div class="article-summary-box-inner">
                                        <span>Video semantic segmentation is an essential task for the analysis and
understanding of videos. Recent efforts largely focus on supervised video
segmentation by learning from fully annotated data, but the learnt models often
experience clear performance drop while applied to videos of a different
domain. This paper presents DA-VSN, a domain adaptive video segmentation
network that addresses domain gaps in videos by temporal consistency
regularization (TCR) for consecutive frames of target-domain videos. DA-VSN
consists of two novel and complementary designs. The first is cross-domain TCR
that guides the prediction of target frames to have similar temporal
consistency as that of source frames (learnt from annotated source data) via
adversarial learning. The second is intra-domain TCR that guides unconfident
predictions of target frames to have similar temporal consistency as confident
predictions of target frames. Extensive experiments demonstrate the superiority
of our proposed domain adaptive video segmentation network which outperforms
multiple baselines consistently by large margins.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pruning Ternary Quantization. (arXiv:2107.10998v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jie Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xue Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10998">
                                    <div class="article-summary-box-inner">
                                        <span>We propose pruning ternary quantization (PTQ), a simple, yet effective,
symmetric ternary quantization method. The method significantly compresses
neural network weights to a sparse ternary of [-1,0,1] and thus reduces
computational, storage, and memory footprints. We show that PTQ can convert
regular weights to ternary orthonormal bases by simply using pruning and L2
projection. In addition, we introduce a refined straight-through estimator to
finalize and stabilize the quantized weights. Our method can provide at most
46x compression ratio on the ResNet-18 structure, with an acceptable accuracy
of 65.36%, outperforming leading methods. Furthermore, PTQ can compress a
ResNet-18 model from 46 MB to 955KB (~48x) and a ResNet-50 model from 99 MB to
3.3MB (~30x), while the top-1 accuracy on ImageNet drops slightly from 69.7% to
65.3% and from 76.15% to 74.47%, respectively. Our method unifies pruning and
quantization and thus provides a range of size-accuracy trade-off.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Score-Based Point Cloud Denoising. (arXiv:2107.10981v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shitong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10981">
                                    <div class="article-summary-box-inner">
                                        <span>Point clouds acquired from scanning devices are often perturbed by noise,
which affects downstream tasks such as surface reconstruction and analysis. The
distribution of a noisy point cloud can be viewed as the distribution of a set
of noise-free samples $p(x)$ convolved with some noise model $n$, leading to
$(p * n)(x)$ whose mode is the underlying clean surface. To denoise a noisy
point cloud, we propose to increase the log-likelihood of each point from $p *
n$ via gradient ascent -- iteratively updating each point&#x27;s position. Since $p
* n$ is unknown at test-time, and we only need the score (i.e., the gradient of
the log-probability function) to perform gradient ascent, we propose a neural
network architecture to estimate the score of $p * n$ given only noisy point
clouds as input. We derive objective functions for training the network and
develop a denoising algorithm leveraging on the estimated scores. Experiments
demonstrate that the proposed model outperforms state-of-the-art methods under
a variety of noise models, and shows the potential to be applied in other tasks
such as point cloud upsampling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Resource Efficient Mountainous Skyline Extraction using Shallow Learning. (arXiv:2107.10997v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmad_T/0/1/0/all/0/1">Touqeer Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Emami_E/0/1/0/all/0/1">Ebrahim Emami</a>, <a href="http://arxiv.org/find/cs/1/au:+Cadik_M/0/1/0/all/0/1">Martin &#x10c;ad&#xed;k</a>, <a href="http://arxiv.org/find/cs/1/au:+Bebis_G/0/1/0/all/0/1">George Bebis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10997">
                                    <div class="article-summary-box-inner">
                                        <span>Skyline plays a pivotal role in mountainous visual geo-localization and
localization/navigation of planetary rovers/UAVs and virtual/augmented reality
applications. We present a novel mountainous skyline detection approach where
we adapt a shallow learning approach to learn a set of filters to discriminate
between edges belonging to sky-mountain boundary and others coming from
different regions. Unlike earlier approaches, which either rely on extraction
of explicit feature descriptors and their classification, or fine-tuning
general scene parsing deep networks for sky segmentation, our approach learns
linear filters based on local structure analysis. At test time, for every
candidate edge pixel, a single filter is chosen from the set of learned filters
based on pixel&#x27;s structure tensor, and then applied to the patch around it. We
then employ dynamic programming to solve the shortest path problem for the
resultant multistage graph to get the sky-mountain boundary. The proposed
approach is computationally faster than earlier methods while providing
comparable performance and is more suitable for resource constrained platforms
e.g., mobile devices, planetary rovers and UAVs. We compare our proposed
approach against earlier skyline detection methods using four different data
sets. Our code is available at
\url{https://github.com/TouqeerAhmad/skyline_detection}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detail Preserving Residual Feature Pyramid Modules for Optical Flow. (arXiv:2107.10990v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Long_L/0/1/0/all/0/1">Libo Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Lang_J/0/1/0/all/0/1">Jochen Lang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10990">
                                    <div class="article-summary-box-inner">
                                        <span>Feature pyramids and iterative refinement have recently led to great progress
in optical flow estimation. However, downsampling in feature pyramids can cause
blending of foreground objects with the background, which will mislead
subsequent decisions in the iterative processing. The results are missing
details especially in the flow of thin and of small structures. We propose a
novel Residual Feature Pyramid Module (RFPM) which retains important details in
the feature map without changing the overall iterative refinement design of the
optical flow estimation. RFPM incorporates a residual structure between
multiple feature pyramids into a downsampling module that corrects the blending
of objects across boundaries. We demonstrate how to integrate our module with
two state-of-the-art iterative refinement architectures. Results show that our
RFPM visibly reduces flow errors and improves state-of-art performance in the
clean pass of Sintel, and is one of the top-performing methods in KITTI.
According to the particular modular structure of RFPM, we introduce a special
transfer learning approach that can dramatically decrease the training time
compared to a typical full optical flow training schedule on multiple datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explainable artificial intelligence (XAI) in deep learning-based medical image analysis. (arXiv:2107.10912v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Velden_B/0/1/0/all/0/1">Bas H.M. van der Velden</a>, <a href="http://arxiv.org/find/eess/1/au:+Kuijf_H/0/1/0/all/0/1">Hugo J. Kuijf</a>, <a href="http://arxiv.org/find/eess/1/au:+Gilhuijs_K/0/1/0/all/0/1">Kenneth G.A. Gilhuijs</a>, <a href="http://arxiv.org/find/eess/1/au:+Viergever_M/0/1/0/all/0/1">Max A. Viergever</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10912">
                                    <div class="article-summary-box-inner">
                                        <span>With an increase in deep learning-based methods, the call for explainability
of such methods grows, especially in high-stakes decision making areas such as
medical image analysis. This survey presents an overview of eXplainable
Artificial Intelligence (XAI) used in deep learning-based medical image
analysis. A framework of XAI criteria is introduced to classify deep
learning-based medical image analysis methods. Papers on XAI techniques in
medical image analysis are then surveyed and categorized according to the
framework and according to anatomical location. The paper concludes with an
outlook of future opportunities for XAI in medical image analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pose Estimation and 3D Reconstruction of Vehicles from Stereo-Images Using a Subcategory-Aware Shape Prior. (arXiv:2107.10898v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Coenen_M/0/1/0/all/0/1">Max Coenen</a>, <a href="http://arxiv.org/find/cs/1/au:+Rottensteiner_F/0/1/0/all/0/1">Franz Rottensteiner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10898">
                                    <div class="article-summary-box-inner">
                                        <span>The 3D reconstruction of objects is a prerequisite for many highly relevant
applications of computer vision such as mobile robotics or autonomous driving.
To deal with the inverse problem of reconstructing 3D objects from their 2D
projections, a common strategy is to incorporate prior object knowledge into
the reconstruction approach by establishing a 3D model and aligning it to the
2D image plane. However, current approaches are limited due to inadequate shape
priors and the insufficiency of the derived image observations for a reliable
alignment with the 3D model. The goal of this paper is to show how 3D object
reconstruction can profit from a more sophisticated shape prior and from a
combined incorporation of different observation types inferred from the images.
We introduce a subcategory-aware deformable vehicle model that makes use of a
prediction of the vehicle type for a more appropriate regularisation of the
vehicle shape. A multi-branch CNN is presented to derive predictions of the
vehicle type and orientation. This information is also introduced as prior
information for model fitting. Furthermore, the CNN extracts vehicle keypoints
and wireframes, which are well-suited for model-to-image association and model
fitting. The task of pose estimation and reconstruction is addressed by a
versatile probabilistic model. Extensive experiments are conducted using two
challenging real-world data sets on both of which the benefit of the developed
shape prior can be shown. A comparison to state-of-the-art methods for vehicle
pose estimation shows that the proposed approach performs on par or better,
confirming the suitability of the developed shape prior and probabilistic model
for vehicle reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Certified Robustness for Ensemble Models and Beyond. (arXiv:2107.10873v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuolin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaojun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1">Bhavya Kailkhura</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tao Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10873">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies show that deep neural networks (DNN) are vulnerable to
adversarial examples, which aim to mislead DNNs by adding perturbations with
small magnitude. To defend against such attacks, both empirical and theoretical
defense approaches have been extensively studied for a single ML model. In this
work, we aim to analyze and provide the certified robustness for ensemble ML
models, together with the sufficient and necessary conditions of robustness for
different ensemble protocols. Although ensemble models are shown more robust
than a single model empirically; surprisingly, we find that in terms of the
certified robustness the standard ensemble models only achieve marginal
improvement compared to a single model. Thus, to explore the conditions that
guarantee to provide certifiably robust ensemble ML models, we first prove that
diversified gradient and large confidence margin are sufficient and necessary
conditions for certifiably robust ensemble models under the model-smoothness
assumption. We then provide the bounded model-smoothness analysis based on the
proposed Ensemble-before-Smoothing strategy. We also prove that an ensemble
model can always achieve higher certified robustness than a single base model
under mild conditions. Inspired by the theoretical findings, we propose the
lightweight Diversity Regularized Training (DRT) to train certifiably robust
ensemble ML models. Extensive experiments show that our DRT enhanced ensembles
can consistently achieve higher certified robustness than existing single and
ensemble ML models, demonstrating the state-of-the-art certified L2-robustness
on MNIST, CIFAR-10, and ImageNet datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human Pose Transfer with Disentangled Feature Consistency. (arXiv:2107.10984v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1">Kun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_C/0/1/0/all/0/1">Chengxiang Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_Z/0/1/0/all/0/1">Zhengping Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1">Bo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Z/0/1/0/all/0/1">Zheng Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_G/0/1/0/all/0/1">Gangyi Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10984">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models have made great progress in synthesizing images with
arbitrary human poses and transferring poses of one person to others. However,
most existing approaches explicitly leverage the pose information extracted
from the source images as a conditional input for the generative networks.
Meanwhile, they usually focus on the visual fidelity of the synthesized images
but neglect the inherent consistency, which further confines their performance
of pose transfer. To alleviate the current limitations and improve the quality
of the synthesized images, we propose a pose transfer network with Disentangled
Feature Consistency (DFC-Net) to facilitate human pose transfer. Given a pair
of images containing the source and target person, DFC-Net extracts pose and
static information from the source and target respectively, then synthesizes an
image of the target person with the desired pose from the source. Moreover,
DFC-Net leverages disentangled feature consistency losses in the adversarial
training to strengthen the transfer coherence and integrates the keypoint
amplifier to enhance the pose feature extraction. Additionally, an unpaired
support dataset Mixamo-Sup providing more extra pose information has been
further utilized during the training to improve the generality and robustness
of DFC-Net. Extensive experimental results on Mixamo-Pose and EDN-10k have
demonstrated DFC-Net achieves state-of-the-art performance on pose transfer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pre-Clustering Point Clouds of Crop Fields Using Scalable Methods. (arXiv:2107.10950v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nelson_H/0/1/0/all/0/1">Henry J. Nelson</a>, <a href="http://arxiv.org/find/cs/1/au:+Papanikolopoulos_N/0/1/0/all/0/1">Nikolaos Papanikolopoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10950">
                                    <div class="article-summary-box-inner">
                                        <span>In order to apply the recent successes of automated plant phenotyping and
machine learning on a large scale, efficient and general algorithms must be
designed to intelligently split crop fields into small, yet actionable,
portions that can then be processed by more complex algorithms. In this paper
we notice a similarity between the current state-of-the-art for this problem
and a commonly used density-based clustering algorithm, Quickshift. Exploiting
this similarity we propose a number of novel, application specific algorithms
with the goal of producing a general and scalable plant segmentation algorithm.
The novel algorithms proposed in this work are shown to produce quantitatively
better results than the current state-of-the-art while being less sensitive to
input parameters and maintaining the same algorithmic time complexity. When
incorporated into field-scale phenotyping systems, the proposed algorithms
should work as a drop in replacement that can greatly improve the accuracy of
results while ensuring that performance and scalability remain undiminished.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compositional Models: Multi-Task Learning and Knowledge Transfer with Modular Networks. (arXiv:2107.10963v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhmoginov_A/0/1/0/all/0/1">Andrey Zhmoginov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bashkirova_D/0/1/0/all/0/1">Dina Bashkirova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandler_M/0/1/0/all/0/1">Mark Sandler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10963">
                                    <div class="article-summary-box-inner">
                                        <span>Conditional computation and modular networks have been recently proposed for
multitask learning and other problems as a way to decompose problem solving
into multiple reusable computational blocks. We propose a new approach for
learning modular networks based on the isometric version of ResNet with all
residual blocks having the same configuration and the same number of
parameters. This architectural choice allows adding, removing and changing the
order of residual blocks. In our method, the modules can be invoked repeatedly
and allow knowledge transfer to novel tasks by adjusting the order of
computation. This allows soft weight sharing between tasks with only a small
increase in the number of parameters. We show that our method leads to
interpretable self-organization of modules in case of multi-task learning,
transfer learning and domain adaptation while achieving competitive results on
those tasks. From practical perspective, our approach allows to: (a) reuse
existing modules for learning new task by adjusting the computation order, (b)
use it for unsupervised multi-source domain adaptation to illustrate that
adaptation to unseen data can be achieved by only manipulating the order of
pretrained modules, (c) show how our approach can be used to increase accuracy
of existing architectures for image classification tasks such as ImageNet,
without any parameter increase, by reusing the same block multiple times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Generalization under Conditional and Label Shifts via Variational Bayesian Inference. (arXiv:2107.10931v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Linghao Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_F/0/1/0/all/0/1">Fangxu Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_J/0/1/0/all/0/1">Jinsong Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakhri_G/0/1/0/all/0/1">Georges EL Fakhri</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1">Jonghye Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10931">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose a domain generalization (DG) approach to learn on
several labeled source domains and transfer knowledge to a target domain that
is inaccessible in training. Considering the inherent conditional and label
shifts, we would expect the alignment of $p(x|y)$ and $p(y)$. However, the
widely used domain invariant feature learning (IFL) methods relies on aligning
the marginal concept shift w.r.t. $p(x)$, which rests on an unrealistic
assumption that $p(y)$ is invariant across domains. We thereby propose a novel
variational Bayesian inference framework to enforce the conditional
distribution alignment w.r.t. $p(x|y)$ via the prior distribution matching in a
latent space, which also takes the marginal label shift w.r.t. $p(y)$ into
consideration with the posterior alignment. Extensive experiments on various
benchmarks demonstrate that our framework is robust to the label shift and the
cross-domain accuracy is significantly improved, thereby achieving superior
performance over the conventional IFL counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAGE: A Split-Architecture Methodology for Efficient End-to-End Autonomous Vehicle Control. (arXiv:2107.10895v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Malawade_A/0/1/0/all/0/1">Arnav Malawade</a>, <a href="http://arxiv.org/find/eess/1/au:+Odema_M/0/1/0/all/0/1">Mohanad Odema</a>, <a href="http://arxiv.org/find/eess/1/au:+Lajeunesse_DeGroot_S/0/1/0/all/0/1">Sebastien Lajeunesse-DeGroot</a>, <a href="http://arxiv.org/find/eess/1/au:+Faruque_M/0/1/0/all/0/1">Mohammad Abdullah Al Faruque</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10895">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous vehicles (AV) are expected to revolutionize transportation and
improve road safety significantly. However, these benefits do not come without
cost; AVs require large Deep-Learning (DL) models and powerful hardware
platforms to operate reliably in real-time, requiring between several hundred
watts to one kilowatt of power. This power consumption can dramatically reduce
vehicles&#x27; driving range and affect emissions. To address this problem, we
propose SAGE: a methodology for selectively offloading the key energy-consuming
modules of DL architectures to the cloud to optimize edge energy usage while
meeting real-time latency constraints. Furthermore, we leverage Head Network
Distillation (HND) to introduce efficient bottlenecks within the DL
architecture in order to minimize the network overhead costs of offloading with
almost no degradation in the model&#x27;s performance. We evaluate SAGE using an
Nvidia Jetson TX2 and an industry-standard Nvidia Drive PX2 as the AV edge
devices and demonstrate that our offloading strategy is practical for a wide
range of DL models and internet connection bandwidths on 3G, 4G LTE, and WiFi
technologies. Compared to edge-only computation, SAGE reduces energy
consumption by an average of 36.13%, 47.07%, and 55.66% for an AV with one
low-resolution camera, one high-resolution camera, and three high-resolution
cameras, respectively. SAGE also reduces upload data size by up to 98.40%
compared to direct camera offloading.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Power Plant Classification from Remote Imaging with Deep Learning. (arXiv:2107.10894v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mommert_M/0/1/0/all/0/1">Michael Mommert</a>, <a href="http://arxiv.org/find/cs/1/au:+Scheibenreif_L/0/1/0/all/0/1">Linus Scheibenreif</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanna_J/0/1/0/all/0/1">Jo&#xeb;lle Hanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Borth_D/0/1/0/all/0/1">Damian Borth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10894">
                                    <div class="article-summary-box-inner">
                                        <span>Satellite remote imaging enables the detailed study of land use patterns on a
global scale. We investigate the possibility to improve the information content
of traditional land use classification by identifying the nature of industrial
sites from medium-resolution remote sensing images. In this work, we focus on
classifying different types of power plants from Sentinel-2 imaging data. Using
a ResNet-50 deep learning model, we are able to achieve a mean accuracy of
90.0% in distinguishing 10 different power plant types and a background class.
Furthermore, we are able to identify the cooling mechanisms utilized in thermal
power plants with a mean accuracy of 87.5%. Our results enable us to
qualitatively investigate the energy mix from Sentinel-2 imaging data, and
prove the feasibility to classify industrial sites on a global scale from
freely available satellite imagery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Graph Matching based Collaborative Filtering. (arXiv:2105.04067v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yixin Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Erfani_S/0/1/0/all/0/1">Sarah Erfani</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_J/0/1/0/all/0/1">Junhao Gan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04067">
                                    <div class="article-summary-box-inner">
                                        <span>User and item attributes are essential side-information; their interactions
(i.e., their co-occurrence in the sample data) can significantly enhance
prediction accuracy in various recommender systems. We identify two different
types of attribute interactions, inner interactions and cross interactions:
inner interactions are those between only user attributes or those between only
item attributes; cross interactions are those between user attributes and item
attributes. Existing models do not distinguish these two types of attribute
interactions, which may not be the most effective way to exploit the
information carried by the interactions. To address this drawback, we propose a
neural Graph Matching based Collaborative Filtering model (GMCF), which
effectively captures the two types of attribute interactions through modeling
and aggregating attribute interactions in a graph matching structure for
recommendation. In our model, the two essential recommendation procedures,
characteristic learning and preference matching, are explicitly conducted
through graph learning (based on inner interactions) and node matching (based
on cross interactions), respectively. Experimental results show that our model
outperforms state-of-the-art models. Further studies verify the effectiveness
of GMCF in improving the accuracy of recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Channel Automatic Music Transcription Using Tensor Algebra. (arXiv:2107.11250v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Axel_M/0/1/0/all/0/1">Marmoret Axel</a>, <a href="http://arxiv.org/find/cs/1/au:+Nancy_B/0/1/0/all/0/1">Bertin Nancy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeremy_C/0/1/0/all/0/1">Cohen Jeremy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11250">
                                    <div class="article-summary-box-inner">
                                        <span>Music is an art, perceived in unique ways by every listener, coming from
acoustic signals. In the meantime, standards as musical scores exist to
describe it. Even if humans can make this transcription, it is costly in terms
of time and efforts, even more with the explosion of information consecutively
to the rise of the Internet. In that sense, researches are driven in the
direction of Automatic Music Transcription. While this task is considered
solved in the case of single notes, it is still open when notes superpose
themselves, forming chords. This report aims at developing some of the existing
techniques towards Music Transcription, particularly matrix factorization, and
introducing the concept of multi-channel automatic music transcription. This
concept will be explored with mathematical objects called tensors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What are you optimizing for? Aligning Recommender Systems with Human Values. (arXiv:2107.10939v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stray_J/0/1/0/all/0/1">Jonathan Stray</a>, <a href="http://arxiv.org/find/cs/1/au:+Vendrov_I/0/1/0/all/0/1">Ivan Vendrov</a>, <a href="http://arxiv.org/find/cs/1/au:+Nixon_J/0/1/0/all/0/1">Jeremy Nixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Adler_S/0/1/0/all/0/1">Steven Adler</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1">Dylan Hadfield-Menell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10939">
                                    <div class="article-summary-box-inner">
                                        <span>We describe cases where real recommender systems were modified in the service
of various human values such as diversity, fairness, well-being, time well
spent, and factual accuracy. From this we identify the current practice of
values engineering: the creation of classifiers from human-created data with
value-based labels. This has worked in practice for a variety of issues, but
problems are addressed one at a time, and users and other stakeholders have
seldom been involved. Instead, we look to AI alignment work for approaches that
could learn complex values directly from stakeholders, and identify four major
directions: useful measures of alignment, participatory design and operation,
interactive value learning, and informed deliberative judgments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learn to Intervene: An Adaptive Learning Policy for Restless Bandits in Application to Preventive Healthcare. (arXiv:2105.07965v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biswas_A/0/1/0/all/0/1">Arpita Biswas</a>, <a href="http://arxiv.org/find/cs/1/au:+Aggarwal_G/0/1/0/all/0/1">Gaurav Aggarwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Varakantham_P/0/1/0/all/0/1">Pradeep Varakantham</a>, <a href="http://arxiv.org/find/cs/1/au:+Tambe_M/0/1/0/all/0/1">Milind Tambe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07965">
                                    <div class="article-summary-box-inner">
                                        <span>In many public health settings, it is important for patients to adhere to
health programs, such as taking medications and periodic health checks.
Unfortunately, beneficiaries may gradually disengage from such programs, which
is detrimental to their health. A concrete example of gradual disengagement has
been observed by an organization that carries out a free automated call-based
program for spreading preventive care information among pregnant women. Many
women stop picking up calls after being enrolled for a few months. To avoid
such disengagements, it is important to provide timely interventions. Such
interventions are often expensive and can be provided to only a small fraction
of the beneficiaries. We model this scenario as a restless multi-armed bandit
(RMAB) problem, where each beneficiary is assumed to transition from one state
to another depending on the intervention. Moreover, since the transition
probabilities are unknown a priori, we propose a Whittle index based Q-Learning
mechanism and show that it converges to the optimal solution. Our method
improves over existing learning-based methods for RMABs on multiple benchmarks
from literature and also on the maternal healthcare dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shifts: A Dataset of Real Distributional Shift Across Multiple Large-Scale Tasks. (arXiv:2107.07455v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Malinin_A/0/1/0/all/0/1">Andrey Malinin</a>, <a href="http://arxiv.org/find/cs/1/au:+Band_N/0/1/0/all/0/1">Neil Band</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganshin/0/1/0/all/0/1">Ganshin</a>, <a href="http://arxiv.org/find/cs/1/au:+Alexander/0/1/0/all/0/1">Alexander</a>, <a href="http://arxiv.org/find/cs/1/au:+Chesnokov_G/0/1/0/all/0/1">German Chesnokov</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gales_M/0/1/0/all/0/1">Mark J. F. Gales</a>, <a href="http://arxiv.org/find/cs/1/au:+Noskov_A/0/1/0/all/0/1">Alexey Noskov</a>, <a href="http://arxiv.org/find/cs/1/au:+Ploskonosov_A/0/1/0/all/0/1">Andrey Ploskonosov</a>, <a href="http://arxiv.org/find/cs/1/au:+Prokhorenkova_L/0/1/0/all/0/1">Liudmila Prokhorenkova</a>, <a href="http://arxiv.org/find/cs/1/au:+Provilkov_I/0/1/0/all/0/1">Ivan Provilkov</a>, <a href="http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1">Vatsal Raina</a>, <a href="http://arxiv.org/find/cs/1/au:+Raina_V/0/1/0/all/0/1">Vyas Raina</a>, <a href="http://arxiv.org/find/cs/1/au:+Roginskiy/0/1/0/all/0/1">Roginskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Denis/0/1/0/all/0/1">Denis</a>, <a href="http://arxiv.org/find/cs/1/au:+Shmatova_M/0/1/0/all/0/1">Mariya Shmatova</a>, <a href="http://arxiv.org/find/cs/1/au:+Tigas_P/0/1/0/all/0/1">Panos Tigas</a>, <a href="http://arxiv.org/find/cs/1/au:+Yangel_B/0/1/0/all/0/1">Boris Yangel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.07455">
                                    <div class="article-summary-box-inner">
                                        <span>There has been significant research done on developing methods for improving
robustness to distributional shift and uncertainty estimation. In contrast,
only limited work has examined developing standard datasets and benchmarks for
assessing these approaches. Additionally, most work on uncertainty estimation
and robustness has developed new techniques based on small-scale regression or
image classification tasks. However, many tasks of practical interest have
different modalities, such as tabular data, audio, text, or sensor data, which
offer significant challenges involving regression and discrete or continuous
structured prediction. Thus, given the current state of the field, a
standardized large-scale dataset of tasks across a range of modalities affected
by distributional shifts is necessary. This will enable researchers to
meaningfully evaluate the plethora of recently developed uncertainty
quantification methods, as well as assessment criteria and state-of-the-art
baselines. In this work, we propose the \emph{Shifts Dataset} for evaluation of
uncertainty estimates and robustness to distributional shift. The dataset,
which has been collected from industrial sources and services, is composed of
three tasks, with each corresponding to a particular data modality: tabular
weather prediction, machine translation, and self-driving car (SDC) vehicle
motion prediction. All of these data modalities and tasks are affected by real,
&#x60;in-the-wild&#x27; distributional shifts and pose interesting challenges with
respect to uncertainty estimation. In this work we provide a description of the
dataset and baseline results for all tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A data-driven approach to beating SAA out-of-sample. (arXiv:2105.12342v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Gotoh_J/0/1/0/all/0/1">Jun-ya Gotoh</a>, <a href="http://arxiv.org/find/math/1/au:+Kim_M/0/1/0/all/0/1">Michael Jong Kim</a>, <a href="http://arxiv.org/find/math/1/au:+Lim_A/0/1/0/all/0/1">Andrew E.B. Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12342">
                                    <div class="article-summary-box-inner">
                                        <span>While solutions of Distributionally Robust Optimization (DRO) problems can
sometimes have a higher out-of-sample expected reward than the Sample Average
Approximation (SAA), there is no guarantee. In this paper, we introduce the
class of Distributionally Optimistic Optimization (DOO) models, and show that
it is always possible to &quot;beat&quot; SAA out-of-sample if we consider not just
worst-case (DRO) models but also best-case (DOO) ones. We also show, however,
that this comes at a cost: Optimistic solutions are more sensitive to model
error than either worst-case or SAA optimizers, and hence are less robust.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PyTorch, Explain! A Python library for Logic Explained Networks. (arXiv:2105.11697v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barbiero_P/0/1/0/all/0/1">Pietro Barbiero</a>, <a href="http://arxiv.org/find/cs/1/au:+Ciravegna_G/0/1/0/all/0/1">Gabriele Ciravegna</a>, <a href="http://arxiv.org/find/cs/1/au:+Georgiev_D/0/1/0/all/0/1">Dobrik Georgiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Giannini_F/0/1/0/all/0/1">Franscesco Giannini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11697">
                                    <div class="article-summary-box-inner">
                                        <span>&quot;PyTorch, Explain!&quot; is a Python module integrating a variety of
state-of-the-art approaches to provide logic explanations from neural networks.
This package focuses on bringing these methods to non-specialists. It has
minimal dependencies and it is distributed under the Apache 2.0 licence
allowing both academic and commercial use. Source code and documentation can be
downloaded from the github repository:
https://github.com/pietrobarbiero/pytorch_explain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Speech Recognition in Sanskrit: A New Speech Corpus and Modelling Insights. (arXiv:2106.05852v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Adiga_D/0/1/0/all/0/1">Devaraja Adiga</a>, <a href="http://arxiv.org/find/eess/1/au:+Kumar_R/0/1/0/all/0/1">Rishabh Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Krishna_A/0/1/0/all/0/1">Amrith Krishna</a>, <a href="http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>, <a href="http://arxiv.org/find/eess/1/au:+Ramakrishnan_G/0/1/0/all/0/1">Ganesh Ramakrishnan</a>, <a href="http://arxiv.org/find/eess/1/au:+Goyal_P/0/1/0/all/0/1">Pawan Goyal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.05852">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic speech recognition (ASR) in Sanskrit is interesting, owing to the
various linguistic peculiarities present in the language. The Sanskrit language
is lexically productive, undergoes euphonic assimilation of phones at the word
boundaries and exhibits variations in spelling conventions and in
pronunciations. In this work, we propose the first large scale study of
automatic speech recognition (ASR) in Sanskrit, with an emphasis on the impact
of unit selection in Sanskrit ASR. In this work, we release a 78 hour ASR
dataset for Sanskrit, which faithfully captures several of the linguistic
characteristics expressed by the language. We investigate the role of different
acoustic model and language model units in ASR systems for Sanskrit. We also
propose a new modelling unit, inspired by the syllable level unit selection,
that captures character sequences from one vowel in the word to the next vowel.
We also highlight the importance of choosing graphemic representations for
Sanskrit and show the impact of this choice on word error rates (WER). Finally,
we extend these insights from Sanskrit ASR for building ASR systems in two
other Indic languages, Gujarati and Telugu. For both these languages, our
experimental results show that the use of phonetic based graphemic
representations in ASR results in performance improvements as compared to ASR
systems that use native scripts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Neural Speech Synthesis. (arXiv:2106.15561v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/eess/1/au:+Soong_F/0/1/0/all/0/1">Frank Soong</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15561">
                                    <div class="article-summary-box-inner">
                                        <span>Text to speech (TTS), or speech synthesis, which aims to synthesize
intelligible and natural speech given text, is a hot research topic in speech,
language, and machine learning communities and has broad applications in the
industry. As the development of deep learning and artificial intelligence,
neural network-based TTS has significantly improved the quality of synthesized
speech in recent years. In this paper, we conduct a comprehensive survey on
neural TTS, aiming to provide a good understanding of current research and
future trends. We focus on the key components in neural TTS, including text
analysis, acoustic models and vocoders, and several advanced topics, including
fast TTS, low-resource TTS, robust TTS, expressive TTS, and adaptive TTS, etc.
We further summarize resources related to TTS (e.g., datasets, opensource
implementations) and discuss future research directions. This survey can serve
both academic researchers and industry practitioners working on TTS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Multi-type Temporal Sequences to Mitigate Class-imbalanced Problem. (arXiv:2104.03428v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadghiani_N/0/1/0/all/0/1">Nima Salehi Sadghiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_Z/0/1/0/all/0/1">Zhuo Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_A/0/1/0/all/0/1">Andrew Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03428">
                                    <div class="article-summary-box-inner">
                                        <span>From the ad network standpoint, a user&#x27;s activity is a multi-type sequence of
temporal events consisting of event types and time intervals. Understanding
user patterns in ad networks has received increasing attention from the machine
learning community. Particularly, the problems of fraud detection, Conversion
Rate (CVR), and Click-Through Rate (CTR) prediction are of interest. However,
the class imbalance between major and minor classes in these tasks can bias a
machine learning model leading to poor performance. This study proposes using
two multi-type (continuous and discrete) training approaches for GANs to deal
with the limitations of traditional GANs in passing the gradient updates for
discrete tokens. First, we used the Reinforcement Learning (RL)-based training
approach and then, an approximation of the multinomial distribution
parameterized in terms of the softmax function (Gumble-Softmax). Our extensive
experiments based on synthetic data have shown the trained generator can
generate sequences with desired properties measured by multiple criteria.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interval-censored Hawkes processes. (arXiv:2104.07932v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rizoiu_M/0/1/0/all/0/1">Marian-Andrei Rizoiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Soen_A/0/1/0/all/0/1">Alexander Soen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shidi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Calderon_P/0/1/0/all/0/1">Pio Calderon</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1">Leanne Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1">Aditya Krishna Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lexing Xie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07932">
                                    <div class="article-summary-box-inner">
                                        <span>This work builds a novel point process and tools to use the Hawkes process
with interval-censored data. Such data records the aggregated counts of events
solely during specific time intervals -- such as the number of patients
admitted to the hospital or the volume of vehicles passing traffic loop
detectors -- and not the exact occurrence time of the events. First, we
establish the Mean Behavior Poisson (MBP) process, a novel Poisson process with
a direct parameter correspondence to the popular self-exciting Hawkes process.
The event intensity function of the MBP is the expected intensity over all
possible Hawkes realizations with the same parameter set. We fit MBP in the
interval-censored setting using an interval-censored Poisson log-likelihood
(IC-LL). We use the parameter equivalence to uncover the parameters of the
associated Hawkes process. Second, we introduce two novel exogenous functions
to distinguish the exogenous from the endogenous events. We propose the
multi-impulse exogenous function when the exogenous events are observed as
event time and the latent homogeneous Poisson process exogenous function when
the exogenous events are presented as interval-censored volumes. Third, we
provide several approximation methods to estimate the intensity and compensator
function of MBP when no analytical solution exists. Fourth and finally, we
connect the interval-censored loss of MBP to a broader class of Bregman
divergence-based functions. Using the connection, we show that the current
state of the art in popularity estimation (Hawkes Intensity Process (HIP)
(Rizoiu et al.,2017b)) is a particular case of the MBP process. We verify our
models through empirical testing on synthetic data and real-world data. We find
that on real-world datasets that our MBP process outperforms HIP for the task
of popularity prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why Approximate Matrix Square Root Outperforms Accurate SVD in Global Covariance Pooling?. (arXiv:2105.02498v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yue Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02498">
                                    <div class="article-summary-box-inner">
                                        <span>Global covariance pooling (GCP) aims at exploiting the second-order
statistics of the convolutional feature. Its effectiveness has been
demonstrated in boosting the classification performance of Convolutional Neural
Networks (CNNs). Singular Value Decomposition (SVD) is used in GCP to compute
the matrix square root. However, the approximate matrix square root calculated
using Newton-Schulz iteration \cite{li2018towards} outperforms the accurate one
computed via SVD \cite{li2017second}. We empirically analyze the reason behind
the performance gap from the perspectives of data precision and gradient
smoothness. Various remedies for computing smooth SVD gradients are
investigated. Based on our observation and analyses, a hybrid training protocol
is proposed for SVD-based GCP meta-layers such that competitive performances
can be achieved against Newton-Schulz iteration. Moreover, we propose a new GCP
meta-layer that uses SVD in the forward pass, and Pad\&#x27;e Approximants in the
backward propagation to compute the gradients. The proposed meta-layer has been
integrated into different CNN models and achieves state-of-the-art performances
on both large-scale and fine-grained datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Graph Structures with Transformer for Multivariate Time Series Anomaly Detection in IoT. (arXiv:2104.03466v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zekai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Dingshuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1">Zixuan Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1">Xiuzhen Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03466">
                                    <div class="article-summary-box-inner">
                                        <span>Many real-world IoT systems, which include a variety of internet-connected
sensory devices, produce substantial amounts of multivariate time series data.
Meanwhile, vital IoT infrastructures like smart power grids and water
distribution networks are frequently targeted by cyber-attacks, making anomaly
detection an important study topic. Modeling such relatedness is, nevertheless,
unavoidable for any efficient and effective anomaly detection system, given the
intricate topological and nonlinear connections that are originally unknown
among sensors. Furthermore, detecting anomalies in multivariate time series is
difficult due to their temporal dependency and stochasticity. This paper
presented GTA, a new framework for multivariate time series anomaly detection
that involves automatically learning a graph structure, graph convolution, and
modeling temporal dependency using a Transformer-based architecture. The
connection learning policy, which is based on the Gumbel-softmax sampling
approach to learn bi-directed links among sensors directly, is at the heart of
learning graph structure. To describe the anomaly information flow between
network nodes, we introduced a new graph convolution called Influence
Propagation convolution. In addition, to tackle the quadratic complexity
barrier, we suggested a multi-branch attention mechanism to replace the
original multi-head self-attention method. Extensive experiments on four
publicly available anomaly detection benchmarks further demonstrate the
superiority of our approach over alternative state-of-the-arts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Representation for Neural Code Search. (arXiv:2107.00992v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jian Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zimin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Monperrus_M/0/1/0/all/0/1">Martin Monperrus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.00992">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic code search is about finding semantically relevant code snippets for
a given natural language query. In the state-of-the-art approaches, the
semantic similarity between code and query is quantified as the distance of
their representation in the shared vector space. In this paper, to improve the
vector space, we introduce tree-serialization methods on a simplified form of
AST and build the multimodal representation for the code data. We conduct
extensive experiments using a single corpus that is large-scale and
multi-language: CodeSearchNet. Our results show that both our tree-serialized
representations and multimodal learning model improve the performance of code
search. Last, we define intuitive quantification metrics oriented to the
completeness of semantic and syntactic information of the code data, to help
understand the experimental findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularity and stability of feedback relaxed controls. (arXiv:2001.03148v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Reisinger_C/0/1/0/all/0/1">Christoph Reisinger</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_Y/0/1/0/all/0/1">Yufei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.03148">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a relaxed control regularization with general exploration
rewards to design robust feedback controls for multi-dimensional
continuous-time stochastic exit time problems. We establish that the
regularized control problem admits a H\&quot;{o}lder continuous feedback control,
and demonstrate that both the value function and the feedback control of the
regularized control problem are Lipschitz stable with respect to parameter
perturbations. Moreover, we show that a pre-computed feedback relaxed control
has a robust performance in a perturbed system, and derive a first-order
sensitivity equation for both the value function and optimal feedback relaxed
control. These stability results provide a theoretical justification for recent
reinforcement learning heuristics that including an exploration reward in the
optimization objective leads to more robust decision making. We finally prove
first-order monotone convergence of the value functions for relaxed control
problems with vanishing exploration parameters, which subsequently enables us
to construct the pure exploitation strategy of the original control problem
based on the feedback relaxed controls.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Including Signed Languages in Natural Language Processing. (arXiv:2105.05222v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1">Kayo Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Moryossef_A/0/1/0/all/0/1">Amit Moryossef</a>, <a href="http://arxiv.org/find/cs/1/au:+Hochgesang_J/0/1/0/all/0/1">Julie Hochgesang</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1">Yoav Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Alikhani_M/0/1/0/all/0/1">Malihe Alikhani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.05222">
                                    <div class="article-summary-box-inner">
                                        <span>Signed languages are the primary means of communication for many deaf and
hard of hearing individuals. Since signed languages exhibit all the fundamental
linguistic properties of natural language, we believe that tools and theories
of Natural Language Processing (NLP) are crucial towards its modeling. However,
existing research in Sign Language Processing (SLP) seldom attempt to explore
and leverage the linguistic organization of signed languages. This position
paper calls on the NLP community to include signed languages as a research area
with high social and scientific impact. We first discuss the linguistic
properties of signed languages to consider during their modeling. Then, we
review the limitations of current SLP models and identify the open challenges
to extend NLP to signed languages. Finally, we urge (1) the adoption of an
efficient tokenization method; (2) the development of linguistically-informed
models; (3) the collection of real-world signed language data; (4) the
inclusion of local signed language communities as an active and leading voice
in the direction of research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Function approximation by deep neural networks with parameters $\{0,\pm \frac{1}{2}, \pm 1, 2\}$. (arXiv:2103.08659v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Beknazaryan_A/0/1/0/all/0/1">Aleksandr Beknazaryan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08659">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper it is shown that $C_\beta$-smooth functions can be approximated
by deep neural networks with ReLU activation function and with parameters
$\{0,\pm \frac{1}{2}, \pm 1, 2\}$. The $l_0$ and $l_1$ parameter norms of
considered networks are thus equivalent. The depth, width and the number of
active parameters of the constructed networks have, up to a logarithmic factor,
the same dependence on the approximation error as the networks with parameters
in $[-1,1]$. In particular, this means that the nonparametric regression
estimation with the constructed networks attains the same convergence rate as
with sparse networks with parameters in $[-1,1]$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OpReg-Boost: Learning to Accelerate Online Algorithms with Operator Regression. (arXiv:2105.13271v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bastianello_N/0/1/0/all/0/1">Nicola Bastianello</a>, <a href="http://arxiv.org/find/cs/1/au:+Simonetto_A/0/1/0/all/0/1">Andrea Simonetto</a>, <a href="http://arxiv.org/find/cs/1/au:+DallAnese_E/0/1/0/all/0/1">Emiliano Dall&#x27;Anese</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13271">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new regularization approach -- termed OpReg-Boost -- to
boost the convergence and lessen the asymptotic error of online optimization
and learning algorithms. In particular, the paper considers online algorithms
for optimization problems with a time-varying (weakly) convex composite cost.
For a given online algorithm, OpReg-Boost learns the closest algorithmic map
that yields linear convergence; to this end, the learning procedure hinges on
the concept of operator regression. We show how to formalize the operator
regression problem and propose a computationally-efficient Peaceman-Rachford
solver that exploits a closed-form solution of simple quadratically-constrained
quadratic programs (QCQPs). Simulation results showcase the superior properties
of OpReg-Boost w.r.t. the more classical forward-backward algorithm, FISTA, and
Anderson acceleration, and with respect to its close relative
convex-regression-boost (CvxReg-Boost) which is also novel but less performing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Next Generation Reservoir Computing. (arXiv:2106.07688v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gauthier_D/0/1/0/all/0/1">Daniel J. Gauthier</a>, <a href="http://arxiv.org/find/cs/1/au:+Bollt_E/0/1/0/all/0/1">Erik Bollt</a>, <a href="http://arxiv.org/find/cs/1/au:+Griffith_A/0/1/0/all/0/1">Aaron Griffith</a>, <a href="http://arxiv.org/find/cs/1/au:+Barbosa_W/0/1/0/all/0/1">Wendson A.S. Barbosa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.07688">
                                    <div class="article-summary-box-inner">
                                        <span>Reservoir computing is a best-in-class machine learning algorithm for
processing information generated by dynamical systems using observed
time-series data. Importantly, it requires very small training data sets, uses
linear optimization, and thus requires minimal computing resources. However,
the algorithm uses randomly sampled matrices to define the underlying recurrent
neural network and has a multitude of metaparameters that must be optimized.
Recent results demonstrate the equivalence of reservoir computing to nonlinear
vector autoregression, which requires no random matrices, fewer metaparameters,
and provides interpretable results. Here, we demonstrate that nonlinear vector
autoregression excels at reservoir computing benchmark tasks and requires even
shorter training data sets and training time, heralding the next generation of
reservoir computing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured Convolutional Kernel Networks for Airline Crew Scheduling. (arXiv:2105.11646v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yaakoubi_Y/0/1/0/all/0/1">Yassine Yaakoubi</a>, <a href="http://arxiv.org/find/cs/1/au:+Soumis_F/0/1/0/all/0/1">Fran&#xe7;ois Soumis</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1">Simon Lacoste-Julien</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11646">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the needs from an airline crew scheduling application, we
introduce structured convolutional kernel networks (Struct-CKN), which combine
CKNs from Mairal et al. (2014) in a structured prediction framework that
supports constraints on the outputs. CKNs are a particular kind of
convolutional neural networks that approximate a kernel feature map on training
data, thus combining properties of deep learning with the non-parametric
flexibility of kernel methods. Extending CKNs to structured outputs allows us
to obtain useful initial solutions on a flight-connection dataset that can be
further refined by an airline crew scheduling solver. More specifically, we use
a flight-based network modeled as a general conditional random field capable of
incorporating local constraints in the learning process. Our experiments
demonstrate that this approach yields significant improvements for the
large-scale crew pairing problem (50,000 flights per month) over standard
approaches, reducing the solution cost by 17% (a gain of millions of dollars)
and the cost of global constraints by 97%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoupling Exploration and Exploitation in Reinforcement Learning. (arXiv:2107.08966v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schafer_L/0/1/0/all/0/1">Lukas Sch&#xe4;fer</a>, <a href="http://arxiv.org/find/cs/1/au:+Christianos_F/0/1/0/all/0/1">Filippos Christianos</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanna_J/0/1/0/all/0/1">Josiah Hanna</a>, <a href="http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1">Stefano V. Albrecht</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.08966">
                                    <div class="article-summary-box-inner">
                                        <span>Intrinsic rewards are commonly applied to improve exploration in
reinforcement learning. However, these approaches suffer from instability
caused by non-stationary reward shaping and strong dependency on
hyperparameters. In this work, we propose Decoupled RL (DeRL) which trains
separate policies for exploration and exploitation. DeRL can be applied with
on-policy and off-policy RL algorithms. We evaluate DeRL algorithms in two
sparse-reward environments with multiple types of intrinsic rewards. We show
that DeRL is more robust to scaling and speed of decay of intrinsic rewards and
converges to the same evaluation returns than intrinsically motivated baselines
in fewer interactions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Graph Classification over Non-IID Graphs. (arXiv:2106.13423v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Han Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jing Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Li Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.13423">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning has emerged as an important paradigm for training machine
learning models in different domains. For graph-level tasks such as graph
classification, graphs can also be regarded as a special type of data samples,
which can be collected and stored in separate local systems. Similar to other
domains, multiple local systems, each holding a small set of graphs, may
benefit from collaboratively training a powerful graph mining model, such as
the popular graph neural networks (GNNs). To provide more motivation towards
such endeavors, we analyze real-world graphs from different domains to confirm
that they indeed share certain graph properties that are statistically
significant compared with random graphs. However, we also find that different
sets of graphs, even from the same domain or same dataset, are non-IID
regarding both graph structures and node features. To handle this, we propose a
graph clustered federated learning (GCFL) framework that dynamically finds
clusters of local systems based on the gradients of GNNs, and theoretically
justify that such clusters can reduce the structure and feature heterogeneity
among graphs owned by the local systems. Moreover, we observe the gradients of
GNNs to be rather fluctuating in GCFL which impedes high-quality clustering,
and design a gradient sequence-based clustering mechanism based on dynamic time
warping (GCFL+). Extensive experimental results and in-depth analysis
demonstrate the effectiveness of our proposed frameworks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the simplicity and conditioning of low rank semidefinite programs. (arXiv:2002.10673v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Ding_L/0/1/0/all/0/1">Lijun Ding</a>, <a href="http://arxiv.org/find/math/1/au:+Udell_M/0/1/0/all/0/1">Madeleine Udell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.10673">
                                    <div class="article-summary-box-inner">
                                        <span>Low rank matrix recovery problems appear widely in statistics, combinatorics,
and imaging. One celebrated method for solving these problems is to formulate
and solve a semidefinite program (SDP). It is often known that the exact
solution to the SDP with perfect data recovers the solution to the original low
rank matrix recovery problem. It is more challenging to show that an
approximate solution to the SDP formulated with noisy problem data acceptably
solves the original problem; arguments are usually ad hoc for each problem
setting, and can be complex.

In this note, we identify a set of conditions that we call simplicity that
limit the error due to noisy problem data or incomplete convergence. In this
sense, simple SDPs are robust: simple SDPs can be (approximately) solved
efficiently at scale; and the resulting approximate solutions, even with noisy
data, can be trusted. Moreover, we show that simplicity holds generically, and
also for many structured low rank matrix recovery problems, including the
stochastic block model, $\mathbb{Z}_2$ synchronization, and matrix completion.
Formally, we call an SDP simple if it has a surjective constraint map, admits a
unique primal and dual solution pair, and satisfies strong duality and strict
complementarity.

However, simplicity is not a panacea: we show the Burer-Monteiro formulation
of the SDP may have spurious second-order critical points, even for a simple
SDP with a rank 1 solution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zeroth-Order Regularized Optimization (ZORO): Approximately Sparse Gradients and Adaptive Sampling. (arXiv:2003.13001v5 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Cai_H/0/1/0/all/0/1">HanQin Cai</a>, <a href="http://arxiv.org/find/math/1/au:+Mckenzie_D/0/1/0/all/0/1">Daniel Mckenzie</a>, <a href="http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1">Wotao Yin</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1">Zhenliang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.13001">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of minimizing a high-dimensional objective function,
which may include a regularization term, using (possibly noisy) evaluations of
the function. Such optimization is also called derivative-free, zeroth-order,
or black-box optimization. We propose a new $\textbf{Z}$eroth-$\textbf{O}$rder
$\textbf{R}$egularized $\textbf{O}$ptimization method, dubbed ZORO. When the
underlying gradient is approximately sparse at an iterate, ZORO needs very few
objective function evaluations to obtain a new iterate that decreases the
objective function. We achieve this with an adaptive, randomized gradient
estimator, followed by an inexact proximal-gradient scheme. Under a novel
approximately sparse gradient assumption and various different convex settings,
we show the (theoretical and empirical) convergence rate of ZORO is only
logarithmically dependent on the problem dimension. Numerical experiments show
that ZORO outperforms the existing methods with similar assumptions, on both
synthetic and real datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extracting Weighted Automata for Approximate Minimization in Language Modelling. (arXiv:2106.02965v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lacroce_C/0/1/0/all/0/1">Clara Lacroce</a>, <a href="http://arxiv.org/find/cs/1/au:+Panangaden_P/0/1/0/all/0/1">Prakash Panangaden</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1">Guillaume Rabusseau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02965">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we study the approximate minimization problem for language
modelling. We assume we are given some language model as a black box. The
objective is to obtain a weighted finite automaton (WFA) that fits within a
given size constraint and which mimics the behaviour of the original model
while minimizing some notion of distance between the black box and the
extracted WFA. We provide an algorithm for the approximate minimization of
black boxes trained for language modelling of sequential data over a one-letter
alphabet. By reformulating the problem in terms of Hankel matrices, we leverage
classical results on the approximation of Hankel operators, namely the
celebrated Adamyan-Arov-Krein (AAK) theory. This allows us to use the spectral
norm to measure the distance between the black box and the WFA. We provide
theoretical guarantees to study the potentially infinite-rank Hankel matrix of
the black box, without accessing the training data, and we prove that our
method returns an asymptotically-optimal approximation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An adaptive cognitive sensor node for ECG monitoring in the Internet of Medical Things. (arXiv:2106.06498v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scrugli_M/0/1/0/all/0/1">Matteo Antonio Scrugli</a>, <a href="http://arxiv.org/find/cs/1/au:+Loi_D/0/1/0/all/0/1">Daniela Loi</a>, <a href="http://arxiv.org/find/cs/1/au:+Raffo_L/0/1/0/all/0/1">Luigi Raffo</a>, <a href="http://arxiv.org/find/cs/1/au:+Meloni_P/0/1/0/all/0/1">Paolo Meloni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.06498">
                                    <div class="article-summary-box-inner">
                                        <span>The Internet of Medical Things (IoMT) paradigm is becoming mainstream in
multiple clinical trials and healthcare procedures. Cardiovascular diseases
monitoring, usually involving electrocardiogram (ECG) traces analysis, is one
of the most promising and high-impact applications. Nevertheless, to fully
exploit the potential of IoMT in this domain, some steps forward are needed.
First, the edge-computing paradigm must be added to the picture. A certain
level of near-sensor processing has to be enabled, to improve the scalability,
portability, reliability, responsiveness of the IoMT nodes. Second, novel,
increasingly accurate, data analysis algorithms, such as those based on
artificial intelligence and Deep Learning, must be exploited. To reach these
objectives, designers and programmers of IoMT nodes, have to face challenging
optimization tasks, in order to execute fairly complex computing tasks on
low-power wearable and portable processing systems, with tight power and
battery lifetime budgets. In this work, we explore the implementation of a
cognitive data analysis algorithm, based on a convolutional neural network
trained to classify ECG waveforms, on a resource-constrained
microcontroller-based computing platform. To minimize power consumption, we add
an adaptivity layer that dynamically manages the hardware and software
configuration of the device to adapt it at runtime to the required operating
mode. Our experimental results show that adapting the node setup to the
workload at runtime can save up to 50% power consumption. Our optimized and
quantized neural network reaches an accuracy value higher than 97% for
arrhythmia disorders detection on MIT-BIH Arrhythmia dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Precise High-Dimensional Asymptotic Theory for Boosting and Minimum-$\ell_1$-Norm Interpolated Classifiers. (arXiv:2002.01586v3 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Liang_T/0/1/0/all/0/1">Tengyuan Liang</a>, <a href="http://arxiv.org/find/math/1/au:+Sur_P/0/1/0/all/0/1">Pragya Sur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.01586">
                                    <div class="article-summary-box-inner">
                                        <span>This paper establishes a precise high-dimensional asymptotic theory for
boosting on separable data, taking statistical and computational perspectives.
We consider a high-dimensional setting where the number of features (weak
learners) $p$ scales with the sample size $n$, in an overparametrized regime.
Under a class of statistical models, we provide an exact analysis of the
generalization error of boosting when the algorithm interpolates the training
data and maximizes the empirical $\ell_1$-margin. Further, we explicitly pin
down the relation between the boosting test error and the optimal Bayes error,
as well as the proportion of active features at interpolation (with zero
initialization). In turn, these precise characterizations answer certain
questions raised in \cite{breiman1999prediction, schapire1998boosting}
surrounding boosting, under assumed data generating processes. At the heart of
our theory lies an in-depth study of the maximum-$\ell_1$-margin, which can be
accurately described by a new system of non-linear equations; to analyze this
margin, we rely on Gaussian comparison techniques and develop a novel uniform
deviation argument. Our statistical and computational arguments can handle (1)
any finite-rank spiked covariance model for the feature distribution and (2)
variants of boosting corresponding to general $\ell_q$-geometry, $q \in [1,
2]$. As a final component, via the Lindeberg principle, we establish a
universality result showcasing that the scaled $\ell_1$-margin (asymptotically)
remains the same, whether the covariates used for boosting arise from a
non-linear random feature model or an appropriately linearized model with
matching moments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Experiments with a PCCoder extension. (arXiv:1912.00781v2 [cs.PL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hernest_D/0/1/0/all/0/1">Dan Hernest</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.00781">
                                    <div class="article-summary-box-inner">
                                        <span>Recent research in synthesis of programs written in some Domain Specific
Language (DSL) by means of neural networks from a limited set of inputs-output
correspondences such as DeepCoder and its PCCoder reimplementation/optimization
proved the efficiency of this kind of approach to automatic program generation
in a DSL language that although limited in scope is universal in the sense that
programs can be translated to basically any programming language. We experiment
with the extension of the DSL of DeepCoder/PCCoder with symbols IFI and IFL
which denote functional expressions of the If ramification (test) instruction
for types Int and List. We notice an increase (doubling) of the size of the
training set, the number of parameters of the trained neural network and of the
time spent looking for the program synthesized from limited sets of
inputs-output correspondences. The result is positive in the sense of
preserving the accuracy of applying synthesis on randomly generated test sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">State, global and local parameter estimation using local ensemble Kalman filters: applications to online machine learning of chaotic dynamics. (arXiv:2107.11253v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Malartic_Q/0/1/0/all/0/1">Quentin Malartic</a>, <a href="http://arxiv.org/find/stat/1/au:+Farchi_A/0/1/0/all/0/1">Alban Farchi</a>, <a href="http://arxiv.org/find/stat/1/au:+Bocquet_M/0/1/0/all/0/1">Marc Bocquet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11253">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies have shown that it is possible to combine machine learning
methods with data assimilation to reconstruct a dynamical system using only
sparse and noisy observations of that system. The same approach can be used to
correct the error of a knowledge-based model. The resulting surrogate model is
hybrid, with a statistical part supplementing a physical part. In practice, the
correction can be added as an integrated term (\textit{i.e.} in the model
resolvent) or directly inside the tendencies of the physical model. The
resolvent correction is easy to implement. The tendency correction is more
technical, in particular it requires the adjoint of the physical model, but
also more flexible. We use the two-scale Lorenz model to compare the two
methods. The accuracy in long-range forecast experiments is somewhat similar
between the surrogate models using the resolvent correction and the tendency
correction. By contrast, the surrogate models using the tendency correction
significantly outperform the surrogate models using the resolvent correction in
data assimilation experiments. Finally, we show that the tendency correction
opens the possibility to make online model error correction, \textit{i.e.}
improving the model progressively as new observations become available. The
resulting algorithm can be seen as a new formulation of weak-constraint 4D-Var.
We compare online and offline learning using the same framework with the
two-scale Lorenz system, and show that with online learning, it is possible to
extract all the information from sparse and noisy observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tackling the Overestimation of Forest Carbon with Deep Learning and Aerial Imagery. (arXiv:2107.11320v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reiersen_G/0/1/0/all/0/1">Gyri Reiersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dao_D/0/1/0/all/0/1">David Dao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lutjens_B/0/1/0/all/0/1">Bj&#xf6;rn L&#xfc;tjens</a>, <a href="http://arxiv.org/find/cs/1/au:+Klemmer_K/0/1/0/all/0/1">Konstantin Klemmer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoxiang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11320">
                                    <div class="article-summary-box-inner">
                                        <span>Forest carbon offsets are increasingly popular and can play a significant
role in financing climate mitigation, forest conservation, and reforestation.
Measuring how much carbon is stored in forests is, however, still largely done
via expensive, time-consuming, and sometimes unaccountable field measurements.
To overcome these limitations, many verification bodies are leveraging machine
learning (ML) algorithms to estimate forest carbon from satellite or aerial
imagery. Aerial imagery allows for tree species or family classification, which
improves the satellite imagery-based forest type classification. However,
aerial imagery is significantly more expensive to collect and it is unclear by
how much the higher resolution improves the forest carbon estimation. This
proposal paper describes the first systematic comparison of forest carbon
estimation from aerial imagery, satellite imagery, and ground-truth field
measurements via deep learning-based algorithms for a tropical reforestation
project. Our initial results show that forest carbon estimates from satellite
imagery can overestimate above-ground biomass by more than 10-times for
tropical reforestation projects. The significant difference between aerial and
satellite-derived forest carbon measurements shows the potential for aerial
imagery-based ML algorithms and raises the importance to extend this study to a
global benchmark between options for carbon measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Stable Adaptive Explicit Differentiable Predictive Control for Unknown Linear Systems. (arXiv:2004.11184v5 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Drgona_J/0/1/0/all/0/1">Jan Drgona</a>, <a href="http://arxiv.org/find/eess/1/au:+Tuor_A/0/1/0/all/0/1">Aaron Tuor</a>, <a href="http://arxiv.org/find/eess/1/au:+Vrabie_D/0/1/0/all/0/1">Draguna Vrabie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.11184">
                                    <div class="article-summary-box-inner">
                                        <span>We present differentiable predictive control (DPC), a method for learning
constrained adaptive neural control policies and dynamical models of unknown
linear systems. DPC presents an approximate data-driven solution approach to
the explicit Model Predictive Control (MPC) problem as a scalable alternative
to computationally expensive multiparametric programming solvers. DPC is
formulated as a constrained deep learning problem whose architecture is
inspired by the structure of classical MPC. The optimization of the neural
control policy is based on automatic differentiation of the MPC-inspired loss
function through a differentiable closed-loop system model. This novel solution
approach can optimize adaptive neural control policies for time-varying
references while obeying state and input constraints without the prior need of
an MPC controller. We show that DPC can learn to stabilize constrained neural
control policies for systems with unstable dynamics. Moreover, we provide
sufficient conditions for asymptotic stability of generic closed-loop system
dynamics with neural feedback policies. In simulation case studies, we assess
the performance of the proposed DPC method in terms of reference tracking,
robustness, and computational and memory footprints compared against classical
model-based and data-driven control approaches. We demonstrate that DPC scales
linearly with problem size, compared to exponential scalability of classical
explicit MPC based on multiparametric programming.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimum Risk Portfolio and Eigen Portfolio: A Comparative Analysis Using Selected Stocks from the Indian Stock Market. (arXiv:2107.11371v1 [q-fin.PM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Sen_J/0/1/0/all/0/1">Jaydip Sen</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Mehtab_S/0/1/0/all/0/1">Sidra Mehtab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11371">
                                    <div class="article-summary-box-inner">
                                        <span>Designing an optimum portfolio that allocates weights to its constituent
stocks in a way that achieves the best trade-off between the return and the
risk is a challenging research problem. The classical mean-variance theory of
portfolio proposed by Markowitz is found to perform sub-optimally on the
real-world stock market data since the error in estimation for the expected
returns adversely affects the performance of the portfolio. This paper presents
three approaches to portfolio design, viz, the minimum risk portfolio, the
optimum risk portfolio, and the Eigen portfolio, for seven important sectors of
the Indian stock market. The daily historical prices of the stocks are scraped
from Yahoo Finance website from January 1, 2016, to December 31, 2020. Three
portfolios are built for each of the seven sectors chosen for this study, and
the portfolios are analyzed on the training data based on several metrics such
as annualized return and risk, weights assigned to the constituent stocks, the
correlation heatmaps, and the principal components of the Eigen portfolios.
Finally, the optimum risk portfolios and the Eigen portfolios for all sectors
are tested on their return over a period of a six-month period. The
performances of the portfolios are compared and the portfolio yielding the
higher return for each sector is identified.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate spectral clustering using both reference vectors and topology of the network generated by growing neural gas. (arXiv:2009.07101v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fujita_K/0/1/0/all/0/1">Kazuhisa Fujita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07101">
                                    <div class="article-summary-box-inner">
                                        <span>Spectral clustering (SC) is one of the most popular clustering methods and
often outperforms traditional clustering methods. SC uses the eigenvectors of a
Laplacian matrix calculated from a similarity matrix of a dataset. SC has
serious drawbacks: the significant increases in the time complexity derived
from the computation of eigenvectors and the memory space complexity to store
the similarity matrix. To address the issues, I develop a new approximate
spectral clustering using the network generated by growing neural gas (GNG),
called ASC with GNG in this study. ASC with GNG uses not only reference vectors
for vector quantization but also the topology of the network for extraction of
the topological relationship between data points in a dataset. ASC with GNG
calculates the similarity matrix from both the reference vectors and the
topology of the network generated by GNG. Using the network generated from a
dataset by GNG, ASC with GNG achieves to reduce the computational and space
complexities and improve clustering quality. In this study, I demonstrate that
ASC with GNG effectively reduces the computational time. Moreover, this study
shows that ASC with GNG provides equal to or better clustering performance than
SC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Mixed Integer Programs Using Neural Networks. (arXiv:2012.13349v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Nair_V/0/1/0/all/0/1">Vinod Nair</a>, <a href="http://arxiv.org/find/math/1/au:+Bartunov_S/0/1/0/all/0/1">Sergey Bartunov</a>, <a href="http://arxiv.org/find/math/1/au:+Gimeno_F/0/1/0/all/0/1">Felix Gimeno</a>, <a href="http://arxiv.org/find/math/1/au:+Glehn_I/0/1/0/all/0/1">Ingrid von Glehn</a>, <a href="http://arxiv.org/find/math/1/au:+Lichocki_P/0/1/0/all/0/1">Pawel Lichocki</a>, <a href="http://arxiv.org/find/math/1/au:+Lobov_I/0/1/0/all/0/1">Ivan Lobov</a>, <a href="http://arxiv.org/find/math/1/au:+ODonoghue_B/0/1/0/all/0/1">Brendan O&#x27;Donoghue</a>, <a href="http://arxiv.org/find/math/1/au:+Sonnerat_N/0/1/0/all/0/1">Nicolas Sonnerat</a>, <a href="http://arxiv.org/find/math/1/au:+Tjandraatmadja_C/0/1/0/all/0/1">Christian Tjandraatmadja</a>, <a href="http://arxiv.org/find/math/1/au:+Wang_P/0/1/0/all/0/1">Pengming Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Addanki_R/0/1/0/all/0/1">Ravichandra Addanki</a>, <a href="http://arxiv.org/find/math/1/au:+Hapuarachchi_T/0/1/0/all/0/1">Tharindi Hapuarachchi</a>, <a href="http://arxiv.org/find/math/1/au:+Keck_T/0/1/0/all/0/1">Thomas Keck</a>, <a href="http://arxiv.org/find/math/1/au:+Keeling_J/0/1/0/all/0/1">James Keeling</a>, <a href="http://arxiv.org/find/math/1/au:+Kohli_P/0/1/0/all/0/1">Pushmeet Kohli</a>, <a href="http://arxiv.org/find/math/1/au:+Ktena_I/0/1/0/all/0/1">Ira Ktena</a>, <a href="http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1">Yujia Li</a>, <a href="http://arxiv.org/find/math/1/au:+Vinyals_O/0/1/0/all/0/1">Oriol Vinyals</a>, <a href="http://arxiv.org/find/math/1/au:+Zwols_Y/0/1/0/all/0/1">Yori Zwols</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13349">
                                    <div class="article-summary-box-inner">
                                        <span>Mixed Integer Programming (MIP) solvers rely on an array of sophisticated
heuristics developed with decades of research to solve large-scale MIP
instances encountered in practice. Machine learning offers to automatically
construct better heuristics from data by exploiting shared structure among
instances in the data. This paper applies learning to the two key sub-tasks of
a MIP solver, generating a high-quality joint variable assignment, and bounding
the gap in objective value between that assignment and an optimal one. Our
approach constructs two corresponding neural network-based components, Neural
Diving and Neural Branching, to use in a base MIP solver such as SCIP. Neural
Diving learns a deep neural network to generate multiple partial assignments
for its integer variables, and the resulting smaller MIPs for un-assigned
variables are solved with SCIP to construct high quality joint assignments.
Neural Branching learns a deep neural network to make variable selection
decisions in branch-and-bound to bound the objective value gap with a small
tree. This is done by imitating a new variant of Full Strong Branching we
propose that scales to large instances using GPUs. We evaluate our approach on
six diverse real-world datasets, including two Google production datasets and
MIPLIB, by training separate neural networks on each. Most instances in all the
datasets combined have $10^3-10^6$ variables and constraints after presolve,
which is significantly larger than previous learning approaches. Comparing
solvers with respect to primal-dual gap averaged over a held-out set of
instances, the learning-augmented SCIP is 2x to 10x better on all datasets
except one on which it is $10^5$x better, at large time limits. To the best of
our knowledge, ours is the first learning approach to demonstrate such large
improvements over SCIP on both large-scale real-world application datasets and
MIPLIB.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supervised Tree-Wasserstein Distance. (arXiv:2101.11520v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Takezawa_Y/0/1/0/all/0/1">Yuki Takezawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_R/0/1/0/all/0/1">Ryoma Sato</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamada_M/0/1/0/all/0/1">Makoto Yamada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.11520">
                                    <div class="article-summary-box-inner">
                                        <span>To measure the similarity of documents, the Wasserstein distance is a
powerful tool, but it requires a high computational cost. Recently, for fast
computation of the Wasserstein distance, methods for approximating the
Wasserstein distance using a tree metric have been proposed. These tree-based
methods allow fast comparisons of a large number of documents; however, they
are unsupervised and do not learn task-specific distances. In this work, we
propose the Supervised Tree-Wasserstein (STW) distance, a fast, supervised
metric learning method based on the tree metric. Specifically, we rewrite the
Wasserstein distance on the tree metric by the parent-child relationships of a
tree and formulate it as a continuous optimization problem using a contrastive
loss. Experimentally, we show that the STW distance can be computed fast, and
improves the accuracy of document classification tasks. Furthermore, the STW
distance is formulated by matrix multiplications, runs on a GPU, and is
suitable for batch processing. Therefore, we show that the STW distance is
extremely efficient when comparing a large number of documents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs Using Deep Reinforcement Learning. (arXiv:2101.08074v2 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yan_C/0/1/0/all/0/1">Chao Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiang_X/0/1/0/all/0/1">Xiaojia Xiang</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_C/0/1/0/all/0/1">Chang Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lan_Z/0/1/0/all/0/1">Zhen Lan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08074">
                                    <div class="article-summary-box-inner">
                                        <span>Developing the flocking behavior for a dynamic squad of fixed-wing UAVs is
still a challenge due to kinematic complexity and environmental uncertainty. In
this paper, we deal with the decentralized flocking and collision avoidance
problem through deep reinforcement learning (DRL). Specifically, we formulate a
decentralized DRL-based decision making framework from the perspective of every
follower, where a collision avoidance mechanism is integrated into the flocking
controller. Then, we propose a novel reinforcement learning algorithm PS-CACER
for training a shared control policy for all the followers. Besides, we design
a plug-n-play embedding module based on convolutional neural networks and the
attention mechanism. As a result, the variable-length system state can be
encoded into a fixed-length embedding vector, which makes the learned DRL
policy independent with the number and the order of followers. Finally,
numerical simulation results demonstrate the effectiveness of the proposed
method, and the learned policies can be directly transferred to semi-physical
simulation without any parameter finetuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structack: Structure-based Adversarial Attacks on Graph Neural Networks. (arXiv:2107.11327v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hussain_H/0/1/0/all/0/1">Hussain Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Duricic_T/0/1/0/all/0/1">Tomislav Duricic</a>, <a href="http://arxiv.org/find/cs/1/au:+Lex_E/0/1/0/all/0/1">Elisabeth Lex</a>, <a href="http://arxiv.org/find/cs/1/au:+Helic_D/0/1/0/all/0/1">Denis Helic</a>, <a href="http://arxiv.org/find/cs/1/au:+Strohmaier_M/0/1/0/all/0/1">Markus Strohmaier</a>, <a href="http://arxiv.org/find/cs/1/au:+Kern_R/0/1/0/all/0/1">Roman Kern</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11327">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that graph neural networks (GNNs) are vulnerable to
adversarial attacks on graph data. Common attack approaches are typically
informed, i.e. they have access to information about node attributes such as
labels and feature vectors. In this work, we study adversarial attacks that are
uninformed, where an attacker only has access to the graph structure, but no
information about node attributes. Here the attacker aims to exploit structural
knowledge and assumptions, which GNN models make about graph data. In
particular, literature has shown that structural node centrality and similarity
have a strong influence on learning with GNNs. Therefore, we study the impact
of centrality and similarity on adversarial attacks on GNNs. We demonstrate
that attackers can exploit this information to decrease the performance of GNNs
by focusing on injecting links between nodes of low similarity and,
surprisingly, low centrality. We show that structure-based uninformed attacks
can approach the performance of informed attacks, while being computationally
more efficient. With our paper, we present a new attack strategy on GNNs that
we refer to as Structack. Structack can successfully manipulate the performance
of GNNs with very limited information while operating under tight computational
constraints. Our work contributes towards building more robust machine learning
approaches on graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A fast and simple modification of Newton&#x27;s method helping to avoid saddle points. (arXiv:2006.01512v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Truong_T/0/1/0/all/0/1">Tuyen Trung Truong</a>, <a href="http://arxiv.org/find/math/1/au:+To_T/0/1/0/all/0/1">Tat Dat To</a>, <a href="http://arxiv.org/find/math/1/au:+Nguyen_T/0/1/0/all/0/1">Tuan Hang Nguyen</a>, <a href="http://arxiv.org/find/math/1/au:+Nguyen_T/0/1/0/all/0/1">Thu Hang Nguyen</a>, <a href="http://arxiv.org/find/math/1/au:+Nguyen_H/0/1/0/all/0/1">Hoang Phuong Nguyen</a>, <a href="http://arxiv.org/find/math/1/au:+Helmy_M/0/1/0/all/0/1">Maged Helmy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.01512">
                                    <div class="article-summary-box-inner">
                                        <span>We propose in this paper New Q-Newton&#x27;s method. The update rule for the
simplest version is $x_{n+1}&#x3D;x_n-w_n$ where
$w_n&#x3D;pr_{A_n,+}(v_n)-pr_{A_n,-}(v_n)$, with $A_n&#x3D;\nabla
^2f(x_n)+\delta_n||\nabla f(x_n)||^2.Id$ and $v_n&#x3D;A_n^{-1}.\nabla f(x_n)$. Here
$\delta_n$ is an appropriate real number so that $A_n$ is invertible, and
$pr_{A_n,\pm}$ are projections to the vector subspaces generated by
eigenvectors of positive (correspondingly negative) eigenvalues of $A_n$.

The main result of this paper roughly says that if $f$ is $C^3$ and a
sequence $\{x_n\}$, constructed by the New Q-Newton&#x27;s method from a random
initial point $x_0$, {\bf converges}, then the limit point is a critical point
and is not a saddle point, and the convergence rate is the same as that of
Newton&#x27;s method. At the end of the paper, we present some issues (saddle points
and convergence) one faces when implementing Newton&#x27;s method and modifications
into Deep Neural Networks. We test the good performance of New Q-Newton&#x27;s
method against algorithms such as Newton&#x27;s method, BFGS, Adaptive Cubic
Regularization, Random damping Newton&#x27;s method and Inertial Newton&#x27;s method, as
well as Unbounded Two-way Backtracking Gradient Descent. The experiments cover
both realistic settings (such as a toy model of protein folding and stochastic
optimization) as well as various benchmark test functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Integrating Scientific Knowledge with Machine Learning for Engineering and Environmental Systems. (arXiv:2003.04919v5 [physics.comp-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Willard_J/0/1/0/all/0/1">Jared Willard</a>, <a href="http://arxiv.org/find/physics/1/au:+Jia_X/0/1/0/all/0/1">Xiaowei Jia</a>, <a href="http://arxiv.org/find/physics/1/au:+Xu_S/0/1/0/all/0/1">Shaoming Xu</a>, <a href="http://arxiv.org/find/physics/1/au:+Steinbach_M/0/1/0/all/0/1">Michael Steinbach</a>, <a href="http://arxiv.org/find/physics/1/au:+Kumar_V/0/1/0/all/0/1">Vipin Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.04919">
                                    <div class="article-summary-box-inner">
                                        <span>There is a growing consensus that solutions to complex science and
engineering problems require novel methodologies that are able to integrate
traditional physics-based modeling approaches with state-of-the-art machine
learning (ML) techniques. This paper provides a structured overview of such
techniques. Application-centric objective areas for which these approaches have
been applied are summarized, and then classes of methodologies used to
construct physics-guided ML models and hybrid physics-ML frameworks are
described. We then provide a taxonomy of these existing techniques, which
uncovers knowledge gaps and potential crossovers of methods between disciplines
that can serve as ideas for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Task-Agnostic Action Spaces for Movement Optimization. (arXiv:2009.10337v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Babadi_A/0/1/0/all/0/1">Amin Babadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Panne_M/0/1/0/all/0/1">Michiel van de Panne</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">C. Karen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamalainen_P/0/1/0/all/0/1">Perttu H&#xe4;m&#xe4;l&#xe4;inen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.10337">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel method for exploring the dynamics of physically based
animated characters, and learning a task-agnostic action space that makes
movement optimization easier. Like several previous papers, we parameterize
actions as target states, and learn a short-horizon goal-conditioned low-level
control policy that drives the agent&#x27;s state towards the targets. Our novel
contribution is that with our exploration data, we are able to learn the
low-level policy in a generic manner and without any reference movement data.
Trained once for each agent or simulation environment, the policy improves the
efficiency of optimizing both trajectories and high-level policies across
multiple tasks and optimization algorithms. We also contribute novel
visualizations that show how using target states as actions makes optimized
trajectories more robust to disturbances; this manifests as wider optima that
are easy to find. Due to its simplicity and generality, our proposed approach
should provide a building block that can improve a large variety of movement
optimization methods and applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Empirical Risk Minimization in the Interpolating Regime with Application to Neural Network Learning. (arXiv:1905.10686v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mucke_N/0/1/0/all/0/1">Nicole M&#xfc;cke</a>, <a href="http://arxiv.org/find/stat/1/au:+Steinwart_I/0/1/0/all/0/1">Ingo Steinwart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.10686">
                                    <div class="article-summary-box-inner">
                                        <span>A common strategy to train deep neural networks (DNNs) is to use very large
architectures and to train them until they (almost) achieve zero training
error. Empirically observed good generalization performance on test data, even
in the presence of lots of label noise, corroborate such a procedure. On the
other hand, in statistical learning theory it is known that over-fitting models
may lead to poor generalization properties, occurring in e.g. empirical risk
minimization (ERM) over too large hypotheses classes. Inspired by this
contradictory behavior, so-called interpolation methods have recently received
much attention, leading to consistent and optimally learning methods for some
local averaging schemes with zero training error. However, there is no
theoretical analysis of interpolating ERM-like methods so far. We take a step
in this direction by showing that for certain, large hypotheses classes, some
interpolating ERMs enjoy very good statistical guarantees while others fail in
the worst sense. Moreover, we show that the same phenomenon occurs for DNNs
with zero training error and sufficiently large architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Breaking Type Safety in Go: An Empirical Study on the Usage of the unsafe Package. (arXiv:2006.09973v4 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Costa_D/0/1/0/all/0/1">Diego Elias Costa</a>, <a href="http://arxiv.org/find/cs/1/au:+Mujahid_S/0/1/0/all/0/1">Suhaib Mujahid</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdalkareem_R/0/1/0/all/0/1">Rabe Abdalkareem</a>, <a href="http://arxiv.org/find/cs/1/au:+Shihab_E/0/1/0/all/0/1">Emad Shihab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09973">
                                    <div class="article-summary-box-inner">
                                        <span>A decade after its first release, the Go programming language has become a
major programming language in the development landscape. While praised for its
clean syntax and C-like performance, Go also contains a strong static
type-system that prevents arbitrary type casting and arbitrary memory access,
making the language type-safe by design. However, to give developers the
possibility of implementing low-level code, Go ships with a special package
called unsafe that offers developers a way around the type-safety of Go
programs. The package gives greater flexibility to developers but comes at a
higher risk of runtime errors, chances of non-portability, and the loss of
compatibility guarantees for future versions of Go.

In this paper, we present the first large-scale study on the usage of the
unsafe package in 2,438 popular Go projects. Our investigation shows that
unsafe is used in 24% of Go projects, motivated primarily by communicating with
operating systems and C code, but is also commonly used as a source of
performance optimization. Developers are willing to use unsafe to break
language specifications (e.g., string immutability) for better performance and
6% of analyzed projects that use unsafe perform risky pointer conversions that
can lead to program crashes and unexpected behavior. Furthermore, we report a
series of real issues faced by projects that use unsafe, from crashing errors
and non-deterministic behavior to having their deployment restricted from
certain popular environments. Our findings can be used to understand how and
why developers break type-safety in Go, and help motivate further tools and
language development that could make the usage of unsafe in Go even safer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Hard-Parameter Sharing in Multi-Task Learning. (arXiv:2107.11359v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lijun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qizheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_H/0/1/0/all/0/1">Hui Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11359">
                                    <div class="article-summary-box-inner">
                                        <span>Hard parameter sharing in multi-task learning (MTL) allows tasks to share
some of model parameters, reducing storage cost and improving prediction
accuracy. The common sharing practice is to share bottom layers of a deep
neural network among tasks while using separate top layers for each task. In
this work, we revisit this common practice via an empirical study on
fine-grained image classification tasks and make two surprising observations.
(1) Using separate bottom-layer parameters could achieve significantly better
performance than the common practice and this phenomenon holds for different
number of tasks jointly trained on different backbone architectures with
different quantity of task-specific parameters. (2) A multi-task model with a
small proportion of task-specific parameters from bottom layers can achieve
competitive performance with independent models trained on each task separately
and outperform a state-of-the-art MTL framework. Our observations suggest that
people rethink the current sharing paradigm and adopt the new strategy of using
separate bottom-layer parameters as a stronger baseline for model design in
MTL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mining Data Impressions from Deep Models as Substitute for the Unavailable Training Data. (arXiv:2101.06069v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nayak_G/0/1/0/all/0/1">Gaurav Kumar Nayak</a>, <a href="http://arxiv.org/find/cs/1/au:+Mopuri_K/0/1/0/all/0/1">Konda Reddy Mopuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Saksham Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1">Anirban Chakraborty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.06069">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained deep models hold their learnt knowledge in the form of model
parameters. These parameters act as &quot;memory&quot; for the trained models and help
them generalize well on unseen data. However, in absence of training data, the
utility of a trained model is merely limited to either inference or better
initialization towards a target task. In this paper, we go further and extract
synthetic data by leveraging the learnt model parameters. We dub them &quot;Data
Impressions&quot;, which act as proxy to the training data and can be used to
realize a variety of tasks. These are useful in scenarios where only the
pretrained models are available and the training data is not shared (e.g., due
to privacy or sensitivity concerns). We show the applicability of data
impressions in solving several computer vision tasks such as unsupervised
domain adaptation, continual learning as well as knowledge distillation. We
also study the adversarial robustness of lightweight models trained via
knowledge distillation using these data impressions. Further, we demonstrate
the efficacy of data impressions in generating data-free Universal Adversarial
Perturbations (UAPs) with better fooling rates. Extensive experiments performed
on benchmark datasets demonstrate competitive performance achieved using data
impressions in absence of original training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimum-Distortion Embedding. (arXiv:2103.02559v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1">Akshay Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Ali_A/0/1/0/all/0/1">Alnur Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyd_S/0/1/0/all/0/1">Stephen Boyd</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02559">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the vector embedding problem. We are given a finite set of items,
with the goal of assigning a representative vector to each one, possibly under
some constraints (such as the collection of vectors being standardized, i.e.,
have zero mean and unit covariance). We are given data indicating that some
pairs of items are similar, and optionally, some other pairs are dissimilar.
For pairs of similar items, we want the corresponding vectors to be near each
other, and for dissimilar pairs, we want the corresponding vectors to not be
near each other, measured in Euclidean distance. We formalize this by
introducing distortion functions, defined for some pairs of the items. Our goal
is to choose an embedding that minimizes the total distortion, subject to the
constraints. We call this the minimum-distortion embedding (MDE) problem.

The MDE framework is simple but general. It includes a wide variety of
embedding methods, such as spectral embedding, principal component analysis,
multidimensional scaling, dimensionality reduction methods (like Isomap and
UMAP), force-directed layout, and others. It also includes new embeddings, and
provides principled ways of validating historical and new embeddings alike.

We develop a projected quasi-Newton method that approximately solves MDE
problems and scales to large data sets. We implement this method in PyMDE, an
open-source Python package. In PyMDE, users can select from a library of
distortion functions and constraints or specify custom ones, making it easy to
rapidly experiment with different embeddings. Our software scales to data sets
with millions of items and tens of millions of distortion functions. To
demonstrate our method, we compute embeddings for several real-world data sets,
including images, an academic co-author network, US county demographic data,
and single-cell mRNA transcriptomes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Toward Automated Classroom Observation: Multimodal Machine Learning to Estimate CLASS Positive Climate and Negative Climate. (arXiv:2005.09525v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramakrishnan_A/0/1/0/all/0/1">Anand Ramakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zylich_B/0/1/0/all/0/1">Brian Zylich</a>, <a href="http://arxiv.org/find/cs/1/au:+Ottmar_E/0/1/0/all/0/1">Erin Ottmar</a>, <a href="http://arxiv.org/find/cs/1/au:+LoCasale_Crouch_J/0/1/0/all/0/1">Jennifer LoCasale-Crouch</a>, <a href="http://arxiv.org/find/cs/1/au:+Whitehill_J/0/1/0/all/0/1">Jacob Whitehill</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.09525">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we present a multi-modal machine learning-based system, which we
call ACORN, to analyze videos of school classrooms for the Positive Climate
(PC) and Negative Climate (NC) dimensions of the CLASS observation protocol
that is widely used in educational research. ACORN uses convolutional neural
networks to analyze spectral audio features, the faces of teachers and
students, and the pixels of each image frame, and then integrates this
information over time using Temporal Convolutional Networks. The audiovisual
ACORN&#x27;s PC and NC predictions have Pearson correlations of $0.55$ and $0.63$
with ground-truth scores provided by expert CLASS coders on the UVA Toddler
dataset (cross-validation on $n&#x3D;300$ 15-min video segments), and a purely
auditory ACORN predicts PC and NC with correlations of $0.36$ and $0.41$ on the
MET dataset (test set of $n&#x3D;2000$ videos segments). These numbers are similar
to inter-coder reliability of human coders. Finally, using Graph Convolutional
Networks we make early strides (AUC&#x3D;$0.70$) toward predicting the specific
moments (45-90sec clips) when the PC is particularly weak/strong. Our findings
inform the design of automatic classroom observation and also more general
video activity recognition and summary recognition systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BrainNetGAN: Data augmentation of brain connectivity using generative adversarial network for dementia classification. (arXiv:2103.08494v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yiran Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola-Bibiane Schonlieb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08494">
                                    <div class="article-summary-box-inner">
                                        <span>Alzheimer&#x27;s disease (AD) is the most common age-related dementia. It remains
a challenge to identify the individuals at risk of dementia for precise
management. Brain MRI offers a noninvasive biomarker to detect brain aging.
Previous evidence shows that the brain structural change detected by diffusion
MRI is associated with dementia. Mounting studies has conceptualised the brain
as a complex network, which has shown the utility of this approach in
characterising various neurological and psychiatric disorders. Therefore, the
structural connectivity shows promise in dementia classification. The proposed
BrainNetGAN is a generative adversarial network variant to augment the brain
structural connectivity matrices for binary dementia classification tasks.
Structural connectivity matrices between separated brain regions are
constructed using tractography on diffusion MRI data. The BrainNetGAN model is
trained to generate fake brain connectivity matrices, which are expected to
reflect latent distribution of the real brain network data. Finally, a
convolutional neural network classifier is proposed for binary dementia
classification. Numerical results show that the binary classification
performance in the testing set was improved using the BrainNetGAN augmented
dataset. The proposed methodology allows quick synthesis of an arbitrary number
of augmented connectivity matrices and can be easily transferred to similar
classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Differentiable Language Model Adversarial Attack on Text Classifiers. (arXiv:2107.11275v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fursov_I/0/1/0/all/0/1">Ivan Fursov</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1">Alexey Zaytsev</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnyshev_P/0/1/0/all/0/1">Pavel Burnyshev</a>, <a href="http://arxiv.org/find/cs/1/au:+Dmitrieva_E/0/1/0/all/0/1">Ekaterina Dmitrieva</a>, <a href="http://arxiv.org/find/cs/1/au:+Klyuchnikov_N/0/1/0/all/0/1">Nikita Klyuchnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kravchenko_A/0/1/0/all/0/1">Andrey Kravchenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Artemova_E/0/1/0/all/0/1">Ekaterina Artemova</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1">Evgeny Burnaev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11275">
                                    <div class="article-summary-box-inner">
                                        <span>Robustness of huge Transformer-based models for natural language processing
is an important issue due to their capabilities and wide adoption. One way to
understand and improve robustness of these models is an exploration of an
adversarial attack scenario: check if a small perturbation of an input can fool
a model.

Due to the discrete nature of textual data, gradient-based adversarial
methods, widely used in computer vision, are not applicable per~se. The
standard strategy to overcome this issue is to develop token-level
transformations, which do not take the whole sentence into account.

In this paper, we propose a new black-box sentence-level attack. Our method
fine-tunes a pre-trained language model to generate adversarial examples. A
proposed differentiable loss function depends on a substitute classifier score
and an approximate edit distance computed via a deep learning model.

We show that the proposed attack outperforms competitors on a diverse set of
NLP problems for both computed metrics and human evaluation. Moreover, due to
the usage of the fine-tuned language model, the generated adversarial examples
are hard to detect, thus current models are not robust. Hence, it is difficult
to defend from the proposed attack, which is not the case for other attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rigging the Lottery: Making All Tickets Winners. (arXiv:1911.11134v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Evci_U/0/1/0/all/0/1">Utku Evci</a>, <a href="http://arxiv.org/find/cs/1/au:+Gale_T/0/1/0/all/0/1">Trevor Gale</a>, <a href="http://arxiv.org/find/cs/1/au:+Menick_J/0/1/0/all/0/1">Jacob Menick</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_P/0/1/0/all/0/1">Pablo Samuel Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Elsen_E/0/1/0/all/0/1">Erich Elsen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.11134">
                                    <div class="article-summary-box-inner">
                                        <span>Many applications require sparse neural networks due to space or inference
time restrictions. There is a large body of work on training dense networks to
yield sparse networks for inference, but this limits the size of the largest
trainable sparse model to that of the largest trainable dense model. In this
paper we introduce a method to train sparse neural networks with a fixed
parameter count and a fixed computational cost throughout training, without
sacrificing accuracy relative to existing dense-to-sparse training methods. Our
method updates the topology of the sparse network during training by using
parameter magnitudes and infrequent gradient calculations. We show that this
approach requires fewer floating-point operations (FLOPs) to achieve a given
level of accuracy compared to prior techniques. We demonstrate state-of-the-art
sparse training results on a variety of networks and datasets, including
ResNet-50, MobileNets on Imagenet-2012, and RNNs on WikiText-103. Finally, we
provide some insights into why allowing the topology to change during the
optimization can overcome local minima encountered when the topology remains
static. Code used in our work can be found in github.com/google-research/rigl.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularising Inverse Problems with Generative Machine Learning Models. (arXiv:2107.11191v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Duff_M/0/1/0/all/0/1">Margaret Duff</a>, <a href="http://arxiv.org/find/eess/1/au:+Campbell_N/0/1/0/all/0/1">Neill D. F. Campbell</a>, <a href="http://arxiv.org/find/eess/1/au:+Ehrhardt_M/0/1/0/all/0/1">Matthias J. Ehrhardt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11191">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural network approaches to inverse imaging problems have produced
impressive results in the last few years. In this paper, we consider the use of
generative models in a variational regularisation approach to inverse problems.
The considered regularisers penalise images that are far from the range of a
generative model that has learned to produce images similar to a training
dataset. We name this family \textit{generative regularisers}. The success of
generative regularisers depends on the quality of the generative model and so
we propose a set of desired criteria to assess models and guide future
research. In our numerical experiments, we evaluate three common generative
models, autoencoders, variational autoencoders and generative adversarial
networks, against our desired criteria. We also test three different generative
regularisers on the inverse problems of deblurring, deconvolution, and
tomography. We show that the success of solutions restricted to lie exactly in
the range of the generator is highly dependent on the ability of the generative
model but that allowing small deviations from the range of the generator
produces more consistent results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Adaptive Submodular Maximization. (arXiv:2107.11333v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Shaojie Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11333">
                                    <div class="article-summary-box-inner">
                                        <span>Most of existing studies on adaptive submodular optimization focus on the
average-case, i.e., their objective is to find a policy that maximizes the
expected utility over a known distribution of realizations. However, a policy
that has a good average-case performance may have very poor performance under
the worst-case realization. In this study, we propose to study two variants of
adaptive submodular optimization problems, namely, worst-case adaptive
submodular maximization and robust submodular maximization. The first problem
aims to find a policy that maximizes the worst-case utility and the latter one
aims to find a policy, if any, that achieves both near optimal average-case
utility and worst-case utility simultaneously. We introduce a new class of
stochastic functions, called \emph{worst-case submodular function}. For the
worst-case adaptive submodular maximization problem subject to a $p$-system
constraint, we develop an adaptive worst-case greedy policy that achieves a
$\frac{1}{p+1}$ approximation ratio against the optimal worst-case utility if
the utility function is worst-case submodular. For the robust adaptive
submodular maximization problem subject to a cardinality constraint, if the
utility function is both worst-case submodular and adaptive submodular, we
develop a hybrid adaptive policy that achieves an approximation close to
$1-e^{-\frac{1}{2}}$ under both worst case setting and average case setting
simultaneously. We also describe several applications of our theoretical
results, including pool-base active learning, stochastic submodular set cover
and adaptive viral marketing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CogDL: Toolkit for Deep Learning on Graphs. (arXiv:2103.00959v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cen_Y/0/1/0/all/0/1">Yukuo Cen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Z/0/1/0/all/0/1">Zhenyu Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Q/0/1/0/all/0/1">Qibin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yizhen Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1">Xingcheng Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Aohan Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Shiguang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_G/0/1/0/all/0/1">Guohao Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00959">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning on graphs has attracted tremendous attention from the graph
learning community in recent years. It has been widely used in several
real-world applications such as social network analysis and recommender
systems. In this paper, we introduce CogDL, an extensive toolkit for deep
learning on graphs that allows researchers and developers to easily conduct
experiments and build applications. It provides standard training and
evaluation for the most important tasks in the graph domain, including node
classification, graph classification, etc. For each task, it provides
implementations of state-of-the-art models. The models in our toolkit are
divided into two major parts, graph embedding methods and graph neural
networks. Most of the graph embedding methods learn node-level or graph-level
representations in an unsupervised way and preserves the graph properties such
as structural information, while graph neural networks capture node features
and work in semi-supervised or self-supervised settings. All models implemented
in our toolkit can be easily reproducible for leaderboard results. Most models
in CogDL are developed on top of PyTorch, and users can leverage the advantages
of PyTorch to implement their own models. Furthermore, we demonstrate the
effectiveness of CogDL for real-world applications in AMiner, a large academic
mining system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Deep Registration Latent Spaces. (arXiv:2107.11238v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Estienne_T/0/1/0/all/0/1">Th&#xe9;o Estienne</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakalopoulou_M/0/1/0/all/0/1">Maria Vakalopoulou</a>, <a href="http://arxiv.org/find/cs/1/au:+Christodoulidis_S/0/1/0/all/0/1">Stergios Christodoulidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Battistella_E/0/1/0/all/0/1">Enzo Battistella</a>, <a href="http://arxiv.org/find/cs/1/au:+Henry_T/0/1/0/all/0/1">Th&#xe9;ophraste Henry</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerousseau_M/0/1/0/all/0/1">Marvin Lerousseau</a>, <a href="http://arxiv.org/find/cs/1/au:+Leroy_A/0/1/0/all/0/1">Amaury Leroy</a>, <a href="http://arxiv.org/find/cs/1/au:+Chassagnon_G/0/1/0/all/0/1">Guillaume Chassagnon</a>, <a href="http://arxiv.org/find/cs/1/au:+Revel_M/0/1/0/all/0/1">Marie-Pierre Revel</a>, <a href="http://arxiv.org/find/cs/1/au:+Paragios_N/0/1/0/all/0/1">Nikos Paragios</a>, <a href="http://arxiv.org/find/cs/1/au:+Deutsch_E/0/1/0/all/0/1">Eric Deutsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11238">
                                    <div class="article-summary-box-inner">
                                        <span>Explainability of deep neural networks is one of the most challenging and
interesting problems in the field. In this study, we investigate the topic
focusing on the interpretability of deep learning-based registration methods.
In particular, with the appropriate model architecture and using a simple
linear projection, we decompose the encoding space, generating a new basis, and
we empirically show that this basis captures various decomposed anatomically
aware geometrical transformations. We perform experiments using two different
datasets focusing on lungs and hippocampus MRI. We show that such an approach
can decompose the highly convoluted latent spaces of registration pipelines in
an orthogonal space with several interesting properties. We hope that this work
could shed some light on a better understanding of deep learning-based
registration methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Quantile Aggregation. (arXiv:2103.00083v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Kim_T/0/1/0/all/0/1">Taesup Kim</a>, <a href="http://arxiv.org/find/stat/1/au:+Fakoor_R/0/1/0/all/0/1">Rasool Fakoor</a>, <a href="http://arxiv.org/find/stat/1/au:+Mueller_J/0/1/0/all/0/1">Jonas Mueller</a>, <a href="http://arxiv.org/find/stat/1/au:+Tibshirani_R/0/1/0/all/0/1">Ryan J. Tibshirani</a>, <a href="http://arxiv.org/find/stat/1/au:+Smola_A/0/1/0/all/0/1">Alexander J. Smola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00083">
                                    <div class="article-summary-box-inner">
                                        <span>Conditional quantile estimation is a key statistical learning challenge
motivated by the need to quantify uncertainty in predictions or to model a
diverse population without being overly reductive. As such, many models have
been developed for this problem. Adopting a meta viewpoint, we propose a
general framework (inspired by neural network optimization) for aggregating any
number of conditional quantile models in order to boost predictive accuracy. We
consider weighted ensembling strategies of increasing flexibility where the
weights may vary over individual models, quantile levels, and feature values.
An appeal of our approach is its portability: we ensure that estimated
quantiles at adjacent levels do not cross by applying simple transformations
through which gradients can be backpropagated, and this allows us to leverage
the modern deep learning toolkit for building quantile ensembles. Our
experiments confirm that ensembling can lead to big gains in accuracy, even
when the constituent models are themselves powerful and flexible.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning with a Reject Option: A survey. (arXiv:2107.11277v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hendrickx_K/0/1/0/all/0/1">Kilian Hendrickx</a>, <a href="http://arxiv.org/find/cs/1/au:+Perini_L/0/1/0/all/0/1">Lorenzo Perini</a>, <a href="http://arxiv.org/find/cs/1/au:+Plas_D/0/1/0/all/0/1">Dries Van der Plas</a>, <a href="http://arxiv.org/find/cs/1/au:+Meert_W/0/1/0/all/0/1">Wannes Meert</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Jesse Davis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11277">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models always make a prediction, even when it is likely to
be inaccurate. This behavior should be avoided in many decision support
applications, where mistakes can have severe consequences. Albeit already
studied in 1970, machine learning with a reject option recently gained
interest. This machine learning subfield enables machine learning models to
abstain from making a prediction when likely to make a mistake.

This survey aims to provide an overview on machine learning with a reject
option. We introduce the conditions leading to two types of rejection,
ambiguity and novelty rejection. Moreover, we define the existing architectures
for models with a reject option, describe the standard learning strategies to
train such models and relate traditional machine learning techniques to
rejection. Additionally, we review strategies to evaluate a model&#x27;s predictive
and rejective quality. Finally, we provide examples of relevant application
domains and show how machine learning with rejection relates to other machine
learning research areas.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finite-Bit Quantization For Distributed Algorithms With Linear Convergence. (arXiv:2107.11304v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Lee_C/0/1/0/all/0/1">Chang-Shen Lee</a>, <a href="http://arxiv.org/find/math/1/au:+Michelusi_N/0/1/0/all/0/1">Nicol&#xf2; Michelusi</a>, <a href="http://arxiv.org/find/math/1/au:+Scutari_G/0/1/0/all/0/1">Gesualdo Scutari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11304">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies distributed algorithms for (strongly convex) composite
optimization problems over mesh networks, subject to quantized communications.
Instead of focusing on a specific algorithmic design, we propose a black-box
model casting distributed algorithms in the form of fixed-point iterates,
converging at linear rate. The algorithmic model is coupled with a novel
(random) Biased Compression (BC-)rule on the quantizer design, which preserves
linear convergence. A new quantizer coupled with a communication-efficient
encoding scheme is also proposed, which efficiently implements the BC-rule
using a finite number of bits. This contrasts with most of existing
quantization rules, whose implementation calls for an infinite number of bits.
A unified communication complexity analysis is developed for the black-box
model, determining the average number of bit required to reach a solution of
the optimization problem within the required accuracy. Numerical results
validate our theoretical findings and show that distributed algorithms equipped
with the proposed quantizer have more favorable communication complexity than
algorithms using existing quantization rules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wavelet Design in a Learning Framework. (arXiv:2107.11225v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jawali_D/0/1/0/all/0/1">Dhruv Jawali</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Abhishek Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Seelamantula_C/0/1/0/all/0/1">Chandra Sekhar Seelamantula</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11225">
                                    <div class="article-summary-box-inner">
                                        <span>Wavelets have proven to be highly successful in several signal and image
processing applications. Wavelet design has been an active field of research
for over two decades, with the problem often being approached from an
analytical perspective. In this paper, we introduce a learning based approach
to wavelet design. We draw a parallel between convolutional autoencoders and
wavelet multiresolution approximation, and show how the learning angle provides
a coherent computational framework for addressing the design problem. We aim at
designing data-independent wavelets by training filterbank autoencoders, which
precludes the need for customized datasets. In fact, we use high-dimensional
Gaussian vectors for training filterbank autoencoders, and show that a
near-zero training loss implies that the learnt filters satisfy the perfect
reconstruction property with very high probability. Properties of a wavelet
such as orthogonality, compact support, smoothness, symmetry, and vanishing
moments can be incorporated by designing the autoencoder architecture
appropriately and with a suitable regularization term added to the mean-squared
error cost used in the learning process. Our approach not only recovers the
well known Daubechies family of orthogonal wavelets and the
Cohen-Daubechies-Feauveau family of symmetric biorthogonal wavelets, but also
learns wavelets outside these families.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human Pose Estimation from Sparse Inertial Measurements through Recurrent Graph Convolution. (arXiv:2107.11214v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puchert_P/0/1/0/all/0/1">Patrik Puchert</a>, <a href="http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1">Timo Ropinski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11214">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the adjacency adaptive graph convolutional long-short term memory
network (AAGC-LSTM) for human pose estimation from sparse inertial
measurements, obtained from only 6 measurement units. The AAGC-LSTM combines
both spatial and temporal dependency in a single network operation. This is
made possible by equipping graph convolutions with adjacency adaptivity, which
also allows for learning unknown dependencies of the human body joints. To
further boost accuracy, we propose longitudinal loss weighting to consider
natural movement patterns, as well as body-aware contralateral data
augmentation. By combining these contributions, we are able to utilize the
inherent graph nature of the human body, and can thus outperform the state of
the art for human pose estimation from sparse inertial measurements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fundamental Limits and Tradeoffs in Invariant Representation Learning. (arXiv:2012.10713v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Han Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dan_C/0/1/0/all/0/1">Chen Dan</a>, <a href="http://arxiv.org/find/cs/1/au:+Aragam_B/0/1/0/all/0/1">Bryon Aragam</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1">Tommi S. Jaakkola</a>, <a href="http://arxiv.org/find/cs/1/au:+Gordon_G/0/1/0/all/0/1">Geoffrey J. Gordon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravikumar_P/0/1/0/all/0/1">Pradeep Ravikumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10713">
                                    <div class="article-summary-box-inner">
                                        <span>Many machine learning applications, e.g., privacy-preserving learning,
algorithmic fairness and domain adaptation/generalization, involve learning the
so-called invariant representations that achieve two competing goals: To
maximize information or accuracy with respect to a target while simultaneously
maximizing invariance or independence with respect to a set of protected
features (e.g.\ for fairness, privacy, etc). Despite its abundant applications
in the aforementioned domains, theoretical understanding on the limits and
tradeoffs of invariant representations is still severely lacking. In this
paper, we provide an information theoretic analysis of this general and
important problem under both classification and regression settings. In both
cases, we analyze the inherent tradeoffs between accuracy and invariance by
providing a geometric characterization of the feasible region in the
information plane, where we connect the geometric properties of this feasible
region to the fundamental limitations of the tradeoff problem. In the
regression setting, we further give a complete and exact characterization of
the frontier between accuracy and invariance. Although our contributions are
mainly theoretical, we also demonstrate the practical applications of our
results in certifying the suboptimality of certain representation learning
algorithms in both classification and regression tasks. Our results shed new
light on this fundamental problem by providing insights on the interplay
between accuracy and invariance. These results deepen our understanding of this
fundamental problem and may be useful in guiding the design of future
representation learning algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LARGE: Latent-Based Regression through GAN Semantics. (arXiv:2107.11186v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nitzan_Y/0/1/0/all/0/1">Yotam Nitzan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_R/0/1/0/all/0/1">Rinon Gal</a>, <a href="http://arxiv.org/find/cs/1/au:+Brenner_O/0/1/0/all/0/1">Ofir Brenner</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1">Daniel Cohen-Or</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11186">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel method for solving regression tasks using few-shot or weak
supervision. At the core of our method is the fundamental observation that GANs
are incredibly successful at encoding semantic information within their latent
space, even in a completely unsupervised setting. For modern generative
frameworks, this semantic encoding manifests as smooth, linear directions which
affect image attributes in a disentangled manner. These directions have been
widely used in GAN-based image editing. We show that such directions are not
only linear, but that the magnitude of change induced on the respective
attribute is approximately linear with respect to the distance traveled along
them. By leveraging this observation, our method turns a pre-trained GAN into a
regression model, using as few as two labeled samples. This enables solving
regression tasks on datasets and attributes which are difficult to produce
quality supervision for. Additionally, we show that the same latent-distances
can be used to sort collections of images by the strength of given attributes,
even in the absence of explicit supervision. Extensive experimental evaluations
demonstrate that our method can be applied across a wide range of domains,
leverage multiple latent direction discovery frameworks, and achieve
state-of-the-art results in few-shot and low-supervision settings, even when
compared to methods designed to tackle a single task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Shapley values: a measure of joint feature importance. (arXiv:2107.11357v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Harris_C/0/1/0/all/0/1">Chris Harris</a>, <a href="http://arxiv.org/find/stat/1/au:+Pymar_R/0/1/0/all/0/1">Richard Pymar</a>, <a href="http://arxiv.org/find/stat/1/au:+Rowat_C/0/1/0/all/0/1">Colin Rowat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11357">
                                    <div class="article-summary-box-inner">
                                        <span>The Shapley value is one of the most widely used model-agnostic measures of
feature importance in explainable AI: it has clear axiomatic foundations, is
guaranteed to uniquely exist, and has a clear interpretation as a feature&#x27;s
average effect on a model&#x27;s prediction. We introduce joint Shapley values,
which directly extend the Shapley axioms. This preserves the classic Shapley
value&#x27;s intuitions: joint Shapley values measure a set of features&#x27; average
effect on a model&#x27;s prediction. We prove the uniqueness of joint Shapley
values, for any order of explanation. Results for games show that joint Shapley
values present different insights from existing interaction indices, which
assess the effect of a feature within a set of features. Deriving joint Shapley
values in ML attribution problems thus gives us the first measure of the joint
effect of sets of features on model predictions. In a dataset with binary
features, we present a presence-adjusted method for calculating global values
that retains the efficiency property.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Channel Automatic Music Transcription Using Tensor Algebra. (arXiv:2107.11250v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Axel_M/0/1/0/all/0/1">Marmoret Axel</a>, <a href="http://arxiv.org/find/cs/1/au:+Nancy_B/0/1/0/all/0/1">Bertin Nancy</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeremy_C/0/1/0/all/0/1">Cohen Jeremy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11250">
                                    <div class="article-summary-box-inner">
                                        <span>Music is an art, perceived in unique ways by every listener, coming from
acoustic signals. In the meantime, standards as musical scores exist to
describe it. Even if humans can make this transcription, it is costly in terms
of time and efforts, even more with the explosion of information consecutively
to the rise of the Internet. In that sense, researches are driven in the
direction of Automatic Music Transcription. While this task is considered
solved in the case of single notes, it is still open when notes superpose
themselves, forming chords. This report aims at developing some of the existing
techniques towards Music Transcription, particularly matrix factorization, and
introducing the concept of multi-channel automatic music transcription. This
concept will be explored with mathematical objects called tensors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective and Interpretable fMRI Analysis via Functional Brain Network Generation. (arXiv:2107.11247v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kan_X/0/1/0/all/0/1">Xuan Kan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1">Hejie Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Ying Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Carl Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11247">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies in neuroscience show great potential of functional brain
networks constructed from fMRI data for popularity modeling and clinical
predictions. However, existing functional brain networks are noisy and unaware
of downstream prediction tasks, while also incompatible with recent powerful
machine learning models of GNNs. In this work, we develop an end-to-end
trainable pipeline to extract prominent fMRI features, generate brain networks,
and make predictions with GNNs, all under the guidance of downstream prediction
tasks. Preliminary experiments on the PNC fMRI data show the superior
effectiveness and unique interpretability of our framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Taxonomizing local versus global structure in neural network loss landscapes. (arXiv:2107.11228v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yaoqing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodgkinson_L/0/1/0/all/0/1">Liam Hodgkinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Theisen_R/0/1/0/all/0/1">Ryan Theisen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_J/0/1/0/all/0/1">Joe Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramchandran_K/0/1/0/all/0/1">Kannan Ramchandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11228">
                                    <div class="article-summary-box-inner">
                                        <span>Viewing neural network models in terms of their loss landscapes has a long
history in the statistical mechanics approach to learning, and in recent years
it has received attention within machine learning proper. Among other things,
local metrics (such as the smoothness of the loss landscape) have been shown to
correlate with global properties of the model (such as good generalization).
Here, we perform a detailed empirical analysis of the loss landscape structure
of thousands of neural network models, systematically varying learning tasks,
model architectures, and/or quantity/quality of data. By considering a range of
metrics that attempt to capture different aspects of the loss landscape, we
demonstrate that the best test accuracy is obtained when: the loss landscape is
globally well-connected; ensembles of trained models are more similar to each
other; and models converge to locally smooth regions. We also show that
globally poorly-connected landscapes can arise when models are small or when
they are trained to lower quality data; and that, if the loss landscape is
globally poorly-connected, then training to zero loss can actually lead to
worse test accuracy. Based on these results, we develop a simple
one-dimensional model with load-like and temperature-like parameters, we
introduce the notion of an \emph{effective loss landscape} depending on these
parameters, and we interpret our results in terms of a \emph{rugged convexity}
of the loss landscape. When viewed through this lens, our detailed empirical
results shed light on phases of learning (and consequent double descent
behavior), fundamental versus incidental determinants of good generalization,
the role of load-like and temperature-like parameters in the learning process,
different influences on the loss landscape from model and data, and the
relationships between local and global metrics, all topics of recent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human Pose Regression with Residual Log-likelihood Estimation. (arXiv:2107.11291v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiefeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_S/0/1/0/all/0/1">Siyuan Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Ailing Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Can Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1">Bo Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wentao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Cewu Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11291">
                                    <div class="article-summary-box-inner">
                                        <span>Heatmap-based methods dominate in the field of human pose estimation by
modelling the output distribution through likelihood heatmaps. In contrast,
regression-based methods are more efficient but suffer from inferior
performance. In this work, we explore maximum likelihood estimation (MLE) to
develop an efficient and effective regression-based methods. From the
perspective of MLE, adopting different regression losses is making different
assumptions about the output density function. A density function closer to the
true distribution leads to a better regression performance. In light of this,
we propose a novel regression paradigm with Residual Log-likelihood Estimation
(RLE) to capture the underlying output distribution. Concretely, RLE learns the
change of the distribution instead of the unreferenced underlying distribution
to facilitate the training process. With the proposed reparameterization
design, our method is compatible with off-the-shelf flow models. The proposed
method is effective, efficient and flexible. We show its potential in various
human pose estimation tasks with comprehensive experiments. Compared to the
conventional regression paradigm, regression with RLE bring 12.4 mAP
improvement on MSCOCO without any test-time overhead. Moreover, for the first
time, especially on multi-person pose estimation, our regression method is
superior to the heatmap-based methods. Our code is available at
https://github.com/Jeff-sjtu/res-loglikelihood-regression</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OLR 2021 Challenge: Datasets, Rules and Baselines. (arXiv:2107.11113v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Binling Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wenxuan Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhi_Y/0/1/0/all/0/1">Yiming Zhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Q/0/1/0/all/0/1">Qingyang Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Liming Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11113">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the sixth Oriental Language Recognition (OLR) 2021
Challenge, which intends to improve the performance of language recognition
systems and speech recognition systems within multilingual scenarios. The data
profile, four tasks, two baselines, and the evaluation principles are
introduced in this paper. In addition to the Language Identification (LID)
tasks, multilingual Automatic Speech Recognition (ASR) tasks are introduced to
OLR 2021 Challenge for the first time. The challenge this year focuses on more
practical and challenging problems, with four tasks: (1) constrained LID, (2)
unconstrained LID, (3) constrained multilingual ASR, (4) unconstrained
multilingual ASR. Baselines for LID tasks and multilingual ASR tasks are
provided, respectively. The LID baseline system is an extended TDNN x-vector
model constructed with Pytorch. A transformer-based end-to-end model is
provided as the multilingual ASR baseline system. These recipes will be online
published, and available for participants to construct their own LID or ASR
systems. The baseline results demonstrate that those tasks are rather
challenging and deserve more effort to achieve better performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Peeking inside the Black Box: Interpreting Deep Learning Models for Exoplanet Atmospheric Retrievals. (arXiv:2011.11284v2 [astro-ph.EP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Yip_K/0/1/0/all/0/1">Kai Hou Yip</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Changeat_Q/0/1/0/all/0/1">Quentin Changeat</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Nikolaou_N/0/1/0/all/0/1">Nikolaos Nikolaou</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Morvan_M/0/1/0/all/0/1">Mario Morvan</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Edwards_B/0/1/0/all/0/1">Billy Edwards</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Waldmann_I/0/1/0/all/0/1">Ingo P. Waldmann</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Tinetti_G/0/1/0/all/0/1">Giovanna Tinetti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11284">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning algorithms are growing in popularity in the field of
exoplanetary science due to their ability to model highly non-linear relations
and solve interesting problems in a data-driven manner. Several works have
attempted to perform fast retrievals of atmospheric parameters with the use of
machine learning algorithms like deep neural networks (DNNs). Yet, despite
their high predictive power, DNNs are also infamous for being &#x27;black boxes&#x27;. It
is their apparent lack of explainability that makes the astrophysics community
reluctant to adopt them. What are their predictions based on? How confident
should we be in them? When are they wrong and how wrong can they be? In this
work, we present a number of general evaluation methodologies that can be
applied to any trained model and answer questions like these. In particular, we
train three different popular DNN architectures to retrieve atmospheric
parameters from exoplanet spectra and show that all three achieve good
predictive performance. We then present an extensive analysis of the
predictions of DNNs, which can inform us - among other things - of the
credibility limits for atmospheric parameters for a given instrument and model.
Finally, we perform a perturbation-based sensitivity analysis to identify to
which features of the spectrum the outcome of the retrieval is most sensitive.
We conclude that for different molecules, the wavelength ranges to which the
DNN&#x27;s predictions are most sensitive, indeed coincide with their characteristic
absorption regions. The methodologies presented in this work help to improve
the evaluation of DNNs and to grant interpretability to their predictions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A comparison of combined data assimilation and machine learning methods for offline and online model error correction. (arXiv:2107.11114v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Farchi_A/0/1/0/all/0/1">Alban Farchi</a>, <a href="http://arxiv.org/find/stat/1/au:+Bocquet_M/0/1/0/all/0/1">Marc Bocquet</a>, <a href="http://arxiv.org/find/stat/1/au:+Laloyaux_P/0/1/0/all/0/1">Patrick Laloyaux</a>, <a href="http://arxiv.org/find/stat/1/au:+Bonavita_M/0/1/0/all/0/1">Massimo Bonavita</a>, <a href="http://arxiv.org/find/stat/1/au:+Malartic_Q/0/1/0/all/0/1">Quentin Malartic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11114">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies have shown that it is possible to combine machine learning
methods with data assimilation to reconstruct a dynamical system using only
sparse and noisy observations of that system. The same approach can be used to
correct the error of a knowledge-based model. The resulting surrogate model is
hybrid, with a statistical part supplementing a physical part. In practice, the
correction can be added as an integrated term (i.e. in the model resolvent) or
directly inside the tendencies of the physical model. The resolvent correction
is easy to implement. The tendency correction is more technical, in particular
it requires the adjoint of the physical model, but also more flexible. We use
the two-scale Lorenz model to compare the two methods. The accuracy in
long-range forecast experiments is somewhat similar between the surrogate
models using the resolvent correction and the tendency correction. By contrast,
the surrogate models using the tendency correction significantly outperform the
surrogate models using the resolvent correction in data assimilation
experiments. Finally, we show that the tendency correction opens the
possibility to make online model error correction, i.e. improving the model
progressively as new observations become available. The resulting algorithm can
be seen as a new formulation of weak-constraint 4D-Var. We compare online and
offline learning using the same framework with the two-scale Lorenz system, and
show that with online learning, it is possible to extract all the information
from sparse and noisy observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ax-BxP: Approximate Blocked Computation for Precision-Reconfigurable Deep Neural Network Acceleration. (arXiv:2011.13000v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Elangovan_R/0/1/0/all/0/1">Reena Elangovan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Shubham Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Raghunathan_A/0/1/0/all/0/1">Anand Raghunathan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13000">
                                    <div class="article-summary-box-inner">
                                        <span>Precision scaling has emerged as a popular technique to optimize the compute
and storage requirements of Deep Neural Networks (DNNs). Efforts toward
creating ultra-low-precision (sub-8-bit) DNNs suggest that the minimum
precision required to achieve a given network-level accuracy varies
considerably across networks, and even across layers within a network,
requiring support for variable precision in DNN hardware. Previous proposals
such as bit-serial hardware incur high overheads, significantly diminishing the
benefits of lower precision. To efficiently support precision
re-configurability in DNN accelerators, we introduce an approximate computing
method wherein DNN computations are performed block-wise (a block is a group of
bits) and re-configurability is supported at the granularity of blocks. Results
of block-wise computations are composed in an approximate manner to enable
efficient re-configurability. We design a DNN accelerator that embodies
approximate blocked computation and propose a method to determine a suitable
approximation configuration for a given DNN. By varying the approximation
configurations across DNNs, we achieve 1.17x-1.73x and 1.02x-2.04x improvement
in system energy and performance respectively, over an 8-bit fixed-point (FxP8)
baseline, with negligible loss in classification accuracy. Further, by varying
the approximation configurations across layers and data-structures within DNNs,
we achieve 1.25x-2.42x and 1.07x-2.95x improvement in system energy and
performance respectively, with negligible accuracy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty Prediction for Deep Sequential Regression Using Meta Models. (arXiv:2007.01350v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Navratil_J/0/1/0/all/0/1">Jiri Navratil</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnold_M/0/1/0/all/0/1">Matthew Arnold</a>, <a href="http://arxiv.org/find/cs/1/au:+Elder_B/0/1/0/all/0/1">Benjamin Elder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.01350">
                                    <div class="article-summary-box-inner">
                                        <span>Generating high quality uncertainty estimates for sequential regression,
particularly deep recurrent networks, remains a challenging and open problem.
Existing approaches often make restrictive assumptions (such as stationarity)
yet still perform poorly in practice, particularly in presence of real world
non-stationary signals and drift. This paper describes a flexible method that
can generate symmetric and asymmetric uncertainty estimates, makes no
assumptions about stationarity, and outperforms competitive baselines on both
drift and non drift scenarios. This work helps make sequential regression more
effective and practical for use in real-world applications, and is a powerful
new addition to the modeling toolbox for sequential uncertainty quantification
in general.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heteroscedastic Temporal Variational Autoencoder For Irregularly Sampled Time Series. (arXiv:2107.11350v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1">Satya Narayan Shukla</a>, <a href="http://arxiv.org/find/cs/1/au:+Marlin_B/0/1/0/all/0/1">Benjamin M. Marlin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11350">
                                    <div class="article-summary-box-inner">
                                        <span>Irregularly sampled time series commonly occur in several domains where they
present a significant challenge to standard deep learning models. In this
paper, we propose a new deep learning framework for probabilistic interpolation
of irregularly sampled time series that we call the Heteroscedastic Temporal
Variational Autoencoder (HeTVAE). HeTVAE includes a novel input layer to encode
information about input observation sparsity, a temporal VAE architecture to
propagate uncertainty due to input sparsity, and a heteroscedastic output layer
to enable variable uncertainty in output interpolations. Our results show that
the proposed architecture is better able to reflect variable uncertainty
through time due to sparse and irregular sampling than a range of baseline and
traditional models, as well as recently proposed deep latent variable models
that use homoscedastic output layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VisMCA: A Visual Analytics System for Misclassification Correction and Analysis. VAST Challenge 2020, Mini-Challenge 2 Award: Honorable Mention for Detailed Analysis of Patterns of Misclassification. (arXiv:2107.11181v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1">Huyen N. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Jake Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jian Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1">Ngan V.T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1">Tommy Dang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11181">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents VisMCA, an interactive visual analytics system that
supports deepening understanding in ML results, augmenting users&#x27; capabilities
in correcting misclassification, and providing an analysis of underlying
patterns, in response to the VAST Challenge 2020 Mini-Challenge 2. VisMCA
facilitates tracking provenance and provides a comprehensive view of object
detection results, easing re-labeling, and producing reliable, corrected data
for future training. Our solution implements multiple analytical views on
visual analysis to offer a deep insight for underlying pattern discovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Teaching a neural network with non-tunable exciton-polariton nodes. (arXiv:2107.11156v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Opala_A/0/1/0/all/0/1">Andrzej Opala</a>, <a href="http://arxiv.org/find/cs/1/au:+Panico_R/0/1/0/all/0/1">Riccardo Panico</a>, <a href="http://arxiv.org/find/cs/1/au:+Ardizzone_V/0/1/0/all/0/1">Vincenzo Ardizzone</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietka_B/0/1/0/all/0/1">Barbara Pietka</a>, <a href="http://arxiv.org/find/cs/1/au:+Szczytko_J/0/1/0/all/0/1">Jacek Szczytko</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanvitto_D/0/1/0/all/0/1">Daniele Sanvitto</a>, <a href="http://arxiv.org/find/cs/1/au:+Matuszewski_M/0/1/0/all/0/1">Micha&#x142; Matuszewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballarini_D/0/1/0/all/0/1">Dario Ballarini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11156">
                                    <div class="article-summary-box-inner">
                                        <span>In contrast to software simulations of neural networks, hardware or
neuromorphic implementations have often limited or no tunability. While such
networks promise great improvements in terms of speed and energy efficiency,
their performance is limited by the difficulty to apply efficient teaching. We
propose a system of non-tunable exciton-polariton nodes and an efficient
teaching method that relies on the precise measurement of the nonlinear node
response and the subsequent use of the backpropagation algorithm. We
demonstrate experimentally that the classification accuracy in the MNIST
handwritten digit benchmark is greatly improved compared to the case where
backpropagation is not used.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bias Loss for Mobile Neural Networks. (arXiv:2107.11170v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abrahamyan_L/0/1/0/all/0/1">Lusine Abrahamyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziatchin_V/0/1/0/all/0/1">Valentin Ziatchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Deligiannis_N/0/1/0/all/0/1">Nikos Deligiannis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11170">
                                    <div class="article-summary-box-inner">
                                        <span>Compact convolutional neural networks (CNNs) have witnessed exceptional
improvements in performance in recent years. However, they still fail to
provide the same predictive power as CNNs with a large number of parameters.
The diverse and even abundant features captured by the layers is an important
characteristic of these successful CNNs. However, differences in this
characteristic between large CNNs and their compact counterparts have rarely
been investigated. In compact CNNs, due to the limited number of parameters,
abundant features are unlikely to be obtained, and feature diversity becomes an
essential characteristic. Diverse features present in the activation maps
derived from a data point during model inference may indicate the presence of a
set of unique descriptors necessary to distinguish between objects of different
classes. In contrast, data points with low feature diversity may not provide a
sufficient amount of unique descriptors to make a valid prediction; we refer to
them as random predictions. Random predictions can negatively impact the
optimization process and harm the final performance. This paper proposes
addressing the problem raised by random predictions by reshaping the standard
cross-entropy to make it biased toward data points with a limited number of
unique descriptive features. Our novel Bias Loss focuses the training on a set
of valuable data points and prevents the vast number of samples with poor
learning features from misleading the optimization process. Furthermore, to
show the importance of diversity, we present a family of SkipNet models whose
architectures are brought to boost the number of unique descriptors in the last
layers. Our Skipnet-M can achieve 1% higher classification accuracy than
MobileNetV3 Large.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic detection of mobile malware using smartphone data and machine learning. (arXiv:2107.11167v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wit_J/0/1/0/all/0/1">J.S. Panman de Wit</a>, <a href="http://arxiv.org/find/cs/1/au:+Ham_J/0/1/0/all/0/1">J. van der Ham</a>, <a href="http://arxiv.org/find/cs/1/au:+Bucur_D/0/1/0/all/0/1">D. Bucur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11167">
                                    <div class="article-summary-box-inner">
                                        <span>Mobile malware are malicious programs that target mobile devices. They are an
increasing problem, as seen in the rise of detected mobile malware samples per
year. The number of active smartphone users is expected to grow, stressing the
importance of research on the detection of mobile malware. Detection methods
for mobile malware exist but are still limited.

In this paper, we provide an overview of the performance of machine learning
(ML) techniques to detect malware on Android, without using privileged access.
The ML-classifiers use device information such as the CPU usage, battery usage,
and memory usage for the detection of 10 subtypes of Mobile Trojans on the
Android Operating System (OS).

We use a real-life dataset containing device and malware data from 47 users
for a year (2016). We examine which features, i.e. aspects, of a device, are
most important to monitor to detect (subtypes of) Mobile Trojans. The focus of
this paper is on dynamic hardware features. Using these dynamic features we
apply state-of-the-art machine learning classifiers: Random Forest, K-Nearest
Neighbour, and AdaBoost. We show classification results on different feature
sets, making a distinction between global device features, and specific app
features. None of the measured feature sets require privileged access.

Our results show that the Random Forest classifier performs best as a general
malware classifier: across 10 subtypes of Mobile Trojans, it achieves an F1
score of 0.73 with a False Positive Rate (FPR) of 0.009 and a False Negative
Rate (FNR) of 0.380. The Random Forest, K-Nearest Neighbours, and AdaBoost
classifiers achieve F1 scores above 0.72, an FPR below 0.02 and, an FNR below
0.33, when trained separately to detect each subtype of Mobile Trojans.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constellation: Learning relational abstractions over objects for compositional imagination. (arXiv:2107.11153v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Whittington_J/0/1/0/all/0/1">James C.R. Whittington</a>, <a href="http://arxiv.org/find/cs/1/au:+Kabra_R/0/1/0/all/0/1">Rishabh Kabra</a>, <a href="http://arxiv.org/find/cs/1/au:+Matthey_L/0/1/0/all/0/1">Loic Matthey</a>, <a href="http://arxiv.org/find/cs/1/au:+Burgess_C/0/1/0/all/0/1">Christopher P. Burgess</a>, <a href="http://arxiv.org/find/cs/1/au:+Lerchner_A/0/1/0/all/0/1">Alexander Lerchner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11153">
                                    <div class="article-summary-box-inner">
                                        <span>Learning structured representations of visual scenes is currently a major
bottleneck to bridging perception with reasoning. While there has been exciting
progress with slot-based models, which learn to segment scenes into sets of
objects, learning configurational properties of entire groups of objects is
still under-explored. To address this problem, we introduce Constellation, a
network that learns relational abstractions of static visual scenes, and
generalises these abstractions over sensory particularities, thus offering a
potential basis for abstract relational reasoning. We further show that this
basis, along with language association, provides a means to imagine sensory
content in new ways. This work is a first step in the explicit representation
of visual relationships and using them for complex cognitive procedures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model Selection for Offline Reinforcement Learning: Practical Considerations for Healthcare Settings. (arXiv:2107.11003v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Shengpu Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiens_J/0/1/0/all/0/1">Jenna Wiens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11003">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) can be used to learn treatment policies and aid
decision making in healthcare. However, given the need for generalization over
complex state/action spaces, the incorporation of function approximators (e.g.,
deep neural networks) requires model selection to reduce overfitting and
improve policy performance at deployment. Yet a standard validation pipeline
for model selection requires running a learned policy in the actual
environment, which is often infeasible in a healthcare setting. In this work,
we investigate a model selection pipeline for offline RL that relies on
off-policy evaluation (OPE) as a proxy for validation performance. We present
an in-depth analysis of popular OPE methods, highlighting the additional
hyperparameters and computational requirements (fitting/inference of auxiliary
models) when used to rank a set of candidate policies. We compare the utility
of different OPE methods as part of the model selection pipeline in the context
of learning to treat patients with sepsis. Among all the OPE methods we
considered, fitted Q evaluation (FQE) consistently leads to the best validation
ranking, but at a high computational cost. To balance this trade-off between
accuracy of ranking and computational efficiency, we propose a simple two-stage
approach to accelerate model selection by avoiding potentially unnecessary
computation. Our work serves as a practical guide for offline RL model
selection and can help RL practitioners select policies using real-world
datasets. To facilitate reproducibility and future extensions, the code
accompanying this paper is available online at
https://github.com/MLD3/OfflineRL_ModelSelection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative adversarial networks in time series: A survey and taxonomy. (arXiv:2107.11098v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brophy_E/0/1/0/all/0/1">Eoin Brophy</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhengwei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+She_Q/0/1/0/all/0/1">Qi She</a>, <a href="http://arxiv.org/find/cs/1/au:+Ward_T/0/1/0/all/0/1">Tomas Ward</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11098">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GANs) studies have grown exponentially in
the past few years. Their impact has been seen mainly in the computer vision
field with realistic image and video manipulation, especially generation,
making significant advancements. While these computer vision advances have
garnered much attention, GAN applications have diversified across disciplines
such as time series and sequence generation. As a relatively new niche for
GANs, fieldwork is ongoing to develop high quality, diverse and private time
series data. In this paper, we review GAN variants designed for time series
related applications. We propose a taxonomy of discrete-variant GANs and
continuous-variant GANs, in which GANs deal with discrete time series and
continuous time series data. Here we showcase the latest and most popular
literature in this field; their architectures, results, and applications. We
also provide a list of the most popular evaluation metrics and their
suitability across applications. Also presented is a discussion of privacy
measures for these GANs and further protections and directions for dealing with
sensitive data. We aim to frame clearly and concisely the latest and
state-of-the-art research in this area and their applications to real-world
technologies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A novel meta-learning initialization method for physics-informed neural networks. (arXiv:2107.10991v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiaoya Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Weien Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1">Wen Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10991">
                                    <div class="article-summary-box-inner">
                                        <span>Physics-informed neural networks (PINNs) have been widely used to solve
various scientific computing problems. However, large training costs limit
PINNs for some real-time applications. Although some works have been proposed
to improve the training efficiency of PINNs, few consider the influence of
initialization. To this end, we propose a New Reptile initialization based
Physics-Informed Neural Network (NRPINN). The original Reptile algorithm is a
meta-learning initialization method based on labeled data. PINNs can be trained
with less labeled data or even without any labeled data by adding partial
differential equations (PDEs) as a penalty term into the loss function.
Inspired by this idea, we propose the new Reptile initialization to sample more
tasks from the parameterized PDEs and adapt the penalty term of the loss. The
new Reptile initialization can acquire initialization parameters from related
tasks by supervised, unsupervised, and semi-supervised learning. Then, PINNs
with initialization parameters can efficiently solve PDEs. Besides, the new
Reptile initialization can also be used for the variants of PINNs. Finally, we
demonstrate and verify the NRPINN considering both forward problems, including
solving Poisson, Burgers, and Schr\&quot;odinger equations, as well as inverse
problems, where unknown parameters in the PDEs are estimated. Experimental
results show that the NRPINN training is much faster and achieves higher
accuracy than PINNs with other initialization methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RGB Image Classification with Quantum Convolutional Ansaetze. (arXiv:2107.11099v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Jing_Y/0/1/0/all/0/1">Yu Jing</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Yang_Y/0/1/0/all/0/1">Yang Yang</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wu_C/0/1/0/all/0/1">Chonghang Wu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Fu_W/0/1/0/all/0/1">Wenbing Fu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Li_X/0/1/0/all/0/1">Xiaogang Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Xu_H/0/1/0/all/0/1">Hua Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11099">
                                    <div class="article-summary-box-inner">
                                        <span>With the rapid growth of qubit numbers and coherence times in quantum
hardware technology, implementing shallow neural networks on the so-called
Noisy Intermediate-Scale Quantum (NISQ) devices has attracted a lot of
interest. Many quantum (convolutional) circuit ansaetze are proposed for
grayscale images classification tasks with promising empirical results.
However, when applying these ansaetze on RGB images, the intra-channel
information that is useful for vision tasks is not extracted effectively. In
this paper, we propose two types of quantum circuit ansaetze to simulate
convolution operations on RGB images, which differ in the way how inter-channel
and intra-channel information are extracted. To the best of our knowledge, this
is the first work of a quantum convolutional circuit to deal with RGB images
effectively, with a higher test accuracy compared to the purely classical CNNs.
We also investigate the relationship between the size of quantum circuit ansatz
and the learnability of the hybrid quantum-classical convolutional neural
network. Through experiments based on CIFAR-10 and MNIST datasets, we
demonstrate that a larger size of the quantum circuit ansatz improves
predictive performance in multiclass classification tasks, providing useful
insights for near term quantum algorithm developments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AD-GAN: End-to-end Unsupervised Nuclei Segmentation with Aligned Disentangling Training. (arXiv:2107.11022v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yao_K/0/1/0/all/0/1">Kai Yao</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Jie Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Jude_C/0/1/0/all/0/1">Curran Jude</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11022">
                                    <div class="article-summary-box-inner">
                                        <span>We consider unsupervised cell nuclei segmentation in this paper. Exploiting
the recently-proposed unpaired image-to-image translation between cell nuclei
images and randomly synthetic masks, existing approaches, e.g., CycleGAN, have
achieved encouraging results. However, these methods usually take a two-stage
pipeline and fail to learn end-to-end in cell nuclei images. More seriously,
they could lead to the lossy transformation problem, i.e., the content
inconsistency between the original images and the corresponding segmentation
output. To address these limitations, we propose a novel end-to-end
unsupervised framework called Aligned Disentangling Generative Adversarial
Network (AD-GAN). Distinctively, AD-GAN introduces representation
disentanglement to separate content representation (the underling spatial
structure) from style representation (the rendering of the structure). With
this framework, spatial structure can be preserved explicitly, enabling a
significant reduction of macro-level lossy transformation. We also propose a
novel training algorithm able to align the disentangled content in the latent
space to reduce micro-level lossy transformation. Evaluations on real-world 2D
and 3D datasets show that AD-GAN substantially outperforms the other comparison
methods and the professional software both quantitatively and qualitatively.
Specifically, the proposed AD-GAN leads to significant improvement over the
current best unsupervised methods by an average 17.8% relatively (w.r.t. the
metric DICE) on four cell nuclei datasets. As an unsupervised method, AD-GAN
even performs competitive with the best supervised models, taking a further
leap towards end-to-end unsupervised nuclei segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven deep density estimation. (arXiv:2107.11085v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Puchert_P/0/1/0/all/0/1">Patrik Puchert</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermosilla_P/0/1/0/all/0/1">Pedro Hermosilla</a>, <a href="http://arxiv.org/find/cs/1/au:+Ritschel_T/0/1/0/all/0/1">Tobias Ritschel</a>, <a href="http://arxiv.org/find/cs/1/au:+Ropinski_T/0/1/0/all/0/1">Timo Ropinski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11085">
                                    <div class="article-summary-box-inner">
                                        <span>Density estimation plays a crucial role in many data analysis tasks, as it
infers a continuous probability density function (PDF) from discrete samples.
Thus, it is used in tasks as diverse as analyzing population data, spatial
locations in 2D sensor readings, or reconstructing scenes from 3D scans. In
this paper, we introduce a learned, data-driven deep density estimation (DDE)
to infer PDFs in an accurate and efficient manner, while being independent of
domain dimensionality or sample size. Furthermore, we do not require access to
the original PDF during estimation, neither in parametric form, nor as priors,
or in the form of many samples. This is enabled by training an unstructured
convolutional neural network on an infinite stream of synthetic PDFs, as
unbound amounts of synthetic training data generalize better across a deck of
natural PDFs than any natural finite training data will do. Thus, we hope that
our publicly available DDE method will be beneficial in many areas of data
analysis, where continuous models are to be estimated from discrete
observations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepTitle -- Leveraging BERT to generate Search Engine Optimized Headlines. (arXiv:2107.10935v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anastasiu_C/0/1/0/all/0/1">Cristian Anastasiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Behnke_H/0/1/0/all/0/1">Hanna Behnke</a>, <a href="http://arxiv.org/find/cs/1/au:+Luck_S/0/1/0/all/0/1">Sarah L&#xfc;ck</a>, <a href="http://arxiv.org/find/cs/1/au:+Malesevic_V/0/1/0/all/0/1">Viktor Malesevic</a>, <a href="http://arxiv.org/find/cs/1/au:+Najmi_A/0/1/0/all/0/1">Aamna Najmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Poveda_Panter_J/0/1/0/all/0/1">Javier Poveda-Panter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10935">
                                    <div class="article-summary-box-inner">
                                        <span>Automated headline generation for online news articles is not a trivial task
- machine generated titles need to be grammatically correct, informative,
capture attention and generate search traffic without being &quot;click baits&quot; or
&quot;fake news&quot;. In this paper we showcase how a pre-trained language model can be
leveraged to create an abstractive news headline generator for German language.
We incorporate state of the art fine-tuning techniques for abstractive text
summarization, i.e. we use different optimizers for the encoder and decoder
where the former is pre-trained and the latter is trained from scratch. We
modify the headline generation to incorporate frequently sought keywords
relevant for search engine optimization. We conduct experiments on a German
news data set and achieve a ROUGE-L-gram F-score of 40.02. Furthermore, we
address the limitations of ROUGE for measuring the quality of text
summarization by introducing a sentence similarity metric and human evaluation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Economic Recession Prediction Using Deep Neural Network. (arXiv:2107.10980v1 [econ.GN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/econ/1/au:+Wang_Z/0/1/0/all/0/1">Zihao Wang</a>, <a href="http://arxiv.org/find/econ/1/au:+Li_K/0/1/0/all/0/1">Kun Li</a>, <a href="http://arxiv.org/find/econ/1/au:+Xia_S/0/1/0/all/0/1">Steve Q. Xia</a>, <a href="http://arxiv.org/find/econ/1/au:+Liu_H/0/1/0/all/0/1">Hongfu Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10980">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the effectiveness of different machine learning methodologies
in predicting economic cycles. We identify the deep learning methodology of
Bi-LSTM with Autoencoder as the most accurate model to forecast the beginning
and end of economic recessions in the U.S. We adopt commonly-available macro
and market-condition features to compare the ability of different machine
learning models to generate good predictions both in-sample and out-of-sample.
The proposed model is flexible and dynamic when both predictive variables and
model coefficients vary over time. It provided good out-of-sample predictions
for the past two recessions and early warning about the COVID-19 recession.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MCDAL: Maximum Classifier Discrepancy for Active Learning. (arXiv:2107.11049v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1">Jae Won Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong-Jin Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Jung_Y/0/1/0/all/0/1">Yunjae Jung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kweon_I/0/1/0/all/0/1">In So Kweon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11049">
                                    <div class="article-summary-box-inner">
                                        <span>Recent state-of-the-art active learning methods have mostly leveraged
Generative Adversarial Networks (GAN) for sample acquisition; however, GAN is
usually known to suffer from instability and sensitivity to hyper-parameters.
In contrast to these methods, we propose in this paper a novel active learning
framework that we call Maximum Classifier Discrepancy for Active Learning
(MCDAL) which takes the prediction discrepancies between multiple classifiers.
In particular, we utilize two auxiliary classification layers that learn
tighter decision boundaries by maximizing the discrepancies among them.
Intuitively, the discrepancies in the auxiliary classification layers&#x27;
predictions indicate the uncertainty in the prediction. In this regard, we
propose a novel method to leverage the classifier discrepancies for the
acquisition function for active learning. We also provide an interpretation of
our idea in relation to existing GAN based active learning methods and domain
adaptation frameworks. Moreover, we empirically demonstrate the utility of our
approach where the performance of our approach exceeds the state-of-the-art
methods on several image classification and semantic segmentation datasets in
active learning setups.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Based Reconstruction of Total Solar Irradiance. (arXiv:2107.11042v1 [astro-ph.SR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Abduallah_Y/0/1/0/all/0/1">Yasser Abduallah</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Wang_J/0/1/0/all/0/1">Jason T. L. Wang</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Shen_Y/0/1/0/all/0/1">Yucong Shen</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Alobaid_K/0/1/0/all/0/1">Khalid A. Alobaid</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Criscuoli_S/0/1/0/all/0/1">Serena Criscuoli</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Wang_H/0/1/0/all/0/1">Haimin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11042">
                                    <div class="article-summary-box-inner">
                                        <span>The Earth&#x27;s primary source of energy is the radiant energy generated by the
Sun, which is referred to as solar irradiance, or total solar irradiance (TSI)
when all of the radiation is measured. A minor change in the solar irradiance
can have a significant impact on the Earth&#x27;s climate and atmosphere. As a
result, studying and measuring solar irradiance is crucial in understanding
climate changes and solar variability. Several methods have been developed to
reconstruct total solar irradiance for long and short periods of time; however,
they are physics-based and rely on the availability of data, which does not go
beyond 9,000 years. In this paper we propose a new method, called TSInet, to
reconstruct total solar irradiance by deep learning for short and long periods
of time that span beyond the physical models&#x27; data availability. On the data
that are available, our method agrees well with the state-of-the-art
physics-based reconstruction models. To our knowledge, this is the first time
that deep learning has been used to reconstruct total solar irradiance for more
than 9,000 years.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LocalGLMnet: interpretable deep learning for tabular data. (arXiv:2107.11059v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Richman_R/0/1/0/all/0/1">Ronald Richman</a>, <a href="http://arxiv.org/find/cs/1/au:+Wuthrich_M/0/1/0/all/0/1">Mario V. W&#xfc;thrich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11059">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning models have gained great popularity in statistical modeling
because they lead to very competitive regression models, often outperforming
classical statistical models such as generalized linear models. The
disadvantage of deep learning models is that their solutions are difficult to
interpret and explain, and variable selection is not easily possible because
deep learning models solve feature engineering and variable selection
internally in a nontransparent way. Inspired by the appealing structure of
generalized linear models, we propose a new network architecture that shares
similar features as generalized linear models, but provides superior predictive
power benefiting from the art of representation learning. This new architecture
allows for variable selection of tabular data and for interpretation of the
calibrated deep learning model, in fact, our approach provides an additive
decomposition in the spirit of Shapley values and integrated gradients.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Estimating Predictive Uncertainty Under Program Data Distribution Shift. (arXiv:2107.10989v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yufei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Simin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10989">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning (DL) techniques have achieved great success in predictive
accuracy in a variety of tasks, but deep neural networks (DNNs) are shown to
produce highly overconfident scores for even abnormal samples. Well-defined
uncertainty indicates whether a model&#x27;s output should (or should not) be
trusted and thus becomes critical in real-world scenarios which typically
involves shifted input distributions due to many factors. Existing uncertainty
approaches assume that testing samples from a different data distribution would
induce unreliable model predictions thus have higher uncertainty scores. They
quantify model uncertainty by calibrating DL model&#x27;s confidence of a given
input and evaluate the effectiveness in computer vision (CV) and natural
language processing (NLP)-related tasks. However, their methodologies&#x27;
reliability may be compromised under programming tasks due to difference in
data representations and shift patterns. In this paper, we first define three
different types of distribution shift in program data and build a large-scale
shifted Java dataset. We implement two common programming language tasks on our
dataset to study the effect of each distribution shift on DL model performance.
We also propose a large-scale benchmark of existing state-of-the-art predictive
uncertainty on programming tasks and investigate their effectiveness under data
distribution shift. Experiments show that program distribution shift does
degrade the DL model performance to varying degrees and that existing
uncertainty methods all present certain limitations in quantifying uncertainty
on program dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High Dimensional Differentially Private Stochastic Optimization with Heavy-tailed Data. (arXiv:2107.11136v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1">Lijie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_S/0/1/0/all/0/1">Shuo Ni</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1">Hanshen Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11136">
                                    <div class="article-summary-box-inner">
                                        <span>As one of the most fundamental problems in machine learning, statistics and
differential privacy, Differentially Private Stochastic Convex Optimization
(DP-SCO) has been extensively studied in recent years. However, most of the
previous work can only handle either regular data distribution or irregular
data in the low dimensional space case. To better understand the challenges
arising from irregular data distribution, in this paper we provide the first
study on the problem of DP-SCO with heavy-tailed data in the high dimensional
space. In the first part we focus on the problem over some polytope constraint
(such as the $\ell_1$-norm ball). We show that if the loss function is smooth
and its gradient has bounded second order moment, it is possible to get a (high
probability) error bound (excess population risk) of $\tilde{O}(\frac{\log
d}{(n\epsilon)^\frac{1}{3}})$ in the $\epsilon$-DP model, where $n$ is the
sample size and $d$ is the dimensionality of the underlying space. Next, for
LASSO, if the data distribution that has bounded fourth-order moments, we
improve the bound to $\tilde{O}(\frac{\log d}{(n\epsilon)^\frac{2}{5}})$ in the
$(\epsilon, \delta)$-DP model. In the second part of the paper, we study sparse
learning with heavy-tailed data. We first revisit the sparse linear model and
propose a truncated DP-IHT method whose output could achieve an error of
$\tilde{O}(\frac{s^{*2}\log d}{n\epsilon})$, where $s^*$ is the sparsity of the
underlying parameter. Then we study a more general problem over the sparsity
({\em i.e.,} $\ell_0$-norm) constraint, and show that it is possible to achieve
an error of $\tilde{O}(\frac{s^{*\frac{3}{2}}\log d}{n\epsilon})$, which is
also near optimal up to a factor of $\tilde{O}{(\sqrt{s^*})}$, if the loss
function is smooth and strongly convex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Introducing: DeepHead, Wide-band Electromagnetic Imaging Paradigm. (arXiv:2107.11107v1 [physics.med-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Al_Saffar_A/0/1/0/all/0/1">A. Al-Saffar</a>, <a href="http://arxiv.org/find/physics/1/au:+Guo_L/0/1/0/all/0/1">L. Guo</a>, <a href="http://arxiv.org/find/physics/1/au:+Abbosh_A/0/1/0/all/0/1">A. Abbosh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11107">
                                    <div class="article-summary-box-inner">
                                        <span>Electromagnetic medical imaging in the microwave regime is a hard problem
notorious for 1) instability 2) under-determinism. This two-pronged problem is
tackled with a two-pronged solution that uses double compression to maximally
utilizing the cheap unlabelled data to a) provide a priori information required
to ease under-determinism and b) reduce sensitivity of inference to the input.
The result is a stable solver with a high resolution output. DeepHead is a
fully data-driven implementation of the paradigm proposed in the context of
microwave brain imaging. It infers the dielectric distribution of the brain at
a desired single frequency while making use of an input that spreads over a
wide band of frequencies. The performance of the model is evaluated with both
simulations and human volunteers experiments. The inference made is juxtaposed
with ground-truth dielectric distribution in simulation case, and the golden
MRI / CT imaging modalities of the volunteers in real-world case.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptively Weighted Top-N Recommendation for Organ Matching. (arXiv:2107.10971v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shojaee_P/0/1/0/all/0/1">Parshin Shojaee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1">Ran Jin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10971">
                                    <div class="article-summary-box-inner">
                                        <span>Reducing the shortage of organ donations to meet the demands of patients on
the waiting list has being a major challenge in organ transplantation. Because
of the shortage, organ matching decision is the most critical decision to
assign the limited viable organs to the most suitable patients. Currently,
organ matching decisions were only made by matching scores calculated via
scoring models, which are built by the first principles. However, these models
may disagree with the actual post-transplantation matching performance (e.g.,
patient&#x27;s post-transplant quality of life (QoL) or graft failure measurements).
In this paper, we formulate the organ matching decision-making as a top-N
recommendation problem and propose an Adaptively Weighted Top-N Recommendation
(AWTR) method. AWTR improves performance of the current scoring models by using
limited actual matching performance in historical data set as well as the
collected covariates from organ donors and patients. AWTR sacrifices the
overall recommendation accuracy by emphasizing the recommendation and ranking
accuracy for top-N matched patients. The proposed method is validated in a
simulation study, where KAS [60] is used to simulate the organ-patient
recommendation response. The results show that our proposed method outperforms
seven state-of-the-art top-N recommendation benchmark methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VisDA-2021 Competition Universal Domain Adaptation to Improve Performance on Out-of-Distribution Data. (arXiv:2107.11011v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bashkirova_D/0/1/0/all/0/1">Dina Bashkirova</a>, <a href="http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1">Dan Hendrycks</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Donghyun Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Samarth Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Saito_K/0/1/0/all/0/1">Kuniaki Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Teterwak_P/0/1/0/all/0/1">Piotr Teterwak</a>, <a href="http://arxiv.org/find/cs/1/au:+Usman_B/0/1/0/all/0/1">Ben Usman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11011">
                                    <div class="article-summary-box-inner">
                                        <span>Progress in machine learning is typically measured by training and testing a
model on the same distribution of data, i.e., the same domain. This
over-estimates future accuracy on out-of-distribution data. The Visual Domain
Adaptation (VisDA) 2021 competition tests models&#x27; ability to adapt to novel
test distributions and handle distributional shift. We set up unsupervised
domain adaptation challenges for image classifiers and will evaluate adaptation
to novel viewpoints, backgrounds, modalities and degradation in quality. Our
challenge draws on large-scale publicly available datasets but constructs the
evaluation across domains, rather that the traditional in-domain bench-marking.
Furthermore, we focus on the difficult &quot;universal&quot; setting where, in addition
to input distribution drift, methods may encounter missing and/or novel classes
in the target dataset. Performance will be measured using a rigorous protocol,
comparing to state-of-the-art domain adaptation methods with the help of
established metrics. We believe that the competition will encourage further
improvement in machine learning methods&#x27; ability to handle realistic data in
many deployment scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tsformer: Time series Transformer for tourism demand forecasting. (arXiv:2107.10977v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1">Siyuan Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1">Chuanming Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10977">
                                    <div class="article-summary-box-inner">
                                        <span>AI-based methods have been widely applied to tourism demand forecasting.
However, current AI-based methods are short of the ability to process long-term
dependency, and most of them lack interpretability. The Transformer used
initially for machine translation shows an incredible ability to long-term
dependency processing. Based on the Transformer, we proposed a time series
Transformer (Tsformer) with Encoder-Decoder architecture for tourism demand
forecasting. The proposed Tsformer encodes long-term dependency with encoder,
captures short-term dependency with decoder, and simplifies the attention
interactions under the premise of highlighting dominant attention through a
series of attention masking mechanisms. These improvements make the multi-head
attention mechanism process the input sequence according to the time
relationship, contributing to better interpretability. What&#x27;s more, the context
processing ability of the Encoder-Decoder architecture allows adopting the
calendar of days to be forecasted to enhance the forecasting performance.
Experiments conducted on the Jiuzhaigou valley and Siguniang mountain tourism
demand datasets with other nine baseline methods indicate that the proposed
Tsformer outperformed all baseline models in the short-term and long-term
tourism demand forecasting tasks. Moreover, ablation studies demonstrate that
the adoption of the calendar of days to be forecasted contributes to the
forecasting performance of the proposed Tsformer. For better interpretability,
the attention weight matrix visualization is performed. It indicates that the
Tsformer concentrates on seasonal features and days close to days to be
forecast in short-term forecasting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the structure of wind: A data-driven nonlocal turbulence model for the atmospheric boundary layer. (arXiv:2107.11046v1 [physics.flu-dyn])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Keith_B/0/1/0/all/0/1">Brendan Keith</a>, <a href="http://arxiv.org/find/physics/1/au:+Khristenko_U/0/1/0/all/0/1">Ustim Khristenko</a>, <a href="http://arxiv.org/find/physics/1/au:+Wohlmuth_B/0/1/0/all/0/1">Barbara Wohlmuth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11046">
                                    <div class="article-summary-box-inner">
                                        <span>We develop a novel data-driven approach to modeling the atmospheric boundary
layer. This approach leads to a nonlocal, anisotropic synthetic turbulence
model which we refer to as the deep rapid distortion (DRD) model. Our approach
relies on an operator regression problem which characterizes the best fitting
candidate in a general family of nonlocal covariance kernels parameterized in
part by a neural network. This family of covariance kernels is expressed in
Fourier space and is obtained from approximate solutions to the Navier--Stokes
equations at very high Reynolds numbers. Each member of the family incorporates
important physical properties such as mass conservation and a realistic energy
cascade. The DRD model can be calibrated with noisy data from field
experiments. After calibration, the model can be used to generate synthetic
turbulent velocity fields. To this end, we provide a new numerical method based
on domain decomposition which delivers scalable, memory-efficient turbulence
generation with the DRD model as well as others. We demonstrate the robustness
of our approach with both filtered and noisy data coming from the 1968 Air
Force Cambridge Research Laboratory Kansas experiments. Using this data, we
witness exceptional accuracy with the DRD model, especially when compared to
the International Electrotechnical Commission standard.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The decomposition of the higher-order homology embedding constructed from the $k$-Laplacian. (arXiv:2107.10970v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1">Yu-Chia Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Meila_M/0/1/0/all/0/1">Marina Meil&#x103;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10970">
                                    <div class="article-summary-box-inner">
                                        <span>The null space of the $k$-th order Laplacian $\mathbf{\mathcal L}_k$, known
as the {\em $k$-th homology vector space}, encodes the non-trivial topology of
a manifold or a network. Understanding the structure of the homology embedding
can thus disclose geometric or topological information from the data. The study
of the null space embedding of the graph Laplacian $\mathbf{\mathcal L}_0$ has
spurred new research and applications, such as spectral clustering algorithms
with theoretical guarantees and estimators of the Stochastic Block Model. In
this work, we investigate the geometry of the $k$-th homology embedding and
focus on cases reminiscent of spectral clustering. Namely, we analyze the {\em
connected sum} of manifolds as a perturbation to the direct sum of their
homology embeddings. We propose an algorithm to factorize the homology
embedding into subspaces corresponding to a manifold&#x27;s simplest topological
components. The proposed framework is applied to the {\em shortest homologous
loop detection} problem, a problem known to be NP-hard in general. Our spectral
loop detection algorithm scales better than existing methods and is effective
on diverse data such as point clouds and images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Communication Efficiency in Federated Learning: Achievements and Challenges. (arXiv:2107.10996v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahid_O/0/1/0/all/0/1">Osama Shahid</a>, <a href="http://arxiv.org/find/cs/1/au:+Pouriyeh_S/0/1/0/all/0/1">Seyedamin Pouriyeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Parizi_R/0/1/0/all/0/1">Reza M. Parizi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1">Quan Z. Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivastava_G/0/1/0/all/0/1">Gautam Srivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1">Liang Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10996">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) is known to perform Machine Learning tasks in a
distributed manner. Over the years, this has become an emerging technology
especially with various data protection and privacy policies being imposed FL
allows performing machine learning tasks whilst adhering to these challenges.
As with the emerging of any new technology, there are going to be challenges
and benefits. A challenge that exists in FL is the communication costs, as FL
takes place in a distributed environment where devices connected over the
network have to constantly share their updates this can create a communication
bottleneck. In this paper, we present a survey of the research that is
performed to overcome the communication constraints in an FL setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Generalization of Meta-learning on Unseen Domains via Adversarial Shift. (arXiv:2107.11056v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_P/0/1/0/all/0/1">Pinzhuo Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yao Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11056">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning provides a promising way for learning to efficiently learn and
achieves great success in many applications. However, most meta-learning
literature focuses on dealing with tasks from a same domain, making it brittle
to generalize to tasks from the other unseen domains. In this work, we address
this problem by simulating tasks from the other unseen domains to improve the
generalization and robustness of meta-learning method. Specifically, we propose
a model-agnostic shift layer to learn how to simulate the domain shift and
generate pseudo tasks, and develop a new adversarial learning-to-learn
mechanism to train it. Based on the pseudo tasks, the meta-learning model can
learn cross-domain meta-knowledge, which can generalize well on unseen domains.
We conduct extensive experiments under the domain generalization setting.
Experimental results demonstrate that the proposed shift layer is applicable to
various meta-learning frameworks. Moreover, our method also leads to
state-of-the-art performance on different cross-domain few-shot classification
benchmarks and produces good results on cross-domain few-shot regression.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ego-GNNs: Exploiting Ego Structures in Graph Neural Networks. (arXiv:2107.10957v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sandfelder_D/0/1/0/all/0/1">Dylan Sandfelder</a>, <a href="http://arxiv.org/find/cs/1/au:+Vijayan_P/0/1/0/all/0/1">Priyesh Vijayan</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1">William L. Hamilton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10957">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) have achieved remarkable success as a framework
for deep learning on graph-structured data. However, GNNs are fundamentally
limited by their tree-structured inductive bias: the WL-subtree kernel
formulation bounds the representational capacity of GNNs, and polynomial-time
GNNs are provably incapable of recognizing triangles in a graph. In this work,
we propose to augment the GNN message-passing operations with information
defined on ego graphs (i.e., the induced subgraph surrounding each node). We
term these approaches Ego-GNNs and show that Ego-GNNs are provably more
powerful than standard message-passing GNNs. In particular, we show that
Ego-GNNs are capable of recognizing closed triangles, which is essential given
the prominence of transitivity in real-world graphs. We also motivate our
approach from the perspective of graph signal processing as a form of multiplex
graph convolution. Experimental results on node classification using synthetic
and real data highlight the achievable performance gains using this approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Size doesn&#x27;t matter: predicting physico- or biochemical properties based on dozens of molecules. (arXiv:2107.10882v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karpov_K/0/1/0/all/0/1">Kirill Karpov</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Mitrofanov_A/0/1/0/all/0/1">Artem Mitrofanov</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Korolev_V/0/1/0/all/0/1">Vadim Korolev</a> (1 and 2), <a href="http://arxiv.org/find/cs/1/au:+Tkachenko_V/0/1/0/all/0/1">Valery Tkachenko</a> (2) ((1) Lomonosov Moscow State University, Department of Chemistry, Leninskie gory, 1 bld. 3, Moscow, Russia, (2) Science Data Software, LLC, 14909 Forest Landing Cir, Rockville, USA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10882">
                                    <div class="article-summary-box-inner">
                                        <span>The use of machine learning in chemistry has become a common practice. At the
same time, despite the success of modern machine learning methods, the lack of
data limits their use. Using a transfer learning methodology can help solve
this problem. This methodology assumes that a model built on a sufficient
amount of data captures general features of the chemical compound structure on
which it was trained and that the further reuse of these features on a dataset
with a lack of data will greatly improve the quality of the new model. In this
paper, we develop this approach for small organic molecules, implementing
transfer learning with graph convolutional neural networks. The paper shows a
significant improvement in the performance of models for target properties with
a lack of data. The effects of the dataset composition on model quality and the
applicability domain of the resulting models are also considered.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear Polytree Structural Equation Models: Structural Learning and Inverse Correlation Estimation. (arXiv:2107.10955v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lou_X/0/1/0/all/0/1">Xingmei Lou</a>, <a href="http://arxiv.org/find/stat/1/au:+Hu_Y/0/1/0/all/0/1">Yu Hu</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1">Xiaodong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10955">
                                    <div class="article-summary-box-inner">
                                        <span>We are interested in the problem of learning the directed acyclic graph (DAG)
when data are generated from a linear structural equation model (SEM) and the
causal structure can be characterized by a polytree. Specially, under both
Gaussian and sub-Gaussian models, we study the sample size conditions for the
well-known Chow-Liu algorithm to exactly recover the equivalence class of the
polytree, which is uniquely represented by a CPDAG. We also study the error
rate for the estimation of the inverse correlation matrix under such models.
Our theoretical findings are illustrated by comprehensive numerical
simulations, and experiments on benchmark data also demonstrate the robustness
of the method when the ground truth graphical structure can only be
approximated by a polytree.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compositional Models: Multi-Task Learning and Knowledge Transfer with Modular Networks. (arXiv:2107.10963v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhmoginov_A/0/1/0/all/0/1">Andrey Zhmoginov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bashkirova_D/0/1/0/all/0/1">Dina Bashkirova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sandler_M/0/1/0/all/0/1">Mark Sandler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10963">
                                    <div class="article-summary-box-inner">
                                        <span>Conditional computation and modular networks have been recently proposed for
multitask learning and other problems as a way to decompose problem solving
into multiple reusable computational blocks. We propose a new approach for
learning modular networks based on the isometric version of ResNet with all
residual blocks having the same configuration and the same number of
parameters. This architectural choice allows adding, removing and changing the
order of residual blocks. In our method, the modules can be invoked repeatedly
and allow knowledge transfer to novel tasks by adjusting the order of
computation. This allows soft weight sharing between tasks with only a small
increase in the number of parameters. We show that our method leads to
interpretable self-organization of modules in case of multi-task learning,
transfer learning and domain adaptation while achieving competitive results on
those tasks. From practical perspective, our approach allows to: (a) reuse
existing modules for learning new task by adjusting the computation order, (b)
use it for unsupervised multi-source domain adaptation to illustrate that
adaptation to unseen data can be achieved by only manipulating the order of
pretrained modules, (c) show how our approach can be used to increase accuracy
of existing architectures for image classification tasks such as ImageNet,
without any parameter increase, by reusing the same block multiple times.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble of Convolution Neural Networks on Heterogeneous Signals for Sleep Stage Scoring. (arXiv:2107.11045v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Blanco_E/0/1/0/all/0/1">Enrique Fernandez-Blanco</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Lozano_C/0/1/0/all/0/1">Carlos Fernandez-Lozano</a>, <a href="http://arxiv.org/find/cs/1/au:+Pazos_A/0/1/0/all/0/1">Alejandro Pazos</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivero_D/0/1/0/all/0/1">Daniel Rivero</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11045">
                                    <div class="article-summary-box-inner">
                                        <span>Over the years, several approaches have tried to tackle the problem of
performing an automatic scoring of the sleeping stages. Although any
polysomnography usually collects over a dozen of different signals, this
particular problem has been mainly tackled by using only the
Electroencephalograms presented in those records. On the other hand, the other
recorded signals have been mainly ignored by most works. This paper explores
and compares the convenience of using additional signals apart from
electroencephalograms. More specifically, this work uses the SHHS-1 dataset
with 5,804 patients containing an electromyogram recorded simultaneously as two
electroencephalograms. To compare the results, first, the same architecture has
been evaluated with different input signals and all their possible
combinations. These tests show how, using more than one signal especially if
they are from different sources, improves the results of the classification.
Additionally, the best models obtained for each combination of one or more
signals have been used in ensemble models and, its performance has been
compared showing the convenience of using these multi-signal models to improve
the classification. The best overall model, an ensemble of Depth-wise
Separational Convolutional Neural Networks, has achieved an accuracy of 86.06\%
with a Cohen&#x27;s Kappa of 0.80 and a $F_{1}$ of 0.77. Up to date, those are the
best results on the complete dataset and it shows a significant improvement in
the precision and recall for the most uncommon class in the dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Rate-Constrained Optimization of Non-decomposable Objectives. (arXiv:2107.10960v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1">Abhishek Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_H/0/1/0/all/0/1">Harikrishna Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotter_A/0/1/0/all/0/1">Andrew Cotter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10960">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a popular family of constrained optimization problems arising in
machine learning that involve optimizing a non-decomposable evaluation metric
with a certain thresholded form, while constraining another metric of interest.
Examples of such problems include optimizing the false negative rate at a fixed
false positive rate, optimizing precision at a fixed recall, optimizing the
area under the precision-recall or ROC curves, etc. Our key idea is to
formulate a rate-constrained optimization that expresses the threshold
parameter as a function of the model parameters via the Implicit Function
theorem. We show how the resulting optimization problem can be solved using
standard gradient based methods. Experiments on benchmark datasets demonstrate
the effectiveness of our proposed method over existing state-of-the art
approaches for these problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reservoir Computing Approach for Gray Images Segmentation. (arXiv:2107.11077v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koprinkova_Hristova_P/0/1/0/all/0/1">Petia Koprinkova-Hristova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11077">
                                    <div class="article-summary-box-inner">
                                        <span>The paper proposes a novel approach for gray scale images segmentation. It is
based on multiple features extraction from single feature per image pixel,
namely its intensity value, using Echo state network. The newly extracted
features -- reservoir equilibrium states -- reveal hidden image characteristics
that improve its segmentation via a clustering algorithm. Moreover, it was
demonstrated that the intrinsic plasticity tuning of reservoir fits its
equilibrium states to the original image intensity distribution thus allowing
for its better segmentation. The proposed approach is tested on the benchmark
image Lena.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A reinforcement learning approach to resource allocation in genomic selection. (arXiv:2107.10901v1 [q-bio.GN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Moeinizade_S/0/1/0/all/0/1">Saba Moeinizade</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hu_G/0/1/0/all/0/1">Guiping Hu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Wang_L/0/1/0/all/0/1">Lizhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10901">
                                    <div class="article-summary-box-inner">
                                        <span>Genomic selection (GS) is a technique that plant breeders use to select
individuals to mate and produce new generations of species. Allocation of
resources is a key factor in GS. At each selection cycle, breeders are facing
the choice of budget allocation to make crosses and produce the next generation
of breeding parents. Inspired by recent advances in reinforcement learning for
AI problems, we develop a reinforcement learning-based algorithm to
automatically learn to allocate limited resources across different generations
of breeding. We mathematically formulate the problem in the framework of Markov
Decision Process (MDP) by defining state and action spaces. To avoid the
explosion of the state space, an integer linear program is proposed that
quantifies the trade-off between resources and time. Finally, we propose a
value function approximation method to estimate the action-value function and
then develop a greedy policy improvement technique to find the optimal
resources. We demonstrate the effectiveness of the proposed method in enhancing
genetic gain using a case study with realistic data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Adaptive State Aggregation Algorithm for Markov Decision Processes. (arXiv:2107.11053v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guanting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaebler_J/0/1/0/all/0/1">Johann Demetrio Gaebler</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_M/0/1/0/all/0/1">Matt Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chunlin Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yinyu Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11053">
                                    <div class="article-summary-box-inner">
                                        <span>Value iteration is a well-known method of solving Markov Decision Processes
(MDPs) that is simple to implement and boasts strong theoretical convergence
guarantees. However, the computational cost of value iteration quickly becomes
infeasible as the size of the state space increases. Various methods have been
proposed to overcome this issue for value iteration in large state and action
space MDPs, often at the price, however, of generalizability and algorithmic
simplicity. In this paper, we propose an intuitive algorithm for solving MDPs
that reduces the cost of value iteration updates by dynamically grouping
together states with similar cost-to-go values. We also prove that our
algorithm converges almost surely to within \(2\varepsilon / (1 - \gamma)\) of
the true optimal value in the \(\ell^\infty\) norm, where \(\gamma\) is the
discount factor and aggregated states differ by at most \(\varepsilon\).
Numerical experiments on a variety of simulated environments confirm the
robustness of our algorithm and its ability to solve MDPs with much cheaper
updates especially as the scale of the MDP problem increases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning Versus Classical Machine Learning: A Convergence Comparison. (arXiv:2107.10976v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asad_M/0/1/0/all/0/1">Muhammad Asad</a>, <a href="http://arxiv.org/find/cs/1/au:+Moustafa_A/0/1/0/all/0/1">Ahmed Moustafa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1">Takayuki Ito</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10976">
                                    <div class="article-summary-box-inner">
                                        <span>In the past few decades, machine learning has revolutionized data processing
for large scale applications. Simultaneously, increasing privacy threats in
trending applications led to the redesign of classical data training models. In
particular, classical machine learning involves centralized data training,
where the data is gathered, and the entire training process executes at the
central server. Despite significant convergence, this training involves several
privacy threats on participants&#x27; data when shared with the central cloud
server. To this end, federated learning has achieved significant importance
over distributed data training. In particular, the federated learning allows
participants to collaboratively train the local models on local data without
revealing their sensitive information to the central cloud server. In this
paper, we perform a convergence comparison between classical machine learning
and federated learning on two publicly available datasets, namely,
logistic-regression-MNIST dataset and image-classification-CIFAR-10 dataset.
The simulation results demonstrate that federated learning achieves higher
convergence within limited communication rounds while maintaining participants&#x27;
anonymity. We hope that this research will show the benefits and help federated
learning to be implemented widely.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HURRA! Human readable router anomaly detection. (arXiv:2107.11078v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Navarro_J/0/1/0/all/0/1">Jose M. Navarro</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossi_D/0/1/0/all/0/1">Dario Rossi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.11078">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents HURRA, a system that aims to reduce the time spent by
human operators in the process of network troubleshooting. To do so, it
comprises two modules that are plugged after any anomaly detection algorithm:
(i) a first attention mechanism, that ranks the present features in terms of
their relation with the anomaly and (ii) a second module able to incorporates
previous expert knowledge seamlessly, without any need of human interaction nor
decisions. We show the efficacy of these simple processes on a collection of
real router datasets obtained from tens of ISPs which exhibit a rich variety of
anomalies and very heterogeneous set of KPIs, on which we gather manually
annotated ground truth by the operator solving the troubleshooting ticket. Our
experimental evaluation shows that (i) the proposed system is effective in
achieving high levels of agreement with the expert, that (ii) even a simple
statistical approach is able to extracting useful information from expert
knowledge gained in past cases to further improve performance and finally that
(iii) the main difficulty in live deployment concerns the automated selection
of the anomaly detection algorithm and the tuning of its hyper-parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discovering Sparse Interpretable Dynamics from Partial Observations. (arXiv:2107.10879v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Peter Y. Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Arino_J/0/1/0/all/0/1">Joan Ari&#xf1;o</a>, <a href="http://arxiv.org/find/cs/1/au:+Soljacic_M/0/1/0/all/0/1">Marin Solja&#x10d;i&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10879">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying the governing equations of a nonlinear dynamical system is key to
both understanding the physical features of the system and constructing an
accurate model of the dynamics that generalizes well beyond the available data.
We propose a machine learning framework for discovering these governing
equations using only partial observations, combining an encoder for state
reconstruction with a sparse symbolic model. Our tests show that this method
can successfully reconstruct the full system state and identify the underlying
dynamics for a variety of ODE and PDE systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Generalization under Conditional and Label Shifts via Variational Bayesian Inference. (arXiv:2107.10931v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1">Bo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Linghao Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_F/0/1/0/all/0/1">Fangxu Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_J/0/1/0/all/0/1">Jinsong Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jun Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakhri_G/0/1/0/all/0/1">Georges EL Fakhri</a>, <a href="http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1">Jonghye Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10931">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we propose a domain generalization (DG) approach to learn on
several labeled source domains and transfer knowledge to a target domain that
is inaccessible in training. Considering the inherent conditional and label
shifts, we would expect the alignment of $p(x|y)$ and $p(y)$. However, the
widely used domain invariant feature learning (IFL) methods relies on aligning
the marginal concept shift w.r.t. $p(x)$, which rests on an unrealistic
assumption that $p(y)$ is invariant across domains. We thereby propose a novel
variational Bayesian inference framework to enforce the conditional
distribution alignment w.r.t. $p(x|y)$ via the prior distribution matching in a
latent space, which also takes the marginal label shift w.r.t. $p(y)$ into
consideration with the posterior alignment. Extensive experiments on various
benchmarks demonstrate that our framework is robust to the label shift and the
cross-domain accuracy is significantly improved, thereby achieving superior
performance over the conventional IFL counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Structured second-order methods via natural gradient descent. (arXiv:2107.10884v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lin_W/0/1/0/all/0/1">Wu Lin</a>, <a href="http://arxiv.org/find/stat/1/au:+Nielsen_F/0/1/0/all/0/1">Frank Nielsen</a>, <a href="http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1">Mohammad Emtiyaz Khan</a>, <a href="http://arxiv.org/find/stat/1/au:+Schmidt_M/0/1/0/all/0/1">Mark Schmidt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10884">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose new structured second-order methods and structured
adaptive-gradient methods obtained by performing natural-gradient descent on
structured parameter spaces. Natural-gradient descent is an attractive approach
to design new algorithms in many settings such as gradient-free,
adaptive-gradient, and second-order methods. Our structured methods not only
enjoy a structural invariance but also admit a simple expression. Finally, we
test the efficiency of our proposed methods on both deterministic non-convex
problems and deep learning problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FNetAR: Mixing Tokens with Autoregressive Fourier Transforms. (arXiv:2107.10932v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lou_T/0/1/0/all/0/1">Tim Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1">Michael Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramezanali_M/0/1/0/all/0/1">Mohammad Ramezanali</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_V/0/1/0/all/0/1">Vincent Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10932">
                                    <div class="article-summary-box-inner">
                                        <span>In this note we examine the autoregressive generalization of the FNet
algorithm, in which self-attention layers from the standard Transformer
architecture are substituted with a trivial sparse-uniformsampling procedure
based on Fourier transforms. Using the Wikitext-103 benchmark, we
demonstratethat FNetAR retains state-of-the-art performance (25.8 ppl) on the
task of causal language modelingcompared to a Transformer-XL baseline (24.2
ppl) with only half the number self-attention layers,thus providing further
evidence for the superfluity of deep neural networks with heavily
compoundedattention mechanisms. The autoregressive Fourier transform could
likely be used for parameterreduction on most Transformer-based time-series
prediction models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What are you optimizing for? Aligning Recommender Systems with Human Values. (arXiv:2107.10939v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stray_J/0/1/0/all/0/1">Jonathan Stray</a>, <a href="http://arxiv.org/find/cs/1/au:+Vendrov_I/0/1/0/all/0/1">Ivan Vendrov</a>, <a href="http://arxiv.org/find/cs/1/au:+Nixon_J/0/1/0/all/0/1">Jeremy Nixon</a>, <a href="http://arxiv.org/find/cs/1/au:+Adler_S/0/1/0/all/0/1">Steven Adler</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1">Dylan Hadfield-Menell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10939">
                                    <div class="article-summary-box-inner">
                                        <span>We describe cases where real recommender systems were modified in the service
of various human values such as diversity, fairness, well-being, time well
spent, and factual accuracy. From this we identify the current practice of
values engineering: the creation of classifiers from human-created data with
value-based labels. This has worked in practice for a variety of issues, but
problems are addressed one at a time, and users and other stakeholders have
seldom been involved. Instead, we look to AI alignment work for approaches that
could learn complex values directly from stakeholders, and identify four major
directions: useful measures of alignment, participatory design and operation,
interactive value learning, and informed deliberative judgments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Certified Robustness for Ensemble Models and Beyond. (arXiv:2107.10873v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhuolin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Linyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaojun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1">Bhavya Kailkhura</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tao Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10873">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies show that deep neural networks (DNN) are vulnerable to
adversarial examples, which aim to mislead DNNs by adding perturbations with
small magnitude. To defend against such attacks, both empirical and theoretical
defense approaches have been extensively studied for a single ML model. In this
work, we aim to analyze and provide the certified robustness for ensemble ML
models, together with the sufficient and necessary conditions of robustness for
different ensemble protocols. Although ensemble models are shown more robust
than a single model empirically; surprisingly, we find that in terms of the
certified robustness the standard ensemble models only achieve marginal
improvement compared to a single model. Thus, to explore the conditions that
guarantee to provide certifiably robust ensemble ML models, we first prove that
diversified gradient and large confidence margin are sufficient and necessary
conditions for certifiably robust ensemble models under the model-smoothness
assumption. We then provide the bounded model-smoothness analysis based on the
proposed Ensemble-before-Smoothing strategy. We also prove that an ensemble
model can always achieve higher certified robustness than a single base model
under mild conditions. Inspired by the theoretical findings, we propose the
lightweight Diversity Regularized Training (DRT) to train certifiably robust
ensemble ML models. Extensive experiments show that our DRT enhanced ensembles
can consistently achieve higher certified robustness than existing single and
ensemble ML models, demonstrating the state-of-the-art certified L2-robustness
on MNIST, CIFAR-10, and ImageNet datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiclass versus Binary Differentially Private PAC Learning. (arXiv:2107.10870v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bun_M/0/1/0/all/0/1">Mark Bun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaboardi_M/0/1/0/all/0/1">Marco Gaboardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivakumar_S/0/1/0/all/0/1">Satchit Sivakumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10870">
                                    <div class="article-summary-box-inner">
                                        <span>We show a generic reduction from multiclass differentially private PAC
learning to binary private PAC learning. We apply this transformation to a
recently proposed binary private PAC learner to obtain a private multiclass
learner with sample complexity that has a polynomial dependence on the
multiclass Littlestone dimension and a poly-logarithmic dependence on the
number of classes. This yields an exponential improvement in the dependence on
both parameters over learners from previous work. Our proof extends the notion
of $\Psi$-dimension defined in work of Ben-David et al. [JCSS &#x27;95] to the
online setting and explores its general properties.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bagging, optimized dynamic mode decomposition (BOP-DMD) for robust, stable forecasting with spatial and temporal uncertainty-quantification. (arXiv:2107.10878v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sashidhar_D/0/1/0/all/0/1">Diya Sashidhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1">J. Nathan Kutz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10878">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamic mode decomposition (DMD) provides a regression framework for
adaptively learning a best-fit linear dynamics model over snapshots of
temporal, or spatio-temporal, data. A diversity of regression techniques have
been developed for producing the linear model approximation whose solutions are
exponentials in time. For spatio-temporal data, DMD provides low-rank and
interpretable models in the form of dominant modal structures along with their
exponential/oscillatory behavior in time. The majority of DMD algorithms,
however, are prone to bias errors from noisy measurements of the dynamics,
leading to poor model fits and unstable forecasting capabilities. The optimized
DMD algorithm minimizes the model bias with a variable projection optimization,
thus leading to stabilized forecasting capabilities. Here, the optimized DMD
algorithm is improved by using statistical bagging methods whereby a single set
of snapshots is used to produce an ensemble of optimized DMD models. The
outputs of these models are averaged to produce a bagging, optimized dynamic
mode decomposition (BOP-DMD). BOP-DMD not only improves performance, it also
robustifies the model and provides both spatial and temporal uncertainty
quantification (UQ). Thus unlike currently available DMD algorithms, BOP-DMD
provides a stable and robust model for probabilistic, or Bayesian forecasting
with comprehensive UQ metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Filament Plots for Data Visualization. (arXiv:2107.10869v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Strawn_N/0/1/0/all/0/1">Nate Strawn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10869">
                                    <div class="article-summary-box-inner">
                                        <span>We construct a computationally inexpensive 3D extension of Andrew&#x27;s plots by
considering curves generated by Frenet-Serret equations and induced by
optimally smooth 2D Andrew&#x27;s plots. We consider linear isometries from a
Euclidean data space to infinite dimensional spaces of 2D curves, and
parametrize the linear isometries that produce (on average) optimally smooth
curves over a given dataset. This set of optimal isometries admits many degrees
of freedom, and (using recent results on generalized Gauss sums) we identify a
particular a member of this set which admits an asymptotic projective &quot;tour&quot;
property. Finally, we consider the unit-length 3D curves (filaments) induced by
these 2D Andrew&#x27;s plots, where the linear isometry property preserves distances
as &quot;relative total square curvatures&quot;. This work concludes by illustrating
filament plots for several datasets. Code is available at
https://github.com/n8epi/filaments</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local SGD Optimizes Overparameterized Neural Networks in Polynomial Time. (arXiv:2107.10868v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yuyang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahdavi_M/0/1/0/all/0/1">Mehrdad Mahdavi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2107.10868">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we prove that Local (S)GD (or FedAvg) can optimize two-layer
neural networks with Rectified Linear Unit (ReLU) activation function in
polynomial time. Despite the established convergence theory of Local SGD on
optimizing general smooth functions in communication-efficient distributed
optimization, its convergence on non-smooth ReLU networks still eludes full
theoretical understanding. The key property used in many Local SGD analysis on
smooth function is gradient Lipschitzness, so that the gradient on local models
will not drift far away from that on averaged model. However, this decent
property does not hold in networks with non-smooth ReLU activation function. We
show that, even though ReLU network does not admit gradient Lipschitzness
property, the difference between gradients on local models and average model
will not change too much, under the dynamics of Local SGD. We validate our
theoretical results via extensive experiments. This work is the first to show
the convergence of Local SGD on non-smooth functions, and will shed lights on
the optimization theory of federated training of deep neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Neural Speech Synthesis. (arXiv:2106.15561v3 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tan_X/0/1/0/all/0/1">Xu Tan</a>, <a href="http://arxiv.org/find/eess/1/au:+Qin_T/0/1/0/all/0/1">Tao Qin</a>, <a href="http://arxiv.org/find/eess/1/au:+Soong_F/0/1/0/all/0/1">Frank Soong</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_T/0/1/0/all/0/1">Tie-Yan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.15561">
                                    <div class="article-summary-box-inner">
                                        <span>Text to speech (TTS), or speech synthesis, which aims to synthesize
intelligible and natural speech given text, is a hot research topic in speech,
language, and machine learning communities and has broad applications in the
industry. As the development of deep learning and artificial intelligence,
neural network-based TTS has significantly improved the quality of synthesized
speech in recent years. In this paper, we conduct a comprehensive survey on
neural TTS, aiming to provide a good understanding of current research and
future trends. We focus on the key components in neural TTS, including text
analysis, acoustic models and vocoders, and several advanced topics, including
fast TTS, low-resource TTS, robust TTS, expressive TTS, and adaptive TTS, etc.
We further summarize resources related to TTS (e.g., datasets, opensource
implementations) and discuss future research directions. This survey can serve
both academic researchers and industry practitioners working on TTS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>

    <footer>
        <time id="build-timestamp" datetime="2021-07-30T02:13:30.638Z">2021-07-30T02:13:30.638Z</time>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.js"></script>
    <script src="highlightRegex.js"></script>
    <script src="index.js"></script>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=386&t=tt&d=sDvlbgmeTw_E_GoVDGdggVOFT21w54hFtP9VETatnEM&cmo=ff4242&cmn=3dd13d"></script>
    <!-- %before-body-end.html% -->
</body>

</html>