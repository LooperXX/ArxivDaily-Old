 
<!DOCTYPE html>
<html lang="en">

<head>
    <title>ArxivDaily</title>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="robots" content="noindex, nofollow" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <link rel="alternate" type="application/rss+xml" title="ArxivDaily" href="feed.atom" />
    <link href="index.css" rel="stylesheet" />
    <!-- %before-head-end.html% -->
</head>

<body>
    <!-- %after-body-begin.html% -->
    <a href="https://github.com/LooperXX/ArxivDaily" style="margin: 0 auto;padding: 0.5em 1em;">LooperXX/ArxivDaily</a>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-08">2021-06-08</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpanNER: Named Entity Re-/Recognition as Span Prediction. (arXiv:2106.00641v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1">Jinlan Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuanjing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00641">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen the paradigm shift of Named Entity Recognition (NER)
systems from sequence labeling to span prediction. Despite its preliminary
effectiveness, the span prediction model&#x27;s architectural bias has not been
fully understood. In this paper, we first investigate the strengths and
weaknesses when the span prediction model is used for named entity recognition
compared with the sequence labeling framework and how to further improve it,
which motivates us to make complementary advantages of systems based on
different paradigms. We then reveal that span prediction, simultaneously, can
serve as a system combiner to re-recognize named entities from different
systems&#x27; outputs. We experimentally implement 154 systems on 11 datasets,
covering three languages, comprehensive results show the effectiveness of span
prediction models that both serve as base NER systems and system combiners. We
make all code and datasets available: \url{https://github.com/neulab/spanner},
as well as an online system demo: \url{this http URL}. Our model also has
been deployed into the ExplainaBoard platform, which allows users to flexibly
perform a system combination of top-scoring systems in an interactive way:
\url{this http URL}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NewsEmbed: Modeling News through Pre-trained Document Representations. (arXiv:2106.00590v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00590">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively modeling text-rich fresh content such as news articles at
document-level is a challenging problem. To ensure a content-based model
generalize well to a broad range of applications, it is critical to have a
training dataset that is large beyond the scale of human labels while achieving
desired quality. In this work, we address those two challenges by proposing a
novel approach to mine semantically-relevant fresh documents, and their topic
labels, with little human supervision. Meanwhile, we design a multitask model
called NewsEmbed that alternatively trains a contrastive learning with a
multi-label classification to derive a universal document encoder. We show that
the proposed approach can provide billions of high quality organic training
examples and can be naturally extended to multilingual setting where texts in
different languages are encoded in the same semantic space. We experimentally
demonstrate NewsEmbed&#x27;s competitive performance across multiple natural
language understanding tasks, both supervised and unsupervised.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KGPool: Dynamic Knowledge Graph Context Selection for Relation Extraction. (arXiv:2106.00459v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nadgeri_A/0/1/0/all/0/1">Abhishek Nadgeri</a>, <a href="http://arxiv.org/find/cs/1/au:+Bastos_A/0/1/0/all/0/1">Anson Bastos</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1">Kuldeep Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulang_I/0/1/0/all/0/1">Isaiah Onando Mulang&#x27;</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoffart_J/0/1/0/all/0/1">Johannes Hoffart</a>, <a href="http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1">Saeedeh Shekarpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Saraswat_V/0/1/0/all/0/1">Vijay Saraswat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00459">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel method for relation extraction (RE) from a single
sentence, mapping the sentence and two given entities to a canonical fact in a
knowledge graph (KG). Especially in this presumed sentential RE setting, the
context of a single sentence is often sparse. This paper introduces the KGPool
method to address this sparsity, dynamically expanding the context with
additional facts from the KG. It learns the representation of these facts
(entity alias, entity descriptions, etc.) using neural methods, supplementing
the sentential context. Unlike existing methods that statically use all
expanded facts, KGPool conditions this expansion on the sentence. We study the
efficacy of KGPool by evaluating it with different neural models and KGs
(Wikidata and NYT Freebase). Our experimental evaluation on standard datasets
shows that by feeding the KGPool representation into a Graph Neural Network,
the overall method is significantly more accurate than state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Relation Alignment for Calibrated Cross-modal Retrieval. (arXiv:2105.13868v2 [cs.CL] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Shuhuai Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Junyang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guangxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1">Rui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">An Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13868">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the achievements of large-scale multimodal pre-training approaches,
cross-modal retrieval, e.g., image-text retrieval, remains a challenging task.
To bridge the semantic gap between the two modalities, previous studies mainly
focus on word-region alignment at the object level, lacking the matching
between the linguistic relation among the words and the visual relation among
the regions. The neglect of such relation consistency impairs the
contextualized representation of image-text pairs and hinders the model
performance and the interpretability. In this paper, we first propose a novel
metric, Intra-modal Self-attention Distance (ISD), to quantify the relation
consistency by measuring the semantic distance between linguistic and visual
relations. In response, we present Inter-modal Alignment on Intra-modal
Self-attentions (IAIS), a regularized training method to optimize the ISD and
calibrate intra-modal self-attentions from the two modalities mutually via
inter-modal alignment. The IAIS regularizer boosts the performance of
prevailing models on Flickr30k and MS COCO datasets by a considerable margin,
which demonstrates the superiority of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Select, Extract and Generate: Neural Keyphrase Generation with Layer-wise Coverage Attention. (arXiv:2008.01739v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1">Wasi Uddin Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_X/0/1/0/all/0/1">Xiao Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Soomin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.01739">
                                    <div class="article-summary-box-inner">
                                        <span>Natural language processing techniques have demonstrated promising results in
keyphrase generation. However, one of the major challenges in \emph{neural}
keyphrase generation is processing long documents using deep neural networks.
Generally, documents are truncated before given as inputs to neural networks.
Consequently, the models may miss essential points conveyed in the target
document. To overcome this limitation, we propose \emph{SEG-Net}, a neural
keyphrase generation model that is composed of two major components, (1) a
selector that selects the salient sentences in a document and (2) an
extractor-generator that jointly extracts and generates keyphrases from the
selected sentences. SEG-Net uses Transformer, a self-attentive architecture, as
the basic building block with a novel \emph{layer-wise} coverage attention to
summarize most of the points discussed in the document. The experimental
results on seven keyphrase generation benchmarks from scientific and web
documents demonstrate that SEG-Net outperforms the state-of-the-art neural
generative methods by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Automated Evaluation of Open Domain Dialog via Diverse Reference Augmentation. (arXiv:2106.02833v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gangal_V/0/1/0/all/0/1">Varun Gangal</a>, <a href="http://arxiv.org/find/cs/1/au:+Jhamtani_H/0/1/0/all/0/1">Harsh Jhamtani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1">Eduard Hovy</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1">Taylor Berg-Kirkpatrick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02833">
                                    <div class="article-summary-box-inner">
                                        <span>Multiple different responses are often plausible for a given open domain
dialog context. Prior work has shown the importance of having multiple valid
reference responses for meaningful and robust automated evaluations. In such
cases, common practice has been to collect more human written references.
However, such collection can be expensive, time consuming, and not easily
scalable. Instead, we propose a novel technique for automatically expanding a
human generated reference to a set of candidate references. We fetch plausible
references from knowledge sources, and adapt them so that they are more fluent
in context of the dialog instance in question. More specifically, we use (1) a
commonsense knowledge base to elicit a large number of plausible reactions
given the dialog history (2) relevant instances retrieved from dialog corpus,
using similar past as well as future contexts. We demonstrate that our
automatically expanded reference sets lead to large improvements in
correlations of automated metrics with human ratings of system outputs for
DailyDialog dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning with Variational Semantic Memory for Word Sense Disambiguation. (arXiv:2106.02960v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yingjun Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Holla_N/0/1/0/all/0/1">Nithin Holla</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhen_X/0/1/0/all/0/1">Xiantong Zhen</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1">Cees G.M. Snoek</a>, <a href="http://arxiv.org/find/cs/1/au:+Shutova_E/0/1/0/all/0/1">Ekaterina Shutova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02960">
                                    <div class="article-summary-box-inner">
                                        <span>A critical challenge faced by supervised word sense disambiguation (WSD) is
the lack of large annotated datasets with sufficient coverage of words in their
diversity of senses. This inspired recent research on few-shot WSD using
meta-learning. While such work has successfully applied meta-learning to learn
new word senses from very few examples, its performance still lags behind its
fully supervised counterpart. Aiming to further close this gap, we propose a
model of semantic memory for WSD in a meta-learning setting. Semantic memory
encapsulates prior experiences seen throughout the lifetime of the model, which
aids better generalization in limited data settings. Our model is based on
hierarchical variational inference and incorporates an adaptive memory update
rule via a hypernetwork. We show our model advances the state of the art in
few-shot WSD, supports effective learning in extremely data scarce (e.g.
one-shot) scenarios and produces meaning prototypes that capture similar senses
of distinct words.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhancing Taxonomy Completion with Concept Generation via Fusing Relational Representations. (arXiv:2106.02974v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_Q/0/1/0/all/0/1">Qingkai Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Jinfeng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1">Wenhao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cleland_Huang_J/0/1/0/all/0/1">Jane Cleland-Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Meng Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02974">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic construction of a taxonomy supports many applications in
e-commerce, web search, and question answering. Existing taxonomy expansion or
completion methods assume that new concepts have been accurately extracted and
their embedding vectors learned from the text corpus. However, one critical and
fundamental challenge in fixing the incompleteness of taxonomies is the
incompleteness of the extracted concepts, especially for those whose names have
multiple words and consequently low frequency in the corpus. To resolve the
limitations of extraction-based methods, we propose GenTaxo to enhance taxonomy
completion by identifying positions in existing taxonomies that need new
concepts and then generating appropriate concept names. Instead of relying on
the corpus for concept embeddings, GenTaxo learns the contextual embeddings
from their surrounding graph-based and language-based relational information,
and leverages the corpus for pre-training a concept name generator.
Experimental results demonstrate that GenTaxo improves the completeness of
taxonomies over existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepCPCFG: Deep Learning and Context Free Grammars for End-to-End Information Extraction. (arXiv:2103.05908v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chua_F/0/1/0/all/0/1">Freddy C. Chua</a>, <a href="http://arxiv.org/find/cs/1/au:+Duffy_N/0/1/0/all/0/1">Nigel P. Duffy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05908">
                                    <div class="article-summary-box-inner">
                                        <span>We address the challenge of extracting structured information from business
documents without detailed annotations. We propose Deep Conditional
Probabilistic Context Free Grammars (DeepCPCFG) to parse two-dimensional
complex documents and use Recursive Neural Networks to create an end-to-end
system for finding the most probable parse that represents the structured
information to be extracted. This system is trained end-to-end with scanned
documents as input and only relational-records as labels. The
relational-records are extracted from existing databases avoiding the cost of
annotating documents by hand. We apply this approach to extract information
from scanned invoices achieving state-of-the-art results despite using no
hand-annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Acoustic Unit Discovery by Leveraging a Language-Independent Subword Discriminative Feature Representation. (arXiv:2104.00994v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Feng_S/0/1/0/all/0/1">Siyuan Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Zelasko_P/0/1/0/all/0/1">Piotr &#x17b;elasko</a>, <a href="http://arxiv.org/find/eess/1/au:+Moro_Velazquez_L/0/1/0/all/0/1">Laureano Moro-Vel&#xe1;zquez</a>, <a href="http://arxiv.org/find/eess/1/au:+Scharenborg_O/0/1/0/all/0/1">Odette Scharenborg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00994">
                                    <div class="article-summary-box-inner">
                                        <span>This paper tackles automatically discovering phone-like acoustic units (AUD)
from unlabeled speech data. Past studies usually proposed single-step
approaches. We propose a two-stage approach: the first stage learns a
subword-discriminative feature representation and the second stage applies
clustering to the learned representation and obtains phone-like clusters as the
discovered acoustic units. In the first stage, a recently proposed method in
the task of unsupervised subword modeling is improved by replacing a
monolingual out-of-domain (OOD) ASR system with a multilingual one to create a
subword-discriminative representation that is more language-independent. In the
second stage, segment-level k-means is adopted, and two methods to represent
the variable-length speech segments as fixed-dimension feature vectors are
compared. Experiments on a very low-resource Mboshi language corpus show that
our approach outperforms state-of-the-art AUD in both normalized mutual
information (NMI) and F-score. The multilingual ASR improved upon the
monolingual ASR in providing OOD phone labels and in estimating the phone
boundaries. A comparison of our systems with and without knowing the
ground-truth phone boundaries showed a 16% NMI performance gap, suggesting that
the current approach can significantly benefit from improved phone boundary
estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">hBert + BiasCorp -- Fighting Racism on the Web. (arXiv:2104.02242v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Onabola_O/0/1/0/all/0/1">Olawale Onabola</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zhuang Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Akera_B/0/1/0/all/0/1">Benjamin Akera</a>, <a href="http://arxiv.org/find/cs/1/au:+Ibraheem_A/0/1/0/all/0/1">Abdulrahman Ibraheem</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1">Jia Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dianbo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02242">
                                    <div class="article-summary-box-inner">
                                        <span>Subtle and overt racism is still present both in physical and online
communities today and has impacted many lives in different segments of the
society. In this short piece of work, we present how we&#x27;re tackling this
societal issue with Natural Language Processing. We are releasing BiasCorp, a
dataset containing 139,090 comments and news segment from three specific
sources - Fox News, BreitbartNews and YouTube. The first batch (45,000 manually
annotated) is ready for publication. We are currently in the final phase of
manually labeling the remaining dataset using Amazon Mechanical Turk. BERT has
been used widely in several downstream tasks. In this work, we present hBERT,
where we modify certain layers of the pretrained BERT model with the new
Hopfield Layer. hBert generalizes well across different distributions with the
added advantage of a reduced model complexity. We are also releasing a
JavaScript library and a Chrome Extension Application, to help developers make
use of our trained model in web applications (say chat application) and for
users to identify and report racially biased contents on the web respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BiToD: A Bilingual Multi-Domain Dataset For Task-Oriented Dialogue Modeling. (arXiv:2106.02787v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhaojiang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Madotto_A/0/1/0/all/0/1">Andrea Madotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1">Genta Indra Winata</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1">Peng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_F/0/1/0/all/0/1">Feijun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yuxiang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Chen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1">Pascale Fung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02787">
                                    <div class="article-summary-box-inner">
                                        <span>Task-oriented dialogue (ToD) benchmarks provide an important avenue to
measure progress and develop better conversational agents. However, existing
datasets for end-to-end ToD modeling are limited to a single language,
hindering the development of robust end-to-end ToD systems for multilingual
countries and regions. Here we introduce BiToD, the first bilingual
multi-domain dataset for end-to-end task-oriented dialogue modeling. BiToD
contains over 7k multi-domain dialogues (144k utterances) with a large and
realistic bilingual knowledge base. It serves as an effective benchmark for
evaluating bilingual ToD systems and cross-lingual transfer learning
approaches. We provide state-of-the-art baselines under three evaluation
settings (monolingual, bilingual, and cross-lingual). The analysis of our
baselines in different settings highlights 1) the effectiveness of training a
bilingual ToD system compared to two independent monolingual ToD systems, and
2) the potential of leveraging a bilingual knowledge base and cross-lingual
transfer learning to improve the system performance under low resource
condition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contextual Biasing of Language Models for Speech Recognition in Goal-Oriented Conversational Agents. (arXiv:2103.10325v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1">Ashish Shenoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1">Sravan Bodapati</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1">Katrin Kirchhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10325">
                                    <div class="article-summary-box-inner">
                                        <span>Goal-oriented conversational interfaces are designed to accomplish specific
tasks and typically have interactions that tend to span multiple turns adhering
to a pre-defined structure and a goal. However, conventional neural language
models (NLM) in Automatic Speech Recognition (ASR) systems are mostly trained
sentence-wise with limited context. In this paper, we explore different ways to
incorporate context into a LSTM based NLM in order to model long range
dependencies and improve speech recognition. Specifically, we use context carry
over across multiple turns and use lexical contextual cues such as system
dialog act from Natural Language Understanding (NLU) models and the user
provided structure of the chatbot. We also propose a new architecture that
utilizes context embeddings derived from BERT on sample utterances provided
during inference time. Our experiments show a word error rate (WER) relative
reduction of 7% over non-contextual utterance-level NLM rescorers on
goal-oriented audio datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS. (arXiv:2103.15060v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Ye Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Zen_H/0/1/0/all/0/1">Heiga Zen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jonathan Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yonghui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.15060">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces PnG BERT, a new encoder model for neural TTS. This
model is augmented from the original BERT model, by taking both phoneme and
grapheme representations of text as input, as well as the word-level alignment
between them. It can be pre-trained on a large text corpus in a self-supervised
manner, and fine-tuned in a TTS task. Experimental results show that a neural
TTS model using a pre-trained PnG BERT as its encoder yields more natural
prosody and more accurate pronunciation than a baseline model using only
phoneme input with no pre-training. Subjective side-by-side preference
evaluations show that raters have no statistically significant preference
between the speech synthesized using a PnG BERT and ground truth recordings
from professional speakers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dodrio: Exploring Transformer Models with Interactive Visualization. (arXiv:2103.14625v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zijie J. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Turko_R/0/1/0/all/0/1">Robert Turko</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1">Duen Horng Chau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14625">
                                    <div class="article-summary-box-inner">
                                        <span>Why do large pre-trained transformer-based models perform so well across a
wide variety of NLP tasks? Recent research suggests the key may lie in
multi-headed attention mechanism&#x27;s ability to learn and represent linguistic
information. Understanding how these models represent both syntactic and
semantic knowledge is vital to investigate why they succeed and fail, what they
have learned, and how they can improve. We present Dodrio, an open-source
interactive visualization tool to help NLP researchers and practitioners
analyze attention mechanisms in transformer-based models with linguistic
knowledge. Dodrio tightly integrates an overview that summarizes the roles of
different attention heads, and detailed views that help users compare attention
weights with the syntactic structure and semantic information in the input
text. To facilitate the visual comparison of attention weights and linguistic
knowledge, Dodrio applies different graph visualization techniques to represent
attention weights scalable to longer input text. Case studies highlight how
Dodrio provides insights into understanding the attention mechanism in
transformer-based models. Dodrio is available at
https://poloclub.github.io/dodrio/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2004.09764v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xianghong Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Haoli Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.09764">
                                    <div class="article-summary-box-inner">
                                        <span>Variational autoencoders (VAEs) have been widely applied for text modeling.
In practice, however, they are troubled by two challenges: information
underrepresentation and posterior collapse. The former arises as only the last
hidden state of LSTM encoder is transformed into the latent space, which is
generally insufficient to summarize the data. The latter is a long-standing
problem during the training of VAEs as the optimization is trapped to a
disastrous local optimum. In this paper, we propose Discrete Auto-regressive
Variational Attention Model (DAVAM) to address the challenges. Specifically, we
introduce an auto-regressive variational attention approach to enrich the
latent space by effectively capturing the semantic dependency from the input.
We further design discrete latent space for the variational attention and
mathematically show that our model is free from posterior collapse. Extensive
experiments on language modeling tasks demonstrate the superiority of DAVAM
against several VAE counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PALI at SemEval-2021 Task 2: Fine-Tune XLM-RoBERTa for Word in Context Disambiguation. (arXiv:2104.10375v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Shuyi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jian Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haiqin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lianxin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1">Yang Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jianping Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10375">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the PALI team&#x27;s winning system for SemEval-2021 Task 2:
Multilingual and Cross-lingual Word-in-Context Disambiguation. We fine-tune
XLM-RoBERTa model to solve the task of word in context disambiguation, i.e., to
determine whether the target word in the two contexts contains the same meaning
or not. In the implementation, we first specifically design an input tag to
emphasize the target word in the contexts. Second, we construct a new vector on
the fine-tuned embeddings from XLM-RoBERTa and feed it to a fully-connected
network to output the probability of whether the target word in the context has
the same meaning or not. The new vector is attained by concatenating the
embedding of the [CLS] token and the embeddings of the target word in the
contexts. In training, we explore several tricks, such as the Ranger optimizer,
data augmentation, and adversarial training, to improve the model prediction.
Consequently, we attain first place in all four cross-lingual tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERTnesia: Investigating the capture and forgetting of knowledge in BERT. (arXiv:2106.02902v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wallat_J/0/1/0/all/0/1">Jonas Wallat</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_J/0/1/0/all/0/1">Jaspreet Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Anand_A/0/1/0/all/0/1">Avishek Anand</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02902">
                                    <div class="article-summary-box-inner">
                                        <span>Probing complex language models has recently revealed several insights into
linguistic and semantic patterns found in the learned representations. In this
article, we probe BERT specifically to understand and measure the relational
knowledge it captures in its parametric memory. While probing for linguistic
understanding is commonly applied to all layers of BERT as well as fine-tuned
models, this has not been done for factual knowledge. We utilize existing
knowledge base completion tasks (LAMA) to probe every layer of pre-trained as
well as fine-tuned BERT models(ranking, question answering, NER). Our findings
show that knowledge is not just contained in BERT&#x27;s final layers. Intermediate
layers contribute a significant amount (17-60%) to the total knowledge found.
Probing intermediate layers also reveals how different types of knowledge
emerge at varying rates. When BERT is fine-tuned, relational knowledge is
forgotten. The extent of forgetting is impacted by the fine-tuning objective
and the training data. We found that ranking models forget the least and retain
more knowledge in their final layer compared to masked language modeling and
question-answering. However, masked language modeling performed the best at
acquiring new knowledge from the training data. When it comes to learning
facts, we found that capacity and fact density are key factors. We hope this
initial work will spur further research into understanding the parametric
memory of language models and the effect of training objectives on factual
knowledge. The code to repeat the experiments is publicly available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">W-RST: Towards a Weighted RST-style Discourse Framework. (arXiv:2106.02658v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huber_P/0/1/0/all/0/1">Patrick Huber</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Wen Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1">Giuseppe Carenini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02658">
                                    <div class="article-summary-box-inner">
                                        <span>Aiming for a better integration of data-driven and linguistically-inspired
approaches, we explore whether RST Nuclearity, assigning a binary assessment of
importance between text segments, can be replaced by automatically generated,
real-valued scores, in what we call a Weighted-RST framework. In particular, we
find that weighted discourse trees from auxiliary tasks can benefit key NLP
downstream applications, compared to nuclearity-centered approaches. We further
show that real-valued importance distributions partially and interestingly
align with the assessment and uncertainty of human annotators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The R-U-A-Robot Dataset: Helping Avoid Chatbot Deception by Detecting User Questions About Human or Non-Human Identity. (arXiv:2106.02692v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gros_D/0/1/0/all/0/1">David Gros</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhou Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02692">
                                    <div class="article-summary-box-inner">
                                        <span>Humans are increasingly interacting with machines through language, sometimes
in contexts where the user may not know they are talking to a machine (like
over the phone or a text chatbot). We aim to understand how system designers
and researchers might allow their systems to confirm its non-human identity. We
collect over 2,500 phrasings related to the intent of &#x60;&#x60;Are you a robot?&quot;. This
is paired with over 2,500 adversarially selected utterances where only
confirming the system is non-human would be insufficient or disfluent. We
compare classifiers to recognize the intent and discuss the precision/recall
and model complexity tradeoffs. Such classifiers could be integrated into
dialog systems to avoid undesired deception. We then explore how both a
generative research model (Blender) as well as two deployed systems (Amazon
Alexa, Google Assistant) handle this intent, finding that systems often fail to
confirm their non-human identity. Finally, we try to understand what a good
response to the intent would be, and conduct a user study to compare the
important aspects when responding to this intent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relational Learning with Gated and Attentive Neighbor Aggregator for Few-Shot Knowledge Graph Completion. (arXiv:2104.13095v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Guanglin Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1">Chengguang Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_R/0/1/0/all/0/1">Ruiying Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Jian Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jian Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1">Luo Si</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13095">
                                    <div class="article-summary-box-inner">
                                        <span>Aiming at expanding few-shot relations&#x27; coverage in knowledge graphs (KGs),
few-shot knowledge graph completion (FKGC) has recently gained more research
interests. Some existing models employ a few-shot relation&#x27;s multi-hop neighbor
information to enhance its semantic representation. However, noise neighbor
information might be amplified when the neighborhood is excessively sparse and
no neighbor is available to represent the few-shot relation. Moreover, modeling
and inferring complex relations of one-to-many (1-N), many-to-one (N-1), and
many-to-many (N-N) by previous knowledge graph completion approaches requires
high model complexity and a large amount of training instances. Thus, inferring
complex relations in the few-shot scenario is difficult for FKGC models due to
limited training instances. In this paper, we propose a few-shot relational
learning with global-local framework to address the above issues. At the global
stage, a novel gated and attentive neighbor aggregator is built for accurately
integrating the semantics of a few-shot relation&#x27;s neighborhood, which helps
filtering the noise neighbors even if a KG contains extremely sparse
neighborhoods. For the local stage, a meta-learning based TransH (MTransH)
method is designed to model complex relations and train our model in a few-shot
learning fashion. Extensive experiments show that our model outperforms the
state-of-the-art FKGC approaches on the frequently-used benchmark datasets
NELL-One and Wiki-One. Compared with the strong baseline model MetaR, our model
achieves 5-shot FKGC performance improvements of 8.0% on NELL-One and 2.8% on
Wiki-One by the metric Hits@10.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ConVEx: Data-Efficient and Few-Shot Slot Labeling. (arXiv:2010.11791v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Henderson_M/0/1/0/all/0/1">Matthew Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11791">
                                    <div class="article-summary-box-inner">
                                        <span>We propose ConVEx (Conversational Value Extractor), an efficient pretraining
and fine-tuning neural approach for slot-labeling dialog tasks. Instead of
relying on more general pretraining objectives from prior work (e.g., language
modeling, response selection), ConVEx&#x27;s pretraining objective, a novel pairwise
cloze task using Reddit data, is well aligned with its intended usage on
sequence labeling tasks. This enables learning domain-specific slot labelers by
simply fine-tuning decoding layers of the pretrained general-purpose sequence
labeling model, while the majority of the pretrained model&#x27;s parameters are
kept frozen. We report state-of-the-art performance of ConVEx across a range of
diverse domains and data sets for dialog slot-labeling, with the largest gains
in the most challenging, few-shot setups. We believe that ConVEx&#x27;s reduced
pretraining times (i.e., only 18 hours on 12 GPUs) and cost, along with its
efficient fine-tuning and strong performance, promise wider portability and
scalability for data-efficient sequence-labeling tasks in general.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sattiy at SemEval-2021 Task 9: An Ensemble Solution for Statement Verification and Evidence Finding with Tables. (arXiv:2104.10366v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruan_X/0/1/0/all/0/1">Xiaoyi Ruan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_M/0/1/0/all/0/1">Meizhi Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jian Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haiqin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lianxin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1">Yang Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mengyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10366">
                                    <div class="article-summary-box-inner">
                                        <span>Question answering from semi-structured tables can be seen as a semantic
parsing task and is significant and practical for pushing the boundary of
natural language understanding. Existing research mainly focuses on
understanding contents from unstructured evidence, e.g., news, natural language
sentences, and documents. The task of verification from structured evidence,
such as tables, charts, and databases, is still less explored. This paper
describes sattiy team&#x27;s system in SemEval-2021 task 9: Statement Verification
and Evidence Finding with Tables (SEM-TAB-FACT). This competition aims to
verify statements and to find evidence from tables for scientific articles and
to promote the proper interpretation of the surrounding article. In this paper,
we exploited ensemble models of pre-trained language models over tables, TaPas
and TaBERT, for Task A and adjust the result based on some rules extracted for
Task B. Finally, in the leaderboard, we attain the F1 scores of 0.8496 and
0.7732 in Task A for the 2-way and 3-way evaluation, respectively, and the F1
score of 0.4856 in Task B.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adapting Long Context NLM for ASR Rescoring in Conversational Agents. (arXiv:2104.11070v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1">Ashish Shenoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1">Sravan Bodapati</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunkara_M/0/1/0/all/0/1">Monica Sunkara</a>, <a href="http://arxiv.org/find/cs/1/au:+Ronanki_S/0/1/0/all/0/1">Srikanth Ronanki</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1">Katrin Kirchhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11070">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Language Models (NLM), when trained and evaluated with context
spanning multiple utterances, have been shown to consistently outperform both
conventional n-gram language models and NLMs that use limited context. In this
paper, we investigate various techniques to incorporate turn based context
history into both recurrent (LSTM) and Transformer-XL based NLMs. For recurrent
based NLMs, we explore context carry over mechanism and feature based
augmentation, where we incorporate other forms of contextual information such
as bot response and system dialogue acts as classified by a Natural Language
Understanding (NLU) model. To mitigate the sharp nearby, fuzzy far away problem
with contextual NLM, we propose the use of attention layer over lexical
metadata to improve feature based augmentation. Additionally, we adapt our
contextual NLM towards user provided on-the-fly speech patterns by leveraging
encodings from a large pre-trained masked language model and performing fusion
with a Transformer-XL based NLM. We test our proposed models using N-best
rescoring of ASR hypotheses of task-oriented dialogues and also evaluate on
downstream NLU tasks such as intent classification and slot labeling. The best
performing model shows a relative WER between 1.6% and 9.1% and a slot labeling
F1 score improvement of 4% over non-contextual baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shellcode_IA32: A Dataset for Automatic Shellcode Generation. (arXiv:2104.13100v2 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liguori_P/0/1/0/all/0/1">Pietro Liguori</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Hossami_E/0/1/0/all/0/1">Erfan Al-Hossami</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotroneo_D/0/1/0/all/0/1">Domenico Cotroneo</a>, <a href="http://arxiv.org/find/cs/1/au:+Natella_R/0/1/0/all/0/1">Roberto Natella</a>, <a href="http://arxiv.org/find/cs/1/au:+Cukic_B/0/1/0/all/0/1">Bojan Cukic</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaikh_S/0/1/0/all/0/1">Samira Shaikh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.13100">
                                    <div class="article-summary-box-inner">
                                        <span>We take the first step to address the task of automatically generating
shellcodes, i.e., small pieces of code used as a payload in the exploitation of
a software vulnerability, starting from natural language comments. We assemble
and release a novel dataset (Shellcode_IA32), consisting of challenging but
common assembly instructions with their natural language descriptions. We
experiment with standard methods in neural machine translation (NMT) to
establish baseline performance levels on this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection of fake news on CoViD-19 on Web Search Engines. (arXiv:2103.11804v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazzeo_V/0/1/0/all/0/1">V. Mazzeo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rapisarda_A/0/1/0/all/0/1">A. Rapisarda</a>, <a href="http://arxiv.org/find/cs/1/au:+Giuffrida_G/0/1/0/all/0/1">G. Giuffrida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11804">
                                    <div class="article-summary-box-inner">
                                        <span>In early January 2020, after China reported the first cases of the new
coronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully
accurate information has started spreading faster than the virus itself.
Alongside this pandemic, people have experienced a parallel infodemic, i.e., an
overabundance of information, some of which misleading or even harmful, that
has widely spread around the globe. Although Social Media are increasingly
being used as information source, Web Search Engines, like Google or Yahoo!,
still represent a powerful and trustworthy resource for finding information on
the Web. This is due to their capability to capture the largest amount of
information, helping users quickly identify the most relevant, useful, although
not always the most reliable, results for their search queries. This study aims
to detect potential misleading and fake contents by capturing and analysing
textual information, which flow through Search Engines. By using a real-world
dataset associated with recent CoViD-19 pandemic, we first apply re-sampling
techniques for class imbalance, then we use existing Machine Learning
algorithms for classification of not reliable news. By extracting lexical and
host-based features of associated Uniform Resource Locators (URLs) for news
articles, we show that the proposed methods, so common in phishing and
malicious URLs detection, can improve the efficiency and performance of
classifiers. Based on these findings, we suggest that the use of both textual
and URLs features can improve the effectiveness of fake news detection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cluster-Former: Clustering-based Sparse Transformer for Long-Range Dependency Encoding. (arXiv:2009.06097v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuohang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1">Luowei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1">Zhe Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yen-Chun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuwei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Siqi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yu Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jingjing Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06097">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer has become ubiquitous in the deep learning field. One of the key
ingredients that destined its success is the self-attention mechanism, which
allows fully-connected contextual encoding over input tokens. However, despite
its effectiveness in modeling short sequences, self-attention suffers when
handling inputs with extreme long-range dependencies, as its complexity grows
quadratically with respect to the sequence length. Therefore, long sequences
are often encoded by Transformer in chunks using a sliding window. In this
paper, we propose Cluster-Former, a novel clustering-based sparse Transformer
to perform attention across chunked sequences. The proposed framework is
pivoted on two unique types of Transformer layer: Sliding-Window Layer and
Cluster-Former Layer, which encode local sequence information and global
context jointly and iteratively. This new design allows information integration
beyond local windows, which is especially beneficial for question answering
(QA) tasks that rely on long-range dependencies. Experiments show that
Cluster-Former achieves state-of-the-art performance on several major QA
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-Fine Entity Representations for Document-level Relation Extraction. (arXiv:2012.02507v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1">Damai Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jing Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1">Shuang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1">Baobao Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1">Zhifang Sui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02507">
                                    <div class="article-summary-box-inner">
                                        <span>Document-level Relation Extraction (RE) requires extracting relations
expressed within and across sentences. Recent works show that graph-based
methods, usually constructing a document-level graph that captures
document-aware interactions, can obtain useful entity representations thus
helping tackle document-level RE. These methods either focus more on the entire
graph, or pay more attention to a part of the graph, e.g., paths between the
target entity pair. However, we find that document-level RE may benefit from
focusing on both of them simultaneously. Therefore, to obtain more
comprehensive entity representations, we propose the Coarse-to-Fine Entity
Representation model (CFER) that adopts a coarse-to-fine strategy involving two
phases. First, CFER uses graph neural networks to integrate global information
in the entire graph at a coarse level. Next, CFER utilizes the global
information as a guidance to selectively aggregate path information between the
target entity pair at a fine level. In classification, we combine the entity
representations from both two levels into more comprehensive representations
for relation extraction. Experimental results on two document-level RE
datasets, DocRED and CDR, show that CFER outperforms existing models and is
robust to the uneven label distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intent Classification and Slot Filling for Privacy Policies. (arXiv:2101.00123v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1">Wasi Uddin Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_J/0/1/0/all/0/1">Jianfeng Chi</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1">Tu Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Norton_T/0/1/0/all/0/1">Thomas Norton</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuan Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00123">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding privacy policies is crucial for users as it empowers them to
learn about the information that matters to them. Sentences written in a
privacy policy document explain privacy practices, and the constituent text
spans convey further specific information about that practice. We refer to
predicting the privacy practice explained in a sentence as intent
classification and identifying the text spans sharing specific information as
slot filling. In this work, we propose PolicyIE, an English corpus consisting
of 5,250 intent and 11,788 slot annotations spanning 31 privacy policies of
websites and mobile applications. PolicyIE corpus is a challenging real-world
benchmark with limited labeled examples reflecting the cost of collecting
large-scale annotations from domain experts. We present two alternative neural
approaches as baselines, (1) intent classification and slot filling as a joint
sequence tagging and (2) modeling them as a sequence-to-sequence (Seq2Seq)
learning task. The experiment results show that both approaches perform
comparably in intent classification, while the Seq2Seq method outperforms the
sequence tagging approach in slot filling by a large margin. We perform a
detailed error analysis to reveal the challenges of the proposed corpus.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Open-Ended Commonsense Reasoning. (arXiv:2010.14439v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bill Yuchen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haitian Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1">Bhuwan Dhingra</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1">Manzil Zaheer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1">William W. Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14439">
                                    <div class="article-summary-box-inner">
                                        <span>Current commonsense reasoning research focuses on developing models that use
commonsense knowledge to answer multiple-choice questions. However, systems
designed to answer multiple-choice questions may not be useful in applications
that do not provide a small list of candidate answers to choose from. As a step
towards making commonsense reasoning research more realistic, we propose to
study open-ended commonsense reasoning (OpenCSR) -- the task of answering a
commonsense question without any pre-defined choices -- using as a resource
only a corpus of commonsense facts written in natural language. OpenCSR is
challenging due to a large decision space, and because many questions require
implicit multi-hop reasoning. As an approach to OpenCSR, we propose DrFact, an
efficient Differentiable model for multi-hop Reasoning over knowledge Facts. To
evaluate OpenCSR methods, we adapt several popular commonsense reasoning
benchmarks, and collect multiple new answers for each test question via
crowd-sourcing. Experiments show that DrFact outperforms strong baseline
methods by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeuralLog: Natural Language Inference with Joint Neural and Logical Reasoning. (arXiv:2105.14167v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zeming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qiyue Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Moss_L/0/1/0/all/0/1">Lawrence S. Moss</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14167">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning (DL) based language models achieve high performance on various
benchmarks for Natural Language Inference (NLI). And at this time, symbolic
approaches to NLI are receiving less attention. Both approaches (symbolic and
DL) have their advantages and weaknesses. However, currently, no method
combines them in a system to solve the task of NLI. To merge symbolic and deep
learning methods, we propose an inference framework called NeuralLog, which
utilizes both a monotonicity-based logical inference engine and a neural
network language model for phrase alignment. Our framework models the NLI task
as a classic search problem and uses the beam search algorithm to search for
optimal inference paths. Experiments show that our joint logic and neural
inference system improves accuracy on the NLI task and can achieve state-of-art
accuracy on the SICK and MED datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Story Generation on Plural Images. (arXiv:2001.10980v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.10980">
                                    <div class="article-summary-box-inner">
                                        <span>Traditionally, text generation models take in a sequence of text as input,
and iteratively generate the next most probable word using pre-trained
parameters. In this work, we propose the architecture to use images instead of
text as the input of the text generation model, called StoryGen. In the
architecture, we design a Relational Text Data Generator algorithm that relates
different features from multiple images. The output samples from the model
demonstrate the ability to generate meaningful paragraphs of text containing
the extracted features from the input images. This is an undergraduate project
report. Completed Dec. 2019 at the Cooper Union.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Task Adaptation using Natural Language. (arXiv:2106.02972v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1">Prasoon Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1">Raymond J. Mooney</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02972">
                                    <div class="article-summary-box-inner">
                                        <span>Imitation learning and instruction-following are two common approaches to
communicate a user&#x27;s intent to a learning agent. However, as the complexity of
tasks grows, it could be beneficial to use both demonstrations and language to
communicate with an agent. In this work, we propose a novel setting where an
agent is given both a demonstration and a description, and must combine
information from both the modalities. Specifically, given a demonstration for a
task (the source task), and a natural language description of the differences
between the demonstrated task and a related but different task (the target
task), our goal is to train an agent to complete the target task in a zero-shot
setting, that is, without any demonstrations for the target task. To this end,
we introduce Language-Aided Reward and Value Adaptation (LARVA) which, given a
source demonstration and a linguistic description of how the target task
differs, learns to output a reward / value function that accurately describes
the target task. Our experiments show that on a diverse set of adaptations, our
approach is able to complete more than 95% of target tasks when using
template-based descriptions, and more than 70% when using free-form natural
language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Table2Charts: Recommending Charts by Learning Shared Table Representations. (arXiv:2008.11015v3 [cs.DB] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mengyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qingtao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xinyi He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuejiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yibo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1">Wei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Shi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yining Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Daxin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dongmei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11015">
                                    <div class="article-summary-box-inner">
                                        <span>It is common for people to create different types of charts to explore a
multi-dimensional dataset (table). However, to recommend commonly composed
charts in real world, one should take the challenges of efficiency, imbalanced
data and table context into consideration. In this paper, we propose
Table2Charts framework which learns common patterns from a large corpus of
(table, charts) pairs. Based on deep Q-learning with copying mechanism and
heuristic searching, Table2Charts does table-to-sequence generation, where each
sequence follows a chart template. On a large spreadsheet corpus with 165k
tables and 266k charts, we show that Table2Charts could learn a shared
representation of table fields so that recommendation tasks on different chart
types could mutually enhance each other. Table2Charts outperforms other chart
recommendation systems in both multi-type task (with doubled recall numbers
R@3&#x3D;0.61 and R@1&#x3D;0.43) and human evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. (arXiv:2103.09593v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Samson Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1">Shafiq Joty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09593">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual models have demonstrated impressive cross-lingual transfer
performance. However, test sets like XNLI are monolingual at the example level.
In multilingual communities, it is common for polyglots to code-mix when
conversing with each other. Inspired by this phenomenon, we present two strong
black-box adversarial attacks (one word-level, one phrase-level) for
multilingual models that push their ability to handle code-mixed sentences to
the limit. The former uses bilingual dictionaries to propose perturbations and
translations of the clean example for sense disambiguation. The latter directly
aligns the clean example with its translations before extracting phrases as
perturbations. Our phrase-level attack has a success rate of 89.75% against
XLM-R-large, bringing its average accuracy of 79.85 down to 8.18 on XNLI.
Finally, we propose an efficient adversarial training scheme that trains in the
same number of steps as the original model and show that it improves model
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Challenges in Information-Seeking QA: Unanswerable Questions and Paragraph Retrieval. (arXiv:2010.11915v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1">Akari Asai</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1">Eunsol Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11915">
                                    <div class="article-summary-box-inner">
                                        <span>Recent pretrained language models &quot;solved&quot; many reading comprehension
benchmarks, where questions are written with access to the evidence document.
However, datasets containing information-seeking queries where evidence
documents are provided after the queries are written independently remain
challenging. We analyze why answering information-seeking queries is more
challenging and where their prevalent unanswerabilities arise, on Natural
Questions and TyDi QA. Our controlled experiments suggest two headrooms --
paragraph selection and answerability prediction, i.e. whether the paired
evidence document contains the answer to the query or not. When provided with a
gold paragraph and knowing when to abstain from answering, existing models
easily outperform a human annotator. However, predicting answerability itself
remains challenging. We manually annotate 800 unanswerable examples across six
languages on what makes them challenging to answer. With this new data, we
conduct per-category answerability prediction, revealing issues in the current
dataset collection as well as task formulation. Together, our study points to
avenues for future research in information-seeking question answering, both for
dataset creation and model development.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MagicPai at SemEval-2021 Task 7: Method for Detecting and Rating Humor Based on Multi-Task Adversarial Training. (arXiv:2104.10336v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jian Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1">Shuyi Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haiqin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1">Lianxin Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mengyuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruan_X/0/1/0/all/0/1">Xiaoyi Ruan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mo_Y/0/1/0/all/0/1">Yang Mo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10336">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes MagicPai&#x27;s system for SemEval 2021 Task 7, HaHackathon:
Detecting and Rating Humor and Offense. This task aims to detect whether the
text is humorous and how humorous it is. There are four subtasks in the
competition. In this paper, we mainly present our solution, a multi-task
learning model based on adversarial examples, for task 1a and 1b. More
specifically, we first vectorize the cleaned dataset and add the perturbation
to obtain more robust embedding representations. We then correct the loss via
the confidence level. Finally, we perform interactive joint learning on
multiple tasks to capture the relationship between whether the text is humorous
and how humorous it is. The final result shows the effectiveness of our system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-hop Question Answering via Reasoning Chains. (arXiv:1910.02610v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jifan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Shih-ting Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1">Greg Durrett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.02610">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-hop question answering requires models to gather information from
different parts of a text to answer a question. Most current approaches learn
to address this task in an end-to-end way with neural networks, without
maintaining an explicit representation of the reasoning process. We propose a
method to extract a discrete reasoning chain over the text, which consists of a
series of sentences leading to the answer. We then feed the extracted chains to
a BERT-based QA model to do final answer prediction. Critically, we do not rely
on gold annotated chains or &quot;supporting facts:&quot; at training time, we derive
pseudogold reasoning chains using heuristics based on named entity recognition
and coreference resolution. Nor do we rely on these annotations at test time,
as our model learns to extract chains from raw text alone. We test our approach
on two recently proposed large multi-hop question answering datasets: WikiHop
and HotpotQA, and achieve state-of-art performance on WikiHop and strong
performance on HotpotQA. Our analysis shows the properties of chains that are
crucial for high performance: in particular, modeling extraction sequentially
is important, as is dealing with each candidate sentence in a context-aware
way. Furthermore, human evaluation shows that our extracted chains allow humans
to give answers with high confidence, indicating that these are a strong
intermediate abstraction for this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Step Inference for Reasoning Over Paragraphs. (arXiv:2004.02995v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiangming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gardner_M/0/1/0/all/0/1">Matt Gardner</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_S/0/1/0/all/0/1">Shay B. Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lapata_M/0/1/0/all/0/1">Mirella Lapata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.02995">
                                    <div class="article-summary-box-inner">
                                        <span>Complex reasoning over text requires understanding and chaining together
free-form predicates and logical connectives. Prior work has largely tried to
do this either symbolically or with black-box transformers. We present a middle
ground between these two extremes: a compositional model reminiscent of neural
module networks that can perform chained logical reasoning. This model first
finds relevant sentences in the context and then chains them together using
neural modules. Our model gives significant performance improvements (up to
29\% relative error reduction when comfibined with a reranker) on ROPES, a
recently introduced complex reasoning dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GO FIGURE: A Meta Evaluation of Factuality in Summarization. (arXiv:2010.12834v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gabriel_S/0/1/0/all/0/1">Saadia Gabriel</a>, <a href="http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1">Asli Celikyilmaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Jha_R/0/1/0/all/0/1">Rahul Jha</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12834">
                                    <div class="article-summary-box-inner">
                                        <span>While neural language models can generate text with remarkable fluency and
coherence, controlling for factual correctness in generation remains an open
research question. This major discrepancy between the surface-level fluency and
the content-level correctness of neural generation has motivated a new line of
research that seeks automatic metrics for evaluating the factuality of machine
text. In this paper, we introduce GO FIGURE, a meta-evaluation framework for
evaluating factuality evaluation metrics. We propose five necessary and
intuitive conditions to evaluate factuality metrics on diagnostic factuality
data across three different summarization tasks. Our benchmark analysis on ten
factuality metrics reveals that our meta-evaluation framework provides a robust
and efficient evaluation that is extensible to multiple types of factual
consistency and standard generation metrics, including QA metrics. It also
reveals that while QA metrics generally improve over standard metrics that
measure factuality across domains, performance is highly dependent on the way
in which questions are generated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lookup-Table Recurrent Language Models for Long Tail Speech Recognition. (arXiv:2104.04552v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">W. Ronny Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1">Tara N. Sainath</a>, <a href="http://arxiv.org/find/cs/1/au:+Peyser_C/0/1/0/all/0/1">Cal Peyser</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Shankar Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rybach_D/0/1/0/all/0/1">David Rybach</a>, <a href="http://arxiv.org/find/cs/1/au:+Strohman_T/0/1/0/all/0/1">Trevor Strohman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.04552">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Lookup-Table Language Models (LookupLM), a method for scaling up
the size of RNN language models with only a constant increase in the floating
point operations, by increasing the expressivity of the embedding table. In
particular, we instantiate an (additional) embedding table which embeds the
previous n-gram token sequence, rather than a single token. This allows the
embedding table to be scaled up arbitrarily -- with a commensurate increase in
performance -- without changing the token vocabulary. Since embeddings are
sparsely retrieved from the table via a lookup; increasing the size of the
table adds neither extra operations to each forward pass nor extra parameters
that need to be stored on limited GPU/TPU memory. We explore scaling n-gram
embedding tables up to nearly a billion parameters. When trained on a 3-billion
sentence corpus, we find that LookupLM improves long tail log perplexity by
2.44 and long tail WER by 23.4% on a downstream speech recognition task over a
standard RNN language model baseline, an improvement comparable to a scaling up
the baseline by 6.2x the number of floating point operations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Better Robustness by More Coverage: Adversarial Training with Mixup Augmentation for Robust Fine-tuning. (arXiv:2012.15699v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Si_C/0/1/0/all/0/1">Chenglei Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhengyan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1">Fanchao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yasheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15699">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained language models (PLMs) perform poorly under adversarial attacks.
To improve the adversarial robustness, adversarial data augmentation (ADA) has
been widely adopted to cover more search space of adversarial attacks by adding
textual adversarial examples during training. However, the number of
adversarial examples for text augmentation is still extremely insufficient due
to the exponentially large attack search space. In this work, we propose a
simple and effective method to cover a much larger proportion of the attack
search space, called Adversarial and Mixup Data Augmentation (AMDA).
Specifically, AMDA linearly interpolates the representations of pairs of
training samples to form new virtual samples, which are more abundant and
diverse than the discrete text adversarial examples in conventional ADA.
Moreover, to fairly evaluate the robustness of different models, we adopt a
challenging evaluation setup, which generates a new set of adversarial examples
targeting each model. In text classification experiments of BERT and RoBERTa,
AMDA achieves significant robustness gains under two strong adversarial attacks
and alleviates the performance degradation of ADA on the clean data. Our code
is available at: https://github.com/thunlp/MixADA .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global-aware Beam Search for Neural Abstractive Summarization. (arXiv:2009.06891v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Ye Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1">Zixun Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zong_L/0/1/0/all/0/1">Lu Zong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1">Kaizhu Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06891">
                                    <div class="article-summary-box-inner">
                                        <span>This study develops a calibrated beam-based algorithm with global awareness
for neural abstractive summarization, aiming to improve the local optimality
problem of the original beam search in a rigorous way. Specifically, a novel
global protocol is proposed based on the attention distribution to stipulate
how a global optimal hypothesis should attend to the source. A global scoring
function is then developed to regulate beam search to generate summaries in a
more near-global optimal fashion. This novel design enjoys a distinctive
property, i.e. the global attention distribution could be predicted before
inference, enabling stepwise improvements on the beam search through the global
scoring function. Extensive experiments on $9$ datasets show that the
global-aware inference significantly improves state-of-the-art summarization
models even using empirical hyper-parameters. The algorithm is also proven
robust as it remains to generate meaningful texts with corrupted attention
distributions. The codes and a comprehensive set of examples are available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Denoising Word Embeddings by Averaging in a Shared Space. (arXiv:2106.02954v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1">Avi Caciularu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1">Ido Dagan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberger_J/0/1/0/all/0/1">Jacob Goldberger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02954">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new approach for smoothing and improving the quality of word
embeddings. We consider a method of fusing word embeddings that were trained on
the same corpus but with different initializations. We project all the models
to a shared vector space using an efficient implementation of the Generalized
Procrustes Analysis (GPA) procedure, previously used in multilingual word
translation. Our word representation demonstrates consistent improvements over
the raw models as well as their simplistic average, on a range of tasks. As the
new representations are more stable and reliable, there is a noticeable
improvement in rare word evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly-Supervised Methods for Suicide Risk Assessment: Role of Related Domains. (arXiv:2106.02792v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chenghao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yudong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1">Smaranda Muresan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02792">
                                    <div class="article-summary-box-inner">
                                        <span>Social media has become a valuable resource for the study of suicidal
ideation and the assessment of suicide risk. Among social media platforms,
Reddit has emerged as the most promising one due to its anonymity and its focus
on topic-based communities (subreddits) that can be indicative of someone&#x27;s
state of mind or interest regarding mental health disorders such as
r/SuicideWatch, r/Anxiety, r/depression. A challenge for previous work on
suicide risk assessment has been the small amount of labeled data. We propose
an empirical investigation into several classes of weakly-supervised
approaches, and show that using pseudo-labeling based on related issues around
mental health (e.g., anxiety, depression) helps improve model performance for
suicide risk assessment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lifelong Learning of Hate Speech Classification on Social Media. (arXiv:2106.02821v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1">Jing Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+ElSherief_M/0/1/0/all/0/1">Mai ElSherief</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xifeng Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02821">
                                    <div class="article-summary-box-inner">
                                        <span>Existing work on automated hate speech classification assumes that the
dataset is fixed and the classes are pre-defined. However, the amount of data
in social media increases every day, and the hot topics changes rapidly,
requiring the classifiers to be able to continuously adapt to new data without
forgetting the previously learned knowledge. This ability, referred to as
lifelong learning, is crucial for the real-word application of hate speech
classifiers in social media. In this work, we propose lifelong learning of hate
speech classification on social media. To alleviate catastrophic forgetting, we
propose to use Variational Representation Learning (VRL) along with a memory
module based on LB-SOINN (Load-Balancing Self-Organizing Incremental Neural
Network). Experimentally, we show that combining variational representation
learning and the LB-SOINN memory module achieves better performance than the
commonly-used lifelong learning techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MergeDistill: Merging Pre-trained Language Models using Distillation. (arXiv:2106.02834v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khanuja_S/0/1/0/all/0/1">Simran Khanuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1">Melvin Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1">Partha Talukdar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02834">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained multilingual language models (LMs) have achieved state-of-the-art
results in cross-lingual transfer, but they often lead to an inequitable
representation of languages due to limited capacity, skewed pre-training data,
and sub-optimal vocabularies. This has prompted the creation of an ever-growing
pre-trained model universe, where each model is trained on large amounts of
language or domain specific data with a carefully curated, linguistically
informed vocabulary. However, doing so brings us back full circle and prevents
one from leveraging the benefits of multilinguality. To address the gaps at
both ends of the spectrum, we propose MergeDistill, a framework to merge
pre-trained LMs in a way that can best leverage their assets with minimal
dependencies, using task-agnostic knowledge distillation. We demonstrate the
applicability of our framework in a practical setting by leveraging
pre-existing teacher LMs and training student LMs that perform competitively
with or even outperform teacher LMs trained on several orders of magnitude more
data and with a fixed model capacity. We also highlight the importance of
teacher selection and its impact on student model performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MultiOpEd: A Corpus of Multi-Perspective News Editorials. (arXiv:2106.02725v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Sihao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Uyttendaele_X/0/1/0/all/0/1">Xander Uyttendaele</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1">Dan Roth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02725">
                                    <div class="article-summary-box-inner">
                                        <span>We propose MultiOpEd, an open-domain news editorial corpus that supports
various tasks pertaining to the argumentation structure in news editorials,
focusing on automatic perspective discovery. News editorial is a genre of
persuasive text, where the argumentation structure is usually implicit.
However, the arguments presented in an editorial typically center around a
concise, focused thesis, which we refer to as their perspective. MultiOpEd aims
at supporting the study of multiple tasks relevant to automatic perspective
discovery, where a system is expected to produce a single-sentence thesis
statement summarizing the arguments presented. We argue that identifying and
abstracting such natural language perspectives from editorials is a crucial
step toward studying the implicit argumentation structure in news editorials.
We first discuss the challenges and define a few conceptual tasks towards our
goal. To demonstrate the utility of MultiOpEd and the induced tasks, we study
the problem of perspective summarization in a multi-task learning setting, as a
case study. We show that, with the induced tasks as auxiliary tasks, we can
improve the quality of the perspective summary generated. We hope that
MultiOpEd will be a useful resource for future studies on argumentation in the
news editorial domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings. (arXiv:2106.02736v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goyal_K/0/1/0/all/0/1">Kartik Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1">Chris Dyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1">Taylor Berg-Kirkpatrick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02736">
                                    <div class="article-summary-box-inner">
                                        <span>While recent work has shown that scores from models trained by the ubiquitous
masked language modeling (MLM) objective effectively discriminate probable and
improbable sequences, it is still an open question if these MLMs specify a
principled probability distribution over the space of possible sequences. In
this paper, we interpret MLMs as energy-based sequence models and propose two
energy parametrizations derivable from the trained MLMs. In order to draw
samples correctly from these models, we develop a tractable \emph{sampling}
scheme based on the Metropolis--Hastings Monte Carlo algorithm. In our
approach, samples are proposed from the same masked conditionals used for
training the masked language models, and they are accepted or rejected based on
their energy values according to the target distribution. We validate the
effectiveness of the proposed parametrizations by exploring the quality of
samples drawn from these energy-based models on the conditional generation task
of machine translation. We theoretically and empirically justify our sampling
algorithm by showing that the masked conditionals on their own do not yield a
Markov chain whose stationary distribution is that of our target distribution,
and our approach generates higher quality samples than other recently proposed
undirected generation approaches (Wang et al., 2019, Ghazvininejad et al.,
2019).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Emergent Communication of Generalizations. (arXiv:2106.02668v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1">Jesse Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1">Noah Goodman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02668">
                                    <div class="article-summary-box-inner">
                                        <span>To build agents that can collaborate effectively with others, recent research
has trained artificial agents to communicate with each other in Lewis-style
referential games. However, this often leads to successful but uninterpretable
communication. We argue that this is due to the game objective: communicating
about a single object in a shared visual context is prone to overfitting and
does not encourage language useful beyond concrete reference. In contrast,
human language conveys a rich variety of abstract ideas. To promote such
skills, we propose games that require communicating generalizations over sets
of objects representing abstract visual concepts, optionally with separate
contexts for each agent. We find that these games greatly improve systematicity
and interpretability of the learned languages, according to several metrics in
the literature. Finally, we propose a method for identifying logical operations
embedded in the emergent languages by learning an approximate compositional
reconstruction of the language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Layered gradient accumulation and modular pipeline parallelism: fast and efficient training of large language models. (arXiv:2106.02679v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lamy_Poirier_J/0/1/0/all/0/1">Joel Lamy-Poirier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02679">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of the transformer has sparked a quick growth in the size of
language models, far outpacing hardware improvements. (Dense) transformers are
expected to reach the trillion-parameter scale in the near future, for which
training requires thousands or even tens of thousands of GPUs. We investigate
the challenges of training at this scale and beyond on commercially available
hardware. In particular, we analyse the shortest possible training time for
different configurations of distributed training, leveraging empirical scaling
laws for language models to estimate the optimal (critical) batch size.
Contrary to popular belief, we find no evidence for a memory wall, and instead
argue that the real limitation -- other than the cost -- lies in the training
duration.

In addition to this analysis, we introduce two new methods, \textit{layered
gradient accumulation} and \textit{modular pipeline parallelism}, which
together cut the shortest training time by half. The methods also reduce data
movement, lowering the network requirement to a point where a fast InfiniBand
connection is not necessary. This increased network efficiency also improve on
the methods introduced with the ZeRO optimizer, reducing the memory usage to a
tiny fraction of the available GPU memory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Look Wide and Interpret Twice: Improving Performance on Interactive Instruction-following Tasks. (arXiv:2106.00596v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Van-Quang Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Suganuma_M/0/1/0/all/0/1">Masanori Suganuma</a>, <a href="http://arxiv.org/find/cs/1/au:+Okatani_T/0/1/0/all/0/1">Takayuki Okatani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00596">
                                    <div class="article-summary-box-inner">
                                        <span>There is a growing interest in the community in making an embodied AI agent
perform a complicated task while interacting with an environment following
natural language directives. Recent studies have tackled the problem using
ALFRED, a well-designed dataset for the task, but achieved only very low
accuracy. This paper proposes a new method, which outperforms the previous
methods by a large margin. It is based on a combination of several new ideas.
One is a two-stage interpretation of the provided instructions. The method
first selects and interprets an instruction without using visual information,
yielding a tentative action sequence prediction. It then integrates the
prediction with the visual information etc., yielding the final prediction of
an action and an object. As the object&#x27;s class to interact is identified in the
first stage, it can accurately select the correct object from the input image.
Moreover, our method considers multiple egocentric views of the environment and
extracts essential information by applying hierarchical attention conditioned
on the current instruction. This contributes to the accurate prediction of
actions for navigation. A preliminary version of the method won the ALFRED
Challenge 2020. The current version achieves the unseen environment&#x27;s success
rate of 4.45% with a single view, which is further improved to 8.37% with
multiple views.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-grained Angular Contrastive Learning with Coarse Labels. (arXiv:2012.03515v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bukchin_G/0/1/0/all/0/1">Guy Bukchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartz_E/0/1/0/all/0/1">Eli Schwartz</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Shahar_O/0/1/0/all/0/1">Ori Shahar</a>, <a href="http://arxiv.org/find/cs/1/au:+Feris_R/0/1/0/all/0/1">Rogerio Feris</a>, <a href="http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1">Raja Giryes</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlinsky_L/0/1/0/all/0/1">Leonid Karlinsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03515">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning methods offer pre-training techniques optimized for easier
later adaptation of the model to new classes (unseen during training) using one
or a few examples. This adaptivity to unseen classes is especially important
for many practical applications where the pre-trained label space cannot remain
fixed for effective use and the model needs to be &quot;specialized&quot; to support new
categories on the fly. One particularly interesting scenario, essentially
overlooked by the few-shot literature, is Coarse-to-Fine Few-Shot (C2FS), where
the training classes (e.g. animals) are of much &#x60;coarser granularity&#x27; than the
target (test) classes (e.g. breeds). A very practical example of C2FS is when
the target classes are sub-classes of the training classes. Intuitively, it is
especially challenging as (both regular and few-shot) supervised pre-training
tends to learn to ignore intra-class variability which is essential for
separating sub-classes. In this paper, we introduce a novel &#x27;Angular
normalization&#x27; module that allows to effectively combine supervised and
self-supervised contrastive pre-training to approach the proposed C2FS task,
demonstrating significant gains in a broad study over multiple baselines and
datasets. We hope that this work will help to pave the way for future research
on this new, challenging, and very practical topic of C2FS classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manipulating SGD with Data Ordering Attacks. (arXiv:2104.09667v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1">Ilia Shumailov</a>, <a href="http://arxiv.org/find/cs/1/au:+Shumaylov_Z/0/1/0/all/0/1">Zakhar Shumaylov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazhdan_D/0/1/0/all/0/1">Dmitry Kazhdan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yiren Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1">Nicolas Papernot</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdogdu_M/0/1/0/all/0/1">Murat A. Erdogdu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_R/0/1/0/all/0/1">Ross Anderson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09667">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning is vulnerable to a wide variety of attacks. It is now well
understood that by changing the underlying data distribution, an adversary can
poison the model trained with it or introduce backdoors. In this paper we
present a novel class of training-time attacks that require no changes to the
underlying dataset or model architecture, but instead only change the order in
which data are supplied to the model. In particular, we find that the attacker
can either prevent the model from learning, or poison it to learn behaviours
specified by the attacker. Furthermore, we find that even a single
adversarially-ordered epoch can be enough to slow down model learning, or even
to reset all of the learning progress. Indeed, the attacks presented here are
not specific to the model or dataset, but rather target the stochastic nature
of modern learning procedures. We extensively evaluate our attacks on computer
vision and natural language benchmarks to find that the adversary can disrupt
model training and even introduce backdoors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Points2Polygons: Context-Based Segmentation from Weak Labels Using Adversarial Networks. (arXiv:2106.02804v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1">Kuai Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_H/0/1/0/all/0/1">Hakeem Frank</a>, <a href="http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1">Daniel Wilson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02804">
                                    <div class="article-summary-box-inner">
                                        <span>In applied image segmentation tasks, the ability to provide numerous and
precise labels for training is paramount to the accuracy of the model at
inference time. However, this overhead is often neglected, and recently
proposed segmentation architectures rely heavily on the availability and
fidelity of ground truth labels to achieve state-of-the-art accuracies. Failure
to acknowledge the difficulty in creating adequate ground truths can lead to an
over-reliance on pre-trained models or a lack of adoption in real-world
applications. We introduce Points2Polygons (P2P), a model which makes use of
contextual metric learning techniques that directly addresses this problem.
Points2Polygons performs well against existing fully-supervised segmentation
baselines with limited training data, despite using lightweight segmentation
models (U-Net with a ResNet18 backbone) and having access to only weak labels
in the form of object centroids and no pre-training. We demonstrate this on
several different small but non-trivial datasets. We show that metric learning
using contextual data provides key insights for self-supervised tasks in
general, and allow segmentation models to easily generalize across
traditionally label-intensive domains in computer vision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Classification of Very Large Images with Tiny Objects. (arXiv:2106.02694v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1">Fanjie Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1">Ricardo Henao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02694">
                                    <div class="article-summary-box-inner">
                                        <span>An increasing number of applications in the computer vision domain,
specially, in medical imaging and remote sensing, are challenging when the goal
is to classify very large images with tiny objects. More specifically, these
type of classification tasks face two key challenges: $i$) the size of the
input image in the target dataset is usually in the order of megapixels,
however, existing deep architectures do not easily operate on such big images
due to memory constraints, consequently, we seek a memory-efficient method to
process these images; and $ii$) only a small fraction of the input images are
informative of the label of interest, resulting in low region of interest (ROI)
to image ratio. However, most of the current convolutional neural networks
(CNNs) are designed for image classification datasets that have relatively
large ROIs and small image size (sub-megapixel). Existing approaches have
addressed these two challenges in isolation. We present an end-to-end CNN model
termed Zoom-In network that leverages hierarchical attention sampling for
classification of large images with tiny objects using a single GPU. We
evaluate our method on two large-image datasets and one gigapixel dataset.
Experimental results show that our model achieves higher accuracy than existing
methods while requiring less computing resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Supercharging Imbalanced Data Learning With Energy-based Contrastive Representation Transfer. (arXiv:2011.12454v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiu_Z/0/1/0/all/0/1">Zidi Xiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Junya Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1">Ricardo Henao</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_B/0/1/0/all/0/1">Benjamin Goldstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1">Lawrence Carin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1">Chenyang Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.12454">
                                    <div class="article-summary-box-inner">
                                        <span>Dealing with severe class imbalance poses a major challenge for real-world
applications, especially when the accurate classification and generalization of
minority classes is of primary interest. In computer vision, learning from long
tailed datasets is a recurring theme, especially for natural image datasets.
While existing solutions mostly appeal to sampling or weighting adjustments to
alleviate the pathological imbalance, or imposing inductive bias to prioritize
non-spurious associations, we take novel perspectives to promote sample
efficiency and model generalization based on the invariance principles of
causality. Our proposal posits a meta-distributional scenario, where the data
generating mechanism is invariant across the label-conditional feature
distributions. Such causal assumption enables efficient knowledge transfer from
the dominant classes to their under-represented counterparts, even if the
respective feature distributions show apparent disparities. This allows us to
leverage a causal data inflation procedure to enlarge the representation of
minority classes. Our development is orthogonal to the existing extreme
classification techniques thus can be seamlessly integrated. The utility of our
proposal is validated with an extensive set of synthetic and real-world
computer vision tasks against SOTA solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AOSLO-net: A deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscope images. (arXiv:2106.02800v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_Q/0/1/0/all/0/1">Qian Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Sampani_K/0/1/0/all/0/1">Konstantina Sampani</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1">Mengjia Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Cai_S/0/1/0/all/0/1">Shengze Cai</a>, <a href="http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1">Yixiang Deng</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">He Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Jennifer K. Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Karniadakis_G/0/1/0/all/0/1">George Em Karniadakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02800">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptive optics scanning laser ophthalmoscopy (AOSLO) provides real-time
retinal images with high resolution down to 2 $\mu m$. This technique enables
detection of the morphologies of individual microaneurysms (MAs), which are one
of the earliest signs of diabetic retinopathy (DR), a frequent complication of
diabetes that can lead to visual impairment and blindness. In contrast to
previous automatic models developed for MA detection on standard fundus
photographs, currently there is no high throughput image protocol available for
automatic analysis of AOSLO photographs. To address this urgency, we introduce
AOSLO-net, a deep neural network framework with customized training policy,
including preprocessing, data augmentation and transfer learning, to
automatically segment MAs from AOSLO images. We evaluate the performance of
AOSLO-net using 87 DR AOSLO images demonstrating very accurate MA detection and
segmentation, leading to correct MA morphological classification, while
outperforming the state-of-the-art both in accuracy and cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TinyTL: Reduce Activations, Not Trainable Parameters for Efficient On-Device Learning. (arXiv:2007.11622v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Han Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chuang Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Ligeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Song Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.11622">
                                    <div class="article-summary-box-inner">
                                        <span>On-device learning enables edge devices to continually adapt the AI models to
new data, which requires a small memory footprint to fit the tight memory
constraint of edge devices. Existing work solves this problem by reducing the
number of trainable parameters. However, this doesn&#x27;t directly translate to
memory saving since the major bottleneck is the activations, not parameters. In
this work, we present Tiny-Transfer-Learning (TinyTL) for memory-efficient
on-device learning. TinyTL freezes the weights while only learns the bias
modules, thus no need to store the intermediate activations. To maintain the
adaptation capacity, we introduce a new memory-efficient bias module, the lite
residual module, to refine the feature extractor by learning small residual
feature maps adding only 3.8% memory overhead. Extensive experiments show that
TinyTL significantly saves the memory (up to 6.5x) with little accuracy loss
compared to fine-tuning the full network. Compared to fine-tuning the last
layer, TinyTL provides significant accuracy improvements (up to 34.1%) with
little memory overhead. Furthermore, combined with feature extractor
adaptation, TinyTL provides 7.3-12.9x memory saving without sacrificing
accuracy compared to fine-tuning the full Inception-V3.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy. (arXiv:2104.09435v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hyoungjun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Na_M/0/1/0/all/0/1">Myeongsu Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Bumju Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Soohyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Ki Hean Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Sunghoe Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jong Chul Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09435">
                                    <div class="article-summary-box-inner">
                                        <span>Volumetric imaging by fluorescence microscopy is often limited by anisotropic
spatial resolution from inferior axial resolution compared to the lateral
resolution. To address this problem, here we present a deep-learning-enabled
unsupervised super-resolution technique that enhances anisotropic images in
volumetric fluorescence microscopy. In contrast to the existing deep learning
approaches that require matched high-resolution target volume images, our
method greatly reduces the effort to put into practice as the training of a
network requires as little as a single 3D image stack, without a priori
knowledge of the image formation process, registration of training data, or
separate acquisition of target data. This is achieved based on the optimal
transport driven cycle-consistent generative adversarial network that learns
from an unpaired matching between high-resolution 2D images in lateral image
plane and low-resolution 2D images in the other planes. Using fluorescence
confocal microscopy and light-sheet microscopy, we demonstrate that the trained
network not only enhances axial resolution, but also restores suppressed visual
details between the imaging planes and removes imaging artifacts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GPSfM: Global Projective SFM Using Algebraic Constraints on Multi-View Fundamental Matrices. (arXiv:1812.00426v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kasten_Y/0/1/0/all/0/1">Yoni Kasten</a>, <a href="http://arxiv.org/find/cs/1/au:+Geifman_A/0/1/0/all/0/1">Amnon Geifman</a>, <a href="http://arxiv.org/find/cs/1/au:+Galun_M/0/1/0/all/0/1">Meirav Galun</a>, <a href="http://arxiv.org/find/cs/1/au:+Basri_R/0/1/0/all/0/1">Ronen Basri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1812.00426">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of recovering projective camera matrices
from collections of fundamental matrices in multiview settings. We make two
main contributions. First, given ${n \choose 2}$ fundamental matrices computed
for $n$ images, we provide a complete algebraic characterization in the form of
conditions that are both necessary and sufficient to enabling the recovery of
camera matrices. These conditions are based on arranging the fundamental
matrices as blocks in a single matrix, called the $n$-view fundamental matrix,
and characterizing this matrix in terms of the signs of its eigenvalues and
rank structures. Secondly, we propose a concrete algorithm for projective
structure-from-motion that utilizes this characterization. Given a complete or
partial collection of measured fundamental matrices, our method seeks camera
matrices that minimize a global algebraic error for the measured fundamental
matrices. In contrast to existing methods, our optimization, without any
initialization, produces a consistent set of fundamental matrices that
corresponds to a unique set of cameras (up to a choice of projective frame).
Our experiments indicate that our method achieves state of the art performance
in both accuracy and running time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IPS300+: a Challenging Multimodal Dataset for Intersection Perception System. (arXiv:2106.02781v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huanan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xinyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhiwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Lei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1">Shuyue Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Y/0/1/0/all/0/1">Yongqiang Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02781">
                                    <div class="article-summary-box-inner">
                                        <span>Due to the high complexity and occlusion, insufficient perception in the
crowded urban intersection can be a serious safety risk for both human drivers
and autonomous algorithms, whereas CVIS (Cooperative Vehicle Infrastructure
System) is a proposed solution for full-participants perception in this
scenario. However, the research on roadside multimodal perception is still in
its infancy, and there is no open-source dataset for such scenario.
Accordingly, this paper fills the gap. Through an IPS (Intersection Perception
System) installed at the diagonal of the intersection, this paper proposes a
high-quality multimodal dataset for the intersection perception task. The
center of the experimental intersection covers an area of 3000m2, and the
extended distance reaches 300m, which is typical for CVIS. The first batch of
open-source data includes 14198 frames, and each frame has an average of 319.84
labels, which is 9.6 times larger than the most crowded dataset (H3D dataset in
2019) by now. In order to facilitate further study, this dataset tries to keep
the label documents consistent with the KITTI dataset, and a standardized
benchmark is created for algorithm evaluation. Our dataset is available at:
this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Discovery, Control, and Disentanglement of Semantic Attributes with Applications to Anomaly Detection. (arXiv:2002.11169v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1">William Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_I/0/1/0/all/0/1">I-Jeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1">Fady Alajaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1">Philippe Burlina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.11169">
                                    <div class="article-summary-box-inner">
                                        <span>Our work focuses on unsupervised and generative methods that address the
following goals: (a) learning unsupervised generative representations that
discover latent factors controlling image semantic attributes, (b) studying how
this ability to control attributes formally relates to the issue of latent
factor disentanglement, clarifying related but dissimilar concepts that had
been confounded in the past, and (c) developing anomaly detection methods that
leverage representations learned in (a). For (a), we propose a network
architecture that exploits the combination of multiscale generative models with
mutual information (MI) maximization. For (b), we derive an analytical result
(Lemma 1) that brings clarity to two related but distinct concepts: the ability
of generative networks to control semantic attributes of images they generate,
resulting from MI maximization, and the ability to disentangle latent space
representations, obtained via total correlation minimization. More
specifically, we demonstrate that maximizing semantic attribute control
encourages disentanglement of latent factors. Using Lemma 1 and adopting MI in
our loss function, we then show empirically that, for image generation tasks,
the proposed approach exhibits superior performance as measured in the quality
and disentanglement trade space, when compared to other state of the art
methods, with quality assessed via the Frechet Inception Distance (FID), and
disentanglement via mutual information gap. For (c), we design several systems
for anomaly detection exploiting representations learned in (a), and
demonstrate their performance benefits when compared to state-of-the-art
generative and discriminative algorithms. The above contributions in
representation learning have potential applications in addressing other
important problems in computer vision, such as bias and privacy in AI.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual communication of object concepts at different levels of abstraction. (arXiv:2106.02775v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Justin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Judith E. Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02775">
                                    <div class="article-summary-box-inner">
                                        <span>People can produce drawings of specific entities (e.g., Garfield), as well as
general categories (e.g., &quot;cat&quot;). What explains this ability to produce such
varied drawings of even highly familiar object concepts? We hypothesized that
drawing objects at different levels of abstraction depends on both sensory
information and representational goals, such that drawings intended to portray
a recently seen object preserve more detail than those intended to represent a
category. Participants drew objects cued either with a photo or a category
label. For each cue type, half the participants aimed to draw a specific
exemplar; the other half aimed to draw the category. We found that label-cued
category drawings were the most recognizable at the basic level, whereas
photo-cued exemplar drawings were the least recognizable. Together, these
findings highlight the importance of task context for explaining how people use
drawings to communicate visual concepts in different ways.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Replay-based Continual Zero-Shot Learning. (arXiv:2101.08894v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1">Chandan Gautam</a>, <a href="http://arxiv.org/find/cs/1/au:+Parameswaran_S/0/1/0/all/0/1">Sethupathy Parameswaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1">Ashish Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1">Suresh Sundaram</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08894">
                                    <div class="article-summary-box-inner">
                                        <span>Zero-shot learning is a new paradigm to classify objects from classes that
are not available at training time. Zero-shot learning (ZSL) methods have
attracted considerable attention in recent years because of their ability to
classify unseen/novel class examples. Most of the existing approaches on ZSL
works when all the samples from seen classes are available to train the model,
which does not suit real life. In this paper, we tackle this hindrance by
developing a generative replay-based continual ZSL (GRCZSL). The proposed
method endows traditional ZSL to learn from streaming data and acquire new
knowledge without forgetting the previous tasks&#x27; gained experience. We handle
catastrophic forgetting in GRCZSL by replaying the synthetic samples of seen
classes, which have appeared in the earlier tasks. These synthetic samples are
synthesized using the trained conditional variational autoencoder (VAE) over
the immediate past task. Moreover, we only require the current and immediate
previous VAE at any time for training and testing. The proposed GRZSL method is
developed for a single-head setting of continual learning, simulating a
real-world problem setting. In this setting, task identity is given during
training but unavailable during testing. GRCZSL performance is evaluated on
five benchmark datasets for the generalized setup of ZSL with fixed and dynamic
(incremental class) settings of continual learning. The existing class setting
presented recently in the literature is not suitable for a class-incremental
setting. Therefore, this paper proposes a new setting to address this issue.
Experimental results show that the proposed method significantly outperforms
the baseline and the state-of-the-art method and makes it more suitable for
real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Story Generation on Plural Images. (arXiv:2001.10980v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.10980">
                                    <div class="article-summary-box-inner">
                                        <span>Traditionally, text generation models take in a sequence of text as input,
and iteratively generate the next most probable word using pre-trained
parameters. In this work, we propose the architecture to use images instead of
text as the input of the text generation model, called StoryGen. In the
architecture, we design a Relational Text Data Generator algorithm that relates
different features from multiple images. The output samples from the model
demonstrate the ability to generate meaningful paragraphs of text containing
the extracted features from the input images. This is an undergraduate project
report. Completed Dec. 2019 at the Cooper Union.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Flow Regularization: Improving Structured Sparsity in Deep Neural Networks. (arXiv:2106.02914v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yue Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yuan Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Luchan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yang Xiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02914">
                                    <div class="article-summary-box-inner">
                                        <span>Pruning is a model compression method that removes redundant parameters in
deep neural networks (DNNs) while maintaining accuracy. Most available filter
pruning methods require complex treatments such as iterative pruning, features
statistics/ranking, or additional optimization designs in the training process.
In this paper, we propose a simple and effective regularization strategy from a
new perspective of evolution of features, which we call feature flow
regularization (FFR), for improving structured sparsity and filter pruning in
DNNs. Specifically, FFR imposes controls on the gradient and curvature of
feature flow along the neural network, which implicitly increases the sparsity
of the parameters. The principle behind FFR is that coherent and smooth
evolution of features will lead to an efficient network that avoids redundant
parameters. The high structured sparsity obtained from FFR enables us to prune
filters effectively. Experiments with VGGNets, ResNets on CIFAR-10/100, and
Tiny ImageNet datasets demonstrate that FFR can significantly improve both
unstructured and structured sparsity. Our pruning results in terms of reduction
of parameters and FLOPs are comparable to or even better than those of
state-of-the-art pruning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">i3dLoc: Image-to-range Cross-domain Localization Robust to Inconsistent Environmental Conditions. (arXiv:2105.12883v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1">Peng Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lingyun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Ji Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Choset_H/0/1/0/all/0/1">Howie Choset</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1">Sebastian Scherer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12883">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for localizing a single camera with respect to a point
cloud map in indoor and outdoor scenes. The problem is challenging because
correspondences of local invariant features are inconsistent across the domains
between image and 3D. The problem is even more challenging as the method must
handle various environmental conditions such as illumination, weather, and
seasonal changes. Our method can match equirectangular images to the 3D range
projections by extracting cross-domain symmetric place descriptors. Our key
insight is to retain condition-invariant 3D geometry features from limited data
samples while eliminating the condition-related features by a designed
Generative Adversarial Network. Based on such features, we further design a
spherical convolution network to learn viewpoint-invariant symmetric place
descriptors. We evaluate our method on extensive self-collected datasets, which
involve \textit{Long-term} (variant appearance conditions),
\textit{Large-scale} (up to $2km$ structure/unstructured environment), and
\textit{Multistory} (four-floor confined space). Our method surpasses other
current state-of-the-arts by achieving around $3$ times higher place retrievals
to inconsistent environments, and above $3$ times accuracy on online
localization. To highlight our method&#x27;s generalization capabilities, we also
evaluate the recognition across different datasets. With a single trained
model, i3dLoc can demonstrate reliable visual localization in random
conditions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Soft-Attention Improves Skin Cancer Classification Performance. (arXiv:2105.03358v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Datta_S/0/1/0/all/0/1">Soumyya Kanti Datta</a>, <a href="http://arxiv.org/find/eess/1/au:+Shaikh_M/0/1/0/all/0/1">Mohammad Abuzar Shaikh</a>, <a href="http://arxiv.org/find/eess/1/au:+Srihari_S/0/1/0/all/0/1">Sargur N. Srihari</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_M/0/1/0/all/0/1">Mingchen Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03358">
                                    <div class="article-summary-box-inner">
                                        <span>In clinical applications, neural networks must focus on and highlight the
most important parts of an input image. Soft-Attention mechanism enables a
neural network toachieve this goal. This paper investigates the effectiveness
of Soft-Attention in deep neural architectures. The central aim of
Soft-Attention is to boost the value of important features and suppress the
noise-inducing features. We compare the performance of VGG, ResNet,
InceptionResNetv2 and DenseNet architectures with and without the
Soft-Attention mechanism, while classifying skin lesions. The original network
when coupled with Soft-Attention outperforms the baseline[16] by 4.7% while
achieving a precision of 93.7% on HAM10000 dataset [25]. Additionally,
Soft-Attention coupling improves the sensitivity score by 3.8% compared to
baseline[31] and achieves 91.6% on ISIC-2017 dataset [2]. The code is publicly
available at github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Variational Bayesian Framework for Blind Image Deblurring. (arXiv:2106.02884v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1">Hui Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Yue_Z/0/1/0/all/0/1">Zongsheng Yue</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhao_Q/0/1/0/all/0/1">Qian Zhao</a>, <a href="http://arxiv.org/find/eess/1/au:+Meng_D/0/1/0/all/0/1">Deyu Meng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02884">
                                    <div class="article-summary-box-inner">
                                        <span>Blind image deblurring is an important yet very challenging problem in
low-level vision. Traditional optimization based methods generally formulate
this task as a maximum-a-posteriori estimation or variational inference
problem, whose performance highly relies on the handcraft priors for both the
latent image and the blur kernel. In contrast, recent deep learning methods
generally learn, from a large collection of training images, deep neural
networks (DNNs) directly mapping the blurry image to the clean one or to the
blur kernel, paying less attention to the physical degradation process of the
blurry image. In this paper, we present a deep variational Bayesian framework
for blind image deblurring. Under this framework, the posterior of the latent
clean image and blur kernel can be jointly estimated in an amortized inference
fashion with DNNs, and the involved inference DNNs can be trained by fully
considering the physical blur model, together with the supervision of data
driven priors for the clean image and blur kernel, which is naturally led to by
the evidence lower bound objective. Comprehensive experiments are conducted to
substantiate the effectiveness of the proposed framework. The results show that
it can not only achieve a promising performance with relatively simple
networks, but also enhance the performance of existing DNNs for deblurring.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid-Attention Guided Network with Multiple Resolution Features for Person Re-Identification. (arXiv:2009.07536v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guoqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Junchuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yuhui Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yi Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shengyong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07536">
                                    <div class="article-summary-box-inner">
                                        <span>Extracting effective and discriminative features is very important for
addressing the challenging person re-identification (re-ID) task. Prevailing
deep convolutional neural networks (CNNs) usually use high-level features for
identifying pedestrian. However, some essential spatial information resided in
low-level features such as shape, texture and color will be lost when learning
the high-level features, due to extensive padding and pooling operations in the
training stage. In addition, most existing person re-ID methods are mainly
based on hand-craft bounding boxes where images are precisely aligned. It is
unrealistic in practical applications, since the exploited object detection
algorithms often produce inaccurate bounding boxes. This will inevitably
degrade the performance of existing algorithms. To address these problems, we
put forward a novel person re-ID model that fuses high- and low-level
embeddings to reduce the information loss caused in learning high-level
features. Then we divide the fused embedding into several parts and reconnect
them to obtain the global feature and more significant local features, so as to
alleviate the affect caused by the inaccurate bounding boxes. In addition, we
also introduce the spatial and channel attention mechanisms in our model, which
aims to mine more discriminative features related to the target. Finally, we
reconstruct the feature extractor to ensure that our model can obtain more
richer and robust features. Extensive experiments display the superiority of
our approach compared with existing approaches. Our code is available at
https://github.com/libraflower/MutipleFeature-for-PRID.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Web based disease prediction and recommender system. (arXiv:2106.02813v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajora_H/0/1/0/all/0/1">Harish Rajora</a>, <a href="http://arxiv.org/find/cs/1/au:+Punn_N/0/1/0/all/0/1">Narinder Singh Punn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1">Sanjay Kumar Sonbhadra</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sonali Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02813">
                                    <div class="article-summary-box-inner">
                                        <span>Worldwide, several cases go undiagnosed due to poor healthcare support in
remote areas. In this context, a centralized system is needed for effective
monitoring and analysis of the medical records. A web-based patient diagnostic
system is a central platform to store the medical history and predict the
possible disease based on the current symptoms experienced by a patient to
ensure faster and accurate diagnosis. Early disease prediction can help the
users determine the severity of the disease and take quick action. The proposed
web-based disease prediction system utilizes machine learning based
classification techniques on a data set acquired from the National Centre of
Disease Control (NCDC). $K$-nearest neighbor (K-NN), random forest and naive
bayes classification approaches are utilized and an ensemble voting algorithm
is also proposed where each classifier is assigned weights dynamically based on
the prediction confidence. The proposed system is also equipped with a
recommendation scheme to recommend the type of tests based on the existing
symptoms of the patient, so that necessary precautions can be taken. A
centralized database ensures that the medical data is preserved and there is
transparency in the system. The tampering into the system is prevented by
giving the no &quot;updation&quot; rights once the diagnosis is created.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predify: Augmenting deep neural networks with brain-inspired predictive coding dynamics. (arXiv:2106.02749v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choksi_B/0/1/0/all/0/1">Bhavin Choksi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mozafari_M/0/1/0/all/0/1">Milad Mozafari</a>, <a href="http://arxiv.org/find/cs/1/au:+OMay_C/0/1/0/all/0/1">Callum Biggs O&#x27;May</a>, <a href="http://arxiv.org/find/cs/1/au:+Ador_B/0/1/0/all/0/1">Benjamin Ador</a>, <a href="http://arxiv.org/find/cs/1/au:+Alamia_A/0/1/0/all/0/1">Andrea Alamia</a>, <a href="http://arxiv.org/find/cs/1/au:+VanRullen_R/0/1/0/all/0/1">Rufin VanRullen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02749">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks excel at image classification, but their performance is
far less robust to input perturbations than human perception. In this work we
explore whether this shortcoming may be partly addressed by incorporating
brain-inspired recurrent dynamics in deep convolutional networks. We take
inspiration from a popular framework in neuroscience: &#x27;predictive coding&#x27;. At
each layer of the hierarchical model, generative feedback &#x27;predicts&#x27; (i.e.,
reconstructs) the pattern of activity in the previous layer. The reconstruction
errors are used to iteratively update the network&#x27;s representations across
timesteps, and to optimize the network&#x27;s feedback weights over the natural
image dataset-a form of unsupervised training. We show that implementing this
strategy into two popular networks, VGG16 and EfficientNetB0, improves their
robustness against various corruptions. We hypothesize that other feedforward
networks could similarly benefit from the proposed framework. To promote
research in this direction, we provide an open-sourced PyTorch-based package
called Predify, which can be used to implement and investigate the impacts of
the predictive coding dynamics in any convolutional neural network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BalaGAN: Image Translation Between Imbalanced Domains via Cross-Modal Transfer. (arXiv:2010.02036v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Patashnik_O/0/1/0/all/0/1">Or Patashnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Danon_D/0/1/0/all/0/1">Dov Danon</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1">Daniel Cohen-Or</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02036">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art image-to-image translation methods tend to struggle in an
imbalanced domain setting, where one image domain lacks richness and diversity.
We introduce a new unsupervised translation network, BalaGAN, specifically
designed to tackle the domain imbalance problem. We leverage the latent
modalities of the richer domain to turn the image-to-image translation problem,
between two imbalanced domains, into a balanced, multi-class, and conditional
translation problem, more resembling the style transfer setting. Specifically,
we analyze the source domain and learn a decomposition of it into a set of
latent modes or classes, without any supervision. This leaves us with a
multitude of balanced cross-domain translation tasks, between all pairs of
classes, including the target domain. During inference, the trained network
takes as input a source image, as well as a reference or style image from one
of the modes as a condition, and produces an image which resembles the source
on the pixel-wise level, but shares the same mode as the reference. We show
that employing modalities within the dataset improves the quality of the
translated images, and that BalaGAN outperforms strong baselines of both
unconditioned and style-transfer-based image-to-image translation methods, in
terms of image quality and diversity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mutual Information Regularized Identity-aware Facial ExpressionRecognition in Compressed Video. (arXiv:2010.10637v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Linghao Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jane You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10637">
                                    <div class="article-summary-box-inner">
                                        <span>How to extract effective expression representations that invariant to the
identity-specific attributes is a long-lasting problem for facial expression
recognition (FER). Most of the previous methods process the RGB images of a
sequence, while we argue that the off-the-shelf and valuable expression-related
muscle movement is already embedded in the compression format. In this paper,
we target to explore the inter-subject variations eliminated facial expression
representation in the compressed video domain. In the up to two orders of
magnitude compressed domain, we can explicitly infer the expression from the
residual frames and possibly extract identity factors from the I frame with a
pre-trained face recognition network. By enforcing the marginal independence of
them, the expression feature is expected to be purer for the expression and be
robust to identity shifts. Specifically, we propose a novel collaborative
min-min game for mutual information (MI) minimization in latent space. We do
not need the identity label or multiple expression samples from the same person
for identity elimination. Moreover, when the apex frame is annotated in the
dataset, the complementary constraint can be further added to regularize the
feature-level game. In testing, only the compressed residual frames are
required to achieve expression prediction. Our solution can achieve comparable
or better performance than the recent decoded image-based methods on the
typical FER benchmarks with about 3 times faster inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Topology from Synthetic Data for Unsupervised Depth Completion. (arXiv:2106.02994v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alex Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cicek_S/0/1/0/all/0/1">Safa Cicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02994">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for inferring dense depth maps from images and sparse
depth measurements by leveraging synthetic data to learn the association of
sparse point clouds with dense natural shapes, and using the image as evidence
to validate the predicted depth map. Our learned prior for natural shapes uses
only sparse depth as input, not images, so the method is not affected by the
covariate shift when attempting to transfer learned models from synthetic data
to real ones. This allows us to use abundant synthetic data with ground truth
to learn the most difficult component of the reconstruction process, which is
topology estimation, and use the image to refine the prediction based on
photometric evidence. Our approach uses fewer parameters than previous methods,
yet, achieves the state of the art on both indoor and outdoor benchmark
datasets. Code available at:
https://github.com/alexklwong/learning-topology-synthetic-data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">T-Net: Deep Stacked Scale-Iteration Network for Image Dehazing. (arXiv:2106.02809v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1">Lirong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yanshan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaihao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_W/0/1/0/all/0/1">Wenhan Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02809">
                                    <div class="article-summary-box-inner">
                                        <span>Hazy images reduce the visibility of the image content, and haze will lead to
failure in handling subsequent computer vision tasks. In this paper, we address
the problem of image dehazing by proposing a dehazing network named T-Net,
which consists of a backbone network based on the U-Net architecture and a dual
attention module. And it can achieve multi-scale feature fusion by using skip
connections with a new fusion strategy. Furthermore, by repeatedly unfolding
the plain T-Net, Stack T-Net is proposed to take advantage of the dependence of
deep features across stages via a recursive strategy. In order to reduce
network parameters, the intra-stage recursive computation of ResNet is adopted
in our Stack T-Net. And we take both the stage-wise result and the original
hazy image as input to each T-Net and finally output the prediction of clean
image. Experimental results on both synthetic and real-world images demonstrate
that our plain T-Net and the advanced Stack T-Net perform favorably against the
state-of-the-art dehazing algorithms, and show that our Stack T-Net could
further improve the dehazing effect, demonstrating the effectiveness of the
recursive strategy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conv-MPN: Convolutional Message Passing Neural Network for Structured Outdoor Architecture Reconstruction. (arXiv:1912.01756v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fuyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nauata_N/0/1/0/all/0/1">Nelson Nauata</a>, <a href="http://arxiv.org/find/cs/1/au:+Furukawa_Y/0/1/0/all/0/1">Yasutaka Furukawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.01756">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel message passing neural (MPN) architecture
Conv-MPN, which reconstructs an outdoor building as a planar graph from a
single RGB image. Conv-MPN is specifically designed for cases where nodes of a
graph have explicit spatial embedding. In our problem, nodes correspond to
building edges in an image. Conv-MPN is different from MPN in that 1) the
feature associated with a node is represented as a feature volume instead of a
1D vector; and 2) convolutions encode messages instead of fully connected
layers. Conv-MPN learns to select a true subset of nodes (i.e., building edges)
to reconstruct a building planar graph. Our qualitative and quantitative
evaluations over 2,000 buildings show that Conv-MPN makes significant
improvements over the existing fully neural solutions. We believe that the
paper has a potential to open a new line of graph neural network research for
structured geometry reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Relation Alignment for Calibrated Cross-modal Retrieval. (arXiv:2105.13868v2 [cs.CL] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Shuhuai Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Junyang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guangxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1">Rui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">An Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13868">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the achievements of large-scale multimodal pre-training approaches,
cross-modal retrieval, e.g., image-text retrieval, remains a challenging task.
To bridge the semantic gap between the two modalities, previous studies mainly
focus on word-region alignment at the object level, lacking the matching
between the linguistic relation among the words and the visual relation among
the regions. The neglect of such relation consistency impairs the
contextualized representation of image-text pairs and hinders the model
performance and the interpretability. In this paper, we first propose a novel
metric, Intra-modal Self-attention Distance (ISD), to quantify the relation
consistency by measuring the semantic distance between linguistic and visual
relations. In response, we present Inter-modal Alignment on Intra-modal
Self-attentions (IAIS), a regularized training method to optimize the ISD and
calibrate intra-modal self-attentions from the two modalities mutually via
inter-modal alignment. The IAIS regularizer boosts the performance of
prevailing models on Flickr30k and MS COCO datasets by a considerable margin,
which demonstrates the superiority of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Walsh-Hadamard Transform and Smooth-Thresholding Based Binary Layers in Deep Neural Networks. (arXiv:2104.07085v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_H/0/1/0/all/0/1">Hongyi Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Dabawi_D/0/1/0/all/0/1">Diaa Dabawi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cetin_A/0/1/0/all/0/1">Ahmet Enis Cetin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07085">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel layer based on fast Walsh-Hadamard
transform (WHT) and smooth-thresholding to replace $1\times 1$ convolution
layers in deep neural networks. In the WHT domain, we denoise the transform
domain coefficients using the new smooth-thresholding non-linearity, a smoothed
version of the well-known soft-thresholding operator. We also introduce a
family of multiplication-free operators from the basic 2$\times$2 Hadamard
transform to implement $3\times 3$ depthwise separable convolution layers.
Using these two types of layers, we replace the bottleneck layers in
MobileNet-V2 to reduce the network&#x27;s number of parameters with a slight loss in
accuracy. For example, by replacing the final third bottleneck layers, we
reduce the number of parameters from 2.270M to 540K. This reduces the accuracy
from 95.21\% to 92.98\% on the CIFAR-10 dataset. Our approach significantly
improves the speed of data processing. The fast Walsh-Hadamard transform has a
computational complexity of $O(m\log_2 m)$. As a result, it is computationally
more efficient than the $1\times1$ convolution layer. The fast Walsh-Hadamard
layer processes a tensor in $\mathbb{R}^{10\times32\times32\times1024}$ about 2
times faster than $1\times1$ convolution layer on NVIDIA Jetson Nano computer
board.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ClawCraneNet: Leveraging Object-level Relation for Text-based Video Segmentation. (arXiv:2103.10702v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yawei Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10702">
                                    <div class="article-summary-box-inner">
                                        <span>Text-based video segmentation is a challenging task that segments out the
natural language referred objects in videos. It essentially requires semantic
comprehension and fine-grained video understanding. Existing methods introduce
language representation into segmentation models in a bottom-up manner, which
merely conducts vision-language interaction within local receptive fields of
ConvNets. We argue that such interaction is not fulfilled since the model can
barely construct region-level relationships given partial observations, which
is contrary to the description logic of natural language/referring expressions.
In fact, people usually describe a target object using relations with other
objects, which may not be easily understood without seeing the whole video. To
address the issue, we introduce a novel top-down approach by imitating how we
human segment an object with the language guidance. We first figure out all
candidate objects in videos and then choose the refereed one by parsing
relations among those high-level objects. Three kinds of object-level relations
are investigated for precise relationship understanding, i.e., positional
relation, text-guided semantic relation, and temporal relation. Extensive
experiments on A2D Sentences and J-HMDB Sentences show our method outperforms
state-of-the-art methods by a large margin. Qualitative results also show our
results are more explainable. Besides, based on the inspiration, we win the
first place in CVPR2021 Referring Youtube-VOS challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast and High-Quality Blind Multi-Spectral Image Pansharpening. (arXiv:2103.09943v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Lantao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Dehong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_H/0/1/0/all/0/1">Hassan Mansour</a>, <a href="http://arxiv.org/find/cs/1/au:+Boufounos_P/0/1/0/all/0/1">Petros T. Boufounos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09943">
                                    <div class="article-summary-box-inner">
                                        <span>Blind pansharpening addresses the problem of generating a high
spatial-resolution multi-spectral (HRMS) image given a low spatial-resolution
multi-spectral (LRMS) image with the guidance of its associated spatially
misaligned high spatial-resolution panchromatic (PAN) image without parametric
side information. In this paper, we propose a fast approach to blind
pansharpening and achieve state-of-the-art image reconstruction quality.
Typical blind pansharpening algorithms are often computationally intensive
since the blur kernel and the target HRMS image are often computed using
iterative solvers and in an alternating fashion. To achieve fast blind
pansharpening, we decouple the solution of the blur kernel and of the HRMS
image. First, we estimate the blur kernel by computing the kernel coefficients
with minimum total generalized variation that blur a downsampled version of the
PAN image to approximate a linear combination of the LRMS image channels. Then,
we estimate each channel of the HRMS image using local Laplacian prior to
regularize the relationship between each HRMS channel and the PAN image.
Solving the HRMS image is accelerated by both parallelizing across the channels
and by fast numerical algorithms for each channel. Due to the fast scheme and
the powerful priors we used on the blur kernel coefficients (total generalized
variation) and on the cross-channel relationship (local Laplacian prior),
numerical experiments demonstrate that our algorithm outperforms
state-of-the-art model-based counterparts in terms of both computational time
and reconstruction quality of the HRMS images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ImageNet-21K Pretraining for the Masses. (arXiv:2104.10972v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1">Tal Ridnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1">Emanuel Ben-Baruch</a>, <a href="http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1">Asaf Noy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1">Lihi Zelnik-Manor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10972">
                                    <div class="article-summary-box-inner">
                                        <span>ImageNet-1K serves as the primary dataset for pretraining deep learning
models for computer vision tasks. ImageNet-21K dataset, which is bigger and
more diverse, is used less frequently for pretraining, mainly due to its
complexity, low accessibility, and underestimation of its added value. This
paper aims to close this gap, and make high-quality efficient pretraining on
ImageNet-21K available for everyone. Via a dedicated preprocessing stage,
utilization of WordNet hierarchical structure, and a novel training scheme
called semantic softmax, we show that various models significantly benefit from
ImageNet-21K pretraining on numerous datasets and tasks, including small
mobile-oriented models. We also show that we outperform previous ImageNet-21K
pretraining schemes for prominent new models like ViT and Mixer. Our proposed
pretraining pipeline is efficient, accessible, and leads to SoTA reproducible
results, from a publicly available dataset. The training code and pretrained
models are available at: https://github.com/Alibaba-MIIL/ImageNet21K</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards High Fidelity Face Relighting with Realistic Shadows. (arXiv:2104.00825v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hou_A/0/1/0/all/0/1">Andrew Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ze Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkis_M/0/1/0/all/0/1">Michel Sarkis</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_N/0/1/0/all/0/1">Ning Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1">Yiying Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoming Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00825">
                                    <div class="article-summary-box-inner">
                                        <span>Existing face relighting methods often struggle with two problems:
maintaining the local facial details of the subject and accurately removing and
synthesizing shadows in the relit image, especially hard shadows. We propose a
novel deep face relighting method that addresses both problems. Our method
learns to predict the ratio (quotient) image between a source image and the
target image with the desired lighting, allowing us to relight the image while
maintaining the local facial details. During training, our model also learns to
accurately modify shadows by using estimated shadow masks to emphasize on the
high-contrast shadow borders. Furthermore, we introduce a method to use the
shadow mask to estimate the ambient light intensity in an image, and are thus
able to leverage multiple datasets during training with different global
lighting intensities. With quantitative and qualitative evaluations on the
Multi-PIE and FFHQ datasets, we demonstrate that our proposed method faithfully
maintains the local facial details of the subject and can accurately handle
hard shadows while achieving state-of-the-art face relighting performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using a Supervised Method without supervision for foreground segmentation. (arXiv:2011.07954v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kassel_L/0/1/0/all/0/1">Levi Kassel</a>, <a href="http://arxiv.org/find/cs/1/au:+Werman_M/0/1/0/all/0/1">Michael Werman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07954">
                                    <div class="article-summary-box-inner">
                                        <span>Neural networks are a powerful framework for foreground segmentation in video
acquired by static cameras, segmenting moving objects from the background in a
robust way in various challenging scenarios. The premier methods are those
based on supervision requiring a final training stage on a database of tens to
hundreds of manually segmented images from the specific static camera. In this
work, we propose a method to automatically create an &quot;artificial&quot; database that
is sufficient for training the supervised methods so that it performs better
than current unsupervised methods. It is based on combining a weak foreground
segmenter, compared to the supervised method, to extract suitable objects from
the training images and randomly inserting these objects back into a background
image. Test results are shown on the test sequences in CDnet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maximum Entropy Subspace Clustering Network. (arXiv:2012.03176v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhihao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yuheng Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1">Junhui Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qingfu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03176">
                                    <div class="article-summary-box-inner">
                                        <span>Deep subspace clustering networks have attracted much attention in subspace
clustering, in which an auto-encoder non-linearly maps the input data into a
latent space, and a fully connected layer named self-expressiveness module is
introduced to learn the affinity matrix via a typical regularization term
(e.g., sparse or low-rank). However, the adopted regularization terms ignore
the connectivity within each subspace, limiting their clustering performance.
In addition, the adopted framework suffers from the coupling issue between the
auto-encoder module and the self-expressiveness module, making the network
training non-trivial. To tackle these two issues, we propose a novel deep
subspace clustering method named Maximum Entropy Subspace Clustering Network
(MESC-Net). Specifically, MESC-Net maximizes the entropy of the affinity matrix
to promote the connectivity within each subspace, in which its elements
corresponding to the same subspace are uniformly and densely distributed.
Furthermore, we design a novel framework to explicitly decouple the
auto-encoder module and the self-expressiveness module. We also theoretically
prove that the learned affinity matrix satisfies the block-diagonal property
under the independent subspaces. Extensive quantitative and qualitative results
on commonly used benchmark datasets validate MESC-Net significantly outperforms
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Chromatic and spatial analysis of one-pixel attacks against an image classifier. (arXiv:2105.13771v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alatalo_J/0/1/0/all/0/1">Janne Alatalo</a>, <a href="http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1">Joni Korpihalkola</a>, <a href="http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1">Tuomo Sipola</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1">Tero Kokkonen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13771">
                                    <div class="article-summary-box-inner">
                                        <span>One-pixel attack is a curious way of deceiving neural network classifier by
changing only one pixel in the input image. The full potential and boundaries
of this attack method are not yet fully understood. In this research, the
successful and unsuccessful attacks are studied in more detail to illustrate
the working mechanisms of a one-pixel attack created using differential
evolution. The data comes from our earlier studies where we applied the attack
against medical imaging. We used a real breast cancer tissue dataset and a real
classifier as the attack target. This research presents ways to analyze
chromatic and spatial distributions of one-pixel attacks. In addition, we
present one-pixel attack confidence maps to illustrate the behavior of the
target classifier. We show that the more effective attacks change the color of
the pixel more, and that the successful attacks are situated at the center of
the images. This kind of analysis is not only useful for understanding the
behavior of the attack but also the qualities of the classifying neural
network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Less is More: Pay Less Attention in Vision Transformers. (arXiv:2105.14217v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zizheng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1">Bohan Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">Haoyu He</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jianfei Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14217">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have become one of the dominant architectures in deep learning,
particularly as a powerful alternative to convolutional neural networks (CNNs)
in computer vision. However, Transformer training and inference in previous
works can be prohibitively expensive due to the quadratic complexity of
self-attention over a long sequence of representations, especially for
high-resolution dense prediction tasks. To this end, we present a novel Less
attention vIsion Transformer (LIT), building upon the fact that convolutions,
fully-connected (FC) layers, and self-attentions have almost equivalent
mathematical expressions for processing image patch sequences. Specifically, we
propose a hierarchical Transformer where we use pure multi-layer perceptrons
(MLPs) to encode rich local patterns in the early stages while applying
self-attention modules to capture longer dependencies in deeper layers.
Moreover, we further propose a learned deformable token merging module to
adaptively fuse informative patches in a non-uniform manner. The proposed LIT
achieves promising performance on image recognition tasks, including image
classification, object detection and instance segmentation, serving as a strong
backbone for many vision tasks. Code is available at:
https://github.com/MonashAI/LIT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers. (arXiv:2105.15203v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiding Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1">Jose M. Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15203">
                                    <div class="article-summary-box-inner">
                                        <span>We present SegFormer, a simple, efficient yet powerful semantic segmentation
framework which unifies Transformers with lightweight multilayer perception
(MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a
novel hierarchically structured Transformer encoder which outputs multiscale
features. It does not need positional encoding, thereby avoiding the
interpolation of positional codes which leads to decreased performance when the
testing resolution differs from training. 2) SegFormer avoids complex decoders.
The proposed MLP decoder aggregates information from different layers, and thus
combining both local attention and global attention to render powerful
representations. We show that this simple and lightweight design is the key to
efficient segmentation on Transformers. We scale our approach up to obtain a
series of models from SegFormer-B0 to SegFormer-B5, reaching significantly
better performance and efficiency than previous counterparts. For example,
SegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x
smaller and 2.2% better than the previous best method. Our best model,
SegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows
excellent zero-shot robustness on Cityscapes-C. Code will be released at:
github.com/NVlabs/SegFormer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Enabling Meta-Learning from Target Models. (arXiv:2104.03736v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Su Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1">Le Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03736">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning can extract an inductive bias from previous learning experience
and assist the training processes of new tasks. It is often realized through
optimizing a meta-model with the evaluation loss of a series of task-specific
solvers. Most existing algorithms sample non-overlapping $\mathit{support}$
sets and $\mathit{query}$ sets to train and evaluate the solvers respectively
due to simplicity ($\mathcal{S}/\mathcal{Q}$ protocol). However, another
evaluation method that assesses the discrepancy between the solver and a target
model is short of research ($\mathcal{S}/\mathcal{T}$ protocol).
$\mathcal{S}/\mathcal{T}$ protocol has unique advantages such as offering more
informative supervision, but it is computationally expensive. This paper looks
into this special evaluation method and takes a step towards putting it into
practice. We find that with a small ratio of tasks armed with target models,
classic meta-learning algorithms can be improved a lot without consuming many
resources. Furthermore, we empirically verify the effectiveness of
$\mathcal{S}/\mathcal{T}$ protocol in a typical application of meta-learning,
$\mathit{i.e.}$, few-shot learning. In detail, after constructing target models
by fine-tuning the pre-trained network on those hard tasks, we match the
task-specific solvers to target models via knowledge distillation. Experiments
demonstrate the superiority of our proposal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ResT: An Efficient Transformer for Visual Recognition. (arXiv:2105.13677v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qinglong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yubin Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13677">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents an efficient multi-scale vision Transformer, called ResT,
that capably served as a general-purpose backbone for image recognition. Unlike
existing Transformer methods, which employ standard Transformer blocks to
tackle raw images with a fixed resolution, our ResT have several advantages:
(1) A memory-efficient multi-head self-attention is built, which compresses the
memory by a simple depth-wise convolution, and projects the interaction across
the attention-heads dimension while keeping the diversity ability of
multi-heads; (2) Position encoding is constructed as spatial attention, which
is more flexible and can tackle with input images of arbitrary size without
interpolation or fine-tune; (3) Instead of the straightforward tokenization at
the beginning of each stage, we design the patch embedding as a stack of
overlapping convolution operation with stride on the 2D-reshaped token map. We
comprehensively validate ResT on image classification and downstream tasks.
Experimental results show that the proposed ResT can outperform the recently
state-of-the-art backbones by a large margin, demonstrating the potential of
ResT as strong backbones. The code and models will be made publicly available
at https://github.com/wofmanaf/ResT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stylizing 3D Scene via Implicit Representation and HyperNetwork. (arXiv:2105.13016v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chiang_P/0/1/0/all/0/1">Pei-Ze Chiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsai_M/0/1/0/all/0/1">Meng-Shiun Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Tseng_H/0/1/0/all/0/1">Hung-Yu Tseng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_W/0/1/0/all/0/1">Wei-sheng Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chiu_W/0/1/0/all/0/1">Wei-Chen Chiu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13016">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we aim to address the 3D scene stylization problem - generating
stylized images of the scene at arbitrary novel view angles. A straightforward
solution is to combine existing novel view synthesis and image/video style
transfer approaches, which often leads to blurry results or inconsistent
appearance. Inspired by the high quality results of the neural radiance fields
(NeRF) method, we propose a joint framework to directly render novel views with
the desired style. Our framework consists of two components: an implicit
representation of the 3D scene with the neural radiance field model, and a
hypernetwork to transfer the style information into the scene representation.
In particular, our implicit representation model disentangles the scene into
the geometry and appearance branches, and the hypernetwork learns to predict
the parameters of the appearance branch from the reference style image. To
alleviate the training difficulties and memory burden, we propose a two-stage
training procedure and a patch sub-sampling approach to optimize the style and
content losses with the neural radiance field model. After optimization, our
model is able to render consistent novel views at arbitrary view angles with
arbitrary style. Both quantitative evaluation and human subject study have
demonstrated that the proposed method generates faithful stylization results
with consistent appearance across different views.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography. (arXiv:2103.06419v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jinke Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lv_P/0/1/0/all/0/1">Peiqing Lv</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1">Haiying Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1">Changfa Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06419">
                                    <div class="article-summary-box-inner">
                                        <span>Background and objective: In this paper, a modified U-Net based framework is
presented, which leverages techniques from Squeeze-and-Excitation (SE) block,
Atrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate and
robust liver CT segmentation, and the effectiveness of the proposed method was
tested on two public datasets LiTS17 and SLiver07.

Methods: A new network architecture called SAR-U-Net was designed. Firstly,
the SE block is introduced to adaptively extract image features after each
convolution in the U-Net encoder, while suppressing irrelevant regions, and
highlighting features of specific segmentation task; Secondly, ASPP was
employed to replace the transition layer and the output layer, and acquire
multi-scale image information via different receptive fields. Thirdly, to
alleviate the degradation problem, the traditional convolution block was
replaced with the residual block and thus prompt the network to gain accuracy
from considerably increased depth.

Results: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD and
MSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with other
closely related 2D-based models, the proposed method achieved the highest
accuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD,
ASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Compared
with other closely related models, the proposed method achieved the highest
segmentation accuracy except for the RVD.

Conclusion: The proposed model enables a great improvement on the accuracy
compared to 2D-based models, and its robustness in circumvent challenging
problems, such as small liver regions, discontinuous liver regions, and fuzzy
liver boundaries, is also well demonstrated and validated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Robustness of Vision Transformers to Adversarial Examples. (arXiv:2104.02610v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmood_K/0/1/0/all/0/1">Kaleel Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1">Rigel Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Dijk_M/0/1/0/all/0/1">Marten van Dijk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02610">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in attention-based networks have shown that Vision
Transformers can achieve state-of-the-art or near state-of-the-art results on
many image classification tasks. This puts transformers in the unique position
of being a promising alternative to traditional convolutional neural networks
(CNNs). While CNNs have been carefully studied with respect to adversarial
attacks, the same cannot be said of Vision Transformers. In this paper, we
study the robustness of Vision Transformers to adversarial examples. Our
analyses of transformer security is divided into three parts. First, we test
the transformer under standard white-box and black-box attacks. Second, we
study the transferability of adversarial examples between CNNs and
transformers. We show that adversarial examples do not readily transfer between
CNNs and transformers. Based on this finding, we analyze the security of a
simple ensemble defense of CNNs and transformers. By creating a new attack, the
self-attention blended gradient attack, we show that such an ensemble is not
secure under a white-box adversary. However, under a black-box adversary, we
show that an ensemble can achieve unprecedented robustness without sacrificing
clean accuracy. Our analysis for this work is done using six types of white-box
attacks and two types of black-box attacks. Our study encompasses multiple
Vision Transformers, Big Transfer Models and CNN architectures trained on
CIFAR-10, CIFAR-100 and ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Scene Completion via Integrating Instances and Scene in-the-Loop. (arXiv:2104.03640v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1">Yingjie Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuesong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kwan-Yee Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaogang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03640">
                                    <div class="article-summary-box-inner">
                                        <span>Semantic Scene Completion aims at reconstructing a complete 3D scene with
precise voxel-wise semantics from a single-view depth or RGBD image. It is a
crucial but challenging problem for indoor scene understanding. In this work,
we present a novel framework named Scene-Instance-Scene Network
(\textit{SISNet}), which takes advantages of both instance and scene level
semantic information. Our method is capable of inferring fine-grained shape
details as well as nearby objects whose semantic categories are easily
mixed-up. The key insight is that we decouple the instances from a coarsely
completed semantic scene instead of a raw input image to guide the
reconstruction of instances and the overall scene. SISNet conducts iterative
scene-to-instance (SI) and instance-to-scene (IS) semantic completion.
Specifically, the SI is able to encode objects&#x27; surrounding context for
effectively decoupling instances from the scene and each instance could be
voxelized into higher resolution to capture finer details. With IS,
fine-grained instance information can be integrated back into the 3D scene and
thus leads to more accurate semantic scene completion. Utilizing such an
iterative mechanism, the scene and instance completion benefits each other to
achieve higher completion accuracy. Extensively experiments show that our
proposed method consistently outperforms state-of-the-art methods on both real
NYU, NYUCAD and synthetic SUNCG-RGBD datasets. The code and the supplementary
material will be available at \url{https://github.com/yjcaimeow/SISNet}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Each Part Matters: Local Patterns Facilitate Cross-view Geo-localization. (arXiv:2008.11646v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tingyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhedong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Chenggang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiyong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yaoqi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Bolun Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11646">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-view geo-localization is to spot images of the same geographic target
from different platforms, e.g., drone-view cameras and satellites. It is
challenging in the large visual appearance changes caused by extreme viewpoint
variations. Existing methods usually concentrate on mining the fine-grained
feature of the geographic target in the image center, but underestimate the
contextual information in neighbor areas. In this work, we argue that neighbor
areas can be leveraged as auxiliary information, enriching discriminative clues
for geolocalization. Specifically, we introduce a simple and effective deep
neural network, called Local Pattern Network (LPN), to take advantage of
contextual information in an end-to-end manner. Without using extra part
estimators, LPN adopts a square-ring feature partition strategy, which provides
the attention according to the distance to the image center. It eases the part
matching and enables the part-wise representation learning. Owing to the
square-ring partition design, the proposed LPN has good scalability to rotation
variations and achieves competitive results on three prevailing benchmarks,
i.e., University-1652, CVUSA and CVACT. Besides, we also show the proposed LPN
can be easily embedded into other frameworks to further boost performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels. (arXiv:2105.04522v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Englesson_E/0/1/0/all/0/1">Erik Englesson</a>, <a href="http://arxiv.org/find/cs/1/au:+Azizpour_H/0/1/0/all/0/1">Hossein Azizpour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04522">
                                    <div class="article-summary-box-inner">
                                        <span>Prior works have found it beneficial to combine provably noise-robust loss
functions e.g., mean absolute error (MAE) with standard categorical loss
function e.g. cross entropy (CE) to improve their learnability. Here, we
propose to use Jensen-Shannon divergence as a noise-robust loss function and
show that it interestingly interpolate between CE and MAE with a controllable
mixing parameter. Furthermore, we make a crucial observation that CE exhibit
lower consistency around noisy data points. Based on this observation, we adopt
a generalized version of the Jensen-Shannon divergence for multiple
distributions to encourage consistency around data points. Using this loss
function, we show state-of-the-art results on both synthetic (CIFAR), and
real-world (WebVision) noise with varying noise rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Conditional Disentanglement Framework for Multimodal Brain MR Image Translation. (arXiv:2101.05434v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Xing_F/0/1/0/all/0/1">Fangxu Xing</a>, <a href="http://arxiv.org/find/eess/1/au:+Fakhri_G/0/1/0/all/0/1">Georges El Fakhri</a>, <a href="http://arxiv.org/find/eess/1/au:+Woo_J/0/1/0/all/0/1">Jonghye Woo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05434">
                                    <div class="article-summary-box-inner">
                                        <span>Multimodal MRI provides complementary and clinically relevant information to
probe tissue condition and to characterize various diseases. However, it is
often difficult to acquire sufficiently many modalities from the same subject
due to limitations in study plans, while quantitative analysis is still
demanded. In this work, we propose a unified conditional disentanglement
framework to synthesize any arbitrary modality from an input modality. Our
framework hinges on a cycle-constrained conditional adversarial training
approach, where it can extract a modality-invariant anatomical feature with a
modality-agnostic encoder and generate a target modality with a conditioned
decoder. We validate our framework on four MRI modalities, including
T1-weighted, T1 contrast enhanced, T2-weighted, and FLAIR MRI, from the
BraTS&#x27;18 database, showing superior performance on synthesis quality over the
comparison methods. In addition, we report results from experiments on a tumor
segmentation task carried out with synthesized data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Registration of serial sections: An evaluation method based on distortions of the ground truths. (arXiv:2011.11060v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lobachev_O/0/1/0/all/0/1">Oleg Lobachev</a>, <a href="http://arxiv.org/find/cs/1/au:+Funatomi_T/0/1/0/all/0/1">Takuya Funatomi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfaffenroth_A/0/1/0/all/0/1">Alexander Pfaffenroth</a>, <a href="http://arxiv.org/find/cs/1/au:+Forster_R/0/1/0/all/0/1">Reinhold F&#xf6;rster</a>, <a href="http://arxiv.org/find/cs/1/au:+Knudsen_L/0/1/0/all/0/1">Lars Knudsen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wrede_C/0/1/0/all/0/1">Christoph Wrede</a>, <a href="http://arxiv.org/find/cs/1/au:+Guthe_M/0/1/0/all/0/1">Michael Guthe</a>, <a href="http://arxiv.org/find/cs/1/au:+Haberthur_D/0/1/0/all/0/1">David Haberth&#xfc;r</a>, <a href="http://arxiv.org/find/cs/1/au:+Hlushchuk_R/0/1/0/all/0/1">Ruslan Hlushchuk</a>, <a href="http://arxiv.org/find/cs/1/au:+Salaets_T/0/1/0/all/0/1">Thomas Salaets</a>, <a href="http://arxiv.org/find/cs/1/au:+Toelen_J/0/1/0/all/0/1">Jaan Toelen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaffling_S/0/1/0/all/0/1">Simone Gaffling</a>, <a href="http://arxiv.org/find/cs/1/au:+Muhlfeld_C/0/1/0/all/0/1">Christian M&#xfc;hlfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Grothausmann_R/0/1/0/all/0/1">Roman Grothausmann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11060">
                                    <div class="article-summary-box-inner">
                                        <span>Registration of histological serial sections is a challenging task. Serial
sections exhibit distortions and damage from sectioning. Missing information on
how the tissue looked before cutting makes a realistic validation of 2D
registrations extremely difficult.

This work proposes methods for ground-truth-based evaluation of
registrations. Firstly, we present a methodology to generate test data for
registrations. We distort an innately registered image stack in the manner
similar to the cutting distortion of serial sections. Test cases are generated
from existing 3D data sets, thus the ground truth is known. Secondly, our test
case generation premises evaluation of the registrations with known ground
truths. Our methodology for such an evaluation technique distinguishes this
work from other approaches. Both under- and over-registration become evident in
our evaluations. We also survey existing validation efforts.

We present a full-series evaluation across six different registration methods
applied to our distorted 3D data sets of animal lungs. Our distorted and ground
truth data sets are made publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relative stability toward diffeomorphisms indicates performance in deep nets. (arXiv:2105.02468v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Petrini_L/0/1/0/all/0/1">Leonardo Petrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Favero_A/0/1/0/all/0/1">Alessandro Favero</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1">Mario Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1">Matthieu Wyart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02468">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding why deep nets can classify data in large dimensions remains a
challenge. It has been proposed that they do so by becoming stable to
diffeomorphisms, yet existing empirical measurements support that it is often
not the case. We revisit this question by defining a maximum-entropy
distribution on diffeomorphisms, that allows to study typical diffeomorphisms
of a given norm. We confirm that stability toward diffeomorphisms does not
strongly correlate to performance on benchmark data sets of images. By
contrast, we find that the stability toward diffeomorphisms relative to that of
generic transformations $R_f$ correlates remarkably with the test error
$\epsilon_t$. It is of order unity at initialization but decreases by several
decades during training for state-of-the-art architectures. For CIFAR10 and 15
known architectures, we find $\epsilon_t\approx 0.2\sqrt{R_f}$, suggesting that
obtaining a small $R_f$ is important to achieve good performance. We study how
$R_f$ depends on the size of the training set and compare it to a simple model
of invariant learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$ Regularization. (arXiv:2106.02923v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rhodes_T/0/1/0/all/0/1">Travers Rhodes</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daniel D. Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02923">
                                    <div class="article-summary-box-inner">
                                        <span>There have been many recent advances in representation learning; however,
unsupervised representation learning can still struggle with model
identification issues. Variational Auto-Encoders (VAEs) and their extensions
such as $\beta$-VAEs have been shown to locally align latent variables with PCA
directions, which can help to improve model disentanglement under some
conditions. Borrowing inspiration from Independent Component Analysis (ICA) and
sparse coding, we propose applying an $L_1$ loss to the VAE&#x27;s generative
Jacobian during training to encourage local latent variable alignment with
independent factors of variation in the data. We demonstrate our results on a
variety of datasets, giving qualitative and quantitative results using
information theoretic and modularity measures that show our added $L_1$ cost
encourages local axis alignment of the latent representation with individual
factors of variation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What If We Only Use Real Datasets for Scene Text Recognition? Toward Scene Text Recognition With Fewer Labels. (arXiv:2103.04400v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1">Jeonghun Baek</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsui_Y/0/1/0/all/0/1">Yusuke Matsui</a>, <a href="http://arxiv.org/find/cs/1/au:+Aizawa_K/0/1/0/all/0/1">Kiyoharu Aizawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04400">
                                    <div class="article-summary-box-inner">
                                        <span>Scene text recognition (STR) task has a common practice: All state-of-the-art
STR models are trained on large synthetic data. In contrast to this practice,
training STR models only on fewer real labels (STR with fewer labels) is
important when we have to train STR models without synthetic data: for
handwritten or artistic texts that are difficult to generate synthetically and
for languages other than English for which we do not always have synthetic
data. However, there has been implicit common knowledge that training STR
models on real data is nearly impossible because real data is insufficient. We
consider that this common knowledge has obstructed the study of STR with fewer
labels. In this work, we would like to reactivate STR with fewer labels by
disproving the common knowledge. We consolidate recently accumulated public
real data and show that we can train STR models satisfactorily only with real
labeled data. Subsequently, we find simple data augmentation to fully exploit
real data. Furthermore, we improve the models by collecting unlabeled data and
introducing semi- and self-supervised methods. As a result, we obtain a
competitive model to state-of-the-art methods. To the best of our knowledge,
this is the first study that 1) shows sufficient performance by only using real
labels and 2) introduces semi- and self-supervised methods into STR with fewer
labels. Our code and data are available:
https://github.com/ku21fan/STR-Fewer-Labels</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scaling Local Self-Attention for Parameter Efficient Visual Backbones. (arXiv:2103.12731v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vaswani_A/0/1/0/all/0/1">Ashish Vaswani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramachandran_P/0/1/0/all/0/1">Prajit Ramachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivas_A/0/1/0/all/0/1">Aravind Srinivas</a>, <a href="http://arxiv.org/find/cs/1/au:+Parmar_N/0/1/0/all/0/1">Niki Parmar</a>, <a href="http://arxiv.org/find/cs/1/au:+Hechtman_B/0/1/0/all/0/1">Blake Hechtman</a>, <a href="http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1">Jonathon Shlens</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12731">
                                    <div class="article-summary-box-inner">
                                        <span>Self-attention has the promise of improving computer vision systems due to
parameter-independent scaling of receptive fields and content-dependent
interactions, in contrast to parameter-dependent scaling and
content-independent interactions of convolutions. Self-attention models have
recently been shown to have encouraging improvements on accuracy-parameter
trade-offs compared to baseline convolutional models such as ResNet-50. In this
work, we aim to develop self-attention models that can outperform not just the
canonical baseline models, but even the high-performing convolutional models.
We propose two extensions to self-attention that, in conjunction with a more
efficient implementation of self-attention, improve the speed, memory usage,
and accuracy of these models. We leverage these improvements to develop a new
self-attention model family, HaloNets, which reach state-of-the-art accuracies
on the parameter-limited setting of the ImageNet classification benchmark. In
preliminary transfer learning experiments, we find that HaloNet models
outperform much larger models and have better inference performance. On harder
tasks such as object detection and instance segmentation, our simple local
self-attention and convolutional hybrids show improvements over very strong
baselines. These results mark another step in demonstrating the efficacy of
self-attention models on settings traditionally dominated by convolutional
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision. (arXiv:2105.06464v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1">Shiyi Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiding Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Choy_C/0/1/0/all/0/1">Christopher Choy</a>, <a href="http://arxiv.org/find/cs/1/au:+Radhakrishnan_S/0/1/0/all/0/1">Subhashree Radhakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guilin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1">Larry S. Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06464">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce DiscoBox, a novel framework that jointly learns instance
segmentation and semantic correspondence using bounding box supervision.
Specifically, we propose a self-ensembling framework where instance
segmentation and semantic correspondence are jointly guided by a structured
teacher in addition to the bounding box supervision. The teacher is a
structured energy model incorporating a pairwise potential and a cross-image
potential to model the pairwise pixel relationships both within and across the
boxes. Minimizing the teacher energy simultaneously yields refined object masks
and dense correspondences between intra-class objects, which are taken as
pseudo-labels to supervise the task network and provide positive/negative
correspondence pairs for dense constrastive learning. We show a symbiotic
relationship where the two tasks mutually benefit from each other. Our best
model achieves 37.9% AP on COCO instance segmentation, surpassing prior weakly
supervised methods and is competitive to supervised methods. We also obtain
state of the art weakly supervised results on PASCAL VOC12 and PF-PASCAL with
real-time inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Resolution Network. (arXiv:2106.02898v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Mingjian Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_E/0/1/0/all/0/1">Enhua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qiulin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_Y/0/1/0/all/0/1">Ying Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1">Zhenzhong Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02898">
                                    <div class="article-summary-box-inner">
                                        <span>Deep convolutional neural networks (CNNs) are often of sophisticated design
with numerous convolutional layers and learnable parameters for the accuracy
reason. To alleviate the expensive costs of deploying them on mobile devices,
recent works have made huge efforts for excavating redundancy in pre-defined
architectures. Nevertheless, the redundancy on the input resolution of modern
CNNs has not been fully investigated, i.e., the resolution of input image is
fixed. In this paper, we observe that the smallest resolution for accurately
predicting the given image is different using the same neural network. To this
end, we propose a novel dynamic-resolution network (DRNet) in which the
resolution is determined dynamically based on each input sample. Thus, a
resolution predictor with negligible computational costs is explored and
optimized jointly with the desired network. In practice, the predictor learns
the smallest resolution that can retain and even exceed the original
recognition accuracy for each image. During the inference, each input image
will be resized to its predicted resolution for minimizing the overall
computation burden. We then conduct extensive experiments on several benchmark
networks and datasets. The results show that our DRNet can be embedded in any
off-the-shelf network architecture to obtain a considerable reduction in
computational complexity. For instance, DRNet achieves similar performance with
an about 34% computation reduction, while gains 1.4% accuracy increase with 10%
computation reduction compared to the original ResNet-50 on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Geometric Matrix Completion. (arXiv:1911.07255v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boyarski_A/0/1/0/all/0/1">Amit Boyarski</a>, <a href="http://arxiv.org/find/cs/1/au:+Vedula_S/0/1/0/all/0/1">Sanketh Vedula</a>, <a href="http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1">Alex Bronstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.07255">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Matrix Factorization (DMF) is an emerging approach to the problem of
matrix completion. Recent works have established that gradient descent applied
to a DMF model induces an implicit regularization on the rank of the recovered
matrix. In this work we interpret the DMF model through the lens of spectral
geometry. This allows us to incorporate explicit regularization without
breaking the DMF structure, thus enjoying the best of both worlds. In
particular, we focus on matrix completion problems with underlying geometric or
topological relations between the rows and/or columns. Such relations are
prevalent in matrix completion problems that arise in many applications, such
as recommender systems and drug-target interaction. Our contributions enable
DMF models to exploit these relations, and make them competitive on real
benchmarks, while exhibiting one of the first successful applications of deep
linear networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PCT: Point cloud transformer. (arXiv:2012.09688v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Meng-Hao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jun-Xiong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zheng-Ning Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1">Tai-Jiang Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1">Ralph R. Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shi-Min Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09688">
                                    <div class="article-summary-box-inner">
                                        <span>The irregular domain and lack of ordering make it challenging to design deep
neural networks for point cloud processing. This paper presents a novel
framework named Point Cloud Transformer(PCT) for point cloud learning. PCT is
based on Transformer, which achieves huge success in natural language
processing and displays great potential in image processing. It is inherently
permutation invariant for processing a sequence of points, making it
well-suited for point cloud learning. To better capture local context within
the point cloud, we enhance input embedding with the support of farthest point
sampling and nearest neighbor search. Extensive experiments demonstrate that
the PCT achieves the state-of-the-art performance on shape classification, part
segmentation and normal estimation tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Search Asymmetry: Deep Nets and Humans Share Similar Inherent Biases. (arXiv:2106.02953v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1">Shashi Kant Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mengmi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chia-Chien Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolfe_J/0/1/0/all/0/1">Jeremy M. Wolfe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kreiman_G/0/1/0/all/0/1">Gabriel Kreiman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02953">
                                    <div class="article-summary-box-inner">
                                        <span>Visual search is a ubiquitous and often challenging daily task, exemplified
by looking for the car keys at home or a friend in a crowd. An intriguing
property of some classical search tasks is an asymmetry such that finding a
target A among distractors B can be easier than finding B among A. To elucidate
the mechanisms responsible for asymmetry in visual search, we propose a
computational model that takes a target and a search image as inputs and
produces a sequence of eye movements until the target is found. The model
integrates eccentricity-dependent visual recognition with target-dependent
top-down cues. We compared the model against human behavior in six paradigmatic
search tasks that show asymmetry in humans. Without prior exposure to the
stimuli or task-specific training, the model provides a plausible mechanism for
search asymmetry. We hypothesized that the polarity of search asymmetry arises
from experience with the natural environment. We tested this hypothesis by
training the model on an augmented version of ImageNet where the biases of
natural images were either removed or reversed. The polarity of search
asymmetry disappeared or was altered depending on the training protocol. This
study highlights how classical perceptual properties can emerge in neural
network models, without the need for task-specific training, but rather as a
consequence of the statistical properties of the developmental diet fed to the
model. All source code and stimuli are publicly available
https://github.com/kreimanlab/VisualSearchAsymmetry</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Patch Slimming for Efficient Vision Transformers. (arXiv:2106.02852v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yehui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jianyuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02852">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the efficiency problem for visual transformers by
excavating redundant calculation in given networks. The recent transformer
architecture has demonstrated its effectiveness for achieving excellent
performance on a series of computer vision tasks. However, similar to that of
convolutional neural networks, the huge computational cost of vision
transformers is still a severe issue. Considering that the attention mechanism
aggregates different patches layer-by-layer, we present a novel patch slimming
approach that discards useless patches in a top-down paradigm. We first
identify the effective patches in the last layer and then use them to guide the
patch selection process of previous layers. For each layer, the impact of a
patch on the final output feature is approximated and patches with less impact
will be removed. Experimental results on benchmark datasets demonstrate that
the proposed method can significantly reduce the computational costs of vision
transformers without affecting their performances. For example, over 45% FLOPs
of the ViT-Ti model can be reduced with only 0.2% top-1 accuracy drop on the
ImageNet dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Joint Sparse Non-negative Matrix Factorization Framework for Identifying the Common and Subject-specific Functional Units of Tongue Motion During Speech. (arXiv:2007.04865v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Woo_J/0/1/0/all/0/1">Jonghye Woo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xing_F/0/1/0/all/0/1">Fangxu Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Prince_J/0/1/0/all/0/1">Jerry L. Prince</a>, <a href="http://arxiv.org/find/cs/1/au:+Stone_M/0/1/0/all/0/1">Maureen Stone</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1">Arnold Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Reese_T/0/1/0/all/0/1">Timothy G. Reese</a>, <a href="http://arxiv.org/find/cs/1/au:+Wedeen_V/0/1/0/all/0/1">Van J. Wedeen</a>, <a href="http://arxiv.org/find/cs/1/au:+Fakhri_G/0/1/0/all/0/1">Georges El Fakhri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.04865">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligible speech is produced by creating varying internal local muscle
groupings -- i.e., functional units -- that are generated in a systematic and
coordinated manner. There are two major challenges in characterizing and
analyzing functional units.~First, due to the complex and convoluted nature of
tongue structure and function, it is of great importance to develop a method
that can accurately decode complex muscle coordination patterns during speech.
Second, it is challenging to keep identified functional units across subjects
comparable due to their substantial variability. In this work, to address these
challenges, we develop a new deep learning framework to identify common and
subject-specific functional units of tongue motion during speech.~Our framework
hinges on joint deep graph-regularized sparse non-negative matrix factorization
(NMF) using motion quantities derived from displacements by tagged Magnetic
Resonance Imaging. More specifically, we transform NMF with sparse and graph
regularizations into modular architectures akin to deep neural networks by
means of unfolding the Iterative Shrinkage-Thresholding Algorithm to learn
interpretable building blocks and associated weighting map. We then apply
spectral clustering to common and subject-specific weighting maps from which we
jointly determine the common and subject-specific functional units. Experiments
carried out with simulated datasets show that the proposed method achieved on
par or better clustering performance over the comparison methods. Experiments
carried out with in vivo tongue motion data show that the proposed method can
determine the common and subject-specific functional units with increased
interpretability and decreased size variability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Correlation Filters for Unmanned Aerial Vehicle-Based Aerial Tracking: A Review and Experimental Evaluation. (arXiv:2010.06255v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Changhong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bowen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1">Fangqiang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Fuling Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1">Geng Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06255">
                                    <div class="article-summary-box-inner">
                                        <span>Aerial tracking, which has exhibited its omnipresent dedication and splendid
performance, is one of the most active applications in the remote sensing
field. Especially, unmanned aerial vehicle (UAV)-based remote sensing system,
equipped with a visual tracking approach, has been widely used in aviation,
navigation, agriculture,transportation, and public security, etc. As is
mentioned above, the UAV-based aerial tracking platform has been gradually
developed from research to practical application stage, reaching one of the
main aerial remote sensing technologies in the future. However, due to the
real-world onerous situations, e.g., harsh external challenges, the vibration
of the UAV mechanical structure (especially under strong wind conditions), the
maneuvering flight in complex environment, and the limited computation
resources onboard, accuracy, robustness, and high efficiency are all crucial
for the onboard tracking methods. Recently, the discriminative correlation
filter (DCF)-based trackers have stood out for their high computational
efficiency and appealing robustness on a single CPU, and have flourished in the
UAV visual tracking community. In this work, the basic framework of the
DCF-based trackers is firstly generalized, based on which, 23 state-of-the-art
DCF-based trackers are orderly summarized according to their innovations for
solving various issues. Besides, exhaustive and quantitative experiments have
been extended on various prevailing UAV tracking benchmarks, i.e., UAV123,
UAV123@10fps, UAV20L, UAVDT, DTB70, and VisDrone2019-SOT, which contain 371,903
frames in total. The experiments show the performance, verify the feasibility,
and demonstrate the current challenges of DCF-based trackers onboard UAV
tracking.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor Imagery Recognition. (arXiv:2005.00777v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hou_Y/0/1/0/all/0/1">Yimin Hou</a>, <a href="http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1">Shuyue Jia</a>, <a href="http://arxiv.org/find/eess/1/au:+Lun_X/0/1/0/all/0/1">Xiangmin Lun</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1">Yan Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00777">
                                    <div class="article-summary-box-inner">
                                        <span>Recognition accuracy and response time are both critically essential ahead of
building practical electroencephalography (EEG) based brain-computer interface
(BCI). Recent approaches, however, have either compromised in the
classification accuracy or responding time. This paper presents a novel deep
learning approach designed towards remarkably accurate and responsive motor
imagery (MI) recognition based on scalp EEG. Bidirectional Long Short-term
Memory (BiLSTM) with the Attention mechanism manages to derive relevant
features from raw EEG signals. The connected graph convolutional neural network
(GCN) promotes the decoding performance by cooperating with the topological
structure of features, which are estimated from the overall data. The
0.4-second detection framework has shown effective and efficient prediction
based on individual and group-wise training, with 98.81% and 94.64% accuracy,
respectively, which outperformed all the state-of-the-art studies. The
introduced deep feature mining approach can precisely recognize human motion
intents from raw EEG signals, which paves the road to translate the EEG based
MI recognition to practical BCI systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable Fourier Features for Multi-DimensionalSpatial Positional Encoding. (arXiv:2106.02795v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1">Si Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1">Samy Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02795">
                                    <div class="article-summary-box-inner">
                                        <span>Attentional mechanisms are order-invariant. Positional encoding is a crucial
component to allow attention-based deep model architectures such as Transformer
to address sequences or images where the position of information matters. In
this paper, we propose a novel positional encoding method based on learnable
Fourier features. Instead of hard-coding each position as a token or a vector,
we represent each position, which can be multi-dimensional, as a trainable
encoding based on learnable Fourier feature mapping, modulated with a
multi-layer perceptron. The representation is particularly advantageous for a
spatial multi-dimensional position, e.g., pixel positions on an image, where
$L_2$ distances or more complex positional relationships need to be captured.
Our experiments based on several public benchmark tasks show that our learnable
Fourier feature representation for multi-dimensional positional encoding
outperforms existing methods by both improving the accuracy and allowing faster
convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Category Contrast for Unsupervised Domain Adaptation in Visual Tasks. (arXiv:2106.02885v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiaxing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1">Dayan Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">Aoran Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02885">
                                    <div class="article-summary-box-inner">
                                        <span>Instance contrast for unsupervised representation learning has achieved great
success in recent years. In this work, we explore the idea of instance
contrastive learning in unsupervised domain adaptation (UDA) and propose a
novel Category Contrast technique (CaCo) that introduces semantic priors on top
of instance discrimination for visual UDA tasks. By considering instance
contrastive learning as a dictionary look-up operation, we construct a
semantics-aware dictionary with samples from both source and target domains
where each target sample is assigned a (pseudo) category label based on the
category priors of source samples. This allows category contrastive learning
(between target queries and the category-level dictionary) for
category-discriminative yet domain-invariant feature representations: samples
of the same category (from either source or target domain) are pulled closer
while those of different categories are pushed apart simultaneously. Extensive
UDA experiments in multiple visual tasks ($e.g.$, segmentation, classification
and detection) show that the simple implementation of CaCo achieves superior
performance as compared with the highly-optimized state-of-the-art methods.
Analytically and empirically, the experiments also demonstrate that CaCo is
complementary to existing UDA methods and generalizable to other learning
setups such as semi-supervised learning, unsupervised model adaptation, etc.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">S2SD: Simultaneous Similarity-based Self-Distillation for Deep Metric Learning. (arXiv:2009.08348v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roth_K/0/1/0/all/0/1">Karsten Roth</a>, <a href="http://arxiv.org/find/cs/1/au:+Milbich_T/0/1/0/all/0/1">Timo Milbich</a>, <a href="http://arxiv.org/find/cs/1/au:+Ommer_B/0/1/0/all/0/1">Bj&#xf6;rn Ommer</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_J/0/1/0/all/0/1">Joseph Paul Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1">Marzyeh Ghassemi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08348">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Metric Learning (DML) provides a crucial tool for visual similarity and
zero-shot applications by learning generalizing embedding spaces, although
recent work in DML has shown strong performance saturation across training
objectives. However, generalization capacity is known to scale with the
embedding space dimensionality. Unfortunately, high dimensional embeddings also
create higher retrieval cost for downstream applications. To remedy this, we
propose \emph{Simultaneous Similarity-based Self-distillation (S2SD). S2SD
extends DML with knowledge distillation from auxiliary, high-dimensional
embedding and feature spaces to leverage complementary context during training
while retaining test-time cost and with negligible changes to the training
time. Experiments and ablations across different objectives and standard
benchmarks show S2SD offers notable improvements of up to 7% in Recall@1, while
also setting a new state-of-the-art. Code available at
https://github.com/MLforHealth/S2SD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Region-aware Adaptive Instance Normalization for Image Harmonization. (arXiv:2106.02853v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ling_J/0/1/0/all/0/1">Jun Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1">Han Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Li Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1">Rong Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_X/0/1/0/all/0/1">Xiao Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02853">
                                    <div class="article-summary-box-inner">
                                        <span>Image composition plays a common but important role in photo editing. To
acquire photo-realistic composite images, one must adjust the appearance and
visual style of the foreground to be compatible with the background. Existing
deep learning methods for harmonizing composite images directly learn an image
mapping network from the composite to the real one, without explicit
exploration on visual style consistency between the background and the
foreground images. To ensure the visual style consistency between the
foreground and the background, in this paper, we treat image harmonization as a
style transfer problem. In particular, we propose a simple yet effective
Region-aware Adaptive Instance Normalization (RAIN) module, which explicitly
formulates the visual style from the background and adaptively applies them to
the foreground. With our settings, our RAIN module can be used as a drop-in
module for existing image harmonization networks and is able to bring
significant improvements. Extensive experiments on the existing image
harmonization benchmark datasets show the superior capability of the proposed
method. Code is available at {https://github.com/junleen/RainNet}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Neural Networks with Gated Recurrent Connections. (arXiv:2106.02859v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1">Xiaolin Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02859">
                                    <div class="article-summary-box-inner">
                                        <span>The convolutional neural network (CNN) has become a basic model for solving
many computer vision problems. In recent years, a new class of CNNs, recurrent
convolution neural network (RCNN), inspired by abundant recurrent connections
in the visual systems of animals, was proposed. The critical element of RCNN is
the recurrent convolutional layer (RCL), which incorporates recurrent
connections between neurons in the standard convolutional layer. With
increasing number of recurrent computations, the receptive fields (RFs) of
neurons in RCL expand unboundedly, which is inconsistent with biological facts.
We propose to modulate the RFs of neurons by introducing gates to the recurrent
connections. The gates control the amount of context information inputting to
the neurons and the neurons&#x27; RFs therefore become adaptive. The resulting layer
is called gated recurrent convolution layer (GRCL). Multiple GRCLs constitute a
deep model called gated RCNN (GRCNN). The GRCNN was evaluated on several
computer vision tasks including object recognition, scene text recognition and
object detection, and obtained much better results than the RCNN. In addition,
when combined with other adaptive RF techniques, the GRCNN demonstrated
competitive performance to the state-of-the-art models on benchmark datasets
for these tasks. The codes are released at
\href{https://github.com/Jianf-Wang/GRCNN}{https://github.com/Jianf-Wang/GRCNN}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principle Bit Analysis: Autoencoding with Schur-Concave Loss. (arXiv:2106.02796v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhadane_S/0/1/0/all/0/1">Sourbh Bhadane</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_A/0/1/0/all/0/1">Aaron B. Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Acharya_J/0/1/0/all/0/1">Jayadev Acharya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02796">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a linear autoencoder in which the latent variables are quantized,
or corrupted by noise, and the constraint is Schur-concave in the set of latent
variances. Although finding the optimal encoder/decoder pair for this setup is
a nonconvex optimization problem, we show that decomposing the source into its
principal components is optimal. If the constraint is strictly Schur-concave
and the empirical covariance matrix has only simple eigenvalues, then any
optimal encoder/decoder must decompose the source in this way. As one
application, we consider a strictly Schur-concave constraint that estimates the
number of bits needed to represent the latent variables under fixed-rate
encoding, a setup that we call \emph{Principal Bit Analysis (PBA)}. This yields
a practical, general-purpose, fixed-rate compressor that outperforms existing
algorithms. As a second application, we show that a prototypical
autoencoder-based variable-rate compressor is guaranteed to decompose the
source into its principal components.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Video Generation for Complex Data. (arXiv:2106.02719v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castrejon_L/0/1/0/all/0/1">Lluis Castrejon</a>, <a href="http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1">Nicolas Ballas</a>, <a href="http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1">Aaron Courville</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02719">
                                    <div class="article-summary-box-inner">
                                        <span>Videos can often be created by first outlining a global description of the
scene and then adding local details. Inspired by this we propose a hierarchical
model for video generation which follows a coarse to fine approach. First our
model generates a low resolution video, establishing the global scene
structure, that is then refined by subsequent levels in the hierarchy. We train
each level in our hierarchy sequentially on partial views of the videos. This
reduces the computational complexity of our generative model, which scales to
high-resolution videos beyond a few frames. We validate our approach on
Kinetics-600 and BDD100K, for which we train a three level model capable of
generating 256x256 videos with 48 frames.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sequential Random Network for Fine-grained Image Classification. (arXiv:2103.07230v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chaorong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Malu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_F/0/1/0/all/0/1">Fengqing Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1">Anping Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yuanyuan Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07230">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Convolutional Neural Network (DCNN) and Transformer have achieved
remarkable successes in image recognition. However, their performance in
fine-grained image recognition is still difficult to meet the requirements of
actual needs. This paper proposes a Sequence Random Network (SRN) to enhance
the performance of DCNN. The output of DCNN is one-dimensional features. This
one-dimensional feature abstractly represents image information, but it does
not express well the detailed information of image. To address this issue, we
use the proposed SRN which composed of BiLSTM and several Tanh-Dropout blocks
(called BiLSTM-TDN), to further process DCNN one-dimensional features for
highlighting the detail information of image. After the feature transform by
BiLSTM-TDN, the recognition performance has been greatly improved. We conducted
the experiments on six fine-grained image datasets. Except for FGVC-Aircraft,
the accuracies of the proposed methods on the other datasets exceeded 99%.
Experimental results show that BiLSTM-TDN is far superior to the existing
state-of-the-art methods. In addition to DCNN, BiLSTM-TDN can also be extended
to other models, such as Transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Damaging Contrastive Learning. (arXiv:2106.02990v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Ziyu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mortazavi_B/0/1/0/all/0/1">Bobak Mortazavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02990">
                                    <div class="article-summary-box-inner">
                                        <span>The recent breakthrough achieved by contrastive learning accelerates the pace
for deploying unsupervised training on real-world data applications. However,
unlabeled data in reality is commonly imbalanced and shows a long-tail
distribution, and it is unclear how robustly the latest contrastive learning
methods could perform in the practical scenario. This paper proposes to
explicitly tackle this challenge, via a principled framework called
Self-Damaging Contrastive Learning (SDCLR), to automatically balance the
representation learning without knowing the classes. Our main inspiration is
drawn from the recent finding that deep models have difficult-to-memorize
samples, and those may be exposed through network pruning. It is further
natural to hypothesize that long-tail samples are also tougher for the model to
learn well due to insufficient examples. Hence, the key innovation in SDCLR is
to create a dynamic self-competitor model to contrast with the target model,
which is a pruned version of the latter. During training, contrasting the two
models will lead to adaptive online mining of the most easily forgotten samples
for the current target model, and implicitly emphasize them more in the
contrastive loss. Extensive experiments across multiple datasets and imbalance
settings show that SDCLR significantly improves not only overall accuracies but
also balancedness, in terms of linear evaluation on the full-shot and few-shot
settings. Our code is available at: https://github.com/VITA-Group/SDCLR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hidden Markov Modeling for Maximum Likelihood Neuron Reconstruction. (arXiv:2106.02701v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Athey_T/0/1/0/all/0/1">Thomas L. Athey</a>, <a href="http://arxiv.org/find/cs/1/au:+Tward_D/0/1/0/all/0/1">Daniel Tward</a>, <a href="http://arxiv.org/find/cs/1/au:+Mueller_U/0/1/0/all/0/1">Ulrich Mueller</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_M/0/1/0/all/0/1">Michael I. Miller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02701">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in brain clearing and imaging have made it possible to image
entire mammalian brains at sub-micron resolution. These images offer the
potential to assemble brain-wide atlases of projection neuron morphology, but
manual neuron reconstruction remains a bottleneck. Here we present a method
inspired by hidden Markov modeling and appearance modeling of fluorescent
neuron images that can automatically trace neuronal processes. Our method
leverages dynamic programming to scale to terabyte sized image data and can be
applied to images with one or more neurons. We applied our algorithm to the
output of image segmentation models where false negatives severed neuronal
processes, and showed that it can follow axons in the presence of noise or
nearby neurons. Our method has the potential to be integrated into a semi or
fully automated reconstruction pipeline. Additionally, it creates a framework
through which users can intervene with hard constraints to, for example, rule
out certain reconstructions, or assign axons to particular cell bodies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DEEPMIR: A DEEP neural network for differential detection of cerebral Microbleeds and IRon deposits in MRI. (arXiv:2010.00148v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Rashid_T/0/1/0/all/0/1">Tanweer Rashid</a>, <a href="http://arxiv.org/find/eess/1/au:+Abdulkadir_A/0/1/0/all/0/1">Ahmed Abdulkadir</a>, <a href="http://arxiv.org/find/eess/1/au:+Nasrallah_I/0/1/0/all/0/1">Ilya M. Nasrallah</a>, <a href="http://arxiv.org/find/eess/1/au:+Ware_J/0/1/0/all/0/1">Jeffrey B. Ware</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_H/0/1/0/all/0/1">Hangfan Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Spincemaille_P/0/1/0/all/0/1">Pascal Spincemaille</a>, <a href="http://arxiv.org/find/eess/1/au:+Romero_J/0/1/0/all/0/1">J. Rafael Romero</a>, <a href="http://arxiv.org/find/eess/1/au:+Bryan_R/0/1/0/all/0/1">R. Nick Bryan</a>, <a href="http://arxiv.org/find/eess/1/au:+Heckbert_S/0/1/0/all/0/1">Susan R. Heckbert</a>, <a href="http://arxiv.org/find/eess/1/au:+Habes_M/0/1/0/all/0/1">Mohamad Habes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.00148">
                                    <div class="article-summary-box-inner">
                                        <span>Lobar cerebral microbleeds (CMBs) and localized non-hemorrhage iron deposits
in the basal ganglia have been associated with brain aging, vascular disease
and neurodegenerative disorders. Particularly, CMBs are small lesions and
require multiple neuroimaging modalities for accurate detection. Quantitative
susceptibility mapping (QSM) derived from in vivo magnetic resonance imaging
(MRI) is necessary to differentiate between iron content and mineralization. We
set out to develop a deep learning-based segmentation method suitable for
segmenting both CMBs and iron deposits. We included a convenience sample of 24
participants from the MESA cohort and used T2-weighted images, susceptibility
weighted imaging (SWI), and QSM to segment the two types of lesions. We
developed a protocol for simultaneous manual annotation of CMBs and
non-hemorrhage iron deposits in the basal ganglia. This manual annotation was
then used to train a deep convolution neural network (CNN). Specifically, we
adapted the U-Net model with a higher number of resolution layers to be able to
detect small lesions such as CMBs from standard resolution MRI. We tested
different combinations of the three modalities to determine the most
informative data sources for the detection tasks. In the detection of CMBs
using single class and multiclass models, we achieved an average sensitivity
and precision of between 0.84-0.88 and 0.40-0.59, respectively. The same
framework detected non-hemorrhage iron deposits with an average sensitivity and
precision of about 0.75-0.81 and 0.62-0.75, respectively. Our results showed
that deep learning could automate the detection of small vessel disease lesions
and including multimodal MR data (particularly QSM) can improve the detection
of CMB and non-hemorrhage iron deposits with sensitivity and precision that is
compatible with use in large-scale research studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Non-Volume Preserving-based Fusion to Group-Level Emotion Recognition on Crowd Videos. (arXiv:1811.11849v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Quach_K/0/1/0/all/0/1">Kha Gia Quach</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_N/0/1/0/all/0/1">Ngan Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Duong_C/0/1/0/all/0/1">Chi Nhan Duong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jalata_I/0/1/0/all/0/1">Ibsa Jalata</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1">Kaushik Roy</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_K/0/1/0/all/0/1">Khoa Luu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1811.11849">
                                    <div class="article-summary-box-inner">
                                        <span>Group-level emotion recognition (ER) is a growing research area as the
demands for assessing crowds of all sizes are becoming an interest in both the
security arena as well as social media. This work extends the earlier ER
investigations, which focused on either group-level ER on single images or
within a video, by fully investigating group-level expression recognition on
crowd videos. In this paper, we propose an effective deep feature level fusion
mechanism to model the spatial-temporal information in the crowd videos. In our
approach, the fusing process is performed on the deep feature domain by a
generative probabilistic model, Non-Volume Preserving Fusion (NVPF), that
models spatial information relationships. Furthermore, we extend our proposed
spatial NVPF approach to the spatial-temporal NVPF approach to learn the
temporal information between frames. To demonstrate the robustness and
effectiveness of each component in the proposed approach, three experiments
were conducted: (i) evaluation on AffectNet database to benchmark the proposed
EmoNet for recognizing facial expression; (ii) evaluation on EmotiW2018 to
benchmark the proposed deep feature level fusion mechanism NVPF; and, (iii)
examine the proposed TNVPF on an innovative Group-level Emotion on Crowd Videos
(GECV) dataset composed of 627 videos collected from publicly available
sources. GECV dataset is a collection of videos containing crowds of people.
Each video is labeled with emotion categories at three levels: individual
faces, group of people, and the entire video frame.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orthogonal Over-Parameterized Training. (arXiv:2004.04690v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Rongmei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1">James M. Rehg</a>, <a href="http://arxiv.org/find/cs/1/au:+Paull_L/0/1/0/all/0/1">Liam Paull</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Li Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Le Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.04690">
                                    <div class="article-summary-box-inner">
                                        <span>The inductive bias of a neural network is largely determined by the
architecture and the training algorithm. To achieve good generalization, how to
effectively train a neural network is of great importance. We propose a novel
orthogonal over-parameterized training (OPT) framework that can provably
minimize the hyperspherical energy which characterizes the diversity of neurons
on a hypersphere. By maintaining the minimum hyperspherical energy during
training, OPT can greatly improve the empirical generalization. Specifically,
OPT fixes the randomly initialized weights of the neurons and learns an
orthogonal transformation that applies to these neurons. We consider multiple
ways to learn such an orthogonal transformation, including unrolling
orthogonalization algorithms, applying orthogonal parameterization, and
designing orthogonality-preserving gradient descent. For better scalability, we
propose the stochastic OPT which performs orthogonal transformation
stochastically for partial dimensions of neurons. Interestingly, OPT reveals
that learning a proper coordinate system for neurons is crucial to
generalization. We provide some insights on why OPT yields better
generalization. Extensive experiments validate the superiority of OPT over the
standard training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks. (arXiv:2002.05123v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pony_R/0/1/0/all/0/1">Roi Pony</a>, <a href="http://arxiv.org/find/cs/1/au:+Naeh_I/0/1/0/all/0/1">Itay Naeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05123">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks for video classification, just like image classification
networks, may be subjected to adversarial manipulation. The main difference
between image classifiers and video classifiers is that the latter usually use
temporal information contained within the video. In this work we present a
manipulation scheme for fooling video classifiers by introducing a flickering
temporal perturbation that in some cases may be unnoticeable by human observers
and is implementable in the real world. After demonstrating the manipulation of
action classification of single videos, we generalize the procedure to make
universal adversarial perturbation, achieving high fooling ratio. In addition,
we generalize the universal perturbation and produce a temporal-invariant
perturbation, which can be applied to the video without synchronizing the
perturbation to the input. The attack was implemented on several target models
and the transferability of the attack was demonstrated. These properties allow
us to bridge the gap between simulated environment and real-world application,
as will be demonstrated in this paper for the first time for an over-the-air
flickering attack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DEFT: Detection Embeddings for Tracking. (arXiv:2102.02267v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chaabane_M/0/1/0/all/0/1">Mohamed Chaabane</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1">Peter Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Beveridge_J/0/1/0/all/0/1">J. Ross Beveridge</a>, <a href="http://arxiv.org/find/cs/1/au:+OHara_S/0/1/0/all/0/1">Stephen O&#x27;Hara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02267">
                                    <div class="article-summary-box-inner">
                                        <span>Most modern multiple object tracking (MOT) systems follow the
tracking-by-detection paradigm, consisting of a detector followed by a method
for associating detections into tracks. There is a long history in tracking of
combining motion and appearance features to provide robustness to occlusions
and other challenges, but typically this comes with the trade-off of a more
complex and slower implementation. Recent successes on popular 2D tracking
benchmarks indicate that top-scores can be achieved using a state-of-the-art
detector and relatively simple associations relying on single-frame spatial
offsets -- notably outperforming contemporary methods that leverage learned
appearance features to help re-identify lost tracks. In this paper, we propose
an efficient joint detection and tracking model named DEFT, or &quot;Detection
Embeddings for Tracking.&quot; Our approach relies on an appearance-based object
matching network jointly-learned with an underlying object detection network.
An LSTM is also added to capture motion constraints. DEFT has comparable
accuracy and speed to the top methods on 2D online tracking leaderboards while
having significant advantages in robustness when applied to more challenging
tracking data. DEFT raises the bar on the nuScenes monocular 3D tracking
challenge, more than doubling the performance of the previous top method. Code
is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Middle-level Fusion for Lightweight RGB-D Salient Object Detection. (arXiv:2104.11543v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_N/0/1/0/all/0/1">Nianchang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qiang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jungong Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11543">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing lightweight RGB-D salient object detection (SOD) models are
based on two-stream structure or single-stream structure. The former one first
uses two sub-networks to extract unimodal features from RGB and depth images,
respectively, and then fuses them for SOD. While, the latter one directly
extracts multi-modal features from the input RGB-D images and then focuses on
exploiting cross-level complementary information. However, two-stream structure
based models inevitably require more parameters and single-stream structure
based ones cannot well exploit the cross-modal complementary information since
they ignore the modality difference. To address these issues, we propose to
employ the middle-level fusion structure for designing lightweight RGB-D SOD
model in this paper, which first employs two sub-networks to extract low- and
middle-level unimodal features, respectively, and then fuses those extracted
middle-level unimodal features for extracting corresponding high-level
multi-modal features in the subsequent sub-network. Different from existing
models, this structure can effectively exploit the cross-modal complementary
information and significantly reduce the network&#x27;s parameters, simultaneously.
Therefore, a novel lightweight SOD model is designed, which contains a
information-aware multi-modal feature fusion (IMFF) module for effectively
capturing the cross-modal complementary information and a lightweight
feature-level and decision-level feature fusion (LFDF) module for aggregating
the feature-level and the decision-level saliency information in different
stages with less parameters. Our proposed model has only 3.9M parameters and
runs at 33 FPS. The experimental results on several benchmark datasets verify
the effectiveness and superiority of the proposed method over some
state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real Time Video based Heart and Respiration Rate Monitoring. (arXiv:2106.02669v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pourbemany_J/0/1/0/all/0/1">Jafar Pourbemany</a>, <a href="http://arxiv.org/find/eess/1/au:+Essa_A/0/1/0/all/0/1">Almabrok Essa</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1">Ye Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02669">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, research about monitoring vital signs by smartphones grows
significantly. There are some special sensors like Electrocardiogram (ECG) and
Photoplethysmographic (PPG) to detect heart rate (HR) and respiration rate
(RR). Smartphone cameras also can measure HR by detecting and processing
imaging Photoplethysmographic (iPPG) signals from the video of a user&#x27;s face.
Indeed, the variation in the intensity of the green channel can be measured by
the iPPG signals of the video. This study aimed to provide a method to extract
heart rate and respiration rate using the video of individuals&#x27; faces. The
proposed method is based on measuring fluctuations in the Hue, and can
therefore extract both HR and RR from the video of a user&#x27;s face. The proposed
method is evaluated by performing on 25 healthy individuals. For each subject,
20 seconds video of his/her face is recorded. Results show that the proposed
approach of measuring iPPG using Hue gives more accurate rates than the Green
channel.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RegionViT: Regional-to-Local Attention for Vision Transformers. (arXiv:2106.02689v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chun-Fu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Panda_R/0/1/0/all/0/1">Rameswar Panda</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_Q/0/1/0/all/0/1">Quanfu Fan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02689">
                                    <div class="article-summary-box-inner">
                                        <span>Vision transformer (ViT) has recently showed its strong capability in
achieving comparable results to convolutional neural networks (CNNs) on image
classification. However, vanilla ViT simply inherits the same architecture from
the natural language processing directly, which is often not optimized for
vision applications. Motivated by this, in this paper, we propose a new
architecture that adopts the pyramid structure and employ a novel
regional-to-local attention rather than global self-attention in vision
transformers. More specifically, our model first generates regional tokens and
local tokens from an image with different patch sizes, where each regional
token is associated with a set of local tokens based on the spatial location.
The regional-to-local attention includes two steps: first, the regional
self-attention extract global information among all regional tokens and then
the local self-attention exchanges the information among one regional token and
the associated local tokens via self-attention. Therefore, even though local
self-attention confines the scope in a local region but it can still receive
global information. Extensive experiments on three vision tasks, including
image classification, object detection and action recognition, show that our
approach outperforms or is on par with state-of-the-art ViT variants including
many concurrent works. Our source codes and models will be publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging the Gap Between Adversarial Robustness and Optimization Bias. (arXiv:2102.08868v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1">Fartash Faghri</a>, <a href="http://arxiv.org/find/cs/1/au:+Gowal_S/0/1/0/all/0/1">Sven Gowal</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1">Cristina Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1">David J. Fleet</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedregosa_F/0/1/0/all/0/1">Fabian Pedregosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08868">
                                    <div class="article-summary-box-inner">
                                        <span>We demonstrate that the choice of optimizer, neural network architecture, and
regularizer significantly affect the adversarial robustness of linear neural
networks, providing guarantees without the need for adversarial training. To
this end, we revisit a known result linking maximally robust classifiers and
minimum norm solutions, and combine it with recent results on the implicit bias
of optimizers. First, we show that, under certain conditions, it is possible to
achieve both perfect standard accuracy and a certain degree of robustness,
simply by training an overparametrized model using the implicit bias of the
optimization. In that regime, there is a direct relationship between the type
of the optimizer and the attack to which the model is robust. To the best of
our knowledge, this work is the first to study the impact of optimization
methods such as sign gradient descent and proximal methods on adversarial
robustness. Second, we characterize the robustness of linear convolutional
models, showing that they resist attacks subject to a constraint on the
Fourier-$\ell_\infty$ norm. To illustrate these findings we design a novel
Fourier-$\ell_\infty$ attack that finds adversarial examples with controllable
frequencies. We evaluate Fourier-$\ell_\infty$ robustness of
adversarially-trained deep CIFAR-10 models from the standard RobustBench
benchmark and visualize adversarial perturbations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascaded Context Enhancement Network for Automatic Skin Lesion Segmentation. (arXiv:2004.08107v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_R/0/1/0/all/0/1">Ruxin Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_S/0/1/0/all/0/1">Shuyuan Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Ji_C/0/1/0/all/0/1">Chaojie Ji</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Ye Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.08107">
                                    <div class="article-summary-box-inner">
                                        <span>Skin lesion segmentation is an important step for automatic melanoma
diagnosis. Due to the non-negligible diversity of lesions from different
patients, extracting powerful context for fine-grained semantic segmentation is
still challenging today. Although the deep convolutional neural network (CNNs)
have made significant improvements on skin lesion segmentation, they often fail
to reserve the spatial details and long-range dependencies context due to
consecutive convolution striding and pooling operations inside CNNs. In this
paper, we formulate a cascaded context enhancement neural network for automatic
skin lesion segmentation. A new cascaded context aggregation (CCA) module with
a gate-based information integration approach is proposed to sequentially and
selectively aggregate original image and multi-level features from the encoder
sub-network. The generated context is further utilized to guide discriminative
features extraction by the designed context-guided local affinity (CGL) module.
Furthermore, an auxiliary loss is added to the CCA module for refining the
prediction. In our work, we evaluate our approach on four public skin
dermoscopy image datasets. The proposed method achieves the Jaccard Index (JA)
of 87.1%, 80.3%, 83.4%, and 86.6% on ISIC-2016, ISIC-2017, ISIC-2018, and PH2
datasets, which are higher than other state-of-the-art models respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Learning by Self-Transition for Handling Noisy Labels. (arXiv:2012.04337v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Hwanjun Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minseok Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dongmin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1">Yooju Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jae-Gil Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04337">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world data inevitably contains noisy labels, which induce the poor
generalization of deep neural networks. It is known that the network typically
begins to rapidly memorize false-labeled samples after a certain point of
training. Thus, to counter the label noise challenge, we propose a novel
self-transitional learning method called MORPH, which automatically switches
its learning phase at the transition point from seeding to evolution. In the
seeding phase, the network is updated using all the samples to collect a seed
of clean samples. Then, in the evolution phase, the network is updated using
only the set of arguably clean samples, which precisely keeps expanding by the
updated network. Thus, MORPH effectively avoids the overfitting to
false-labeled samples throughout the entire training period. Extensive
experiments using five real-world or synthetic benchmark datasets demonstrate
substantial improvements over state-of-the-art methods in terms of robustness
and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Facial Image Deformation Based on Landmark Detection. (arXiv:1910.13671v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chaoyue Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yugang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shulai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1">Bingbing Ni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1910.13671">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we use facial landmarks to make the deformation for facial
images more authentic. The deformation includes the expansion of eyes and the
shrinking of noses, mouths, and cheeks. An advanced 106-point facial landmark
detector is utilized to provide control points for deformation. Bilinear
interpolation is used in the expansion and Moving Least Squares methods (MLS)
including Affine Deformation, Similarity Deformation and Rigid Deformation are
used in the shrinking. We compare the running time as well as the quality of
deformed images using different MLS methods. The experimental results show that
the Rigid Deformation which can keep other parts of the images unchanged
performs better even if it takes the longest time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Human Mesh Regression with Dense Correspondence. (arXiv:2006.05734v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ouyang_W/0/1/0/all/0/1">Wanli Ouyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wentao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaogang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05734">
                                    <div class="article-summary-box-inner">
                                        <span>Estimating 3D mesh of the human body from a single 2D image is an important
task with many applications such as augmented reality and Human-Robot
interaction. However, prior works reconstructed 3D mesh from global image
feature extracted by using convolutional neural network (CNN), where the dense
correspondences between the mesh surface and the image pixels are missing,
leading to suboptimal solution. This paper proposes a model-free 3D human mesh
estimation framework, named DecoMR, which explicitly establishes the dense
correspondence between the mesh and the local image features in the UV space
(i.e. a 2D space used for texture mapping of 3D mesh). DecoMR first predicts
pixel-to-surface dense correspondence map (i.e., IUV image), with which we
transfer local features from the image space to the UV space. Then the
transferred local image features are processed in the UV space to regress a
location map, which is well aligned with transferred features. Finally we
reconstruct 3D human mesh from the regressed location map with a predefined
mapping function. We also observe that the existing discontinuous UV map are
unfriendly to the learning of network. Therefore, we propose a novel UV map
that maintains most of the neighboring relations on the original mesh surface.
Experiments demonstrate that our proposed local feature alignment and
continuous UV map outperforms existing 3D mesh based methods on multiple public
benchmarks. Code will be made available at
https://github.com/zengwang430521/DecoMR</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Temporal Graph Neural Network for Trajectory Prediction. (arXiv:2106.02930v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1">Defu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hengbo Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1">Masayoshi Tomizuka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02930">
                                    <div class="article-summary-box-inner">
                                        <span>An effective understanding of the contextual environment and accurate motion
forecasting of surrounding agents is crucial for the development of autonomous
vehicles and social mobile robots. This task is challenging since the behavior
of an autonomous agent is not only affected by its own intention, but also by
the static environment and surrounding dynamically interacting agents. Previous
works focused on utilizing the spatial and temporal information in time domain
while not sufficiently taking advantage of the cues in frequency domain. To
this end, we propose a Spectral Temporal Graph Neural Network (SpecTGNN), which
can capture inter-agent correlations and temporal dependency simultaneously in
frequency domain in addition to time domain. SpecTGNN operates on both an agent
graph with dynamic state information and an environment graph with the features
extracted from context images in two streams. The model integrates graph
Fourier transform, spectral graph convolution and temporal gated convolution to
encode history information and forecast future trajectories. Moreover, we
incorporate a multi-head spatio-temporal attention mechanism to mitigate the
effect of error propagation in a long time horizon. We demonstrate the
performance of SpecTGNN on two public trajectory prediction benchmark datasets,
which achieves state-of-the-art performance in terms of prediction accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FS-Net: Fast Shape-based Network for Category-Level 6D Object Pose Estimation with Decoupled Rotation Mechanism. (arXiv:2103.07054v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1">Xi Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1">Hyung Jin Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Duan_J/0/1/0/all/0/1">Jinming Duan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Linlin Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonardis_A/0/1/0/all/0/1">Ales Leonardis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07054">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we focus on category-level 6D pose and size estimation from
monocular RGB-D image. Previous methods suffer from inefficient category-level
pose feature extraction which leads to low accuracy and inference speed. To
tackle this problem, we propose a fast shape-based network (FS-Net) with
efficient category-level feature extraction for 6D pose estimation. First, we
design an orientation aware autoencoder with 3D graph convolution for latent
feature extraction. The learned latent feature is insensitive to point shift
and object size thanks to the shift and scale-invariance properties of the 3D
graph convolution. Then, to efficiently decode category-level rotation
information from the latent feature, we propose a novel decoupled rotation
mechanism that employs two decoders to complementarily access the rotation
information. Meanwhile, we estimate translation and size by two residuals,
which are the difference between the mean of object points and ground truth
translation, and the difference between the mean size of the category and
ground truth size, respectively. Finally, to increase the generalization
ability of FS-Net, we propose an online box-cage based 3D deformation mechanism
to augment the training data. Extensive experiments on two benchmark datasets
show that the proposed method achieves state-of-the-art performance in both
category- and instance-level 6D object pose estimation. Especially in
category-level pose estimation, without extra synthetic data, our method
outperforms existing methods by 6.3% on the NOCS-REAL dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guidance and Teaching Network for Video Salient Object Detection. (arXiv:2105.10110v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiao_Y/0/1/0/all/0/1">Yingxia Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chou_Y/0/1/0/all/0/1">Yu-Cheng Chou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shouyuan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1">Ge-Peng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_R/0/1/0/all/0/1">Rong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_G/0/1/0/all/0/1">Ge Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10110">
                                    <div class="article-summary-box-inner">
                                        <span>Owing to the difficulties of mining spatial-temporal cues, the existing
approaches for video salient object detection (VSOD) are limited in
understanding complex and noisy scenarios, and often fail in inferring
prominent objects. To alleviate such shortcomings, we propose a simple yet
efficient architecture, termed Guidance and Teaching Network (GTNet), to
independently distil effective spatial and temporal cues with implicit guidance
and explicit teaching at feature- and decision-level, respectively. To be
specific, we (a) introduce a temporal modulator to implicitly bridge features
from motion into the appearance branch, which is capable of fusing cross-modal
features collaboratively, and (b) utilise motion-guided mask to propagate the
explicit cues during the feature aggregation. This novel learning strategy
achieves satisfactory results via decoupling the complex spatial-temporal cues
and mapping informative cues across different modalities. Extensive experiments
on three challenging benchmarks show that the proposed method can run at ~28
fps on a single TITAN Xp GPU and perform competitively against 14 cutting-edge
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end Prostate Cancer Detection in bpMRI via 3D CNNs: Effects of Attention Mechanisms, Clinical Priori and Decoupled False Positive Reduction. (arXiv:2101.03244v8 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Saha_A/0/1/0/all/0/1">Anindo Saha</a>, <a href="http://arxiv.org/find/eess/1/au:+Hosseinzadeh_M/0/1/0/all/0/1">Matin Hosseinzadeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Huisman_H/0/1/0/all/0/1">Henkjan Huisman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.03244">
                                    <div class="article-summary-box-inner">
                                        <span>We present a multi-stage 3D computer-aided detection and diagnosis (CAD)
model for automated localization of clinically significant prostate cancer
(csPCa) in bi-parametric MR imaging (bpMRI). Deep attention mechanisms drive
its detection network, targeting salient structures and highly discriminative
feature dimensions across multiple resolutions. Its goal is to accurately
identify csPCa lesions from indolent cancer and the wide range of benign
pathology that can afflict the prostate gland. Simultaneously, a decoupled
residual classifier is used to achieve consistent false positive reduction,
without sacrificing high sensitivity or computational efficiency. In order to
guide model generalization with domain-specific clinical knowledge, a
probabilistic anatomical prior is used to encode the spatial prevalence and
zonal distinction of csPCa. Using a large dataset of 1950 prostate bpMRI paired
with radiologically-estimated annotations, we hypothesize that such CNN-based
models can be trained to detect biopsy-confirmed malignancies in an independent
cohort.

For 486 institutional testing scans, the 3D CAD system achieves
83.69$\pm$5.22% and 93.19$\pm$2.96% detection sensitivity at 0.50 and 1.46
false positive(s) per patient, respectively, with 0.882$\pm$0.030 AUROC in
patient-based diagnosis $-$significantly outperforming four state-of-the-art
baseline architectures (U-SEResNet, UNet++, nnU-Net, Attention U-Net) from
recent literature. For 296 external biopsy-confirmed testing scans, the
ensembled CAD system shares moderate agreement with a consensus of expert
radiologists (76.69%; $kappa$ $&#x3D;$ 0.51$\pm$0.04) and independent pathologists
(81.08%; $kappa$ $&#x3D;$ 0.56$\pm$0.06); demonstrating strong generalization to
histologically-confirmed csPCa diagnosis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Segmentation Learning from Sparse Annotations and Hierarchical Descriptors. (arXiv:2105.12885v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1">Peng Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lingyun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_J/0/1/0/all/0/1">Jianmin Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Scherer_S/0/1/0/all/0/1">Sebastian Scherer</a>, <a href="http://arxiv.org/find/cs/1/au:+Choset_H/0/1/0/all/0/1">Howie Choset</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12885">
                                    <div class="article-summary-box-inner">
                                        <span>One of the main obstacles to 3D semantic segmentation is the significant
amount of endeavor required to generate expensive point-wise annotations for
fully supervised training. To alleviate manual efforts, we propose GIDSeg, a
novel approach that can simultaneously learn segmentation from sparse
annotations via reasoning global-regional structures and individual-vicinal
properties. GIDSeg depicts global- and individual- relation via a dynamic edge
convolution network coupled with a kernelized identity descriptor. The ensemble
effects are obtained by endowing a fine-grained receptive field to a
low-resolution voxelized map. In our GIDSeg, an adversarial learning module is
also designed to further enhance the conditional constraint of identity
descriptors within the joint feature distribution. Despite the apparent
simplicity, our proposed approach achieves superior performance over
state-of-the-art for inferencing 3D dense segmentation with only sparse
annotations. Particularly, with $5\%$ annotations of raw data, GIDSeg
outperforms other 3D segmentation methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pinball-OCSVM for early-stage COVID-19 diagnosis with limited posteroanterior chest X-ray images. (arXiv:2010.08115v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sonbhadra_S/0/1/0/all/0/1">Sanjay Kumar Sonbhadra</a>, <a href="http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1">Sonali Agarwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Nagabhushan_P/0/1/0/all/0/1">P. Nagabhushan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08115">
                                    <div class="article-summary-box-inner">
                                        <span>The infection of respiratory coronavirus disease 2019 (COVID-19) starts with
the upper respiratory tract and as the virus grows, the infection can progress
to lungs and develop pneumonia. The conventional way of COVID-19 diagnosis is
reverse transcription polymerase chain reaction (RT-PCR), which is less
sensitive during early stages; especially if the patient is asymptomatic, which
may further cause more severe pneumonia. In this context, several deep learning
models have been proposed to identify pulmonary infections using publicly
available chest X-ray (CXR) image datasets for early diagnosis, better
treatment and quick cure. In these datasets, presence of less number of
COVID-19 positive samples compared to other classes (normal, pneumonia and
Tuberculosis) raises the challenge for unbiased learning of deep learning
models. All deep learning models opted class balancing techniques to solve this
issue; which however should be avoided in any medical diagnosis process.
Moreover, the deep learning models are also data hungry and need massive
computation resources. Therefore for quicker diagnosis, this research proposes
a novel pinball loss function based one-class support vector machine
(PB-OCSVM), that can work in presence of limited COVID-19 positive CXR samples
with objectives to maximize the learning efficiency and to minimize the false
predictions. The performance of the proposed model is compared with
conventional OCSVM and existing deep learning models, and the experimental
results prove that the proposed model outperformed over state-of-the-art
methods. To validate the robustness of the proposed model, experiments are also
performed with noisy CXR images and UCI benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TARA: Training and Representation Alteration for AI Fairness and Domain Generalization. (arXiv:2012.06387v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1">William Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadzic_A/0/1/0/all/0/1">Armin Hadzic</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1">Neil Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1">Fady Alajaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1">Phil Burlina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06387">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel method for enforcing AI fairness with respect to protected
or sensitive factors. This method uses a dual strategy performing training and
representation alteration (TARA) for the mitigation of prominent causes of AI
bias by including: a) the use of representation learning alteration via
adversarial independence to suppress the bias-inducing dependence of the data
representation from protected factors; and b) training set alteration via
intelligent augmentation to address bias-causing data imbalance, by using
generative models that allow the fine control of sensitive factors related to
underrepresented populations via domain adaptation and latent space
manipulation. When testing our methods on image analytics, experiments
demonstrate that TARA significantly or fully debiases baseline models while
outperforming competing debiasing methods that have the same amount of
information, e.g., with (% overall accuracy, % accuracy gap) &#x3D; (78.8, 0.5) vs.
the baseline method&#x27;s score of (71.8, 10.5) for EyePACS, and (73.7, 11.8) vs.
(69.1, 21.7) for CelebA. Furthermore, recognizing certain limitations in
current metrics used for assessing debiasing performance, we propose novel
conjunctive debiasing metrics. Our experiments also demonstrate the ability of
these novel metrics in assessing the Pareto efficiency of the proposed methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An End-to-End Breast Tumour Classification Model Using Context-Based Patch Modelling- A BiLSTM Approach for Image Classification. (arXiv:2106.02864v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1">Suvidha Tripathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Satish Kumar Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hwee Kuan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02864">
                                    <div class="article-summary-box-inner">
                                        <span>Researchers working on computational analysis of Whole Slide Images (WSIs) in
histopathology have primarily resorted to patch-based modelling due to large
resolution of each WSI. The large resolution makes WSIs infeasible to be fed
directly into the machine learning models due to computational constraints.
However, due to patch-based analysis, most of the current methods fail to
exploit the underlying spatial relationship among the patches. In our work, we
have tried to integrate this relationship along with feature-based correlation
among the extracted patches from the particular tumorous region. For the given
task of classification, we have used BiLSTMs to model both forward and backward
contextual relationship. RNN based models eliminate the limitation of sequence
size by allowing the modelling of variable size images within a deep learning
model. We have also incorporated the effect of spatial continuity by exploring
different scanning techniques used to sample patches. To establish the
efficiency of our approach, we trained and tested our model on two datasets,
microscopy images and WSI tumour regions. After comparing with contemporary
literature we achieved the better performance with accuracy of 90% for
microscopy image dataset. For WSI tumour region dataset, we compared the
classification results with deep learning networks such as ResNet, DenseNet,
and InceptionV3 using maximum voting technique. We achieved the highest
performance accuracy of 84%. We found out that BiLSTMs with CNN features have
performed much better in modelling patches into an end-to-end Image
classification network. Additionally, the variable dimensions of WSI tumour
regions were used for classification without the need for resizing. This
suggests that our method is independent of tumour image size and can process
large dimensional images without losing the resolution details.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring Model Biases in the Absence of Ground Truth. (arXiv:2103.03417v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aka_O/0/1/0/all/0/1">Osman Aka</a>, <a href="http://arxiv.org/find/cs/1/au:+Burke_K/0/1/0/all/0/1">Ken Burke</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauerle_A/0/1/0/all/0/1">Alex B&#xe4;uerle</a>, <a href="http://arxiv.org/find/cs/1/au:+Greer_C/0/1/0/all/0/1">Christina Greer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1">Margaret Mitchell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03417">
                                    <div class="article-summary-box-inner">
                                        <span>The measurement of bias in machine learning often focuses on model
performance across identity subgroups (such as man and woman) with respect to
groundtruth labels. However, these methods do not directly measure the
associations that a model may have learned, for example between labels and
identity subgroups. Further, measuring a model&#x27;s bias requires a fully
annotated evaluation dataset which may not be easily available in practice. We
present an elegant mathematical solution that tackles both issues
simultaneously, using image classification as a working example. By treating a
classification model&#x27;s predictions for a given image as a set of labels
analogous to a bag of words, we rank the biases that a model has learned with
respect to different identity labels. We use (man, woman) as a concrete example
of an identity label set (although this set need not be binary), and present
rankings for the labels that are most biased towards one identity or the other.
We demonstrate how the statistical properties of different association metrics
can lead to different rankings of the most &quot;gender biased&quot; labels, and conclude
that normalized pointwise mutual information (nPMI) is most useful in practice.
Finally, we announce an open-sourced nPMI visualization tool using TensorBoard.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ZeroWaste Dataset: Towards Automated Waste Recycling. (arXiv:2106.02740v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bashkirova_D/0/1/0/all/0/1">Dina Bashkirova</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Ziliang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Akl_J/0/1/0/all/0/1">James Akl</a>, <a href="http://arxiv.org/find/cs/1/au:+Alladkani_F/0/1/0/all/0/1">Fadi Alladkani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_P/0/1/0/all/0/1">Ping Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ablavsky_V/0/1/0/all/0/1">Vitaly Ablavsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Calli_B/0/1/0/all/0/1">Berk Calli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bargal_S/0/1/0/all/0/1">Sarah Adel Bargal</a>, <a href="http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1">Kate Saenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02740">
                                    <div class="article-summary-box-inner">
                                        <span>Less than 35% of recyclable waste is being actually recycled in the US, which
leads to increased soil and sea pollution and is one of the major concerns of
environmental researchers as well as the common public. At the heart of the
problem is the inefficiencies of the waste sorting process (separating paper,
plastic, metal, glass, etc.) due to the extremely complex and cluttered nature
of the waste stream. Automated waste detection strategies have a great
potential to enable more efficient, reliable and safer waste sorting practices,
but the literature lacks comprehensive datasets and methodology for the
industrial waste sorting solutions. In this paper, we take a step towards
computer-aided waste detection and present the first in-the-wild
industrial-grade waste detection and segmentation dataset, ZeroWaste. This
dataset contains over1800fully segmented video frames collected from a real
waste sorting plant along with waste material labels for training and
evaluation of the segmentation methods, as well as over6000unlabeled frames
that can be further used for semi-supervised and self-supervised learning
techniques. ZeroWaste also provides frames of the conveyor belt before and
after the sorting process, comprising a novel setup that can be used for
weakly-supervised segmentation. We present baselines for fully-, semi- and
weakly-supervised segmentation methods. Our experimental results demonstrate
that state-of-the-art segmentation methods struggle to correctly detect and
classify target objects which suggests the challenging nature of our proposed
in-the-wild dataset. We believe that ZeroWastewill catalyze research in object
detection and semantic segmentation in extreme clutter as well as applications
in the recycling domain. Our project page can be found
atthis http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RDA: Robust Domain Adaptation via Fourier Adversarial Attacking. (arXiv:2106.02874v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiaxing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1">Dayan Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">Aoran Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02874">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised domain adaptation (UDA) involves a supervised loss in a labeled
source domain and an unsupervised loss in an unlabeled target domain, which
often faces more severe overfitting (than classical supervised learning) as the
supervised source loss has clear domain gap and the unsupervised target loss is
often noisy due to the lack of annotations. This paper presents RDA, a robust
domain adaptation technique that introduces adversarial attacking to mitigate
overfitting in UDA. We achieve robust domain adaptation by a novel Fourier
adversarial attacking (FAA) method that allows large magnitude of perturbation
noises but has minimal modification of image semantics, the former is critical
to the effectiveness of its generated adversarial samples due to the existence
of &#x27;domain gaps&#x27;. Specifically, FAA decomposes images into multiple frequency
components (FCs) and generates adversarial samples by just perturbating certain
FCs that capture little semantic information. With FAA-generated samples, the
training can continue the &#x27;random walk&#x27; and drift into an area with a flat loss
landscape, leading to more robust domain adaptation. Extensive experiments over
multiple domain adaptation tasks show that RDA can work with different computer
vision tasks with superior performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Radar-Camera Pixel Depth Association for Depth Completion. (arXiv:2106.02778v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1">Yunfei Long</a>, <a href="http://arxiv.org/find/cs/1/au:+Morris_D/0/1/0/all/0/1">Daniel Morris</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaoming Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Castro_M/0/1/0/all/0/1">Marcos Castro</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravarty_P/0/1/0/all/0/1">Punarjay Chakravarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Narayanan_P/0/1/0/all/0/1">Praveen Narayanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02778">
                                    <div class="article-summary-box-inner">
                                        <span>While radar and video data can be readily fused at the detection level,
fusing them at the pixel level is potentially more beneficial. This is also
more challenging in part due to the sparsity of radar, but also because
automotive radar beams are much wider than a typical pixel combined with a
large baseline between camera and radar, which results in poor association
between radar pixels and color pixel. A consequence is that depth completion
methods designed for LiDAR and video fare poorly for radar and video. Here we
propose a radar-to-pixel association stage which learns a mapping from radar
returns to pixels. This mapping also serves to densify radar returns. Using
this as a first stage, followed by a more traditional depth completion method,
we are able to achieve image-guided depth completion with radar and video. We
demonstrate performance superior to camera and radar alone on the nuScenes
dataset. Our source code is available at https://github.com/longyunf/rc-pda.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Domain Adaptation via Adaptive and Progressive Feature Alignment. (arXiv:2106.02845v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiaxing Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_D/0/1/0/all/0/1">Dayan Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_A/0/1/0/all/0/1">Aoran Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Shijian Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02845">
                                    <div class="article-summary-box-inner">
                                        <span>Contemporary domain adaptive semantic segmentation aims to address data
annotation challenges by assuming that target domains are completely
unannotated. However, annotating a few target samples is usually very
manageable and worthwhile especially if it improves the adaptation performance
substantially. This paper presents SSDAS, a Semi-Supervised Domain Adaptive
image Segmentation network that employs a few labeled target samples as anchors
for adaptive and progressive feature alignment between labeled source samples
and unlabeled target samples. We position the few labeled target samples as
references that gauge the similarity between source and target features and
guide adaptive inter-domain alignment for learning more similar source
features. In addition, we replace the dissimilar source features by
high-confidence target features continuously during the iterative training
process, which achieves progressive intra-domain alignment between confident
and unconfident target features. Extensive experiments show the proposed SSDAS
greatly outperforms a number of baselines, i.e., UDA-based semantic
segmentation and SSDA-based image classification. In addition, SSDAS is
complementary and can be easily incorporated into UDA-based methods with
consistent improvements in domain adaptive semantic segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Making CNNs Interpretable by Building Dynamic Sequential Decision Forests with Top-down Hierarchy Learning. (arXiv:2106.02824v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yilin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shaozuo Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaokang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">Wei Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02824">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a generic model transfer scheme to make
Convlutional Neural Networks (CNNs) interpretable, while maintaining their high
classification accuracy. We achieve this by building a differentiable decision
forest on top of CNNs, which enjoys two characteristics: 1) During training,
the tree hierarchies of the forest are learned in a top-down manner under the
guidance from the category semantics embedded in the pre-trained CNN weights;
2) During inference, a single decision tree is dynamically selected from the
forest for each input sample, enabling the transferred model to make sequential
decisions corresponding to the attributes shared by semantically-similar
categories, rather than directly performing flat classification. We name the
transferred model deep Dynamic Sequential Decision Forest (dDSDF). Experimental
results show that dDSDF not only achieves higher classification accuracy than
its conuterpart, i.e., the original CNN, but has much better interpretability,
as qualitatively it has plausible hierarchies and quantitatively it leads to
more precise saliency maps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SketchGen: Generating Constrained CAD Sketches. (arXiv:2106.02711v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Para_W/0/1/0/all/0/1">Wamiq Reyaz Para</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1">Shariq Farooq Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerrero_P/0/1/0/all/0/1">Paul Guerrero</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelly_T/0/1/0/all/0/1">Tom Kelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1">Niloy Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas Guibas</a>, <a href="http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1">Peter Wonka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02711">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-aided design (CAD) is the most widely used modeling approach for
technical design. The typical starting point in these designs is 2D sketches
which can later be extruded and combined to obtain complex three-dimensional
assemblies. Such sketches are typically composed of parametric primitives, such
as points, lines, and circular arcs, augmented with geometric constraints
linking the primitives, such as coincidence, parallelism, or orthogonality.
Sketches can be represented as graphs, with the primitives as nodes and the
constraints as edges. Training a model to automatically generate CAD sketches
can enable several novel workflows, but is challenging due to the complexity of
the graphs and the heterogeneity of the primitives and constraints. In
particular, each type of primitive and constraint may require a record of
different size and parameter types. We propose SketchGen as a generative model
based on a transformer architecture to address the heterogeneity problem by
carefully designing a sequential language for the primitives and constraints
that allows distinguishing between different primitive or constraint types and
their parameters, while encouraging our model to re-use information across
related parameters, encoding shared structure. A particular highlight of our
work is the ability to produce primitives linked via constraints that enables
the final output to be further regularized via a constraint solver. We evaluate
our model by demonstrating constraint prediction for given sets of primitives
and full sketch generation from scratch, showing that our approach
significantly out performs the state-of-the-art in CAD sketch generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Camera Vehicle Counting Using Edge-AI. (arXiv:2106.02842v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ciampi_L/0/1/0/all/0/1">Luca Ciampi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gennaro_C/0/1/0/all/0/1">Claudio Gennaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Carrara_F/0/1/0/all/0/1">Fabio Carrara</a>, <a href="http://arxiv.org/find/cs/1/au:+Falchi_F/0/1/0/all/0/1">Fabrizio Falchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vairo_C/0/1/0/all/0/1">Claudio Vairo</a>, <a href="http://arxiv.org/find/cs/1/au:+Amato_G/0/1/0/all/0/1">Giuseppe Amato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02842">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel solution to automatically count vehicles in a
parking lot using images captured by smart cameras. Unlike most of the
literature on this task, which focuses on the analysis of single images, this
paper proposes the use of multiple visual sources to monitor a wider parking
area from different perspectives. The proposed multi-camera system is capable
of automatically estimate the number of cars present in the entire parking lot
directly on board the edge devices. It comprises an on-device deep
learning-based detector that locates and counts the vehicles from the captured
images and a decentralized geometric-based approach that can analyze the
inter-camera shared areas and merge the data acquired by all the devices. We
conduct the experimental evaluation on an extended version of the CNRPark-EXT
dataset, a collection of images taken from the parking lot on the campus of the
National Research Council (CNR) in Pisa, Italy. We show that our system is
robust and takes advantage of the redundant information deriving from the
different cameras, improving the overall performance without requiring any
extra geometrical information of the monitored scene.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DISCO: accurate Discrete Scale Convolutions. (arXiv:2106.02733v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sosnovik_I/0/1/0/all/0/1">Ivan Sosnovik</a>, <a href="http://arxiv.org/find/cs/1/au:+Moskalev_A/0/1/0/all/0/1">Artem Moskalev</a>, <a href="http://arxiv.org/find/cs/1/au:+Smeulders_A/0/1/0/all/0/1">Arnold Smeulders</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02733">
                                    <div class="article-summary-box-inner">
                                        <span>Scale is often seen as a given, disturbing factor in many vision tasks. When
doing so it is one of the factors why we need more data during learning. In
recent work scale equivariance was added to convolutional neural networks. It
was shown to be effective for a range of tasks. We aim for accurate
scale-equivariant convolutional neural networks (SE-CNNs) applicable for
problems where high granularity of scale and small filter sizes are required.
Current SE-CNNs rely on weight sharing and filter rescaling, the latter of
which is accurate for integer scales only. To reach accurate scale
equivariance, we derive general constraints under which scale-convolution
remains equivariant to discrete rescaling. We find the exact solution for all
cases where it exists, and compute the approximation for the rest. The discrete
scale-convolution pays off, as demonstrated in a new state-of-the-art
classification on MNIST-scale and improving the results on STL-10. With the
same SE scheme, we also improve the computational effort of a scale-equivariant
Siamese tracker on OTB-13.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GLSD: The Global Large-Scale Ship Database and Baseline Evaluations. (arXiv:2106.02773v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhenfeng Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jiaming Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_L/0/1/0/all/0/1">Lianbing Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1">Tao Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruiqian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1">Xianwei Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_Q/0/1/0/all/0/1">Qing Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhiqiang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02773">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce a challenging global large-scale ship database
(called GLSD), designed specifically for ship detection tasks. The designed
GLSD database includes a total of 140,616 annotated instances from 100,729
images. Based on the collected images, we propose 13 categories that widely
exists in international routes. These categories include sailing boat, fishing
boat, passenger ship, war ship, general cargo ship, container ship, bulk cargo
carrier, barge, ore carrier, speed boat, canoe, oil carrier, and tug. The
motivations of developing GLSD include the following: 1) providing a refined
ship detection database; 2) providing the worldwide researchers of ship
detection and exhaustive label information (bounding box and ship class label)
in one uniform global database; and 3) providing a large-scale ship database
with geographic information (port and country information) that benefits
multi-modal analysis. In addition, we discuss the evaluation protocols given
image characteristics in GLSD and analyze the performance of selected
state-of-the-art object detection algorithms on GSLD, providing baselines for
future studies. More information regarding the designed GLSD can be found at
https://github.com/jiaming-wang/GLSD.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NewsEmbed: Modeling News through Pre-trained Document Representations. (arXiv:2106.00590v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00590">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively modeling text-rich fresh content such as news articles at
document-level is a challenging problem. To ensure a content-based model
generalize well to a broad range of applications, it is critical to have a
training dataset that is large beyond the scale of human labels while achieving
desired quality. In this work, we address those two challenges by proposing a
novel approach to mine semantically-relevant fresh documents, and their topic
labels, with little human supervision. Meanwhile, we design a multitask model
called NewsEmbed that alternatively trains a contrastive learning with a
multi-label classification to derive a universal document encoder. We show that
the proposed approach can provide billions of high quality organic training
examples and can be naturally extended to multilingual setting where texts in
different languages are encoded in the same semantic space. We experimentally
demonstrate NewsEmbed&#x27;s competitive performance across multiple natural
language understanding tasks, both supervised and unsupervised.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Relation Alignment for Calibrated Cross-modal Retrieval. (arXiv:2105.13868v2 [cs.CL] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1">Shuhuai Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1">Junyang Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1">Guangxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Men_R/0/1/0/all/0/1">Rui Men</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_A/0/1/0/all/0/1">An Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13868">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the achievements of large-scale multimodal pre-training approaches,
cross-modal retrieval, e.g., image-text retrieval, remains a challenging task.
To bridge the semantic gap between the two modalities, previous studies mainly
focus on word-region alignment at the object level, lacking the matching
between the linguistic relation among the words and the visual relation among
the regions. The neglect of such relation consistency impairs the
contextualized representation of image-text pairs and hinders the model
performance and the interpretability. In this paper, we first propose a novel
metric, Intra-modal Self-attention Distance (ISD), to quantify the relation
consistency by measuring the semantic distance between linguistic and visual
relations. In response, we present Inter-modal Alignment on Intra-modal
Self-attentions (IAIS), a regularized training method to optimize the ISD and
calibrate intra-modal self-attentions from the two modalities mutually via
inter-modal alignment. The IAIS regularizer boosts the performance of
prevailing models on Flickr30k and MS COCO datasets by a considerable margin,
which demonstrates the superiority of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalized Transformer for Explainable Recommendation. (arXiv:2105.11601v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfeng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11601">
                                    <div class="article-summary-box-inner">
                                        <span>Personalization of natural language generation plays a vital role in a large
spectrum of tasks, such as explainable recommendation, review summarization and
dialog systems. In these tasks, user and item IDs are important identifiers for
personalization. Transformer, which is demonstrated with strong language
modeling capability, however, is not personalized and fails to make use of the
user and item IDs since the ID tokens are not even in the same semantic space
as the words. To address this problem, we present a PErsonalized Transformer
for Explainable Recommendation (PETER), on which we design a simple and
effective learning objective that utilizes the IDs to predict the words in the
target explanation, so as to endow the IDs with linguistic meanings and to
achieve personalized Transformer. Besides generating explanations, PETER can
also make recommendations, which makes it a unified model for the whole
recommendation-explanation pipeline. Extensive experiments show that our small
unpretrained model outperforms fine-tuned BERT on the generation task, in terms
of both effectiveness and efficiency, which highlights the importance and the
nice utility of our design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-Fine Entity Representations for Document-level Relation Extraction. (arXiv:2012.02507v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1">Damai Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jing Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1">Shuang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1">Baobao Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1">Zhifang Sui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02507">
                                    <div class="article-summary-box-inner">
                                        <span>Document-level Relation Extraction (RE) requires extracting relations
expressed within and across sentences. Recent works show that graph-based
methods, usually constructing a document-level graph that captures
document-aware interactions, can obtain useful entity representations thus
helping tackle document-level RE. These methods either focus more on the entire
graph, or pay more attention to a part of the graph, e.g., paths between the
target entity pair. However, we find that document-level RE may benefit from
focusing on both of them simultaneously. Therefore, to obtain more
comprehensive entity representations, we propose the Coarse-to-Fine Entity
Representation model (CFER) that adopts a coarse-to-fine strategy involving two
phases. First, CFER uses graph neural networks to integrate global information
in the entire graph at a coarse level. Next, CFER utilizes the global
information as a guidance to selectively aggregate path information between the
target entity pair at a fine level. In classification, we combine the entity
representations from both two levels into more comprehensive representations
for relation extraction. Experimental results on two document-level RE
datasets, DocRED and CDR, show that CFER outperforms existing models and is
robust to the uneven label distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A novel method for recommendation systems using invasive weed optimization. (arXiv:2106.02831v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soltaninejad_F/0/1/0/all/0/1">Fahimeh Soltaninejad</a>, <a href="http://arxiv.org/find/cs/1/au:+Bidgoly_A/0/1/0/all/0/1">Amir Jalaly Bidgoly</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02831">
                                    <div class="article-summary-box-inner">
                                        <span>One of the popular approaches in recommendation systems is Collaborative
Filtering (CF). The most significant step in CF is choosing the appropriate set
of users. For this purpose, similarity measures are usually used for computing
the similarity between a specific user and the other users. This paper proposes
a new invasive weed optimization (IWO) based CF approach that uses users&#x27;
context to identify important and effective users set. By using a newly defined
similarity measure based on both rating values and a measure values called
confidence, the proposed approach calculates the similarity between users and
thus identifies and filters the most similar users to a specific user. It then
uses IWO to calculate the importance degree of users and finally, by using the
identified important users and their importance degrees it predicts unknown
ratings. To evaluate the proposed method, several experiments have been
performed on two known real world datasets and the results show that the
proposed method improves the state of the art results up to 15% in terms of
Root Mean Square Error (RMSE) and Mean Absolute Error (MAE).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PURS: Personalized Unexpected Recommender System for Improving User Satisfaction. (arXiv:2106.02771v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1">Maofei Que</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhichao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1">Alexander Tuzhilin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02771">
                                    <div class="article-summary-box-inner">
                                        <span>Classical recommender system methods typically face the filter bubble problem
when users only receive recommendations of their familiar items, making them
bored and dissatisfied. To address the filter bubble problem, unexpected
recommendations have been proposed to recommend items significantly deviating
from user&#x27;s prior expectations and thus surprising them by presenting &quot;fresh&quot;
and previously unexplored items to the users. In this paper, we describe a
novel Personalized Unexpected Recommender System (PURS) model that incorporates
unexpectedness into the recommendation process by providing multi-cluster
modeling of user interests in the latent space and personalized unexpectedness
via the self-attention mechanism and via selection of an appropriate unexpected
activation function. Extensive offline experiments on three real-world datasets
illustrate that the proposed PURS model significantly outperforms the
state-of-the-art baseline approaches in terms of both accuracy and
unexpectedness measures. In addition, we conduct an online A/B test at a major
video platform Alibaba-Youku, where our model achieves over 3\% increase in the
average video view per user metric. The proposed model is in the process of
being deployed by the company.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble Learning Based Classification Algorithm Recommendation. (arXiv:2101.05993v1 [cs.IR] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guangtao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qinbao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoyan Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05993">
                                    <div class="article-summary-box-inner">
                                        <span>Recommending appropriate algorithms to a classification problem is one of the
most challenging issues in the field of data mining. The existing algorithm
recommendation models are generally constructed on only one kind of
meta-features by single learners. Considering that i) ensemble learners usually
show better performance and ii) different kinds of meta-features characterize
the classification problems in different viewpoints independently, and further
the models constructed with different sets of meta-features will be
complementary with each other and applicable for ensemble. This paper proposes
an ensemble learning-based algorithm recommendation method. To evaluate the
proposed recommendation method, extensive experiments with 13 well-known
candidate classification algorithms and five different kinds of meta-features
are conducted on 1090 benchmark classification problems. The results show the
effectiveness of the proposed ensemble learning based recommendation method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bidirectional Distillation for Top-K Recommender System. (arXiv:2106.02870v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kweon_W/0/1/0/all/0/1">Wonbin Kweon</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1">SeongKu Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hwanjo Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02870">
                                    <div class="article-summary-box-inner">
                                        <span>Recommender systems (RS) have started to employ knowledge distillation, which
is a model compression technique training a compact model (student) with the
knowledge transferred from a cumbersome model (teacher). The state-of-the-art
methods rely on unidirectional distillation transferring the knowledge only
from the teacher to the student, with an underlying assumption that the teacher
is always superior to the student. However, we demonstrate that the student
performs better than the teacher on a significant proportion of the test set,
especially for RS. Based on this observation, we propose Bidirectional
Distillation (BD) framework whereby both the teacher and the student
collaboratively improve with each other. Specifically, each model is trained
with the distillation loss that makes to follow the other&#x27;s prediction along
with its original loss function. For effective bidirectional distillation, we
propose rank discrepancy-aware sampling scheme to distill only the informative
knowledge that can fully enhance each other. The proposed scheme is designed to
effectively cope with a large performance gap between the teacher and the
student. Trained in the bidirectional way, it turns out that both the teacher
and the student are significantly improved compared to when being trained
separately. Our extensive experiments on real-world datasets show that our
proposed framework consistently outperforms the state-of-the-art competitors.
We also provide analyses for an in-depth understanding of BD and ablation
studies to verify the effectiveness of each proposed component.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Attentive Sequential Learning for Cross-Domain Click-Through Rate Prediction. (arXiv:2106.02768v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhichao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1">Maofei Que</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1">Alexander Tuzhilin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02768">
                                    <div class="article-summary-box-inner">
                                        <span>Cross domain recommender system constitutes a powerful method to tackle the
cold-start and sparsity problem by aggregating and transferring user
preferences across multiple category domains. Therefore, it has great potential
to improve click-through-rate prediction performance in online commerce
platforms having many domains of products. While several cross domain
sequential recommendation models have been proposed to leverage information
from a source domain to improve CTR predictions in a target domain, they did
not take into account bidirectional latent relations of user preferences across
source-target domain pairs. As such, they cannot provide enhanced cross-domain
CTR predictions for both domains simultaneously. In this paper, we propose a
novel approach to cross-domain sequential recommendations based on the dual
learning mechanism that simultaneously transfers information between two
related domains in an iterative manner until the learning process stabilizes.
In particular, the proposed Dual Attentive Sequential Learning (DASL) model
consists of two novel components Dual Embedding and Dual Attention, which
jointly establish the two-stage learning process: we first construct dual
latent embeddings that extract user preferences in both domains simultaneously,
and subsequently provide cross-domain recommendations by matching the extracted
latent embeddings with candidate items through dual-attention learning
mechanism. We conduct extensive offline experiments on three real-world
datasets to demonstrate the superiority of our proposed model, which
significantly and consistently outperforms several state-of-the-art baselines
across all experimental settings. We also conduct an online A/B test at a major
video streaming platform Alibaba-Youku, where our proposed model significantly
improves business performance over the latest production system in the company.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Auditing Source Diversity Bias in Video Search Results Using Virtual Agents. (arXiv:2106.02715v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Urman_A/0/1/0/all/0/1">Aleksandra Urman</a>, <a href="http://arxiv.org/find/cs/1/au:+Makhortykh_M/0/1/0/all/0/1">Mykola Makhortykh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ulloa_R/0/1/0/all/0/1">Roberto Ulloa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02715">
                                    <div class="article-summary-box-inner">
                                        <span>We audit the presence of domain-level source diversity bias in video search
results. Using a virtual agent-based approach, we compare outputs of four
Western and one non-Western search engines for English and Russian queries. Our
findings highlight that source diversity varies substantially depending on the
language with English queries returning more diverse outputs. We also find
disproportionately high presence of a single platform, YouTube, in top search
outputs for all Western search engines except Google. At the same time, we
observe that Youtube&#x27;s major competitors such as Vimeo or Dailymotion do not
appear in the sampled Google&#x27;s video search results. This finding suggests that
Google might be downgrading the results from the main competitors of
Google-owned Youtube and highlights the necessity for further studies focusing
on the presence of own-content bias in Google&#x27;s search results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-Agnostic Counterfactual Reasoning for Eliminating Popularity Bias in Recommender System. (arXiv:2010.15363v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_T/0/1/0/all/0/1">Tianxin Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fuli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jiawei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Ziwei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1">Jinfeng Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15363">
                                    <div class="article-summary-box-inner">
                                        <span>The general aim of the recommender system is to provide personalized
suggestions to users, which is opposed to suggesting popular items. However,
the normal training paradigm, i.e., fitting a recommender model to recover the
user behavior data with pointwise or pairwise loss, makes the model biased
towards popular items. This results in the terrible Matthew effect, making
popular items be more frequently recommended and become even more popular.
Existing work addresses this issue with Inverse Propensity Weighting (IPW),
which decreases the impact of popular items on the training and increases the
impact of long-tail items. Although theoretically sound, IPW methods are highly
sensitive to the weighting strategy, which is notoriously difficult to tune. In
this work, we explore the popularity bias issue from a novel and fundamental
perspective -- cause-effect. We identify that popularity bias lies in the
direct effect from the item node to the ranking score, such that an item&#x27;s
intrinsic property is the cause of mistakenly assigning it a higher ranking
score. To eliminate popularity bias, it is essential to answer the
counterfactual question that what the ranking score would be if the model only
uses item property. To this end, we formulate a causal graph to describe the
important cause-effect relations in the recommendation process. During
training, we perform multi-task learning to achieve the contribution of each
cause; during testing, we perform counterfactual inference to remove the effect
of item popularity. Remarkably, our solution amends the learning process of
recommendation which is agnostic to a wide range of models -- it can be easily
implemented in existing methods. We demonstrate it on Matrix Factorization (MF)
and LightGCN [20]. Experiments on five real-world datasets demonstrate the
effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MC2G: An Efficient Algorithm for Matrix Completion with Social and Item Similarity Graphs. (arXiv:2006.04373v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qiaosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Suh_G/0/1/0/all/0/1">Geewon Suh</a>, <a href="http://arxiv.org/find/cs/1/au:+Suh_C/0/1/0/all/0/1">Changho Suh</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1">Vincent Y. F. Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04373">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we design and analyze MC2G (Matrix Completion with 2 Graphs),
an algorithm that performs matrix completion in the presence of social and item
similarity graphs. MC2G runs in quasilinear time and is parameter free. It is
based on spectral clustering and local refinement steps. The expected number of
sampled entries required for MC2G to succeed (i.e., recover the clusters in the
graphs and complete the matrix) matches an information-theoretic lower bound up
to a constant factor for a wide range of parameters. We show via extensive
experiments on both synthetic and real datasets that MC2G outperforms other
state-of-the-art matrix completion algorithms that leverage graph side
information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Embed Categorical Features without Embedding Tables for Recommendation. (arXiv:2010.10784v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1">Wang-Cheng Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1">Derek Zhiyuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1">Tiansheng Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xinyang Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Ting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1">Lichan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1">Ed H. Chi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10784">
                                    <div class="article-summary-box-inner">
                                        <span>Embedding learning of categorical features (e.g. user/item IDs) is at the
core of various recommendation models including matrix factorization and neural
collaborative filtering. The standard approach creates an embedding table where
each row represents a dedicated embedding vector for every unique feature
value. However, this method fails to efficiently handle high-cardinality
features and unseen feature values (e.g. new video ID) that are prevalent in
real-world recommendation systems. In this paper, we propose an alternative
embedding framework Deep Hash Embedding (DHE), replacing embedding tables by a
deep embedding network to compute embeddings on the fly. DHE first encodes the
feature value to a unique identifier vector with multiple hashing functions and
transformations, and then applies a DNN to convert the identifier vector to an
embedding. The encoding module is deterministic, non-learnable, and free of
storage, while the embedding network is updated during the training time to
learn embedding generation. Empirical results show that DHE achieves comparable
AUC against the standard one-hot full embedding, with smaller model sizes. Our
work sheds light on the design of DNN-based alternative embedding schemes for
categorical features without using embedding table lookup.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection of fake news on CoViD-19 on Web Search Engines. (arXiv:2103.11804v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazzeo_V/0/1/0/all/0/1">V. Mazzeo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rapisarda_A/0/1/0/all/0/1">A. Rapisarda</a>, <a href="http://arxiv.org/find/cs/1/au:+Giuffrida_G/0/1/0/all/0/1">G. Giuffrida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11804">
                                    <div class="article-summary-box-inner">
                                        <span>In early January 2020, after China reported the first cases of the new
coronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully
accurate information has started spreading faster than the virus itself.
Alongside this pandemic, people have experienced a parallel infodemic, i.e., an
overabundance of information, some of which misleading or even harmful, that
has widely spread around the globe. Although Social Media are increasingly
being used as information source, Web Search Engines, like Google or Yahoo!,
still represent a powerful and trustworthy resource for finding information on
the Web. This is due to their capability to capture the largest amount of
information, helping users quickly identify the most relevant, useful, although
not always the most reliable, results for their search queries. This study aims
to detect potential misleading and fake contents by capturing and analysing
textual information, which flow through Search Engines. By using a real-world
dataset associated with recent CoViD-19 pandemic, we first apply re-sampling
techniques for class imbalance, then we use existing Machine Learning
algorithms for classification of not reliable news. By extracting lexical and
host-based features of associated Uniform Resource Locators (URLs) for news
articles, we show that the proposed methods, so common in phishing and
malicious URLs detection, can improve the efficiency and performance of
classifiers. Based on these findings, we suggest that the use of both textual
and URLs features can improve the effectiveness of fake news detection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Compression-Compilation Framework for On-mobile Real-time BERT Applications. (arXiv:2106.00526v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niu_W/0/1/0/all/0/1">Wei Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Z/0/1/0/all/0/1">Zhenglun Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1">Geng Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weiwen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_J/0/1/0/all/0/1">Jiexiong Guan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1">Caiwen Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Pu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Sijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_B/0/1/0/all/0/1">Bin Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yanzhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00526">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer-based deep learning models have increasingly demonstrated high
accuracy on many natural language processing (NLP) tasks. In this paper, we
propose a compression-compilation co-design framework that can guarantee the
identified model to meet both resource and real-time specifications of mobile
devices. Our framework applies a compiler-aware neural architecture
optimization method (CANAO), which can generate the optimal compressed model
that balances both accuracy and latency. We are able to achieve up to 7.8x
speedup compared with TensorFlow-Lite with only minor accuracy loss. We present
two types of BERT applications on mobile devices: Question Answering (QA) and
Text Generation. Both can be executed in real-time with latency as low as 45ms.
Videos for demonstrating the framework can be found on
https://www.youtube.com/watch?v&#x3D;_WIRvK_2PZI</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NewsEmbed: Modeling News through Pre-trained Document Representations. (arXiv:2106.00590v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jialu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00590">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively modeling text-rich fresh content such as news articles at
document-level is a challenging problem. To ensure a content-based model
generalize well to a broad range of applications, it is critical to have a
training dataset that is large beyond the scale of human labels while achieving
desired quality. In this work, we address those two challenges by proposing a
novel approach to mine semantically-relevant fresh documents, and their topic
labels, with little human supervision. Meanwhile, we design a multitask model
called NewsEmbed that alternatively trains a contrastive learning with a
multi-label classification to derive a universal document encoder. We show that
the proposed approach can provide billions of high quality organic training
examples and can be naturally extended to multilingual setting where texts in
different languages are encoded in the same semantic space. We experimentally
demonstrate NewsEmbed&#x27;s competitive performance across multiple natural
language understanding tasks, both supervised and unsupervised.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimax Regret for Bandit Convex Optimisation of Ridge Functions. (arXiv:2106.00444v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lattimore_T/0/1/0/all/0/1">Tor Lattimore</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00444">
                                    <div class="article-summary-box-inner">
                                        <span>We analyse adversarial bandit convex optimisation with an adversary that is
restricted to playing functions of the form $f_t(x) &#x3D; g_t(\langle x,
\theta\rangle)$ for convex $g_t : \mathbb R \to \mathbb R$ and unknown $\theta
\in \mathbb R^d$ that is homogeneous over time. We provide a short
information-theoretic proof that the minimax regret is at most $O(d \sqrt{n}
\log(n \operatorname{diam}(\mathcal K)))$ where $n$ is the number of
interactions, $d$ the dimension and $\operatorname{diam}(\mathcal K)$ is the
diameter of the constraint set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OpenBox: A Generalized Black-box Optimization Service. (arXiv:2106.00421v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wentao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuanwei Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Huaijun Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingchao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiawei Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jinyang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wentao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_B/0/1/0/all/0/1">Bin Cui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00421">
                                    <div class="article-summary-box-inner">
                                        <span>Black-box optimization (BBO) has a broad range of applications, including
automatic machine learning, engineering, physics, and experimental design.
However, it remains a challenge for users to apply BBO methods to their
problems at hand with existing software packages, in terms of applicability,
performance, and efficiency. In this paper, we build OpenBox, an open-source
and general-purpose BBO service with improved usability. The modular design
behind OpenBox also facilitates flexible abstraction and optimization of basic
BBO components that are common in other existing systems. OpenBox is
distributed, fault-tolerant, and scalable. To improve efficiency, OpenBox
further utilizes &quot;algorithm agnostic&quot; parallelization and transfer learning.
Our experimental results demonstrate the effectiveness and efficiency of
OpenBox compared to existing systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anti-Koopmanism. (arXiv:2106.00106v2 [math.FA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Gonzalez_E/0/1/0/all/0/1">Efrain Gonzalez</a>, <a href="http://arxiv.org/find/math/1/au:+Abudia_M/0/1/0/all/0/1">Moad Abudia</a>, <a href="http://arxiv.org/find/math/1/au:+Jury_M/0/1/0/all/0/1">Michael Jury</a>, <a href="http://arxiv.org/find/math/1/au:+Kamalapurkar_R/0/1/0/all/0/1">Rushikesh Kamalapurkar</a>, <a href="http://arxiv.org/find/math/1/au:+Rosenfeld_J/0/1/0/all/0/1">Joel A. Rosenfeld</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00106">
                                    <div class="article-summary-box-inner">
                                        <span>This article addresses several longstanding misconceptions concerning Koopman
operators, including the existence of lattices of eigenfunctions, common
eigenfunctions between Koopman operators, and boundedness and compactness of
Koopman operators, among others. Counterexamples are provided for each
misconception. This manuscript also proves that the Gaussian RBF&#x27;s native space
only supports bounded Koopman operator corresponding to affine dynamics, which
shows that the assumption of boundedness is very limiting. A framework for DMD
is presented that requires only densely defined Koopman operators over
reproducing kernel Hilbert spaces, and the effectiveness of this approach is
demonstrated through reconstruction examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Escaping Saddle Points Faster with Stochastic Momentum. (arXiv:2106.02985v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun-Kun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chi-Heng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1">Jacob Abernethy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02985">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic gradient descent (SGD) with stochastic momentum is popular in
nonconvex stochastic optimization and particularly for the training of deep
neural networks. In standard SGD, parameters are updated by improving along the
path of the gradient at the current iterate on a batch of examples, where the
addition of a &#x60;&#x60;momentum&#x27;&#x27; term biases the update in the direction of the
previous change in parameters. In non-stochastic convex optimization one can
show that a momentum adjustment provably reduces convergence time in many
settings, yet such results have been elusive in the stochastic and non-convex
settings. At the same time, a widely-observed empirical phenomenon is that in
training deep networks stochastic momentum appears to significantly improve
convergence time, variants of it have flourished in the development of other
popular update methods, e.g. ADAM [KB15], AMSGrad [RKK18], etc. Yet theoretical
justification for the use of stochastic momentum has remained a significant
open question. In this paper we propose an answer: stochastic momentum improves
deep network training because it modifies SGD to escape saddle points faster
and, consequently, to more quickly find a second order stationary point. Our
theoretical results also shed light on the related question of how to choose
the ideal momentum parameter--our analysis suggests that $\beta \in [0,1)$
should be large (close to 1), which comports with empirical findings. We also
provide experimental findings that further validate these conclusions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SketchGen: Generating Constrained CAD Sketches. (arXiv:2106.02711v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Para_W/0/1/0/all/0/1">Wamiq Reyaz Para</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1">Shariq Farooq Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerrero_P/0/1/0/all/0/1">Paul Guerrero</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelly_T/0/1/0/all/0/1">Tom Kelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitra_N/0/1/0/all/0/1">Niloy Mitra</a>, <a href="http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1">Leonidas Guibas</a>, <a href="http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1">Peter Wonka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02711">
                                    <div class="article-summary-box-inner">
                                        <span>Computer-aided design (CAD) is the most widely used modeling approach for
technical design. The typical starting point in these designs is 2D sketches
which can later be extruded and combined to obtain complex three-dimensional
assemblies. Such sketches are typically composed of parametric primitives, such
as points, lines, and circular arcs, augmented with geometric constraints
linking the primitives, such as coincidence, parallelism, or orthogonality.
Sketches can be represented as graphs, with the primitives as nodes and the
constraints as edges. Training a model to automatically generate CAD sketches
can enable several novel workflows, but is challenging due to the complexity of
the graphs and the heterogeneity of the primitives and constraints. In
particular, each type of primitive and constraint may require a record of
different size and parameter types. We propose SketchGen as a generative model
based on a transformer architecture to address the heterogeneity problem by
carefully designing a sequential language for the primitives and constraints
that allows distinguishing between different primitive or constraint types and
their parameters, while encouraging our model to re-use information across
related parameters, encoding shared structure. A particular highlight of our
work is the ability to produce primitives linked via constraints that enables
the final output to be further regularized via a constraint solver. We evaluate
our model by demonstrating constraint prediction for given sets of primitives
and full sketch generation from scratch, showing that our approach
significantly out performs the state-of-the-art in CAD sketch generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning with Fewer Tasks through Task Interpolation. (arXiv:2106.02695v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1">Huaxiu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Linjun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1">Chelsea Finn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02695">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning enables algorithms to quickly learn a newly encountered task
with just a few labeled examples by transferring previously learned knowledge.
However, the bottleneck of current meta-learning algorithms is the requirement
of a large number of meta-training tasks, which may not be accessible in
real-world scenarios. To address the challenge that available tasks may not
densely sample the space of tasks, we propose to augment the task set through
interpolation. By meta-learning with task interpolation (MLTI), our approach
effectively generates additional tasks by randomly sampling a pair of tasks and
interpolating the corresponding features and labels. Under both gradient-based
and metric-based meta-learning settings, our theoretical analysis shows MLTI
corresponds to a data-adaptive meta-regularization and further improves the
generalization. Empirically, in our experiments on eight datasets from diverse
domains including image recognition, pose prediction, molecule property
prediction, and medical image classification, we find that the proposed general
MLTI framework is compatible with representative meta-learning algorithms and
consistently outperforms other state-of-the-art strategies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Review of Machine Learning Classification Using Quantum Annealing for Real-world Applications. (arXiv:2106.02964v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Nath_R/0/1/0/all/0/1">Rajdeep Kumar Nath</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Thapliyal_H/0/1/0/all/0/1">Himanshu Thapliyal</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Humble_T/0/1/0/all/0/1">Travis S. Humble</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02964">
                                    <div class="article-summary-box-inner">
                                        <span>Optimizing the training of a machine learning pipeline helps in reducing
training costs and improving model performance. One such optimizing strategy is
quantum annealing, which is an emerging computing paradigm that has shown
potential in optimizing the training of a machine learning model. The
implementation of a physical quantum annealer has been realized by D-Wave
systems and is available to the research community for experiments. Recent
experimental results on a variety of machine learning applications using
quantum annealing have shown interesting results where the performance of
classical machine learning techniques is limited by limited training data and
high dimensional features. This article explores the application of D-Wave&#x27;s
quantum annealer for optimizing machine learning pipelines for real-world
classification problems. We review the application domains on which a physical
quantum annealer has been used to train machine learning classifiers. We
discuss and analyze the experiments performed on the D-Wave quantum annealer
for applications such as image recognition, remote sensing imagery,
computational biology, and particle physics. We discuss the possible advantages
and the problems for which quantum annealing is likely to be advantageous over
classical computation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lifelong Learning of Hate Speech Classification on Social Media. (arXiv:2106.02821v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_J/0/1/0/all/0/1">Jing Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+ElSherief_M/0/1/0/all/0/1">Mai ElSherief</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1">Xifeng Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02821">
                                    <div class="article-summary-box-inner">
                                        <span>Existing work on automated hate speech classification assumes that the
dataset is fixed and the classes are pre-defined. However, the amount of data
in social media increases every day, and the hot topics changes rapidly,
requiring the classifiers to be able to continuously adapt to new data without
forgetting the previously learned knowledge. This ability, referred to as
lifelong learning, is crucial for the real-word application of hate speech
classifiers in social media. In this work, we propose lifelong learning of hate
speech classification on social media. To alleviate catastrophic forgetting, we
propose to use Variational Representation Learning (VRL) along with a memory
module based on LB-SOINN (Load-Balancing Self-Organizing Incremental Neural
Network). Experimentally, we show that combining variational representation
learning and the LB-SOINN memory module achieves better performance than the
commonly-used lifelong learning techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Contrastive Learning: Removing Undesirable Information in Self-Supervised Representations. (arXiv:2106.02866v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yao-Hung Hubert Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_M/0/1/0/all/0/1">Martin Q. Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Han Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1">Louis-Philippe Morency</a>, <a href="http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1">Ruslan Salakhutdinov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02866">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning is a form of unsupervised learning that leverages
rich information in data to learn representations. However, data sometimes
contains certain information that may be undesirable for downstream tasks. For
instance, gender information may lead to biased decisions on many
gender-irrelevant tasks. In this paper, we develop conditional contrastive
learning to remove undesirable information in self-supervised representations.
To remove the effect of the undesirable variable, our proposed approach
conditions on the undesirable variable (i.e., by fixing the variations of it)
during the contrastive learning process. In particular, inspired by the
contrastive objective InfoNCE, we introduce Conditional InfoNCE (C-InfoNCE),
and its computationally efficient variant, Weak-Conditional InfoNCE
(WeaC-InfoNCE), for conditional contrastive learning. We demonstrate
empirically that our methods can successfully learn self-supervised
representations for downstream tasks while removing a great level of
information related to the undesirable variables. We study three scenarios,
each with a different type of undesirable variables: task-irrelevant
meta-information for self-supervised speech representation learning, sensitive
attributes for fair representation learning, and domain specification for
multi-domain visual representation learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ImGAGN:Imbalanced Network Embedding via Generative Adversarial Graph Networks. (arXiv:2106.02817v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qu_L/0/1/0/all/0/1">Liang Qu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Huaisheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1">Ruiqi Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1">Yuhui Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hongzhi Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02817">
                                    <div class="article-summary-box-inner">
                                        <span>Imbalanced classification on graphs is ubiquitous yet challenging in many
real-world applications, such as fraudulent node detection. Recently, graph
neural networks (GNNs) have shown promising performance on many network
analysis tasks. However, most existing GNNs have almost exclusively focused on
the balanced networks, and would get unappealing performance on the imbalanced
networks. To bridge this gap, in this paper, we present a generative
adversarial graph network model, called ImGAGN to address the imbalanced
classification problem on graphs. It introduces a novel generator for graph
structure data, named GraphGenerator, which can simulate both the minority
class nodes&#x27; attribute distribution and network topological structure
distribution by generating a set of synthetic minority nodes such that the
number of nodes in different classes can be balanced. Then a graph
convolutional network (GCN) discriminator is trained to discriminate between
real nodes and fake (i.e., generated) nodes, and also between minority nodes
and majority nodes on the synthetic balanced network. To validate the
effectiveness of the proposed method, extensive experiments are conducted on
four real-world imbalanced network datasets. Experimental results demonstrate
that the proposed method ImGAGN outperforms state-of-the-art algorithms for
semi-supervised imbalanced node classification task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constrained Generalized Additive 2 Model with Consideration of High-Order Interactions. (arXiv:2106.02836v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Watanabe_A/0/1/0/all/0/1">Akihisa Watanabe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuramata_M/0/1/0/all/0/1">Michiya Kuramata</a>, <a href="http://arxiv.org/find/cs/1/au:+Majima_K/0/1/0/all/0/1">Kaito Majima</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiyohara_H/0/1/0/all/0/1">Haruka Kiyohara</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondo_K/0/1/0/all/0/1">Kensho Kondo</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakata_K/0/1/0/all/0/1">Kazuhide Nakata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02836">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, machine learning and AI have been introduced in many
industrial fields. In fields such as finance, medicine, and autonomous driving,
where the inference results of a model may have serious consequences, high
interpretability as well as prediction accuracy is required. In this study, we
propose CGA2M+, which is based on the Generalized Additive 2 Model (GA2M) and
differs from it in two major ways. The first is the introduction of
monotonicity. Imposing monotonicity on some functions based on an analyst&#x27;s
knowledge is expected to improve not only interpretability but also
generalization performance. The second is the introduction of a higher-order
term: given that GA2M considers only second-order interactions, we aim to
balance interpretability and prediction accuracy by introducing a higher-order
term that can capture higher-order interactions. In this way, we can improve
prediction performance without compromising interpretability by applying
learning innovation. Numerical experiments showed that the proposed model has
high predictive performance and interpretability. Furthermore, we confirmed
that generalization performance is improved by introducing monotonicity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Context-Aware Sparse Deep Coordination Graphs. (arXiv:2106.02886v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tonghan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_L/0/1/0/all/0/1">Liang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_W/0/1/0/all/0/1">Weijun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qianlan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chongjie Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02886">
                                    <div class="article-summary-box-inner">
                                        <span>Learning sparse coordination graphs adaptive to the coordination dynamics
among agents is a long-standing problem in cooperative multi-agent learning.
This paper studies this problem by proposing several value-based and
observation-based schemes for learning dynamic topologies and evaluating them
on a new Multi-Agent COordination (MACO) benchmark. The benchmark collects
classic coordination problems in the literature, increases their difficulty,
and classifies them into different types. By analyzing the individual
advantages of each learning scheme on each type of problem and their overall
performance, we propose a novel method using the variance of utility difference
functions to learn context-aware sparse coordination topologies. Moreover, our
method learns action representations that effectively reduce the influence of
utility functions&#x27; estimation errors on graph construction. Experiments show
that our method significantly outperforms dense and static topologies across
the MACO and StarCraft II micromanagement benchmark.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low Budget Active Learning via Wasserstein Distance: An Integer Programming Approach. (arXiv:2106.02968v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1">Rafid Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1">Sanja Fidler</a>, <a href="http://arxiv.org/find/cs/1/au:+Law_M/0/1/0/all/0/1">Marc T. Law</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02968">
                                    <div class="article-summary-box-inner">
                                        <span>Given restrictions on the availability of data, active learning is the
process of training a model with limited labeled data by selecting a core
subset of an unlabeled data pool to label. Although selecting the most useful
points for training is an optimization problem, the scale of deep learning data
sets forces most selection strategies to employ efficient heuristics. Instead,
we propose a new integer optimization problem for selecting a core set that
minimizes the discrete Wasserstein distance from the unlabeled pool. We
demonstrate that this problem can be tractably solved with a Generalized
Benders Decomposition algorithm. Our strategy requires high-quality latent
features which we obtain by unsupervised learning on the unlabeled pool.
Numerical results on several data sets show that our optimization approach is
competitive with baselines and particularly outperforms them in the low budget
regime where less than one percent of the data set is labeled.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PURS: Personalized Unexpected Recommender System for Improving User Satisfaction. (arXiv:2106.02771v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1">Maofei Que</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhichao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1">Alexander Tuzhilin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02771">
                                    <div class="article-summary-box-inner">
                                        <span>Classical recommender system methods typically face the filter bubble problem
when users only receive recommendations of their familiar items, making them
bored and dissatisfied. To address the filter bubble problem, unexpected
recommendations have been proposed to recommend items significantly deviating
from user&#x27;s prior expectations and thus surprising them by presenting &quot;fresh&quot;
and previously unexplored items to the users. In this paper, we describe a
novel Personalized Unexpected Recommender System (PURS) model that incorporates
unexpectedness into the recommendation process by providing multi-cluster
modeling of user interests in the latent space and personalized unexpectedness
via the self-attention mechanism and via selection of an appropriate unexpected
activation function. Extensive offline experiments on three real-world datasets
illustrate that the proposed PURS model significantly outperforms the
state-of-the-art baseline approaches in terms of both accuracy and
unexpectedness measures. In addition, we conduct an online A/B test at a major
video platform Alibaba-Youku, where our model achieves over 3\% increase in the
average video view per user metric. The proposed model is in the process of
being deployed by the company.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multimodal Story Generation on Plural Images. (arXiv:2001.10980v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jing Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.10980">
                                    <div class="article-summary-box-inner">
                                        <span>Traditionally, text generation models take in a sequence of text as input,
and iteratively generate the next most probable word using pre-trained
parameters. In this work, we propose the architecture to use images instead of
text as the input of the text generation model, called StoryGen. In the
architecture, we design a Relational Text Data Generator algorithm that relates
different features from multiple images. The output samples from the model
demonstrate the ability to generate meaningful paragraphs of text containing
the extracted features from the input images. This is an undergraduate project
report. Completed Dec. 2019 at the Cooper Union.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Sparse Classifiers: Continuous and Mixed Integer Optimization Perspectives. (arXiv:2001.06471v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dedieu_A/0/1/0/all/0/1">Antoine Dedieu</a>, <a href="http://arxiv.org/find/stat/1/au:+Hazimeh_H/0/1/0/all/0/1">Hussein Hazimeh</a>, <a href="http://arxiv.org/find/stat/1/au:+Mazumder_R/0/1/0/all/0/1">Rahul Mazumder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.06471">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a discrete optimization formulation for learning sparse
classifiers, where the outcome depends upon a linear combination of a small
subset of features. Recent work has shown that mixed integer programming (MIP)
can be used to solve (to optimality) $\ell_0$-regularized regression problems
at scales much larger than what was conventionally considered possible. Despite
their usefulness, MIP-based global optimization approaches are significantly
slower compared to the relatively mature algorithms for $\ell_1$-regularization
and heuristics for nonconvex regularized problems. We aim to bridge this gap in
computation times by developing new MIP-based algorithms for
$\ell_0$-regularized classification. We propose two classes of scalable
algorithms: an exact algorithm that can handle $p\approx 50,000$ features in a
few minutes, and approximate algorithms that can address instances with
$p\approx 10^6$ in times comparable to the fast $\ell_1$-based algorithms. Our
exact algorithm is based on the novel idea of \textsl{integrality generation},
which solves the original problem (with $p$ binary variables) via a sequence of
mixed integer programs that involve a small number of binary variables. Our
approximate algorithms are based on coordinate descent and local combinatorial
search. In addition, we present new estimation error bounds for a class of
$\ell_0$-regularized estimators. Experiments on real and synthetic data
demonstrate that our approach leads to models with considerably improved
statistical performance (especially, variable selection) when compared to
competing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Point Cloud Failure Criterion for Composites using k-Nearest Neighbor Classification. (arXiv:2106.02714v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajan_S/0/1/0/all/0/1">Subramaniam Rajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khaled_B/0/1/0/all/0/1">Bilal Khaled</a>, <a href="http://arxiv.org/find/cs/1/au:+Shyamsunder_L/0/1/0/all/0/1">Loukham Shyamsunder</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02714">
                                    <div class="article-summary-box-inner">
                                        <span>Numerous theories of failure have been postulated and implemented in various
commercial programs for composite materials. Even the best theories have had
limited success in predicting damage and failure in validation exercises. In
view of this background, many researchers have started exploring the use of
multiscale modeling to improve the fidelity of the modeling and simulation of
various structural and materials systems. In this paper, a multi-scale modeling
scheme is used to illustrate how a combination of virtual and laboratory
testing programs can be used to generate a point cloud of failure surface data
that can then be queried during finite element analysis at the continuum scale
to ascertain if the onset of failure has occurred. The k-nearest neighbor
(k-NN) classification concept is used to obtain the answer to the query. A
linear, elastic, static finite element example using a unidirectional composite
shows that the framework can be generated and used effectively and efficiently
with the possibility to extend the approach for all types of composite
architectures and behaviors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Should Graph Convolution Trust Neighbors? A Simple Causal Inference Method. (arXiv:2010.11797v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fuli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Weiran Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiangnan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Xin_X/0/1/0/all/0/1">Xin Xin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qifan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1">Tat-Seng Chua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11797">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Convolutional Network (GCN) is an emerging technique for information
retrieval (IR) applications. While GCN assumes the homophily property of a
graph, real-world graphs are never perfect: the local structure of a node may
contain discrepancy, e.g., the labels of a node&#x27;s neighbors could vary. This
pushes us to consider the discrepancy of local structure in GCN modeling.
Existing work approaches this issue by introducing an additional module such as
graph attention, which is expected to learn the contribution of each neighbor.
However, such module may not work reliably as expected, especially when there
lacks supervision signal, e.g., when the labeled data is small. Moreover,
existing methods focus on modeling the nodes in the training data, and never
consider the local structure discrepancy of testing nodes.

This work focuses on the local structure discrepancy issue for testing nodes,
which has received little scrutiny. From a novel perspective of causality, we
investigate whether a GCN should trust the local structure of a testing node
when predicting its label. To this end, we analyze the working mechanism of GCN
with causal graph, estimating the causal effect of a node&#x27;s local structure for
the prediction. The idea is simple yet effective: given a trained GCN model, we
first intervene the prediction by blocking the graph structure; we then compare
the original prediction with the intervened prediction to assess the causal
effect of the local structure on the prediction. Through this way, we can
eliminate the impact of local structure discrepancy and make more accurate
prediction. Extensive experiments on seven node classification datasets show
that our method effectively enhances the inference stage of GCN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imitation Learning via Simultaneous Optimization of Policies and Auxiliary Trajectories. (arXiv:2105.03019v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_M/0/1/0/all/0/1">Mandy Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Anqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyk_K/0/1/0/all/0/1">Karl Van Wyk</a>, <a href="http://arxiv.org/find/cs/1/au:+Dellaert_F/0/1/0/all/0/1">Frank Dellaert</a>, <a href="http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1">Byron Boots</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratliff_N/0/1/0/all/0/1">Nathan Ratliff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03019">
                                    <div class="article-summary-box-inner">
                                        <span>Imitation learning (IL) is a frequently used approach for data-efficient
policy learning. Many IL methods, such as Dataset Aggregation (DAgger), combat
challenges like distributional shift by interacting with oracular experts.
Unfortunately, assuming access to oracular experts is often unrealistic in
practice; data used in IL frequently comes from offline processes such as
lead-through or teleoperation. In this paper, we present a novel imitation
learning technique called Collocation for Demonstration Encoding (CoDE) that
operates on only a fixed set of trajectory demonstrations. We circumvent
challenges with methods like back-propagation-through-time by introducing an
auxiliary trajectory network, which takes inspiration from collocation
techniques in optimal control. Our method generalizes well and more accurately
reproduces the demonstrated behavior with fewer guiding trajectories when
compared to standard behavioral cloning methods. We present simulation results
on a 7-degree-of-freedom (DoF) robotic manipulator that learns to exhibit
lifting, target-reaching, and obstacle avoidance behaviors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Kickstarting Deep Reinforcement Learning with Privacy-Aware Learners. (arXiv:2102.09599v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gohari_P/0/1/0/all/0/1">Parham Gohari</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Bo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1">Bo Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_M/0/1/0/all/0/1">Matthew Hale</a>, <a href="http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1">Ufuk Topcu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09599">
                                    <div class="article-summary-box-inner">
                                        <span>Kickstarting deep reinforcement learning algorithms facilitate a
teacher-student relationship among the agents and allow for a well-performing
teacher to share demonstrations with a student to expedite the student&#x27;s
training. However, despite the known benefits, the demonstrations may contain
sensitive information about the teacher&#x27;s training data and existing
kickstarting methods do not take any measures to protect it. Therefore, we use
the framework of differential privacy to develop a mechanism that securely
shares the teacher&#x27;s demonstrations with the student. The mechanism allows for
the teacher to decide upon the accuracy of its demonstrations with respect to
the privacy budget that it consumes, thereby granting the teacher full control
over its data privacy. We then develop a kickstarted deep reinforcement
learning algorithm for the student that is privacy-aware because we calibrate
its objective with the parameters of the teacher&#x27;s privacy mechanism. The
privacy-aware design of the algorithm makes it possible to kickstart the
student&#x27;s learning despite the perturbations induced by the privacy mechanism.
From numerical experiments, we highlight three empirical results: (i) the
algorithm succeeds in expediting the student&#x27;s learning, (ii) the student
converges to a performance level that was not possible without the
demonstrations, and (iii) the student maintains its enhanced performance even
after the teacher stops sharing useful demonstrations due to its privacy budget
constraints.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Enabling Meta-Learning from Target Models. (arXiv:2104.03736v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1">Su Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Han-Jia Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_L/0/1/0/all/0/1">Le Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhan_D/0/1/0/all/0/1">De-Chuan Zhan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03736">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning can extract an inductive bias from previous learning experience
and assist the training processes of new tasks. It is often realized through
optimizing a meta-model with the evaluation loss of a series of task-specific
solvers. Most existing algorithms sample non-overlapping $\mathit{support}$
sets and $\mathit{query}$ sets to train and evaluate the solvers respectively
due to simplicity ($\mathcal{S}/\mathcal{Q}$ protocol). However, another
evaluation method that assesses the discrepancy between the solver and a target
model is short of research ($\mathcal{S}/\mathcal{T}$ protocol).
$\mathcal{S}/\mathcal{T}$ protocol has unique advantages such as offering more
informative supervision, but it is computationally expensive. This paper looks
into this special evaluation method and takes a step towards putting it into
practice. We find that with a small ratio of tasks armed with target models,
classic meta-learning algorithms can be improved a lot without consuming many
resources. Furthermore, we empirically verify the effectiveness of
$\mathcal{S}/\mathcal{T}$ protocol in a typical application of meta-learning,
$\mathit{i.e.}$, few-shot learning. In detail, after constructing target models
by fine-tuning the pre-trained network on those hard tasks, we match the
task-specific solvers to target models via knowledge distillation. Experiments
demonstrate the superiority of our proposal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regret Minimization Experience Replay. (arXiv:2105.07253v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1">Zhenghai Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xu-Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_J/0/1/0/all/0/1">Jing-Cheng Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shengyi Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1">Feng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yang Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07253">
                                    <div class="article-summary-box-inner">
                                        <span>In reinforcement learning, experience replay stores past samples for further
reuse. Prioritized sampling is a promising technique to better utilize these
samples. Previous criteria of prioritization include TD error, recentness and
corrective feedback, which are mostly heuristically designed. In this work, we
start from the regret minimization objective, and obtain an optimal
prioritization strategy for Bellman update that can directly maximize the
return of the policy. The theory suggests that data with higher hindsight TD
error, better on-policiness and more accurate Q value should be assigned with
higher weights during sampling. Thus most previous criteria only consider this
strategy partially. We not only provide theoretical justifications for previous
criteria, but also propose two new methods to compute the prioritization
weight, namely ReMERN and ReMERT. ReMERN learns an error network, while ReMERT
exploits the temporal ordering of states. Both methods outperform previous
prioritized sampling algorithms in challenging RL benchmarks, including MuJoCo,
Atari and Meta-World.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information Discrepancy in Strategic Learning. (arXiv:2103.01028v3 [cs.GT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bechavod_Y/0/1/0/all/0/1">Yahav Bechavod</a>, <a href="http://arxiv.org/find/cs/1/au:+Podimata_C/0/1/0/all/0/1">Chara Podimata</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhiwei Steven Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ziani_J/0/1/0/all/0/1">Juba Ziani</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01028">
                                    <div class="article-summary-box-inner">
                                        <span>We study the effects of information discrepancy across sub-populations on
their ability to simultaneously improve their features in strategic learning
settings. Specifically, we consider a game where a principal deploys a decision
rule in an attempt to optimize the whole population&#x27;s welfare, and agents
strategically adapt to it to receive better scores. Inspired by real-life
settings, such as loan approvals and college admissions, we remove the typical
assumption made in the strategic learning literature that the decision rule is
fully known to the agents, and focus on settings where it is inaccessible. In
their lack of knowledge, individuals try to infer this rule by learning from
their peers (e.g., friends and acquaintances who previously applied for a
loan), naturally forming groups in the population, each with possibly different
type and level of information about the decision rule. In our equilibrium
analysis, we show that the principal&#x27;s decision rule optimizing the welfare
across subgroups may cause a surprising negative externality; the true quality
of some of the subgroups can actually deteriorate. On the positive side, we
show that in many natural cases, optimal improvement is guaranteed
simultaneously for all subgroups in equilibrium. We also characterize the
disparity in improvements across subgroups via a measure of their informational
overlap. Finally, we complement our theoretical analysis with experiments on
real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kernel Smoothing, Mean Shift, and Their Learning Theory with Directional Data. (arXiv:2010.13523v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1">Yikun Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1">Yen-Chi Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.13523">
                                    <div class="article-summary-box-inner">
                                        <span>Directional data consist of observations distributed on a (hyper)sphere, and
appear in many applied fields, such as astronomy, ecology, and environmental
science. This paper studies both statistical and computational problems of
kernel smoothing for directional data. We generalize the classical mean shift
algorithm to directional data, which allows us to identify local modes of the
directional kernel density estimator (KDE). The statistical convergence rates
of the directional KDE and its derivatives are derived, and the problem of mode
estimation is examined. We also prove the ascending property of the directional
mean shift algorithm and investigate a general problem of gradient ascent on
the unit hypersphere. To demonstrate the applicability of the algorithm, we
evaluate it as a mode clustering method on both simulated and real-world data
sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Representation Matters: Assessing the Importance of Subgroup Allocations in Training Data. (arXiv:2103.03399v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rolf_E/0/1/0/all/0/1">Esther Rolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Worledge_T/0/1/0/all/0/1">Theodora Worledge</a>, <a href="http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1">Benjamin Recht</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03399">
                                    <div class="article-summary-box-inner">
                                        <span>Collecting more diverse and representative training data is often touted as a
remedy for the disparate performance of machine learning predictors across
subpopulations. However, a precise framework for understanding how dataset
properties like diversity affect learning outcomes is largely lacking. By
casting data collection as part of the learning process, we demonstrate that
diverse representation in training data is key not only to increasing subgroup
performances, but also to achieving population level objectives. Our analysis
and experiments describe how dataset compositions influence performance and
provide constructive results for using trends in existing data, alongside
domain knowledge, to help guide intentional, objective-aware dataset design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principled Simplicial Neural Networks for Trajectory Prediction. (arXiv:2102.10058v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roddenberry_T/0/1/0/all/0/1">T. Mitchell Roddenberry</a>, <a href="http://arxiv.org/find/cs/1/au:+Glaze_N/0/1/0/all/0/1">Nicholas Glaze</a>, <a href="http://arxiv.org/find/cs/1/au:+Segarra_S/0/1/0/all/0/1">Santiago Segarra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10058">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the construction of neural network architectures for data on
simplicial complexes. In studying maps on the chain complex of a simplicial
complex, we define three desirable properties of a simplicial neural network
architecture: namely, permutation equivariance, orientation equivariance, and
simplicial awareness. The first two properties respectively account for the
fact that the node indexing and the simplex orientations in a simplicial
complex are arbitrary. The last property encodes the desirable feature that the
output of the neural network depends on the entire simplicial complex and not
on a subset of its dimensions. Based on these properties, we propose a simple
convolutional architecture, rooted in tools from algebraic topology, for the
problem of trajectory prediction, and show that it obeys all three of these
properties when an odd, nonlinear activation function is used. We then
demonstrate the effectiveness of this architecture in extrapolating
trajectories on synthetic and real datasets, with particular emphasis on the
gains in generalizability to unseen trajectories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Model-Agnostic Post-Hoc Adjustment for Balancing Ranking Fairness and Algorithm Utility. (arXiv:2006.08267v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Sen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1">Weishen Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Changshui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08267">
                                    <div class="article-summary-box-inner">
                                        <span>Bipartite ranking, which aims to learn a scoring function that ranks positive
individuals higher than negative ones from labeled data, is widely adopted in
various applications where sample prioritization is needed. Recently, there
have been rising concerns on whether the learned scoring function can cause
systematic disparity across different protected groups defined by sensitive
attributes. While there could be trade-off between fairness and performance, in
this paper we propose a model agnostic post-processing framework for balancing
them in the bipartite ranking scenario. Specifically, we maximize a weighted
sum of the utility and fairness by directly adjusting the relative ordering of
samples across groups. By formulating this problem as the identification of an
optimal warping path across different protected groups, we propose a
non-parametric method to search for such an optimal path through a dynamic
programming process. Our method is compatible with various classification
models and applicable to a variety of ranking fairness metrics. Comprehensive
experiments on a suite of benchmark data sets and two real-world patient
electronic health record repositories show that our method can achieve a great
balance between the algorithm utility and ranking fairness. Furthermore, we
experimentally verify the robustness of our method when faced with the fewer
training samples and the difference between training and testing ranking score
distributions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Efficient Representations for Keyword Spotting with Triplet Loss. (arXiv:2101.04792v4 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Vygon_R/0/1/0/all/0/1">Roman Vygon</a>, <a href="http://arxiv.org/find/eess/1/au:+Mikhaylovskiy_N/0/1/0/all/0/1">Nikolay Mikhaylovskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04792">
                                    <div class="article-summary-box-inner">
                                        <span>In the past few years, triplet loss-based metric embeddings have become a
de-facto standard for several important computer vision problems, most
no-tably, person reidentification. On the other hand, in the area of speech
recognition the metric embeddings generated by the triplet loss are rarely used
even for classification problems. We fill this gap showing that a combination
of two representation learning techniques: a triplet loss-based embedding and a
variant of kNN for classification instead of cross-entropy loss significantly
(by 26% to 38%) improves the classification accuracy for convolutional networks
on a LibriSpeech-derived LibriWords datasets. To do so, we propose a novel
phonetic similarity based triplet mining approach. We also improve the current
best published SOTA for Google Speech Commands dataset V1 10+2 -class
classification by about 34%, achieving 98.55% accuracy, V2 10+2-class
classification by about 20%, achieving 98.37% accuracy, and V2 35-class
classification by over 50%, achieving 97.0% accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Reconstruction: Partially Local Federated Learning. (arXiv:2102.03448v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singhal_K/0/1/0/all/0/1">Karan Singhal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidahmed_H/0/1/0/all/0/1">Hakim Sidahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+Garrett_Z/0/1/0/all/0/1">Zachary Garrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_S/0/1/0/all/0/1">Shanshan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rush_K/0/1/0/all/0/1">Keith Rush</a>, <a href="http://arxiv.org/find/cs/1/au:+Prakash_S/0/1/0/all/0/1">Sushant Prakash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03448">
                                    <div class="article-summary-box-inner">
                                        <span>Personalization methods in federated learning aim to balance the benefits of
federated and local training for data availability, communication cost, and
robustness to client heterogeneity. Approaches that require clients to
communicate all model parameters can be undesirable due to privacy and
communication constraints. Other approaches require always-available or
stateful clients, impractical in large-scale cross-device settings. We
introduce Federated Reconstruction, the first model-agnostic framework for
partially local federated learning suitable for training and inference at
scale. We motivate the framework via a connection to model-agnostic meta
learning, empirically demonstrate its performance over existing approaches for
collaborative filtering and next word prediction, and release an open-source
library for evaluating approaches in this setting. We also describe the
successful deployment of this approach at scale for federated collaborative
filtering in a mobile keyboard application.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modern Hopfield Networks for Few- and Zero-Shot Reaction Template Prediction. (arXiv:2104.03279v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Seidl_P/0/1/0/all/0/1">Philipp Seidl</a>, <a href="http://arxiv.org/find/cs/1/au:+Renz_P/0/1/0/all/0/1">Philipp Renz</a>, <a href="http://arxiv.org/find/cs/1/au:+Dyubankova_N/0/1/0/all/0/1">Natalia Dyubankova</a>, <a href="http://arxiv.org/find/cs/1/au:+Neves_P/0/1/0/all/0/1">Paulo Neves</a>, <a href="http://arxiv.org/find/cs/1/au:+Verhoeven_J/0/1/0/all/0/1">Jonas Verhoeven</a>, <a href="http://arxiv.org/find/cs/1/au:+Segler_M/0/1/0/all/0/1">Marwin Segler</a>, <a href="http://arxiv.org/find/cs/1/au:+Wegner_J/0/1/0/all/0/1">J&#xf6;rg K. Wegner</a>, <a href="http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1">Sepp Hochreiter</a>, <a href="http://arxiv.org/find/cs/1/au:+Klambauer_G/0/1/0/all/0/1">G&#xfc;nter Klambauer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.03279">
                                    <div class="article-summary-box-inner">
                                        <span>Finding synthesis routes for molecules of interest is an essential step in
the discovery of new drugs and materials. To find such routes,
computer-assisted synthesis planning (CASP) methods are employed which rely on
a model of chemical reactivity. In this study, we model single-step
retrosynthesis in a template-based approach using modern Hopfield networks
(MHNs). We adapt MHNs to associate different modalities, reaction templates and
molecules, which allows the model to leverage structural information about
reaction templates. This approach significantly improves the performance of
template relevance prediction, especially for templates with few or zero
training examples. With inference speed several times faster than that of
baseline methods, we improve predictive performance for top-k exact match
accuracy for $\mathrm{k}\geq5$ in the retrosynthesis benchmark USPTO-50k.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Positive-Negative Momentum: Manipulating Stochastic Gradient Noise to Improve Generalization. (arXiv:2103.17182v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Zeke Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1">Li Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1">Zhanxing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.17182">
                                    <div class="article-summary-box-inner">
                                        <span>It is well-known that stochastic gradient noise (SGN) acts as implicit
regularization for deep learning and is essentially important for both
optimization and generalization of deep networks. Some works attempted to
artificially simulate SGN by injecting random noise to improve deep learning.
However, it turned out that the injected simple random noise cannot work as
well as SGN, which is anisotropic and parameter-dependent. For simulating SGN
at low computational costs and without changing the learning rate or batch
size, we propose the Positive-Negative Momentum (PNM) approach that is a
powerful alternative to conventional Momentum in classic optimizers. The
introduced PNM method maintains two approximate independent momentum terms.
Then, we can control the magnitude of SGN explicitly by adjusting the momentum
difference. We theoretically prove the convergence guarantee and the
generalization advantage of PNM over Stochastic Gradient Descent (SGD). By
incorporating PNM into the two conventional optimizers, SGD with Momentum and
Adam, our extensive experiments empirically verified the significant advantage
of the PNM-based variants over the corresponding conventional Momentum-based
optimizers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LeadCache: Regret-Optimal Caching in Networks. (arXiv:2009.08228v2 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paria_D/0/1/0/all/0/1">Debjit Paria</a>, <a href="http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1">Abhishek Sinha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08228">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a set-valued online prediction problem in the context of network
caching. Assume that users are connected to a number of caches via a bipartite
network. At any time slot, each user requests some file chosen from a large
catalog. A user&#x27;s request is met if the requested file is cached in at least
one of the caches connected to the user. The objective is to predict and
optimally store the files on the caches to maximize the total number of cache
hits. We propose $\texttt{LeadCache}$ - an online caching policy based on the
Follow-the-Perturbed-Leader paradigm. We show that the policy is regret-optimal
up to a factor of $\tilde{O}(n^{3/8}),$ where $n$ is the number of users. We
implement the policy by designing a new linear-time Pipage rounding algorithm.
With an additional Strong-Law-type assumption, we show that the total number of
file fetches under $\texttt{LeadCache}$ remains almost surely finite.
Additionally, we derive a tight regret lower bound using results from graph
coloring. Our conclusion is that the proposed learning-based caching policy
decisively outperforms the classical policies both theoretically and
empirically.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling a Deep Learned Volume Formula. (arXiv:2012.03955v2 [hep-th] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-th/1/au:+Craven_J/0/1/0/all/0/1">Jessica Craven</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Jejjala_V/0/1/0/all/0/1">Vishnu Jejjala</a>, <a href="http://arxiv.org/find/hep-th/1/au:+Kar_A/0/1/0/all/0/1">Arjun Kar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03955">
                                    <div class="article-summary-box-inner">
                                        <span>We present a simple phenomenological formula which approximates the
hyperbolic volume of a knot using only a single evaluation of its Jones
polynomial at a root of unity. The average error is just $2.86$% on the first
$1.7$ million knots, which represents a large improvement over previous
formulas of this kind. To find the approximation formula, we use layer-wise
relevance propagation to reverse engineer a black box neural network which
achieves a similar average error for the same approximation task when trained
on $10$% of the total dataset. The particular roots of unity which appear in
our analysis cannot be written as $e^{2\pi i / (k+2)}$ with integer $k$;
therefore, the relevant Jones polynomial evaluations are not given by
unknot-normalized expectation values of Wilson loop operators in conventional
$SU(2)$ Chern$\unicode{x2013}$Simons theory with level $k$. Instead, they
correspond to an analytic continuation of such expectation values to fractional
level. We briefly review the continuation procedure and comment on the presence
of certain Lefschetz thimbles, to which our approximation formula is sensitive,
in the analytically continued Chern$\unicode{x2013}$Simons integration cycle.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Framework to Learn with Interpretation. (arXiv:2010.09345v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parekh_J/0/1/0/all/0/1">Jayneel Parekh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mozharovskyi_P/0/1/0/all/0/1">Pavlo Mozharovskyi</a>, <a href="http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1">Florence d&#x27;Alch&#xe9;-Buc</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09345">
                                    <div class="article-summary-box-inner">
                                        <span>To tackle interpretability in deep learning, we present a novel framework to
jointly learn a predictive model and its associated interpretation model. The
interpreter provides both local and global interpretability about the
predictive model in terms of human-understandable high level attribute
functions, with minimal loss of accuracy. This is achieved by a dedicated
architecture and well chosen regularization penalties. We seek for a small-size
dictionary of high level attribute functions that take as inputs the outputs of
selected hidden layers and whose outputs feed a linear classifier. We impose
strong conciseness on the activation of attributes with an entropy-based
criterion while enforcing fidelity to both inputs and outputs of the predictive
model. A detailed pipeline to visualize the learnt features is also developed.
Moreover, besides generating interpretable models by design, our approach can
be specialized to provide post-hoc interpretations for a pre-trained neural
network. We validate our approach against several state-of-the-art methods on
multiple datasets and show its efficacy on both kinds of tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Composite Optimization. (arXiv:2011.08474v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Honglin Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1">Manzil Zaheer</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddi_S/0/1/0/all/0/1">Sashank Reddi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08474">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) is a distributed learning paradigm that scales
on-device learning collaboratively and privately. Standard FL algorithms such
as FedAvg are primarily geared towards smooth unconstrained settings. In this
paper, we study the Federated Composite Optimization (FCO) problem, in which
the loss function contains a non-smooth regularizer. Such problems arise
naturally in FL applications that involve sparsity, low-rank, monotonicity, or
more general constraints. We first show that straightforward extensions of
primal algorithms such as FedAvg are not well-suited for FCO since they suffer
from the &quot;curse of primal averaging,&quot; resulting in poor convergence. As a
solution, we propose a new primal-dual algorithm, Federated Dual Averaging
(FedDualAvg), which by employing a novel server dual averaging procedure
circumvents the curse of primal averaging. Our theoretical analysis and
empirical experiments demonstrate that FedDualAvg outperforms the other
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation of deep learning models for multi-step ahead time series prediction. (arXiv:2103.14250v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1">Rohitash Chandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_S/0/1/0/all/0/1">Shaurya Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1">Rishabh Gupta</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14250">
                                    <div class="article-summary-box-inner">
                                        <span>Time series prediction with neural networks has been the focus of much
research in the past few decades. Given the recent deep learning revolution,
there has been much attention in using deep learning models for time series
prediction, and hence it is important to evaluate their strengths and
weaknesses. In this paper, we present an evaluation study that compares the
performance of deep learning models for multi-step ahead time series
prediction. The deep learning methods comprise simple recurrent neural
networks, long short-term memory (LSTM) networks, bidirectional LSTM networks,
encoder-decoder LSTM networks, and convolutional neural networks. We provide a
further comparison with simple neural networks that use stochastic gradient
descent and adaptive moment estimation (Adam) for training. We focus on
univariate time series for multi-step-ahead prediction from benchmark
time-series datasets and provide a further comparison of the results with
related methods from the literature. The results show that the bidirectional
and encoder-decoder LSTM network provides the best performance in accuracy for
the given time series problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably End-to-end Label-Noise Learning without Anchor Points. (arXiv:2102.02400v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xuefeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tongliang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1">Bo Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Gang Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1">Masashi Sugiyama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02400">
                                    <div class="article-summary-box-inner">
                                        <span>In label-noise learning, the transition matrix plays a key role in building
statistically consistent classifiers. Existing consistent estimators for the
transition matrix have been developed by exploiting anchor points. However, the
anchor-point assumption is not always satisfied in real scenarios. In this
paper, we propose an end-to-end framework for solving label-noise learning
without anchor points, in which we simultaneously optimize two objectives: the
cross entropy loss between the prediction by the neural network and the given
noisy label, and the volume of the simplex formed by the columns of the
transition matrix. Our proposed framework can identify the transition matrix if
the clean class-posterior probabilities are sufficiently scattered. This is by
far the mildest assumption under which the transition matrix is provably
identifiable and the learned classifier is statistically consistent.
Experimental results on benchmark datasets demonstrate the effectiveness and
robustness of the proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Maximum Entropy Inverse Reinforcement Learning: New Perspectives and Algorithms. (arXiv:2012.00889v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Snoswell_A/0/1/0/all/0/1">Aaron J. Snoswell</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Surya P. N. Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_N/0/1/0/all/0/1">Nan Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00889">
                                    <div class="article-summary-box-inner">
                                        <span>We provide new perspectives and inference algorithms for Maximum Entropy
(MaxEnt) Inverse Reinforcement Learning (IRL), which provides a principled
method to find a most non-committal reward function consistent with given
expert demonstrations, among many consistent reward functions.

We first present a generalized MaxEnt formulation based on minimizing a
KL-divergence instead of maximizing an entropy. This improves the previous
heuristic derivation of the MaxEnt IRL model (for stochastic MDPs), allows a
unified view of MaxEnt IRL and Relative Entropy IRL, and leads to a model-free
learning algorithm for the MaxEnt IRL model. Second, a careful review of
existing inference algorithms and implementations showed that they
approximately compute the marginals required for learning the model. We provide
examples to illustrate this, and present an efficient and exact inference
algorithm. Our algorithm can handle variable length demonstrations; in
addition, while a basic version takes time quadratic in the maximum
demonstration length L, an improved version of this algorithm reduces this to
linear using a padding trick.

Experiments show that our exact algorithm improves reward learning as
compared to the approximate ones. Furthermore, our algorithm scales up to a
large, real-world dataset involving driver behaviour forecasting. We provide an
optimized implementation compatible with the OpenAI Gym interface. Our new
insight and algorithms could possibly lead to further interest and exploration
of the original MaxEnt IRL model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conditional Versus Adversarial Euler-based Generators For Time Series. (arXiv:2102.05313v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Remlinger_C/0/1/0/all/0/1">Carl Remlinger</a>, <a href="http://arxiv.org/find/stat/1/au:+Mikael_J/0/1/0/all/0/1">Joseph Mikael</a>, <a href="http://arxiv.org/find/stat/1/au:+Elie_R/0/1/0/all/0/1">Romuald Elie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05313">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce three new generative models for time series. Based on Euler
discretization and Wasserstein metrics, they are able to capture time marginal
distributions and temporal dynamics. Two of these methods rely on the
adaptation of generative adversarial networks (GANs) to time series. Both of
them outperform state-of-the-art benchmarks by capturing the underlying
temporal structure on synthetic time series. The third algorithm, called
Conditional Euler Generator (CEGEN), minimizes a dedicated distance between the
transition probability distributions over all time steps. In the context of Ito
processes, we provide theoretical guarantees that minimizing this criterion
implies accurate estimations of the drift and volatility parameters. We
demonstrate empirically that CEGEN outperforms state-of-the-art and GAN
generators on both marginal and temporal dynamics metrics. Besides, it
identifies accurate correlation structures in high dimension. When few data
points are available, we verify the effectiveness of CEGEN, when combined with
transfer learning methods on Monte Carlo simulations. Finally, we illustrate
the robustness of our method on various real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning High Dimensional Wasserstein Geodesics. (arXiv:2102.02992v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shaojun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yongxin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongyuan Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Haomin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02992">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new formulation and learning strategy for computing the
Wasserstein geodesic between two probability distributions in high dimensions.
By applying the method of Lagrange multipliers to the dynamic formulation of
the optimal transport (OT) problem, we derive a minimax problem whose saddle
point is the Wasserstein geodesic. We then parametrize the functions by deep
neural networks and design a sample based bidirectional learning algorithm for
training. The trained networks enable sampling from the Wasserstein geodesic.
As by-products, the algorithm also computes the Wasserstein distance and OT map
between the marginal distributions. We demonstrate the performance of our
algorithms through a series of experiments with both synthetic and realistic
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring Model Biases in the Absence of Ground Truth. (arXiv:2103.03417v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aka_O/0/1/0/all/0/1">Osman Aka</a>, <a href="http://arxiv.org/find/cs/1/au:+Burke_K/0/1/0/all/0/1">Ken Burke</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauerle_A/0/1/0/all/0/1">Alex B&#xe4;uerle</a>, <a href="http://arxiv.org/find/cs/1/au:+Greer_C/0/1/0/all/0/1">Christina Greer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1">Margaret Mitchell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03417">
                                    <div class="article-summary-box-inner">
                                        <span>The measurement of bias in machine learning often focuses on model
performance across identity subgroups (such as man and woman) with respect to
groundtruth labels. However, these methods do not directly measure the
associations that a model may have learned, for example between labels and
identity subgroups. Further, measuring a model&#x27;s bias requires a fully
annotated evaluation dataset which may not be easily available in practice. We
present an elegant mathematical solution that tackles both issues
simultaneously, using image classification as a working example. By treating a
classification model&#x27;s predictions for a given image as a set of labels
analogous to a bag of words, we rank the biases that a model has learned with
respect to different identity labels. We use (man, woman) as a concrete example
of an identity label set (although this set need not be binary), and present
rankings for the labels that are most biased towards one identity or the other.
We demonstrate how the statistical properties of different association metrics
can lead to different rankings of the most &quot;gender biased&quot; labels, and conclude
that normalized pointwise mutual information (nPMI) is most useful in practice.
Finally, we announce an open-sourced nPMI visualization tool using TensorBoard.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to distribute data across tasks for meta-learning?. (arXiv:2103.08463v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cioba_A/0/1/0/all/0/1">Alexandru Cioba</a>, <a href="http://arxiv.org/find/cs/1/au:+Bromberg_M/0/1/0/all/0/1">Michael Bromberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qian Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niyogi_R/0/1/0/all/0/1">Ritwik Niyogi</a>, <a href="http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1">Georgios Batzolis</a>, <a href="http://arxiv.org/find/cs/1/au:+Garcia_J/0/1/0/all/0/1">Jezabel Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Shiu_D/0/1/0/all/0/1">Da-shan Shiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernacchia_A/0/1/0/all/0/1">Alberto Bernacchia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08463">
                                    <div class="article-summary-box-inner">
                                        <span>Meta-learning models transfer the knowledge acquired from previous tasks to
quickly learn new ones. They are trained on benchmarks with a fixed number of
data points per task. This number is usually arbitrary and it is unknown how it
affects performance at testing. Since labelling of data is expensive, finding
the optimal allocation of labels across training tasks may reduce costs. Given
a fixed budget of labels, should we use a small number of highly labelled
tasks, or many tasks with few labels each? Should we allocate more labels to
some tasks and less to others? We show that: 1) If tasks are homogeneous, there
is a uniform optimal allocation, whereby all tasks get the same amount of data;
2) At fixed budget, there is a trade-off between number of tasks and number of
data points per task, with a unique and constant optimum; 3) When trained
separately, harder task should get more data, at the cost of a smaller number
of tasks; 4) When training on a mixture of easy and hard tasks, more data
should be allocated to easy tasks. Interestingly, Neuroscience experiments have
shown that human visual skills also transfer better from easy tasks. We prove
these results mathematically on mixed linear regression, and we show
empirically that the same results hold for few-shot image classification on
CIFAR-FS and mini-ImageNet. Our results provide guidance for allocating labels
across tasks when collecting data for meta-learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PeerGAN: Generative Adversarial Networks with a Competing Peer Discriminator. (arXiv:2101.07524v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jiaheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Minghao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_J/0/1/0/all/0/1">Jiahao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiutong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">James Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07524">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce PeerGAN, a generative adversarial network (GAN)
solution to improve the stability of the generated samples and to mitigate mode
collapse. Built upon the Vanilla GAN&#x27;s two-player game between the
discriminator $D_1$ and the generator $G$, we introduce a peer discriminator
$D_2$ to the min-max game. Similar to previous work using two discriminators,
the first role of both $D_1$, $D_2$ is to distinguish between generated samples
and real ones, while the generator tries to generate high-quality samples which
are able to fool both discriminators. Different from existing methods, we
introduce another game between $D_1$ and $D_2$ to discourage their agreement
and therefore increase the level of diversity of the generated samples. This
property alleviates the issue of early mode collapse by preventing $D_1$ and
$D_2$ from converging too fast. We provide theoretical analysis for the
equilibrium of the min-max game formed among $G, D_1, D_2$. We offer
convergence behavior of PeerGAN as well as stability of the min-max game. It&#x27;s
worth mentioning that PeerGAN operates in the unsupervised setting, and the
additional game between $D_1$ and $D_2$ does not need any label supervision.
Experiments results on a synthetic dataset and on real-world image datasets
(MNIST, Fashion MNIST, CIFAR-10, STL-10, CelebA, VGG) demonstrate that PeerGAN
outperforms competitive baseline work in generating diverse and high-quality
samples, while only introduces negligible computation cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-Invariant State Abstractions for Model-Based Reinforcement Learning. (arXiv:2102.09850v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tomar_M/0/1/0/all/0/1">Manan Tomar</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Amy Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1">Roberto Calandra</a>, <a href="http://arxiv.org/find/cs/1/au:+Taylor_M/0/1/0/all/0/1">Matthew E. Taylor</a>, <a href="http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1">Joelle Pineau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09850">
                                    <div class="article-summary-box-inner">
                                        <span>Accuracy and generalization of dynamics models is key to the success of
model-based reinforcement learning (MBRL). As the complexity of tasks
increases, so does the sample inefficiency of learning accurate dynamics
models. However, many complex tasks also exhibit sparsity in the dynamics,
i.e., actions have only a local effect on the system dynamics. In this paper,
we exploit this property with a causal invariance perspective in the
single-task setting, introducing a new type of state abstraction called
\textit{model-invariance}. Unlike previous forms of state abstractions, a
model-invariance state abstraction leverages causal sparsity over state
variables. This allows for compositional generalization to unseen states,
something that non-factored forms of state abstractions cannot do. We prove
that an optimal policy can be learned over this model-invariance state
abstraction and show improved generalization in a simple toy domain. Next, we
propose a practical method to approximately learn a model-invariant
representation for complex domains and validate our approach by showing
improved modelling performance over standard maximum likelihood approaches on
challenging tasks, such as the MuJoCo-based Humanoid. Finally, within the MBRL
setting we show strong performance gains with respect to sample efficiency
across a host of other continuous control tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Resource Allocation in Multi-armed Bandit Exploration: Overcoming Sublinear Scaling with Adaptive Parallelism. (arXiv:2011.00330v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1">Brijen Thananjeyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kandasamy_K/0/1/0/all/0/1">Kirthevasan Kandasamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1">Ion Stoica</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1">Ken Goldberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00330">
                                    <div class="article-summary-box-inner">
                                        <span>We study exploration in stochastic multi-armed bandits when we have access to
a divisible resource that can be allocated in varying amounts to arm pulls. We
focus in particular on the allocation of distributed computing resources, where
we may obtain results faster by allocating more resources per pull, but might
have reduced throughput due to nonlinear scaling. For example, in
simulation-based scientific studies, an expensive simulation can be sped up by
running it on multiple cores. This speed-up however, is partly offset by the
communication among cores, which results in lower throughput than if fewer
cores were allocated per trial to run more trials in parallel. In this paper,
we explore these trade-offs in two settings. First, in a fixed confidence
setting, we need to find the best arm with a given target success probability
as quickly as possible. We propose an algorithm which trades off between
information accumulation and throughput and show that the time taken can be
upper bounded by the solution of a dynamic program whose inputs are the gaps
between the sub-optimal and optimal arms. We also prove a matching hardness
result. Second, we present an algorithm for a fixed deadline setting, where we
are given a time deadline and need to maximize the probability of finding the
best arm. We corroborate our theoretical insights with simulation experiments
that show that the algorithms consistently match or outperform baseline
algorithms on a variety of problem instances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Witness Two-Sample Test. (arXiv:2102.05573v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kubler_J/0/1/0/all/0/1">Jonas M. K&#xfc;bler</a>, <a href="http://arxiv.org/find/cs/1/au:+Jitkrittum_W/0/1/0/all/0/1">Wittawat Jitkrittum</a>, <a href="http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1">Bernhard Sch&#xf6;lkopf</a>, <a href="http://arxiv.org/find/cs/1/au:+Muandet_K/0/1/0/all/0/1">Krikamol Muandet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05573">
                                    <div class="article-summary-box-inner">
                                        <span>The Maximum Mean Discrepancy (MMD) has been the state-of-the-art
nonparametric test for tackling the two-sample problem. Its statistic is given
by the difference in expectations of the witness function, a real-valued
function defined as a weighted sum of kernel evaluations on a set of basis
points. Typically the kernel is optimized on a training set, and hypothesis
testing is performed on a separate test set to avoid overfitting (i.e., control
type-I error). That is, the test set is used to simultaneously estimate the
expectations and define the basis points, while the training set only serves to
select the kernel and is discarded. In this work, we argue that this data
splitting scheme is overly conservative, and propose to use the training data
to also define the weights and the basis points for better data efficiency. We
show that 1) the new test is consistent and has a well-controlled type-I error;
2) the optimal witness function is given by a precision-weighted mean in the
reproducing kernel Hilbert space associated with the kernel, and is closely
related to kernel Fisher discriminant analysis; and 3) the test power of the
proposed test is comparable or exceeds that of the MMD and other modern tests,
as verified empirically on challenging synthetic and real problems (e.g., Higgs
data).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepCPCFG: Deep Learning and Context Free Grammars for End-to-End Information Extraction. (arXiv:2103.05908v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chua_F/0/1/0/all/0/1">Freddy C. Chua</a>, <a href="http://arxiv.org/find/cs/1/au:+Duffy_N/0/1/0/all/0/1">Nigel P. Duffy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05908">
                                    <div class="article-summary-box-inner">
                                        <span>We address the challenge of extracting structured information from business
documents without detailed annotations. We propose Deep Conditional
Probabilistic Context Free Grammars (DeepCPCFG) to parse two-dimensional
complex documents and use Recursive Neural Networks to create an end-to-end
system for finding the most probable parse that represents the structured
information to be extracted. This system is trained end-to-end with scanned
documents as input and only relational-records as labels. The
relational-records are extracted from existing databases avoiding the cost of
annotating documents by hand. We apply this approach to extract information
from scanned invoices achieving state-of-the-art results despite using no
hand-annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Integral Probability Metric based Regularization for Optimal Transport. (arXiv:2011.05001v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Manupriya_P/0/1/0/all/0/1">Piyushi Manupriya</a> (IIT Hyderabad, INDIA), <a href="http://arxiv.org/find/cs/1/au:+Nath_J/0/1/0/all/0/1">J. Saketha Nath</a> (IIT Hyderabad, INDIA), <a href="http://arxiv.org/find/cs/1/au:+Jawanpuria_P/0/1/0/all/0/1">Pratik Jawanpuria</a> (Microsoft IDC, INDIA)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05001">
                                    <div class="article-summary-box-inner">
                                        <span>Regularization in Optimal Transport (OT) problems has been shown to
critically affect the associated computational and sample complexities. It also
has been observed that regularization effectively helps in handling noisy
marginals as well as marginals with unequal masses. However, existing works on
OT restrict themselves to $\phi$-divergences based regularization. In this
work, we propose and analyze Integral Probability Metric (IPM) based
regularization in OT problems. While it is expected that the well-established
advantages of IPMs are inherited by the IPM-regularized OT variants, we
interestingly observe that some useful aspects of $\phi$-regularization are
preserved. For example, we show that the OT formulation, where the marginal
constraints are relaxed using IPM-regularization, also lifts the ground metric
to that over (perhaps un-normalized) measures. Infact, the lifted metric turns
out to be another IPM whose generating set is the intersection of that of the
IPM employed for regularization and the set of 1-Lipschitz functions under the
ground metric. Also, in the special case where the regularization is squared
maximum mean discrepancy based, the proposed OT variant, as well as the
corresponding Barycenter formulation, turn out to be those of minimizing a
convex quadratic subject to non-negativity/simplex constraints and hence can be
solved efficiently. Simulations confirm that the optimal transport plans/maps
obtained with IPM-regularization are intrinsically different from those
obtained with $\phi$-regularization. Empirical results illustrate the efficacy
of the proposed IPM-regularized OT formulation.

This draft contains the main paper and the Appendices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Thresholded Lasso Bandit. (arXiv:2010.11994v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ariu_K/0/1/0/all/0/1">Kaito Ariu</a>, <a href="http://arxiv.org/find/stat/1/au:+Abe_K/0/1/0/all/0/1">Kenshi Abe</a>, <a href="http://arxiv.org/find/stat/1/au:+Proutiere_A/0/1/0/all/0/1">Alexandre Prouti&#xe8;re</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11994">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we revisit the regret minimization problem in sparse
stochastic contextual linear bandits, where feature vectors may be of large
dimension $d$, but where the reward function depends on a few, say $s_0\ll d$,
of these features only. We present Thresholded Lasso bandit, an algorithm that
(i) estimates the vector defining the reward function as well as its sparse
support, i.e., significant feature elements, using the Lasso framework with
thresholding, and (ii) selects an arm greedily according to this estimate
projected on its support. The algorithm does not require prior knowledge of the
sparsity index $s_0$. For this simple algorithm, we establish non-asymptotic
regret upper bounds scaling as $\mathcal{O}( \log d + \sqrt{T} )$ in general,
and as $\mathcal{O}( \log d + \log T)$ under the so-called margin condition (a
setting where arms are well separated). The regret of previous algorithms
scales as $\mathcal{O}( \log d + \sqrt{T \log (d T)})$ and $\mathcal{O}( \log T
\log d)$ in the two settings, respectively. Through numerical experiments, we
confirm that our algorithm outperforms existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anonymizing Machine Learning Models. (arXiv:2007.13086v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goldsteen_A/0/1/0/all/0/1">Abigail Goldsteen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ezov_G/0/1/0/all/0/1">Gilad Ezov</a>, <a href="http://arxiv.org/find/cs/1/au:+Shmelkin_R/0/1/0/all/0/1">Ron Shmelkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Moffie_M/0/1/0/all/0/1">Micha Moffie</a>, <a href="http://arxiv.org/find/cs/1/au:+Farkash_A/0/1/0/all/0/1">Ariel Farkash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.13086">
                                    <div class="article-summary-box-inner">
                                        <span>There is a known tension between the need to analyze personal data to drive
business and privacy concerns. Many data protection regulations, including the
EU General Data Protection Regulation (GDPR) and the California Consumer
Protection Act (CCPA), set out strict restrictions and obligations on companies
that collect or process personal data. Moreover, machine learning models
themselves can be used to derive personal information, as demonstrated by
recent membership and attribute inference attacks. Anonymized data, however, is
exempt from data protection principles and obligations. Thus, models built on
anonymized data are also exempt from any privacy obligations, in addition to
providing better protection against such attacks on the training data. Learning
on anonymized data typically results in a significant degradation in accuracy.
We address this challenge by guiding our anonymization using the knowledge
encoded within the model, and targeting it to minimize the impact on the
model&#x27;s accuracy, a process we call accuracy-guided anonymization. We
demonstrate that by focusing on the model&#x27;s accuracy rather than information
loss, our method outperforms state of the art k-anonymity methods in terms of
the achieved utility, in particular with high values of k and large numbers of
quasi-identifiers. We also demonstrate that our approach achieves similar
results in its ability to prevent membership inference attacks as alternative
approaches based on differential privacy. This shows that model-guided
anonymization can, in some cases, be a legitimate substitute for such methods,
while averting some of their inherent drawbacks such as complexity, performance
overhead and being fitted to specific model types. As opposed to methods that
rely on adding noise during training, our approach does not rely on making any
modifications to the training algorithm itself.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unit Ball Model for Embedding Hierarchical Structures in the Complex Hyperbolic Space. (arXiv:2105.03966v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1">Huiru Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Caigao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yangqiu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">James Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_J/0/1/0/all/0/1">Junwu Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03966">
                                    <div class="article-summary-box-inner">
                                        <span>Learning the representation of data with hierarchical structures in the
hyperbolic space attracts increasing attention in recent years. Due to the
constant negative curvature, the hyperbolic space resembles tree metrics and
captures the tree-like properties naturally, which enables the hyperbolic
embeddings to improve over traditional Euclidean models. However, many
real-world hierarchically structured data such as taxonomies and multitree
networks have varying local structures and they are not trees, thus they do not
ubiquitously match the constant curvature property of the hyperbolic space. To
address this limitation of hyperbolic embeddings, we explore the complex
hyperbolic space, which has the variable negative curvature, for representation
learning. Specifically, we propose to learn the embeddings of hierarchically
structured data in the unit ball model of the complex hyperbolic space. The
unit ball model based embeddings have a more powerful representation capacity
to capture a variety of hierarchical structures. Through experiments on
synthetic and real-world data, we show that our approach improves over the
hyperbolic embedding models significantly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Embed Categorical Features without Embedding Tables for Recommendation. (arXiv:2010.10784v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kang_W/0/1/0/all/0/1">Wang-Cheng Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_D/0/1/0/all/0/1">Derek Zhiyuan Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_T/0/1/0/all/0/1">Tiansheng Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xinyang Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Ting Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1">Lichan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1">Ed H. Chi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10784">
                                    <div class="article-summary-box-inner">
                                        <span>Embedding learning of categorical features (e.g. user/item IDs) is at the
core of various recommendation models including matrix factorization and neural
collaborative filtering. The standard approach creates an embedding table where
each row represents a dedicated embedding vector for every unique feature
value. However, this method fails to efficiently handle high-cardinality
features and unseen feature values (e.g. new video ID) that are prevalent in
real-world recommendation systems. In this paper, we propose an alternative
embedding framework Deep Hash Embedding (DHE), replacing embedding tables by a
deep embedding network to compute embeddings on the fly. DHE first encodes the
feature value to a unique identifier vector with multiple hashing functions and
transformations, and then applies a DNN to convert the identifier vector to an
embedding. The encoding module is deterministic, non-learnable, and free of
storage, while the embedding network is updated during the training time to
learn embedding generation. Empirical results show that DHE achieves comparable
AUC against the standard one-hot full embedding, with smaller model sizes. Our
work sheds light on the design of DNN-based alternative embedding schemes for
categorical features without using embedding table lookup.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TinyTL: Reduce Activations, Not Trainable Parameters for Efficient On-Device Learning. (arXiv:2007.11622v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1">Han Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1">Chuang Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Ligeng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1">Song Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.11622">
                                    <div class="article-summary-box-inner">
                                        <span>On-device learning enables edge devices to continually adapt the AI models to
new data, which requires a small memory footprint to fit the tight memory
constraint of edge devices. Existing work solves this problem by reducing the
number of trainable parameters. However, this doesn&#x27;t directly translate to
memory saving since the major bottleneck is the activations, not parameters. In
this work, we present Tiny-Transfer-Learning (TinyTL) for memory-efficient
on-device learning. TinyTL freezes the weights while only learns the bias
modules, thus no need to store the intermediate activations. To maintain the
adaptation capacity, we introduce a new memory-efficient bias module, the lite
residual module, to refine the feature extractor by learning small residual
feature maps adding only 3.8% memory overhead. Extensive experiments show that
TinyTL significantly saves the memory (up to 6.5x) with little accuracy loss
compared to fine-tuning the full network. Compared to fine-tuning the last
layer, TinyTL provides significant accuracy improvements (up to 34.1%) with
little memory overhead. Furthermore, combined with feature extractor
adaptation, TinyTL provides 7.3-12.9x memory saving without sacrificing
accuracy compared to fine-tuning the full Inception-V3.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Open-Ended Commonsense Reasoning. (arXiv:2010.14439v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bill Yuchen Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Haitian Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1">Bhuwan Dhingra</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1">Manzil Zaheer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1">William W. Cohen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14439">
                                    <div class="article-summary-box-inner">
                                        <span>Current commonsense reasoning research focuses on developing models that use
commonsense knowledge to answer multiple-choice questions. However, systems
designed to answer multiple-choice questions may not be useful in applications
that do not provide a small list of candidate answers to choose from. As a step
towards making commonsense reasoning research more realistic, we propose to
study open-ended commonsense reasoning (OpenCSR) -- the task of answering a
commonsense question without any pre-defined choices -- using as a resource
only a corpus of commonsense facts written in natural language. OpenCSR is
challenging due to a large decision space, and because many questions require
implicit multi-hop reasoning. As an approach to OpenCSR, we propose DrFact, an
efficient Differentiable model for multi-hop Reasoning over knowledge Facts. To
evaluate OpenCSR methods, we adapt several popular commonsense reasoning
benchmarks, and collect multiple new answers for each test question via
crowd-sourcing. Experiments show that DrFact outperforms strong baseline
methods by a large margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Declarative Approaches to Counterfactual Explanations for Classification. (arXiv:2011.07423v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bertossi_L/0/1/0/all/0/1">Leopoldo Bertossi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07423">
                                    <div class="article-summary-box-inner">
                                        <span>We propose answer-set programs that specify and compute counterfactual
interventions on entities that are input on a classification model. In relation
to the outcome of the model, the resulting counterfactual entities serve as a
basis for the definition and computation of causality-based explanation scores
for the feature values in the entity under classification, namely
&quot;responsibility scores&quot;. The approach and the programs can be applied with
black-box models, and also with models that can be specified as logic programs,
such as rule-based classifiers. The main focus of this work is on the
specification and computation of &quot;best&quot; counterfactual entities, i.e. those
that lead to maximum responsibility scores. From them one can read off the
explanations as maximum responsibility feature values in the original entity.
We also extend the programs to bring into the picture semantic or domain
knowledge. We show how the approach could be extended by means of probabilistic
methods, and how the underlying probability distributions could be modified
through the use of constraints.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding the Performance of Knowledge Graph Embeddings in Drug Discovery. (arXiv:2105.10488v2 [q-bio.BM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Bonner_S/0/1/0/all/0/1">Stephen Bonner</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Barrett_I/0/1/0/all/0/1">Ian P Barrett</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ye_C/0/1/0/all/0/1">Cheng Ye</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Swiers_R/0/1/0/all/0/1">Rowan Swiers</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Engkvist_O/0/1/0/all/0/1">Ola Engkvist</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hoyt_C/0/1/0/all/0/1">Charles Tapley Hoyt</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hamilton_W/0/1/0/all/0/1">William L Hamilton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10488">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge Graphs (KG) and associated Knowledge Graph Embedding (KGE) models
have recently begun to be explored in the context of drug discovery and have
the potential to assist in key challenges such as target identification. In the
drug discovery domain, KGs can be employed as part of a process which can
result in lab-based experiments being performed, or impact on other decisions,
incurring significant time and financial costs and most importantly, ultimately
influencing patient healthcare. For KGE models to have impact in this domain, a
better understanding of not only of performance, but also the various factors
which determine it, is required.

In this study we investigate, over the course of many thousands of
experiments, the predictive performance of five KGE models on two public drug
discovery-oriented KGs. Our goal is not to focus on the best overall model or
configuration, instead we take a deeper look at how performance can be affected
by changes in the training setup, choice of hyperparameters, model parameter
initialisation seed and different splits of the datasets. Our results highlight
that these factors have significant impact on performance and can even affect
the ranking of models. Indeed these factors should be reported along with model
architectures to ensure complete reproducibility and fair comparisons of future
work, and we argue this is critical for the acceptance of use, and impact of
KGEs in a biomedical setting. To aid reproducibility of our own work, we
release all experimentation code.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring the originality of intellectual property assets based on machine learning outputs. (arXiv:2010.06997v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ragot_S/0/1/0/all/0/1">S&#xe9;bastien Ragot</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.06997">
                                    <div class="article-summary-box-inner">
                                        <span>Originality criteria are frequently used to compare assets and, in
particular, to assess the validity of intellectual property (IP) rights such as
copyright and design rights. In this work, the originality of an asset is
formulated as a function of the distances between this asset and its
comparands, using concepts of maximum entropy and surprisal analysis. Namely,
the originality function is defined according to the surprisal associated with
a given asset. Creative assets can be justifiably compared to particles that
repel each other via an electrostatic-like pair potential. This allows a very
simple, suitably bounded formula to be obtained, in which the originality of an
asset writes as the ratio of a reference energy to an interaction energy
imparted to that asset. In particular, the originality of an asset can be
expressed as a ratio of two average distances, i.e., the harmonic mean of the
distances from this asset to its comparands divided by the harmonic mean of the
distances between the sole comparands. Accordingly, the originality of objects
such as IP assets can be simply estimated based on distances computed thanks to
unsupervised machine learning techniques or other distance computation
algorithms. Application is made to various types of assets, including emojis,
typeface designs, paintings, and novel titles.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UNiTE: Unitary N-body Tensor Equivariant Network with Applications to Quantum Chemistry. (arXiv:2105.14655v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiao_Z/0/1/0/all/0/1">Zhuoran Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Christensen_A/0/1/0/all/0/1">Anders S. Christensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Welborn_M/0/1/0/all/0/1">Matthew Welborn</a>, <a href="http://arxiv.org/find/cs/1/au:+Manby_F/0/1/0/all/0/1">Frederick R. Manby</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1">Thomas F. Miller III</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14655">
                                    <div class="article-summary-box-inner">
                                        <span>Equivariant neural networks have been successful in incorporating various
types of symmetries, but are mostly limited to vector representations of
geometric objects. Despite the prevalence of higher-order tensors in various
application domains, e.g. in quantum chemistry, equivariant neural networks for
general tensors remain unexplored. Previous strategies for learning equivariant
functions on tensors mostly rely on expensive tensor factorization which is not
scalable when the dimensionality of the problem becomes large. In this work, we
propose unitary $N$-body tensor equivariant neural network (UNiTE), an
architecture for a general class of symmetric tensors called $N$-body tensors.
The proposed neural network is equivariant with respect to the actions of a
unitary group, such as the group of 3D rotations. Furthermore, it has a linear
time complexity with respect to the number of non-zero elements in the tensor.
We also introduce a normalization method, viz., Equivariant Normalization, to
improve generalization of the neural network while preserving symmetry. When
applied to quantum chemistry, UNiTE outperforms all state-of-the-art machine
learning methods of that domain with over 110% average improvements on multiple
benchmarks. Finally, we show that UNiTE achieves a robust zero-shot
generalization performance on diverse down stream chemistry tasks, while being
three orders of magnitude faster than conventional numerical methods with
competitive accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrepancy-Based Active Learning for Domain Adaptation. (arXiv:2103.03757v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mathelin_A/0/1/0/all/0/1">Antoine de Mathelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Deheeger_F/0/1/0/all/0/1">Francois Deheeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Mougeot_M/0/1/0/all/0/1">Mathilde Mougeot</a>, <a href="http://arxiv.org/find/cs/1/au:+Vayatis_N/0/1/0/all/0/1">Nicolas Vayatis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03757">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of the paper is to design active learning strategies which lead to
domain adaptation under an assumption of covariate shift in the case of
Lipschitz labeling function. Building on previous work by Mansour et al. (2009)
we adapt the concept of discrepancy distance between source and target
distributions to restrict the maximization over the hypothesis class to a
localized class of functions which are performing accurate labeling on the
source domain. We derive generalization error bounds for such active learning
strategies in terms of Rademacher average and localized discrepancy for general
loss functions which satisfy a regularity condition. A practical K-medoids
algorithm that can address the case of large data set is inferred from the
theoretical bounds. Our numerical experiments show that the proposed algorithm
is competitive against other state-of-the-art active learning techniques in the
context of domain adaptation, in particular on large data sets of around one
hundred thousand images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Refining Deep Generative Models via Discriminator Gradient Flow. (arXiv:2012.00780v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ansari_A/0/1/0/all/0/1">Abdul Fatir Ansari</a>, <a href="http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1">Ming Liang Ang</a>, <a href="http://arxiv.org/find/cs/1/au:+Soh_H/0/1/0/all/0/1">Harold Soh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00780">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative modeling has seen impressive advances in recent years, to the
point where it is now commonplace to see simulated samples (e.g., images) that
closely resemble real-world data. However, generation quality is generally
inconsistent for any given model and can vary dramatically between samples. We
introduce Discriminator Gradient flow (DGflow), a new technique that improves
generated samples via the gradient flow of entropy-regularized f-divergences
between the real and the generated data distributions. The gradient flow takes
the form of a non-linear Fokker-Plank equation, which can be easily simulated
by sampling from the equivalent McKean-Vlasov process. By refining inferior
samples, our technique avoids wasteful sample rejection used by previous
methods (DRS &amp; MH-GAN). Compared to existing works that focus on specific GAN
variants, we show our refinement approach can be applied to GANs with
vector-valued critics and even other deep generative models such as VAEs and
Normalizing Flows. Empirical results on multiple synthetic, image, and text
datasets demonstrate that DGflow leads to significant improvement in the
quality of generated samples for a variety of generative models, outperforming
the state-of-the-art Discriminator Optimal Transport (DOT) and Discriminator
Driven Latent Sampling (DDLS) methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neograd: Near-Ideal Gradient Descent. (arXiv:2010.07873v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zimmer_M/0/1/0/all/0/1">Michael F. Zimmer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.07873">
                                    <div class="article-summary-box-inner">
                                        <span>The purpose of this paper is to improve upon existing variants of gradient
descent by solving two problems: (1) removing (or reducing) the plateau that
occurs while minimizing the cost function,(2) continually adjusting the
learning rate to an &quot;ideal&quot; value. The approach taken is to approximately solve
for the learning rate as a function of a trust metric. When this technique is
hybridized with momentum, it creates an especially effective gradient descent
variant, called NeogradM. It is shown to outperform Adam on several test
problems, and can easily reach cost function values that are smaller by a
factor of $10^8$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Matching in Selective and Balanced Representation Space for Treatment Effects Estimation. (arXiv:2009.06828v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chu_Z/0/1/0/all/0/1">Zhixuan Chu</a>, <a href="http://arxiv.org/find/stat/1/au:+Rathbun_S/0/1/0/all/0/1">Stephen L. Rathbun</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_S/0/1/0/all/0/1">Sheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06828">
                                    <div class="article-summary-box-inner">
                                        <span>The dramatically growing availability of observational data is being
witnessed in various domains of science and technology, which facilitates the
study of causal inference. However, estimating treatment effects from
observational data is faced with two major challenges, missing counterfactual
outcomes and treatment selection bias. Matching methods are among the most
widely used and fundamental approaches to estimating treatment effects, but
existing matching methods have poor performance when facing data with high
dimensional and complicated variables. We propose a feature selection
representation matching (FSRM) method based on deep representation learning and
matching, which maps the original covariate space into a selective, nonlinear,
and balanced representation space, and then conducts matching in the learned
representation space. FSRM adopts deep feature selection to minimize the
influence of irrelevant variables for estimating treatment effects and
incorporates a regularizer based on the Wasserstein distance to learn balanced
representations. We evaluate the performance of our FSRM method on three
datasets, and the results demonstrate superiority over the state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding Negative Samples in Instance Discriminative Self-supervised Representation Learning. (arXiv:2102.06866v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nozawa_K/0/1/0/all/0/1">Kento Nozawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1">Issei Sato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06866">
                                    <div class="article-summary-box-inner">
                                        <span>Instance discriminative self-supervised representation learning has been
attracted attention thanks to its unsupervised nature and informative feature
representation for downstream tasks. In practice, it commonly uses a larger
number of negative samples than the number of supervised classes. However,
there is an inconsistency in the existing analysis; theoretically, a large
number of negative samples degrade classification performance on a downstream
supervised task, while empirically, they improve the performance. We provide a
novel framework to analyze this empirical result regarding negative samples
using the coupon collector&#x27;s problem. Our bound can implicitly incorporate the
supervised loss of the downstream task in the self-supervised loss by
increasing the number of negative samples. We confirm that our proposed
analysis holds on real-world benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Overcoming the curse of dimensionality with Laplacian regularization in semi-supervised learning. (arXiv:2009.04324v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Cabannes_V/0/1/0/all/0/1">Vivien Cabannes</a>, <a href="http://arxiv.org/find/stat/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1">Loucas Pillaud-Vivien</a>, <a href="http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1">Francis Bach</a>, <a href="http://arxiv.org/find/stat/1/au:+Rudi_A/0/1/0/all/0/1">Alessandro Rudi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04324">
                                    <div class="article-summary-box-inner">
                                        <span>As annotations of data can be scarce in large-scale practical problems,
leveraging unlabelled examples is one of the most important aspects of machine
learning. This is the aim of semi-supervised learning. To benefit from the
access to unlabelled data, it is natural to diffuse smoothly knowledge of
labelled data to unlabelled one. This induces to the use of Laplacian
regularization. Yet, current implementations of Laplacian regularization suffer
from several drawbacks, notably the well-known curse of dimensionality. In this
paper, we provide a statistical analysis to overcome those issues, and unveil a
large body of spectral filtering methods that exhibit desirable behaviors. They
are implemented through (reproducing) kernel methods, for which we provide
realistic computational guidelines in order to make our method usable with
large amounts of data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deconditional Downscaling with Gaussian Processes. (arXiv:2105.12909v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chau_S/0/1/0/all/0/1">Siu Lun Chau</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouabid_S/0/1/0/all/0/1">Shahine Bouabid</a>, <a href="http://arxiv.org/find/cs/1/au:+Sejdinovic_D/0/1/0/all/0/1">Dino Sejdinovic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12909">
                                    <div class="article-summary-box-inner">
                                        <span>Refining low-resolution (LR) spatial fields with high-resolution (HR)
information is challenging as the diversity of spatial datasets often prevents
direct matching of observations. Yet, when LR samples are modeled as aggregate
conditional means of HR samples with respect to a mediating variable that is
globally observed, the recovery of the underlying fine-grained field can be
framed as taking an &quot;inverse&quot; of the conditional expectation, namely a
deconditioning problem. In this work, we introduce conditional mean processes
(CMP), a new class of Gaussian Processes describing conditional means. By
treating CMPs as inter-domain features of the underlying field, a posterior for
the latent field can be established as a solution to the deconditioning
problem. Furthermore, we show that this solution can be viewed as a two-staged
vector-valued kernel ridge regressor and show that it has a minimax optimal
convergence rate under mild assumptions. Lastly, we demonstrate its proficiency
in a synthetic and a real-world atmospheric field downscaling problem, showing
substantial improvements over existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Learning by Self-Transition for Handling Noisy Labels. (arXiv:2012.04337v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1">Hwanjun Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minseok Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1">Dongmin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1">Yooju Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jae-Gil Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04337">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world data inevitably contains noisy labels, which induce the poor
generalization of deep neural networks. It is known that the network typically
begins to rapidly memorize false-labeled samples after a certain point of
training. Thus, to counter the label noise challenge, we propose a novel
self-transitional learning method called MORPH, which automatically switches
its learning phase at the transition point from seeding to evolution. In the
seeding phase, the network is updated using all the samples to collect a seed
of clean samples. Then, in the evolution phase, the network is updated using
only the set of arguably clean samples, which precisely keeps expanding by the
updated network. Thus, MORPH effectively avoids the overfitting to
false-labeled samples throughout the entire training period. Extensive
experiments using five real-world or synthetic benchmark datasets demonstrate
substantial improvements over state-of-the-art methods in terms of robustness
and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAR-U-Net: squeeze-and-excitation block and atrous spatial pyramid pooling based residual U-Net for automatic liver segmentation in Computed Tomography. (arXiv:2103.06419v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1">Jinke Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Lv_P/0/1/0/all/0/1">Peiqing Lv</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1">Haiying Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1">Changfa Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06419">
                                    <div class="article-summary-box-inner">
                                        <span>Background and objective: In this paper, a modified U-Net based framework is
presented, which leverages techniques from Squeeze-and-Excitation (SE) block,
Atrous Spatial Pyramid Pooling (ASPP) and residual learning for accurate and
robust liver CT segmentation, and the effectiveness of the proposed method was
tested on two public datasets LiTS17 and SLiver07.

Methods: A new network architecture called SAR-U-Net was designed. Firstly,
the SE block is introduced to adaptively extract image features after each
convolution in the U-Net encoder, while suppressing irrelevant regions, and
highlighting features of specific segmentation task; Secondly, ASPP was
employed to replace the transition layer and the output layer, and acquire
multi-scale image information via different receptive fields. Thirdly, to
alleviate the degradation problem, the traditional convolution block was
replaced with the residual block and thus prompt the network to gain accuracy
from considerably increased depth.

Results: In the LiTS17 experiment, the mean values of Dice, VOE, RVD, ASD and
MSD were 95.71, 9.52, -0.84, 1.54 and 29.14, respectively. Compared with other
closely related 2D-based models, the proposed method achieved the highest
accuracy. In the experiment of the SLiver07, the mean values of Dice, VOE, RVD,
ASD and MSD were 97.31, 5.37, -1.08, 1.85 and 27.45, respectively. Compared
with other closely related models, the proposed method achieved the highest
segmentation accuracy except for the RVD.

Conclusion: The proposed model enables a great improvement on the accuracy
compared to 2D-based models, and its robustness in circumvent challenging
problems, such as small liver regions, discontinuous liver regions, and fuzzy
liver boundaries, is also well demonstrated and validated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning Approaches for Binary Classification to Discover Liver Diseases using Clinical Data. (arXiv:2104.12055v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mostafa_F/0/1/0/all/0/1">Fahad B. Mostafa</a>, <a href="http://arxiv.org/find/stat/1/au:+Hasan_M/0/1/0/all/0/1">Md Easin Hasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.12055">
                                    <div class="article-summary-box-inner">
                                        <span>For a medical diagnosis, health professionals use different kinds of
pathological ways to make a decision for medical reports in terms of patients
medical condition. In the modern era, because of the advantage of computers and
technologies, one can collect data and visualize many hidden outcomes from
them. Statistical machine learning algorithms based on specific problems can
assist one to make decisions. Machine learning data driven algorithms can be
used to validate existing methods and help researchers to suggest potential new
decisions. In this paper, multiple imputation by chained equations was applied
to deal with missing data, and Principal Component Analysis to reduce the
dimensionality. To reveal significant findings, data visualizations were
implemented. We presented and compared many binary classifier machine learning
algorithms (Artificial Neural Network, Random Forest, Support Vector Machine)
which were used to classify blood donors and non-blood donors with hepatitis,
fibrosis and cirrhosis diseases. From the data published in UCI-MLR [1], all
mentioned techniques were applied to find one better method to classify blood
donors and non-blood donors (hepatitis, fibrosis, and cirrhosis) that can help
health professionals in a laboratory to make better decisions. Our proposed
ML-method showed better accuracy score (e.g. 98.23% for SVM). Thus, it improved
the quality of classification.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Learning with 1D Convolutions on Random Walks. (arXiv:2102.08786v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Toenshoff_J/0/1/0/all/0/1">Jan Toenshoff</a>, <a href="http://arxiv.org/find/cs/1/au:+Ritzert_M/0/1/0/all/0/1">Martin Ritzert</a>, <a href="http://arxiv.org/find/cs/1/au:+Wolf_H/0/1/0/all/0/1">Hinrikus Wolf</a>, <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08786">
                                    <div class="article-summary-box-inner">
                                        <span>We propose CRaWl (CNNs for Random Walks), a novel neural network architecture
for graph learning. It is based on processing sequences of small subgraphs
induced by random walks with standard 1D CNNs. Thus, CRaWl is fundamentally
different from typical message passing graph neural network architectures. It
is inspired by techniques counting small subgraphs, such as the graphlet kernel
and motif counting, and combines them with random walk based techniques in a
highly efficient and scalable neural architecture. We demonstrate empirically
that CRaWl matches or outperforms state-of-the-art GNN architectures across a
multitude of benchmark datasets for classification and regression on graphs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Sample Complexity of Stability Constrained Imitation Learning. (arXiv:2102.09161v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1">Stephen Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Robey_A/0/1/0/all/0/1">Alexander Robey</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tingnan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Matni_N/0/1/0/all/0/1">Nikolai Matni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09161">
                                    <div class="article-summary-box-inner">
                                        <span>We study the following question in the context of imitation learning for
continuous control: how are the underlying stability properties of an expert
policy reflected in the sample-complexity of an imitation learning task? We
provide the first results showing that a surprisingly granular connection can
be made between the underlying expert system&#x27;s incremental gain stability, a
novel measure of robust convergence between pairs of system trajectories, and
the dependency on the task horizon $T$ of the resulting generalization bounds.
In particular, we propose and analyze incremental gain stability constrained
versions of behavior cloning and a DAgger-like algorithm, and show that the
resulting sample-complexity bounds naturally reflect the underlying stability
properties of the expert system. As a special case, we delineate a class of
systems for which the number of trajectories needed to achieve
$\varepsilon$-suboptimality is sublinear in the task horizon $T$, and do so
without requiring (strong) convexity of the loss function in the policy
parameters. Finally, we conduct numerical experiments demonstrating the
validity of our insights on both a simple nonlinear system for which the
underlying stability properties can be easily tuned, and on a high-dimensional
quadrupedal robotic simulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Strength of Minibatch Noise in SGD. (arXiv:2102.05375v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ziyin_L/0/1/0/all/0/1">Liu Ziyin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kangqiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Mori_T/0/1/0/all/0/1">Takashi Mori</a>, <a href="http://arxiv.org/find/cs/1/au:+Ueda_M/0/1/0/all/0/1">Masahito Ueda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05375">
                                    <div class="article-summary-box-inner">
                                        <span>The noise in stochastic gradient descent (SGD), caused by minibatch sampling,
is poorly understood despite its practical importance in deep learning. In this
work, we study the nature of SGD noise and fluctuation. We show that some
degree of mismatch between model and data complexity is needed for SGD to
&#x60;&#x60;stir&quot; a noise; such mismatch may be due to a label or input noise,
regularization, or underparametrization. Compared with previous works, the
present work focuses on deriving exactly solvable analytical results. Our work
also motivates a more accurate general formulation to describe minibatch noise,
and we show that the SGD noise takes different shapes and strengths in
different kinds of minima.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exact Distribution-Free Hypothesis Tests for the Regression Function of Binary Classification via Conditional Kernel Mean Embeddings. (arXiv:2103.05126v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tamas_A/0/1/0/all/0/1">Ambrus Tam&#xe1;s</a>, <a href="http://arxiv.org/find/stat/1/au:+Csaji_B/0/1/0/all/0/1">Bal&#xe1;zs Csan&#xe1;d Cs&#xe1;ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05126">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we suggest two statistical hypothesis tests for the regression
function of binary classification based on conditional kernel mean embeddings.
The regression function is a fundamental object in classification as it
determines both the Bayes optimal classifier and the misclassification
probabilities. A resampling based framework is presented and combined with
consistent point estimators of the conditional kernel mean map, in order to
construct distribution-free hypothesis tests. These tests are introduced in a
flexible manner allowing us to control the exact probability of type I error
for any sample size. We also prove that both proposed techniques are consistent
under weak statistical assumptions, i.e., the type II error probabilities
pointwise converge to zero.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Fine-Tuning: Transferring Behavior in Reinforcement Learning. (arXiv:2102.13515v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Campos_V/0/1/0/all/0/1">V&#xed;ctor Campos</a>, <a href="http://arxiv.org/find/cs/1/au:+Sprechmann_P/0/1/0/all/0/1">Pablo Sprechmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Hansen_S/0/1/0/all/0/1">Steven Hansen</a>, <a href="http://arxiv.org/find/cs/1/au:+Barreto_A/0/1/0/all/0/1">Andre Barreto</a>, <a href="http://arxiv.org/find/cs/1/au:+Kapturowski_S/0/1/0/all/0/1">Steven Kapturowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Vitvitskyi_A/0/1/0/all/0/1">Alex Vitvitskyi</a>, <a href="http://arxiv.org/find/cs/1/au:+Badia_A/0/1/0/all/0/1">Adri&#xe0; Puigdom&#xe8;nech Badia</a>, <a href="http://arxiv.org/find/cs/1/au:+Blundell_C/0/1/0/all/0/1">Charles Blundell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13515">
                                    <div class="article-summary-box-inner">
                                        <span>Designing agents that acquire knowledge autonomously and use it to solve new
tasks efficiently is an important challenge in reinforcement learning.
Knowledge acquired during an unsupervised pre-training phase is often
transferred by fine-tuning neural network weights once rewards are exposed, as
is common practice in supervised domains. Given the nature of the reinforcement
learning problem, we argue that standard fine-tuning strategies alone are not
enough for efficient transfer in challenging domains. We introduce Behavior
Transfer (BT), a technique that leverages pre-trained policies for exploration
and that is complementary to transferring neural network weights. Our
experiments show that, when combined with large-scale pre-training in the
absence of rewards, existing intrinsic motivation objectives can lead to the
emergence of complex behaviors. These pre-trained policies can then be
leveraged by BT to discover better solutions than without pre-training, and
combining BT with standard fine-tuning strategies results in additional
benefits. The largest gains are generally observed in domains requiring
structured exploration, including settings where the behavior of the
pre-trained policies is misaligned with the downstream task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerating Inference for Sparse Extreme Multi-Label Ranking Trees. (arXiv:2106.02697v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Etter_P/0/1/0/all/0/1">Philip A. Etter</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhong_K/0/1/0/all/0/1">Kai Zhong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Hsiang-Fu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1">Lexing Ying</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1">Inderjit Dhillon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02697">
                                    <div class="article-summary-box-inner">
                                        <span>Tree-based models underpin many modern semantic search engines and
recommender systems due to their sub-linear inference times. In industrial
applications, these models operate at extreme scales, where every bit of
performance is critical. Memory constraints at extreme scales also require that
models be sparse, hence tree-based models are often back-ended by sparse matrix
algebra routines. However, there are currently no sparse matrix techniques
specifically designed for the sparsity structure one encounters in tree-based
models for extreme multi-label ranking/classification (XMR/XMC) problems. To
address this issue, we present the masked sparse chunk multiplication (MSCM)
technique, a sparse matrix technique specifically tailored to XMR trees. MSCM
is easy to implement, embarrassingly parallelizable, and offers a significant
performance boost to any existing tree inference pipeline at no cost. We
perform a comprehensive study of MSCM applied to several different sparse
inference schemes and benchmark our methods on a general purpose extreme
multi-label ranking framework. We observe that MSCM gives consistently dramatic
speedups across both the online and batch inference settings, single- and
multi-threaded settings, and on many different tree models and datasets. To
demonstrate its utility in industrial applications, we apply MSCM to an
enterprise-scale semantic product search problem with 100 million products and
achieve sub-millisecond latency of 0.88 ms per query on a single thread -- an
8x reduction in latency over vanilla inference techniques. The MSCM technique
requires absolutely no sacrifices to model accuracy as it gives exactly the
same results as standard sparse matrix techniques. Therefore, we believe that
MSCM will enable users of XMR trees to save a substantial amount of compute
resources in their inference pipelines at very little cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethink the Connections among Generalization, Memorization and the Spectral Bias of DNNs. (arXiv:2004.13954v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongrui Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.13954">
                                    <div class="article-summary-box-inner">
                                        <span>Over-parameterized deep neural networks (DNNs) with sufficient capacity to
memorize random noise can achieve excellent generalization performance,
challenging the bias-variance trade-off in classical learning theory. Recent
studies claimed that DNNs first learn simple patterns and then memorize noise;
some other works showed a phenomenon that DNNs have a spectral bias to learn
target functions from low to high frequencies during training. However, we show
that the monotonicity of the learning bias does not always hold: under the
experimental setup of deep double descent, the high-frequency components of
DNNs diminish in the late stage of training, leading to the second descent of
the test error. Besides, we find that the spectrum of DNNs can be applied to
indicating the second descent of the test error, even though it is calculated
from the training set only.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Distributed Source Coding. (arXiv:2106.02797v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Whang_J/0/1/0/all/0/1">Jay Whang</a>, <a href="http://arxiv.org/find/cs/1/au:+Acharya_A/0/1/0/all/0/1">Anish Acharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyeji Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimakis_A/0/1/0/all/0/1">Alexandros G. Dimakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02797">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed source coding is the task of encoding an input in the absence of
correlated side information that is only available to the decoder. Remarkably,
Slepian and Wolf showed in 1973 that an encoder that has no access to the
correlated side information can asymptotically achieve the same compression
rate as when the side information is available at both the encoder and the
decoder. While there is significant prior work on this topic in information
theory, practical distributed source coding has been limited to synthetic
datasets and specific correlation structures. Here we present a general
framework for lossy distributed source coding that is agnostic to the
correlation structure and can scale to high dimensions. Rather than relying on
hand-crafted source-modeling, our method utilizes a powerful conditional deep
generative model to learn the distributed encoder and decoder. We evaluate our
method on realistic high-dimensional datasets and show substantial improvements
in distributed compression performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Selective Inference for Latent Block Models. (arXiv:2005.13273v5 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Watanabe_C/0/1/0/all/0/1">Chihiro Watanabe</a>, <a href="http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1">Taiji Suzuki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.13273">
                                    <div class="article-summary-box-inner">
                                        <span>Model selection in latent block models has been a challenging but important
task in the field of statistics. Specifically, a major challenge is encountered
when constructing a test on a block structure obtained by applying a specific
clustering algorithm to a finite size matrix. In this case, it becomes crucial
to consider the selective bias in the block structure, that is, the block
structure is selected from all the possible cluster memberships based on some
criterion by the clustering algorithm. To cope with this problem, this study
provides a selective inference method for latent block models. Specifically, we
construct a statistical test on a set of row and column cluster memberships of
a latent block model, which is given by a squared residue minimization
algorithm. The proposed test, by its nature, includes and thus can also be used
as the test on the set of row and column cluster numbers. We also propose an
approximated version of the test based on simulated annealing to avoid
combinatorial explosion in searching the optimal block structure. The results
show that the proposed exact and approximated tests work effectively, compared
to the naive test that did not take the selective bias into account.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Noisy Label Models: Labeler-Dependent Noise with Adversarial Awareness. (arXiv:2105.14083v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dawson_G/0/1/0/all/0/1">Glenn Dawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Polikar_R/0/1/0/all/0/1">Robi Polikar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14083">
                                    <div class="article-summary-box-inner">
                                        <span>Most studies on learning from noisy labels rely on unrealistic models of
i.i.d. label noise, such as class-conditional transition matrices. More recent
work on instance-dependent noise models are more realistic, but assume a single
generative process for label noise across the entire dataset. We propose a more
principled model of label noise that generalizes instance-dependent noise to
multiple labelers, based on the observation that modern datasets are typically
annotated using distributed crowdsourcing methods. Under our labeler-dependent
model, label noise manifests itself under two modalities: natural error of
good-faith labelers, and adversarial labels provided by malicious actors. We
present two adversarial attack vectors that more accurately reflect the label
noise that may be encountered in real-world settings, and demonstrate that
under our multimodal noisy labels model, state-of-the-art approaches for
learning from noisy labels are defeated by adversarial label attacks. Finally,
we propose a multi-stage, labeler-aware, model-agnostic framework that reliably
filters noisy labels by leveraging knowledge about which data partitions were
labeled by which labeler, and show that our proposed framework remains robust
even in the presence of extreme adversarial label noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dodrio: Exploring Transformer Models with Interactive Visualization. (arXiv:2103.14625v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zijie J. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Turko_R/0/1/0/all/0/1">Robert Turko</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1">Duen Horng Chau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14625">
                                    <div class="article-summary-box-inner">
                                        <span>Why do large pre-trained transformer-based models perform so well across a
wide variety of NLP tasks? Recent research suggests the key may lie in
multi-headed attention mechanism&#x27;s ability to learn and represent linguistic
information. Understanding how these models represent both syntactic and
semantic knowledge is vital to investigate why they succeed and fail, what they
have learned, and how they can improve. We present Dodrio, an open-source
interactive visualization tool to help NLP researchers and practitioners
analyze attention mechanisms in transformer-based models with linguistic
knowledge. Dodrio tightly integrates an overview that summarizes the roles of
different attention heads, and detailed views that help users compare attention
weights with the syntactic structure and semantic information in the input
text. To facilitate the visual comparison of attention weights and linguistic
knowledge, Dodrio applies different graph visualization techniques to represent
attention weights scalable to longer input text. Case studies highlight how
Dodrio provides insights into understanding the attention mechanism in
transformer-based models. Dodrio is available at
https://poloclub.github.io/dodrio/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble Learning Based Classification Algorithm Recommendation. (arXiv:2101.05993v1 [cs.IR] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guangtao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qinbao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoyan Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.05993">
                                    <div class="article-summary-box-inner">
                                        <span>Recommending appropriate algorithms to a classification problem is one of the
most challenging issues in the field of data mining. The existing algorithm
recommendation models are generally constructed on only one kind of
meta-features by single learners. Considering that i) ensemble learners usually
show better performance and ii) different kinds of meta-features characterize
the classification problems in different viewpoints independently, and further
the models constructed with different sets of meta-features will be
complementary with each other and applicable for ensemble. This paper proposes
an ensemble learning-based algorithm recommendation method. To evaluate the
proposed recommendation method, extensive experiments with 13 well-known
candidate classification algorithms and five different kinds of meta-features
are conducted on 1090 benchmark classification problems. The results show the
effectiveness of the proposed ensemble learning based recommendation method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OpinionRank: Extracting Ground Truth Labels from Unreliable Expert Opinions with Graph-Based Spectral Ranking. (arXiv:2102.05884v2 [cs.LG] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dawson_G/0/1/0/all/0/1">Glenn Dawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Polikar_R/0/1/0/all/0/1">Robi Polikar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05884">
                                    <div class="article-summary-box-inner">
                                        <span>As larger and more comprehensive datasets become standard in contemporary
machine learning, it becomes increasingly more difficult to obtain reliable,
trustworthy label information with which to train sophisticated models. To
address this problem, crowdsourcing has emerged as a popular, inexpensive, and
efficient data mining solution for performing distributed label collection.
However, crowdsourced annotations are inherently untrustworthy, as the labels
are provided by anonymous volunteers who may have varying, unreliable
expertise. Worse yet, some participants on commonly used platforms such as
Amazon Mechanical Turk may be adversarial, and provide intentionally incorrect
label information without the end user&#x27;s knowledge. We discuss three
conventional models of the label generation process, describing their
parameterizations and the model-based approaches used to solve them. We then
propose OpinionRank, a model-free, interpretable, graph-based spectral
algorithm for integrating crowdsourced annotations into reliable labels for
performing supervised or semi-supervised learning. Our experiments show that
OpinionRank performs favorably when compared against more highly parameterized
algorithms. We also show that OpinionRank is scalable to very large datasets
and numbers of label sources, and requires considerably fewer computational
resources than previous approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sparsification for Sums of Exponentials and its Algorithmic Applications. (arXiv:2106.02774v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jerry Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Allen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1">Ankur Moitra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02774">
                                    <div class="article-summary-box-inner">
                                        <span>Many works in signal processing and learning theory operate under the
assumption that the underlying model is simple, e.g. that a signal is
approximately $k$-Fourier-sparse or that a distribution can be approximated by
a mixture model that has at most $k$ components. However the problem of fitting
the parameters of such a model becomes more challenging when the
frequencies/components are too close together.

In this work we introduce new methods for sparsifying sums of exponentials
and give various algorithmic applications. First we study Fourier-sparse
interpolation without a frequency gap, where Chen et al. gave an algorithm for
finding an $\epsilon$-approximate solution which uses $k&#x27; &#x3D; \mbox{poly}(k, \log
1/\epsilon)$ frequencies. Second, we study learning Gaussian mixture models in
one dimension without a separation condition. Kernel density estimators give an
$\epsilon$-approximation that uses $k&#x27; &#x3D; O(k/\epsilon^2)$ components. These
methods both output models that are much more complex than what we started out
with. We show how to post-process to reduce the number of
frequencies/components down to $k&#x27; &#x3D; \widetilde{O}(k)$, which is optimal up to
logarithmic factors. Moreover we give applications to model selection. In
particular, we give the first algorithms for approximately (and robustly)
determining the number of components in a Gaussian mixture model that work
without a separation condition.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Counterfactual Explanations Can Be Manipulated. (arXiv:2106.02666v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Slack_D/0/1/0/all/0/1">Dylan Slack</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilgard_S/0/1/0/all/0/1">Sophie Hilgard</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakkaraju_H/0/1/0/all/0/1">Himabindu Lakkaraju</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Sameer Singh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02666">
                                    <div class="article-summary-box-inner">
                                        <span>Counterfactual explanations are emerging as an attractive option for
providing recourse to individuals adversely impacted by algorithmic decisions.
As they are deployed in critical applications (e.g. law enforcement, financial
lending), it becomes important to ensure that we clearly understand the
vulnerabilities of these methods and find ways to address them. However, there
is little understanding of the vulnerabilities and shortcomings of
counterfactual explanations. In this work, we introduce the first framework
that describes the vulnerabilities of counterfactual explanations and shows how
they can be manipulated. More specifically, we show counterfactual explanations
may converge to drastically different counterfactuals under a small
perturbation indicating they are not robust. Leveraging this insight, we
introduce a novel objective to train seemingly fair models where counterfactual
explanations find much lower cost recourse under a slight perturbation. We
describe how these models can unfairly provide low-cost recourse for specific
subgroups in the data while appearing fair to auditors. We perform experiments
on loan and violent crime prediction data sets where certain subgroups achieve
up to 20x lower cost recourse under the perturbation. These results raise
concerns regarding the dependability of current counterfactual explanation
techniques, which we hope will inspire investigations in robust counterfactual
explanations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Hyper-Flow Diffusion. (arXiv:2102.07945v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fountoulakis_K/0/1/0/all/0/1">Kimon Fountoulakis</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shenghao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07945">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, hypergraphs have attracted a lot of attention due to their ability
to capture complex relations among entities. The insurgence of hypergraphs has
resulted in data of increasing size and complexity that exhibit interesting
small-scale and local structure, e.g., small-scale communities and localized
node-ranking around a given set of seed nodes. Popular and principled ways to
capture the local structure are the local hypergraph clustering problem and
related seed set expansion problem. In this work, we propose the first local
diffusion method that achieves edge-size-independent Cheeger-type guarantee for
the problem of local hypergraph clustering while applying to a rich class of
higher-order relations that covers many previously studied special cases. Our
method is based on a primal-dual optimization formulation where the primal
problem has a natural network flow interpretation, and the dual problem has a
cut-based interpretation using the $\ell_2$-norm penalty on associated
cut-costs. We demonstrate the new technique is significantly better than
state-of-the-art methods on both synthetic and real-world data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable Uncertainty under Laplace Approximations. (arXiv:2010.02720v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kristiadi_A/0/1/0/all/0/1">Agustinus Kristiadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1">Matthias Hein</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1">Philipp Hennig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02720">
                                    <div class="article-summary-box-inner">
                                        <span>Laplace approximations are classic, computationally lightweight means for
constructing Bayesian neural networks (BNNs). As in other approximate BNNs, one
cannot necessarily expect the induced predictive uncertainty to be calibrated.
Here we develop a formalism to explicitly &quot;train&quot; the uncertainty in a
decoupled way to the prediction itself. To this end, we introduce uncertainty
units for Laplace-approximated networks: Hidden units associated with a
particular weight structure that can be added to any pre-trained,
point-estimated network. Due to their weights, these units are inactive -- they
do not affect the predictions. But their presence changes the geometry (in
particular the Hessian) of the loss landscape, thereby affecting the network&#x27;s
uncertainty estimates under a Laplace approximation. We show that such units
can be trained via an uncertainty-aware objective, improving standard Laplace
approximations&#x27; performance in various uncertainty quantification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustly Learning Mixtures of $k$ Arbitrary Gaussians. (arXiv:2012.02119v3 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bakshi_A/0/1/0/all/0/1">Ainesh Bakshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1">Ilias Diakonikolas</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_H/0/1/0/all/0/1">He Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1">Daniel M. Kane</a>, <a href="http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1">Pravesh K. Kothari</a>, <a href="http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1">Santosh S. Vempala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02119">
                                    <div class="article-summary-box-inner">
                                        <span>We give a polynomial-time algorithm for the problem of robustly estimating a
mixture of $k$ arbitrary Gaussians in $\mathbb{R}^d$, for any fixed $k$, in the
presence of a constant fraction of arbitrary corruptions. This resolves the
main open problem in several previous works on algorithmic robust statistics,
which addressed the special cases of robustly estimating (a) a single Gaussian,
(b) a mixture of TV-distance separated Gaussians, and (c) a uniform mixture of
two Gaussians. Our main tools are an efficient \emph{partial clustering}
algorithm that relies on the sum-of-squares method, and a novel \emph{tensor
decomposition} algorithm that allows errors in both Frobenius norm and low-rank
terms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Interpretable and Trustworthy are GAMs?. (arXiv:2006.06466v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Chun-Hao Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Sarah Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Lengerich_B/0/1/0/all/0/1">Ben Lengerich</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1">Anna Goldenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Caruana_R/0/1/0/all/0/1">Rich Caruana</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06466">
                                    <div class="article-summary-box-inner">
                                        <span>Generalized additive models (GAMs) have become a leading modelclass for
interpretable machine learning. However, there are many algorithms for training
GAMs, and these can learn different or even contradictory models, while being
equally accurate. Which GAM should we trust? In this paper, we quantitatively
and qualitatively investigate a variety of GAM algorithms on real and simulated
datasets. We find that GAMs with high feature sparsity (only using afew
variables to make predictions) can miss patterns in the data and be unfair to
rare subpopulations. Our results suggest that inductive bias plays a crucial
role in what interpretable models learn and that tree-based GAMs represent the
best balance of sparsity, fidelity and accuracy and thus appear to be the most
trustworthy GAM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Importance Weight Estimation and Generalization in Domain Adaptation under Label Shift. (arXiv:2011.14251v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1">Kamyar Azizzadenesheli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14251">
                                    <div class="article-summary-box-inner">
                                        <span>We study generalization under labeled shift for categorical and general
normed label spaces. We propose a series of methods to estimate the importance
weights from labeled source to unlabeled target domain and provide confidence
bounds for these estimators. We deploy these estimators and provide
generalization bounds in the unlabeled target domain.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Replay-based Continual Zero-Shot Learning. (arXiv:2101.08894v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1">Chandan Gautam</a>, <a href="http://arxiv.org/find/cs/1/au:+Parameswaran_S/0/1/0/all/0/1">Sethupathy Parameswaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1">Ashish Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaram_S/0/1/0/all/0/1">Suresh Sundaram</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08894">
                                    <div class="article-summary-box-inner">
                                        <span>Zero-shot learning is a new paradigm to classify objects from classes that
are not available at training time. Zero-shot learning (ZSL) methods have
attracted considerable attention in recent years because of their ability to
classify unseen/novel class examples. Most of the existing approaches on ZSL
works when all the samples from seen classes are available to train the model,
which does not suit real life. In this paper, we tackle this hindrance by
developing a generative replay-based continual ZSL (GRCZSL). The proposed
method endows traditional ZSL to learn from streaming data and acquire new
knowledge without forgetting the previous tasks&#x27; gained experience. We handle
catastrophic forgetting in GRCZSL by replaying the synthetic samples of seen
classes, which have appeared in the earlier tasks. These synthetic samples are
synthesized using the trained conditional variational autoencoder (VAE) over
the immediate past task. Moreover, we only require the current and immediate
previous VAE at any time for training and testing. The proposed GRZSL method is
developed for a single-head setting of continual learning, simulating a
real-world problem setting. In this setting, task identity is given during
training but unavailable during testing. GRCZSL performance is evaluated on
five benchmark datasets for the generalized setup of ZSL with fixed and dynamic
(incremental class) settings of continual learning. The existing class setting
presented recently in the literature is not suitable for a class-incremental
setting. Therefore, this paper proposes a new setting to address this issue.
Experimental results show that the proposed method significantly outperforms
the baseline and the state-of-the-art method and makes it more suitable for
real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving hybrid machine learning tasks by traversing weight space geodesics. (arXiv:2106.02793v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raghavan_G/0/1/0/all/0/1">Guruprasad Raghavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomson_M/0/1/0/all/0/1">Matt Thomson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02793">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning problems have an intrinsic geometric structure as central
objects including a neural network&#x27;s weight space and the loss function
associated with a particular task can be viewed as encoding the intrinsic
geometry of a given machine learning problem. Therefore, geometric concepts can
be applied to analyze and understand theoretical properties of machine learning
strategies as well as to develop new algorithms. In this paper, we address
three seemingly unrelated open questions in machine learning by viewing them
through a unified framework grounded in differential geometry. Specifically, we
view the weight space of a neural network as a manifold endowed with a
Riemannian metric that encodes performance on specific tasks. By defining a
metric, we can construct geodesic, minimum length, paths in weight space that
represent sets of networks of equivalent or near equivalent functional
performance on a specific task. We, then, traverse geodesic paths while
identifying networks that satisfy a second objective. Inspired by the geometric
insight, we apply our geodesic framework to 3 major applications: (i) Network
sparsification (ii) Mitigating catastrophic forgetting by constructing networks
with high performance on a series of objectives and (iii) Finding high-accuracy
paths connecting distinct local optima of deep networks in the non-convex loss
landscape. Our results are obtained on a wide range of network architectures
(MLP, VGG11/16) trained on MNIST, CIFAR-10/100. Broadly, we introduce a
geometric framework that unifies a range of machine learning objectives and
that can be applied to multiple classes of neural network architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bellman Eluder Dimension: New Rich Classes of RL Problems, and Sample-Efficient Algorithms. (arXiv:2102.00815v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Chi Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qinghua Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Miryoosefi_S/0/1/0/all/0/1">Sobhan Miryoosefi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.00815">
                                    <div class="article-summary-box-inner">
                                        <span>Finding the minimal structural assumptions that empower sample-efficient
learning is one of the most important research directions in Reinforcement
Learning (RL). This paper advances our understanding of this fundamental
question by introducing a new complexity measure -- Bellman Eluder (BE)
dimension. We show that the family of RL problems of low BE dimension is
remarkably rich, which subsumes a vast majority of existing tractable RL
problems including but not limited to tabular MDPs, linear MDPs, reactive
POMDPs, low Bellman rank problems as well as low Eluder dimension problems.
This paper further designs a new optimization-based algorithm -- GOLF, and
reanalyzes a hypothesis elimination-based algorithm -- OLIVE (proposed in Jiang
et al., 2017). We prove that both algorithms learn the near-optimal policies of
low BE dimension problems in a number of samples that is polynomial in all
relevant parameters, but independent of the size of state-action space. Our
regret and sample complexity results match or improve the best existing results
for several well-known subclasses of low BE dimension problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Accelerated Stochastic Gradient Descent. (arXiv:2006.08950v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Honglin Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1">Tengyu Ma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08950">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Federated Accelerated Stochastic Gradient Descent (FedAc), a
principled acceleration of Federated Averaging (FedAvg, also known as Local
SGD) for distributed optimization. FedAc is the first provable acceleration of
FedAvg that improves convergence speed and communication efficiency on various
types of convex functions. For example, for strongly convex and smooth
functions, when using $M$ workers, the previous state-of-the-art FedAvg
analysis can achieve a linear speedup in $M$ if given $M$ rounds of
synchronization, whereas FedAc only requires $M^{\frac{1}{3}}$ rounds.
Moreover, we prove stronger guarantees for FedAc when the objectives are
third-order smooth. Our technique is based on a potential-based perturbed
iterate analysis, a novel stability analysis of generalized accelerated SGD,
and a strategic tradeoff between acceleration and stability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Perfect reconstruction of sparse signals with piecewise continuous nonconvex penalties and nonconvexity control. (arXiv:1902.07436v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sakata_A/0/1/0/all/0/1">Ayaka Sakata</a>, <a href="http://arxiv.org/find/stat/1/au:+Obuchi_T/0/1/0/all/0/1">Tomoyuki Obuchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1902.07436">
                                    <div class="article-summary-box-inner">
                                        <span>We consider compressed sensing formulated as a minimization problem of
nonconvex sparse penalties, Smoothly Clipped Absolute deviation (SCAD) and
Minimax Concave Penalty (MCP). The nonconvexity of these penalties is
controlled by nonconvexity parameters, and L1 penalty is contained as a limit
with respect to these parameters. The analytically derived reconstruction limit
overcomes that of L1 and the algorithmic limit in the Bayes-optimal setting,
when the nonconvexity parameters have suitable values. However, for small
nonconvexity parameters, where the reconstruction of the relatively dense
signals is theoretically guaranteed, the corresponding approximate message
passing (AMP) cannot achieve perfect reconstruction. We identify that the
shrinks in the basin of attraction to the perfect reconstruction causes the
discrepancy between the AMP and corresponding theory using state evolution. A
part of the discrepancy is resolved by introducing the control of the
nonconvexity parameters to guide the AMP trajectory to the basin of the
attraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Linear Optimization over Wasserstein Balls. (arXiv:2004.07162v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Yue_M/0/1/0/all/0/1">Man-Chung Yue</a>, <a href="http://arxiv.org/find/math/1/au:+Kuhn_D/0/1/0/all/0/1">Daniel Kuhn</a>, <a href="http://arxiv.org/find/math/1/au:+Wiesemann_W/0/1/0/all/0/1">Wolfram Wiesemann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.07162">
                                    <div class="article-summary-box-inner">
                                        <span>Wasserstein balls, which contain all probability measures within a
pre-specified Wasserstein distance to a reference measure, have recently
enjoyed wide popularity in the distributionally robust optimization and machine
learning communities to formulate and solve data-driven optimization problems
with rigorous statistical guarantees. In this technical note we prove that the
Wasserstein ball is weakly compact under mild conditions, and we offer
necessary and sufficient conditions for the existence of optimal solutions. We
also characterize the sparsity of solutions if the Wasserstein ball is centred
at a discrete reference measure. In comparison with the existing literature,
which has proved similar results under different conditions, our proofs are
self-contained and shorter, yet mathematically rigorous, and our necessary and
sufficient conditions for the existence of optimal solutions are easily
verifiable in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Robustness of Vision Transformers to Adversarial Examples. (arXiv:2104.02610v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mahmood_K/0/1/0/all/0/1">Kaleel Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1">Rigel Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Dijk_M/0/1/0/all/0/1">Marten van Dijk</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02610">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in attention-based networks have shown that Vision
Transformers can achieve state-of-the-art or near state-of-the-art results on
many image classification tasks. This puts transformers in the unique position
of being a promising alternative to traditional convolutional neural networks
(CNNs). While CNNs have been carefully studied with respect to adversarial
attacks, the same cannot be said of Vision Transformers. In this paper, we
study the robustness of Vision Transformers to adversarial examples. Our
analyses of transformer security is divided into three parts. First, we test
the transformer under standard white-box and black-box attacks. Second, we
study the transferability of adversarial examples between CNNs and
transformers. We show that adversarial examples do not readily transfer between
CNNs and transformers. Based on this finding, we analyze the security of a
simple ensemble defense of CNNs and transformers. By creating a new attack, the
self-attention blended gradient attack, we show that such an ensemble is not
secure under a white-box adversary. However, under a black-box adversary, we
show that an ensemble can achieve unprecedented robustness without sacrificing
clean accuracy. Our analysis for this work is done using six types of white-box
attacks and two types of black-box attacks. Our study encompasses multiple
Vision Transformers, Big Transfer Models and CNN architectures trained on
CIFAR-10, CIFAR-100 and ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Hybrid Inference System for Improved Curvature Estimation in the Level-Set Method Using Machine Learning. (arXiv:2104.02951v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Larios_Cardenas_L/0/1/0/all/0/1">Luis &#xc1;ngel Larios-C&#xe1;rdenas</a>, <a href="http://arxiv.org/find/cs/1/au:+Gibou_F/0/1/0/all/0/1">Frederic Gibou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02951">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel hybrid strategy based on machine learning to improve
curvature estimation in the level-set method. The proposed inference system
couples enhanced neural networks with standard numerical schemes to compute
curvature more accurately. The core of our hybrid framework is a switching
mechanism that relies on well established numerical techniques to gauge
curvature. If the curvature magnitude is larger than a resolution-dependent
threshold, it uses a neural network to yield a better approximation. Our
networks are multilayer perceptrons fitted to synthetic data sets composed of
sinusoidal- and circular-interface samples at various configurations. To reduce
data set size and training complexity, we leverage the problem&#x27;s characteristic
symmetry and build our models on just half of the curvature spectrum. These
savings lead to a powerful inference system able to outperform any of its
numerical or neural component alone. Experiments with static, smooth interfaces
show that our hybrid solver is notably superior to conventional numerical
methods in coarse grids and along steep interface regions. Compared to prior
research, we have observed outstanding gains in precision after training the
regression model with data pairs from more than a single interface type and
transforming data with specialized input preprocessing. In particular, our
findings confirm that machine learning is a promising venue for reducing or
removing mass loss in the level-set method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks. (arXiv:2002.05123v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pony_R/0/1/0/all/0/1">Roi Pony</a>, <a href="http://arxiv.org/find/cs/1/au:+Naeh_I/0/1/0/all/0/1">Itay Naeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05123">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks for video classification, just like image classification
networks, may be subjected to adversarial manipulation. The main difference
between image classifiers and video classifiers is that the latter usually use
temporal information contained within the video. In this work we present a
manipulation scheme for fooling video classifiers by introducing a flickering
temporal perturbation that in some cases may be unnoticeable by human observers
and is implementable in the real world. After demonstrating the manipulation of
action classification of single videos, we generalize the procedure to make
universal adversarial perturbation, achieving high fooling ratio. In addition,
we generalize the universal perturbation and produce a temporal-invariant
perturbation, which can be applied to the video without synchronizing the
perturbation to the input. The attack was implemented on several target models
and the transferability of the attack was demonstrated. These properties allow
us to bridge the gap between simulated environment and real-world application,
as will be demonstrated in this paper for the first time for an over-the-air
flickering attack.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fed+: A Unified Approach to Robust Personalized Federated Learning. (arXiv:2009.06303v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1">Pengqian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kundu_A/0/1/0/all/0/1">Achintya Kundu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wynter_L/0/1/0/all/0/1">Laura Wynter</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1">Shiau Hong Lim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06303">
                                    <div class="article-summary-box-inner">
                                        <span>We present a class of methods for robust, personalized federated learning,
called Fed+, that unifies many federated learning algorithms. The principal
advantage of this class of methods is to better accommodate the real-world
characteristics found in federated training, such as the lack of IID data
across parties, the need for robustness to outliers or stragglers, and the
requirement to perform well on party-specific datasets. We achieve this through
a problem formulation that allows the central server to employ robust ways of
aggregating the local models while keeping the structure of local computation
intact. Without making any statistical assumption on the degree of
heterogeneity of local data across parties, we provide convergence guarantees
for Fed+ for convex and non-convex loss functions and robust aggregation. The
Fed+ theory is also equipped to handle heterogeneous computing environments
including stragglers without additional assumptions; specifically, the
convergence results cover the general setting where the number of local update
steps across parties can vary. We demonstrate the benefits of Fed+ through
extensive experiments across standard benchmark datasets as well as on a
challenging real-world problem in financial portfolio management where the
heterogeneity of party-level data can lead to training failure in standard
federated learning approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Sharp Blockwise Tensor Perturbation Bound for Orthogonal Iteration. (arXiv:2008.02437v2 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Luo_Y/0/1/0/all/0/1">Yuetian Luo</a>, <a href="http://arxiv.org/find/math/1/au:+Raskutti_G/0/1/0/all/0/1">Garvesh Raskutti</a>, <a href="http://arxiv.org/find/math/1/au:+Yuan_M/0/1/0/all/0/1">Ming Yuan</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_A/0/1/0/all/0/1">Anru R. Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.02437">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we develop novel perturbation bounds for the high-order
orthogonal iteration (HOOI) [DLDMV00b]. Under mild regularity conditions, we
establish blockwise tensor perturbation bounds for HOOI with guarantees for
both tensor reconstruction in Hilbert-Schmidt norm $\|\widehat{\bcT} - \bcT
\|_{\tHS}$ and mode-$k$ singular subspace estimation in Schatten-$q$ norm $\|
\sin \Theta (\widehat{\U}_k, \U_k) \|_q$ for any $q \geq 1$. We show the upper
bounds of mode-$k$ singular subspace estimation are unilateral and converge
linearly to a quantity characterized by blockwise errors of the perturbation
and signal strength. For the tensor reconstruction error bound, we express the
bound through a simple quantity $\xi$, which depends only on perturbation and
the multilinear rank of the underlying signal. Rate matching deterministic
lower bound for tensor reconstruction, which demonstrates the optimality of
HOOI, is also provided. Furthermore, we prove that one-step HOOI (i.e., HOOI
with only a single iteration) is also optimal in terms of tensor reconstruction
and can be used to lower the computational cost. The perturbation results are
also extended to the case that only partial modes of $\bcT$ have low-rank
structure. We support our theoretical results by extensive numerical studies.
Finally, we apply the novel perturbation bounds of HOOI on two applications,
tensor denoising and tensor co-clustering, from machine learning and
statistics, which demonstrates the superiority of the new perturbation results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Oops I Took A Gradient: Scalable Sampling for Discrete Distributions. (arXiv:2102.04509v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grathwohl_W/0/1/0/all/0/1">Will Grathwohl</a>, <a href="http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1">Kevin Swersky</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1">Milad Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1">David Duvenaud</a>, <a href="http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1">Chris J. Maddison</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04509">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a general and scalable approximate sampling strategy for
probabilistic models with discrete variables. Our approach uses gradients of
the likelihood function with respect to its discrete inputs to propose updates
in a Metropolis-Hastings sampler. We show empirically that this approach
outperforms generic samplers in a number of difficult settings including Ising
models, Potts models, restricted Boltzmann machines, and factorial hidden
Markov models. We also demonstrate the use of our improved sampler for training
deep energy-based models on high dimensional discrete data. This approach
outperforms variational auto-encoders and existing energy-based models.
Finally, we give bounds showing that our approach is near-optimal in the class
of samplers which propose local updates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GP-Tree: A Gaussian Process Classifier for Few-Shot Incremental Learning. (arXiv:2102.07868v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Achituve_I/0/1/0/all/0/1">Idan Achituve</a>, <a href="http://arxiv.org/find/cs/1/au:+Navon_A/0/1/0/all/0/1">Aviv Navon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yemini_Y/0/1/0/all/0/1">Yochai Yemini</a>, <a href="http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1">Gal Chechik</a>, <a href="http://arxiv.org/find/cs/1/au:+Fetaya_E/0/1/0/all/0/1">Ethan Fetaya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07868">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes (GPs) are non-parametric, flexible, models that work well
in many tasks. Combining GPs with deep learning methods via deep kernel
learning (DKL) is especially compelling due to the strong representational
power induced by the network. However, inference in GPs, whether with or
without DKL, can be computationally challenging on large datasets. Here, we
propose GP-Tree, a novel method for multi-class classification with Gaussian
processes and DKL. We develop a tree-based hierarchical model in which each
internal node of the tree fits a GP to the data using the P\&#x27;olya-Gamma
augmentation scheme. As a result, our method scales well with both the number
of classes and data size. We demonstrate the effectiveness of our method
against other Gaussian process training baselines, and we show how our general
GP approach achieves improved accuracy on standard incremental few-shot
learning benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Proof of Global Convergence of Gradient Descent for Deep ReLU Networks with Linear Widths. (arXiv:2101.09612v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1">Quynh Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09612">
                                    <div class="article-summary-box-inner">
                                        <span>We give a simple proof for the global convergence of gradient descent in
training deep ReLU networks with the standard square loss, and show some of its
improvements over the state-of-the-art. In particular, while prior works
require all the hidden layers to be wide with width at least $\Omega(N^8)$ ($N$
being the number of training samples), we require a single wide layer of
linear, quadratic or cubic width depending on the type of initialization.
Unlike many recent proofs based on the Neural Tangent Kernel (NTK), our proof
need not track the evolution of the entire NTK matrix, or more generally, any
quantities related to the changes of activation patterns during training.
Instead, we only need to track the evolution of the output at the last hidden
layer, which can be done much more easily thanks to the Lipschitz property of
ReLU. Some highlights of our setting: (i) all the layers are trained with
standard gradient descent, (ii) the network has standard parameterization as
opposed to the NTK one, and (iii) the network has a single wide layer as
opposed to having all wide hidden layers as in most of NTK-related results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orbital MCMC. (arXiv:2010.08047v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Neklyudov_K/0/1/0/all/0/1">Kirill Neklyudov</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08047">
                                    <div class="article-summary-box-inner">
                                        <span>Markov Chain Monte Carlo (MCMC) algorithms ubiquitously employ complex
deterministic transformations to generate proposal points that are then
filtered by the Metropolis-Hastings-Green (MHG) test. However, the condition of
the target measure invariance puts restrictions on the design of these
transformations. In this paper, we first derive the acceptance test for the
stochastic Markov kernel considering arbitrary deterministic maps as proposal
generators. When applied to the transformations with orbits of period two
(involutions), the test reduces to the MHG test. Based on the derived test we
propose two practical algorithms: one operates by constructing periodic orbits
from any diffeomorphism, another on contractions of the state space (such as
optimization trajectories). Finally, we perform an empirical study
demonstrating the practical advantages of both kernels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking the Implementation Matters in Cooperative Multi-Agent Reinforcement Learning. (arXiv:2102.03479v11 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1">Jian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Siyang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Harding_S/0/1/0/all/0/1">Seth Austin Harding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Haibin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1">Shih-wei Liao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03479">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-Agent Reinforcement Learning (MARL) has seen revolutionary
breakthroughs with its successful application to multi-agent cooperative tasks
such as computer games and robot swarms. QMIX, a widely popular MARL algorithm,
has been used to solve cooperative tasks, e.g. Starcraft Multi-Agent Challenge
(SMAC), Difficulty-Enhanced Predator-Prey (DEPP). Recent variants of QMIX
target relaxing the monotonicity constraint of QMIX, allowing for performance
improvement in SMAC. However, in this paper, we investigate the code-level
optimizations of these variants and the monotonicity constraint. We find that
(1) such improvements of the variants are significantly affected by various
code-level optimizations; (2) QMIX with normalized optimizations outperforms
other previous works in SMAC; (3) the monotonicity constraint may improve
sample efficiency in SMAC and DEPP. Last, a discussion with theoretical
analysis is demonstrated about why QMIX works well in SMAC. We open-source the
code at \url{https://github.com/hijkzzz/pymarl2}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Draw: Emergent Communication through Sketching. (arXiv:2106.02067v1 [cs.CV] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mihai_D/0/1/0/all/0/1">Daniela Mihai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1">Jonathon Hare</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02067">
                                    <div class="article-summary-box-inner">
                                        <span>Evidence that visual communication preceded written language and provided a
basis for it goes back to prehistory, in forms such as cave and rock paintings
depicting traces of our distant ancestors. Emergent communication research has
sought to explore how agents can learn to communicate in order to
collaboratively solve tasks. Existing research has focused on language, with a
learned communication channel transmitting sequences of discrete tokens between
the agents. In this work, we explore a visual communication channel between
agents that are allowed to draw with simple strokes. Our agents are
parameterised by deep neural networks, and the drawing procedure is
differentiable, allowing for end-to-end training. In the framework of a
referential communication game, we demonstrate that agents can not only
successfully learn to communicate by drawing, but with appropriate inductive
biases, can do so in a fashion that humans can interpret. We hope to encourage
future research to consider visual communication as a more flexible and
directly interpretable alternative of training collaborative agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Theory of Reinforcement Learning with Once-per-Episode Feedback. (arXiv:2105.14363v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chatterji_N/0/1/0/all/0/1">Niladri S. Chatterji</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1">Aldo Pacchiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1">Peter L. Bartlett</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14363">
                                    <div class="article-summary-box-inner">
                                        <span>We study a theory of reinforcement learning (RL) in which the learner
receives binary feedback only once at the end of an episode. While this is an
extreme test case for theory, it is also arguably more representative of
real-world applications than the traditional requirement in RL practice that
the learner receive feedback at every time step. Indeed, in many real-world
applications of reinforcement learning, such as self-driving cars and robotics,
it is easier to evaluate whether a learner&#x27;s complete trajectory was either
&quot;good&quot; or &quot;bad,&quot; but harder to provide a reward signal at each step. To show
that learning is possible in this more challenging setting, we study the case
where trajectory labels are generated by an unknown parametric model, and
provide a statistically and computationally efficient algorithm that achieves
sub-linear regret.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning the Positions in CountSketch. (arXiv:2007.09890v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Simin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tianrui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vakilian_A/0/1/0/all/0/1">Ali Vakilian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1">Yulin Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.09890">
                                    <div class="article-summary-box-inner">
                                        <span>We consider sketching algorithms which first quickly compress data by
multiplication with a random sketch matrix, and then apply the sketch to
quickly solve an optimization problem, e.g., low rank approximation. In the
learning-based sketching paradigm proposed by Indyk et al. [2019], the sketch
matrix is found by choosing a random sparse matrix, e.g., the CountSketch, and
then updating the values of the non-zero entries by running gradient descent on
a training data set. Despite the growing body of work on this paradigm, a
noticeable omission is that the locations of the non-zero entries of previous
algorithms were fixed, and only their values were learned. In this work we
propose the first learning algorithm that also optimizes the locations of the
non-zero entries. We show this algorithm gives better accuracy for low rank
approximation than previous work, and apply it to other problems such as
$k$-means clustering for the first time. We show that our algorithm is provably
better in the spiked covariance model and for Zipfian matrices. We also show
the importance of the sketch monotonicity property for combining learned
sketches. Our empirical results show the importance of optimizing not only the
values of the non-zero entries but also their positions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized Jensen-Shannon Divergence Loss for Learning with Noisy Labels. (arXiv:2105.04522v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Englesson_E/0/1/0/all/0/1">Erik Englesson</a>, <a href="http://arxiv.org/find/cs/1/au:+Azizpour_H/0/1/0/all/0/1">Hossein Azizpour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04522">
                                    <div class="article-summary-box-inner">
                                        <span>Prior works have found it beneficial to combine provably noise-robust loss
functions e.g., mean absolute error (MAE) with standard categorical loss
function e.g. cross entropy (CE) to improve their learnability. Here, we
propose to use Jensen-Shannon divergence as a noise-robust loss function and
show that it interestingly interpolate between CE and MAE with a controllable
mixing parameter. Furthermore, we make a crucial observation that CE exhibit
lower consistency around noisy data points. Based on this observation, we adopt
a generalized version of the Jensen-Shannon divergence for multiple
distributions to encourage consistency around data points. Using this loss
function, we show state-of-the-art results on both synthetic (CIFAR), and
real-world (WebVision) noise with varying noise rates.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable UAV Collision Avoidance using Deep Reinforcement Learning. (arXiv:2105.12254v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thomas_D/0/1/0/all/0/1">Deepak-George Thomas</a>, <a href="http://arxiv.org/find/cs/1/au:+Olshanskyi_D/0/1/0/all/0/1">Daniil Olshanskyi</a>, <a href="http://arxiv.org/find/cs/1/au:+Krueger_K/0/1/0/all/0/1">Karter Krueger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wongpiromsarn_T/0/1/0/all/0/1">Tichakorn Wongpiromsarn</a>, <a href="http://arxiv.org/find/cs/1/au:+Jannesari_A/0/1/0/all/0/1">Ali Jannesari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.12254">
                                    <div class="article-summary-box-inner">
                                        <span>The significant components of any successful autonomous flight system are
task completion and collision avoidance. Most deep learning algorithms
successfully execute these aspects under the environment and conditions they
are trained. However, they fail when subjected to novel environments. This
paper presents an autonomous multi-rotor flight algorithm, using Deep
Reinforcement Learning augmented with Self-Attention Models, that can
effectively reason when subjected to varying inputs. In addition to their
reasoning ability, they are also interpretable, enabling it to be used under
real-world conditions. We have tested our algorithm under different weather
conditions and environments and found it robust compared to conventional Deep
Reinforcement Learning algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers. (arXiv:2105.15203v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_E/0/1/0/all/0/1">Enze Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenhai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiding Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Alvarez_J/0/1/0/all/0/1">Jose M. Alvarez</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1">Ping Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15203">
                                    <div class="article-summary-box-inner">
                                        <span>We present SegFormer, a simple, efficient yet powerful semantic segmentation
framework which unifies Transformers with lightweight multilayer perception
(MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a
novel hierarchically structured Transformer encoder which outputs multiscale
features. It does not need positional encoding, thereby avoiding the
interpolation of positional codes which leads to decreased performance when the
testing resolution differs from training. 2) SegFormer avoids complex decoders.
The proposed MLP decoder aggregates information from different layers, and thus
combining both local attention and global attention to render powerful
representations. We show that this simple and lightweight design is the key to
efficient segmentation on Transformers. We scale our approach up to obtain a
series of models from SegFormer-B0 to SegFormer-B5, reaching significantly
better performance and efficiency than previous counterparts. For example,
SegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x
smaller and 2.2% better than the previous best method. Our best model,
SegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows
excellent zero-shot robustness on Cityscapes-C. Code will be released at:
github.com/NVlabs/SegFormer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Navigating to the Best Policy in Markov Decision Processes. (arXiv:2106.02847v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Marjani_A/0/1/0/all/0/1">Aymen Al Marjani</a>, <a href="http://arxiv.org/find/stat/1/au:+Garivier_A/0/1/0/all/0/1">Aur&#xe9;lien Garivier</a>, <a href="http://arxiv.org/find/stat/1/au:+Proutiere_A/0/1/0/all/0/1">Alexandre Proutiere</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02847">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the classical active pure exploration problem in Markov
Decision Processes, where the agent sequentially selects actions and, from the
resulting system trajectory, aims at identifying the best policy as fast as
possible. We propose an information-theoretic lower bound on the average number
of steps required before a correct answer can be given with probability at
least $1-\delta$. This lower bound involves a non-convex optimization problem,
for which we propose a convex relaxation. We further provide an algorithm whose
sample complexity matches the relaxed lower bound up to a factor $2$. This
algorithm addresses general communicating MDPs; we propose a variant with
reduced exploration rate (and hence faster convergence) under an additional
ergodicity assumption. This work extends previous results relative to the
\emph{generative setting}~\cite{marjani2020adaptive}, where the agent could at
each step observe the random outcome of any (state, action) pair. In contrast,
we show here how to deal with the \emph{navigation constraints}. Our analysis
relies on an ergodic theorem for non-homogeneous Markov chains which we
consider of wide interest in the analysis of Markov Decision Processes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DiscoBox: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision. (arXiv:2105.06464v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lan_S/0/1/0/all/0/1">Shiyi Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhiding Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Choy_C/0/1/0/all/0/1">Christopher Choy</a>, <a href="http://arxiv.org/find/cs/1/au:+Radhakrishnan_S/0/1/0/all/0/1">Subhashree Radhakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guilin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuke Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1">Larry S. Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1">Anima Anandkumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06464">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce DiscoBox, a novel framework that jointly learns instance
segmentation and semantic correspondence using bounding box supervision.
Specifically, we propose a self-ensembling framework where instance
segmentation and semantic correspondence are jointly guided by a structured
teacher in addition to the bounding box supervision. The teacher is a
structured energy model incorporating a pairwise potential and a cross-image
potential to model the pairwise pixel relationships both within and across the
boxes. Minimizing the teacher energy simultaneously yields refined object masks
and dense correspondences between intra-class objects, which are taken as
pseudo-labels to supervise the task network and provide positive/negative
correspondence pairs for dense constrastive learning. We show a symbiotic
relationship where the two tasks mutually benefit from each other. Our best
model achieves 37.9% AP on COCO instance segmentation, surpassing prior weakly
supervised methods and is competitive to supervised methods. We also obtain
state of the art weakly supervised results on PASCAL VOC12 and PF-PASCAL with
real-time inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Price of Incentivizing Exploration: A Characterization via Thompson Sampling and Sample Complexity. (arXiv:2002.00558v4 [cs.GT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sellke_M/0/1/0/all/0/1">Mark Sellke</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1">Aleksandrs Slivkins</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.00558">
                                    <div class="article-summary-box-inner">
                                        <span>We consider incentivized exploration: a version of multi-armed bandits where
the choice of arms is controlled by self-interested agents, and the algorithm
can only issue recommendations. The algorithm controls the flow of information,
and the information asymmetry can incentivize the agents to explore. Prior work
achieves optimal regret rates up to multiplicative factors that become
arbitrarily large depending on the Bayesian priors, and scale exponentially in
the number of arms. A more basic problem of sampling each arm once runs into
similar factors.

We focus on the price of incentives: the loss in performance, broadly
construed, incurred for the sake of incentive-compatibility. We prove that
Thompson Sampling, a standard bandit algorithm, is incentive-compatible if
initialized with sufficiently many data points. The performance loss due to
incentives is therefore limited to the initial rounds when these data points
are collected. The problem is largely reduced to that of sample complexity: how
many rounds are needed? We address this question, providing matching upper and
lower bounds and instantiating them in various corollaries. Typically, the
optimal sample complexity is polynomial in the number of arms and exponential
in the &quot;strength of beliefs&quot;.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerating Stochastic Simulation with Interactive Neural Processes. (arXiv:2106.02770v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongxia Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chinazzi_M/0/1/0/all/0/1">Matteo Chinazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vespignani_A/0/1/0/all/0/1">Alessandro Vespignani</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yi-An Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1">Rose Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02770">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic simulations such as large-scale, spatiotemporal, age-structured
epidemic models are computationally expensive at fine-grained resolution. We
propose Interactive Neural Process (INP), an interactive framework to
continuously learn a deep learning surrogate model and accelerate simulation.
Our framework is based on the novel integration of Bayesian active learning,
stochastic simulation and deep sequence modeling. In particular, we develop a
novel spatiotemporal neural process model to mimic the underlying process
dynamics. Our model automatically infers the latent process which describes the
intrinsic uncertainty of the simulator. This also gives rise to a new
acquisition function that can quantify the uncertainty of deep learning
predictions. We design Bayesian active learning algorithms to iteratively query
the simulator, gather more data, and continuously improve the model. We perform
theoretical analysis and demonstrate that our approach reduces sample
complexity compared with random sampling in high dimension. Empirically, we
demonstrate our framework can faithfully imitate the behavior of a complex
infectious disease simulator with a small number of examples, enabling rapid
simulation and scenario exploration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constrained episodic reinforcement learning in concave-convex and knapsack settings. (arXiv:2006.05051v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brantley_K/0/1/0/all/0/1">Kiant&#xe9; Brantley</a>, <a href="http://arxiv.org/find/cs/1/au:+Dudik_M/0/1/0/all/0/1">Miroslav Dudik</a>, <a href="http://arxiv.org/find/cs/1/au:+Lykouris_T/0/1/0/all/0/1">Thodoris Lykouris</a>, <a href="http://arxiv.org/find/cs/1/au:+Miryoosefi_S/0/1/0/all/0/1">Sobhan Miryoosefi</a>, <a href="http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1">Max Simchowitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1">Aleksandrs Slivkins</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Wen Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05051">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an algorithm for tabular episodic reinforcement learning with
constraints. We provide a modular analysis with strong theoretical guarantees
for settings with concave rewards and convex constraints, and for settings with
hard constraints (knapsacks). Most of the previous work in constrained
reinforcement learning is limited to linear constraints, and the remaining work
focuses on either the feasibility question or settings with a single episode.
Our experiments demonstrate that the proposed algorithm significantly
outperforms these approaches in existing constrained episodic environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Each Part Matters: Local Patterns Facilitate Cross-view Geo-localization. (arXiv:2008.11646v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tingyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhedong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_C/0/1/0/all/0/1">Chenggang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiyong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yaoqi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Bolun Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11646">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-view geo-localization is to spot images of the same geographic target
from different platforms, e.g., drone-view cameras and satellites. It is
challenging in the large visual appearance changes caused by extreme viewpoint
variations. Existing methods usually concentrate on mining the fine-grained
feature of the geographic target in the image center, but underestimate the
contextual information in neighbor areas. In this work, we argue that neighbor
areas can be leveraged as auxiliary information, enriching discriminative clues
for geolocalization. Specifically, we introduce a simple and effective deep
neural network, called Local Pattern Network (LPN), to take advantage of
contextual information in an end-to-end manner. Without using extra part
estimators, LPN adopts a square-ring feature partition strategy, which provides
the attention according to the distance to the image center. It eases the part
matching and enables the part-wise representation learning. Owing to the
square-ring partition design, the proposed LPN has good scalability to rotation
variations and achieves competitive results on three prevailing benchmarks,
i.e., University-1652, CVUSA and CVACT. Besides, we also show the proposed LPN
can be easily embedded into other frameworks to further boost performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weighting Adversarial Neural Network for Domain Adaptation in Regression. (arXiv:2006.08251v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mathelin_A/0/1/0/all/0/1">Antoine de Mathelin</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_G/0/1/0/all/0/1">Guillaume Richard</a>, <a href="http://arxiv.org/find/cs/1/au:+Deheeger_F/0/1/0/all/0/1">Francois Deheeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Mougeot_M/0/1/0/all/0/1">Mathilde Mougeot</a>, <a href="http://arxiv.org/find/cs/1/au:+Vayatis_N/0/1/0/all/0/1">Nicolas Vayatis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08251">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel instance-based approach to handle regression tasks in the
context of supervised domain adaptation. The approach developed in this paper
relies on the assumption that the task on the target domain can be efficiently
learned by adequately reweighting the source instances during training phase.
We introduce a novel formulation of the optimization objective for domain
adaptation which relies on a discrepancy distance characterizing the difference
between domains according to a specific task and a class of hypotheses. To
solve this problem, we develop an adversarial network algorithm which learns
both the source weighting scheme and the task in one feed-forward gradient
descent. We provide numerical evidence of the relevance of the method on public
datasets for domain adaptation through reproducible experiments accessible via
an online demo interface at: https://antoinedemathelin.github.io/demo/</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subgroup Fairness in Two-Sided Markets. (arXiv:2106.02702v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Q/0/1/0/all/0/1">Quan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Marecek_J/0/1/0/all/0/1">Jakub Marecek</a>, <a href="http://arxiv.org/find/cs/1/au:+Shorten_R/0/1/0/all/0/1">Robert N. Shorten</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02702">
                                    <div class="article-summary-box-inner">
                                        <span>It is well known that two-sided markets are unfair in a number of ways. For
instance, female workers at Uber earn less than their male colleagues per mile
driven. Similar observations have been made for other minority subgroups in
other two-sided markets. Here, we suggest a novel market-clearing mechanism for
two-sided markets, which promotes equalisation of the pay per hour worked
across multiple subgroups, as well as within each subgroup. In the process, we
introduce a novel notion of subgroup fairness (which we call Inter-fairness),
which can be combined with other notions of fairness within each subgroup
(called Intra-fairness), and the utility for the customers (Customer-Care) in
the objective of the market-clearing problem. While the novel non-linear terms
in the objective complicate market clearing by making the problem non-convex,
we show that a certain non-convex augmented Lagrangian relaxation can be
approximated to any precision in time polynomial in the number of market
participants using semi-definite programming. This makes it possible to
implement the market-clearing mechanism efficiently. On the example of
driver-ride assignment in an Uber-like system, we demonstrate the efficacy and
scalability of the approach, and trade-offs between Inter- and Intra-fairness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the complexity of finding a local minimizer of a quadratic function over a polytope. (arXiv:2008.05558v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Ahmadi_A/0/1/0/all/0/1">Amir Ali Ahmadi</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1">Jeffrey Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.05558">
                                    <div class="article-summary-box-inner">
                                        <span>We show that unless P&#x3D;NP, there cannot be a polynomial-time algorithm that
finds a point within Euclidean distance $c^n$ (for any constant $c \ge 0$) of a
local minimizer of an $n$-variate quadratic function over a polytope. This
result (even with $c&#x3D;0$) answers a question of Pardalos and Vavasis that
appeared in 1992 on a list of seven open problems in complexity theory for
numerical optimization. Our proof technique also implies that the problem of
deciding whether a quadratic function has a local minimizer over an (unbounded)
polyhedron, and that of deciding if a quartic polynomial has a local minimizer
are NP-hard.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Algorithm For Generalized Linear Bandit: Online Stochastic Gradient Descent and Thompson Sampling. (arXiv:2006.04012v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_Q/0/1/0/all/0/1">Qin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharpnack_J/0/1/0/all/0/1">James Sharpnack</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04012">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the contextual bandit problem, where a player sequentially makes
decisions based on past observations to maximize the cumulative reward.
Although many algorithms have been proposed for contextual bandit, most of them
rely on finding the maximum likelihood estimator at each iteration, which
requires $O(t)$ time at the $t$-th iteration and are memory inefficient. A
natural way to resolve this problem is to apply online stochastic gradient
descent (SGD) so that the per-step time and memory complexity can be reduced to
constant with respect to $t$, but a contextual bandit policy based on online
SGD updates that balances exploration and exploitation has remained elusive. In
this work, we show that online SGD can be applied to the generalized linear
bandit problem. The proposed SGD-TS algorithm, which uses a single-step SGD
update to exploit past information and uses Thompson Sampling for exploration,
achieves $\tilde{O}(\sqrt{T})$ regret with the total time complexity that
scales linearly in $T$ and $d$, where $T$ is the total number of rounds and $d$
is the number of features. Experimental results show that SGD-TS consistently
outperforms existing algorithms on both synthetic and real datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Adversarial Attacks. (arXiv:2103.02014v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mladenovic_A/0/1/0/all/0/1">Andjela Mladenovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Bose_A/0/1/0/all/0/1">Avishek Joey Bose</a>, <a href="http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1">Hugo Berard</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1">William L. Hamilton</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1">Simon Lacoste-Julien</a>, <a href="http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1">Pascal Vincent</a>, <a href="http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1">Gauthier Gidel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.02014">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial attacks expose important vulnerabilities of deep learning models,
yet little attention has been paid to settings where data arrives as a stream.
In this paper, we formalize the online adversarial attack problem, emphasizing
two key elements found in real-world use-cases: attackers must operate under
partial knowledge of the target model, and the decisions made by the attacker
are irrevocable since they operate on a transient data stream. We first
rigorously analyze a deterministic variant of the online threat model by
drawing parallels to the well-studied $k$-secretary problem in theoretical
computer science and propose Virtual+, a simple yet practical online algorithm.
Our main theoretical result show Virtual+ yields provably the best competitive
ratio over all single-threshold algorithms for $k&lt;5$ -- extending previous
analysis of the $k$-secretary problem. We also introduce the \textit{stochastic
$k$-secretary} -- effectively reducing online blackbox transfer attacks to a
$k$-secretary problem under noise -- and prove theoretical bounds on the
performance of \textit{any} online algorithms adapted to this setting. Finally,
we complement our theoretical results by conducting experiments on both MNIST
and CIFAR-10 with both vanilla and robust classifiers, revealing not only the
necessity of online algorithms in achieving near-optimal performance but also
the rich interplay of a given attack strategy towards online attack selection,
enabling simple strategies like FGSM to outperform classically strong whitebox
adversaries.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Source Causal Inference Using Control Variates. (arXiv:2103.16689v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1">Wenshuo Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Serena Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1">Peng Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yixin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1">Michael I. Jordan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.16689">
                                    <div class="article-summary-box-inner">
                                        <span>While many areas of machine learning have benefited from the increasing
availability of large and varied datasets, the benefit to causal inference has
been limited given the strong assumptions needed to ensure identifiability of
causal effects; these are often not satisfied in real-world datasets. For
example, many large observational datasets (e.g., case-control studies in
epidemiology, click-through data in recommender systems) suffer from selection
bias on the outcome, which makes the average treatment effect (ATE)
unidentifiable. We propose a general algorithm to estimate causal effects from
\emph{multiple} data sources, where the ATE may be identifiable only in some
datasets but not others. The key idea is to construct control variates using
the datasets in which the ATE is not identifiable. We show theoretically that
this reduces the variance of the ATE estimate. We apply this framework to
inference from observational data under outcome selection bias, assuming access
to an auxiliary small dataset from which we can obtain a consistent estimate of
the ATE. We construct a control variate by taking the difference of the odds
ratio estimates from the two datasets. Across simulations and two case studies
with real data, we show that this control variate can significantly reduce the
variance of the ATE estimate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mirror Descent Policy Optimization. (arXiv:2005.09814v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tomar_M/0/1/0/all/0/1">Manan Tomar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shani_L/0/1/0/all/0/1">Lior Shani</a>, <a href="http://arxiv.org/find/cs/1/au:+Efroni_Y/0/1/0/all/0/1">Yonathan Efroni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1">Mohammad Ghavamzadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.09814">
                                    <div class="article-summary-box-inner">
                                        <span>Mirror descent (MD), a well-known first-order method in constrained convex
optimization, has recently been shown as an important tool to analyze
trust-region algorithms in reinforcement learning (RL). However, there remains
a considerable gap between such theoretically analyzed algorithms and the ones
used in practice. Inspired by this, we propose an efficient RL algorithm,
called {\em mirror descent policy optimization} (MDPO). MDPO iteratively
updates the policy by {\em approximately} solving a trust-region problem, whose
objective function consists of two terms: a linearization of the standard RL
objective and a proximity term that restricts two consecutive policies to be
close to each other. Each update performs this approximation by taking multiple
gradient steps on this objective function. We derive {\em on-policy} and {\em
off-policy} variants of MDPO, while emphasizing important design choices
motivated by the existing theory of MD in RL. We highlight the connections
between on-policy MDPO and two popular trust-region RL algorithms: TRPO and
PPO, and show that explicitly enforcing the trust-region constraint is in fact
{\em not} a necessity for high performance gains in TRPO. We then show how the
popular soft actor-critic (SAC) algorithm can be derived by slight
modifications of off-policy MDPO. Overall, MDPO is derived from the MD
principles, offers a unified approach to viewing a number of popular RL
algorithms, and performs better than or on-par with TRPO, PPO, and SAC in a
number of continuous control tasks. Code is available at
\url{https://github.com/manantomar/Mirror-Descent-Policy-Optimization}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Random Feature Model for Input-Output Maps between Banach Spaces. (arXiv:2005.10224v2 [math.NA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Nelsen_N/0/1/0/all/0/1">Nicholas H. Nelsen</a>, <a href="http://arxiv.org/find/math/1/au:+Stuart_A/0/1/0/all/0/1">Andrew M. Stuart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.10224">
                                    <div class="article-summary-box-inner">
                                        <span>Well known to the machine learning community, the random feature model is a
parametric approximation to kernel interpolation or regression methods. It is
typically used to approximate functions mapping a finite-dimensional input
space to the real line. In this paper, we instead propose a methodology for use
of the random feature model as a data-driven surrogate for operators that map
an input Banach space to an output Banach space. Although the methodology is
quite general, we consider operators defined by partial differential equations
(PDEs); here, the inputs and outputs are themselves functions, with the input
parameters being functions required to specify the problem, such as initial
data or coefficients, and the outputs being solutions of the problem. Upon
discretization, the model inherits several desirable attributes from this
infinite-dimensional viewpoint, including mesh-invariant approximation error
with respect to the true PDE solution map and the capability to be trained at
one mesh resolution and then deployed at different mesh resolutions. We view
the random feature model as a non-intrusive data-driven emulator, provide a
mathematical framework for its interpretation, and demonstrate its ability to
efficiently and accurately approximate the nonlinear parameter-to-solution maps
of two prototypical PDEs arising in physical science and engineering
applications: viscous Burgers&#x27; equation and a variable coefficient elliptic
equation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimization Induced Equilibrium Networks. (arXiv:2105.13228v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1">Xingyu Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qiuhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1">Zenan Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yisen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Guangcan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhouchen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13228">
                                    <div class="article-summary-box-inner">
                                        <span>Implicit equilibrium models, i.e., deep neural networks (DNNs) defined by
implicit equations, have been becoming more and more attractive recently. In
this paper, we investigate an emerging question: can an implicit equilibrium
model&#x27;s equilibrium point be regarded as the solution of an optimization
problem? To this end, we first decompose DNNs into a new class of unit layer
that is the proximal operator of an implicit convex function while keeping its
output unchanged. Then, the equilibrium model of the unit layer can be derived,
named Optimization Induced Equilibrium Networks (OptEq), which can be easily
extended to deep layers. The equilibrium point of OptEq can be theoretically
connected to the solution of its corresponding convex optimization problem with
explicit objectives. Based on this, we can flexibly introduce prior properties
to the equilibrium points: 1) modifying the underlying convex problems
explicitly so as to change the architectures of OptEq; and 2) merging the
information into the fixed point iteration, which guarantees to choose the
desired equilibrium point when the fixed point set is non-singleton. We show
that deep OptEq outperforms previous implicit models even with fewer
parameters. This work establishes the first step towards the
optimization-guided design of deep models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Into the Unknown: Active Monitoring of Neural Networks. (arXiv:2009.06429v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lukina_A/0/1/0/all/0/1">Anna Lukina</a>, <a href="http://arxiv.org/find/cs/1/au:+Schilling_C/0/1/0/all/0/1">Christian Schilling</a>, <a href="http://arxiv.org/find/cs/1/au:+Henzinger_T/0/1/0/all/0/1">Thomas A. Henzinger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.06429">
                                    <div class="article-summary-box-inner">
                                        <span>Neural-network classifiers achieve high accuracy when predicting the class of
an input that they were trained to identify. Maintaining this accuracy in
dynamic environments, where inputs frequently fall outside the fixed set of
initially known classes, remains a challenge. The typical approach is to detect
inputs from novel classes and retrain the classifier on an augmented dataset.
However, not only the classifier but also the detection mechanism needs to
adapt in order to distinguish between newly learned and yet unknown input
classes. To address this challenge, we introduce an algorithmic framework for
active monitoring of a neural network. A monitor wrapped in our framework
operates in parallel with the neural network and interacts with a human user
via a series of interpretable labeling queries for incremental adaptation. In
addition, we propose an adaptive quantitative monitor to improve precision. An
experimental evaluation on a diverse set of benchmarks with varying numbers of
classes confirms the benefits of our active monitoring framework in dynamic
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Feature Mining via Attention-based BiLSTM-GCN for Human Motor Imagery Recognition. (arXiv:2005.00777v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hou_Y/0/1/0/all/0/1">Yimin Hou</a>, <a href="http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1">Shuyue Jia</a>, <a href="http://arxiv.org/find/eess/1/au:+Lun_X/0/1/0/all/0/1">Xiangmin Lun</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1">Yan Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00777">
                                    <div class="article-summary-box-inner">
                                        <span>Recognition accuracy and response time are both critically essential ahead of
building practical electroencephalography (EEG) based brain-computer interface
(BCI). Recent approaches, however, have either compromised in the
classification accuracy or responding time. This paper presents a novel deep
learning approach designed towards remarkably accurate and responsive motor
imagery (MI) recognition based on scalp EEG. Bidirectional Long Short-term
Memory (BiLSTM) with the Attention mechanism manages to derive relevant
features from raw EEG signals. The connected graph convolutional neural network
(GCN) promotes the decoding performance by cooperating with the topological
structure of features, which are estimated from the overall data. The
0.4-second detection framework has shown effective and efficient prediction
based on individual and group-wise training, with 98.81% and 94.64% accuracy,
respectively, which outperformed all the state-of-the-art studies. The
introduced deep feature mining approach can precisely recognize human motion
intents from raw EEG signals, which paves the road to translate the EEG based
MI recognition to practical BCI systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporal Spike Sequence Learning via Backpropagation for Deep Spiking Neural Networks. (arXiv:2002.10085v4 [cs.NE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wenrui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Peng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.10085">
                                    <div class="article-summary-box-inner">
                                        <span>Spiking neural networks (SNNs) are well suited for spatio-temporal learning
and implementations on energy-efficient event-driven neuromorphic processors.
However, existing SNN error backpropagation (BP) methods lack proper handling
of spiking discontinuities and suffer from low performance compared with the BP
methods for traditional artificial neural networks. In addition, a large number
of time steps are typically required to achieve decent performance, leading to
high latency and rendering spike-based computation unscalable to deep
architectures. We present a novel Temporal Spike Sequence Learning
Backpropagation (TSSL-BP) method for training deep SNNs, which breaks down
error backpropagation across two types of inter-neuron and intra-neuron
dependencies and leads to improved temporal learning precision. It captures
inter-neuron dependencies through presynaptic firing times by considering the
all-or-none characteristics of firing activities and captures intra-neuron
dependencies by handling the internal evolution of each neuronal state in time.
TSSL-BP efficiently trains deep SNNs within a much shortened temporal window of
a few steps while improving the accuracy for various image classification
datasets including CIFAR10.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Integrating Auxiliary Information in Self-supervised Learning. (arXiv:2106.02869v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1">Yao-Hung Hubert Tsai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tianqin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_P/0/1/0/all/0/1">Peiyuan Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1">Ruslan Salakhutdinov</a>, <a href="http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1">Louis-Philippe Morency</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02869">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents to integrate the auxiliary information (e.g., additional
attributes for data such as the hashtags for Instagram images) in the
self-supervised learning process. We first observe that the auxiliary
information may bring us useful information about data structures: for
instance, the Instagram images with the same hashtags can be semantically
similar. Hence, to leverage the structural information from the auxiliary
information, we present to construct data clusters according to the auxiliary
information. Then, we introduce the Clustering InfoNCE (Cl-InfoNCE) objective
that learns similar representations for augmented variants of data from the
same cluster and dissimilar representations for data from different clusters.
Our approach contributes as follows: 1) Comparing to conventional
self-supervised representations, the auxiliary-information-infused
self-supervised representations bring the performance closer to the supervised
representations; 2) The presented Cl-InfoNCE can also work with unsupervised
constructed clusters (e.g., k-means clusters) and outperform strong
clustering-based self-supervised learning approaches, such as the Prototypical
Contrastive Learning (PCL) method; 3) We show that Cl-InfoNCE may be a better
approach to leverage the data clustering information, by comparing it to the
baseline approach - learning to predict the clustering assignments with
cross-entropy loss. For analysis, we connect the goodness of the learned
representations with the statistical relationships: i) the mutual information
between the labels and the clusters and ii) the conditional entropy of the
clusters given the labels.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Bounds between $f$-Divergences and Integral Probability Metrics. (arXiv:2006.05973v3 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Agrawal_R/0/1/0/all/0/1">Rohit Agrawal</a>, <a href="http://arxiv.org/find/math/1/au:+Horel_T/0/1/0/all/0/1">Thibaut Horel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05973">
                                    <div class="article-summary-box-inner">
                                        <span>The families of $f$-divergences (e.g. the Kullback-Leibler divergence) and
Integral Probability Metrics (e.g. total variation distance or maximum mean
discrepancies) are widely used to quantify the similarity between probability
distributions. In this work, we systematically study the relationship between
these two families from the perspective of convex duality. Starting from a
tight variational representation of the $f$-divergence, we derive a
generalization of the moment-generating function, which we show exactly
characterizes the best lower bound of the $f$-divergence as a function of a
given IPM. Using this characterization, we obtain new bounds while also
recovering in a unified manner well-known results, such as Hoeffding&#x27;s lemma,
Pinsker&#x27;s inequality and its extension to subgaussian functions, and the
Hammersley-Chapman-Robbins bound. This characterization also allows us to prove
new results on topological properties of the divergence which may be of
independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Curves for SGD on Structured Features. (arXiv:2106.02713v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1">Blake Bordelon</a>, <a href="http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1">Cengiz Pehlevan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02713">
                                    <div class="article-summary-box-inner">
                                        <span>The generalization performance of a machine learning algorithm such as a
neural network depends in a non-trivial way on the structure of the data
distribution. Models of generalization in machine learning theory often ignore
the low-dimensional structure of natural signals, either by considering
data-agnostic bounds or by studying the performance of the algorithm when
trained on uncorrelated features. To analyze the influence of data structure on
test loss dynamics, we study an exactly solveable model of stochastic gradient
descent (SGD) which predicts test loss when training on features with arbitrary
covariance structure. We solve the theory exactly for both Gaussian features
and arbitrary features and we show that the simpler Gaussian model accurately
predicts test loss of nonlinear random-feature models and deep neural networks
trained with SGD on real datasets such as MNIST and CIFAR-10. We show that
modeling the geometry of the data in the induced feature space is indeed
crucial to accurately predict the test error throughout learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Orthogonal Over-Parameterized Training. (arXiv:2004.04690v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weiyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1">Rongmei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1">James M. Rehg</a>, <a href="http://arxiv.org/find/cs/1/au:+Paull_L/0/1/0/all/0/1">Liam Paull</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_L/0/1/0/all/0/1">Li Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1">Le Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.04690">
                                    <div class="article-summary-box-inner">
                                        <span>The inductive bias of a neural network is largely determined by the
architecture and the training algorithm. To achieve good generalization, how to
effectively train a neural network is of great importance. We propose a novel
orthogonal over-parameterized training (OPT) framework that can provably
minimize the hyperspherical energy which characterizes the diversity of neurons
on a hypersphere. By maintaining the minimum hyperspherical energy during
training, OPT can greatly improve the empirical generalization. Specifically,
OPT fixes the randomly initialized weights of the neurons and learns an
orthogonal transformation that applies to these neurons. We consider multiple
ways to learn such an orthogonal transformation, including unrolling
orthogonalization algorithms, applying orthogonal parameterization, and
designing orthogonality-preserving gradient descent. For better scalability, we
propose the stochastic OPT which performs orthogonal transformation
stochastically for partial dimensions of neurons. Interestingly, OPT reveals
that learning a proper coordinate system for neurons is crucial to
generalization. We provide some insights on why OPT yields better
generalization. Extensive experiments validate the superiority of OPT over the
standard training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Expressive Power of Invariant and Equivariant Graph Neural Networks. (arXiv:2006.15646v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Azizian_W/0/1/0/all/0/1">Wa&#xef;ss Azizian</a>, <a href="http://arxiv.org/find/cs/1/au:+Lelarge_M/0/1/0/all/0/1">Marc Lelarge</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.15646">
                                    <div class="article-summary-box-inner">
                                        <span>Various classes of Graph Neural Networks (GNN) have been proposed and shown
to be successful in a wide range of applications with graph structured data. In
this paper, we propose a theoretical framework able to compare the expressive
power of these GNN architectures. The current universality theorems only apply
to intractable classes of GNNs. Here, we prove the first approximation
guarantees for practical GNNs, paving the way for a better understanding of
their generalization. Our theoretical results are proved for invariant GNNs
computing a graph embedding (permutation of the nodes of the input graph does
not affect the output) and equivariant GNNs computing an embedding of the nodes
(permutation of the input permutes the output). We show that Folklore Graph
Neural Networks (FGNN), which are tensor based GNNs augmented with matrix
multiplication are the most expressive architectures proposed so far for a
given tensor order. We illustrate our results on the Quadratic Assignment
Problem (a NP-Hard combinatorial problem) by showing that FGNNs are able to
learn how to solve the problem, leading to much better average performances
than existing algorithms (based on spectral, SDP or other GNNs architectures).
On a practical side, we also implement masked tensors to handle batches of
graphs of varying sizes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UFO-BLO: Unbiased First-Order Bilevel Optimization. (arXiv:2006.03631v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1">Valerii Likhosherstov</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xingyou Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1">Krzysztof Choromanski</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Jared Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03631">
                                    <div class="article-summary-box-inner">
                                        <span>Bilevel optimization (BLO) is a popular approach with many applications
including hyperparameter optimization, neural architecture search, adversarial
robustness and model-agnostic meta-learning. However, the approach suffers from
time and memory complexity proportional to the length $r$ of its inner
optimization loop, which has led to several modifications being proposed. One
such modification is \textit{first-order} BLO (FO-BLO) which approximates
outer-level gradients by zeroing out second derivative terms, yielding
significant speed gains and requiring only constant memory as $r$ varies.
Despite FO-BLO&#x27;s popularity, there is a lack of theoretical understanding of
its convergence properties. We make progress by demonstrating a rich family of
examples where FO-BLO-based stochastic optimization does not converge to a
stationary point of the BLO objective. We address this concern by proposing a
new FO-BLO-based unbiased estimate of outer-level gradients, enabling us to
theoretically guarantee this convergence, with no harm to memory and expected
time complexity. Our findings are supported by experimental results on Omniglot
and Mini-ImageNet, popular few-shot meta-learning benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Churn Reduction via Distillation. (arXiv:2106.02654v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Heinrich Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Narasimhan_H/0/1/0/all/0/1">Harikrishna Narasimhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahri_D/0/1/0/all/0/1">Dara Bahri</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotter_A/0/1/0/all/0/1">Andrew Cotter</a>, <a href="http://arxiv.org/find/cs/1/au:+Rostamizadeh_A/0/1/0/all/0/1">Afshin Rostamizadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02654">
                                    <div class="article-summary-box-inner">
                                        <span>In real-world systems, models are frequently updated as more data becomes
available, and in addition to achieving high accuracy, the goal is to also
maintain a low difference in predictions compared to the base model (i.e.
predictive &#x60;&#x60;churn&#x27;&#x27;). If model retraining results in vastly different
behavior, then it could cause negative effects in downstream systems,
especially if this churn can be avoided with limited impact on model accuracy.
In this paper, we show an equivalence between training with distillation using
the base model as the teacher and training with an explicit constraint on the
predictive churn. We then show that distillation performs strongly for low
churn training against a number of recent baselines on a wide range of datasets
and model architectures, including fully-connected networks, convolutional
networks, and transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-rank Characteristic Tensor Density Estimation Part I: Foundations. (arXiv:2008.12315v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Amiridi_M/0/1/0/all/0/1">Magda Amiridi</a>, <a href="http://arxiv.org/find/stat/1/au:+Kargas_N/0/1/0/all/0/1">Nikos Kargas</a>, <a href="http://arxiv.org/find/stat/1/au:+Sidiropoulos_N/0/1/0/all/0/1">Nicholas D. Sidiropoulos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.12315">
                                    <div class="article-summary-box-inner">
                                        <span>Effective non-parametric density estimation is a key challenge in
high-dimensional multivariate data analysis. In this paper,we propose a novel
approach that builds upon tensor factorization tools. Any multivariate density
can be represented by its characteristic function, via the Fourier transform.
If the sought density is compactly supported, then its characteristic function
can be approximated, within controllable error, by a finite tensor of leading
Fourier coefficients, whose size de-pends on the smoothness of the underlying
density. This tensor can be naturally estimated from observed realizations of
the random vector of interest, via sample averaging. In order to circumvent the
curse of dimensionality, we introduce a low-rank model of this characteristic
tensor, which significantly improves the density estimate especially for
high-dimensional data and/or in the sample-starved regime. By virtue of
uniqueness of low-rank tensor decomposition, under certain conditions, our
method enables learning the true data-generating distribution. We demonstrate
the very promising performance of the proposed method using several measured
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational (Gradient) Estimate of the Score Function in Energy-based Latent Variable Models. (arXiv:2010.08258v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bao_F/0/1/0/all/0/1">Fan Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Kun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chongxuan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_L/0/1/0/all/0/1">Lanqing Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Bo Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08258">
                                    <div class="article-summary-box-inner">
                                        <span>The learning and evaluation of energy-based latent variable models (EBLVMs)
without any structural assumptions are highly challenging, because the true
posteriors and the partition functions in such models are generally
intractable. This paper presents variational estimates of the score function
and its gradient with respect to the model parameters in a general EBLVM,
referred to as VaES and VaGES respectively. The variational posterior is
trained to minimize a certain divergence to the true model posterior and the
bias in both estimates can be bounded by the divergence theoretically. With a
minimal model assumption, VaES and VaGES can be applied to the kernelized Stein
discrepancy (KSD) and score matching (SM)-based methods to learn EBLVMs.
Besides, VaES can also be used to estimate the exact Fisher divergence between
the data and general EBLVMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphMI: Extracting Private Graph Data from Graph Neural Networks. (arXiv:2106.02820v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zaixi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhenya Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Chengqiang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Chuanren Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1">Enhong Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02820">
                                    <div class="article-summary-box-inner">
                                        <span>As machine learning becomes more widely used for critical applications, the
need to study its implications in privacy turns to be urgent. Given access to
the target model and auxiliary information, the model inversion attack aims to
infer sensitive features of the training dataset, which leads to great privacy
concerns. Despite its success in grid-like domains, directly applying model
inversion techniques on non-grid domains such as graph achieves poor attack
performance due to the difficulty to fully exploit the intrinsic properties of
graphs and attributes of nodes used in Graph Neural Networks (GNN). To bridge
this gap, we present \textbf{Graph} \textbf{M}odel \textbf{I}nversion attack
(GraphMI), which aims to extract private graph data of the training graph by
inverting GNN, one of the state-of-the-art graph analysis tools. Specifically,
we firstly propose a projected gradient module to tackle the discreteness of
graph edges while preserving the sparsity and smoothness of graph features.
Then we design a graph auto-encoder module to efficiently exploit graph
topology, node attributes, and target model parameters for edge inference. With
the proposed methods, we study the connection between model inversion risk and
edge influence and show that edges with greater influence are more likely to be
recovered. Extensive experiments over several public datasets demonstrate the
effectiveness of our method. We also show that differential privacy in its
canonical form can hardly defend our attack while preserving decent utility.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Modular Analysis of Provable Acceleration via Polyak&#x27;s Momentum: Training a Wide ReLU Network and a Deep Linear Network. (arXiv:2010.01618v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun-Kun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1">Chi-Heng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1">Jacob Abernethy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01618">
                                    <div class="article-summary-box-inner">
                                        <span>Incorporating a so-called &quot;momentum&quot; dynamic in gradient descent methods is
widely used in neural net training as it has been broadly observed that, at
least empirically, it often leads to significantly faster convergence. At the
same time, there are very few theoretical guarantees in the literature to
explain this apparent acceleration effect. Even for the classical strongly
convex quadratic problems, several existing results only show Polyak&#x27;s momentum
has an accelerated linear rate asymptotically. In this paper, we first revisit
the quadratic problems and show a non-asymptotic accelerated linear rate of
Polyak&#x27;s momentum. Then, we provably show that Polyak&#x27;s momentum achieves
acceleration for training a one-layer wide ReLU network and a deep linear
network, which are perhaps the two most popular canonical models for studying
optimization and deep learning in the literature. Prior work Du at al. 2019 and
Wu et al. 2019 showed that using vanilla gradient descent, and with an use of
over-parameterization, the error decays as $(1- \Theta(\frac{1}{ \kappa&#x27;}))^t$
after $t$ iterations, where $\kappa&#x27;$ is the condition number of a Gram Matrix.
Our result shows that with the appropriate choice of parameters Polyak&#x27;s
momentum has a rate of $(1-\Theta(\frac{1}{\sqrt{\kappa&#x27;}}))^t$. For the deep
linear network, prior work Hu et al. 2020 showed that vanilla gradient descent
has a rate of $(1-\Theta(\frac{1}{\kappa}))^t$, where $\kappa$ is the condition
number of a data matrix. Our result shows an acceleration rate $(1-
\Theta(\frac{1}{\sqrt{\kappa}}))^t$ is achievable by Polyak&#x27;s momentum. All the
results in this work are obtained from a modular analysis, which can be of
independent interest. This work establishes that momentum does indeed speed up
neural net training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Custom 7nm CMOS Standard Cell Library for Implementing TNN-based Neuromorphic Processors. (arXiv:2012.05419v2 [cs.AR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nair_H/0/1/0/all/0/1">Harideep Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Vellaisamy_P/0/1/0/all/0/1">Prabhu Vellaisamy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhasuthkar_S/0/1/0/all/0/1">Santha Bhasuthkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">John Paul Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05419">
                                    <div class="article-summary-box-inner">
                                        <span>A set of highly-optimized custom macro extensions is developed for a 7nm CMOS
cell library for implementing Temporal Neural Networks (TNNs) that can mimic
brain-like sensory processing with extreme energy efficiency. A TNN prototype
(13,750 neurons and 315,000 synapses) for MNIST requires only 1.56mm2 die area
and consumes only 1.69mW.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Characterizing the Latent Space of Molecular Deep Generative Models with Persistent Homology Metrics. (arXiv:2010.08548v2 [q-bio.BM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Schiff_Y/0/1/0/all/0/1">Yair Schiff</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chenthamarakshan_V/0/1/0/all/0/1">Vijil Chenthamarakshan</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ramamurthy_K/0/1/0/all/0/1">Karthikeyan Natesan Ramamurthy</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Das_P/0/1/0/all/0/1">Payel Das</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08548">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models are increasingly becoming integral parts of the in
silico molecule design pipeline and have dual goals of learning the chemical
and structural features that render candidate molecules viable while also being
flexible enough to generate novel designs. Specifically, Variational Auto
Encoders (VAEs) are generative models in which encoder-decoder network pairs
are trained to reconstruct training data distributions in such a way that the
latent space of the encoder network is smooth. Therefore, novel candidates can
be found by sampling from this latent space. However, the scope of
architectures and hyperparameters is vast and choosing the best combination for
in silico discovery has important implications for downstream success.
Therefore, it is important to develop a principled methodology for
distinguishing how well a given generative model is able to learn salient
molecular features. In this work, we propose a method for measuring how well
the latent space of deep generative models is able to encode structural and
chemical features of molecular datasets by correlating latent space metrics
with metrics from the field of topological data analysis (TDA). We apply our
evaluation methodology to a VAE trained on SMILES strings and show that 3D
topology information is consistently encoded throughout the latent space of the
model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Decompose a Tensor with Group Structure. (arXiv:2106.02680v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Allen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1">Ankur Moitra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02680">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we study the orbit recovery problem, which is a natural
abstraction for the problem of recovering a planted signal from noisy
measurements under unknown group actions. Many important inverse problems in
statistics, engineering and the sciences fit into this framework. Prior work
has studied cases when the group is discrete and/or abelian. However
fundamentally new techniques are needed in order to handle more complex group
actions.

Our main result is a quasi-polynomial time algorithm to solve orbit recovery
over $SO(3)$ - i.e. the cryo-electron tomography problem which asks to recover
the three-dimensional structure of a molecule from noisy measurements of
randomly rotated copies of it. We analyze a variant of the frequency marching
heuristic in the framework of smoothed analysis. Our approach exploits the
layered structure of the invariant polynomials, and simultaneously yields a new
class of tensor decomposition algorithms that work in settings when the tensor
is not low-rank but rather where the factors are algebraically related to each
other by a group action.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Contextual Bandit Bake-off. (arXiv:1802.04064v5 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bietti_A/0/1/0/all/0/1">Alberto Bietti</a>, <a href="http://arxiv.org/find/stat/1/au:+Agarwal_A/0/1/0/all/0/1">Alekh Agarwal</a>, <a href="http://arxiv.org/find/stat/1/au:+Langford_J/0/1/0/all/0/1">John Langford</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1802.04064">
                                    <div class="article-summary-box-inner">
                                        <span>Contextual bandit algorithms are essential for solving many real-world
interactive machine learning problems. Despite multiple recent successes on
statistically and computationally efficient methods, the practical behavior of
these algorithms is still poorly understood. We leverage the availability of
large numbers of supervised learning datasets to empirically evaluate
contextual bandit algorithms, focusing on practical methods that learn by
relying on optimization oracles from supervised learning. We find that a recent
method (Foster et al., 2018) using optimism under uncertainty works the best
overall. A surprisingly close second is a simple greedy baseline that only
explores implicitly through the diversity of contexts, followed by a variant of
Online Cover (Agarwal et al., 2014) which tends to be more conservative but
robust to problem specification by design. Along the way, we also evaluate
various components of contextual bandit algorithm design such as loss
estimators. Overall, this is a thorough study and review of contextual bandit
methodology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Layered gradient accumulation and modular pipeline parallelism: fast and efficient training of large language models. (arXiv:2106.02679v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lamy_Poirier_J/0/1/0/all/0/1">Joel Lamy-Poirier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02679">
                                    <div class="article-summary-box-inner">
                                        <span>The advent of the transformer has sparked a quick growth in the size of
language models, far outpacing hardware improvements. (Dense) transformers are
expected to reach the trillion-parameter scale in the near future, for which
training requires thousands or even tens of thousands of GPUs. We investigate
the challenges of training at this scale and beyond on commercially available
hardware. In particular, we analyse the shortest possible training time for
different configurations of distributed training, leveraging empirical scaling
laws for language models to estimate the optimal (critical) batch size.
Contrary to popular belief, we find no evidence for a memory wall, and instead
argue that the real limitation -- other than the cost -- lies in the training
duration.

In addition to this analysis, we introduce two new methods, \textit{layered
gradient accumulation} and \textit{modular pipeline parallelism}, which
together cut the shortest training time by half. The methods also reduce data
movement, lowering the network requirement to a point where a fast InfiniBand
connection is not necessary. This increased network efficiency also improve on
the methods introduced with the ZeRO optimizer, reducing the memory usage to a
tiny fraction of the available GPU memory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sequential Neural Posterior and Likelihood Approximation. (arXiv:2102.06522v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wiqvist_S/0/1/0/all/0/1">Samuel Wiqvist</a>, <a href="http://arxiv.org/find/stat/1/au:+Frellsen_J/0/1/0/all/0/1">Jes Frellsen</a>, <a href="http://arxiv.org/find/stat/1/au:+Picchini_U/0/1/0/all/0/1">Umberto Picchini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06522">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the sequential neural posterior and likelihood approximation
(SNPLA) algorithm. SNPLA is a normalizing flows-based algorithm for inference
in implicit models, and therefore is a simulation-based inference method that
only requires simulations from a generative model. SNPLA avoids Markov chain
Monte Carlo sampling and correction-steps of the parameter proposal function
that are introduced in similar methods, but that can be numerically unstable or
restrictive. By utilizing the reverse KL divergence, SNPLA manages to learn
both the likelihood and the posterior in a sequential manner. Over four
experiments, we show that SNPLA performs competitively when utilizing the same
number of model simulations as used in other methods, even though the inference
problem for SNPLA is more complex due to the joint learning of posterior and
likelihood function. Due to utilizing normalizing flows SNPLA generates
posterior draws much faster (4 orders of magnitude) than MCMC-based methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Beam Association for High Mobility mmWave Vehicular Networks: Lightweight Parallel Reinforcement Learning Approach. (arXiv:2005.00694v2 [cs.NI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huynh_N/0/1/0/all/0/1">Nguyen Van Huynh</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Diep N. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_D/0/1/0/all/0/1">Dinh Thai Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutkiewicz_E/0/1/0/all/0/1">Eryk Dutkiewicz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00694">
                                    <div class="article-summary-box-inner">
                                        <span>In intelligent transportation systems (ITS), vehicles are expected to feature
with advanced applications and services which demand ultra-high data rates and
low-latency communications. For that, the millimeter wave (mmWave)
communication has been emerging as a very promising solution. However,
incorporating the mmWave into ITS is particularly challenging due to the high
mobility of vehicles and the inherent sensitivity of mmWave beams to dynamic
blockages. This article addresses these problems by developing an optimal beam
association framework for mmWave vehicular networks under high mobility.
Specifically, we use the semi-Markov decision process to capture the dynamics
and uncertainty of the environment. The Q-learning algorithm is then often used
to find the optimal policy. However, Q-learning is notorious for its
slow-convergence. Instead of adopting deep reinforcement learning structures
(like most works in the literature), we leverage the fact that there are
usually multiple vehicles on the road to speed up the learning process. To that
end, we develop a lightweight yet very effective parallel Q-learning algorithm
to quickly obtain the optimal policy by simultaneously learning from various
vehicles. Extensive simulations demonstrate that our proposed solution can
increase the data rate by 47% and reduce the disconnection probability by 29%
compared to other solutions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Group Invariant Dictionary Learning. (arXiv:2007.07550v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Soh_Y/0/1/0/all/0/1">Yong Sheng Soh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.07550">
                                    <div class="article-summary-box-inner">
                                        <span>The dictionary learning problem concerns the task of representing data as
sparse linear sums drawn from a smaller collection of basic building blocks. In
application domains where such techniques are deployed, we frequently encounter
datasets where some form of symmetry or invariance is present. Motivated by
this observation, we develop a framework for learning dictionaries for data
under the constraint that the collection of basic building blocks remains
invariant under such symmetries. Our procedure for learning such dictionaries
relies on representing the symmetry as the action of a matrix group acting on
the data, and subsequently introducing a convex penalty function so as to
induce sparsity with respect to the collection of matrix group elements. Our
framework specializes to the convolutional dictionary learning problem when we
consider integer shifts. Using properties of positive semidefinite Hermitian
Toeplitz matrices, we develop an extension that learns dictionaries that are
invariant under continuous shifts. Our numerical experiments on synthetic data
and ECG data show that the incorporation of such symmetries as priors are most
valuable when the dataset has few data-points, or when the full range of
symmetries is inadequately expressed in the dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaborative Learning in the Jungle. (arXiv:2008.00742v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+El_Mhamdi_E/0/1/0/all/0/1">El-Mahdi El-Mhamdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadkhani_S/0/1/0/all/0/1">Sadegh Farhadkhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1">Rachid Guerraoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Guirguis_A/0/1/0/all/0/1">Arsany Guirguis</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_L/0/1/0/all/0/1">L&#xea; Nguy&#xea;n Hoang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rouault_S/0/1/0/all/0/1">S&#xe9;bastien Rouault</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.00742">
                                    <div class="article-summary-box-inner">
                                        <span>We study Byzantine collaborative learning, where $n$ nodes seek to
collectively learn from each others&#x27; local data. The data distribution may vary
from one node to another. No node is trusted, and $f &lt; n$ nodes can behave
arbitrarily. We prove that collaborative learning is equivalent to a new form
of agreement, which we call averaging agreement. In this problem, nodes start
each with an initial vector and seek to approximately agree on a common vector,
which is close to the average of honest nodes&#x27; initial vectors. We present two
asynchronous solutions to averaging agreement, each we prove optimal according
to some dimension. The first, based on the minimum-diameter averaging, requires
$ n \geq 6f+1$, but achieves asymptotically the best-possible averaging
constant up to a multiplicative constant. The second, based on reliable
broadcast and coordinate-wise trimmed mean, achieves optimal Byzantine
resilience, i.e., $n \geq 3f+1$. Each of these algorithms induces an optimal
Byzantine collaborative learning protocol. In particular, our equivalence
yields new impossibility theorems on what any collaborative learning algorithm
can achieve in adversarial and heterogeneous environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Logic of Machine Learning. (arXiv:2006.09500v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sapir_M/0/1/0/all/0/1">Marina Sapir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09500">
                                    <div class="article-summary-box-inner">
                                        <span>ML is approached from logic point of view as a problem of maximizing
consistency of a hypothesis in a context of a given training set. Nonjudgmental
logic (NjL) with modalities &#x60;&#x60;It appears that&#x27;&#x27;, &#x60;&#x60;Assume that&#x27;&#x27; is introduced
to formalize and quantify the concepts of inconsistency. Two conjectures are
formulated. First, there are only 5 types of steps for all learners. Second,
any learner minimizes a criterion, which can be represented as a measure of
inconsistency in a semantic of NjL. Many popular ML algorithms (from
hierarchical clustering to k-NN and SVM) are shown to corroborate both
conjectures. In addition, it is demonstrated that NjL allows to formalize and
solve several general learning problems which are not considered as ML usually.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Singular Dynamic Mode Decompositions. (arXiv:2106.02639v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Rosenfeld_J/0/1/0/all/0/1">Joel A. Rosenfeld</a>, <a href="http://arxiv.org/find/eess/1/au:+Kamalapurkar_R/0/1/0/all/0/1">Rushikesh Kamalapurkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02639">
                                    <div class="article-summary-box-inner">
                                        <span>This manuscript is aimed at addressing several long standing limitations of
dynamic mode decompositions in the application of Koopman analysis. Principle
among these limitations are the convergence of associated Dynamic Mode
Decomposition algorithms and the existence of Koopman modes. To address these
limitations, two major modifications are made, where Koopman operators are
removed from the analysis in light of Liouville operators (known as Koopman
generators in special cases), and these operators are shown to be compact for
certain pairs of Hilbert spaces selected separately as the domain and range of
the operator. While eigenfunctions are discarded in this analysis, a viable
reconstruction algorithm is still demonstrated, and the sacrifice of
eigenfunctions realizes the theoretical goals of DMD analysis that have yet to
be achieved in other contexts. The manuscript concludes with the description of
a Dynamic Mode Decomposition algorithm that converges when a dense collection
of occupation kernels, arising from the data, are leveraged in the analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Regret Active learning. (arXiv:2104.02822v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baykal_C/0/1/0/all/0/1">Cenk Baykal</a>, <a href="http://arxiv.org/find/cs/1/au:+Liebenwein_L/0/1/0/all/0/1">Lucas Liebenwein</a>, <a href="http://arxiv.org/find/cs/1/au:+Feldman_D/0/1/0/all/0/1">Dan Feldman</a>, <a href="http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1">Daniela Rus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02822">
                                    <div class="article-summary-box-inner">
                                        <span>We develop an online learning algorithm for identifying unlabeled data points
that are most informative for training (i.e., active learning). By formulating
the active learning problem as the prediction with sleeping experts problem, we
provide a framework for identifying informative data with respect to any given
definition of informativeness. At the core of our work is an efficient
algorithm for sleeping experts that is tailored to achieve low regret on
predictable (easy) instances while remaining resilient to adversarial ones.
This stands in contrast to state-of-the-art active learning methods that are
overwhelmingly based on greedy selection, and hence cannot ensure good
performance across varying problem instances. We present empirical results
demonstrating that our method (i) instantiated with an informativeness measure
consistently outperforms its greedy counterpart and (ii) reliably outperforms
uniform sampling on real-world data sets and models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Constant Approximation Algorithm for Sequential Random-Order No-Substitution k-Median Clustering. (arXiv:2102.04050v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hess_T/0/1/0/all/0/1">Tom Hess</a>, <a href="http://arxiv.org/find/cs/1/au:+Moshkovitz_M/0/1/0/all/0/1">Michal Moshkovitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabato_S/0/1/0/all/0/1">Sivan Sabato</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.04050">
                                    <div class="article-summary-box-inner">
                                        <span>We study k-median clustering under the sequential no-substitution setting. In
this setting, a data stream is sequentially observed, and some of the points
are selected by the algorithm as cluster centers. However, a point can be
selected as a center only immediately after it is observed, before observing
the next point. In addition, a selected center cannot be substituted later. We
give the first algorithm for this setting that obtains a constant approximation
factor on the optimal risk under a random arrival order, an exponential
improvement over previous work. This is also the first constant approximation
guarantee that holds without any structural assumptions on the input data.
Moreover, the number of selected centers is only quasi-linear in k. Our
algorithm and analysis are based on a careful risk estimation that avoids
outliers, a new concept of a linear bin division, and a multiscale approach to
center selection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Treatment Effects in Panels with General Intervention Patterns. (arXiv:2106.02780v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Farias_V/0/1/0/all/0/1">Vivek F. Farias</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_A/0/1/0/all/0/1">Andrew A. Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Peng_T/0/1/0/all/0/1">Tianyi Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02780">
                                    <div class="article-summary-box-inner">
                                        <span>The problem of causal inference with panel data is a central econometric
question. The following is a fundamental version of this problem: Let $M^*$ be
a low rank matrix and $E$ be a zero-mean noise matrix. For a &#x60;treatment&#x27; matrix
$Z$ with entries in $\{0,1\}$ we observe the matrix $O$ with entries $O_{ij} :&#x3D;
M^*_{ij} + E_{ij} + \mathcal{T}_{ij} Z_{ij}$ where $\mathcal{T}_{ij} $ are
unknown, heterogenous treatment effects. The problem requires we estimate the
average treatment effect $\tau^* :&#x3D; \sum_{ij} \mathcal{T}_{ij} Z_{ij} /
\sum_{ij} Z_{ij}$. The synthetic control paradigm provides an approach to
estimating $\tau^*$ when $Z$ places support on a single row. This paper extends
that framework to allow rate-optimal recovery of $\tau^*$ for general $Z$, thus
broadly expanding its applicability. Our guarantees are the first of their type
in this general setting. Computational experiments on synthetic and real-world
data show a substantial advantage over competing estimators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Graph Symmetrisation Bound on Channel Information Leakage under Blowfish Privacy. (arXiv:2007.05975v2 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Edwards_T/0/1/0/all/0/1">Tobias Edwards</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1">Benjamin I. P. Rubinstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zuhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Sanming Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.05975">
                                    <div class="article-summary-box-inner">
                                        <span>Blowfish privacy is a recent generalisation of differential privacy that
enables improved utility while maintaining privacy policies with semantic
guarantees, a factor that has driven the popularity of differential privacy in
computer science. This paper relates Blowfish privacy to an important measure
of privacy loss of information channels from the communications theory
community: min-entropy leakage. Symmetry in an input data neighbouring relation
is central to known connections between differential privacy and min-entropy
leakage. But while differential privacy exhibits strong symmetry, Blowfish
neighbouring relations correspond to arbitrary simple graphs owing to the
framework&#x27;s flexible privacy policies. To bound the min-entropy leakage of
Blowfish-private mechanisms we organise our analysis over symmetrical
partitions corresponding to orbits of graph automorphism groups. A construction
meeting our bound with asymptotic equality demonstrates tightness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Revisiting Hilbert-Schmidt Information Bottleneck for Adversarial Robustness. (arXiv:2106.02734v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zifeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jian_T/0/1/0/all/0/1">Tong Jian</a>, <a href="http://arxiv.org/find/cs/1/au:+Masoomi_A/0/1/0/all/0/1">Aria Masoomi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ioannidis_S/0/1/0/all/0/1">Stratis Ioannidis</a>, <a href="http://arxiv.org/find/cs/1/au:+Dy_J/0/1/0/all/0/1">Jennifer Dy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02734">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the HSIC (Hilbert-Schmidt independence criterion) bottleneck
as a regularizer for learning an adversarially robust deep neural network
classifier. We show that the HSIC bottleneck enhances robustness to adversarial
attacks both theoretically and experimentally. Our experiments on multiple
benchmark datasets and architectures demonstrate that incorporating an HSIC
bottleneck regularizer attains competitive natural accuracy and improves
adversarial robustness, both with and without adversarial examples during
training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bandwidth-based Step-Sizes for Non-Convex Stochastic Optimization. (arXiv:2106.02888v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaoyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Johansson_M/0/1/0/all/0/1">Mikael Johansson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02888">
                                    <div class="article-summary-box-inner">
                                        <span>Many popular learning-rate schedules for deep neural networks combine a
decaying trend with local perturbations that attempt to escape saddle points
and bad local minima. We derive convergence guarantees for bandwidth-based
step-sizes, a general class of learning-rates that are allowed to vary in a
banded region. This framework includes cyclic and non-monotonic step-sizes for
which no theoretical guarantees were previously known. We provide worst-case
guarantees for SGD on smooth non-convex problems under several bandwidth-based
step sizes, including stagewise $1/\sqrt{t}$ and the popular step-decay
(constant and then drop by a constant), which is also shown to be optimal.
Moreover, we show that its momentum variant (SGDM) converges as fast as SGD
with the bandwidth-based step-decay step-size. Finally, we propose some novel
step-size schemes in the bandwidth-based family and verify their efficiency on
several deep neural network training tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attacker Behaviour Profiling using Stochastic Ensemble of Hidden Markov Models. (arXiv:1905.11824v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Deshmukh_S/0/1/0/all/0/1">Soham Deshmukh</a>, <a href="http://arxiv.org/find/cs/1/au:+Rade_R/0/1/0/all/0/1">Rahul Rade</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazi_D/0/1/0/all/0/1">Dr. Faruk Kazi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.11824">
                                    <div class="article-summary-box-inner">
                                        <span>Cyber threat intelligence is one of the emerging areas of focus in
information security. Much of the recent work has focused on rule-based methods
and detection of network attacks using Intrusion Detection algorithms. In this
paper we propose a framework for inspecting and modelling the behavioural
aspect of an attacker to obtain better insight predictive power on his future
actions. For modelling we propose a novel semi-supervised algorithm called
Fusion Hidden Markov Model (FHMM) which is more robust to noise, requires
comparatively less training time, and utilizes the benefits of ensemble
learning to better model temporal relationships in data. This paper evaluates
the performances of FHMM and compares it with both traditional algorithms like
Markov Chain, Hidden Markov Model (HMM) and recently developed Deep Recurrent
Neural Network (Deep RNN) architectures. We conduct the experiments on dataset
consisting of real data attacks on a Cowrie honeypot system. FHMM provides
accuracy comparable to deep RNN architectures at significant lower training
time. Given these experimental results, we recommend using FHMM for modelling
discrete temporal data for significantly faster training and better performance
than existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedNL: Making Newton-Type Methods Applicable to Federated Learning. (arXiv:2106.02969v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Safaryan_M/0/1/0/all/0/1">Mher Safaryan</a>, <a href="http://arxiv.org/find/cs/1/au:+Islamov_R/0/1/0/all/0/1">Rustem Islamov</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1">Xun Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Richtarik_P/0/1/0/all/0/1">Peter Richt&#xe1;rik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02969">
                                    <div class="article-summary-box-inner">
                                        <span>Inspired by recent work of Islamov et al (2021), we propose a family of
Federated Newton Learn (FedNL) methods, which we believe is a marked step in
the direction of making second-order methods applicable to FL. In contrast to
the aforementioned work, FedNL employs a different Hessian learning technique
which i) enhances privacy as it does not rely on the training data to be
revealed to the coordinating server, ii) makes it applicable beyond generalized
linear models, and iii) provably works with general contractive compression
operators for compressing the local Hessians, such as Top-$K$ or Rank-$R$,
which are vastly superior in practice. Notably, we do not need to rely on error
feedback for our methods to work with contractive compressors. Moreover, we
develop FedNL-PP, FedNL-CR and FedNL-LS, which are variants of FedNL that
support partial participation, and globalization via cubic regularization and
line search, respectively, and FedNL-BC, which is a variant that can further
benefit from bidirectional compression of gradients and models, i.e., smart
uplink gradient and smart downlink model compression. We prove local
convergence rates that are independent of the condition number, the number of
training data points, and compression variance. Our communication efficient
Hessian learning technique provably learns the Hessian at the optimum. Finally,
we perform a variety of numerical experiments that show that our FedNL methods
have state-of-the-art communication complexity when compared to key baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Stochastic Behaviour from Aggregate Data. (arXiv:2002.03513v7 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1">Shaojun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongyuan Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Haomin Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.03513">
                                    <div class="article-summary-box-inner">
                                        <span>Learning nonlinear dynamics from aggregate data is a challenging problem
because the full trajectory of each individual is not available, namely, the
individual observed at one time may not be observed at the next time point, or
the identity of individual is unavailable. This is in sharp contrast to
learning dynamics with full trajectory data, on which the majority of existing
methods are based. We propose a novel method using the weak form of Fokker
Planck Equation (FPE) -- a partial differential equation -- to describe the
density evolution of data in a sampled form, which is then combined with
Wasserstein generative adversarial network (WGAN) in the training process. In
such a sample-based framework we are able to learn the nonlinear dynamics from
aggregate data without explicitly solving the partial differential equation
(PDE) FPE. We demonstrate our approach in the context of a series of synthetic
and real-world data sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Constructive Universal High-Dimensional Distribution Generation through Deep ReLU Networks. (arXiv:2006.16664v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perekrestenko_D/0/1/0/all/0/1">Dmytro Perekrestenko</a>, <a href="http://arxiv.org/find/cs/1/au:+Muller_S/0/1/0/all/0/1">Stephan M&#xfc;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Bolcskei_H/0/1/0/all/0/1">Helmut B&#xf6;lcskei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.16664">
                                    <div class="article-summary-box-inner">
                                        <span>We present an explicit deep neural network construction that transforms
uniformly distributed one-dimensional noise into an arbitrarily close
approximation of any two-dimensional Lipschitz-continuous target distribution.
The key ingredient of our design is a generalization of the &quot;space-filling&quot;
property of sawtooth functions discovered in (Bailey &amp; Telgarsky, 2018). We
elicit the importance of depth - in our neural network construction - in
driving the Wasserstein distance between the target distribution and the
approximation realized by the network to zero. An extension to output
distributions of arbitrary dimension is outlined. Finally, we show that the
proposed construction does not incur a cost - in terms of error measured in
Wasserstein-distance - relative to generating $d$-dimensional target
distributions from $d$ independent random variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Graph to Graphs Framework for Retrosynthesis Prediction. (arXiv:2003.12725v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Chence Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Minkai Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hongyu Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Ming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.12725">
                                    <div class="article-summary-box-inner">
                                        <span>A fundamental problem in computational chemistry is to find a set of
reactants to synthesize a target molecule, a.k.a. retrosynthesis prediction.
Existing state-of-the-art methods rely on matching the target molecule with a
large set of reaction templates, which are very computationally expensive and
also suffer from the problem of coverage. In this paper, we propose a novel
template-free approach called G2Gs by transforming a target molecular graph
into a set of reactant molecular graphs. G2Gs first splits the target molecular
graph into a set of synthons by identifying the reaction centers, and then
translates the synthons to the final reactant graphs via a variational graph
translation framework. Experimental results show that G2Gs significantly
outperforms existing template-free approaches by up to 63% in terms of the
top-1 accuracy and achieves a performance close to that of state-of-the-art
template based approaches, but does not require domain knowledge and is much
more scalable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">k-Mixup Regularization for Deep Learning via Optimal Transport. (arXiv:2106.02933v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Greenewald_K/0/1/0/all/0/1">Kristjan Greenewald</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_A/0/1/0/all/0/1">Anming Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yurochkin_M/0/1/0/all/0/1">Mikhail Yurochkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1">Justin Solomon</a>, <a href="http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1">Edward Chien</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02933">
                                    <div class="article-summary-box-inner">
                                        <span>Mixup is a popular regularization technique for training deep neural networks
that can improve generalization and increase adversarial robustness. It
perturbs input training data in the direction of other randomly-chosen
instances in the training set. To better leverage the structure of the data, we
extend mixup to \emph{$k$-mixup} by perturbing $k$-batches of training points
in the direction of other $k$-batches using displacement interpolation,
interpolation under the Wasserstein metric. We demonstrate theoretically and in
simulations that $k$-mixup preserves cluster and manifold structures, and we
extend theory studying efficacy of standard mixup. Our empirical results show
that training with $k$-mixup further improves generalization and robustness on
benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">W-RST: Towards a Weighted RST-style Discourse Framework. (arXiv:2106.02658v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huber_P/0/1/0/all/0/1">Patrick Huber</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Wen Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1">Giuseppe Carenini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02658">
                                    <div class="article-summary-box-inner">
                                        <span>Aiming for a better integration of data-driven and linguistically-inspired
approaches, we explore whether RST Nuclearity, assigning a binary assessment of
importance between text segments, can be replaced by automatically generated,
real-valued scores, in what we call a Weighted-RST framework. In particular, we
find that weighted discourse trees from auxiliary tasks can benefit key NLP
downstream applications, compared to nuclearity-centered approaches. We further
show that real-valued importance distributions partially and interestingly
align with the assessment and uncertainty of human annotators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PID-GAN: A GAN Framework based on a Physics-informed Discriminator for Uncertainty Quantification with Physics. (arXiv:2106.02993v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Daw_A/0/1/0/all/0/1">Arka Daw</a>, <a href="http://arxiv.org/find/cs/1/au:+Maruf_M/0/1/0/all/0/1">M. Maruf</a>, <a href="http://arxiv.org/find/cs/1/au:+Karpatne_A/0/1/0/all/0/1">Anuj Karpatne</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02993">
                                    <div class="article-summary-box-inner">
                                        <span>As applications of deep learning (DL) continue to seep into critical
scientific use-cases, the importance of performing uncertainty quantification
(UQ) with DL has become more pressing than ever before. In scientific
applications, it is also important to inform the learning of DL models with
knowledge of physics of the problem to produce physically consistent and
generalized solutions. This is referred to as the emerging field of
physics-informed deep learning (PIDL). We consider the problem of developing
PIDL formulations that can also perform UQ. To this end, we propose a novel
physics-informed GAN architecture, termed PID-GAN, where the knowledge of
physics is used to inform the learning of both the generator and discriminator
models, making ample use of unlabeled data instances. We show that our proposed
PID-GAN framework does not suffer from imbalance of generator gradients from
multiple loss terms as compared to state-of-the-art. We also empirically
demonstrate the efficacy of our proposed framework on a variety of case studies
involving benchmark physics-based PDEs as well as imperfect physics. All the
code and datasets used in this study have been made available on this link :
https://github.com/arkadaw9/PID-GAN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Infomax Adversarial Learning for Treatment Effect Estimation with Networked Observational Data. (arXiv:2106.02881v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chu_Z/0/1/0/all/0/1">Zhixuan Chu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rathbun_S/0/1/0/all/0/1">Stephen L. Rathbun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Sheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02881">
                                    <div class="article-summary-box-inner">
                                        <span>Treatment effect estimation from observational data is a critical research
topic across many domains. The foremost challenge in treatment effect
estimation is how to capture hidden confounders. Recently, the growing
availability of networked observational data offers a new opportunity to deal
with the issue of hidden confounders. Unlike networked data in traditional
graph learning tasks, such as node classification and link detection, the
networked data under the causal inference problem has its particularity, i.e.,
imbalanced network structure. In this paper, we propose a Graph Infomax
Adversarial Learning (GIAL) model for treatment effect estimation, which makes
full use of the network structure to capture more information by recognizing
the imbalance in network structure. We evaluate the performance of our GIAL
model on two benchmark datasets, and the results demonstrate superiority over
the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Attribute-Aligned Strategy for Learning Speech Representation. (arXiv:2106.02810v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1">Yu-Lin Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Su_B/0/1/0/all/0/1">Bo-Hao Su</a>, <a href="http://arxiv.org/find/eess/1/au:+Hong_Y/0/1/0/all/0/1">Y.-W. Peter Hong</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_C/0/1/0/all/0/1">Chi-Chun Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02810">
                                    <div class="article-summary-box-inner">
                                        <span>Advancement in speech technology has brought convenience to our life.
However, the concern is on the rise as speech signal contains multiple personal
attributes, which would lead to either sensitive information leakage or bias
toward decision. In this work, we propose an attribute-aligned learning
strategy to derive speech representation that can flexibly address these issues
by attribute-selection mechanism. Specifically, we propose a
layered-representation variational autoencoder (LR-VAE), which factorizes
speech representation into attribute-sensitive nodes, to derive an
identity-free representation for speech emotion recognition (SER), and an
emotionless representation for speaker verification (SV). Our proposed method
achieves competitive performances on identity-free SER and a better performance
on emotionless SV, comparing to the current state-of-the-art method of using
adversarial learning applied on a large emotion corpora, the MSP-Podcast. Also,
our proposed learning strategy reduces the model and training process needed to
achieve multiple privacy-preserving tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Time Attention Networks for Irregularly Sampled Time Series. (arXiv:2101.10318v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shukla_S/0/1/0/all/0/1">Satya Narayan Shukla</a>, <a href="http://arxiv.org/find/cs/1/au:+Marlin_B/0/1/0/all/0/1">Benjamin M. Marlin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10318">
                                    <div class="article-summary-box-inner">
                                        <span>Irregular sampling occurs in many time series modeling applications where it
presents a significant challenge to standard deep learning models. This work is
motivated by the analysis of physiological time series data in electronic
health records, which are sparse, irregularly sampled, and multivariate. In
this paper, we propose a new deep learning framework for this setting that we
call Multi-Time Attention Networks. Multi-Time Attention Networks learn an
embedding of continuous-time values and use an attention mechanism to produce a
fixed-length representation of a time series containing a variable number of
observations. We investigate the performance of this framework on interpolation
and classification tasks using multiple datasets. Our results show that the
proposed approach performs as well or better than a range of baseline and
recently proposed models while offering significantly faster training times
than current state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HMRL: Hyper-Meta Learning for Sparse Reward Reinforcement Learning Problem. (arXiv:2002.04238v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1">Yun Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiangfeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_B/0/1/0/all/0/1">Bo Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaofeng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongyuan Zha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.04238">
                                    <div class="article-summary-box-inner">
                                        <span>In spite of the success of existing meta reinforcement learning methods, they
still have difficulty in learning a meta policy effectively for RL problems
with sparse reward. In this respect, we develop a novel meta reinforcement
learning framework called Hyper-Meta RL(HMRL), for sparse reward RL problems.
It is consisted with three modules including the cross-environment meta state
embedding module which constructs a common meta state space to adapt to
different environments; the meta state based environment-specific meta reward
shaping which effectively extends the original sparse reward trajectory by
cross-environmental knowledge complementarity and as a consequence the meta
policy achieves better generalization and efficiency with the shaped meta
reward. Experiments with sparse-reward environments show the superiority of
HMRL on both transferability and policy learning efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Leakage: The Role of Information Complexity in Privacy Leakage. (arXiv:2106.02818v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Atashin_A/0/1/0/all/0/1">Amir Ahooye Atashin</a>, <a href="http://arxiv.org/find/cs/1/au:+Razeghi_B/0/1/0/all/0/1">Behrooz Razeghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1">Deniz G&#xfc;nd&#xfc;z</a>, <a href="http://arxiv.org/find/cs/1/au:+Voloshynovskiy_S/0/1/0/all/0/1">Slava Voloshynovskiy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02818">
                                    <div class="article-summary-box-inner">
                                        <span>We study the role of information complexity in privacy leakage about an
attribute of an adversary&#x27;s interest, which is not known a priori to the system
designer. Considering the supervised representation learning setup and using
neural networks to parameterize the variational bounds of information
quantities, we study the impact of the following factors on the amount of
information leakage: information complexity regularizer weight, latent space
dimension, the cardinalities of the known utility and unknown sensitive
attribute sets, the correlation between utility and sensitive attributes, and a
potential bias in a sensitive attribute of adversary&#x27;s interest. We conduct
extensive experiments on Colored-MNIST and CelebA datasets to evaluate the
effect of information complexity on the amount of intrinsic leakage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Bandits with Unknown Graph Structure. (arXiv:2106.02988v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lu_Y/0/1/0/all/0/1">Yangyi Lu</a>, <a href="http://arxiv.org/find/stat/1/au:+Meisami_A/0/1/0/all/0/1">Amirhossein Meisami</a>, <a href="http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1">Ambuj Tewari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02988">
                                    <div class="article-summary-box-inner">
                                        <span>In causal bandit problems, the action set consists of interventions on
variables of a causal graph. Several researchers have recently studied such
bandit problems and pointed out their practical applications. However, all
existing works rely on a restrictive and impractical assumption that the
learner is given full knowledge of the causal graph structure upfront. In this
paper, we develop novel causal bandit algorithms without knowing the causal
graph. Our algorithms work well for causal trees, causal forests and a general
class of causal graphs. The regret guarantees of our algorithms greatly improve
upon those of standard multi-armed bandit (MAB) algorithms under mild
conditions. Lastly, we prove our mild conditions are necessary: without them
one cannot do better than standard MAB bandit algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Numerical Composition of Differential Privacy. (arXiv:2106.02848v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gopi_S/0/1/0/all/0/1">Sivakanth Gopi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yin Tat Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Wutschitz_L/0/1/0/all/0/1">Lukas Wutschitz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02848">
                                    <div class="article-summary-box-inner">
                                        <span>We give a fast algorithm to optimally compose privacy guarantees of
differentially private (DP) algorithms to arbitrary accuracy. Our method is
based on the notion of privacy loss random variables to quantify the privacy
loss of DP algorithms. The running time and memory needed for our algorithm to
approximate the privacy curve of a DP algorithm composed with itself $k$ times
is $\tilde{O}(\sqrt{k})$. This improves over the best prior method by Koskela
et al. (2020) which requires $\tilde{\Omega}(k^{1.5})$ running time. We
demonstrate the utility of our algorithm by accurately computing the privacy
loss of DP-SGD algorithm of Abadi et al. (2016) and showing that our algorithm
speeds up the privacy computations by a few orders of magnitude compared to
prior work, while maintaining similar accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learnable Fourier Features for Multi-DimensionalSpatial Positional Encoding. (arXiv:2106.02795v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Si_S/0/1/0/all/0/1">Si Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1">Samy Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02795">
                                    <div class="article-summary-box-inner">
                                        <span>Attentional mechanisms are order-invariant. Positional encoding is a crucial
component to allow attention-based deep model architectures such as Transformer
to address sequences or images where the position of information matters. In
this paper, we propose a novel positional encoding method based on learnable
Fourier features. Instead of hard-coding each position as a token or a vector,
we represent each position, which can be multi-dimensional, as a trainable
encoding based on learnable Fourier feature mapping, modulated with a
multi-layer perceptron. The representation is particularly advantageous for a
spatial multi-dimensional position, e.g., pixel positions on an image, where
$L_2$ distances or more complex positional relationships need to be captured.
Our experiments based on several public benchmark tasks show that our learnable
Fourier feature representation for multi-dimensional positional encoding
outperforms existing methods by both improving the accuracy and allowing faster
convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accelerated Learning with Robustness to Adversarial Regressors. (arXiv:2005.01529v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Gaudio_J/0/1/0/all/0/1">Joseph E. Gaudio</a>, <a href="http://arxiv.org/find/math/1/au:+Annaswamy_A/0/1/0/all/0/1">Anuradha M. Annaswamy</a>, <a href="http://arxiv.org/find/math/1/au:+Moreu_J/0/1/0/all/0/1">Jos&#xe9; M. Moreu</a>, <a href="http://arxiv.org/find/math/1/au:+Bolender_M/0/1/0/all/0/1">Michael A. Bolender</a>, <a href="http://arxiv.org/find/math/1/au:+Gibson_T/0/1/0/all/0/1">Travis E. Gibson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01529">
                                    <div class="article-summary-box-inner">
                                        <span>High order momentum-based parameter update algorithms have seen widespread
applications in training machine learning models. Recently, connections with
variational approaches have led to the derivation of new learning algorithms
with accelerated learning guarantees. Such methods however, have only
considered the case of static regressors. There is a significant need for
parameter update algorithms which can be proven stable in the presence of
adversarial time-varying regressors, as is commonplace in control theory. In
this paper, we propose a new discrete time algorithm which 1) provides
stability and asymptotic convergence guarantees in the presence of adversarial
regressors by leveraging insights from adaptive control theory and 2) provides
non-asymptotic accelerated learning guarantees leveraging insights from convex
optimization. In particular, our algorithm reaches an $\epsilon$ sub-optimal
point in at most $\tilde{\mathcal{O}}(1/\sqrt{\epsilon})$ iterations when
regressors are constant - matching lower bounds due to Nesterov of
$\Omega(1/\sqrt{\epsilon})$, up to a $\log(1/\epsilon)$ factor and provides
guaranteed bounds for stability when regressors are time-varying. We provide
numerical experiments for a variant of Nesterov&#x27;s provably hard convex
optimization problem with time-varying regressors, as well as the problem of
recovering an image with a time-varying blur and noise using streaming data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Same State, Different Task: Continual Reinforcement Learning without Interference. (arXiv:2106.02940v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kessler_S/0/1/0/all/0/1">Samuel Kessler</a>, <a href="http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1">Jack Parker-Holder</a>, <a href="http://arxiv.org/find/cs/1/au:+Ball_P/0/1/0/all/0/1">Philip Ball</a>, <a href="http://arxiv.org/find/cs/1/au:+Zohren_S/0/1/0/all/0/1">Stefan Zohren</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1">Stephen J. Roberts</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02940">
                                    <div class="article-summary-box-inner">
                                        <span>Continual Learning (CL) considers the problem of training an agent
sequentially on a set of tasks while seeking to retain performance on all
previous tasks. A key challenge in CL is catastrophic forgetting, which arises
when performance on a previously mastered task is reduced when learning a new
task. While a variety of methods exist to combat forgetting, in some cases
tasks are fundamentally incompatible with each other and thus cannot be learnt
by a single policy. This can occur, in reinforcement learning (RL) when an
agent may be rewarded for achieving different goals from the same observation.
In this paper we formalize this &#x60;&#x60;interference&#x27;&#x27; as distinct from the problem
of forgetting. We show that existing CL methods based on single neural network
predictors with shared replay buffers fail in the presence of interference.
Instead, we propose a simple method, OWL, to address this challenge. OWL learns
a factorized policy, using shared feature extraction layers, but separate
heads, each specializing on a new task. The separate heads in OWL are used to
prevent interference. At test time, we formulate policy selection as a
multi-armed bandit problem, and show it is possible to select the best policy
for an unknown task using feedback from the environment. The use of bandit
algorithms allows the OWL agent to constructively re-use different continually
learnt policies at different times during an episode. We show in multiple RL
environments that existing replay based CL methods fail, while OWL is able to
achieve close to optimal performance when training sequentially.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Stochastic Linear Contextual Bandits Under Adversarial Attacks. (arXiv:2106.02978v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ding_Q/0/1/0/all/0/1">Qin Ding</a>, <a href="http://arxiv.org/find/stat/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>, <a href="http://arxiv.org/find/stat/1/au:+Sharpnack_J/0/1/0/all/0/1">James Sharpnack</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02978">
                                    <div class="article-summary-box-inner">
                                        <span>Stochastic linear contextual bandit algorithms have substantial applications
in practice, such as recommender systems, online advertising, clinical trials,
etc. Recent works show that optimal bandit algorithms are vulnerable to
adversarial attacks and can fail completely in the presence of attacks.
Existing robust bandit algorithms only work for the non-contextual setting
under the attack of rewards and cannot improve the robustness in the general
and popular contextual bandit environment. In addition, none of the existing
methods can defend against attacked context. In this work, we provide the first
robust bandit algorithm for stochastic linear contextual bandit setting under a
fully adaptive and omniscient attack. Our algorithm not only works under the
attack of rewards, but also under attacked context. Moreover, it does not need
any information about the attack budget or the particular form of the attack.
We provide theoretical guarantees for our proposed algorithm and show by
extensive experiments that our proposed algorithm significantly improves the
robustness against various kinds of popular attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Denoising Word Embeddings by Averaging in a Shared Space. (arXiv:2106.02954v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1">Avi Caciularu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1">Ido Dagan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberger_J/0/1/0/all/0/1">Jacob Goldberger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02954">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a new approach for smoothing and improving the quality of word
embeddings. We consider a method of fusing word embeddings that were trained on
the same corpus but with different initializations. We project all the models
to a shared vector space using an efficient implementation of the Generalized
Procrustes Analysis (GPA) procedure, previously used in multilingual word
translation. Our word representation demonstrates consistent improvements over
the raw models as well as their simplistic average, on a range of tasks. As the
new representations are more stable and reliable, there is a noticeable
improvement in rare word evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural dSCA: demixing multimodal interaction among brain areas during naturalistic experiments. (arXiv:2106.02948v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Takagi_Y/0/1/0/all/0/1">Yu Takagi</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hunt_L/0/1/0/all/0/1">Laurence T. Hunt</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ohata_R/0/1/0/all/0/1">Ryu Ohata</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Imamizu_H/0/1/0/all/0/1">Hiroshi Imamizu</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Hirayama_J/0/1/0/all/0/1">Jun-ichiro Hirayama</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02948">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-regional interaction among neuronal populations underlies the brain&#x27;s
processing of rich sensory information in our daily lives. Recent neuroscience
and neuroimaging studies have increasingly used naturalistic stimuli and
experimental design to identify such realistic sensory computation in the
brain. However, existing methods for cross-areal interaction analysis with
dimensionality reduction, such as reduced-rank regression and canonical
correlation analysis, have limited applicability and interpretability in
naturalistic settings because they usually do not appropriately &#x27;demix&#x27; neural
interactions into those associated with different types of task parameters or
stimulus features (e.g., visual or audio). In this paper, we develop a new
method for cross-areal interaction analysis that uses the rich task or stimulus
parameters to reveal how and what types of information are shared by different
neural populations. The proposed neural demixed shared component analysis
combines existing dimensionality reduction methods with a practical neural
network implementation of functional analysis of variance with latent
variables, thereby efficiently demixing nonlinear effects of continuous and
multimodal stimuli. We also propose a simplifying alternative under the
assumptions of linear effects and unimodal stimuli. To demonstrate our methods,
we analyzed two human neuroimaging datasets of participants watching
naturalistic videos of movies and dance movements. The results demonstrate that
our methods provide new insights into multi-regional interaction in the brain
during naturalistic sensory inputs, which cannot be captured by conventional
techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Temporal Graph Neural Network for Trajectory Prediction. (arXiv:2106.02930v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_D/0/1/0/all/0/1">Defu Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiachen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hengbo Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1">Masayoshi Tomizuka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02930">
                                    <div class="article-summary-box-inner">
                                        <span>An effective understanding of the contextual environment and accurate motion
forecasting of surrounding agents is crucial for the development of autonomous
vehicles and social mobile robots. This task is challenging since the behavior
of an autonomous agent is not only affected by its own intention, but also by
the static environment and surrounding dynamically interacting agents. Previous
works focused on utilizing the spatial and temporal information in time domain
while not sufficiently taking advantage of the cues in frequency domain. To
this end, we propose a Spectral Temporal Graph Neural Network (SpecTGNN), which
can capture inter-agent correlations and temporal dependency simultaneously in
frequency domain in addition to time domain. SpecTGNN operates on both an agent
graph with dynamic state information and an environment graph with the features
extracted from context images in two streams. The model integrates graph
Fourier transform, spectral graph convolution and temporal gated convolution to
encode history information and forecast future trajectories. Moreover, we
incorporate a multi-head spatio-temporal attention mechanism to mitigate the
effect of error propagation in a long time horizon. We demonstrate the
performance of SpecTGNN on two public trajectory prediction benchmark datasets,
which achieves state-of-the-art performance in terms of prediction accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detection of fake news on CoViD-19 on Web Search Engines. (arXiv:2103.11804v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazzeo_V/0/1/0/all/0/1">V. Mazzeo</a>, <a href="http://arxiv.org/find/cs/1/au:+Rapisarda_A/0/1/0/all/0/1">A. Rapisarda</a>, <a href="http://arxiv.org/find/cs/1/au:+Giuffrida_G/0/1/0/all/0/1">G. Giuffrida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.11804">
                                    <div class="article-summary-box-inner">
                                        <span>In early January 2020, after China reported the first cases of the new
coronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully
accurate information has started spreading faster than the virus itself.
Alongside this pandemic, people have experienced a parallel infodemic, i.e., an
overabundance of information, some of which misleading or even harmful, that
has widely spread around the globe. Although Social Media are increasingly
being used as information source, Web Search Engines, like Google or Yahoo!,
still represent a powerful and trustworthy resource for finding information on
the Web. This is due to their capability to capture the largest amount of
information, helping users quickly identify the most relevant, useful, although
not always the most reliable, results for their search queries. This study aims
to detect potential misleading and fake contents by capturing and analysing
textual information, which flow through Search Engines. By using a real-world
dataset associated with recent CoViD-19 pandemic, we first apply re-sampling
techniques for class imbalance, then we use existing Machine Learning
algorithms for classification of not reliable news. By extracting lexical and
host-based features of associated Uniform Resource Locators (URLs) for news
articles, we show that the proposed methods, so common in phishing and
malicious URLs detection, can improve the efficiency and performance of
classifiers. Based on these findings, we suggest that the use of both textual
and URLs features can improve the effectiveness of fake news detection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DIVERSE: Bayesian Data IntegratiVE learning for precise drug ResponSE prediction. (arXiv:2104.00520v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Paltun_B/0/1/0/all/0/1">Bet&#xfc;l G&#xfc;ven&#xe7; Paltun</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kaski_S/0/1/0/all/0/1">Samuel Kaski</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Mamitsuka_H/0/1/0/all/0/1">Hiroshi Mamitsuka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00520">
                                    <div class="article-summary-box-inner">
                                        <span>Detecting predictive biomarkers from multi-omics data is important for
precision medicine, to improve diagnostics of complex diseases and for better
treatments. This needs substantial experimental efforts that are made difficult
by the heterogeneity of cell lines and huge cost. An effective solution is to
build a computational model over the diverse omics data, including genomic,
molecular, and environmental information. However, choosing informative and
reliable data sources from among the different types of data is a challenging
problem. We propose DIVERSE, a framework of Bayesian importance-weighted tri-
and bi-matrix factorization(DIVERSE3 or DIVERSE2) to predict drug responses
from data of cell lines, drugs, and gene interactions. DIVERSE integrates the
data sources systematically, in a step-wise manner, examining the importance of
each added data set in turn. More specifically, we sequentially integrate five
different data sets, which have not all been combined in earlier bioinformatic
methods for predicting drug responses. Empirical experiments show that DIVERSE
clearly outperformed five other methods including three state-of-the-art
approaches, under cross-validation, particularly in out-of-matrix prediction,
which is closer to the setting of real use cases and more challenging than
simpler in-matrix prediction. Additionally, case studies for discovering new
drugs further confirmed the performance advantage of DIVERSE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Syndicated Bandits: A Framework for Auto Tuning Hyper-parameters in Contextual Bandit Algorithms. (arXiv:2106.02979v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ding_Q/0/1/0/all/0/1">Qin Ding</a>, <a href="http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1">Yi-Wei Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>, <a href="http://arxiv.org/find/stat/1/au:+Sharpnack_J/0/1/0/all/0/1">James Sharpnack</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02979">
                                    <div class="article-summary-box-inner">
                                        <span>The stochastic contextual bandit problem, which models the trade-off between
exploration and exploitation, has many real applications, including recommender
systems, online advertising and clinical trials. As many other machine learning
algorithms, contextual bandit algorithms often have one or more
hyper-parameters. As an example, in most optimal stochastic contextual bandit
algorithms, there is an unknown exploration parameter which controls the
trade-off between exploration and exploitation. A proper choice of the
hyper-parameters is essential for contextual bandit algorithms to perform well.
However, it is infeasible to use offline tuning methods to select
hyper-parameters in contextual bandit environment since there is no
pre-collected dataset and the decisions have to be made in real time. To tackle
this problem, we first propose a two-layer bandit structure for auto tuning the
exploration parameter and further generalize it to the Syndicated Bandits
framework which can learn multiple hyper-parameters dynamically in contextual
bandit environment. We show our Syndicated Bandits framework can achieve the
optimal regret upper bounds and is general enough to handle the tuning tasks in
many popular contextual bandit algorithms, such as LinUCB, LinTS, UCB-GLM, etc.
Experiments on both synthetic and real datasets validate the effectiveness of
our proposed framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Practical Privacy Filters and Odometers with R\&#x27;enyi Differential Privacy and Applications to Differentially Private Deep Learning. (arXiv:2103.01379v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lecuyer_M/0/1/0/all/0/1">Mathias L&#xe9;cuyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01379">
                                    <div class="article-summary-box-inner">
                                        <span>Differential Privacy (DP) is the leading approach to privacy preserving deep
learning. As such, there are multiple efforts to provide drop-in integration of
DP into popular frameworks. These efforts, which add noise to each gradient
computation to make it DP, rely on composition theorems to bound the total
privacy loss incurred over this sequence of DP computations.

However, existing composition theorems present a tension between efficiency
and flexibility. Most theorems require all computations in the sequence to have
a predefined DP parameter, called the privacy budget. This prevents the design
of training algorithms that adapt the privacy budget on the fly, or that
terminate early to reduce the total privacy loss. Alternatively, the few
existing composition results for adaptive privacy budgets provide complex
bounds on the privacy loss, with constants too large to be practical.

In this paper, we study DP composition under adaptive privacy budgets through
the lens of R\&#x27;enyi Differential Privacy, proving a simpler composition theorem
with smaller constants, making it practical enough to use in algorithm design.
We demonstrate two applications of this theorem for DP deep learning: adapting
the noise or batch size online to improve a model&#x27;s accuracy within a fixed
total privacy loss, and stopping early when fine-tuning a model to reduce total
privacy loss.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IM-META: Influence Maximization Using Node Metadata in Networks With Unknown Topology. (arXiv:2106.02926v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1">Cong Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_W/0/1/0/all/0/1">Won-Yong Shin</a>, <a href="http://arxiv.org/find/cs/1/au:+Spitz_A/0/1/0/all/0/1">Andreas Spitz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02926">
                                    <div class="article-summary-box-inner">
                                        <span>In real-world applications of influence maximization (IM), the network
structure is often unknown. In this case, we may identify the most influential
seed nodes by exploring only a part of the underlying network given a small
budget for node queries. Motivated by the fact that collecting node metadata is
more cost-effective than investigating the relationship between nodes via
queried nodes, we develop IM-META, an end-to-end solution to IM in networks
with unknown topology by retrieving information from both queries and node
metadata. However, using such metadata to aid the IM process is not without
risk due to the noisy nature of metadata and uncertainties in connectivity
inference. To tackle these challenges, we formulate an IM problem that aims to
find two sets, i.e., seed nodes and queried nodes. We propose an effective
method that iteratively performs three steps: 1) we learn the relationship
between collected metadata and edges via a Siamese neural network model, 2) we
select a number of inferred influential edges to construct a reinforced graph
used for discovering an optimal seed set, and 3) we identify the next node to
query by maximizing the inferred influence spread using a topology-aware
ranking strategy. By querying only 5% of nodes, IM-META reaches 93% of the
upper bound performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proximal Causal Learning with Kernels: Two-Stage Estimation and Moment Restriction. (arXiv:2105.04544v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mastouri_A/0/1/0/all/0/1">Afsaneh Mastouri</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuchen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gultchin_L/0/1/0/all/0/1">Limor Gultchin</a>, <a href="http://arxiv.org/find/cs/1/au:+Korba_A/0/1/0/all/0/1">Anna Korba</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1">Ricardo Silva</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1">Matt J. Kusner</a>, <a href="http://arxiv.org/find/cs/1/au:+Gretton_A/0/1/0/all/0/1">Arthur Gretton</a>, <a href="http://arxiv.org/find/cs/1/au:+Muandet_K/0/1/0/all/0/1">Krikamol Muandet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04544">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of causal effect estimation in the presence of
unobserved confounding, but where proxies for the latent confounder(s) are
observed. We propose two kernel-based methods for nonlinear causal effect
estimation in this setting: (a) a two-stage regression approach, and (b) a
maximum moment restriction approach. We focus on the proximal causal learning
setting, but our methods can be used to solve a wider class of inverse problems
characterised by a Fredholm integral equation. In particular, we provide a
unifying view of two-stage and moment restriction approaches for solving this
problem in a nonlinear setting. We provide consistency guarantees for each
algorithm, and we demonstrate these approaches achieve competitive results on
synthetic data and data simulating a real-world task. In particular, our
approach outperforms earlier methods that are not suited to leveraging proxy
variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-armed Bandit Algorithms on System-on-Chip: Go Frequentist or Bayesian?. (arXiv:2106.02855v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Santosh_S/0/1/0/all/0/1">S. V. Sai Santosh</a>, <a href="http://arxiv.org/find/eess/1/au:+Darak_S/0/1/0/all/0/1">Sumit J. Darak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02855">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-armed Bandit (MAB) algorithms identify the best arm among multiple arms
via exploration-exploitation trade-off without prior knowledge of arm
statistics. Their usefulness in wireless radio, IoT, and robotics demand
deployment on edge devices, and hence, a mapping on system-on-chip (SoC) is
desired. Theoretically, the Bayesian approach-based Thompson Sampling (TS)
algorithm offers better performance than the frequentist approach-based Upper
Confidence Bound (UCB) algorithm. However, TS is not synthesizable due to Beta
function. We address this problem by approximating it via a pseudo-random
number generator-based approach and efficiently realize the TS algorithm on
Zynq SoC. In practice, the type of arms distribution (e.g., Bernoulli,
Gaussian, etc.) is unknown and hence, a single algorithm may not be optimal. We
propose a reconfigurable and intelligent MAB (RI-MAB) framework. Here,
intelligence enables the identification of appropriate MAB algorithms for a
given environment, and reconfigurability allows on-the-fly switching between
algorithms on the SoC. This eliminates the need for parallel implementation of
algorithms resulting in huge savings in resources and power consumption. We
analyze the functional correctness, area, power, and execution time of the
proposed and existing architectures for various arm distributions, word-length,
and hardware-software co-design approaches. We demonstrate the superiority of
the RI-MAB over TS and UCB only architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles. (arXiv:2106.02982v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dasgupta_S/0/1/0/all/0/1">Sagar Dasgupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1">Mizanur Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1">Mhafuzul Islam</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1">Mashrur Chowdhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02982">
                                    <div class="article-summary-box-inner">
                                        <span>In this study, a sensor fusion based GNSS spoofing attack detection framework
is presented that consists of three concurrent strategies for an autonomous
vehicle (AV): (i) prediction of location shift, (ii) detection of turns (left
or right), and (iii) recognition of motion state (including standstill state).
Data from multiple low-cost in-vehicle sensors (i.e., accelerometer, steering
angle sensor, speed sensor, and GNSS) are fused and fed into a recurrent neural
network model, which is a long short-term memory (LSTM) network for predicting
the location shift, i.e., the distance that an AV travels between two
consecutive timestamps. We have then combined k-Nearest Neighbors (k-NN) and
Dynamic Time Warping (DTW) algorithms to detect turns using data from the
steering angle sensor. In addition, data from an AV&#x27;s speed sensor is used to
recognize the AV&#x27;s motion state including the standstill state. To prove the
efficacy of the sensor fusion-based attack detection framework, attack datasets
are created for three unique and sophisticated spoofing attacks turn by turn,
overshoot, and stop using the publicly available real-world Honda Research
Institute Driving Dataset (HDD). Our analysis reveals that the sensor
fusion-based detection framework successfully detects all three types of
spoofing attacks within the required computational latency threshold.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relative stability toward diffeomorphisms indicates performance in deep nets. (arXiv:2105.02468v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Petrini_L/0/1/0/all/0/1">Leonardo Petrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Favero_A/0/1/0/all/0/1">Alessandro Favero</a>, <a href="http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1">Mario Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Wyart_M/0/1/0/all/0/1">Matthieu Wyart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02468">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding why deep nets can classify data in large dimensions remains a
challenge. It has been proposed that they do so by becoming stable to
diffeomorphisms, yet existing empirical measurements support that it is often
not the case. We revisit this question by defining a maximum-entropy
distribution on diffeomorphisms, that allows to study typical diffeomorphisms
of a given norm. We confirm that stability toward diffeomorphisms does not
strongly correlate to performance on benchmark data sets of images. By
contrast, we find that the stability toward diffeomorphisms relative to that of
generic transformations $R_f$ correlates remarkably with the test error
$\epsilon_t$. It is of order unity at initialization but decreases by several
decades during training for state-of-the-art architectures. For CIFAR10 and 15
known architectures, we find $\epsilon_t\approx 0.2\sqrt{R_f}$, suggesting that
obtaining a small $R_f$ is important to achieve good performance. We study how
$R_f$ depends on the size of the training set and compare it to a simple model
of invariant learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exposing the Implicit Energy Networks behind Masked Language Models via Metropolis--Hastings. (arXiv:2106.02736v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goyal_K/0/1/0/all/0/1">Kartik Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1">Chris Dyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Berg_Kirkpatrick_T/0/1/0/all/0/1">Taylor Berg-Kirkpatrick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02736">
                                    <div class="article-summary-box-inner">
                                        <span>While recent work has shown that scores from models trained by the ubiquitous
masked language modeling (MLM) objective effectively discriminate probable and
improbable sequences, it is still an open question if these MLMs specify a
principled probability distribution over the space of possible sequences. In
this paper, we interpret MLMs as energy-based sequence models and propose two
energy parametrizations derivable from the trained MLMs. In order to draw
samples correctly from these models, we develop a tractable \emph{sampling}
scheme based on the Metropolis--Hastings Monte Carlo algorithm. In our
approach, samples are proposed from the same masked conditionals used for
training the masked language models, and they are accepted or rejected based on
their energy values according to the target distribution. We validate the
effectiveness of the proposed parametrizations by exploring the quality of
samples drawn from these energy-based models on the conditional generation task
of machine translation. We theoretically and empirically justify our sampling
algorithm by showing that the masked conditionals on their own do not yield a
Markov chain whose stationary distribution is that of our target distribution,
and our approach generates higher quality samples than other recently proposed
undirected generation approaches (Wang et al., 2019, Ghazvininejad et al.,
2019).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MC2G: An Efficient Algorithm for Matrix Completion with Social and Item Similarity Graphs. (arXiv:2006.04373v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1">Qiaosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Suh_G/0/1/0/all/0/1">Geewon Suh</a>, <a href="http://arxiv.org/find/cs/1/au:+Suh_C/0/1/0/all/0/1">Changho Suh</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_V/0/1/0/all/0/1">Vincent Y. F. Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.04373">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we design and analyze MC2G (Matrix Completion with 2 Graphs),
an algorithm that performs matrix completion in the presence of social and item
similarity graphs. MC2G runs in quasilinear time and is parameter free. It is
based on spectral clustering and local refinement steps. The expected number of
sampled entries required for MC2G to succeed (i.e., recover the clusters in the
graphs and complete the matrix) matches an information-theoretic lower bound up
to a constant factor for a wide range of parameters. We show via extensive
experiments on both synthetic and real datasets that MC2G outperforms other
state-of-the-art matrix completion algorithms that leverage graph side
information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Soft-Attention Improves Skin Cancer Classification Performance. (arXiv:2105.03358v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Datta_S/0/1/0/all/0/1">Soumyya Kanti Datta</a>, <a href="http://arxiv.org/find/eess/1/au:+Shaikh_M/0/1/0/all/0/1">Mohammad Abuzar Shaikh</a>, <a href="http://arxiv.org/find/eess/1/au:+Srihari_S/0/1/0/all/0/1">Sargur N. Srihari</a>, <a href="http://arxiv.org/find/eess/1/au:+Gao_M/0/1/0/all/0/1">Mingchen Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03358">
                                    <div class="article-summary-box-inner">
                                        <span>In clinical applications, neural networks must focus on and highlight the
most important parts of an input image. Soft-Attention mechanism enables a
neural network toachieve this goal. This paper investigates the effectiveness
of Soft-Attention in deep neural architectures. The central aim of
Soft-Attention is to boost the value of important features and suppress the
noise-inducing features. We compare the performance of VGG, ResNet,
InceptionResNetv2 and DenseNet architectures with and without the
Soft-Attention mechanism, while classifying skin lesions. The original network
when coupled with Soft-Attention outperforms the baseline[16] by 4.7% while
achieving a precision of 93.7% on HAM10000 dataset [25]. Additionally,
Soft-Attention coupling improves the sensitivity score by 3.8% compared to
baseline[31] and achieves 91.6% on ISIC-2017 dataset [2]. The code is publicly
available at github.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning of User Verification Models Without Sharing Embeddings. (arXiv:2104.08776v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hosseini_H/0/1/0/all/0/1">Hossein Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hyunsin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1">Sungrack Yun</a>, <a href="http://arxiv.org/find/cs/1/au:+Louizos_C/0/1/0/all/0/1">Christos Louizos</a>, <a href="http://arxiv.org/find/cs/1/au:+Soriaga_J/0/1/0/all/0/1">Joseph Soriaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1">Max Welling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08776">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of training User Verification (UV) models in
federated setting, where each user has access to the data of only one class and
user embeddings cannot be shared with the server or other users. To address
this problem, we propose Federated User Verification (FedUV), a framework in
which users jointly learn a set of vectors and maximize the correlation of
their instance embeddings with a secret linear combination of those vectors. We
show that choosing the linear combinations from the codewords of an
error-correcting code allows users to collaboratively train the model without
revealing their embedding vectors. We present the experimental results for user
verification with voice, face, and handwriting data and show that FedUV is on
par with existing approaches, while not sharing the embeddings with other users
or the server.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TARA: Training and Representation Alteration for AI Fairness and Domain Generalization. (arXiv:2012.06387v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_W/0/1/0/all/0/1">William Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadzic_A/0/1/0/all/0/1">Armin Hadzic</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_N/0/1/0/all/0/1">Neil Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Alajaji_F/0/1/0/all/0/1">Fady Alajaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Burlina_P/0/1/0/all/0/1">Phil Burlina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06387">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel method for enforcing AI fairness with respect to protected
or sensitive factors. This method uses a dual strategy performing training and
representation alteration (TARA) for the mitigation of prominent causes of AI
bias by including: a) the use of representation learning alteration via
adversarial independence to suppress the bias-inducing dependence of the data
representation from protected factors; and b) training set alteration via
intelligent augmentation to address bias-causing data imbalance, by using
generative models that allow the fine control of sensitive factors related to
underrepresented populations via domain adaptation and latent space
manipulation. When testing our methods on image analytics, experiments
demonstrate that TARA significantly or fully debiases baseline models while
outperforming competing debiasing methods that have the same amount of
information, e.g., with (% overall accuracy, % accuracy gap) &#x3D; (78.8, 0.5) vs.
the baseline method&#x27;s score of (71.8, 10.5) for EyePACS, and (73.7, 11.8) vs.
(69.1, 21.7) for CelebA. Furthermore, recognizing certain limitations in
current metrics used for assessing debiasing performance, we propose novel
conjunctive debiasing metrics. Our experiments also demonstrate the ability of
these novel metrics in assessing the Pareto efficiency of the proposed methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Forced Variational Integrator Networks for Prediction and Control of Mechanical Systems. (arXiv:2106.02973v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Havens_A/0/1/0/all/0/1">Aaron Havens</a>, <a href="http://arxiv.org/find/cs/1/au:+Chowdhary_G/0/1/0/all/0/1">Girish Chowdhary</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02973">
                                    <div class="article-summary-box-inner">
                                        <span>As deep learning becomes more prevalent for prediction and control of real
physical systems, it is important that these overparameterized models are
consistent with physically plausible dynamics. This elicits a problem with how
much inductive bias to impose on the model through known physical parameters
and principles to reduce complexity of the learning problem to give us more
reliable predictions. Recent work employs discrete variational integrators
parameterized as a neural network architecture to learn conservative Lagrangian
systems. The learned model captures and enforces global energy preserving
properties of the system from very few trajectories. However, most real systems
are inherently non-conservative and, in practice, we would also like to apply
actuation. In this paper we extend this paradigm to account for general forcing
(e.g. control input and damping) via discrete d&#x27;Alembert&#x27;s principle which may
ultimately be used for control applications. We show that this forced
variational integrator networks (FVIN) architecture allows us to accurately
account for energy dissipation and external forcing while still capturing the
true underlying energy-based passive dynamics. We show that in application this
can result in highly-data efficient model-based control and can predict on real
non-conservative systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bridging the Gap Between Adversarial Robustness and Optimization Bias. (arXiv:2102.08868v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1">Fartash Faghri</a>, <a href="http://arxiv.org/find/cs/1/au:+Gowal_S/0/1/0/all/0/1">Sven Gowal</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasconcelos_C/0/1/0/all/0/1">Cristina Vasconcelos</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1">David J. Fleet</a>, <a href="http://arxiv.org/find/cs/1/au:+Pedregosa_F/0/1/0/all/0/1">Fabian Pedregosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Roux_N/0/1/0/all/0/1">Nicolas Le Roux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08868">
                                    <div class="article-summary-box-inner">
                                        <span>We demonstrate that the choice of optimizer, neural network architecture, and
regularizer significantly affect the adversarial robustness of linear neural
networks, providing guarantees without the need for adversarial training. To
this end, we revisit a known result linking maximally robust classifiers and
minimum norm solutions, and combine it with recent results on the implicit bias
of optimizers. First, we show that, under certain conditions, it is possible to
achieve both perfect standard accuracy and a certain degree of robustness,
simply by training an overparametrized model using the implicit bias of the
optimization. In that regime, there is a direct relationship between the type
of the optimizer and the attack to which the model is robust. To the best of
our knowledge, this work is the first to study the impact of optimization
methods such as sign gradient descent and proximal methods on adversarial
robustness. Second, we characterize the robustness of linear convolutional
models, showing that they resist attacks subject to a constraint on the
Fourier-$\ell_\infty$ norm. To illustrate these findings we design a novel
Fourier-$\ell_\infty$ attack that finds adversarial examples with controllable
frequencies. We evaluate Fourier-$\ell_\infty$ robustness of
adversarially-trained deep CIFAR-10 models from the standard RobustBench
benchmark and visualize adversarial perturbations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Greedy Approximation Algorithms for Active Sequential Hypothesis Testing. (arXiv:2103.04250v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gan_K/0/1/0/all/0/1">Kyra Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_S/0/1/0/all/0/1">Su Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Andrew Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.04250">
                                    <div class="article-summary-box-inner">
                                        <span>In the problem of active sequential hypotheses testing (ASHT), a learner
seeks to identify the true hypothesis from among a known set of hypotheses. The
learner is given a set of actions and knows the random distribution of the
outcome of any action under any true hypothesis. Given a target error
$\delta&gt;0$, the goal is to sequentially select the fewest number of actions so
as to identify the true hypothesis with probability at least $1 - \delta$.
Motivated by applications in which the number of hypotheses or actions is
massive (e.g. genomics-based cancer detection), we propose efficient (greedy,
in fact) algorithms and provide the first approximation guarantees for ASHT,
under two types of adaptivity. Both of our guarantees are independent of the
number of actions and logarithmic in the number of hypotheses. We numerically
evaluate the performance of our algorithms using both synthetic and real DNA
mutation data, demonstrating that our algorithms outperform previous heuristic
policies by large margins.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning for Assignment Problem with Time Constraints. (arXiv:2106.02856v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pathan_S/0/1/0/all/0/1">Sharmin Pathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_V/0/1/0/all/0/1">Vyom Shrivastava</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02856">
                                    <div class="article-summary-box-inner">
                                        <span>We present an end-to-end framework for the Assignment Problem with multiple
tasks mapped to a group of workers, using reinforcement learning while
preserving many constraints. Tasks and workers have time constraints and there
is a cost associated with assigning a worker to a task. Each worker can perform
multiple tasks until it exhausts its allowed time units (capacity). We train a
reinforcement learning agent to find near optimal solutions to the problem by
minimizing total cost associated with the assignments while maintaining hard
constraints. We use proximal policy optimization to optimize model parameters.
The model generates a sequence of actions in real-time which correspond to task
assignment to workers, without having to retrain for changes in the dynamic
state of the environment. In our problem setting reward is computed as negative
of the assignment cost. We also demonstrate our results on bin packing and
capacitated vehicle routing problem, using the same framework. Our results
outperform Google OR-Tools using MIP and CP-SAT solvers with large problem
instances, in terms of solution quality and computation time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AOSLO-net: A deep learning-based method for automatic segmentation of retinal microaneurysms from adaptive optics scanning laser ophthalmoscope images. (arXiv:2106.02800v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_Q/0/1/0/all/0/1">Qian Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Sampani_K/0/1/0/all/0/1">Konstantina Sampani</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1">Mengjia Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Cai_S/0/1/0/all/0/1">Shengze Cai</a>, <a href="http://arxiv.org/find/eess/1/au:+Deng_Y/0/1/0/all/0/1">Yixiang Deng</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">He Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Jennifer K. Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Karniadakis_G/0/1/0/all/0/1">George Em Karniadakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02800">
                                    <div class="article-summary-box-inner">
                                        <span>Adaptive optics scanning laser ophthalmoscopy (AOSLO) provides real-time
retinal images with high resolution down to 2 $\mu m$. This technique enables
detection of the morphologies of individual microaneurysms (MAs), which are one
of the earliest signs of diabetic retinopathy (DR), a frequent complication of
diabetes that can lead to visual impairment and blindness. In contrast to
previous automatic models developed for MA detection on standard fundus
photographs, currently there is no high throughput image protocol available for
automatic analysis of AOSLO photographs. To address this urgency, we introduce
AOSLO-net, a deep neural network framework with customized training policy,
including preprocessing, data augmentation and transfer learning, to
automatically segment MAs from AOSLO images. We evaluate the performance of
AOSLO-net using 87 DR AOSLO images demonstrating very accurate MA detection and
segmentation, leading to correct MA morphological classification, while
outperforming the state-of-the-art both in accuracy and cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Equivariant message passing for the prediction of tensorial properties and molecular spectra. (arXiv:2102.03150v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schutt_K/0/1/0/all/0/1">Kristof T. Sch&#xfc;tt</a>, <a href="http://arxiv.org/find/cs/1/au:+Unke_O/0/1/0/all/0/1">Oliver T. Unke</a>, <a href="http://arxiv.org/find/cs/1/au:+Gastegger_M/0/1/0/all/0/1">Michael Gastegger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03150">
                                    <div class="article-summary-box-inner">
                                        <span>Message passing neural networks have become a method of choice for learning
on graphs, in particular the prediction of chemical properties and the
acceleration of molecular dynamics studies. While they readily scale to large
training data sets, previous approaches have proven to be less data efficient
than kernel methods. We identify limitations of invariant representations as a
major reason and extend the message passing formulation to rotationally
equivariant representations. On this basis, we propose the polarizable atom
interaction neural network (PaiNN) and improve on common molecule benchmarks
over previous networks, while reducing model size and inference time. We
leverage the equivariant atomwise representations obtained by PaiNN for the
prediction of tensorial properties. Finally, we apply this to the simulation of
molecular spectra, achieving speedups of 4-5 orders of magnitude compared to
the electronic structure reference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributed Inference with Sparse and Quantized Communication. (arXiv:2004.01302v4 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Mitra_A/0/1/0/all/0/1">Aritra Mitra</a>, <a href="http://arxiv.org/find/eess/1/au:+Richards_J/0/1/0/all/0/1">John A. Richards</a>, <a href="http://arxiv.org/find/eess/1/au:+Bagchi_S/0/1/0/all/0/1">Saurabh Bagchi</a>, <a href="http://arxiv.org/find/eess/1/au:+Sundaram_S/0/1/0/all/0/1">Shreyas Sundaram</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.01302">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of distributed inference where agents in a network
observe a stream of private signals generated by an unknown state, and aim to
uniquely identify this state from a finite set of hypotheses. We focus on
scenarios where communication between agents is costly, and takes place over
channels with finite bandwidth. To reduce the frequency of communication, we
develop a novel event-triggered distributed learning rule that is based on the
principle of diffusing low beliefs on each false hypothesis. Building on this
principle, we design a trigger condition under which an agent broadcasts only
those components of its belief vector that have adequate innovation, to only
those neighbors that require such information. We prove that our rule
guarantees convergence to the true state exponentially fast almost surely
despite sparse communication, and that it has the potential to significantly
reduce information flow from uninformative agents to informative agents. Next,
to deal with finite-precision communication channels, we propose a distributed
learning rule that leverages the idea of adaptive quantization. We show that by
sequentially refining the range of the quantizers, every agent can learn the
truth exponentially fast almost surely, while using just $1$ bit to encode its
belief on each hypothesis. For both our proposed algorithms, we rigorously
characterize the trade-offs between communication-efficiency and the learning
rate.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Code-Mixing on Sesame Street: Dawn of the Adversarial Polyglots. (arXiv:2103.09593v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1">Samson Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1">Shafiq Joty</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09593">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual models have demonstrated impressive cross-lingual transfer
performance. However, test sets like XNLI are monolingual at the example level.
In multilingual communities, it is common for polyglots to code-mix when
conversing with each other. Inspired by this phenomenon, we present two strong
black-box adversarial attacks (one word-level, one phrase-level) for
multilingual models that push their ability to handle code-mixed sentences to
the limit. The former uses bilingual dictionaries to propose perturbations and
translations of the clean example for sense disambiguation. The latter directly
aligns the clean example with its translations before extracting phrases as
perturbations. Our phrase-level attack has a success rate of 89.75% against
XLM-R-large, bringing its average accuracy of 79.85 down to 8.18 on XNLI.
Finally, we propose an efficient adversarial training scheme that trains in the
same number of steps as the original model and show that it improves model
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Tests and Always-Valid Confidence Intervals for contingency tables and beyond. (arXiv:2106.02693v1 [stat.ME])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1">Rosanne Turner</a>, <a href="http://arxiv.org/find/stat/1/au:+Ly_A/0/1/0/all/0/1">Alexander Ly</a>, <a href="http://arxiv.org/find/stat/1/au:+Grunwald_P/0/1/0/all/0/1">Peter Gr&#xfc;nwald</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02693">
                                    <div class="article-summary-box-inner">
                                        <span>We develop E variables for testing whether two data streams come from the
same source or not, and more generally, whether the difference between the
sources is larger than some minimal effect size. These E variables lead to
tests that remain safe, i.e. keep their Type-I error guarantees, under flexible
sampling scenarios such as optional stopping and continuation. We also develop
the corresponding always-valid confidence intervals. In special cases our E
variables also have an optimal &#x60;growth&#x27; property under the alternative. We
illustrate the generic construction through the special case of 2x2 contingency
tables, where we also allow for the incorporation of different restrictions on
a composite alternative. Comparison to p-value analysis in simulations and a
real-world example show that E variables, through their flexibility, often
allow for early stopping of data collection, thereby retaining similar power as
classical methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sample Complexity of Uniform Convergence for Multicalibration. (arXiv:2005.01757v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shabat_E/0/1/0/all/0/1">Eliran Shabat</a>, <a href="http://arxiv.org/find/cs/1/au:+Cohen_L/0/1/0/all/0/1">Lee Cohen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01757">
                                    <div class="article-summary-box-inner">
                                        <span>There is a growing interest in societal concerns in machine learning systems,
especially in fairness. Multicalibration gives a comprehensive methodology to
address group fairness. In this work, we address the multicalibration error and
decouple it from the prediction error. The importance of decoupling the
fairness metric (multicalibration) and the accuracy (prediction error) is due
to the inherent trade-off between the two, and the societal decision regarding
the &quot;right tradeoff&quot; (as imposed many times by regulators). Our work gives
sample complexity bounds for uniform convergence guarantees of multicalibration
error, which implies that regardless of the accuracy, we can guarantee that the
empirical and (true) multicalibration errors are close. We emphasize that our
results: (1) are more general than previous bounds, as they apply to both
agnostic and realizable settings, and do not rely on a specific type of
algorithm (such as deferentially private), (2) improve over previous
multicalibration sample complexity bounds and (3) implies uniform convergence
guarantees for the classical calibration error.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Exact Solver for the Weston-Watkins SVM Subproblem. (arXiv:2102.05640v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1">Yutong Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Scott_C/0/1/0/all/0/1">Clayton D. Scott</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05640">
                                    <div class="article-summary-box-inner">
                                        <span>Recent empirical evidence suggests that the Weston-Watkins support vector
machine is among the best performing multiclass extensions of the binary SVM.
Current state-of-the-art solvers repeatedly solve a particular subproblem
approximately using an iterative strategy. In this work, we propose an
algorithm that solves the subproblem exactly using a novel reparametrization of
the Weston-Watkins dual problem. For linear WW-SVMs, our solver shows
significant speed-up over the state-of-the-art solver when the number of
classes is large. Our exact subproblem solver also allows us to prove linear
convergence of the overall solver.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially Private Multi-Armed Bandits in the Shuffle Model. (arXiv:2106.02900v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Jay Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaplan_H/0/1/0/all/0/1">Haim Kaplan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>, <a href="http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1">Uri Stemmer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02900">
                                    <div class="article-summary-box-inner">
                                        <span>We give an $(\varepsilon,\delta)$-differentially private algorithm for the
multi-armed bandit (MAB) problem in the shuffle model with a
distribution-dependent regret of $O\left(\left(\sum_{a\in
[k]:\Delta_a&gt;0}\frac{\log
T}{\Delta_a}\right)+\frac{k\sqrt{\log\frac{1}{\delta}}\log
T}{\varepsilon}\right)$, and a distribution-independent regret of
$O\left(\sqrt{kT\log T}+\frac{k\sqrt{\log\frac{1}{\delta}}\log
T}{\varepsilon}\right)$, where $T$ is the number of rounds, $\Delta_a$ is the
suboptimality gap of the arm $a$, and $k$ is the total number of arms. Our
upper bound almost matches the regret of the best known algorithms for the
centralized model, and significantly outperforms the best known algorithm in
the local model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete Auto-regressive Variational Attention Models for Text Modeling. (arXiv:2004.09764v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_X/0/1/0/all/0/1">Xianghong Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_H/0/1/0/all/0/1">Haoli Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zenglin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.09764">
                                    <div class="article-summary-box-inner">
                                        <span>Variational autoencoders (VAEs) have been widely applied for text modeling.
In practice, however, they are troubled by two challenges: information
underrepresentation and posterior collapse. The former arises as only the last
hidden state of LSTM encoder is transformed into the latent space, which is
generally insufficient to summarize the data. The latter is a long-standing
problem during the training of VAEs as the optimization is trapped to a
disastrous local optimum. In this paper, we propose Discrete Auto-regressive
Variational Attention Model (DAVAM) to address the challenges. Specifically, we
introduce an auto-regressive variational attention approach to enrich the
latent space by effectively capturing the semantic dependency from the input.
We further design discrete latent space for the variational attention and
mathematically show that our model is free from posterior collapse. Extensive
experiments on language modeling tasks demonstrate the superiority of DAVAM
against several VAE counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiscale Principle of Relevant Information for Hyperspectral Image Classification. (arXiv:1907.06022v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yantao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shujian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Giraldo_L/0/1/0/all/0/1">Luis Sanchez Giraldo</a>, <a href="http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1">Jose C. Principe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1907.06022">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a novel architecture, termed multiscale principle of
relevant information (MPRI), to learn discriminative spectral-spatial features
for hyperspectral image (HSI) classification. MPRI inherits the merits of the
principle of relevant information (PRI) to effectively extract multiscale
information embedded in the given data, and also takes advantage of the
multilayer structure to learn representations in a coarse-to-fine manner.
Specifically, MPRI performs spectral-spatial pixel characterization (using PRI)
and feature dimensionality reduction (using regularized linear discriminant
analysis) iteratively and successively. Extensive experiments on three
benchmark data sets demonstrate that MPRI outperforms existing state-of-the-art
methods (including deep learning based ones) qualitatively and quantitatively,
especially in the scenario of limited training samples. Code of MPRI is
available at \url{this http URL}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Abstractions of Neural Networks. (arXiv:2106.02997v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1">Atticus Geiger</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_H/0/1/0/all/0/1">Hanson Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Icard_T/0/1/0/all/0/1">Thomas Icard</a>, <a href="http://arxiv.org/find/cs/1/au:+Potts_C/0/1/0/all/0/1">Christopher Potts</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02997">
                                    <div class="article-summary-box-inner">
                                        <span>Structural analysis methods (e.g., probing and feature attribution) are
increasingly important tools for neural network analysis. We propose a new
structural analysis method grounded in a formal theory of \textit{causal
abstraction} that provides rich characterizations of model-internal
representations and their roles in input/output behavior. In this method,
neural representations are aligned with variables in interpretable causal
models, and then \textit{interchange interventions} are used to experimentally
verify that the neural representations have the causal properties of their
aligned variables. We apply this method in a case study to analyze neural
models trained on Multiply Quantified Natural Language Inference (MQNLI)
corpus, a highly complex NLI dataset that was constructed with a
tree-structured natural logic causal model. We discover that a BERT-based model
with state-of-the-art performance successfully realizes the approximate causal
structure of the natural logic causal model, whereas a simpler baseline model
fails to show any such structure, demonstrating that neural representations
encode the compositional structure of MQNLI examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Immediate Proximity Detection Using Wi-Fi-Enabled Smartphones. (arXiv:2106.02777v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hyfte_Z/0/1/0/all/0/1">Zach Van Hyfte</a>, <a href="http://arxiv.org/find/cs/1/au:+Zakhor_A/0/1/0/all/0/1">Avideh Zakhor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02777">
                                    <div class="article-summary-box-inner">
                                        <span>Smartphone apps for exposure notification and contact tracing have been shown
to be effective in controlling the COVID-19 pandemic. However, Bluetooth Low
Energy tokens similar to those broadcast by existing apps can still be picked
up far away from the transmitting device. In this paper, we present a new class
of methods for detecting whether or not two Wi-Fi-enabled devices are in
immediate physical proximity, i.e. 2 or fewer meters apart, as established by
the U.S. Centers for Disease Control and Prevention (CDC). Our goal is to
enhance the accuracy of smartphone-based exposure notification and contact
tracing systems. We present a set of binary machine learning classifiers that
take as input pairs of Wi-Fi RSSI fingerprints. We empirically verify that a
single classifier cannot generalize well to a range of different environments
with vastly different numbers of detectable Wi-Fi Access Points (APs). However,
specialized classifiers, tailored to situations where the number of detectable
APs falls within a certain range, are able to detect immediate physical
proximity significantly more accurately. As such, we design three classifiers
for situations with low, medium, and high numbers of detectable APs. These
classifiers distinguish between pairs of RSSI fingerprints recorded 2 or fewer
meters apart and pairs recorded further apart but still in Bluetooth range. We
characterize their balanced accuracy for this task to be between 66.8% and
77.8%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tetrad: Actively Secure 4PC for Secure Training and Inference. (arXiv:2106.02850v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koti_N/0/1/0/all/0/1">Nishat Koti</a>, <a href="http://arxiv.org/find/cs/1/au:+Patra_A/0/1/0/all/0/1">Arpita Patra</a>, <a href="http://arxiv.org/find/cs/1/au:+Rachuri_R/0/1/0/all/0/1">Rahul Rachuri</a>, <a href="http://arxiv.org/find/cs/1/au:+Suresh_A/0/1/0/all/0/1">Ajith Suresh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02850">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we design an efficient mixed-protocol framework, Tetrad, with
applications to privacy-preserving machine learning. It is designed for the
four-party setting with at most one active corruption and supports rings.

Our fair multiplication protocol requires communicating only 5 ring elements
improving over the state-of-the-art protocol of Trident (Chaudhari et al.
NDSS&#x27;20). The technical highlights of Tetrad include efficient (a) truncation
without any overhead, (b) multi-input multiplication protocols for arithmetic
and boolean worlds, (c) garbled-world, tailor-made for the mixed-protocol
framework, and (d) conversion mechanisms to switch between the computation
styles. The fair framework is also extended to provide robustness without
inflating the costs.

The competence of Tetrad is tested with benchmarks for deep neural networks
such as LeNet and VGG16 and support vector machines. One variant of our
framework aims at minimizing the execution time, while the other focuses on the
monetary cost. We observe improvements up to 6x over Trident across these
parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Time-Adaptive Drift-Diffusion Model. (arXiv:2106.02742v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cimolino_G/0/1/0/all/0/1">Gabriele Cimolino</a>, <a href="http://arxiv.org/find/cs/1/au:+Rivest_F/0/1/0/all/0/1">Francois Rivest</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02742">
                                    <div class="article-summary-box-inner">
                                        <span>Animals can quickly learn the timing of events with fixed intervals and their
rate of acquisition does not depend on the length of the interval. In contrast,
recurrent neural networks that use gradient based learning have difficulty
predicting the timing of events that depend on stimulus that occurred long ago.
We present the latent time-adaptive drift-diffusion model (LTDDM), an extension
to the time-adaptive drift-diffusion model (TDDM), a model for animal learning
of timing that exhibits behavioural properties consistent with experimental
data from animals. The performance of LTDDM is compared to that of a state of
the art long short-term memory (LSTM) recurrent neural network across three
timing tasks. Differences in the relative performance of these two models is
discussed and it is shown how LTDDM can learn these events time series orders
of magnitude faster than recurrent neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpikePropamine: Differentiable Plasticity in Spiking Neural Networks. (arXiv:2106.02681v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schmidgall_S/0/1/0/all/0/1">Samuel Schmidgall</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashkanazy_J/0/1/0/all/0/1">Julia Ashkanazy</a>, <a href="http://arxiv.org/find/cs/1/au:+Lawson_W/0/1/0/all/0/1">Wallace Lawson</a>, <a href="http://arxiv.org/find/cs/1/au:+Hays_J/0/1/0/all/0/1">Joe Hays</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02681">
                                    <div class="article-summary-box-inner">
                                        <span>The adaptive changes in synaptic efficacy that occur between spiking neurons
have been demonstrated to play a critical role in learning for biological
neural networks. Despite this source of inspiration, many learning focused
applications using Spiking Neural Networks (SNNs) retain static synaptic
connections, preventing additional learning after the initial training period.
Here, we introduce a framework for simultaneously learning the underlying
fixed-weights and the rules governing the dynamics of synaptic plasticity and
neuromodulated synaptic plasticity in SNNs through gradient descent. We further
demonstrate the capabilities of this framework on a series of challenging
benchmarks, learning the parameters of several plasticity rules including BCM,
Oja&#x27;s, and their respective set of neuromodulatory variants. The experimental
results display that SNNs augmented with differentiable plasticity are
sufficient for solving a set of challenging temporal learning tasks that a
traditional SNN fails to solve, even in the presence of significant noise.
These networks are also shown to be capable of producing locomotion on a
high-dimensional robotic learning task, where near-minimal degradation in
performance is observed in the presence of novel conditions not seen during the
initial training period.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning enables reference-free isotropic super-resolution for volumetric fluorescence microscopy. (arXiv:2104.09435v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hyoungjun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Na_M/0/1/0/all/0/1">Myeongsu Na</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1">Bumju Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Soohyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Ki Hean Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Sunghoe Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jong Chul Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09435">
                                    <div class="article-summary-box-inner">
                                        <span>Volumetric imaging by fluorescence microscopy is often limited by anisotropic
spatial resolution from inferior axial resolution compared to the lateral
resolution. To address this problem, here we present a deep-learning-enabled
unsupervised super-resolution technique that enhances anisotropic images in
volumetric fluorescence microscopy. In contrast to the existing deep learning
approaches that require matched high-resolution target volume images, our
method greatly reduces the effort to put into practice as the training of a
network requires as little as a single 3D image stack, without a priori
knowledge of the image formation process, registration of training data, or
separate acquisition of target data. This is achieved based on the optimal
transport driven cycle-consistent generative adversarial network that learns
from an unpaired matching between high-resolution 2D images in lateral image
plane and low-resolution 2D images in the other planes. Using fluorescence
confocal microscopy and light-sheet microscopy, we demonstrate that the trained
network not only enhances axial resolution, but also restores suppressed visual
details between the imaging planes and removes imaging artifacts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adapting Long Context NLM for ASR Rescoring in Conversational Agents. (arXiv:2104.11070v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shenoy_A/0/1/0/all/0/1">Ashish Shenoy</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodapati_S/0/1/0/all/0/1">Sravan Bodapati</a>, <a href="http://arxiv.org/find/cs/1/au:+Sunkara_M/0/1/0/all/0/1">Monica Sunkara</a>, <a href="http://arxiv.org/find/cs/1/au:+Ronanki_S/0/1/0/all/0/1">Srikanth Ronanki</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirchhoff_K/0/1/0/all/0/1">Katrin Kirchhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11070">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Language Models (NLM), when trained and evaluated with context
spanning multiple utterances, have been shown to consistently outperform both
conventional n-gram language models and NLMs that use limited context. In this
paper, we investigate various techniques to incorporate turn based context
history into both recurrent (LSTM) and Transformer-XL based NLMs. For recurrent
based NLMs, we explore context carry over mechanism and feature based
augmentation, where we incorporate other forms of contextual information such
as bot response and system dialogue acts as classified by a Natural Language
Understanding (NLU) model. To mitigate the sharp nearby, fuzzy far away problem
with contextual NLM, we propose the use of attention layer over lexical
metadata to improve feature based augmentation. Additionally, we adapt our
contextual NLM towards user provided on-the-fly speech patterns by leveraging
encodings from a large pre-trained masked language model and performing fusion
with a Transformer-XL based NLM. We test our proposed models using N-best
rescoring of ASR hypotheses of task-oriented dialogues and also evaluate on
downstream NLU tasks such as intent classification and slot labeling. The best
performing model shows a relative WER between 1.6% and 9.1% and a slot labeling
F1 score improvement of 4% over non-contextual baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Technologies for Trustworthy Machine Learning: A Survey in a Socio-Technical Context. (arXiv:2007.08911v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Toreini_E/0/1/0/all/0/1">Ehsan Toreini</a>, <a href="http://arxiv.org/find/cs/1/au:+Aitken_M/0/1/0/all/0/1">Mhairi Aitken</a>, <a href="http://arxiv.org/find/cs/1/au:+Coopamootoo_K/0/1/0/all/0/1">Kovila P. L. Coopamootoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Elliott_K/0/1/0/all/0/1">Karen Elliott</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelaya_V/0/1/0/all/0/1">Vladimiro Gonzalez Zelaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Missier_P/0/1/0/all/0/1">Paolo Missier</a>, <a href="http://arxiv.org/find/cs/1/au:+Ng_M/0/1/0/all/0/1">Magdalene Ng</a>, <a href="http://arxiv.org/find/cs/1/au:+Moorsel_A/0/1/0/all/0/1">Aad van Moorsel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.08911">
                                    <div class="article-summary-box-inner">
                                        <span>Concerns about the societal impact of AI-based services and systems has
encouraged governments and other organisations around the world to propose AI
policy frameworks to address fairness, accountability, transparency and related
topics. To achieve the objectives of these frameworks, the data and software
engineers who build machine-learning systems require knowledge about a variety
of relevant supporting tools and techniques. In this paper we provide an
overview of technologies that support building trustworthy machine learning
systems, i.e., systems whose properties justify that people place trust in
them. We argue that four categories of system properties are instrumental in
achieving the policy objectives, namely fairness, explainability, auditability
and safety &amp; security (FEAS). We discuss how these properties need to be
considered across all stages of the machine learning life cycle, from data
collection through run-time model inference. As a consequence, we survey in
this paper the main technologies with respect to all four of the FEAS
properties, for data-centric as well as model-centric stages of the machine
learning system life cycle. We conclude with an identification of open research
problems, with a particular focus on the connection between trustworthy machine
learning technologies and their implications for individuals and society.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Birds of a Feather Flock Together: A Close Look at Cooperation Emergence via Multi-Agent RL. (arXiv:2104.11455v2 [cs.MA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_H/0/1/0/all/0/1">Heng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tonghan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiayuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chongjie Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11455">
                                    <div class="article-summary-box-inner">
                                        <span>How cooperation emerges is a long-standing and interdisciplinary problem.
Game-theoretical studies on social dilemmas reveal that altruistic incentives
are critical to the emergence of cooperation but their analyses are limited to
stateless games. For more realistic scenarios, multi-agent reinforcement
learning has been used to study sequential social dilemmas (SSDs). Recent works
show that learning to incentivize other agents can promote cooperation in SSDs.
However, we find that, with these incentivizing mechanisms, the team
cooperation level does not converge and regularly oscillates between
cooperation and defection during learning. We show that a second-order social
dilemma resulting from the incentive mechanisms is the main reason for such
fragile cooperation. We formally analyze the dynamics of second-order social
dilemmas and find that a typical tendency of humans, called homophily, provides
a promising solution. We propose a novel learning framework to encourage
homophilic incentives and show that it achieves stable cooperation in both SSDs
of public goods and tragedy of the commons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral Geometric Matrix Completion. (arXiv:1911.07255v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boyarski_A/0/1/0/all/0/1">Amit Boyarski</a>, <a href="http://arxiv.org/find/cs/1/au:+Vedula_S/0/1/0/all/0/1">Sanketh Vedula</a>, <a href="http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1">Alex Bronstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.07255">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Matrix Factorization (DMF) is an emerging approach to the problem of
matrix completion. Recent works have established that gradient descent applied
to a DMF model induces an implicit regularization on the rank of the recovered
matrix. In this work we interpret the DMF model through the lens of spectral
geometry. This allows us to incorporate explicit regularization without
breaking the DMF structure, thus enjoying the best of both worlds. In
particular, we focus on matrix completion problems with underlying geometric or
topological relations between the rows and/or columns. Such relations are
prevalent in matrix completion problems that arise in many applications, such
as recommender systems and drug-target interaction. Our contributions enable
DMF models to exploit these relations, and make them competitive on real
benchmarks, while exhibiting one of the first successful applications of deep
linear networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heuristic-Guided Reinforcement Learning. (arXiv:2106.02757v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1">Ching-An Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1">Andrey Kolobov</a>, <a href="http://arxiv.org/find/cs/1/au:+Swaminathan_A/0/1/0/all/0/1">Adith Swaminathan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02757">
                                    <div class="article-summary-box-inner">
                                        <span>We provide a framework for accelerating reinforcement learning (RL)
algorithms by heuristics constructed from domain knowledge or offline data.
Tabula rasa RL algorithms require environment interactions or computation that
scales with the horizon of the sequential decision-making task. Using our
framework, we show how heuristic-guided RL induces a much shorter-horizon
subproblem that provably solves the original task. Our framework can be viewed
as a horizon-based regularization for controlling bias and variance in RL under
a finite interaction budget. On the theoretical side, we characterize
properties of a good heuristic and its impact on RL acceleration. In
particular, we introduce the novel concept of an &quot;improvable heuristic&quot; -- a
heuristic that allows an RL agent to extrapolate beyond its prior knowledge. On
the empirical side, we instantiate our framework to accelerate several
state-of-the-art algorithms in simulated robotic control tasks and procedurally
generated games. Our framework complements the rich literature on warm-starting
RL with expert demonstrations or exploratory datasets, and introduces a
principled method for injecting prior knowledge into RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-end learnable EEG channel selection for deep neural networks with Gumbel-softmax. (arXiv:2102.09050v3 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Strypsteen_T/0/1/0/all/0/1">Thomas Strypsteen</a>, <a href="http://arxiv.org/find/eess/1/au:+Bertrand_A/0/1/0/all/0/1">Alexander Bertrand</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09050">
                                    <div class="article-summary-box-inner">
                                        <span>Many electroencephalography (EEG) applications rely on channel selection
methods to remove the least informative channels, e.g., to reduce the amount of
electrodes to be mounted, to decrease the computational load, or to reduce
overfitting effects and improve performance. Wrapper-based channel selection
methods aim to match the channel selection step to the target model, yet they
require to re-train the model multiple times on different candidate channel
subsets, which often leads to an unacceptably high computational cost,
especially when said model is a (deep) neural network. To alleviate this, we
propose a framework to embed the EEG channel selection in the neural network
itself to jointly learn the network weights and optimal channels in an
end-to-end manner by traditional backpropagation algorithms. We deal with the
discrete nature of this new optimization problem by employing continuous
relaxations of the discrete channel selection parameters based on the
Gumbel-softmax trick. We also propose a regularization method that discourages
selecting channels more than once. This generic approach is evaluated on two
different EEG tasks: motor imagery brain-computer interfaces and auditory
attention decoding. The results demonstrate that our framework is generally
applicable, while being competitive with state-of-the art EEG channel selection
methods, tailored to these tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training Robust Graph Neural Networks with Topology Adaptive Edge Dropping. (arXiv:2106.02892v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Zhan Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhattacharya_S/0/1/0/all/0/1">Subhrajit Bhattacharya</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Leiming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Blum_R/0/1/0/all/0/1">Rick S. Blum</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1">Alejandro Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadler_B/0/1/0/all/0/1">Brian M. Sadler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02892">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) are processing architectures that exploit graph
structural information to model representations from network data. Despite
their success, GNNs suffer from sub-optimal generalization performance given
limited training data, referred to as over-fitting. This paper proposes
Topology Adaptive Edge Dropping (TADropEdge) method as an adaptive data
augmentation technique to improve generalization performance and learn robust
GNN models. We start by explicitly analyzing how random edge dropping increases
the data diversity during training, while indicating i.i.d. edge dropping does
not account for graph structural information and could result in noisy
augmented data degrading performance. To overcome this issue, we consider graph
connectivity as the key property that captures graph topology. TADropEdge
incorporates this factor into random edge dropping such that the edge-dropped
subgraphs maintain similar topology as the underlying graph, yielding more
satisfactory data augmentation. In particular, TADropEdge first leverages the
graph spectrum to assign proper weights to graph edges, which represent their
criticality for establishing the graph connectivity. It then normalizes the
edge weights and drops graph edges adaptively based on their normalized
weights. Besides improving generalization performance, TADropEdge reduces
variance for efficient training and can be applied as a generic method modular
to different GNN models. Intensive experiments on real-life and synthetic
datasets corroborate theory and verify the effectiveness of the proposed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Latent Space Tuning for Non-Stationary Distributions. (arXiv:2105.03584v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Scheinker_A/0/1/0/all/0/1">Alexander Scheinker</a>, <a href="http://arxiv.org/find/stat/1/au:+Cropp_F/0/1/0/all/0/1">Frederick Cropp</a>, <a href="http://arxiv.org/find/stat/1/au:+Paiagua_S/0/1/0/all/0/1">Sergio Paiagua</a>, <a href="http://arxiv.org/find/stat/1/au:+Filippetto_D/0/1/0/all/0/1">Daniele Filippetto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03584">
                                    <div class="article-summary-box-inner">
                                        <span>Powerful deep learning tools, such as convolutional neural networks (CNN),
are able to learn the input-output relationships of large complicated systems
directly from data. Encoder-decoder deep CNNs are able to extract features
directly from images, mix them with scalar inputs within a general
low-dimensional latent space, and then generate new complex 2D outputs which
represent complex physical phenomenon. One important challenge faced by deep
learning methods is large non-stationary systems whose characteristics change
quickly with time for which re-training is not feasible. In this paper we
present a method for adaptive tuning of the low-dimensional latent space of
deep encoder-decoder style CNNs based on real-time feedback to quickly
compensate for unknown and fast distribution shifts. We demonstrate our
approach for predicting the properties of a time-varying charged particle beam
in a particle accelerator whose components (accelerating electric fields and
focusing magnetic fields) are also quickly changing with time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Attentive Sequential Learning for Cross-Domain Click-Through Rate Prediction. (arXiv:2106.02768v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Pan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhichao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Que_M/0/1/0/all/0/1">Maofei Que</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yao Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tuzhilin_A/0/1/0/all/0/1">Alexander Tuzhilin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02768">
                                    <div class="article-summary-box-inner">
                                        <span>Cross domain recommender system constitutes a powerful method to tackle the
cold-start and sparsity problem by aggregating and transferring user
preferences across multiple category domains. Therefore, it has great potential
to improve click-through-rate prediction performance in online commerce
platforms having many domains of products. While several cross domain
sequential recommendation models have been proposed to leverage information
from a source domain to improve CTR predictions in a target domain, they did
not take into account bidirectional latent relations of user preferences across
source-target domain pairs. As such, they cannot provide enhanced cross-domain
CTR predictions for both domains simultaneously. In this paper, we propose a
novel approach to cross-domain sequential recommendations based on the dual
learning mechanism that simultaneously transfers information between two
related domains in an iterative manner until the learning process stabilizes.
In particular, the proposed Dual Attentive Sequential Learning (DASL) model
consists of two novel components Dual Embedding and Dual Attention, which
jointly establish the two-stage learning process: we first construct dual
latent embeddings that extract user preferences in both domains simultaneously,
and subsequently provide cross-domain recommendations by matching the extracted
latent embeddings with candidate items through dual-attention learning
mechanism. We conduct extensive offline experiments on three real-world
datasets to demonstrate the superiority of our proposed model, which
significantly and consistently outperforms several state-of-the-art baselines
across all experimental settings. We also conduct an online A/B test at a major
video streaming platform Alibaba-Youku, where our proposed model significantly
improves business performance over the latest production system in the company.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Disentanglement in Variational Auto-Encoders Using Jacobian $L_1$ Regularization. (arXiv:2106.02923v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rhodes_T/0/1/0/all/0/1">Travers Rhodes</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1">Daniel D. Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02923">
                                    <div class="article-summary-box-inner">
                                        <span>There have been many recent advances in representation learning; however,
unsupervised representation learning can still struggle with model
identification issues. Variational Auto-Encoders (VAEs) and their extensions
such as $\beta$-VAEs have been shown to locally align latent variables with PCA
directions, which can help to improve model disentanglement under some
conditions. Borrowing inspiration from Independent Component Analysis (ICA) and
sparse coding, we propose applying an $L_1$ loss to the VAE&#x27;s generative
Jacobian during training to encourage local latent variable alignment with
independent factors of variation in the data. We demonstrate our results on a
variety of datasets, giving qualitative and quantitative results using
information theoretic and modularity measures that show our added $L_1$ cost
encourages local axis alignment of the latent representation with individual
factors of variation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Temperature Imaging Using Pseudo-Inversed Convolutional Neural Network Aided TDLAS Tomography. (arXiv:2106.02901v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Si_J/0/1/0/all/0/1">Jingjing Si</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_G/0/1/0/all/0/1">Guoliang Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheng_Y/0/1/0/all/0/1">Yinbo Cheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Enemali_G/0/1/0/all/0/1">Godwin Enemali</a>, <a href="http://arxiv.org/find/eess/1/au:+Liu_C/0/1/0/all/0/1">Chang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02901">
                                    <div class="article-summary-box-inner">
                                        <span>As an in situ combustion diagnostic tool, Tunable Diode Laser Absorption
Spectroscopy (TDLAS) tomography has been widely used for imaging of
two-dimensional temperature distributions in reactive flows. Compared with the
computational tomographic algorithms, Convolutional Neural Networks (CNNs) have
been proofed to be more robust and accurate for image reconstruction,
particularly in case of limited access of laser beams in the Region of Interest
(RoI). In practice, flame in the RoI that requires to be reconstructed with
good spatial resolution is commonly surrounded by low-temperature background.
Although the background is not of high interest, spectroscopic absorption still
exists due to heat dissipation and gas convection. Therefore, we propose a
Pseudo-Inversed CNN (PI-CNN) for hierarchical temperature imaging that (a) uses
efficiently the training and learning resources for temperature imaging in the
RoI with good spatial resolution, and (b) reconstructs the less spatially
resolved background temperature by adequately addressing the integrity of the
spectroscopic absorption model. In comparison with the traditional CNN, the
newly introduced pseudo inversion of the RoI sensitivity matrix is more
penetrating for revealing the inherent correlation between the projection data
and the RoI to be reconstructed, thus prioritising the temperature imaging in
the RoI with high accuracy and high computational efficiency. In this paper,
the proposed algorithm was validated by both numerical simulation and lab-scale
experiment, indicating good agreement between the phantoms and the
high-fidelity reconstructions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A novel multi-scale loss function for classification problems in machine learning. (arXiv:2106.02676v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Berlyand_L/0/1/0/all/0/1">Leonid Berlyand</a>, <a href="http://arxiv.org/find/math/1/au:+Creese_R/0/1/0/all/0/1">Robert Creese</a>, <a href="http://arxiv.org/find/math/1/au:+Jabin_P/0/1/0/all/0/1">Pierre-Emmanuel Jabin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02676">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce two-scale loss functions for use in various gradient descent
algorithms applied to classification problems via deep neural networks. This
new method is generic in the sense that it can be applied to a wide range of
machine learning architectures, from deep neural networks to support vector
machines for example. These two-scale loss functions allow to focus the
training onto objects in the training set which are not well classified. This
leads to an increase in several measures of performance for
appropriately-defined two-scale loss functions with respect to the more
classical cross-entropy when tested on traditional deep neural networks on the
MNIST, CIFAR10, and CIFAR100 data-sets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Kernel approximation on algebraic varieties. (arXiv:2106.02755v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Altschuler_J/0/1/0/all/0/1">Jason M. Altschuler</a>, <a href="http://arxiv.org/find/cs/1/au:+Parrilo_P/0/1/0/all/0/1">Pablo A. Parrilo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02755">
                                    <div class="article-summary-box-inner">
                                        <span>Low-rank approximation of kernels is a fundamental mathematical problem with
widespread algorithmic applications. Often the kernel is restricted to an
algebraic variety, e.g., in problems involving sparse or low-rank data. We show
that significantly better approximations are obtainable in this setting: the
rank required to achieve a given error depends on the variety&#x27;s dimension
rather than the ambient dimension, which is typically much larger. This is true
in both high-precision and high-dimensional regimes. Our results are presented
for smooth isotropic kernels, the predominant class of kernels used in
applications. Our main technical insight is to approximate smooth kernels by
polynomial kernels, and leverage two key properties of polynomial kernels that
hold when they are restricted to a variety. First, their ranks decrease
exponentially in the variety&#x27;s co-dimension. Second, their maximum values are
governed by their values over a small set of points. Together, our results
provide a general approach for exploiting (approximate) &quot;algebraic structure&quot;
in datasets in order to efficiently solve large-scale data science problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Neural Networks using a Single Neuron: Folded-in-Time Architecture using Feedback-Modulated Delay Loops. (arXiv:2011.10115v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stelzer_F/0/1/0/all/0/1">Florian Stelzer</a> (1, 2 and 4), <a href="http://arxiv.org/find/cs/1/au:+Rohm_A/0/1/0/all/0/1">Andr&#xe9; R&#xf6;hm</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Vicente_R/0/1/0/all/0/1">Raul Vicente</a> (4), <a href="http://arxiv.org/find/cs/1/au:+Fischer_I/0/1/0/all/0/1">Ingo Fischer</a> (3), <a href="http://arxiv.org/find/cs/1/au:+Yanchuk_S/0/1/0/all/0/1">Serhiy Yanchuk</a> (1) ((1) Institute of Mathematics, Technische Universit&#xe4;t Berlin, Germany, (2) Department of Mathematics, Humboldt-Universit&#xe4;t zu Berlin, Germany, (3) Instituto de F&#xed;sica Interdisciplinar y Sistemas Complejos, IFISC (UIB-CSIC), Spain, (4) Institute of Computer Science, University of Tartu, Estonia)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10115">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks are among the most widely applied machine learning tools
showing outstanding performance in a broad range of tasks. We present a method
for folding a deep neural network of arbitrary size into a single neuron with
multiple time-delayed feedback loops. This single-neuron deep neural network
comprises only a single nonlinearity and appropriately adjusted modulations of
the feedback signals. The network states emerge in time as a temporal unfolding
of the neuron&#x27;s dynamics. By adjusting the feedback-modulation within the
loops, we adapt the network&#x27;s connection weights. These connection weights are
determined via a back-propagation algorithm, where both the delay-induced and
local network connections must be taken into account. Our approach can fully
represent standard Deep Neural Networks (DNN), encompasses sparse DNNs, and
extends the DNN concept toward dynamical systems implementations. The new
method, which we call Folded-in-time DNN (Fit-DNN), exhibits promising
performance in a set of benchmark tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Subnetwork Structure be the Key to Out-of-Distribution Generalization?. (arXiv:2106.02890v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1">Dinghuai Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1">Kartik Ahuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yilun Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yisen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1">Aaron Courville</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02890">
                                    <div class="article-summary-box-inner">
                                        <span>Can models with particular structure avoid being biased towards spurious
correlation in out-of-distribution (OOD) generalization? Peters et al. (2016)
provides a positive answer for linear cases. In this paper, we use a functional
modular probing method to analyze deep model structures under OOD setting. We
demonstrate that even in biased models (which focus on spurious correlation)
there still exist unbiased functional subnetworks. Furthermore, we articulate
and demonstrate the functional lottery ticket hypothesis: full network contains
a subnetwork that can achieve better OOD performance. We then propose Modular
Risk Minimization to solve the subnetwork selection problem. Our algorithm
learns the subnetwork structure from a given dataset, and can be combined with
any other OOD regularization methods. Experiments on various OOD generalization
tasks corroborate the effectiveness of our method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ensemble Defense with Data Diversity: Weak Correlation Implies Strong Robustness. (arXiv:2106.02867v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Renjue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hanwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1">Pengfei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Cheng-Chao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1">Aimin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1">Bai Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lijun Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02867">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a framework of filter-based ensemble of deep
neuralnetworks (DNNs) to defend against adversarial attacks. The framework
builds an ensemble of sub-models -- DNNs with differentiated preprocessing
filters. From the theoretical perspective of DNN robustness, we argue that
under the assumption of high quality of the filters, the weaker the
correlations of the sensitivity of the filters are, the more robust the
ensemble model tends to be, and this is corroborated by the experiments of
transfer-based attacks. Correspondingly, we propose a principle that chooses
the specific filters with smaller Pearson correlation coefficients, which
ensures the diversity of the inputs received by DNNs, as well as the
effectiveness of the entire framework against attacks. Our ensemble models are
more robust than those constructed by previous defense methods like adversarial
training, and even competitive with the classical ensemble of adversarial
trained DNNs under adversarial attacks when the attacking radius is large.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Q-Learning in Zero-sum Markov Games. (arXiv:2106.02748v1 [cs.GT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sayin_M/0/1/0/all/0/1">Muhammed O. Sayin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaiqing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Leslie_D/0/1/0/all/0/1">David S. Leslie</a>, <a href="http://arxiv.org/find/cs/1/au:+Basar_T/0/1/0/all/0/1">Tamer Basar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozdaglar_A/0/1/0/all/0/1">Asuman Ozdaglar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02748">
                                    <div class="article-summary-box-inner">
                                        <span>We study multi-agent reinforcement learning (MARL) in infinite-horizon
discounted zero-sum Markov games. We focus on the practical but challenging
setting of decentralized MARL, where agents make decisions without coordination
by a centralized controller, but only based on their own payoffs and local
actions executed. The agents need not observe the opponent&#x27;s actions or
payoffs, possibly being even oblivious to the presence of the opponent, nor be
aware of the zero-sum structure of the underlying game, a setting also referred
to as radically uncoupled in the literature of learning in games. In this
paper, we develop for the first time a radically uncoupled Q-learning dynamics
that is both rational and convergent: the learning dynamics converges to the
best response to the opponent&#x27;s strategy when the opponent follows an
asymptotically stationary strategy; the value function estimates converge to
the payoffs at a Nash equilibrium when both agents adopt the dynamics. The key
challenge in this decentralized setting is the non-stationarity of the learning
environment from an agent&#x27;s perspective, since both her own payoffs and the
system evolution depend on the actions of other agents, and each agent adapts
their policies simultaneously and independently. To address this issue, we
develop a two-timescale learning dynamics where each agent updates her local
Q-function and value function estimates concurrently, with the latter happening
at a slower timescale.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Lottery Ticket Hypothesis for Graph Neural Networks. (arXiv:2102.06790v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tianlong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sui_Y/0/1/0/all/0/1">Yongduo Sui</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuxi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1">Aston Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhangyang Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.06790">
                                    <div class="article-summary-box-inner">
                                        <span>With graphs rapidly growing in size and deeper graph neural networks (GNNs)
emerging, the training and inference of GNNs become increasingly expensive.
Existing network weight pruning algorithms cannot address the main space and
computational bottleneck in GNNs, caused by the size and connectivity of the
graph. To this end, this paper first presents a unified GNN sparsification
(UGS) framework that simultaneously prunes the graph adjacency matrix and the
model weights, for effectively accelerating GNN inference on large-scale
graphs. Leveraging this new tool, we further generalize the recently popular
lottery ticket hypothesis to GNNs for the first time, by defining a graph
lottery ticket (GLT) as a pair of core sub-dataset and sparse sub-network,
which can be jointly identified from the original GNN and the full dense graph
by iteratively applying UGS. Like its counterpart in convolutional neural
networks, GLT can be trained in isolation to match the performance of training
with the full model and graph, and can be drawn from both randomly initialized
and self-supervised pre-trained GNNs. Our proposal has been experimentally
verified across various GNN architectures and diverse tasks, on both
small-scale graph datasets (Cora, Citeseer and PubMed), and large-scale
datasets from the challenging Open Graph Benchmark (OGB). Specifically, for
node classification, our found GLTs achieve the same accuracies with 20%~98%
MACs saving on small graphs and 25%~85% MACs saving on large ones. For link
prediction, GLTs lead to 48%~97% and 70% MACs saving on small and large graph
datasets, respectively, without compromising predictive performance. Codes
available at https://github.com/VITA-Group/Unified-LTH-GNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principle Bit Analysis: Autoencoding with Schur-Concave Loss. (arXiv:2106.02796v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhadane_S/0/1/0/all/0/1">Sourbh Bhadane</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_A/0/1/0/all/0/1">Aaron B. Wagner</a>, <a href="http://arxiv.org/find/cs/1/au:+Acharya_J/0/1/0/all/0/1">Jayadev Acharya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02796">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a linear autoencoder in which the latent variables are quantized,
or corrupted by noise, and the constraint is Schur-concave in the set of latent
variances. Although finding the optimal encoder/decoder pair for this setup is
a nonconvex optimization problem, we show that decomposing the source into its
principal components is optimal. If the constraint is strictly Schur-concave
and the empirical covariance matrix has only simple eigenvalues, then any
optimal encoder/decoder must decompose the source in this way. As one
application, we consider a strictly Schur-concave constraint that estimates the
number of bits needed to represent the latent variables under fixed-rate
encoding, a setup that we call \emph{Principal Bit Analysis (PBA)}. This yields
a practical, general-purpose, fixed-rate compressor that outperforms existing
algorithms. As a second application, we show that a prototypical
autoencoder-based variable-rate compressor is guaranteed to decompose the
source into its principal components.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpreadGNN: Serverless Multi-task Federated Learning for Graph Neural Networks. (arXiv:2106.02743v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_C/0/1/0/all/0/1">Chaoyang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Ceyani_E/0/1/0/all/0/1">Emir Ceyani</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_K/0/1/0/all/0/1">Keshav Balasubramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Annavaram_M/0/1/0/all/0/1">Murali Annavaram</a>, <a href="http://arxiv.org/find/cs/1/au:+Avestimehr_S/0/1/0/all/0/1">Salman Avestimehr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02743">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) are the first choice methods for graph machine
learning problems thanks to their ability to learn state-of-the-art level
representations from graph-structured data. However, centralizing a massive
amount of real-world graph data for GNN training is prohibitive due to
user-side privacy concerns, regulation restrictions, and commercial
competition. Federated Learning is the de-facto standard for collaborative
training of machine learning models over many distributed edge devices without
the need for centralization. Nevertheless, training graph neural networks in a
federated setting is vaguely defined and brings statistical and systems
challenges. This work proposes SpreadGNN, a novel multi-task federated training
framework capable of operating in the presence of partial labels and absence of
a central server for the first time in the literature. SpreadGNN extends
federated multi-task learning to realistic serverless settings for GNNs, and
utilizes a novel optimization algorithm with a convergence guarantee,
Decentralized Periodic Averaging SGD (DPA-SGD), to solve decentralized
multi-task learning problems. We empirically demonstrate the efficacy of our
framework on a variety of non-I.I.D. distributed graph-level molecular property
prediction datasets with partial labels. Our results show that SpreadGNN
outperforms GNN models trained over a central server-dependent federated
learning system, even in constrained topologies. The source code is publicly
available at https://github.com/FedML-AI/SpreadGNN</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">No MCMC for me: Amortized sampling for fast and stable training of energy-based models. (arXiv:2010.04230v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Grathwohl_W/0/1/0/all/0/1">Will Grathwohl</a>, <a href="http://arxiv.org/find/cs/1/au:+Kelly_J/0/1/0/all/0/1">Jacob Kelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1">Milad Hashemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1">Mohammad Norouzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1">Kevin Swersky</a>, <a href="http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1">David Duvenaud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04230">
                                    <div class="article-summary-box-inner">
                                        <span>Energy-Based Models (EBMs) present a flexible and appealing way to represent
uncertainty. Despite recent advances, training EBMs on high-dimensional data
remains a challenging problem as the state-of-the-art approaches are costly,
unstable, and require considerable tuning and domain expertise to apply
successfully. In this work, we present a simple method for training EBMs at
scale which uses an entropy-regularized generator to amortize the MCMC sampling
typically used in EBM training. We improve upon prior MCMC-based entropy
regularization methods with a fast variational approximation. We demonstrate
the effectiveness of our approach by using it to train tractable likelihood
models. Next, we apply our estimator to the recently proposed Joint Energy
Model (JEM), where we match the original performance with faster and stable
training. This allows us to extend JEM models to semi-supervised classification
on tabular data from a variety of continuous domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Network Estimation by Mixing: Adaptivity and More. (arXiv:2106.02803v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Li_T/0/1/0/all/0/1">Tianxi Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Le_C/0/1/0/all/0/1">Can M. Le</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02803">
                                    <div class="article-summary-box-inner">
                                        <span>Networks analysis has been commonly used to study the interactions between
units of complex systems. One problem of particular interest is learning the
network&#x27;s underlying connection pattern given a single and noisy instantiation.
While many methods have been proposed to address this problem in recent years,
they usually assume that the true model belongs to a known class, which is not
verifiable in most real-world applications. Consequently, network modeling
based on these methods either suffers from model misspecification or relies on
additional model selection procedures that are not well understood in theory
and can potentially be unstable in practice. To address this difficulty, we
propose a mixing strategy that leverages available arbitrary models to improve
their individual performances. The proposed method is computationally efficient
and almost tuning-free; thus, it can be used as an off-the-shelf method for
network modeling. We show that the proposed method performs equally well as the
oracle estimate when the true model is included as individual candidates. More
importantly, the method remains robust and outperforms all current estimates
even when the models are misspecified. Extensive simulation examples are used
to verify the advantage of the proposed mixing method. Evaluation of link
prediction performance on 385 real-world networks from six domains also
demonstrates the universal competitiveness of the mixing method across multiple
domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Increasing Depth Leads to U-Shaped Test Risk in Over-parameterized Convolutional Networks. (arXiv:2010.09610v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nichani_E/0/1/0/all/0/1">Eshaan Nichani</a>, <a href="http://arxiv.org/find/cs/1/au:+Radhakrishnan_A/0/1/0/all/0/1">Adityanarayanan Radhakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Uhler_C/0/1/0/all/0/1">Caroline Uhler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09610">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have demonstrated that increasing model capacity through width
in over-parameterized neural networks leads to a decrease in test risk. For
neural networks, however, model capacity can also be increased through depth,
yet understanding the impact of increasing depth on test risk remains an open
question. In this work, we demonstrate that the test risk of over-parameterized
convolutional networks is a U-shaped curve (i.e. monotonically decreasing, then
increasing) with increasing depth. We first provide empirical evidence for this
phenomenon via image classification experiments using both ResNets and the
convolutional neural tangent kernel (CNTK). We then present a novel linear
regression framework for characterizing the impact of depth on test risk, and
show that increasing depth leads to a U-shaped test risk for the linear CNTK.
In particular, we prove that the linear CNTK corresponds to a depth-dependent
linear transformation on the original space and characterize properties of this
transformation. We then analyze over-parameterized linear regression under
arbitrary linear transformations and, in simplified settings, provably identify
the depths which minimize each of the bias and variance terms of the test risk.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Patch Slimming for Efficient Vision Transformers. (arXiv:2106.02852v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yehui Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_K/0/1/0/all/0/1">Kai Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunhe Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1">Jianyuan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02852">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the efficiency problem for visual transformers by
excavating redundant calculation in given networks. The recent transformer
architecture has demonstrated its effectiveness for achieving excellent
performance on a series of computer vision tasks. However, similar to that of
convolutional neural networks, the huge computational cost of vision
transformers is still a severe issue. Considering that the attention mechanism
aggregates different patches layer-by-layer, we present a novel patch slimming
approach that discards useless patches in a top-down paradigm. We first
identify the effective patches in the last layer and then use them to guide the
patch selection process of previous layers. For each layer, the impact of a
patch on the final output feature is approximated and patches with less impact
will be removed. Experimental results on benchmark datasets demonstrate that
the proposed method can significantly reduce the computational costs of vision
transformers without affecting their performances. For example, over 45% FLOPs
of the ViT-Ti model can be reduced with only 0.2% top-1 accuracy drop on the
ImageNet dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Variational Perspective on Diffusion-Based Generative Models and Score Matching. (arXiv:2106.02808v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1">Chin-Wei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1">Jae Hyun Lim</a>, <a href="http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1">Aaron Courville</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02808">
                                    <div class="article-summary-box-inner">
                                        <span>Discrete-time diffusion-based generative models and score matching methods
have shown promising results in modeling high-dimensional image data. Recently,
Song et al. (2021) show that diffusion processes that transform data into noise
can be reversed via learning the score function, i.e. the gradient of the
log-density of the perturbed data. They propose to plug the learned score
function into an inverse formula to define a generative diffusion process.
Despite the empirical success, a theoretical underpinning of this procedure is
still lacking. In this work, we approach the (continuous-time) generative
diffusion directly and derive a variational framework for likelihood
estimation, which includes continuous-time normalizing flows as a special case,
and can be seen as an infinitely deep variational autoencoder. Under this
framework, we show that minimizing the score-matching loss is equivalent to
maximizing a lower bound of the likelihood of the plug-in reverse SDE proposed
by Song et al. (2021), bridging the theoretical gap.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Even More Optimal Stochastic Optimization Algorithm: Minibatching and Interpolation Learning. (arXiv:2106.02720v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Woodworth_B/0/1/0/all/0/1">Blake Woodworth</a>, <a href="http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1">Nathan Srebro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02720">
                                    <div class="article-summary-box-inner">
                                        <span>We present and analyze an algorithm for optimizing smooth and convex or
strongly convex objectives using minibatch stochastic gradient estimates. The
algorithm is optimal with respect to its dependence on both the minibatch size
and minimum expected loss simultaneously. This improves over the optimal method
of Lan (2012), which is insensitive to the minimum expected loss; over the
optimistic acceleration of Cotter et al. (2011), which has suboptimal
dependence on the minibatch size; and over the algorithm of Liu and Belkin
(2018), which is limited to least squares problems and is also similarly
suboptimal with respect to the minibatch size. Applied to interpolation
learning, the improvement over Cotter et al. and Liu and Belkin translates to a
linear, rather than square-root, parallelization speedup.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Coarse-to-Fine Entity Representations for Document-level Relation Extraction. (arXiv:2012.02507v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1">Damai Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1">Jing Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1">Shuang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1">Baobao Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sui_Z/0/1/0/all/0/1">Zhifang Sui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.02507">
                                    <div class="article-summary-box-inner">
                                        <span>Document-level Relation Extraction (RE) requires extracting relations
expressed within and across sentences. Recent works show that graph-based
methods, usually constructing a document-level graph that captures
document-aware interactions, can obtain useful entity representations thus
helping tackle document-level RE. These methods either focus more on the entire
graph, or pay more attention to a part of the graph, e.g., paths between the
target entity pair. However, we find that document-level RE may benefit from
focusing on both of them simultaneously. Therefore, to obtain more
comprehensive entity representations, we propose the Coarse-to-Fine Entity
Representation model (CFER) that adopts a coarse-to-fine strategy involving two
phases. First, CFER uses graph neural networks to integrate global information
in the entire graph at a coarse level. Next, CFER utilizes the global
information as a guidance to selectively aggregate path information between the
target entity pair at a fine level. In classification, we combine the entity
representations from both two levels into more comprehensive representations
for relation extraction. Experimental results on two document-level RE
datasets, DocRED and CDR, show that CFER outperforms existing models and is
robust to the uneven label distribution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pinball-OCSVM for early-stage COVID-19 diagnosis with limited posteroanterior chest X-ray images. (arXiv:2010.08115v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sonbhadra_S/0/1/0/all/0/1">Sanjay Kumar Sonbhadra</a>, <a href="http://arxiv.org/find/eess/1/au:+Agarwal_S/0/1/0/all/0/1">Sonali Agarwal</a>, <a href="http://arxiv.org/find/eess/1/au:+Nagabhushan_P/0/1/0/all/0/1">P. Nagabhushan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.08115">
                                    <div class="article-summary-box-inner">
                                        <span>The infection of respiratory coronavirus disease 2019 (COVID-19) starts with
the upper respiratory tract and as the virus grows, the infection can progress
to lungs and develop pneumonia. The conventional way of COVID-19 diagnosis is
reverse transcription polymerase chain reaction (RT-PCR), which is less
sensitive during early stages; especially if the patient is asymptomatic, which
may further cause more severe pneumonia. In this context, several deep learning
models have been proposed to identify pulmonary infections using publicly
available chest X-ray (CXR) image datasets for early diagnosis, better
treatment and quick cure. In these datasets, presence of less number of
COVID-19 positive samples compared to other classes (normal, pneumonia and
Tuberculosis) raises the challenge for unbiased learning of deep learning
models. All deep learning models opted class balancing techniques to solve this
issue; which however should be avoided in any medical diagnosis process.
Moreover, the deep learning models are also data hungry and need massive
computation resources. Therefore for quicker diagnosis, this research proposes
a novel pinball loss function based one-class support vector machine
(PB-OCSVM), that can work in presence of limited COVID-19 positive CXR samples
with objectives to maximize the learning efficiency and to minimize the false
predictions. The performance of the proposed model is compared with
conventional OCSVM and existing deep learning models, and the experimental
results prove that the proposed model outperformed over state-of-the-art
methods. To validate the robustness of the proposed model, experiments are also
performed with noisy CXR images and UCI benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distilled One-Shot Federated Learning. (arXiv:2009.07999v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1">Yanlin Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_G/0/1/0/all/0/1">George Pu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xiyao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaolin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dapeng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.07999">
                                    <div class="article-summary-box-inner">
                                        <span>Current federated learning algorithms take tens of communication rounds
transmitting unwieldy model weights under ideal circumstances and hundreds when
data is poorly distributed. Inspired by recent work on dataset distillation and
distributed one-shot learning, we propose Distilled One-Shot Federated Learning
(DOSFL) to significantly reduce the communication cost while achieving
comparable performance. In just one round, each client distills their private
dataset, sends the synthetic data (e.g. images or sentences) to the server, and
collectively trains a global model. The distilled data look like noise and are
only useful to the specific model weights, i.e., become useless after the model
updates. With this weight-less and gradient-less design, the total
communication cost of DOSFL is up to three orders of magnitude less than FedAvg
while preserving between 93% to 99% performance of a centralized counterpart.
Afterwards, clients could switch to traditional methods such as FedAvg to
finetune the last few percent to fit personalized local models with local
datasets. Through comprehensive experiments, we show the accuracy and
communication performance of DOSFL on both vision and language tasks with
different models including CNN, LSTM, Transformer, etc. We demonstrate that an
eavesdropping attacker cannot properly train a good model using the leaked
distilled data, without knowing the initial model weights. DOSFL serves as an
inexpensive method to quickly converge on a performant pre-trained model with
less than 0.1% communication cost of traditional methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tensor Normal Training for Deep Learning Models. (arXiv:2106.02925v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_Y/0/1/0/all/0/1">Yi Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldfarb_D/0/1/0/all/0/1">Donald Goldfarb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02925">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the predominant use of first-order methods for training deep learning
models, second-order methods, and in particular, natural gradient methods,
remain of interest because of their potential for accelerating training through
the use of curvature information. Several methods with non-diagonal
preconditioning matrices, including KFAC and Shampoo, have been proposed and
shown to be effective. Based on the so-called tensor normal (TN) distribution,
we propose and analyze a brand new approximate natural gradient method, Tensor
Normal Training (TNT), which like Shampoo, only requires knowledge on the shape
of the training parameters. By approximating the probabilistically based Fisher
matrix, as opposed to the empirical Fisher matrix, our method uses the
layer-wise covariance of the sampling based gradient as the pre-conditioning
matrix. Moreover, the assumption that the sampling-based (tensor) gradient
follows a TN distribution, ensures that its covariance has a Kronecker
separable structure, which leads to a tractable approximation to the Fisher
matrix. Consequently, TNT&#x27;s memory requirements and per-iteration computational
costs are only slightly higher than those for first-order methods. In our
experiments, TNT exhibited superior optimization performance to KFAC and
Shampoo, and to state-of-the-art first-order methods. Moreover, TNT
demonstrated its ability to generalize as well as these first-order methods,
using fewer epochs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Traffic Refinery: Cost-Aware Data Representation for Machine Learning on Network Traffic. (arXiv:2010.14605v3 [cs.NI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bronzino_F/0/1/0/all/0/1">Francesco Bronzino</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmitt_P/0/1/0/all/0/1">Paul Schmitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Ayoubi_S/0/1/0/all/0/1">Sara Ayoubi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyojoon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Teixeira_R/0/1/0/all/0/1">Renata Teixeira</a>, <a href="http://arxiv.org/find/cs/1/au:+Feamster_N/0/1/0/all/0/1">Nick Feamster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14605">
                                    <div class="article-summary-box-inner">
                                        <span>Network management often relies on machine learning to make predictions about
performance and security from network traffic. Often, the representation of the
traffic is as important as the choice of the model. The features that the model
relies on, and the representation of those features, ultimately determine model
accuracy, as well as where and whether the model can be deployed in practice.
Thus, the design and evaluation of these models ultimately requires
understanding not only model accuracy but also the systems costs associated
with deploying the model in an operational network. Towards this goal, this
paper develops a new framework and system that enables a joint evaluation of
both the conventional notions of machine learning performance (e.g., model
accuracy) and the systems-level costs of different representations of network
traffic. We highlight these two dimensions for two practical network management
tasks, video streaming quality inference and malware detection, to demonstrate
the importance of exploring different representations to find the appropriate
operating point. We demonstrate the benefit of exploring a range of
representations of network traffic and present Traffic Refinery, a
proof-of-concept implementation that both monitors network traffic at 10 Gbps
and transforms traffic in real time to produce a variety of feature
representations for machine learning. Traffic Refinery both highlights this
design space and makes it possible to explore different representations for
learning, balancing systems costs related to feature extraction and model
training against model accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding Time-resolved EEG Motor Imagery Signals. (arXiv:2006.08924v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lun_X/0/1/0/all/0/1">Xiangmin Lun</a>, <a href="http://arxiv.org/find/eess/1/au:+Jia_S/0/1/0/all/0/1">Shuyue Jia</a>, <a href="http://arxiv.org/find/eess/1/au:+Hou_Y/0/1/0/all/0/1">Yimin Hou</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_Y/0/1/0/all/0/1">Yan Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Y/0/1/0/all/0/1">Yang Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08924">
                                    <div class="article-summary-box-inner">
                                        <span>Towards developing effective and efficient brain-computer interface (BCI)
systems, precise decoding of brain activity measured by electroencephalogram
(EEG), is highly demanded. Traditional works classify EEG signals without
considering the topological relationship among electrodes. However,
neuroscience research has increasingly emphasized network patterns of brain
dynamics. Thus, the Euclidean structure of electrodes might not adequately
reflect the interaction between signals. To fill the gap, a novel deep learning
framework based on the graph convolutional neural networks (GCNs) was presented
to enhance the decoding performance of raw EEG signals during different types
of motor imagery (MI) tasks while cooperating with the functional topological
relationship of electrodes. Based on the absolute Pearson&#x27;s matrix of overall
signals, the graph Laplacian of EEG electrodes was built up. The GCNs-Net
constructed by graph convolutional layers learns the generalized features. The
followed pooling layers reduce dimensionality, and the fully-connected softmax
layer derives the final prediction. The introduced approach has been shown to
converge for both personalized and group-wise predictions. It has achieved the
highest averaged accuracy, 93.056% and 88.57% (PhysioNet Dataset), 96.24% and
80.89% (High Gamma Dataset), at the subject and group level, respectively,
compared with existing studies, which suggests adaptability and robustness to
individual variability. Moreover, the performance was stably reproducible among
repetitive experiments for cross-validation. To conclude, the GCNs-Net filters
EEG signals based on the functional topological relationship, which manages to
decode relevant features for brain motor imagery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Convergence of Tsetlin Machines for the IDENTITY- and NOT Operators. (arXiv:2007.14268v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1">Lei Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1">Ole-Christoffer Granmo</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodwin_M/0/1/0/all/0/1">Morten Goodwin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14268">
                                    <div class="article-summary-box-inner">
                                        <span>The Tsetlin Machine (TM) is a recent machine learning algorithm with several
distinct properties, such as interpretability, simplicity, and
hardware-friendliness. Although numerous empirical evaluations report on its
performance, the mathematical analysis of its convergence is still open. In
this article, we analyze the convergence of the TM with only one clause
involved for classification. More specifically, we examine two basic logical
operators, namely, the &quot;IDENTITY&quot;- and &quot;NOT&quot; operators. Our analysis reveals
that the TM, with just one clause, can converge correctly to the intended
logical operator, learning from training data over an infinite time horizon.
Besides, it can capture arbitrarily rare patterns and select the most accurate
one when two candidate patterns are incompatible, by configuring a granularity
parameter. The analysis of the convergence of the two basic operators lays the
foundation for analyzing other logical operators. These analyses altogether,
from a mathematical perspective, provide new insights on why TMs have obtained
state-of-the-art performance on several pattern recognition problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Topology from Synthetic Data for Unsupervised Depth Completion. (arXiv:2106.02994v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1">Alex Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Cicek_S/0/1/0/all/0/1">Safa Cicek</a>, <a href="http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1">Stefano Soatto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02994">
                                    <div class="article-summary-box-inner">
                                        <span>We present a method for inferring dense depth maps from images and sparse
depth measurements by leveraging synthetic data to learn the association of
sparse point clouds with dense natural shapes, and using the image as evidence
to validate the predicted depth map. Our learned prior for natural shapes uses
only sparse depth as input, not images, so the method is not affected by the
covariate shift when attempting to transfer learned models from synthetic data
to real ones. This allows us to use abundant synthetic data with ground truth
to learn the most difficult component of the reconstruction process, which is
topology estimation, and use the image to refine the prediction based on
photometric evidence. Our approach uses fewer parameters than previous methods,
yet, achieves the state of the art on both indoor and outdoor benchmark
datasets. Code available at:
https://github.com/alexklwong/learning-topology-synthetic-data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feature Flow Regularization: Improving Structured Sparsity in Deep Neural Networks. (arXiv:2106.02914v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yue Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1">Yuan Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Luchan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiang_Y/0/1/0/all/0/1">Yang Xiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02914">
                                    <div class="article-summary-box-inner">
                                        <span>Pruning is a model compression method that removes redundant parameters in
deep neural networks (DNNs) while maintaining accuracy. Most available filter
pruning methods require complex treatments such as iterative pruning, features
statistics/ranking, or additional optimization designs in the training process.
In this paper, we propose a simple and effective regularization strategy from a
new perspective of evolution of features, which we call feature flow
regularization (FFR), for improving structured sparsity and filter pruning in
DNNs. Specifically, FFR imposes controls on the gradient and curvature of
feature flow along the neural network, which implicitly increases the sparsity
of the parameters. The principle behind FFR is that coherent and smooth
evolution of features will lead to an efficient network that avoids redundant
parameters. The high structured sparsity obtained from FFR enables us to prune
filters effectively. Experiments with VGGNets, ResNets on CIFAR-10/100, and
Tiny ImageNet datasets demonstrate that FFR can significantly improve both
unstructured and structured sparsity. Our pruning results in terms of reduction
of parameters and FLOPs are comparable to or even better than those of
state-of-the-art pruning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Routines for Effective Off-Policy Reinforcement Learning. (arXiv:2106.02943v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cetin_E/0/1/0/all/0/1">Edoardo Cetin</a>, <a href="http://arxiv.org/find/cs/1/au:+Celiktutan_O/0/1/0/all/0/1">Oya Celiktutan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02943">
                                    <div class="article-summary-box-inner">
                                        <span>The performance of reinforcement learning depends upon designing an
appropriate action space, where the effect of each action is measurable, yet,
granular enough to permit flexible behavior. So far, this process involved
non-trivial user choices in terms of the available actions and their execution
frequency. We propose a novel framework for reinforcement learning that
effectively lifts such constraints. Within our framework, agents learn
effective behavior over a routine space: a new, higher-level action space,
where each routine represents a set of &#x27;equivalent&#x27; sequences of granular
actions with arbitrary length. Our routine space is learned end-to-end to
facilitate the accomplishment of underlying off-policy reinforcement learning
objectives. We apply our framework to two state-of-the-art off-policy
algorithms and show that the resulting agents obtain relevant performance
improvements while requiring fewer interactions with the environment per
episode, improving computational efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extracting Weighted Automata for Approximate Minimization in Language Modelling. (arXiv:2106.02965v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lacroce_C/0/1/0/all/0/1">Clara Lacroce</a>, <a href="http://arxiv.org/find/cs/1/au:+Panangaden_P/0/1/0/all/0/1">Prakash Panangaden</a>, <a href="http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1">Guillaume Rabusseau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02965">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we study the approximate minimization problem for language
modelling. We assume we are given some language model as a black box. The
objective is to obtain a weighted finite automaton (WFA) that fits within a
given size constraint and which mimics the behaviour of the original model
while minimizing some notion of distance between the black box and the
extracted WFA. We provide an algorithm for the approximate minimization of
black boxes trained for language modelling of sequential data over a one-letter
alphabet. By reformulating the problem in terms of Hankel matrices, we leverage
classical results on the approximation of Hankel operators, namely the
celebrated Adamyan-Arov-Krein (AAK) theory. This allows us to use the spectral
norm to measure the distance between the black box and the WFA. We provide
theoretical guarantees to study the potentially infinite-rank Hankel matrix of
the black box, without accessing the training data, and we prove that our
method returns an asymptotically-optimal approximation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding and Improving Fairness-Accuracy Trade-offs in Multi-Task Learning. (arXiv:2106.02705v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yuyan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xuezhi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1">Alex Beutel</a>, <a href="http://arxiv.org/find/cs/1/au:+Prost_F/0/1/0/all/0/1">Flavien Prost</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jilin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1">Ed H. Chi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02705">
                                    <div class="article-summary-box-inner">
                                        <span>As multi-task models gain popularity in a wider range of machine learning
applications, it is becoming increasingly important for practitioners to
understand the fairness implications associated with those models. Most
existing fairness literature focuses on learning a single task more fairly,
while how ML fairness interacts with multiple tasks in the joint learning
setting is largely under-explored. In this paper, we are concerned with how
group fairness (e.g., equal opportunity, equalized odds) as an ML fairness
concept plays out in the multi-task scenario. In multi-task learning, several
tasks are learned jointly to exploit task correlations for a more efficient
inductive transfer. This presents a multi-dimensional Pareto frontier on (1)
the trade-off between group fairness and accuracy with respect to each task, as
well as (2) the trade-offs across multiple tasks. We aim to provide a deeper
understanding on how group fairness interacts with accuracy in multi-task
learning, and we show that traditional approaches that mainly focus on
optimizing the Pareto frontier of multi-task accuracy might not perform well on
fairness goals. We propose a new set of metrics to better capture the
multi-dimensional Pareto frontier of fairness-accuracy trade-offs uniquely
presented in a multi-task learning setting. We further propose a
Multi-Task-Aware Fairness (MTA-F) approach to improve fairness in multi-task
learning. Experiments on several real-world datasets demonstrate the
effectiveness of our proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Autonomous Optimization of Fluid Systems at Varying Length Scales. (arXiv:2105.13553v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Siemenn_A/0/1/0/all/0/1">Alexander E. Siemenn</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaulsky_E/0/1/0/all/0/1">Evyatar Shaulsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Beveridge_M/0/1/0/all/0/1">Matthew Beveridge</a>, <a href="http://arxiv.org/find/cs/1/au:+Buonassisi_T/0/1/0/all/0/1">Tonio Buonassisi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hashmi_S/0/1/0/all/0/1">Sara M. Hashmi</a>, <a href="http://arxiv.org/find/cs/1/au:+Drori_I/0/1/0/all/0/1">Iddo Drori</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13553">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous optimization is a process by which hardware conditions are
discovered that generate an optimized experimental product without the guidance
of a domain expert. We design an autonomous optimization framework to discover
the experimental conditions within fluid systems that generate discrete and
uniform droplet patterns. Generating discrete and uniform droplets requires
high-precision control over the experimental conditions of a fluid system.
Fluid stream instabilities, such as Rayleigh-Plateau instability and capillary
instability, drive the separation of a flow into individual droplets. However,
because this phenomenon leverages an instability, by nature the hardware must
be precisely tuned to achieve uniform, repeatable droplets. Typically this
requires a domain expert in the loop and constant re-tuning depending on the
hardware configuration and liquid precursor selection. Herein, we propose a
computer vision-driven Bayesian optimization framework to discover the precise
hardware conditions that generate uniform, reproducible droplets with the
desired features, leveraging flow instability without a domain expert in the
loop. This framework is validated on two fluid systems, at the micrometer and
millimeter length scales, using microfluidic and inkjet systems, respectively,
indicating the application breadth of this approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manipulating SGD with Data Ordering Attacks. (arXiv:2104.09667v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shumailov_I/0/1/0/all/0/1">Ilia Shumailov</a>, <a href="http://arxiv.org/find/cs/1/au:+Shumaylov_Z/0/1/0/all/0/1">Zakhar Shumaylov</a>, <a href="http://arxiv.org/find/cs/1/au:+Kazhdan_D/0/1/0/all/0/1">Dmitry Kazhdan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yiren Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1">Nicolas Papernot</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdogdu_M/0/1/0/all/0/1">Murat A. Erdogdu</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_R/0/1/0/all/0/1">Ross Anderson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09667">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning is vulnerable to a wide variety of attacks. It is now well
understood that by changing the underlying data distribution, an adversary can
poison the model trained with it or introduce backdoors. In this paper we
present a novel class of training-time attacks that require no changes to the
underlying dataset or model architecture, but instead only change the order in
which data are supplied to the model. In particular, we find that the attacker
can either prevent the model from learning, or poison it to learn behaviours
specified by the attacker. Furthermore, we find that even a single
adversarially-ordered epoch can be enough to slow down model learning, or even
to reset all of the learning progress. Indeed, the attacks presented here are
not specific to the model or dataset, but rather target the stochastic nature
of modern learning procedures. We extensively evaluate our attacks on computer
vision and natural language benchmarks to find that the adversary can disrupt
model training and even introduce backdoors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Integrating Expert ODEs into Neural ODEs: Pharmacology and Disease Progression. (arXiv:2106.02875v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qian_Z/0/1/0/all/0/1">Zhaozhi Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zame_W/0/1/0/all/0/1">William R. Zame</a>, <a href="http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1">Mihaela van der Schaar</a>, <a href="http://arxiv.org/find/cs/1/au:+Fleuren_L/0/1/0/all/0/1">Lucas M. Fleuren</a>, <a href="http://arxiv.org/find/cs/1/au:+Elbers_P/0/1/0/all/0/1">Paul Elbers</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02875">
                                    <div class="article-summary-box-inner">
                                        <span>Modeling a system&#x27;s temporal behaviour in reaction to external stimuli is a
fundamental problem in many areas. Pure Machine Learning (ML) approaches often
fail in the small sample regime and cannot provide actionable insights beyond
predictions. A promising modification has been to incorporate expert domain
knowledge into ML models. The application we consider is predicting the
progression of disease under medications, where a plethora of domain knowledge
is available from pharmacology. Pharmacological models describe the dynamics of
carefully-chosen medically meaningful variables in terms of systems of Ordinary
Differential Equations (ODEs). However, these models only describe a limited
collection of variables, and these variables are often not observable in
clinical environments. To close this gap, we propose the latent hybridisation
model (LHM) that integrates a system of expert-designed ODEs with
machine-learned Neural ODEs to fully describe the dynamics of the system and to
link the expert and latent variables to observable quantities. We evaluated LHM
on synthetic data as well as real-world intensive care data of COVID-19
patients. LHM consistently outperforms previous works, especially when few
training samples are available such as at the beginning of the pandemic.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lower Bounds on Cross-Entropy Loss in the Presence of Test-time Adversaries. (arXiv:2104.08382v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhagoji_A/0/1/0/all/0/1">Arjun Nitin Bhagoji</a>, <a href="http://arxiv.org/find/cs/1/au:+Cullina_D/0/1/0/all/0/1">Daniel Cullina</a>, <a href="http://arxiv.org/find/cs/1/au:+Sehwag_V/0/1/0/all/0/1">Vikash Sehwag</a>, <a href="http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1">Prateek Mittal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08382">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding the fundamental limits of robust supervised learning has
emerged as a problem of immense interest, from both practical and theoretical
standpoints. In particular, it is critical to determine classifier-agnostic
bounds on the training loss to establish when learning is possible. In this
paper, we determine optimal lower bounds on the cross-entropy loss in the
presence of test-time adversaries, along with the corresponding optimal
classification outputs. Our formulation of the bound as a solution to an
optimization problem is general enough to encompass any loss function depending
on soft classifier outputs. We also propose and provide a proof of correctness
for a bespoke algorithm to compute this lower bound efficiently, allowing us to
determine lower bounds for multiple practical datasets of interest. We use our
lower bounds as a diagnostic tool to determine the effectiveness of current
robust training methods and find a gap from optimality at larger budgets.
Finally, we investigate the possibility of using of optimal classification
outputs as soft labels to empirically improve robust training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Role of Entropy-based Loss for Learning Causal Structures with Continuous Optimization. (arXiv:2106.02835v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1">Ruichu Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weilin Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_J/0/1/0/all/0/1">Jie Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_Z/0/1/0/all/0/1">Zhifeng Hao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02835">
                                    <div class="article-summary-box-inner">
                                        <span>Causal discovery from observational data is an important but challenging task
in many scientific fields. Recently, NOTEARS [Zheng et al., 2018] formulates
the causal structure learning problem as a continuous optimization problem
using least-square loss with an acyclicity constraint. Though the least-square
loss function is well justified under the standard Gaussian noise assumption,
it is limited if the assumption does not hold. In this work, we theoretically
show that the violation of the Gaussian noise assumption will hinder the causal
direction identification, making the causal orientation fully determined by the
causal strength as well as the variances of noises in the linear case and the
noises of strong non-Gaussianity in the nonlinear case. Consequently, we
propose a more general entropy-based loss that is theoretically consistent with
the likelihood score under any noise distribution. We run extensive empirical
evaluations on both synthetic data and real-world data to validate the
effectiveness of the proposed method and show that our method achieves the best
in Structure Hamming Distance, False Discovery Rate, and True Positive Rate
matrices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic Hawkes Processes for Discovering Time-evolving Communities&#x27; States behind Diffusion Processes. (arXiv:2105.11152v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Okawa_M/0/1/0/all/0/1">Maya Okawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1">Tomoharu Iwata</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_Y/0/1/0/all/0/1">Yusuke Tanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Toda_H/0/1/0/all/0/1">Hiroyuki Toda</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurashima_T/0/1/0/all/0/1">Takeshi Kurashima</a>, <a href="http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1">Hisashi Kashima</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11152">
                                    <div class="article-summary-box-inner">
                                        <span>Sequences of events including infectious disease outbreaks, social network
activities, and crimes are ubiquitous and the data on such events carry
essential information about the underlying diffusion processes between
communities (e.g., regions, online user groups). Modeling diffusion processes
and predicting future events are crucial in many applications including
epidemic control, viral marketing, and predictive policing. Hawkes processes
offer a central tool for modeling the diffusion processes, in which the
influence from the past events is described by the triggering kernel. However,
the triggering kernel parameters, which govern how each community is influenced
by the past events, are assumed to be static over time. In the real world, the
diffusion processes depend not only on the influences from the past, but also
the current (time-evolving) states of the communities, e.g., people&#x27;s awareness
of the disease and people&#x27;s current interests. In this paper, we propose a
novel Hawkes process model that is able to capture the underlying dynamics of
community states behind the diffusion processes and predict the occurrences of
events based on the dynamics. Specifically, we model the latent dynamic
function that encodes these hidden dynamics by a mixture of neural networks.
Then we design the triggering kernel using the latent dynamic function and its
integral. The proposed method, termed DHP (Dynamic Hawkes Processes), offers a
flexible way to learn complex representations of the time-evolving communities&#x27;
states, while at the same time it allows to computing the exact likelihood,
which makes parameter learning tractable. Extensive experiments on four
real-world event datasets show that DHP outperforms five widely adopted methods
for event prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Causal Explanations for Graph Neural Networks. (arXiv:2104.06643v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wanyu Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_H/0/1/0/all/0/1">Hao Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Baochun Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06643">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents Gem, a model-agnostic approach for providing
interpretable explanations for any GNNs on various graph learning tasks.
Specifically, we formulate the problem of providing explanations for the
decisions of GNNs as a causal learning task. Then we train a causal explanation
model equipped with a loss function based on Granger causality. Different from
existing explainers for GNNs, Gem explains GNNs on graph-structured data from a
causal perspective. It has better generalization ability as it has no
requirements on the internal structure of the GNNs or prior knowledge on the
graph learning tasks. In addition, Gem, once trained, can be used to explain
the target GNN very quickly. Our theoretical analysis shows that several recent
explainers fall into a unified framework of additive feature attribution
methods. Experimental results on synthetic and real-world datasets show that
Gem achieves a relative increase of the explanation accuracy by up to $30\%$
and speeds up the explanation process by up to $110\times$ as compared to its
state-of-the-art alternatives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privacy-Preserving Training of Tree Ensembles over Continuous Data. (arXiv:2106.02769v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Adams_S/0/1/0/all/0/1">Samuel Adams</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_C/0/1/0/all/0/1">Chaitali Choudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Cock_M/0/1/0/all/0/1">Martine De Cock</a>, <a href="http://arxiv.org/find/cs/1/au:+Dowsley_R/0/1/0/all/0/1">Rafael Dowsley</a>, <a href="http://arxiv.org/find/cs/1/au:+Melanson_D/0/1/0/all/0/1">David Melanson</a>, <a href="http://arxiv.org/find/cs/1/au:+Nascimento_A/0/1/0/all/0/1">Anderson C. A. Nascimento</a>, <a href="http://arxiv.org/find/cs/1/au:+Railsback_D/0/1/0/all/0/1">Davis Railsback</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1">Jianwei Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02769">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing Secure Multi-Party Computation (MPC) protocols for
privacy-preserving training of decision trees over distributed data assume that
the features are categorical. In real-life applications, features are often
numerical. The standard &#x60;&#x60;in the clear&#x27;&#x27; algorithm to grow decision trees on
data with continuous values requires sorting of training examples for each
feature in the quest for an optimal cut-point in the range of feature values in
each node. Sorting is an expensive operation in MPC, hence finding secure
protocols that avoid such an expensive step is a relevant problem in
privacy-preserving machine learning. In this paper we propose three more
efficient alternatives for secure training of decision tree based models on
data with continuous features, namely: (1) secure discretization of the data,
followed by secure training of a decision tree over the discretized data; (2)
secure discretization of the data, followed by secure training of a random
forest over the discretized data; and (3) secure training of extremely
randomized trees (&#x60;&#x60;extra-trees&#x27;&#x27;) on the original data. Approaches (2) and (3)
both involve randomizing feature choices. In addition, in approach (3)
cut-points are chosen randomly as well, thereby alleviating the need to sort or
to discretize the data up front. We implemented all proposed solutions in the
semi-honest setting with additive secret sharing based MPC. In addition to
mathematically proving that all proposed approaches are correct and secure, we
experimentally evaluated and compared them in terms of classification accuracy
and runtime. We privately train tree ensembles over data sets with 1000s of
instances or features in a few minutes, with accuracies that are at par with
those obtained in the clear. This makes our solution orders of magnitude more
efficient than the existing approaches, which are based on oblivious sorting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Encoder-Decoder Neural Architecture Optimization for Keyword Spotting. (arXiv:2106.02738v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mo_T/0/1/0/all/0/1">Tong Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02738">
                                    <div class="article-summary-box-inner">
                                        <span>Keyword spotting aims to identify specific keyword audio utterances. In
recent years, deep convolutional neural networks have been widely utilized in
keyword spotting systems. However, their model architectures are mainly based
on off-the shelfbackbones such as VGG-Net or ResNet, instead of specially
designed for the task. In this paper, we utilize neural architecture search to
design convolutional neural network models that can boost the performance of
keyword spotting while maintaining an acceptable memory footprint.
Specifically, we search the model operators and their connections in a specific
search space with Encoder-Decoder neural architecture optimization. Extensive
evaluations on Google&#x27;s Speech Commands Dataset show that the model
architecture searched by our approach achieves a state-of-the-art accuracy of
over 97%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-Based Learning for Cooperative Games, with Applications to Feature/Data/Model Valuations. (arXiv:2106.02938v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bian_Y/0/1/0/all/0/1">Yatao Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1">Yu Rong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1">Tingyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1">Jiaxiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junzhou Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02938">
                                    <div class="article-summary-box-inner">
                                        <span>Valuation problems, such as attribution-based feature interpretation, data
valuation and model valuation for ensembles, become increasingly more important
in many machine learning applications. Such problems are commonly solved by
well-known game-theoretic criteria, such as Shapley value or Banzhaf index. In
this work, we present a novel energy-based treatment for cooperative games,
with a theoretical justification by the maximum entropy framework.
Surprisingly, by conducting variational inference of the energy-based model, we
recover various game-theoretic valuation criteria, such as Shapley value and
Banzhaf index, through conducting one-step gradient ascent for maximizing the
mean-field ELBO objective. This observation also verifies the rationality of
existing criteria, as they are all trying to decouple the correlations among
the players through the mean-field approach. By running gradient ascent for
multiple steps, we achieve a trajectory of the valuations, among which we
define the valuation with the best conceivable decoupling error as the
Variational Index. We experimentally demonstrate that the proposed Variational
Index enjoys intriguing properties on certain synthetic and real-world
valuation problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Discrete Variational Derivation of Accelerated Methods in Optimization. (arXiv:2106.02700v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Campos_C/0/1/0/all/0/1">C&#xe9;dric M. Campos</a>, <a href="http://arxiv.org/find/math/1/au:+Mahillo_A/0/1/0/all/0/1">Alejandro Mahillo</a>, <a href="http://arxiv.org/find/math/1/au:+Diego_D/0/1/0/all/0/1">David Mart&#xed;n de Diego</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02700">
                                    <div class="article-summary-box-inner">
                                        <span>Many of the new developments in machine learning are connected with
gradient-based optimization methods. Recently, these methods have been studied
using a variational perspective. This has opened up the possibility of
introducing variational and symplectic integration methods using geometric
integrators. In particular, in this paper, we introduce variational integrators
which allow us to derive different methods for optimization. Using both,
Hamilton&#x27;s principle and Lagrange-d&#x27;Alembert&#x27;s, we derive two families of
optimization methods in one-to-one correspondence that generalize Polyak&#x27;s
heavy ball and the well known Nesterov accelerated gradient method, mimicking
the behavior of the latter which reduces the oscillations of typical momentum
methods. However, since the systems considered are explicitly time-dependent,
the preservation of symplecticity of autonomous systems occurs here solely on
the fibers. Several experiments exemplify the result.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ImageNet-21K Pretraining for the Masses. (arXiv:2104.10972v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ridnik_T/0/1/0/all/0/1">Tal Ridnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Ben_Baruch_E/0/1/0/all/0/1">Emanuel Ben-Baruch</a>, <a href="http://arxiv.org/find/cs/1/au:+Noy_A/0/1/0/all/0/1">Asaf Noy</a>, <a href="http://arxiv.org/find/cs/1/au:+Zelnik_Manor_L/0/1/0/all/0/1">Lihi Zelnik-Manor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10972">
                                    <div class="article-summary-box-inner">
                                        <span>ImageNet-1K serves as the primary dataset for pretraining deep learning
models for computer vision tasks. ImageNet-21K dataset, which is bigger and
more diverse, is used less frequently for pretraining, mainly due to its
complexity, low accessibility, and underestimation of its added value. This
paper aims to close this gap, and make high-quality efficient pretraining on
ImageNet-21K available for everyone. Via a dedicated preprocessing stage,
utilization of WordNet hierarchical structure, and a novel training scheme
called semantic softmax, we show that various models significantly benefit from
ImageNet-21K pretraining on numerous datasets and tasks, including small
mobile-oriented models. We also show that we outperform previous ImageNet-21K
pretraining schemes for prominent new models like ViT and Mixer. Our proposed
pretraining pipeline is efficient, accessible, and leads to SoTA reproducible
results, from a publicly available dataset. The training code and pretrained
models are available at: https://github.com/Alibaba-MIIL/ImageNet21K</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentially Private Deep Learning under the Fairness Lens. (arXiv:2106.02674v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1">Cuong Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Dinh_M/0/1/0/all/0/1">My H. Dinh</a>, <a href="http://arxiv.org/find/cs/1/au:+Fioretto_F/0/1/0/all/0/1">Ferdinando Fioretto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02674">
                                    <div class="article-summary-box-inner">
                                        <span>Differential Privacy (DP) is an important privacy-enhancing technology for
private machine learning systems. It allows to measure and bound the risk
associated with an individual participation in a computation. However, it was
recently observed that DP learning systems may exacerbate bias and unfairness
for different groups of individuals. This paper builds on these important
observations and sheds light on the causes of the disparate impacts arising in
the problem of differentially private empirical risk minimization. It focuses
on the accuracy disparity arising among groups of individuals in two
well-studied DP learning methods: output perturbation and differentially
private stochastic gradient descent. The paper analyzes which data and model
properties are responsible for the disproportionate impacts, why these aspects
are affecting different groups disproportionately and proposes guidelines to
mitigate these effects. The proposed approach is evaluated on several datasets
and settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Zero-shot Task Adaptation using Natural Language. (arXiv:2106.02972v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1">Prasoon Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mooney_R/0/1/0/all/0/1">Raymond J. Mooney</a>, <a href="http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1">Scott Niekum</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02972">
                                    <div class="article-summary-box-inner">
                                        <span>Imitation learning and instruction-following are two common approaches to
communicate a user&#x27;s intent to a learning agent. However, as the complexity of
tasks grows, it could be beneficial to use both demonstrations and language to
communicate with an agent. In this work, we propose a novel setting where an
agent is given both a demonstration and a description, and must combine
information from both the modalities. Specifically, given a demonstration for a
task (the source task), and a natural language description of the differences
between the demonstrated task and a related but different task (the target
task), our goal is to train an agent to complete the target task in a zero-shot
setting, that is, without any demonstrations for the target task. To this end,
we introduce Language-Aided Reward and Value Adaptation (LARVA) which, given a
source demonstration and a linguistic description of how the target task
differs, learns to output a reward / value function that accurately describes
the target task. Our experiments show that on a diverse set of adaptations, our
approach is able to complete more than 95% of target tasks when using
template-based descriptions, and more than 70% when using free-form natural
language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data-driven discovery of interacting particle systems using Gaussian processes. (arXiv:2106.02735v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1">Jinchao Feng</a>, <a href="http://arxiv.org/find/stat/1/au:+Ren_Y/0/1/0/all/0/1">Yunxiang Ren</a>, <a href="http://arxiv.org/find/stat/1/au:+Tang_S/0/1/0/all/0/1">Sui Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02735">
                                    <div class="article-summary-box-inner">
                                        <span>Interacting particle or agent systems that display a rich variety of
collection motions are ubiquitous in science and engineering. A fundamental and
challenging goal is to understand the link between individual interaction rules
and collective behaviors. In this paper, we study the data-driven discovery of
distance-based interaction laws in second-order interacting particle systems.
We propose a learning approach that models the latent interaction kernel
functions as Gaussian processes, which can simultaneously fulfill two inference
goals: one is the nonparametric inference of interaction kernel function with
the pointwise uncertainty quantification, and the other one is the inference of
unknown parameters in the non-collective forces of the system. We formulate
learning interaction kernel functions as a statistical inverse problem and
provide a detailed analysis of recoverability conditions, establishing that a
coercivity condition is sufficient for recoverability. We provide a
finite-sample analysis, showing that our posterior mean estimator converges at
an optimal rate equal to the one in the classical 1-dimensional Kernel Ridge
regression. Numerical results on systems that exhibit different collective
behaviors demonstrate efficient learning of our approach from scarce noisy
trajectory data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction of Apophis Asteroid Flyby Optimal Trajectories and Data Fusion of Earth-Apophis Mission Launch Windows using Deep Neural Networks. (arXiv:2104.06249v2 [astro-ph.IM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Ntumba_M/0/1/0/all/0/1">Manuel Ntumba</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Gore_S/0/1/0/all/0/1">Saurabh Gore</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Awanyo_J/0/1/0/all/0/1">Jean-Baptiste Awanyo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.06249">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, understanding asteroids has shifted from light worlds to
geological worlds by exploring modern spacecraft and advanced radar and
telescopic surveys. However, flyby in 2029 will be an opportunity to conduct an
internal geophysical study and test the current hypothesis on the effects of
tidal forces on asteroids. The Earth-Apophis mission is driven by additional
factors and scientific goals beyond the unique opportunity for natural
experimentation. However, the internal geophysical structures remain largely
unknown. Understanding the strength and internal integrity of asteroids is not
just a matter of scientific curiosity. It is a practical imperative to advance
knowledge for planetary defense against the possibility of an asteroid impact.
This paper presents a conceptual robotics system required for efficiency at
every stage from entry to post-landing and for asteroid monitoring. In short,
asteroid surveillance missions are futuristic frontiers, with the potential for
technological growth that could revolutionize space exploration. Advanced space
technologies and robotic systems are needed to minimize risk and prepare these
technologies for future missions. A neural network model is implemented to
track and predict asteroids&#x27; orbits. Advanced algorithms are also needed to
numerically predict orbital events to minimize error</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Classification of Very Large Images with Tiny Objects. (arXiv:2106.02694v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kong_F/0/1/0/all/0/1">Fanjie Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1">Ricardo Henao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02694">
                                    <div class="article-summary-box-inner">
                                        <span>An increasing number of applications in the computer vision domain,
specially, in medical imaging and remote sensing, are challenging when the goal
is to classify very large images with tiny objects. More specifically, these
type of classification tasks face two key challenges: $i$) the size of the
input image in the target dataset is usually in the order of megapixels,
however, existing deep architectures do not easily operate on such big images
due to memory constraints, consequently, we seek a memory-efficient method to
process these images; and $ii$) only a small fraction of the input images are
informative of the label of interest, resulting in low region of interest (ROI)
to image ratio. However, most of the current convolutional neural networks
(CNNs) are designed for image classification datasets that have relatively
large ROIs and small image size (sub-megapixel). Existing approaches have
addressed these two challenges in isolation. We present an end-to-end CNN model
termed Zoom-In network that leverages hierarchical attention sampling for
classification of large images with tiny objects using a single GPU. We
evaluate our method on two large-image datasets and one gigapixel dataset.
Experimental results show that our model achieves higher accuracy than existing
methods while requiring less computing resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Gradient Fields for Molecular Conformation Generation. (arXiv:2105.03902v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Chence Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shitong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Minkai Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03902">
                                    <div class="article-summary-box-inner">
                                        <span>We study a fundamental problem in computational chemistry known as molecular
conformation generation, trying to predict stable 3D structures from 2D
molecular graphs. Existing machine learning approaches usually first predict
distances between atoms and then generate a 3D structure satisfying the
distances, where noise in predicted distances may induce extra errors during 3D
coordinate generation. Inspired by the traditional force field methods for
molecular dynamics simulation, in this paper, we propose a novel approach
called ConfGF by directly estimating the gradient fields of the log density of
atomic coordinates. The estimated gradient fields allow directly generating
stable conformations via Langevin dynamics. However, the problem is very
challenging as the gradient fields are roto-translation equivariant. We notice
that estimating the gradient fields of atomic coordinates can be translated to
estimating the gradient fields of interatomic distances, and hence develop a
novel algorithm based on recent score-based generative models to effectively
estimate these gradients. Experimental results across multiple tasks show that
ConfGF outperforms previous state-of-the-art baselines by a significant margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">D-Cliques: Compensating NonIIDness in Decentralized Federated Learning with Topology. (arXiv:2104.07365v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bellet_A/0/1/0/all/0/1">Aur&#xe9;lien Bellet</a>, <a href="http://arxiv.org/find/cs/1/au:+Kermarrec_A/0/1/0/all/0/1">Anne-Marie Kermarrec</a>, <a href="http://arxiv.org/find/cs/1/au:+Lavoie_E/0/1/0/all/0/1">Erick Lavoie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07365">
                                    <div class="article-summary-box-inner">
                                        <span>The convergence speed of machine learning models trained with Federated
Learning is significantly affected by non-independent and identically
distributed (non-IID) data partitions, even more so in a fully decentralized
setting without a central server. In this paper, we show that the impact of
local class bias, an important type of data non-IIDness, can be significantly
reduced by carefully designing the underlying communication topology. We
present D-Cliques, a novel topology that reduces gradient bias by grouping
nodes in interconnected cliques such that the local joint distribution in a
clique is representative of the global class distribution. We also show how to
adapt the updates of decentralized SGD to obtain unbiased gradients and
implement an effective momentum with D-Cliques. Our empirical evaluation on
MNIST and CIFAR10 demonstrates that our approach provides similar convergence
speed as a fully-connected topology with a significant reduction in the number
of edges and messages. In a 1000-node topology, D-Cliques requires 98% less
edges and 96% less total messages, with further possible gains using a
small-world topology across cliques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Policies with Zero or Bounded Constraint Violation for Constrained MDPs. (arXiv:2106.02684v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Tao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1">Ruida Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalathil_D/0/1/0/all/0/1">Dileep Kalathil</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1">P. R. Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_C/0/1/0/all/0/1">Chao Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02684">
                                    <div class="article-summary-box-inner">
                                        <span>We address the issue of safety in reinforcement learning. We pose the problem
in an episodic framework of a constrained Markov decision process. Existing
results have shown that it is possible to achieve a reward regret of
$\tilde{\mathcal{O}}(\sqrt{K})$ while allowing an
$\tilde{\mathcal{O}}(\sqrt{K})$ constraint violation in $K$ episodes. A
critical question that arises is whether it is possible to keep the constraint
violation even smaller. We show that when a strictly safe policy is known, then
one can confine the system to zero constraint violation with arbitrarily high
probability while keeping the reward regret of order
$\tilde{\mathcal{O}}(\sqrt{K})$. The algorithm which does so employs the
principle of optimistic pessimism in the face of uncertainty to achieve safe
exploration. When no strictly safe policy is known, though one is known to
exist, then it is possible to restrict the system to bounded constraint
violation with arbitrarily high probability. This is shown to be realized by a
primal-dual algorithm with an optimistic primal estimate and a pessimistic dual
update.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BO-DBA: Query-Efficient Decision-Based Adversarial Attacks via Bayesian Optimization. (arXiv:2106.02732v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhuosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1">Shucheng Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02732">
                                    <div class="article-summary-box-inner">
                                        <span>Decision-based attacks (DBA), wherein attackers perturb inputs to spoof
learning algorithms by observing solely the output labels, are a type of severe
adversarial attacks against Deep Neural Networks (DNNs) requiring minimal
knowledge of attackers. State-of-the-art DBA attacks relying on zeroth-order
gradient estimation require an excessive number of queries. Recently, Bayesian
optimization (BO) has shown promising in reducing the number of queries in
score-based attacks (SBA), in which attackers need to observe real-valued
probability scores as outputs. However, extending BO to the setting of DBA is
nontrivial because in DBA only output labels instead of real-valued scores, as
needed by BO, are available to attackers. In this paper, we close this gap by
proposing an efficient DBA attack, namely BO-DBA. Different from existing
approaches, BO-DBA generates adversarial examples by searching so-called
\emph{directions of perturbations}. It then formulates the problem as a BO
problem that minimizes the real-valued distortion of perturbations. With the
optimized perturbation generation process, BO-DBA converges much faster than
the state-of-the-art DBA techniques. Experimental results on pre-trained
ImageNet classifiers show that BO-DBA converges within 200 queries while the
state-of-the-art DBA techniques need over 15,000 queries to achieve the same
level of perturbation distortion. BO-DBA also shows similar attack success
rates even as compared to BO-based SBA attacks but with less distortion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Real Time Video based Heart and Respiration Rate Monitoring. (arXiv:2106.02669v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pourbemany_J/0/1/0/all/0/1">Jafar Pourbemany</a>, <a href="http://arxiv.org/find/eess/1/au:+Essa_A/0/1/0/all/0/1">Almabrok Essa</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_Y/0/1/0/all/0/1">Ye Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02669">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, research about monitoring vital signs by smartphones grows
significantly. There are some special sensors like Electrocardiogram (ECG) and
Photoplethysmographic (PPG) to detect heart rate (HR) and respiration rate
(RR). Smartphone cameras also can measure HR by detecting and processing
imaging Photoplethysmographic (iPPG) signals from the video of a user&#x27;s face.
Indeed, the variation in the intensity of the green channel can be measured by
the iPPG signals of the video. This study aimed to provide a method to extract
heart rate and respiration rate using the video of individuals&#x27; faces. The
proposed method is based on measuring fluctuations in the Hue, and can
therefore extract both HR and RR from the video of a user&#x27;s face. The proposed
method is evaluated by performing on 25 healthy individuals. For each subject,
20 seconds video of his/her face is recorded. Results show that the proposed
approach of measuring iPPG using Hue gives more accurate rates than the Green
channel.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Mutual Information Regularized Identity-aware Facial ExpressionRecognition in Compressed Video. (arXiv:2010.10637v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaofeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Linghao Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xu Han</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Jane You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10637">
                                    <div class="article-summary-box-inner">
                                        <span>How to extract effective expression representations that invariant to the
identity-specific attributes is a long-lasting problem for facial expression
recognition (FER). Most of the previous methods process the RGB images of a
sequence, while we argue that the off-the-shelf and valuable expression-related
muscle movement is already embedded in the compression format. In this paper,
we target to explore the inter-subject variations eliminated facial expression
representation in the compressed video domain. In the up to two orders of
magnitude compressed domain, we can explicitly infer the expression from the
residual frames and possibly extract identity factors from the I frame with a
pre-trained face recognition network. By enforcing the marginal independence of
them, the expression feature is expected to be purer for the expression and be
robust to identity shifts. Specifically, we propose a novel collaborative
min-min game for mutual information (MI) minimization in latent space. We do
not need the identity label or multiple expression samples from the same person
for identity elimination. Moreover, when the apex frame is annotated in the
dataset, the complementary constraint can be further added to regularize the
feature-level game. In testing, only the compressed residual frames are
required to achieve expression prediction. Our solution can achieve comparable
or better performance than the recent decoded image-based methods on the
typical FER benchmarks with about 3 times faster inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepQTMT: A Deep Learning Approach for Fast QTMT-based CU Partition of Intra-mode VVC. (arXiv:2006.13125v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1">Tianyi Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Xu_M/0/1/0/all/0/1">Mai Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Tang_R/0/1/0/all/0/1">Runzhi Tang</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1">Ying Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Xing_Q/0/1/0/all/0/1">Qunliang Xing</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.13125">
                                    <div class="article-summary-box-inner">
                                        <span>Versatile Video Coding (VVC), as the latest standard, significantly improves
the coding efficiency over its ancestor standard High Efficiency Video Coding
(HEVC), but at the expense of sharply increased complexity. In VVC, the
quad-tree plus multi-type tree (QTMT) structure of coding unit (CU) partition
accounts for over 97% of the encoding time, due to the brute-force search for
recursive rate-distortion (RD) optimization. Instead of the brute-force QTMT
search, this paper proposes a deep learning approach to predict the QTMT-based
CU partition, for drastically accelerating the encoding process of intra-mode
VVC. First, we establish a large-scale database containing sufficient CU
partition patterns with diverse video content, which can facilitate the
data-driven VVC complexity reduction. Next, we propose a multi-stage exit CNN
(MSE-CNN) model with an early-exit mechanism to determine the CU partition, in
accord with the flexible QTMT structure at multiple stages. Then, we design an
adaptive loss function for training the MSE-CNN model, synthesizing both the
uncertain number of split modes and the target on minimized RD cost. Finally, a
multi-threshold decision scheme is developed, achieving desirable trade-off
between complexity and RD performance. Experimental results demonstrate that
our approach can reduce the encoding time of VVC by 44.65%-66.88% with the
negligible Bj{\o}ntegaard delta bit-rate (BD-BR) of 1.322%-3.188%, which
significantly outperforms other state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An End-to-End Breast Tumour Classification Model Using Context-Based Patch Modelling- A BiLSTM Approach for Image Classification. (arXiv:2106.02864v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1">Suvidha Tripathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Satish Kumar Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hwee Kuan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02864">
                                    <div class="article-summary-box-inner">
                                        <span>Researchers working on computational analysis of Whole Slide Images (WSIs) in
histopathology have primarily resorted to patch-based modelling due to large
resolution of each WSI. The large resolution makes WSIs infeasible to be fed
directly into the machine learning models due to computational constraints.
However, due to patch-based analysis, most of the current methods fail to
exploit the underlying spatial relationship among the patches. In our work, we
have tried to integrate this relationship along with feature-based correlation
among the extracted patches from the particular tumorous region. For the given
task of classification, we have used BiLSTMs to model both forward and backward
contextual relationship. RNN based models eliminate the limitation of sequence
size by allowing the modelling of variable size images within a deep learning
model. We have also incorporated the effect of spatial continuity by exploring
different scanning techniques used to sample patches. To establish the
efficiency of our approach, we trained and tested our model on two datasets,
microscopy images and WSI tumour regions. After comparing with contemporary
literature we achieved the better performance with accuracy of 90% for
microscopy image dataset. For WSI tumour region dataset, we compared the
classification results with deep learning networks such as ResNet, DenseNet,
and InceptionV3 using maximum voting technique. We achieved the highest
performance accuracy of 84%. We found out that BiLSTMs with CNN features have
performed much better in modelling patches into an end-to-end Image
classification network. Additionally, the variable dimensions of WSI tumour
regions were used for classification without the need for resizing. This
suggests that our method is independent of tumour image size and can process
large dimensional images without losing the resolution details.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Encoder-Decoder Neural Architecture Optimization for Keyword Spotting. (arXiv:2106.02738v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mo_T/0/1/0/all/0/1">Tong Mo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Bang Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02738">
                                    <div class="article-summary-box-inner">
                                        <span>Keyword spotting aims to identify specific keyword audio utterances. In
recent years, deep convolutional neural networks have been widely utilized in
keyword spotting systems. However, their model architectures are mainly based
on off-the shelfbackbones such as VGG-Net or ResNet, instead of specially
designed for the task. In this paper, we utilize neural architecture search to
design convolutional neural network models that can boost the performance of
keyword spotting while maintaining an acceptable memory footprint.
Specifically, we search the model operators and their connections in a specific
search space with Encoder-Decoder neural architecture optimization. Extensive
evaluations on Google&#x27;s Speech Commands Dataset show that the model
architecture searched by our approach achieves a state-of-the-art accuracy of
over 97%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-07">2021-06-07</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustness Testing of Language Understanding in Task-Oriented Dialog. (arXiv:2012.15262v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiexi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Takanobu_R/0/1/0/all/0/1">Ryuichi Takanobu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Jiaxin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_D/0/1/0/all/0/1">Dazhen Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongguang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nie_W/0/1/0/all/0/1">Weiran Nie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Cheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15262">
                                    <div class="article-summary-box-inner">
                                        <span>Most language understanding models in task-oriented dialog systems are
trained on a small amount of annotated training data, and evaluated in a small
set from the same distribution. However, these models can lead to system
failure or undesirable output when being exposed to natural language
perturbation or variation in practice. In this paper, we conduct comprehensive
evaluation and analysis with respect to the robustness of natural language
understanding models, and introduce three important aspects related to language
understanding in real-world dialog systems, namely, language variety, speech
characteristics, and noise perturbation. We propose a model-agnostic toolkit
LAUG to approximate natural language perturbations for testing the robustness
issues in task-oriented dialog. Four data augmentation approaches covering the
three aspects are assembled in LAUG, which reveals critical robustness issues
in state-of-the-art models. The augmented dataset through LAUG can be used to
facilitate future research on the robustness testing of language understanding
in task-oriented dialog.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction or Comparison: Toward Interpretable Qualitative Reasoning. (arXiv:2106.02399v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1">Mucheng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Heyan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yang Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02399">
                                    <div class="article-summary-box-inner">
                                        <span>Qualitative relationships illustrate how changing one property (e.g., moving
velocity) affects another (e.g., kinetic energy) and constitutes a considerable
portion of textual knowledge. Current approaches use either semantic parsers to
transform natural language inputs into logical expressions or a &quot;black-box&quot;
model to solve them in one step. The former has a limited application range,
while the latter lacks interpretability. In this work, we categorize
qualitative reasoning tasks into two types: prediction and comparison. In
particular, we adopt neural network modules trained in an end-to-end manner to
simulate the two reasoning processes. Experiments on two qualitative reasoning
question answering datasets, QuaRTz and QuaRel, show our methods&#x27; effectiveness
and generalization capability, and the intermediate outputs provided by the
modules make the reasoning process interpretable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximate Fixed-Points in Recurrent Neural Networks. (arXiv:2106.02417v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Wang_Z/0/1/0/all/0/1">Zhengxiong Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Ragni_A/0/1/0/all/0/1">Anton Ragni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02417">
                                    <div class="article-summary-box-inner">
                                        <span>Recurrent neural networks are widely used in speech and language processing.
Due to dependency on the past, standard algorithms for training these models,
such as back-propagation through time (BPTT), cannot be efficiently
parallelised. Furthermore, applying these models to more complex structures
than sequences requires inference time approximations, which introduce
inconsistency between inference and training. This paper shows that recurrent
neural networks can be reformulated as fixed-points of non-linear equation
systems. These fixed-points can be computed using an iterative algorithm
exactly and in as many iterations as the length of any given sequence. Each
iteration of this algorithm adds one additional Markovian-like order of
dependencies such that upon termination all dependencies modelled by the
recurrent neural networks have been incorporated. Although exact fixed-points
inherit the same parallelization and inconsistency issues, this paper shows
that approximate fixed-points can be computed in parallel and used consistently
in training and inference including tasks such as lattice rescoring.
Experimental validation is performed in two tasks, Penn Tree Bank and
WikiText-2, and shows that approximate fixed-points yield competitive
prediction performance to recurrent neural networks trained using the BPTT
algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Robustness of QA Models to Challenge Sets with Variational Question-Answer Pair Generation. (arXiv:2004.03238v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shinoda_K/0/1/0/all/0/1">Kazutoshi Shinoda</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1">Saku Sugawara</a>, <a href="http://arxiv.org/find/cs/1/au:+Aizawa_A/0/1/0/all/0/1">Akiko Aizawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.03238">
                                    <div class="article-summary-box-inner">
                                        <span>Question answering (QA) models for reading comprehension have achieved
human-level accuracy on in-distribution test sets. However, they have been
demonstrated to lack robustness to challenge sets, whose distribution is
different from that of training sets. Existing data augmentation methods
mitigate this problem by simply augmenting training sets with synthetic
examples sampled from the same distribution as the challenge sets. However,
these methods assume that the distribution of a challenge set is known a
priori, making them less applicable to unseen challenge sets. In this study, we
focus on question-answer pair generation (QAG) to mitigate this problem. While
most existing QAG methods aim to improve the quality of synthetic examples, we
conjecture that diversity-promoting QAG can mitigate the sparsity of training
sets and lead to better robustness. We present a variational QAG model that
generates multiple diverse QA pairs from a paragraph. Our experiments show that
our method can improve the accuracy of 12 challenge sets, as well as the
in-distribution accuracy. Our code and data are available at
https://github.com/KazutoshiShinoda/VQAG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Teaching keyword spotters to spot new keywords with limited examples. (arXiv:2106.02443v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Awasthi_A/0/1/0/all/0/1">Abhijeet Awasthi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kilgour_K/0/1/0/all/0/1">Kevin Kilgour</a>, <a href="http://arxiv.org/find/eess/1/au:+Rom_H/0/1/0/all/0/1">Hassan Rom</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02443">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to recognize new keywords with just a few examples is essential for
personalizing keyword spotting (KWS) models to a user&#x27;s choice of keywords.
However, modern KWS models are typically trained on large datasets and
restricted to a small vocabulary of keywords, limiting their transferability to
a broad range of unseen keywords. Towards easily customizable KWS models, we
present KeySEM (Keyword Speech EMbedding), a speech embedding model pre-trained
on the task of recognizing a large number of keywords. Speech representations
offered by KeySEM are highly effective for learning new keywords from a limited
number of examples. Comparisons with a diverse range of related work across
several datasets show that our method achieves consistently superior
performance with fewer training examples. Although KeySEM was pre-trained only
on English utterances, the performance gains also extend to datasets from four
other languages indicating that KeySEM learns useful representations well
aligned with the task of keyword spotting. Finally, we demonstrate KeySEM&#x27;s
ability to learn new keywords sequentially without requiring to re-train on
previously learned keywords. Our experimental observations suggest that KeySEM
is well suited to on-device environments where post-deployment learning and
ease of customization are often desirable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hidden Backdoors in Human-Centric Language Models. (arXiv:2105.00164v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shaofeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_T/0/1/0/all/0/1">Tian Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_B/0/1/0/all/0/1">Benjamin Zi Hao Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_M/0/1/0/all/0/1">Minhui Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Haojin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jialiang Lu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00164">
                                    <div class="article-summary-box-inner">
                                        <span>Natural language processing (NLP) systems have been proven to be vulnerable
to backdoor attacks, whereby hidden features (backdoors) are trained into a
language model and may only be activated by specific inputs (called triggers),
to trick the model into producing unexpected behaviors. In this paper, we
create covert and natural triggers for textual backdoor attacks, \textit{hidden
backdoors}, where triggers can fool both modern language models and human
inspection. We deploy our hidden backdoors through two state-of-the-art trigger
embedding methods. The first approach via homograph replacement, embeds the
trigger into deep neural networks through the visual spoofing of lookalike
character replacement. The second approach uses subtle differences between text
generated by language models and real natural text to produce trigger sentences
with correct grammar and high fluency. We demonstrate that the proposed hidden
backdoors can be effective across three downstream security-critical NLP tasks,
representative of modern human-centric NLP systems, including toxic comment
detection, neural machine translation (NMT), and question answering (QA). Our
two hidden backdoor attacks can achieve an Attack Success Rate (ASR) of at
least $97\%$ with an injection rate of only $3\%$ in toxic comment detection,
$95.1\%$ ASR in NMT with less than $0.5\%$ injected data, and finally $91.12\%$
ASR against QA updated with only 27 poisoning data samples on a model
previously trained with 92,024 samples (0.029\%). We are able to demonstrate
the adversary&#x27;s high success rate of attacks, while maintaining functionality
for regular users, with triggers inconspicuous by the human administrators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Recurrent Neural Networks with Mixed Hierarchical Structures for Natural Language Processing. (arXiv:2106.02562v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zhaoxin Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1">Michael Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02562">
                                    <div class="article-summary-box-inner">
                                        <span>Hierarchical structures exist in both linguistics and Natural Language
Processing (NLP) tasks. How to design RNNs to learn hierarchical
representations of natural languages remains a long-standing challenge. In this
paper, we define two different types of boundaries referred to as static and
dynamic boundaries, respectively, and then use them to construct a multi-layer
hierarchical structure for document classification tasks. In particular, we
focus on a three-layer hierarchical structure with static word- and sentence-
layers and a dynamic phrase-layer. LSTM cells and two boundary detectors are
used to implement the proposed structure, and the resulting network is called
the {\em Recurrent Neural Network with Mixed Hierarchical Structures}
(MHS-RNN). We further add three layers of attention mechanisms to the MHS-RNN
model. Incorporating attention mechanisms allows our model to use more
important content to construct document representation and enhance its
performance on document classification tasks. Experiments on five different
datasets show that the proposed architecture outperforms previous methods on
all the five tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WeChat AI &amp; ICT&#x27;s Submission for DSTC9 Interactive Dialogue Evaluation Track. (arXiv:2101.07947v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zekang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zongjia Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jinchao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07947">
                                    <div class="article-summary-box-inner">
                                        <span>We participate in the DSTC9 Interactive Dialogue Evaluation Track (Gunasekara
et al. 2020) sub-task 1 (Knowledge Grounded Dialogue) and sub-task 2
(Interactive Dialogue). In sub-task 1, we employ a pre-trained language model
to generate topic-related responses and propose a response ensemble method for
response selection. In sub-task2, we propose a novel Dialogue Planning Model
(DPM) to capture conversation flow in the interaction with humans. We also
design an integrated open-domain dialogue system containing pre-process,
dialogue model, scoring model, and post-process, which can generate fluent,
coherent, consistent, and humanlike responses. We tie 1st on human ratings and
also get the highest Meteor, and Bert-score in sub-task 1, and rank 3rd on
interactive human evaluation in sub-task 2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On (co-lex) Ordering Automata. (arXiv:2106.02309v1 [cs.FL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+DAgostino_G/0/1/0/all/0/1">Giovanna D&#x27;Agostino</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotumaccio_N/0/1/0/all/0/1">Nicola Cotumaccio</a>, <a href="http://arxiv.org/find/cs/1/au:+Policriti_A/0/1/0/all/0/1">Alberto Policriti</a>, <a href="http://arxiv.org/find/cs/1/au:+Prezza_N/0/1/0/all/0/1">Nicola Prezza</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02309">
                                    <div class="article-summary-box-inner">
                                        <span>The states of a deterministic finite automaton A can be identified with
collections of words in Pf(L(A)) -- the set of prefixes of words belonging to
the regular language accepted by A. But words can be ordered and among the many
possible orders a very natural one is the co-lexicographic one. Such
naturalness stems from the fact that it suggests a transfer of the order from
words to the automaton&#x27;s states. In a number of papers automata admitting a
total ordering of states coherent with the ordering of the set of words
reaching them have been proposed. Such class of ordered automata -- the Wheeler
automata -- turned out to be efficiently stored/searched using an index.
Unfortunately not all automata can be totally ordered as previously outlined.
However, automata can always be partially ordered and an intrinsic measure of
their complexity can be defined and effectively determined, as the minimum
width of one of their admissible partial orders. As shown in previous works,
this new concept of width of an automaton has useful consequences in the fields
of graph compression, indexing data structures, and automata theory. In this
paper we prove that a canonical, minimum-width, partially-ordered automaton
accepting a language L -- dubbed the Hasse automaton H of L -- can be
exhibited. H provides, in a precise sense, the best possible way to (partially)
order the states of any automaton accepting L, as long as we want to maintain
an operational link with the (co-lexicographic) order of Pf(L(A)). Using H we
prove that the width of the language can be effectively computed from the
minimum automaton recognizing the language. Finally, we explore the
relationship between two (often conflicting) objectives: minimizing the width
and minimizing the number of states of an automaton.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Model Metrics and Procrustes Analysis for Improved Vector Transformation of NLP Embeddings. (arXiv:2106.02490v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conley_T/0/1/0/all/0/1">Thomas Conley</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1">Jugal Kalita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02490">
                                    <div class="article-summary-box-inner">
                                        <span>Artificial Neural networks are mathematical models at their core. This
truismpresents some fundamental difficulty when networks are tasked with
Natural Language Processing. A key problem lies in measuring the similarity or
distance among vectors in NLP embedding space, since the mathematical concept
of distance does not always agree with the linguistic concept. We suggest that
the best way to measure linguistic distance among vectors is by employing the
Language Model (LM) that created them. We introduce Language Model Distance
(LMD) for measuring accuracy of vector transformations based on the
Distributional Hypothesis ( LMD Accuracy ). We show the efficacy of this metric
by applying it to a simple neural network learning the Procrustes algorithm for
bilingual word mapping.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why does CTC result in peaky behavior?. (arXiv:2105.14849v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1">Albert Zeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14849">
                                    <div class="article-summary-box-inner">
                                        <span>The peaky behavior of CTC models is well known experimentally. However, an
understanding about why peaky behavior occurs is missing, and whether this is a
good property. We provide a formal analysis of the peaky behavior and gradient
descent convergence properties of the CTC loss and related training criteria.
Our analysis provides a deep understanding why peaky behavior occurs and when
it is suboptimal. On a simple example which should be trivial to learn for any
model, we prove that a feed-forward neural network trained with CTC from
uniform initialization converges towards peaky behavior with a 100% error rate.
Our analysis further explains why CTC only works well together with the blank
label. We further demonstrate that peaky behavior does not occur on other
related losses including a label prior model, and that this improves
convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLIP: A Dataset for Extracting Action Items for Physicians from Hospital Discharge Notes. (arXiv:2106.02524v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mullenbach_J/0/1/0/all/0/1">James Mullenbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Pruksachatkun_Y/0/1/0/all/0/1">Yada Pruksachatkun</a>, <a href="http://arxiv.org/find/cs/1/au:+Adler_S/0/1/0/all/0/1">Sean Adler</a>, <a href="http://arxiv.org/find/cs/1/au:+Seale_J/0/1/0/all/0/1">Jennifer Seale</a>, <a href="http://arxiv.org/find/cs/1/au:+Swartz_J/0/1/0/all/0/1">Jordan Swartz</a>, <a href="http://arxiv.org/find/cs/1/au:+McKelvey_T/0/1/0/all/0/1">T. Greg McKelvey</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1">David Sontag</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02524">
                                    <div class="article-summary-box-inner">
                                        <span>Continuity of care is crucial to ensuring positive health outcomes for
patients discharged from an inpatient hospital setting, and improved
information sharing can help. To share information, caregivers write discharge
notes containing action items to share with patients and their future
caregivers, but these action items are easily lost due to the lengthiness of
the documents. In this work, we describe our creation of a dataset of clinical
action items annotated over MIMIC-III, the largest publicly available dataset
of real clinical notes. This dataset, which we call CLIP, is annotated by
physicians and covers 718 documents representing 100K sentences. We describe
the task of extracting the action items from these documents as multi-aspect
extractive summarization, with each aspect representing a type of action to be
taken. We evaluate several machine learning models on this task, and show that
the best models exploit in-domain language model pre-training on 59K
unannotated documents, and incorporate context from neighboring sentences. We
also propose an approach to pre-training data selection that allows us to
explore the trade-off between size and domain-specificity of pre-training
datasets for this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization and Completion. (arXiv:2004.13631v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shengding Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1">Xin Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jie Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juanzi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.13631">
                                    <div class="article-summary-box-inner">
                                        <span>A comprehensive knowledge graph (KG) contains an instance-level entity graph
and an ontology-level concept graph. The two-view KG provides a testbed for
models to &quot;simulate&quot; human&#x27;s abilities on knowledge abstraction,
concretization, and completion (KACC), which are crucial for human to recognize
the world and manage learned knowledge. Existing studies mainly focus on
partial aspects of KACC. In order to promote thorough analyses for KACC
abilities of models, we propose a unified KG benchmark by improving existing
benchmarks in terms of dataset scale, task coverage, and difficulty.
Specifically, we collect new datasets that contain larger concept graphs,
abundant cross-view links as well as dense entity graphs. Based on the
datasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA),
multi-hop knowledge concretization (MKC) and then design a comprehensive
benchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical
triples as harder samples. The experimental results of existing methods
demonstrate the challenges of our benchmark. The resource is available at
https://github.com/thunlp/KACC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Great Service! Fine-grained Parsing of Implicit Arguments. (arXiv:2106.02561v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_R/0/1/0/all/0/1">Ruixiang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hershcovich_D/0/1/0/all/0/1">Daniel Hershcovich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02561">
                                    <div class="article-summary-box-inner">
                                        <span>Broad-coverage meaning representations in NLP mostly focus on explicitly
expressed content. More importantly, the scarcity of datasets annotating
diverse implicit roles limits empirical studies into their linguistic nuances.
For example, in the web review &quot;Great service!&quot;, the provider and consumer are
implicit arguments of different types. We examine an annotated corpus of
fine-grained implicit arguments (Cui and Hershcovich, 2020) by carefully
re-annotating it, resolving several inconsistencies. Subsequently, we present
the first transition-based neural parser that can handle implicit arguments
dynamically, and experiment with two different transition systems on the
improved dataset. We find that certain types of implicit arguments are more
difficult to parse than others and that the simpler system is more accurate in
recovering implicit arguments, despite having a lower overall parsing score,
attesting current reasoning limitations of NLP models. This work will
facilitate a better understanding of implicit and underspecified language, by
incorporating it holistically into meaning representations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural semi-Markov CRF for Monolingual Word Alignment. (arXiv:2106.02569v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lan_W/0/1/0/all/0/1">Wuwei Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1">Chao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02569">
                                    <div class="article-summary-box-inner">
                                        <span>Monolingual word alignment is important for studying fine-grained editing
operations (i.e., deletion, addition, and substitution) in text-to-text
generation tasks, such as paraphrase generation, text simplification,
neutralizing biased language, etc. In this paper, we present a novel neural
semi-Markov CRF alignment model, which unifies word and phrase alignments
through variable-length spans. We also create a new benchmark with human
annotations that cover four different text genres to evaluate monolingual word
alignment models in more realistic settings. Experimental results show that our
proposed model outperforms all previous approaches for monolingual word
alignment as well as a competitive QA-based baseline, which was previously only
applied to bilingual data. Our model demonstrates good generalizability to
three out-of-domain datasets and shows great utility in two downstream
applications: automatic text simplification and sentence pair classification
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">cs60075_team2 at SemEval-2021 Task 1 : Lexical Complexity Prediction using Transformer-based Language Models pre-trained on various text corpora. (arXiv:2106.02340v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nandy_A/0/1/0/all/0/1">Abhilash Nandy</a>, <a href="http://arxiv.org/find/cs/1/au:+Adak_S/0/1/0/all/0/1">Sayantan Adak</a>, <a href="http://arxiv.org/find/cs/1/au:+Halder_T/0/1/0/all/0/1">Tanurima Halder</a>, <a href="http://arxiv.org/find/cs/1/au:+Pokala_S/0/1/0/all/0/1">Sai Mahesh Pokala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02340">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the performance of the team cs60075_team2 at SemEval
2021 Task 1 - Lexical Complexity Prediction. The main contribution of this
paper is to fine-tune transformer-based language models pre-trained on several
text corpora, some being general (E.g., Wikipedia, BooksCorpus), some being the
corpora from which the CompLex Dataset was extracted, and others being from
other specific domains such as Finance, Law, etc. We perform ablation studies
on selecting the transformer models and how their individual complexity scores
are aggregated to get the resulting complexity scores. Our method achieves a
best Pearson Correlation of $0.784$ in sub-task 1 (single word) and $0.836$ in
sub-task 2 (multiple word expressions).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Classifying Continuous Constraint Satisfaction problems. (arXiv:2106.02397v1 [cs.CC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Miltzow_T/0/1/0/all/0/1">Tillmann Miltzow</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmiermann_R/0/1/0/all/0/1">Reinier F. Schmiermann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02397">
                                    <div class="article-summary-box-inner">
                                        <span>A continuous constraint satisfaction problem (CCSP) is a constraint
satisfaction problem (CSP) with a domain $U \subset \mathbb{R}$. We engage in a
systematic study to classify CCSPs that are complete of the Existential Theory
of the Reals, i.e., ER-complete. To define this class, we first consider the
problem ETR, which also stands for Existential Theory of the Reals. In an
instance of this problem we are given some sentence of the form $\exists x_1,
\ldots, x_n \in \mathbb{R} : \Phi(x_1, \ldots, x_n)$, where $\Phi$ is a
well-formed quantifier-free formula consisting of the symbols $\{0, 1, +,
\cdot, \geq, &gt;, \wedge, \vee, \neg\}$, the goal is to check whether this
sentence is true. Now the class ER is the family of all problems that admit a
polynomial-time reduction to ETR. It is known that NP $\subseteq$ ER
$\subseteq$ PSPACE.

We restrict our attention on CCSPs with addition constraints ($x + y &#x3D; z$)
and some other mild technical condition. Previously, it was shown that
multiplication constraints ($x \cdot y &#x3D; z$), squaring constraints ($x^2 &#x3D; y$),
or inversion constraints ($x\cdot y &#x3D; 1$) are sufficient to establish
ER-completeness. We extend this in the strongest possible sense for equality
constraints as follows. We show that CCSPs (with addition constraints and some
other mild technical condition) that have any one well-behaved curved equality
constraint ($f(x,y) &#x3D; 0$) are ER-complete. We further extend our results to
inequality constraints. We show that any well-behaved convexly curved and any
well-behaved concavely curved inequality constraint ($f(x,y) \geq 0$ and
$g(x,y) \geq 0$) imply ER-completeness on the class of such CCSPs.

We apply our findings to geometric packing and answer an open question by
Abrahamsen et al. [FOCS 2020]. Namely, we establish ER-completeness of packing
convex pieces into a square container under rotations and translations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Contextualized Knowledge Structures for Commonsense Reasoning. (arXiv:2010.12873v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Raman_M/0/1/0/all/0/1">Mrigank Raman</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1">Aaron Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1">Ryan Rossi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1">Handong Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sungchul Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipka_N/0/1/0/all/0/1">Nedim Lipka</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiang Ren</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12873">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, knowledge graph (KG) augmented models have achieved noteworthy
success on various commonsense reasoning tasks. However, KG edge (fact)
sparsity and noisy edge extraction/generation often hinder models from
obtaining useful knowledge to reason over. To address these issues, we propose
a new KG-augmented model: Hybrid Graph Network (HGN). Unlike prior methods, HGN
learns to jointly contextualize extracted and generated knowledge by reasoning
over both within a unified graph structure. Given the task input context and an
extracted KG subgraph, HGN is trained to generate embeddings for the subgraph&#x27;s
missing edges to form a &quot;hybrid&quot; graph, then reason over the hybrid graph while
filtering out context-irrelevant edges. We demonstrate HGN&#x27;s effectiveness
through considerable performance gains across four commonsense reasoning
benchmarks, plus a user study on edge validness and helpfulness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting Themes within Complex Unstructured Texts: A Case Study on Safeguarding Reports. (arXiv:2010.14584v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Edwards_A/0/1/0/all/0/1">Aleksandra Edwards</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogers_D/0/1/0/all/0/1">David Rogers</a>, <a href="http://arxiv.org/find/cs/1/au:+Camacho_Collados_J/0/1/0/all/0/1">Jose Camacho-Collados</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribaupierre_H/0/1/0/all/0/1">H&#xe9;l&#xe8;ne de Ribaupierre</a>, <a href="http://arxiv.org/find/cs/1/au:+Preece_A/0/1/0/all/0/1">Alun Preece</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.14584">
                                    <div class="article-summary-box-inner">
                                        <span>The task of text and sentence classification is associated with the need for
large amounts of labelled training data. The acquisition of high volumes of
labelled datasets can be expensive or unfeasible, especially for
highly-specialised domains for which documents are hard to obtain. Research on
the application of supervised classification based on small amounts of training
data is limited. In this paper, we address the combination of state-of-the-art
deep learning and classification methods and provide an insight into what
combination of methods fit the needs of small, domain-specific, and
terminologically-rich corpora. We focus on a real-world scenario related to a
collection of safeguarding reports comprising learning experiences and
reflections on tackling serious incidents involving children and vulnerable
adults. The relatively small volume of available reports and their use of
highly domain-specific terminology makes the application of automated
approaches difficult. We focus on the problem of automatically identifying the
main themes in a safeguarding report using supervised classification
approaches. Our results show the potential of deep learning models to simulate
subject-expert behaviour even for complex tasks with limited labelled data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Negation in Cognitive Reasoning. (arXiv:2012.12641v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Schon_C/0/1/0/all/0/1">Claudia Schon</a>, <a href="http://arxiv.org/find/cs/1/au:+Siebert_S/0/1/0/all/0/1">Sophie Siebert</a>, <a href="http://arxiv.org/find/cs/1/au:+Stolzenburg_F/0/1/0/all/0/1">Frieder Stolzenburg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12641">
                                    <div class="article-summary-box-inner">
                                        <span>Negation is both an operation in formal logic and in natural language by
which a proposition is replaced by one stating the opposite, as by the addition
of &quot;not&quot; or another negation cue. Treating negation in an adequate way is
required for cognitive reasoning, which aims at modeling the human ability to
draw meaningful conclusions despite incomplete and inconsistent knowledge. One
task of cognitive reasoning is answering questions given by sentences in
natural language. There are tools based on discourse representation theory to
convert sentences automatically into a formal logic representation, and
additional knowledge can be added using the predicate names in the formula and
knowledge databases. However, the knowledge in logic databases in practice
always is incomplete. Hence, forward reasoning of automated reasoning systems
alone does not suffice to derive answers to questions because, instead of
complete proofs, often only partial positive knowledge can be derived, while
negative knowledge is used only during the reasoning process. In consequence,
we aim at eliminating syntactic negation, strictly speaking, the negated event
or property. In this paper, we describe an effective procedure to determine the
negated event or property in order to replace it by its inverse. This lays the
basis of cognitive reasoning, employing both logic and machine learning for
general question answering. We evaluate our procedure by several benchmarks and
demonstrate its practical usefulness in our cognitive reasoning system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Entity Concept-enhanced Few-shot Relation Extraction. (arXiv:2106.02401v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Guanglin Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qinghua Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1">Shiliang Pu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02401">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot relation extraction (FSRE) is of great importance in long-tail
distribution problem, especially in special domain with low-resource data. Most
existing FSRE algorithms fail to accurately classify the relations merely based
on the information of the sentences together with the recognized entity pairs,
due to limited samples and lack of knowledge. To address this problem, in this
paper, we proposed a novel entity CONCEPT-enhanced FEw-shot Relation Extraction
scheme (ConceptFERE), which introduces the inherent concepts of entities to
provide clues for relation prediction and boost the relations classification
performance. Firstly, a concept-sentence attention module is developed to
select the most appropriate concept from multiple concepts of each entity by
calculating the semantic similarity between sentences and concepts. Secondly, a
self-attention based fusion module is presented to bridge the gap of concept
embedding and sentence embedding from different semantic spaces. Extensive
experiments on the FSRE benchmark dataset FewRel have demonstrated the
effectiveness and the superiority of the proposed ConceptFERE scheme as
compared to the state-of-the-art baselines. Code is available at
https://github.com/LittleGuoKe/ConceptFERE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowing the No-match: Entity Alignment with Dangling Cases. (arXiv:2106.02248v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zequn Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Muhao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02248">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies a new problem setting of entity alignment for knowledge
graphs (KGs). Since KGs possess different sets of entities, there could be
entities that cannot find alignment across them, leading to the problem of
dangling entities. As the first attempt to this problem, we construct a new
dataset and design a multi-task learning framework for both entity alignment
and dangling entity detection. The framework can opt to abstain from predicting
alignment for the detected dangling entities. We propose three techniques for
dangling entity detection that are based on the distribution of
nearest-neighbor distances, i.e., nearest neighbor classification, marginal
ranking and background ranking. After detecting and removing dangling entities,
an incorporated entity alignment model in our framework can provide more robust
alignment for remaining entities. Comprehensive experiments and analyses
demonstrate the effectiveness of our framework. We further discover that the
dangling entity detection module can, in turn, improve alignment learning and
the final performance. The contributed resource is publicly available to foster
further research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Retrieve &amp; Memorize: Dialog Policy Learning with Multi-Action Memory. (arXiv:2106.02317v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yunyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1">Xiaojun Quan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1">Jianxing Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02317">
                                    <div class="article-summary-box-inner">
                                        <span>Dialogue policy learning, a subtask that determines the content of system
response generation and then the degree of task completion, is essential for
task-oriented dialogue systems. However, the unbalanced distribution of system
actions in dialogue datasets often causes difficulty in learning to generate
desired actions and responses. In this paper, we propose a
retrieve-and-memorize framework to enhance the learning of system actions.
Specially, we first design a neural context-aware retrieval module to retrieve
multiple candidate system actions from the training set given a dialogue
context. Then, we propose a memory-augmented multi-decoder network to generate
the system actions conditioned on the candidate actions, which allows the
network to adaptively select key information in the candidate actions and
ignore noises. We conduct experiments on the large-scale multi-domain
task-oriented dialogue dataset MultiWOZ 2.0 and MultiWOZ 2.1.~Experimental
results show that our method achieves competitive performance among several
state-of-the-art models in the context-to-response generation task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regular Expressions for Fast-response COVID-19 Text Classification. (arXiv:2102.09507v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1">Igor L. Markov</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jacqueline Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vagner_A/0/1/0/all/0/1">Adam Vagner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09507">
                                    <div class="article-summary-box-inner">
                                        <span>Text classifiers are at the core of many NLP applications and use a variety
of algorithmic approaches and software. This paper introduces infrastructure
and methodologies for text classifiers based on large-scale regular
expressions. In particular, we describe how Facebook determines if a given
piece of text - anything from a hashtag to a post - belongs to a narrow topic
such as COVID-19. To fully define a topic and evaluate classifier performance
we employ human-guided iterations of keyword discovery, but do not require
labeled data. For COVID-19, we build two sets of regular expressions: (1) for
66 languages, with 99% precision and recall &gt;50%, (2) for the 11 most common
languages, with precision &gt;90% and recall &gt;90%. Regular expressions enable
low-latency queries from multiple platforms. Response to challenges like
COVID-19 is fast and so are revisions. Comparisons to a DNN classifier show
explainable results, higher precision and recall, and less overfitting. Our
learnings can be applied to other narrow-topic classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MERLOT: Multimodal Neural Script Knowledge Models. (arXiv:2106.02636v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1">Rowan Zellers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Ximing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1">Jack Hessel</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youngjae Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jae Sung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jize Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02636">
                                    <div class="article-summary-box-inner">
                                        <span>As humans, we understand events in the visual world contextually, performing
multimodal reasoning across time to make inferences about the past, present,
and future. We introduce MERLOT, a model that learns multimodal script
knowledge by watching millions of YouTube videos with transcribed speech -- in
an entirely label-free, self-supervised manner. By pretraining with a mix of
both frame-level (spatial) and video-level (temporal) objectives, our model not
only learns to match images to temporally corresponding words, but also to
contextualize what is happening globally over time. As a result, MERLOT
exhibits strong out-of-the-box representations of temporal commonsense, and
achieves state-of-the-art performance on 12 different video QA datasets when
finetuned. It also transfers well to the world of static images, allowing
models to reason about the dynamic context behind visual scenes. On Visual
Commonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,
outperforming state-of-the-art models of similar size by over 3%, even those
that make heavy use of auxiliary supervised data (like object bounding boxes).

Ablation analyses demonstrate the complementary importance of: 1) training on
videos versus static images; 2) scaling the magnitude and diversity of the
pretraining video corpus; and 3) using diverse objectives that encourage
full-stack multimodal reasoning, from the recognition to cognition level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Annotation Curricula to Implicitly Train Non-Expert Annotators. (arXiv:2106.02382v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Ji-Ung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Klie_J/0/1/0/all/0/1">Jan-Christoph Klie</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02382">
                                    <div class="article-summary-box-inner">
                                        <span>Annotation studies often require annotators to familiarize themselves with
the task, its annotation scheme, and the data domain. This can be overwhelming
in the beginning, mentally taxing, and induce errors into the resulting
annotations; especially in citizen science or crowd sourcing scenarios where
domain expertise is not required and only annotation guidelines are provided.
To alleviate these issues, we propose annotation curricula, a novel approach to
implicitly train annotators. Our goal is to gradually introduce annotators into
the task by ordering instances that are annotated according to a learning
curriculum. To do so, we first formalize annotation curricula for sentence- and
paragraph-level annotation tasks, define an ordering strategy, and identify
well-performing heuristics and interactively trained models on three existing
English datasets. We then conduct a user study with 40 voluntary participants
who are asked to identify the most fitting misconception for English tweets
about the Covid-19 pandemic. Our results show that using a simple heuristic to
order instances can already significantly reduce the total annotation time
while preserving a high annotation quality. Annotation curricula thus can
provide a novel way to improve data collection. To facilitate future research,
we further share our code and data consisting of 2,400 annotations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProofWriter: Generating Implications, Proofs, and Abductive Statements over Natural Language. (arXiv:2012.13048v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tafjord_O/0/1/0/all/0/1">Oyvind Tafjord</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_B/0/1/0/all/0/1">Bhavana Dalvi Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1">Peter Clark</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13048">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have been shown to emulate logical deduction over natural
language theories (logical rules expressed in natural language), reliably
assigning true/false labels to candidate implications. However, their ability
to generate implications of a theory has not yet been demonstrated, and methods
for reconstructing proofs of answers are imperfect. In this work we show that a
generative model, called ProofWriter, can reliably generate both implications
of a theory and the natural language proof(s) that support them. In particular,
iterating a 1-step implication generator results in proofs that are highly
reliable, and represent actual model decisions (rather than post-hoc
rationalizations). On the RuleTaker dataset, the accuracy of ProofWriter&#x27;s
proofs exceed previous methods by +9% absolute, and in a way that generalizes
to proof depths unseen in training and on out-of-domain problems. We also show
that generative techniques can perform a type of abduction with high precision:
Given a theory and an unprovable conclusion, identify a missing fact that
allows the conclusion to be proved, along with a proof. These results
significantly improve the viability of neural methods for systematically
reasoning over natural language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing. (arXiv:2106.02559v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1">Rowan Hall Maudslay</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02559">
                                    <div class="article-summary-box-inner">
                                        <span>Analysing whether neural language models encode linguistic information has
become popular in NLP. One method of doing so, which is frequently cited to
support the claim that models like BERT encode syntax, is called probing;
probes are small supervised models trained to extract linguistic information
from another model&#x27;s output. If a probe is able to predict a particular
structure, it is argued that the model whose output it is trained on must have
implicitly learnt to encode it. However, drawing a generalisation about a
model&#x27;s linguistic knowledge about a specific phenomena based on what a probe
is able to learn may be problematic: in this work, we show that semantic cues
in training data means that syntactic probes do not properly isolate syntax. We
generate a new corpus of semantically nonsensical but syntactically well-formed
Jabberwocky sentences, which we use to evaluate two probes trained on normal
data. We train the probes on several popular language models (BERT, GPT, and
RoBERTa), and find that in all settings they perform worse when evaluated on
these data, for one probe by an average of 15.4 UUAS points absolute. Although
in most cases they still outperform the baselines, their lead is reduced
substantially, e.g. by 53% in the case of BERT for one probe. This begs the
question: what empirical scores constitute knowing syntax?</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Defending Democracy: Using Deep Learning to Identify and Prevent Misinformation. (arXiv:2106.02607v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1">Anusua Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Suhm_A/0/1/0/all/0/1">Alyssa Suhm</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahankal_P/0/1/0/all/0/1">Prathamesh Mahankal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukuntharaj_S/0/1/0/all/0/1">Subhiksha Mukuntharaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Parab_M/0/1/0/all/0/1">Meghana D. Parab</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_M/0/1/0/all/0/1">Malvika Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1">Meredith Berger</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethumadhavan_A/0/1/0/all/0/1">Arathi Sethumadhavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaiman_A/0/1/0/all/0/1">Ashish Jaiman</a>, <a href="http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1">Rahul Dodhia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02607">
                                    <div class="article-summary-box-inner">
                                        <span>The rise in online misinformation in recent years threatens democracies by
distorting authentic public discourse and causing confusion, fear, and even, in
extreme cases, violence. There is a need to understand the spread of false
content through online networks for developing interventions that disrupt
misinformation before it achieves virality. Using a Deep Bidirectional
Transformer for Language Understanding (BERT) and propagation graphs, this
study classifies and visualizes the spread of misinformation on a social media
network using publicly available Twitter data. The results confirm prior
research around user clusters and the virality of false content while improving
the precision of deep learning models for misinformation detection. The study
further demonstrates the suitability of BERT for providing a scalable model for
false information detection, which can contribute to the development of more
timely and accurate interventions to slow the spread of misinformation in
online environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Improved Attention for Visual Question Answering. (arXiv:2011.02164v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1">Tanzila Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Chou_S/0/1/0/all/0/1">Shih-Han Chou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sigal_L/0/1/0/all/0/1">Leonid Sigal</a>, <a href="http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1">Giuseppe Carenini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02164">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of Visual Question Answering (VQA). Given an image
and a free-form, open-ended, question, expressed in natural language, the goal
of VQA system is to provide accurate answer to this question with respect to
the image. The task is challenging because it requires simultaneous and
intricate understanding of both visual and textual information. Attention,
which captures intra- and inter-modal dependencies, has emerged as perhaps the
most widely used mechanism for addressing these challenges. In this paper, we
propose an improved attention-based architecture to solve VQA. We incorporate
an Attention on Attention (AoA) module within encoder-decoder framework, which
is able to determine the relation between attention results and queries.
Attention module generates weighted average for each query. On the other hand,
AoA module first generates an information vector and an attention gate using
attention results and current context; and then adds another attention to
generate final attended information by multiplying the two. We also propose
multimodal fusion module to combine both visual and textual information. The
goal of this fusion module is to dynamically decide how much information should
be considered from each modality. Extensive experiments on VQA-v2 benchmark
dataset show that our method achieves the state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdaTag: Multi-Attribute Value Extraction from Product Profiles with Adaptive Decoding. (arXiv:2106.02318v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Jun Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zalmout_N/0/1/0/all/0/1">Nasser Zalmout</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Grant_C/0/1/0/all/0/1">Christan Grant</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xin Luna Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02318">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic extraction of product attribute values is an important enabling
technology in e-Commerce platforms. This task is usually modeled using sequence
labeling architectures, with several extensions to handle multi-attribute
extraction. One line of previous work constructs attribute-specific models,
through separate decoders or entirely separate models. However, this approach
constrains knowledge sharing across different attributes. Other contributions
use a single multi-attribute model, with different techniques to embed
attribute information. But sharing the entire network parameters across all
attributes can limit the model&#x27;s capacity to capture attribute-specific
characteristics. In this paper we present AdaTag, which uses adaptive decoding
to handle extraction. We parameterize the decoder with pretrained attribute
embeddings, through a hypernetwork and a Mixture-of-Experts (MoE) module. This
allows for separate, but semantically correlated, decoders to be generated on
the fly for different attributes. This approach facilitates knowledge sharing,
while maintaining the specificity of each attribute. Our experiments on a
real-world e-Commerce dataset show marked improvements over previous methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Computer Generated Dialog with Auxiliary Loss Functions and Custom Evaluation Metrics. (arXiv:2106.02516v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Conley_T/0/1/0/all/0/1">Thomas Conley</a>, <a href="http://arxiv.org/find/cs/1/au:+Clair_J/0/1/0/all/0/1">Jack St. Clair</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1">Jugal Kalita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02516">
                                    <div class="article-summary-box-inner">
                                        <span>Although people have the ability to engage in vapid dialogue without effort,
this may not be a uniquely human trait. Since the 1960&#x27;s researchers have been
trying to create agents that can generate artificial conversation. These
programs are commonly known as chatbots. With increasing use of neural networks
for dialog generation, some conclude that this goal has been achieved. This
research joins the quest by creating a dialog generating Recurrent Neural
Network (RNN) and by enhancing the ability of this network with auxiliary loss
functions and a beam search. Our custom loss functions achieve better cohesion
and coherence by including calculations of Maximum Mutual Information (MMI) and
entropy. We demonstrate the effectiveness of this system by using a set of
custom evaluation metrics inspired by an abundance of previous research and
based on tried-and-true principles of Natural Language Processing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact. (arXiv:2106.02359v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhijing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chauhan_G/0/1/0/all/0/1">Geeticka Chauhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tse_B/0/1/0/all/0/1">Brian Tse</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1">Mrinmaya Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02359">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen many breakthroughs in natural language processing
(NLP), transitioning it from a mostly theoretical field to one with many
real-world applications. Noting the rising number of applications of other
machine learning and AI techniques with pervasive societal impact, we
anticipate the rising importance of developing NLP technologies for social
good. Inspired by theories in moral philosophy and global priorities research,
we aim to promote a guideline for social good in the context of NLP. We lay the
foundations via moral philosophy&#x27;s definition of social good, propose a
framework to evaluate NLP tasks&#x27; direct and indirect real-world impact, and
adopt the methodology of global priorities research to identify priority causes
for NLP research. Finally, we use our theoretical framework to provide some
practical guidelines for future NLP research for social good. Our data and
codes are available at this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Scaling for Universal Suggested Replies Model. (arXiv:2106.02232v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ying_Q/0/1/0/all/0/1">Qianlan Ying</a>, <a href="http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1">Payal Bajaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Deb_B/0/1/0/all/0/1">Budhaditya Deb</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yu Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1">Bojia Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1">Milad Shokouhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xia Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Daxin Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02232">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of scaling automated suggested replies for Outlook
email system to multiple languages. Faced with increased compute requirements
and low resources for language expansion, we build a single universal model for
improving the quality and reducing run-time costs of our production system.
However, restricted data movement across regional centers prevents joint
training across languages. To this end, we propose a multi-task continual
learning framework, with auxiliary tasks and language adapters to learn
universal language representation across regions. The experimental results show
positive cross-lingual transfer across languages while reducing catastrophic
forgetting across regions. Our online results on real user traffic show
significant gains in CTR and characters saved, as well as 65% training cost
reduction compared with per-language models. As a consequence, we have scaled
the feature in multiple languages including low-resource markets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">You Only Compress Once: Towards Effective and Elastic BERT Compression via Exploit-Explore Stochastic Nature Gradient. (arXiv:2106.02435v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shaokun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1">Xiawu Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chenyi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuchao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_F/0/1/0/all/0/1">Fei Chao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mengdi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1">Rongrong Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02435">
                                    <div class="article-summary-box-inner">
                                        <span>Despite superior performance on various natural language processing tasks,
pre-trained models such as BERT are challenged by deploying on
resource-constraint devices. Most existing model compression approaches require
re-compression or fine-tuning across diverse constraints to accommodate various
hardware deployments. This practically limits the further application of model
compression. Moreover, the ineffective training and searching process of
existing elastic compression paradigms[4,27] prevents the direct migration to
BERT compression. Motivated by the necessity of efficient inference across
various constraints on BERT, we propose a novel approach, YOCO-BERT, to achieve
compress once and deploy everywhere. Specifically, we first construct a huge
search space with 10^13 architectures, which covers nearly all configurations
in BERT model. Then, we propose a novel stochastic nature gradient optimization
method to guide the generation of optimal candidate architecture which could
keep a balanced trade-off between explorations and exploitation. When a certain
resource constraint is given, a lightweight distribution optimization approach
is utilized to obtain the optimal network for target deployment without
fine-tuning. Compared with state-of-the-art algorithms, YOCO-BERT provides more
compact models, yet achieving 2.1%-4.5% average accuracy improvement on the
GLUE benchmark. Besides, YOCO-BERT is also more effective, e.g.,the training
complexity is O(1)for N different devices. Code is
availablehttps://github.com/MAC-AutoML/YOCO-BERT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COINS: Dynamically Generating COntextualized Inference Rules for Narrative Story Completion. (arXiv:2106.02497v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paul_D/0/1/0/all/0/1">Debjit Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_A/0/1/0/all/0/1">Anette Frank</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02497">
                                    <div class="article-summary-box-inner">
                                        <span>Despite recent successes of large pre-trained language models in solving
reasoning tasks, their inference capabilities remain opaque. We posit that such
models can be made more interpretable by explicitly generating interim
inference rules, and using them to guide the generation of task-specific
textual outputs. In this paper we present COINS, a recursive inference
framework that i) iteratively reads context sentences, ii) dynamically
generates contextualized inference rules, encodes them, and iii) uses them to
guide task-specific output generation. We apply COINS to a Narrative Story
Completion task that asks a model to complete a story with missing sentences,
to produce a coherent story with plausible logical connections, causal
relationships, and temporal dependencies. By modularizing inference and
sentence generation steps in a recurrent model, we aim to make reasoning steps
and their effects on next sentence generation transparent. Our automatic and
manual evaluations show that the model generates better story sentences than
SOTA baselines, especially in terms of coherence. We further demonstrate
improved performance over strong pre-trained LMs in generating commonsense
inference rules. The recursive nature of COINS holds the potential for
controlled generation of longer sequences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Understanding and Countering Stereotypes: A Computational Approach to the Stereotype Content Model. (arXiv:2106.02596v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fraser_K/0/1/0/all/0/1">Kathleen C. Fraser</a>, <a href="http://arxiv.org/find/cs/1/au:+Nejadgholi_I/0/1/0/all/0/1">Isar Nejadgholi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiritchenko_S/0/1/0/all/0/1">Svetlana Kiritchenko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02596">
                                    <div class="article-summary-box-inner">
                                        <span>Stereotypical language expresses widely-held beliefs about different social
categories. Many stereotypes are overtly negative, while others may appear
positive on the surface, but still lead to negative consequences. In this work,
we present a computational approach to interpreting stereotypes in text through
the Stereotype Content Model (SCM), a comprehensive causal theory from social
psychology. The SCM proposes that stereotypes can be understood along two
primary dimensions: warmth and competence. We present a method for defining
warmth and competence axes in semantic embedding space, and show that the four
quadrants defined by this subspace accurately represent the warmth and
competence concepts, according to annotated lexicons. We then apply our
computational SCM model to textual stereotype data and show that it compares
favourably with survey-based studies in the psychological literature.
Furthermore, we explore various strategies to counter stereotypical beliefs
with anti-stereotypes. It is known that countering stereotypes with
anti-stereotypical examples is one of the most effective ways to reduce biased
thinking, yet the problem of generating anti-stereotypes has not been
previously studied. Thus, a better understanding of how to generate realistic
and effective anti-stereotypes can contribute to addressing pressing societal
concerns of stereotyping, prejudice, and discrimination.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bi-Granularity Contrastive Learning for Post-Training in Few-Shot Scene. (arXiv:2106.02327v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1">Ruikun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Guanhuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Quan_X/0/1/0/all/0/1">Xiaojun Quan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02327">
                                    <div class="article-summary-box-inner">
                                        <span>The major paradigm of applying a pre-trained language model to downstream
tasks is to fine-tune it on labeled task data, which often suffers instability
and low performance when the labeled examples are scarce.~One way to alleviate
this problem is to apply post-training on unlabeled task data before
fine-tuning, adapting the pre-trained model to target domains by contrastive
learning that considers either token-level or sequence-level similarity.
Inspired by the success of sequence masking, we argue that both token-level and
sequence-level similarities can be captured with a pair of masked
sequences.~Therefore, we propose complementary random masking (CRM) to generate
a pair of masked sequences from an input sequence for sequence-level
contrastive learning and then develop contrastive masked language modeling
(CMLM) for post-training to integrate both token-level and sequence-level
contrastive learnings.~Empirical results show that CMLM surpasses several
recent post-training methods in few-shot settings without the need for data
augmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ERICA: An Empathetic Android Companion for Covid-19 Quarantine. (arXiv:2106.02325v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ishii_E/0/1/0/all/0/1">Etsuko Ishii</a>, <a href="http://arxiv.org/find/cs/1/au:+Winata_G/0/1/0/all/0/1">Genta Indra Winata</a>, <a href="http://arxiv.org/find/cs/1/au:+Cahyawijaya_S/0/1/0/all/0/1">Samuel Cahyawijaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Lala_D/0/1/0/all/0/1">Divesh Lala</a>, <a href="http://arxiv.org/find/cs/1/au:+Kawahara_T/0/1/0/all/0/1">Tatsuya Kawahara</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1">Pascale Fung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02325">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past year, research in various domains, including Natural Language
Processing (NLP), has been accelerated to fight against the COVID-19 pandemic,
yet such research has just started on dialogue systems. In this paper, we
introduce an end-to-end dialogue system which aims to ease the isolation of
people under self-quarantine. We conduct a control simulation experiment to
assess the effects of the user interface, a web-based virtual agent called Nora
vs. the android ERICA via a video call. The experimental results show that the
android offers a more valuable user experience by giving the impression of
being more empathetic and engaging in the conversation due to its nonverbal
information, such as facial expressions and body gestures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER. (arXiv:2106.02300v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weile Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Huiqiang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qianhui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Karlsson_B/0/1/0/all/0/1">B&#xf6;rje F. Karlsson</a>, <a href="http://arxiv.org/find/cs/1/au:+Guan_Y/0/1/0/all/0/1">Yi Guan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02300">
                                    <div class="article-summary-box-inner">
                                        <span>Neural methods have been shown to achieve high performance in Named Entity
Recognition (NER), but rely on costly high-quality labeled data for training,
which is not always available across languages. While previous works have shown
that unlabeled data in a target language can be used to improve cross-lingual
model performance, we propose a novel adversarial approach (AdvPicker) to
better leverage such data and further improve results. We design an adversarial
learning framework in which an encoder learns entity domain knowledge from
labeled source-language data and better shared features are captured via
adversarial training - where a discriminator selects less language-dependent
target-language data via similarity to the source language. Experimental
results on standard benchmark datasets well demonstrate that the proposed
method benefits strongly from this data selection process and outperforms
existing state-of-the-art methods; without requiring any additional external
resources (e.g., gazetteers or via machine translation).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Slice-Aware Representations with Mixture of Attentions. (arXiv:2106.02363v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sungjin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Han Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Young-Bum Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarikaya_R/0/1/0/all/0/1">Ruhi Sarikaya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02363">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world machine learning systems are achieving remarkable performance in
terms of coarse-grained metrics like overall accuracy and F-1 score. However,
model improvement and development often require fine-grained modeling on
individual data subsets or slices, for instance, the data slices where the
models have unsatisfactory results. In practice, it gives tangible values for
developing such models that can pay extra attention to critical or interested
slices while retaining the original overall performance. This work extends the
recent slice-based learning (SBL)~\cite{chen2019slice} with a mixture of
attentions (MoA) to learn slice-aware dual attentive representations. We
empirically show that the MoA approach outperforms the baseline method as well
as the original SBL approach on monitored slices with two natural language
understanding (NLU) tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-language Sentence Selection via Data Augmentation and Rationale Training. (arXiv:2106.02293v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanda Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kedzie_C/0/1/0/all/0/1">Chris Kedzie</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1">Suraj Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Galuscakova_P/0/1/0/all/0/1">Petra Galu&#x161;&#x10d;&#xe1;kov&#xe1;</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Oard_D/0/1/0/all/0/1">Douglas W. Oard</a>, <a href="http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1">Kathleen McKeown</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02293">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes an approach to cross-language sentence selection in a
low-resource setting. It uses data augmentation and negative sampling
techniques on noisy parallel sentence data to directly learn a cross-lingual
embedding-based query relevance model. Results show that this approach performs
as well as or better than multiple state-of-the-art machine translation +
monolingual retrieval systems trained on the same parallel data. Moreover, when
a rationale training secondary objective is applied to encourage the model to
match word alignment hints from a phrase-based statistical machine translation
model, consistent improvements are seen across three language pairs
(English-Somali, English-Swahili and English-Tagalog) over a variety of
state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling the Unigram Distribution. (arXiv:2106.02289v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nikkarinen_I/0/1/0/all/0/1">Irene Nikkarinen</a>, <a href="http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1">Tiago Pimentel</a>, <a href="http://arxiv.org/find/cs/1/au:+Blasi_D/0/1/0/all/0/1">Dami&#xe1;n E. Blasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02289">
                                    <div class="article-summary-box-inner">
                                        <span>The unigram distribution is the non-contextual probability of finding a
specific word form in a corpus. While of central importance to the study of
language, it is commonly approximated by each word&#x27;s sample frequency in the
corpus. This approach, being highly dependent on sample size, assigns zero
probability to any out-of-vocabulary (oov) word form. As a result, it produces
negatively biased probabilities for any oov word form, while positively biased
probabilities to in-corpus words. In this work, we argue in favor of properly
modeling the unigram distribution -- claiming it should be a central task in
natural language processing. With this in mind, we present a novel model for
estimating it in a language (a neuralization of Goldwater et al.&#x27;s (2011)
model) and show it produces much better estimates across a diverse set of 7
languages than the na\&quot;ive use of neural character-level language models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AgreeSum: Agreement-Oriented Multi-Document Summarization. (arXiv:2106.02278v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1">Richard Yuanzhe Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lelkes_A/0/1/0/all/0/1">Adam D. Lelkes</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_V/0/1/0/all/0/1">Vinh Q. Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_C/0/1/0/all/0/1">Cong Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02278">
                                    <div class="article-summary-box-inner">
                                        <span>We aim to renew interest in a particular multi-document summarization (MDS)
task which we call AgreeSum: agreement-oriented multi-document summarization.
Given a cluster of articles, the goal is to provide abstractive summaries that
represent information common and faithful to all input articles. Given the lack
of existing datasets, we create a dataset for AgreeSum, and provide annotations
on article-summary entailment relations for a subset of the clusters in the
dataset. We aim to create strong baselines for the task by applying the
top-performing pretrained single-document summarization model PEGASUS onto
AgreeSum, leveraging both annotated clusters by supervised losses, and
unannotated clusters by T5-based entailment-related and language-related
losses. Compared to other baselines, both automatic evaluation and human
evaluation show better article-summary and cluster-summary entailment in
generated summaries. On a separate note, we hope that our article-summary
entailment annotations contribute to the community&#x27;s effort in improving
abstractive summarization faithfulness.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ERNIE-Tiny : A Progressive Distillation Framework for Pretrained Transformer Compression. (arXiv:2106.02241v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_W/0/1/0/all/0/1">Weiyue Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuyi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shikun Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiaxiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Weixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yu Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_H/0/1/0/all/0/1">Hao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Hua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haifeng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02241">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained language models (PLMs) such as BERT adopt a training paradigm
which first pretrain the model in general data and then finetune the model on
task-specific data, and have recently achieved great success. However, PLMs are
notorious for their enormous parameters and hard to be deployed on real-life
applications. Knowledge distillation has been prevailing to address this
problem by transferring knowledge from a large teacher to a much smaller
student over a set of data. We argue that the selection of thee three key
components, namely teacher, training data, and learning objective, is crucial
to the effectiveness of distillation. We, therefore, propose a four-stage
progressive distillation framework ERNIE-Tiny to compress PLM, which varies the
three components gradually from general level to task-specific level.
Specifically, the first stage, General Distillation, performs distillation with
guidance from pretrained teacher, gerenal data and latent distillation loss.
Then, General-Enhanced Distillation changes teacher model from pretrained
teacher to finetuned teacher. After that, Task-Adaptive Distillation shifts
training data from general data to task-specific data. In the end,
Task-Specific Distillation, adds two additional losses, namely Soft-Label and
Hard-Label loss onto the last stage. Empirical results demonstrate the
effectiveness of our framework and generalization gain brought by ERNIE-Tiny.In
particular, experiments show that a 4-layer ERNIE-Tiny maintains over
98.0%performance of its 12-layer teacher BERT base on GLUE benchmark,
surpassing state-of-the-art (SOTA) by 1.0% GLUE score with the same amount of
parameters. Moreover, ERNIE-Tiny achieves a new compression SOTA on five
Chinese NLP tasks, outperforming BERT base by 0.4% accuracy with 7.5x fewer
parameters and9.4x faster inference speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition. (arXiv:2106.02302v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1">Zhong Meng</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1">Naoyuki Kanda</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1">Liang Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1">Xie Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Ye_G/0/1/0/all/0/1">Guoli Ye</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_E/0/1/0/all/0/1">Eric Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1">Jinyu Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1">Yifan Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02302">
                                    <div class="article-summary-box-inner">
                                        <span>Integrating external language models (LMs) into end-to-end (E2E) models
remains a challenging task for domain-adaptive speech recognition. Recently,
internal language model estimation (ILME)-based LM fusion has shown significant
word error rate (WER) reduction from Shallow Fusion by subtracting a weighted
internal LM score from an interpolation of E2E model and external LM scores
during beam search. However, on different test sets, the optimal LM
interpolation weights vary over a wide range and have to be tuned extensively
on well-matched validation sets. In this work, we perform LM fusion in the
minimum WER (MWER) training of an E2E model to obviate the need for LM weights
tuning during inference. Besides MWER training with Shallow Fusion (MWER-SF),
we propose a novel MWER training with ILME (MWER-ILME) where the ILME-based
fusion is conducted to generate N-best hypotheses and their posteriors.
Additional gradient is induced when internal LM is engaged in MWER-ILME loss
computation. During inference, LM weights pre-determined in MWER training
enable robust LM integrations on test sets from different domains. Experimented
with 30K-hour trained transformer transducers, MWER-ILME achieves on average
8.8% and 5.8% relative WER reductions from MWER and MWER-SF training,
respectively, on 6 different test sets</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to Adapt Your Pretrained Multilingual Model to 1600 Languages. (arXiv:2106.02124v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ebrahimi_A/0/1/0/all/0/1">Abteen Ebrahimi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kann_K/0/1/0/all/0/1">Katharina Kann</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02124">
                                    <div class="article-summary-box-inner">
                                        <span>Pretrained multilingual models (PMMs) enable zero-shot learning via
cross-lingual transfer, performing best for languages seen during pretraining.
While methods exist to improve performance for unseen languages, they have
almost exclusively been evaluated using amounts of raw text only available for
a small fraction of the world&#x27;s languages. In this paper, we evaluate the
performance of existing methods to adapt PMMs to new languages using a resource
available for over 1600 languages: the New Testament. This is challenging for
two reasons: (1) the small corpus size, and (2) the narrow domain. While
performance drops for all approaches, we surprisingly still see gains of up to
$17.69\%$ accuracy for part-of-speech tagging and $6.29$ F1 for NER on average
over all languages as compared to XLM-R. Another unexpected finding is that
continued pretraining, the simplest approach, performs best. Finally, we
perform a case study to disentangle the effects of domain and size and to shed
light on the influence of the finetuning source language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NAST: A Non-Autoregressive Generator with Word Alignment for Unsupervised Text Style Transfer. (arXiv:2106.02210v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zikai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chen Henry Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qihan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1">Xiaoyan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02210">
                                    <div class="article-summary-box-inner">
                                        <span>Autoregressive models have been widely used in unsupervised text style
transfer. Despite their success, these models still suffer from the content
preservation problem that they usually ignore part of the source sentence and
generate some irrelevant words with strong styles. In this paper, we propose a
Non-Autoregressive generator for unsupervised text Style Transfer (NAST), which
alleviates the problem from two aspects. First, we observe that most words in
the transferred sentence can be aligned with related words in the source
sentence, so we explicitly model word alignments to suppress irrelevant words.
Second, existing models trained with the cycle loss align sentences in two
stylistic text spaces, which lacks fine-grained control at the word level. The
proposed non-autoregressive generator focuses on the connections between
aligned words, which learns the word-level transfer between styles. For
experiments, we integrate the proposed generator into two base models and
evaluate them on two style transfer tasks. The results show that NAST can
significantly improve the overall performance and provide explainable word
alignments. Moreover, the non-autoregressive generator achieves over 10x
speedups at inference. Our codes are available at
https://github.com/thu-coai/NAST.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dutch Named Entity Recognition and De-identification Methods for the Human Resource Domain. (arXiv:2106.02287v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Toledo_C/0/1/0/all/0/1">Cha&#xef;m van Toledo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dijk_F/0/1/0/all/0/1">Friso van Dijk</a>, <a href="http://arxiv.org/find/cs/1/au:+Spruit_M/0/1/0/all/0/1">Marco Spruit</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02287">
                                    <div class="article-summary-box-inner">
                                        <span>The human resource (HR) domain contains various types of privacy-sensitive
textual data, such as e-mail correspondence and performance appraisal. Doing
research on these documents brings several challenges, one of them
anonymisation. In this paper, we evaluate the current Dutch text
de-identification methods for the HR domain in four steps. First, by updating
one of these methods with the latest named entity recognition (NER) models. The
result is that the NER model based on the CoNLL 2002 corpus in combination with
the BERTje transformer give the best combination for suppressing persons
(recall 0.94) and locations (recall 0.82). For suppressing gender, DEDUCE is
performing best (recall 0.53). Second NER evaluation is based on both strict
de-identification of entities (a person must be suppressed as a person) and
third evaluation on a loose sense of de-identification (no matter what how a
person is suppressed, as long it is suppressed). In the fourth and last step a
new kind of NER dataset is tested for recognising job titles in texts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human-Adversarial Visual Question Answering. (arXiv:2106.02280v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheng_S/0/1/0/all/0/1">Sasha Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Amanpreet Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1">Vedanuj Goswami</a>, <a href="http://arxiv.org/find/cs/1/au:+Magana_J/0/1/0/all/0/1">Jose Alberto Lopez Magana</a>, <a href="http://arxiv.org/find/cs/1/au:+Galuba_W/0/1/0/all/0/1">Wojciech Galuba</a>, <a href="http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1">Devi Parikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02280">
                                    <div class="article-summary-box-inner">
                                        <span>Performance on the most commonly used Visual Question Answering dataset (VQA
v2) is starting to approach human accuracy. However, in interacting with
state-of-the-art VQA models, it is clear that the problem is far from being
solved. In order to stress test VQA models, we benchmark them against
human-adversarial examples. Human subjects interact with a state-of-the-art VQA
model, and for each image in the dataset, attempt to find a question where the
model&#x27;s predicted answer is incorrect. We find that a wide range of
state-of-the-art models perform poorly when evaluated on these examples. We
conduct an extensive analysis of the collected adversarial examples and provide
guidance on future research directions. We hope that this Adversarial VQA
(AdVQA) benchmark can help drive progress in the field and advance the state of
the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conversations Are Not Flat: Modeling the Dynamic Information Flow across Dialogue Utterances. (arXiv:2106.02227v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zekang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jinchao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1">Zhengcong Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02227">
                                    <div class="article-summary-box-inner">
                                        <span>Nowadays, open-domain dialogue models can generate acceptable responses
according to the historical context based on the large-scale pre-trained
language models. However, they generally concatenate the dialogue history
directly as the model input to predict the response, which we named as the flat
pattern and ignores the dynamic information flow across dialogue utterances. In
this work, we propose the DialoFlow model, in which we introduce a dynamic flow
mechanism to model the context flow, and design three training objectives to
capture the information dynamics across dialogue utterances by addressing the
semantic influence brought about by each utterance in large-scale pre-training.
Experiments on the multi-reference Reddit Dataset and DailyDialog Dataset
demonstrate that our DialoFlow significantly outperforms the DialoGPT on the
dialogue generation task. Besides, we propose the Flow score, an effective
automatic metric for evaluating interactive human-bot conversation quality
based on the pre-trained DialoFlow, which presents high chatbot-level
correlation ($r&#x3D;0.9$) with human ratings among 11 chatbots. Code and
pre-trained models will be public.
\footnote{\url{https://github.com/ictnlp/DialoFlow}}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decoupled Dialogue Modeling and Semantic Parsing for Multi-Turn Text-to-SQL. (arXiv:2106.02282v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lu Chen Hanqi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1">Ruisheng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_D/0/1/0/all/0/1">Da Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Mengyue Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1">Kai Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02282">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Text-to-SQL for multi-turn dialogue has attracted great interest.
Here, the user input of the current turn is parsed into the corresponding SQL
query of the appropriate database, given all previous dialogue history. Current
approaches mostly employ end-to-end models and consequently face two
challenges. First, dialogue history modeling and Text-to-SQL parsing are
implicitly combined, hence it is hard to carry out interpretable analysis and
obtain targeted improvement. Second, SQL annotation of multi-turn dialogue is
very expensive, leading to training data sparsity. In this paper, we propose a
novel decoupled multi-turn Text-to-SQL framework, where an utterance rewrite
model first explicitly solves completion of dialogue context, and then a
single-turn Text-to-SQL parser follows. A dual learning approach is also
proposed for the utterance rewrite model to address the data sparsity problem.
Compared with end-to-end approaches, the proposed decoupled method can achieve
excellent performance without any annotated in-domain data. With just a few
annotated rewrite cases, the decoupled method outperforms the released
state-of-the-art end-to-end models on both SParC and CoSQL datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Syntax-augmented Multilingual BERT for Cross-lingual Transfer. (arXiv:2106.02134v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ahmad_W/0/1/0/all/0/1">Wasi Uddin Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoran Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1">Yashar Mehdad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02134">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, we have seen a colossal effort in pre-training multilingual
text encoders using large-scale corpora in many languages to facilitate
cross-lingual transfer learning. However, due to typological differences across
languages, the cross-lingual transfer is challenging. Nevertheless, language
syntax, e.g., syntactic dependencies, can bridge the typological gap. Previous
works have shown that pre-trained multilingual encoders, such as mBERT
\cite{devlin-etal-2019-bert}, capture language syntax, helping cross-lingual
transfer. This work shows that explicitly providing language syntax and
training mBERT using an auxiliary objective to encode the universal dependency
tree structure helps cross-lingual transfer. We perform rigorous experiments on
four NLP tasks, including text classification, question answering, named entity
recognition, and task-oriented semantic parsing. The experiment results show
that syntax-augmented mBERT improves cross-lingual transfer on popular
benchmarks, such as PAWS-X and MLQA, by 1.4 and 1.6 points on average across
all languages. In the \emph{generalized} transfer setting, the performance
boosted significantly, with 3.9 and 3.1 points on average in PAWS-X and MLQA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Scalable Transformers for Neural Machine Translation. (arXiv:2106.02242v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Peng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_S/0/1/0/all/0/1">Shijie Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaogang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Jifeng Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02242">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer has been widely adopted in Neural Machine Translation (NMT)
because of its large capacity and parallel training of sequence generation.
However, the deployment of Transformer is challenging because different
scenarios require models of different complexities and scales. Naively training
multiple Transformers is redundant in terms of both computation and memory. In
this paper, we propose a novel scalable Transformers, which naturally contains
sub-Transformers of different scales and have shared parameters. Each
sub-Transformer can be easily obtained by cropping the parameters of the
largest Transformer. A three-stage training scheme is proposed to tackle the
difficulty of training the scalable Transformers, which introduces additional
supervisions from word-level and sequence-level self-distillation. Extensive
experiments were conducted on WMT EN-De and En-Fr to validate our proposed
scalable Transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation. (arXiv:2106.02170v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bhati_S/0/1/0/all/0/1">Saurabhchand Bhati</a>, <a href="http://arxiv.org/find/eess/1/au:+Villalba_J/0/1/0/all/0/1">Jes&#xfa;s Villalba</a>, <a href="http://arxiv.org/find/eess/1/au:+Zelasko_P/0/1/0/all/0/1">Piotr &#x17b;elasko</a>, <a href="http://arxiv.org/find/eess/1/au:+Moro_Velazquez_L/0/1/0/all/0/1">Laureano Moro-Velazquez</a>, <a href="http://arxiv.org/find/eess/1/au:+Dehak_N/0/1/0/all/0/1">Najim Dehak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02170">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic detection of phoneme or word-like units is one of the core
objectives in zero-resource speech processing. Recent attempts employ
self-supervised training methods, such as contrastive predictive coding (CPC),
where the next frame is predicted given past context. However, CPC only looks
at the audio signal&#x27;s frame-level structure. We overcome this limitation with a
segmental contrastive predictive coding (SCPC) framework that can model the
signal structure at a higher level e.g. at the phoneme level. In this
framework, a convolutional neural network learns frame-level representation
from the raw waveform via noise-contrastive estimation (NCE). A differentiable
boundary detector finds variable-length segments, which are then used to
optimize a segment encoder via NCE to learn segment representations. The
differentiable boundary detector allows us to train frame-level and
segment-level encoders jointly. Typically, phoneme and word segmentation are
treated as separate tasks. We unify them and experimentally show that our
single model outperforms existing phoneme and word segmentation methods on
TIMIT and Buckeye datasets. We analyze the impact of boundary threshold and
when is the right time to include the segmental loss in the learning process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERTTune: Fine-Tuning Neural Machine Translation with BERTScore. (arXiv:2106.02208v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Unanue_I/0/1/0/all/0/1">Inigo Jauregi Unanue</a>, <a href="http://arxiv.org/find/cs/1/au:+Parnell_J/0/1/0/all/0/1">Jacob Parnell</a>, <a href="http://arxiv.org/find/cs/1/au:+Piccardi_M/0/1/0/all/0/1">Massimo Piccardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02208">
                                    <div class="article-summary-box-inner">
                                        <span>Neural machine translation models are often biased toward the limited
translation references seen during training. To amend this form of overfitting,
in this paper we propose fine-tuning the models with a novel training objective
based on the recently-proposed BERTScore evaluation metric. BERTScore is a
scoring function based on contextual embeddings that overcomes the typical
limitations of n-gram-based metrics (e.g. synonyms, paraphrases), allowing
translations that are different from the references, yet close in the
contextual embedding space, to be treated as substantially correct. To be able
to use BERTScore as a training objective, we propose three approaches for
generating soft predictions, allowing the network to remain completely
differentiable end-to-end. Experiments carried out over four, diverse language
pairs have achieved improvements of up to 0.58 pp (3.28%) in BLEU score and up
to 0.76 pp (0.98%) in BERTScore (F_BERT) when fine-tuning a strong baseline.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Language Embeddings for Typology and Cross-lingual Transfer Learning. (arXiv:2106.02082v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_D/0/1/0/all/0/1">Dian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1">Taiqi He</a>, <a href="http://arxiv.org/find/cs/1/au:+Sagae_K/0/1/0/all/0/1">Kenji Sagae</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02082">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-lingual language tasks typically require a substantial amount of
annotated data or parallel translation data. We explore whether language
representations that capture relationships among languages can be learned and
subsequently leveraged in cross-lingual tasks without the use of parallel data.
We generate dense embeddings for 29 languages using a denoising autoencoder,
and evaluate the embeddings using the World Atlas of Language Structures (WALS)
and two extrinsic tasks in a zero-shot setting: cross-lingual dependency
parsing and cross-lingual natural language inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grounding &#x27;Grounding&#x27; in NLP. (arXiv:2106.02192v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chandu_K/0/1/0/all/0/1">Khyathi Raghavi Chandu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bisk_Y/0/1/0/all/0/1">Yonatan Bisk</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1">Alan W Black</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02192">
                                    <div class="article-summary-box-inner">
                                        <span>The NLP community has seen substantial recent interest in grounding to
facilitate interaction between language technologies and the world. However, as
a community, we use the term broadly to reference any linking of text to data
or non-textual modality. In contrast, Cognitive Science more formally defines
&quot;grounding&quot; as the process of establishing what mutual information is required
for successful communication between two interlocutors -- a definition which
might implicitly capture the NLP usage but differs in intent and scope. We
investigate the gap between these definitions and seek answers to the following
questions: (1) What aspects of grounding are missing from NLP tasks? Here we
present the dimensions of coordination, purviews and constraints. (2) How is
the term &quot;grounding&quot; used in the current research? We study the trends in
datasets, domains, and tasks introduced in recent NLP conferences. And finally,
(3) How to advance our current definition to bridge the gap with Cognitive
Science? We present ways to both create new tasks or repurpose existing ones to
make advancements towards achieving a more complete sense of grounding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Addressing Inquiries about History: An Efficient and Practical Framework for Evaluating Open-domain Chatbot Consistency. (arXiv:2106.02228v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zekang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jinchao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fei_Z/0/1/0/all/0/1">Zhengcong Fei</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yang Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02228">
                                    <div class="article-summary-box-inner">
                                        <span>A good open-domain chatbot should avoid presenting contradictory responses
about facts or opinions in a conversational session, known as its consistency
capacity. However, evaluating the consistency capacity of a chatbot is still
challenging. Employing human judges to interact with chatbots on purpose to
check their capacities is costly and low-efficient, and difficult to get rid of
subjective bias. In this paper, we propose the Addressing Inquiries about
History (AIH), an efficient and practical framework for the consistency
evaluation. At the conversation stage, AIH attempts to address appropriate
inquiries about the dialogue history to induce the chatbot to redeclare the
historical facts or opinions. We carry out the conversation between chatbots,
which is more efficient than the human-bot interaction and can also alleviate
the subjective bias. In this way, we manage to rapidly obtain a dialog session
that contains responses with high contradiction possibilities. At the
contradiction recognition stage, we can either employ human judges or a natural
language inference (NLI) model to recognize whether the answers to the
inquiries are contradictory with history. Finally, we are able to rank chatbots
according to the contradiction statistics. Experiments on open-domain chatbots
show that our approach can efficiently and reliably assess the consistency
capacity of chatbots and achieve a high ranking correlation with the human
evaluation. We release the framework and hope to help improve the consistency
capacity of chatbots. \footnote{\url{https://github.com/ictnlp/AIH}}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Dialogue Learning for Spoken Conversational Question Answering. (arXiv:2106.02182v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chenyu You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02182">
                                    <div class="article-summary-box-inner">
                                        <span>In spoken conversational question answering (SCQA), the answer to the
corresponding question is generated by retrieving and then analyzing a fixed
spoken document, including multi-part conversations. Most SCQA systems have
considered only retrieving information from ordered utterances. However, the
sequential order of dialogue is important to build a robust spoken
conversational question answering system, and the changes of utterances order
may severely result in low-quality and incoherent corpora. To this end, we
introduce a self-supervised learning approach, including incoherence
discrimination, insertion detection, and question prediction, to explicitly
capture the coreference resolution and dialogue coherence among spoken
documents. Specifically, we design a joint learning framework where the
auxiliary self-supervised tasks can enable the pre-trained SCQA systems towards
more coherent and meaningful spoken dialogue learning. We also utilize the
proposed self-supervised learning tasks to capture intra-sentence coherence.
Experimental results demonstrate that our proposed method provides more
coherent, meaningful, and appropriate responses, yielding superior performance
gains compared to the original pre-trained language models. Our method achieves
state-of-the-art results on the Spoken-CoQA dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">nmT5 -- Is parallel data still relevant for pre-training massively multilingual language models?. (arXiv:2106.02171v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kale_M/0/1/0/all/0/1">Mihir Kale</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddhant_A/0/1/0/all/0/1">Aditya Siddhant</a>, <a href="http://arxiv.org/find/cs/1/au:+Constant_N/0/1/0/all/0/1">Noah Constant</a>, <a href="http://arxiv.org/find/cs/1/au:+Johnson_M/0/1/0/all/0/1">Melvin Johnson</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Rfou_R/0/1/0/all/0/1">Rami Al-Rfou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_L/0/1/0/all/0/1">Linting Xue</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02171">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, mT5 - a massively multilingual version of T5 - leveraged a unified
text-to-text format to attain state-of-the-art results on a wide variety of
multilingual NLP tasks. In this paper, we investigate the impact of
incorporating parallel data into mT5 pre-training. We find that multi-tasking
language modeling with objectives such as machine translation during
pre-training is a straightforward way to improve performance on downstream
multilingual and cross-lingual tasks. However, the gains start to diminish as
the model capacity increases, suggesting that parallel data might not be as
essential for larger models. At the same time, even at larger model sizes, we
find that pre-training with parallel data still provides benefits in the
limited labelled data regime.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LGBTQ-AI? Exploring Expressions of Gender and Sexual Orientation in Chatbots. (arXiv:2106.02076v1 [cs.HC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Edwards_J/0/1/0/all/0/1">Justin Edwards</a>, <a href="http://arxiv.org/find/cs/1/au:+Clark_L/0/1/0/all/0/1">Leigh Clark</a>, <a href="http://arxiv.org/find/cs/1/au:+Perrone_A/0/1/0/all/0/1">Allison Perrone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02076">
                                    <div class="article-summary-box-inner">
                                        <span>Chatbots are popular machine partners for task-oriented and social
interactions. Human-human computer-mediated communication research has explored
how people express their gender and sexuality in online social interactions,
but little is known about whether and in what way chatbots do the same. We
conducted semi-structured interviews with 5 text-based conversational agents to
explore this topic Through these interviews, we identified 6 common themes
around the expression of gender and sexual identity: identity description,
identity formation, peer acceptance, positive reflection, uncomfortable
feelings and off-topic responses. Chatbots express gender and sexuality
explicitly and through relation of experience and emotions, mimicking the human
language on which they are trained. It is nevertheless evident that chatbots
differ from human dialogue partners as they lack the flexibility and
understanding enabled by lived human experience. While chatbots are proficient
in using language to express identity, they also display a lack of authentic
experiences of gender and sexuality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A diachronic evaluation of gender asymmetry in euphemism. (arXiv:2106.02083v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kapron_King_A/0/1/0/all/0/1">Anna Kapron-King</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yang Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02083">
                                    <div class="article-summary-box-inner">
                                        <span>The use of euphemisms is a known driver of language change. It has been
proposed that women use euphemisms more than men. Although there have been
several studies investigating gender differences in language, the claim about
euphemism usage has not been tested comprehensively through time. If women do
use euphemisms more, this could mean that women also lead the formation of new
euphemisms and language change over time. Using four large diachronic text
corpora of English, we evaluate the claim that women use euphemisms more than
men through a quantitative analysis. We assembled a list of 106 euphemism-taboo
pairs to analyze their relative use through time by each gender in the corpora.
Contrary to the existing belief, our results show that women do not use
euphemisms with a higher proportion than men. We repeated the analysis using
different subsets of the euphemism-taboo pairs list and found that our result
was robust. Our study indicates that in a broad range of settings involving
both speech and writing, and with varying degrees of formality, women do not
use or form euphemisms more than men.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Equal Gender Representation in the Annotations of Toxic Language Detection. (arXiv:2106.02183v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Excell_E/0/1/0/all/0/1">Elizabeth Excell</a>, <a href="http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1">Noura Al Moubayed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02183">
                                    <div class="article-summary-box-inner">
                                        <span>Classifiers tend to propagate biases present in the data on which they are
trained. Hence, it is important to understand how the demographic identities of
the annotators of comments affect the fairness of the resulting model. In this
paper, we focus on the differences in the ways men and women annotate comments
for toxicity, investigating how these differences result in models that amplify
the opinions of male annotators. We find that the BERT model as-sociates toxic
comments containing offensive words with male annotators, causing the model to
predict 67.7% of toxic comments as having been annotated by men. We show that
this disparity between gender predictions can be mitigated by removing
offensive words and highly toxic comments from the training data. We then apply
the learned associations between gender and language to toxic language
classifiers, finding that models trained exclusively on female-annotated data
perform 1.8% better than those trained solely on male-annotated data and that
training models on data after removing all offensive words reduces bias in the
model by 55.5% while increasing the sensitivity by 0.4%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">About Explicit Variance Minimization: Training Neural Networks for Medical Imaging With Limited Data Annotations. (arXiv:2105.14117v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shubin_D/0/1/0/all/0/1">Dmitrii Shubin</a>, <a href="http://arxiv.org/find/cs/1/au:+Eytan_D/0/1/0/all/0/1">Danny Eytan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodfellow_S/0/1/0/all/0/1">Sebastian D. Goodfellow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14117">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised learning methods for computer vision have demonstrated the
effectiveness of pre-training feature representations, resulting in
well-generalizing Deep Neural Networks, even if the annotated data are limited.
However, representation learning techniques require a significant amount of
time for model training, with most of it time spent on precise hyper-parameter
optimization and selection of augmentation techniques. We hypothesized that if
the annotated dataset has enough morphological diversity to capture the general
population&#x27;s as is common in medical imaging, for example, due to conserved
similarities of tissue mythologies, the variance error of the trained model is
the prevalent component of the Bias-Variance Trade-off. We propose the Variance
Aware Training (VAT) method that exploits this property by introducing the
variance error into the model loss function, i.e., enabling minimizing the
variance explicitly. Additionally, we provide the theoretical formulation and
proof of the proposed method to aid in interpreting the approach. Our method
requires selecting only one hyper-parameter and was able to match or improve
the state-of-the-art performance of self-supervised methods while achieving an
order of magnitude reduction in the GPU training time. We validated VAT on
three medical imaging datasets from diverse domains and various learning
objectives. These included a Magnetic Resonance Imaging (MRI) dataset for the
heart semantic segmentation (MICCAI 2017 ACDC challenge), fundus photography
dataset for ordinary regression of diabetic retinopathy progression (Kaggle
2019 APTOS Blindness Detection challenge), and classification of
histopathologic scans of lymph node sections (PatchCamelyon dataset).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">More Is Better: An Analysis of Instance Quantity/Quality Trade-off in Rehearsal-based Continual Learning. (arXiv:2105.14106v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pelosin_F/0/1/0/all/0/1">Francesco Pelosin</a>, <a href="http://arxiv.org/find/cs/1/au:+Torsello_A/0/1/0/all/0/1">Andrea Torsello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14106">
                                    <div class="article-summary-box-inner">
                                        <span>The design of machines and algorithms capable of learning in a dynamically
changing environment has become an increasingly topical problem with the
increase of the size and heterogeneity of data available to learning systems.
As a consequence, the key issue of Continual Learning has become that of
addressing the stability-plasticity dilemma of connectionist systems, as they
need to adapt their model without forgetting previously acquired knowledge.
Within this context, rehearsal-based methods i.e., solutions in where the
learner exploits memory to revisit past data, has proven to be very effective,
leading to performance at the state-of-the-art. In our study, we propose an
analysis of the memory quantity/quality trade-off adopting various data
reduction approaches to increase the number of instances storable in memory. In
particular, we investigate complex instance compression techniques such as deep
encoders, but also trivial approaches such as image resizing and linear
dimensionality reduction. Our findings suggest that the optimal trade-off is
severely skewed toward instance quantity, where rehearsal approaches with
several heavily compressed instances easily outperform state-of-the-art
approaches with the same amount of memory at their disposal. Further, in high
memory configurations, deep approaches extracting spatial structure combined
with extreme resizing (of the order of $8\times8$ images) yield the best
results, while in memory-constrained configurations where deep approaches
cannot be used due to their memory requirement in training, Extreme Learning
Machines (ELM) offer a clear advantage.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Efficient Training Approach for Very Large Scale Face Recognition. (arXiv:2105.10375v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shuo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1">Zhipeng Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaobo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1">Xiaojiang Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1">Baigui Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1">Yang You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.10375">
                                    <div class="article-summary-box-inner">
                                        <span>Face recognition has achieved significant progress in deep-learning era due
to the ultra-large-scale and well-labeled datasets.

However, training on ultra-large-scale datasets is time-consuming and takes
up a lot of hardware resource.

Therefore, designing an efficient training approach is crucial and
indispensable.

The heavy computational and memory costs mainly result from the high
dimensionality of the Fully-Connected (FC) layer.

Specifically, the dimensionality is determined by the number of face
identities, which can be million-level or even more.

To this end, we propose a novel training approach for ultra-large-scale face
datasets, termed Faster Face Classification (F$^2$C).

In F$^2$C, we first define a Gallery Net and a Probe Net that are used to
generate identities&#x27; centers and extract faces&#x27; features for face recognition,
respectively.

Gallery Net has the same structure as Probe Net and inherits the parameters
from Probe Net with a moving average paradigm.

After that, to reduce the training time and hardware costs of the FC layer,
we propose a Dynamic Class Pool (DCP) that stores the features from Gallery Net
and calculates the inner product (logits) with positive samples (whose
identities are in the DCP) in each mini-batch.

DCP can be regarded as a substitute for the FC layer but it is far smaller,
thus greatly reducing the computational and memory costs.

For negative samples (whose identities are not in DCP), we minimize the
cosine similarities between negative samples and those in DCP.

Then, to improve the update efficiency of DCP&#x27;s parameters, we design a dual
data-loader including identity-based and instance-based loaders to generate a
certain of identities and samples in mini-batches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SiamRCR: Reciprocal Classification and Regression for Visual Object Tracking. (arXiv:2105.11237v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1">Jinlong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhengkai Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yueyang Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1">Ying Tai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengjie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Weiyao Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11237">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, most siamese network based trackers locate targets via object
classification and bounding-box regression. Generally, they select the
bounding-box with maximum classification confidence as the final prediction.
This strategy may miss the right result due to the accuracy misalignment
between classification and regression. In this paper, we propose a novel
siamese tracking algorithm called SiamRCR, addressing this problem with a
simple, light and effective solution. It builds reciprocal links between
classification and regression branches, which can dynamically re-weight their
losses for each positive sample. In addition, we add a localization branch to
predict the localization accuracy, so that it can work as the replacement of
the regression assistance link during inference. This branch makes the training
and inference more consistent. Extensive experimental results demonstrate the
effectiveness of SiamRCR and its superiority over the state-of-the-art
competitors on GOT-10k, LaSOT, TrackingNet, OTB-2015, VOT-2018 and VOT-2019.
Moreover, our SiamRCR runs at 65 FPS, far above the real-time requirement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SHD360: A Benchmark Dataset for Salient Human Detection in 360{\deg} Videos. (arXiv:2105.11578v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jing Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamidouche_W/0/1/0/all/0/1">Wassim Hamidouche</a>, <a href="http://arxiv.org/find/cs/1/au:+Deforges_O/0/1/0/all/0/1">Olivier Deforges</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11578">
                                    <div class="article-summary-box-inner">
                                        <span>Salient human detection (SHD) in dynamic 360{\deg} immersive videos is of
great importance for various applications such as robotics, inter-human and
human-object interaction in augmented reality. However, 360{\deg} video SHD has
been seldom discussed in the computer vision community due to a lack of
datasets with large-scale omnidirectional videos and rich annotations. To this
end, we propose SHD360, the first 360{\deg} video SHD dataset containing
various real-life daily scenes borrowed from this http URL, with
hierarchical annotations for 6,268 key frames uniformly sampled from 37,403
omnidirectional video frames at 4K resolution. Since so far there is no method
proposed for 360{\deg} image/video SHD, we systematically benchmark 11
representative state-of-the-art salient object detection approaches on our
SHD360. We hope our proposed dataset and benchmark could serve as a good
starting point for advancing human-centric researches towards 360{\deg}
panoramic data. Our dataset and benchmark will be publicly available at
https://github.com/PanoAsh/SHD360.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Distribution Estimation with Random Field and Random Cluster Theories. (arXiv:2104.10762v5 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Murphy_R/0/1/0/all/0/1">Robert A. Murphy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10762">
                                    <div class="article-summary-box-inner">
                                        <span>Random field and random cluster theory is used to prove certain mathematical
results concerning the probability distribution of images characterized as
generic $2D$ integer arrays during simultaneous learning. Example models in
image classification and object segmentation illustrate the mathematical
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using latent space regression to analyze and leverage compositionality in GANs. (arXiv:2103.10426v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chai_L/0/1/0/all/0/1">Lucy Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1">Jonas Wulff</a>, <a href="http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1">Phillip Isola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10426">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, Generative Adversarial Networks have become ubiquitous in
both research and public perception, but how GANs convert an unstructured
latent code to a high quality output is still an open question. In this work,
we investigate regression into the latent space as a probe to understand the
compositional properties of GANs. We find that combining the regressor and a
pretrained generator provides a strong image prior, allowing us to create
composite images from a collage of random image parts at inference time while
maintaining global consistency. To compare compositional properties across
different generators, we measure the trade-offs between reconstruction of the
unrealistic input and image quality of the regenerated samples. We find that
the regression approach enables more localized editing of individual image
parts compared to direct editing in the latent space, and we conduct
experiments to quantify this independence effect. Our method is agnostic to the
semantics of edits, and does not require labels or predefined concepts during
training. Beyond image composition, our method extends to a number of related
applications, such as image inpainting or example-based image editing, which we
demonstrate on several GANs and datasets, and because it uses only a single
forward pass, it can operate in real-time. Code is available on our project
page: https://chail.github.io/latent-composition/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint. (arXiv:2102.08360v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1">Ella Y. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Som_A/0/1/0/all/0/1">Anirudh Som</a>, <a href="http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1">Ankita Shukla</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1">Hongjun Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Turaga_P/0/1/0/all/0/1">Pavan Turaga</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08360">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have increasingly been used as an auxiliary tool in
healthcare applications, due to their ability to improve performance of several
diagnosis tasks. However, these methods are not widely adopted in clinical
settings due to the practical limitations in the reliability, generalizability,
and interpretability of deep learning based systems. As a result, methods have
been developed that impose additional constraints during network training to
gain more control as well as improve interpretabilty, facilitating their
acceptance in healthcare community. In this work, we investigate the benefit of
using Orthogonal Spheres (OS) constraint for classification of COVID-19 cases
from chest X-ray images. The OS constraint can be written as a simple
orthonormality term which is used in conjunction with the standard
cross-entropy loss during classification network training. Previous studies
have demonstrated significant benefits in applying such constraints to deep
learning models. Our findings corroborate these observations, indicating that
the orthonormality loss function effectively produces improved semantic
localization via GradCAM visualizations, enhanced classification performance,
and reduced model calibration error. Our approach achieves an improvement in
accuracy of 1.6% and 4.8% for two- and three-class classification,
respectively; similar results are found for models with data augmentation
applied. In addition to these findings, our work also presents a new
application of the OS regularizer in healthcare, increasing the post-hoc
interpretability and performance of deep learning models for COVID-19
classification to facilitate adoption of these methods in clinical settings. We
also identify the limitations of our strategy that can be explored for further
research in future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TS-CAM: Token Semantic Coupled Attention Map for Weakly Supervised Object Localization. (arXiv:2103.14862v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wei Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wan_F/0/1/0/all/0/1">Fang Wan</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xingjia Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhiliang Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1">Zhenjun Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1">Bolei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Q/0/1/0/all/0/1">Qixiang Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.14862">
                                    <div class="article-summary-box-inner">
                                        <span>Weakly supervised object localization (WSOL) is a challenging problem when
given image category labels but requires to learn object localization models.
Optimizing a convolutional neural network (CNN) for classification tends to
activate local discriminative regions while ignoring complete object extent,
causing the partial activation issue. In this paper, we argue that partial
activation is caused by the intrinsic characteristics of CNN, where the
convolution operations produce local receptive fields and experience difficulty
to capture long-range feature dependency among pixels. We introduce the token
semantic coupled attention map (TS-CAM) to take full advantage of the
self-attention mechanism in visual transformer for long-range dependency
extraction. TS-CAM first splits an image into a sequence of patch tokens for
spatial embedding, which produce attention maps of long-range visual dependency
to avoid partial activation. TS-CAM then re-allocates category-related
semantics for patch tokens, enabling each of them to be aware of object
categories. TS-CAM finally couples the patch tokens with the semantic-agnostic
attention map to achieve semantic-aware localization. Experiments on the
ILSVRC/CUB-200-2011 datasets show that TS-CAM outperforms its CNN-CAM
counterparts by 7.1%/27.1% for WSOL, achieving state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Good Practices and A Strong Baseline for Traffic Anomaly Detection. (arXiv:2105.03827v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yuxiang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yue He</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yingying Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_X/0/1/0/all/0/1">Xiao Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1">Shifeng Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03827">
                                    <div class="article-summary-box-inner">
                                        <span>The detection of traffic anomalies is a critical component of the intelligent
city transportation management system. Previous works have proposed a variety
of notable insights and taken a step forward in this field, however, dealing
with the complex traffic environment remains a challenge. Moreover, the lack of
high-quality data and the complexity of the traffic scene, motivate us to study
this problem from a hand-crafted perspective. In this paper, we propose a
straightforward and efficient framework that includes pre-processing, a dynamic
track module, and post-processing. With video stabilization, background
modeling, and vehicle detection, the pro-processing phase aims to generate
candidate anomalies. The dynamic tracking module seeks and locates the start
time of anomalies by utilizing vehicle motion patterns and spatiotemporal
status. Finally, we use post-processing to fine-tune the temporal boundary of
anomalies. Not surprisingly, our proposed framework was ranked $1^{st}$ in the
NVIDIA AI CITY 2021 leaderboard for traffic anomaly detection. The code is
available at: https://github.com/Endeavour10020/AICity2021-Anomaly-Detection .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-level Knowledge Distillation via Knowledge Alignment and Correlation. (arXiv:2012.00573v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1">Fei Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Hongxin Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Krovi_V/0/1/0/all/0/1">Venkat Krovi</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1">Feng Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00573">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation (KD) has become an important technique for model
compression and knowledge transfer. In this work, we first perform a
comprehensive analysis of the knowledge transferred by different KD methods. We
demonstrate that traditional KD methods, which minimize the KL divergence of
softmax outputs between networks, are related to the knowledge alignment of an
individual sample only. Meanwhile, recent contrastive learning-based KD methods
mainly transfer relational knowledge between different samples, namely,
knowledge correlation. While it is important to transfer the full knowledge
from teacher to student, we introduce the Multi-level Knowledge Distillation
(MLKD) by effectively considering both knowledge alignment and correlation.
MLKD is task-agnostic and model-agnostic, and can easily transfer knowledge
from supervised or self-supervised pretrained teachers. We show that MLKD can
improve the reliability and transferability of learned representations.
Experiments demonstrate that MLKD outperforms other state-of-the-art methods on
a large number of experimental settings including different (a) pretraining
strategies (b) network architectures (c) datasets (d) tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Editing Conditional Radiance Fields. (arXiv:2105.06466v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Steven Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiuming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhoutong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Richard Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun-Yan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Russell_B/0/1/0/all/0/1">Bryan Russell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06466">
                                    <div class="article-summary-box-inner">
                                        <span>A neural radiance field (NeRF) is a scene model supporting high-quality view
synthesis, optimized per scene. In this paper, we explore enabling user editing
of a category-level NeRF - also known as a conditional radiance field - trained
on a shape category. Specifically, we introduce a method for propagating coarse
2D user scribbles to the 3D space, to modify the color or shape of a local
region. First, we propose a conditional radiance field that incorporates new
modular network components, including a shape branch that is shared across
object instances. Observing multiple instances of the same category, our model
learns underlying part semantics without any supervision, thereby allowing the
propagation of coarse 2D user scribbles to the entire 3D region (e.g., chair
seat). Next, we propose a hybrid network update strategy that targets specific
network components, which balances efficiency and accuracy. During user
interaction, we formulate an optimization problem that both satisfies the
user&#x27;s constraints and preserves the original object structure. We demonstrate
our approach on various editing tasks over three shape datasets and show that
it outperforms prior neural editing approaches. Finally, we edit the appearance
and shape of a real photograph and show that the edit propagates to
extrapolated novel views.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularizing Deep Networks with Semantic Data Augmentation. (arXiv:2007.10538v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yulin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shiji Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xuran Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yitong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Cheng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.10538">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation is widely known as a simple yet surprisingly effective
technique for regularizing deep networks. Conventional data augmentation
schemes, e.g., flipping, translation or rotation, are low-level,
data-independent and class-agnostic operations, leading to limited diversity
for augmented samples. To this end, we propose a novel semantic data
augmentation algorithm to complement traditional approaches. The proposed
method is inspired by the intriguing property that deep networks are effective
in learning linearized features, i.e., certain directions in the deep feature
space correspond to meaningful semantic transformations, e.g., changing the
background or view angle of an object. Based on this observation, translating
training samples along many such directions in the feature space can
effectively augment the dataset for more diversity. To implement this idea, we
first introduce a sampling based method to obtain semantically meaningful
directions efficiently. Then, an upper bound of the expected cross-entropy (CE)
loss on the augmented training set is derived by assuming the number of
augmented samples goes to infinity, yielding a highly efficient algorithm. In
fact, we show that the proposed implicit semantic data augmentation (ISDA)
algorithm amounts to minimizing a novel robust CE loss, which adds minimal
extra computational cost to a normal training procedure. In addition to
supervised learning, ISDA can be applied to semi-supervised learning tasks
under the consistency regularization framework, where ISDA amounts to
minimizing the upper bound of the expected KL-divergence between the augmented
features and the original features. Although being simple, ISDA consistently
improves the generalization performance of popular deep models (e.g., ResNets
and DenseNets) on a variety of datasets, i.e., CIFAR-10, CIFAR-100, SVHN,
ImageNet, and Cityscapes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incomplete Graph Representation and Learning via Partial Graph Neural Networks. (arXiv:2003.10130v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1">Bo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziyan Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.10130">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) are gaining increasing attention on graph data
learning tasks in recent years. However, in many applications, graph may be
coming in an incomplete form where attributes of graph nodes are partially
unknown/missing. Existing GNNs are generally designed on complete graphs which
can not deal with attribute-incomplete graph data directly. To address this
problem, we develop a novel partial aggregation based GNNs, named Partial Graph
Neural Networks (PaGNNs), for attribute-incomplete graph representation and
learning. Our work is motivated by the observation that the neighborhood
aggregation function in standard GNNs can be equivalently viewed as the
neighborhood reconstruction formulation. Based on it, we define two novel
partial aggregation (reconstruction) functions on incomplete graph and derive
PaGNNs for incomplete graph data learning. Extensive experiments on several
datasets demonstrate the effectiveness and efficiency of the proposed PaGNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Improved Attention for Visual Question Answering. (arXiv:2011.02164v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahman_T/0/1/0/all/0/1">Tanzila Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Chou_S/0/1/0/all/0/1">Shih-Han Chou</a>, <a href="http://arxiv.org/find/cs/1/au:+Sigal_L/0/1/0/all/0/1">Leonid Sigal</a>, <a href="http://arxiv.org/find/cs/1/au:+Carenini_G/0/1/0/all/0/1">Giuseppe Carenini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02164">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of Visual Question Answering (VQA). Given an image
and a free-form, open-ended, question, expressed in natural language, the goal
of VQA system is to provide accurate answer to this question with respect to
the image. The task is challenging because it requires simultaneous and
intricate understanding of both visual and textual information. Attention,
which captures intra- and inter-modal dependencies, has emerged as perhaps the
most widely used mechanism for addressing these challenges. In this paper, we
propose an improved attention-based architecture to solve VQA. We incorporate
an Attention on Attention (AoA) module within encoder-decoder framework, which
is able to determine the relation between attention results and queries.
Attention module generates weighted average for each query. On the other hand,
AoA module first generates an information vector and an attention gate using
attention results and current context; and then adds another attention to
generate final attended information by multiplying the two. We also propose
multimodal fusion module to combine both visual and textual information. The
goal of this fusion module is to dynamically decide how much information should
be considered from each modality. Extensive experiments on VQA-v2 benchmark
dataset show that our method achieves the state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas Segmentation: Application to Automatic Pathological Liver CT Segmentation. (arXiv:2102.12056v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1">Changfa Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Xian_M/0/1/0/all/0/1">Min Xian</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1">Xiancheng Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1">Haotian Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheng_H/0/1/0/all/0/1">Heng-Da Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12056">
                                    <div class="article-summary-box-inner">
                                        <span>Liver segmentation from abdominal CT images is an essential step for liver
cancer computer-aided diagnosis and surgical planning. However, both the
accuracy and robustness of existing liver segmentation methods cannot meet the
requirements of clinical applications. In particular, for the common clinical
cases where the liver tissue contains major pathology, current segmentation
methods show poor performance. In this paper, we propose a novel low-rank
tensor decomposition (LRTD) based multi-atlas segmentation (MAS) framework that
achieves accurate and robust pathological liver segmentation of CT images.
Firstly, we propose a multi-slice LRTD scheme to recover the underlying
low-rank structure embedded in 3D medical images. It performs the LRTD on small
image segments consisting of multiple consecutive image slices. Then, we
present an LRTD-based atlas construction method to generate tumor-free liver
atlases that mitigates the performance degradation of liver segmentation due to
the presence of tumors. Finally, we introduce an LRTD-based MAS algorithm to
derive patient-specific liver atlases for each test image, and to achieve
accurate pairwise image registration and label propagation. Extensive
experiments on three public databases of pathological liver cases validate the
effectiveness of the proposed method. Both qualitative and quantitative results
demonstrate that, in the presence of major pathology, the proposed method is
more accurate and robust than state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-interactive Dual-decoder for RGB-thermal Salient Object Detection. (arXiv:2005.02315v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhengzheng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenglong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lang_Y/0/1/0/all/0/1">Yang Lang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jin Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.02315">
                                    <div class="article-summary-box-inner">
                                        <span>RGB-thermal salient object detection (SOD) aims to segment the common
prominent regions of visible image and corresponding thermal infrared image
that we call it RGBT SOD. Existing methods don&#x27;t fully explore and exploit the
potentials of complementarity of different modalities and multi-type cues of
image contents, which play a vital role in achieving accurate results. In this
paper, we propose a multi-interactive dual-decoder to mine and model the
multi-type interactions for accurate RGBT SOD. In specific, we first encode two
modalities into multi-level multi-modal feature representations. Then, we
design a novel dual-decoder to conduct the interactions of multi-level
features, two modalities and global contexts. With these interactions, our
method works well in diversely challenging scenarios even in the presence of
invalid modality. Finally, we carry out extensive experiments on public RGBT
and RGBD SOD datasets, and the results show that the proposed method achieves
the outstanding performance against state-of-the-art algorithms. The source
code has been released
at:https://github.com/lz118/Multi-interactive-Dual-decoder.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning domain-agnostic visual representation for computational pathology using medically-irrelevant style transfer augmentation. (arXiv:2102.01678v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yamashita_R/0/1/0/all/0/1">Rikiya Yamashita</a>, <a href="http://arxiv.org/find/eess/1/au:+Long_J/0/1/0/all/0/1">Jin Long</a>, <a href="http://arxiv.org/find/eess/1/au:+Banda_S/0/1/0/all/0/1">Snikitha Banda</a>, <a href="http://arxiv.org/find/eess/1/au:+Shen_J/0/1/0/all/0/1">Jeanne Shen</a>, <a href="http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1">Daniel L. Rubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01678">
                                    <div class="article-summary-box-inner">
                                        <span>Suboptimal generalization of machine learning models on unseen data is a key
challenge which hampers the clinical applicability of such models to medical
imaging. Although various methods such as domain adaptation and domain
generalization have evolved to combat this challenge, learning robust and
generalizable representations is core to medical image understanding, and
continues to be a problem. Here, we propose STRAP (Style TRansfer Augmentation
for histoPathology), a form of data augmentation based on random style transfer
from non-medical style source such as artistic paintings, for learning
domain-agnostic visual representations in computational pathology. Style
transfer replaces the low-level texture content of an image with the
uninformative style of randomly selected style source image, while preserving
the original high-level semantic content. This improves robustness to domain
shift and can be used as a simple yet powerful tool for learning
domain-agnostic representations. We demonstrate that STRAP leads to
state-of-the-art performance, particularly in the presence of domain shifts, on
two particular classification tasks in computational pathology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fusing CNNs and statistical indicators to improve image classification. (arXiv:2012.11049v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huertas_Tato_J/0/1/0/all/0/1">Javier Huertas-Tato</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_A/0/1/0/all/0/1">Alejandro Mart&#xed;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1">Juli&#xe1;n Fierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Camacho_D/0/1/0/all/0/1">David Camacho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.11049">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Networks have dominated the field of computer vision for the
last ten years, exhibiting extremely powerful feature extraction capabilities
and outstanding classification performance. The main strategy to prolong this
trend relies on further upscaling networks in size. However, costs increase
rapidly while performance improvements may be marginal. We hypothesise that
adding heterogeneous sources of information may be more cost-effective to a CNN
than building a bigger network. In this paper, an ensemble method is proposed
for accurate image classification, fusing automatically detected features
through Convolutional Neural Network architectures with a set of manually
defined statistical indicators. Through a combination of the predictions of a
CNN and a secondary classifier trained on statistical features, better
classification performance can be cheaply achieved. We test multiple learning
algorithms and CNN architectures on a diverse number of datasets to validate
our proposal, making public all our code and data via GitHub. According to our
results, the inclusion of additional indicators and an ensemble classification
approach helps to increase the performance in 8 of 9 datasets, with a
remarkable increase of more than 10% precision in two of them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Enhanced Rotation Prediction for Self-Supervised Learning. (arXiv:1912.11603v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Yamaguchi_S/0/1/0/all/0/1">Shin&#x27;ya Yamaguchi</a>, <a href="http://arxiv.org/find/stat/1/au:+Kanai_S/0/1/0/all/0/1">Sekitoshi Kanai</a>, <a href="http://arxiv.org/find/stat/1/au:+Shioda_T/0/1/0/all/0/1">Tetsuya Shioda</a>, <a href="http://arxiv.org/find/stat/1/au:+Takeda_S/0/1/0/all/0/1">Shoichiro Takeda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.11603">
                                    <div class="article-summary-box-inner">
                                        <span>The rotation prediction (Rotation) is a simple pretext-task for
self-supervised learning (SSL), where models learn useful representations for
target vision tasks by solving pretext-tasks. Although Rotation captures
information of object shapes, it hardly captures information of textures. To
tackle this problem, we introduce a novel pretext-task called image enhanced
rotation prediction (IE-Rot) for SSL. IE-Rot simultaneously solves Rotation and
another pretext-task based on image enhancement (e.g., sharpening and
solarizing) while maintaining simplicity. Through the simultaneous prediction
of rotation and image enhancement, models learn representations to capture the
information of not only object shapes but also textures. Our experimental
results show that IE-Rot models outperform Rotation on various standard
benchmarks including ImageNet classification, PASCAL-VOC detection, and COCO
detection/segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prototype Completion with Primitive Knowledge for Few-Shot Learning. (arXiv:2009.04960v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Baoquan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xutao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yunming Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhichao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1">Lisai Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04960">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot learning is a challenging task, which aims to learn a classifier for
novel classes with few examples. Pre-training based meta-learning methods
effectively tackle the problem by pre-training a feature extractor and then
fine-tuning it through the nearest centroid based meta-learning. However,
results show that the fine-tuning step makes very marginal improvements. In
this paper, 1) we figure out the key reason, i.e., in the pre-trained feature
space, the base classes already form compact clusters while novel classes
spread as groups with large variances, which implies that fine-tuning the
feature extractor is less meaningful; 2) instead of fine-tuning the feature
extractor, we focus on estimating more representative prototypes during
meta-learning. Consequently, we propose a novel prototype completion based
meta-learning framework. This framework first introduces primitive knowledge
(i.e., class-level part or attribute annotations) and extracts representative
attribute features as priors. Then, we design a prototype completion network to
learn to complete prototypes with these priors. To avoid the prototype
completion error caused by primitive knowledge noises or class differences, we
further develop a Gaussian based prototype fusion strategy that combines the
mean-based and completed prototypes by exploiting the unlabeled samples.
Extensive experiments show that our method: (i) can obtain more accurate
prototypes; (ii) outperforms state-of-the-art techniques by 2% - 9% in terms of
classification accuracy. Our code is available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">F-Drop&amp;Match: GANs with a Dead Zone in the High-Frequency Domain. (arXiv:2106.02343v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1">Shin&#x27;ya Yamaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1">Sekitoshi Kanai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02343">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks built from deep convolutional neural networks
(GANs) lack the ability to exactly replicate the high-frequency components of
natural images. To alleviate this issue, we introduce two novel training
techniques called frequency dropping (F-Drop) and frequency matching (F-Match).
The key idea of F-Drop is to filter out unnecessary high-frequency components
from the input images of the discriminators. This simple modification prevents
the discriminators from being confused by perturbations of the high-frequency
components. In addition, F-Drop makes the GANs focus on fitting in the
low-frequency domain, in which there are the dominant components of natural
images. F-Match minimizes the difference between real and fake images in the
frequency domain for generating more realistic images. F-Match is implemented
as a regularization term in the objective functions of the generators; it
penalizes the batch mean error in the frequency domain. F-Match helps the
generators to fit in the high-frequency domain filtered out by F-Drop to the
real image. We experimentally demonstrate that the combination of F-Drop and
F-Match improves the generative performance of GANs in both the frequency and
spatial domain on multiple image benchmarks (CIFAR, TinyImageNet, STL-10,
CelebA, and ImageNet).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RGBT Tracking via Multi-Adapter Network with Hierarchical Divergence Loss. (arXiv:2011.07189v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_A/0/1/0/all/0/1">Andong Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenglong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Y/0/1/0/all/0/1">Yuqing Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_B/0/1/0/all/0/1">Bin Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.07189">
                                    <div class="article-summary-box-inner">
                                        <span>RGBT tracking has attracted increasing attention since RGB and thermal
infrared data have strong complementary advantages, which could make trackers
all-day and all-weather work. However, how to effectively represent RGBT data
for visual tracking remains unstudied well. Existing works usually focus on
extracting modality-shared or modality-specific information, but the potentials
of these two cues are not well explored and exploited in RGBT tracking. In this
paper, we propose a novel multi-adapter network to jointly perform
modality-shared, modality-specific and instance-aware target representation
learning for RGBT tracking. To this end, we design three kinds of adapters
within an end-to-end deep learning framework. In specific, we use the modified
VGG-M as the generality adapter to extract the modality-shared target
representations.To extract the modality-specific features while reducing the
computational complexity, we design a modality adapter, which adds a small
block to the generality adapter in each layer and each modality in a parallel
manner. Such a design could learn multilevel modality-specific representations
with a modest number of parameters as the vast majority of parameters are
shared with the generality adapter. We also design instance adapter to capture
the appearance properties and temporal variations of a certain target.
Moreover, to enhance the shared and specific features, we employ the loss of
multiple kernel maximum mean discrepancy to measure the distribution divergence
of different modal features and integrate it into each layer for more robust
representation learning. Extensive experiments on two RGBT tracking benchmark
datasets demonstrate the outstanding performance of the proposed tracker
against the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reactive Human-to-Robot Handovers of Arbitrary Objects. (arXiv:2011.08961v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_W/0/1/0/all/0/1">Wei Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1">Chris Paxton</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousavian_A/0/1/0/all/0/1">Arsalan Mousavian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_Y/0/1/0/all/0/1">Yu-Wei Chao</a>, <a href="http://arxiv.org/find/cs/1/au:+Cakmak_M/0/1/0/all/0/1">Maya Cakmak</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08961">
                                    <div class="article-summary-box-inner">
                                        <span>Human-robot object handovers have been an actively studied area of robotics
over the past decade; however, very few techniques and systems have addressed
the challenge of handing over diverse objects with arbitrary appearance, size,
shape, and rigidity. In this paper, we present a vision-based system that
enables reactive human-to-robot handovers of unknown objects. Our approach
combines closed-loop motion planning with real-time, temporally-consistent
grasp generation to ensure reactivity and motion smoothness. Our system is
robust to different object positions and orientations, and can grasp both rigid
and non-rigid objects. We demonstrate the generalizability, usability, and
robustness of our approach on a novel benchmark set of 26 diverse household
objects, a user study with naive users (N&#x3D;6) handing over a subset of 15
objects, and a systematic evaluation examining different ways of handing
objects. More results and videos can be found at
https://sites.google.com/nvidia.com/handovers-of-arbitrary-objects.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering. (arXiv:2106.02634v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1">Vincent Sitzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezchikov_S/0/1/0/all/0/1">Semon Rezchikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1">William T. Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1">Fredo Durand</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02634">
                                    <div class="article-summary-box-inner">
                                        <span>Inferring representations of 3D scenes from 2D observations is a fundamental
problem of computer graphics, computer vision, and artificial intelligence.
Emerging 3D-structured neural scene representations are a promising approach to
3D scene understanding. In this work, we propose a novel neural scene
representation, Light Field Networks or LFNs, which represent both geometry and
appearance of the underlying 3D scene in a 360-degree, four-dimensional light
field parameterized via a neural implicit representation. Rendering a ray from
an LFN requires only a *single* network evaluation, as opposed to hundreds of
evaluations per ray for ray-marching or volumetric based renderers in
3D-structured neural scene representations. In the setting of simple scenes, we
leverage meta-learning to learn a prior over LFNs that enables multi-view
consistent light field reconstruction from as little as a single image
observation. This results in dramatic reductions in time and memory complexity,
and enables real-time rendering. The cost of storing a 360-degree light field
via an LFN is two orders of magnitude lower than conventional methods such as
the Lumigraph. Utilizing the analytical differentiability of neural implicit
representations and a novel parameterization of light space, we further
demonstrate the extraction of sparse depth maps from LFNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SkeletonNet: A Topology-Preserving Solution for Learning Mesh Reconstruction of Object Surfaces from RGB Images. (arXiv:2008.05742v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jiapeng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xiaoguang Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1">Xin Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.05742">
                                    <div class="article-summary-box-inner">
                                        <span>This paper focuses on the challenging task of learning 3D object surface
reconstructions from RGB images. Existingmethods achieve varying degrees of
success by using different surface representations. However, they all have
their own drawbacks,and cannot properly reconstruct the surface shapes of
complex topologies, arguably due to a lack of constraints on the
topologicalstructures in their learning frameworks. To this end, we propose to
learn and use the topology-preserved, skeletal shape representationto assist
the downstream task of object surface reconstruction from RGB images.
Technically, we propose the novelSkeletonNetdesign that learns a volumetric
representation of a skeleton via a bridged learning of a skeletal point set,
where we use paralleldecoders each responsible for the learning of points on 1D
skeletal curves and 2D skeletal sheets, as well as an efficient module
ofglobally guided subvolume synthesis for a refined, high-resolution skeletal
volume; we present a differentiablePoint2Voxellayer tomake SkeletonNet
end-to-end and trainable. With the learned skeletal volumes, we propose two
models, the Skeleton-Based GraphConvolutional Neural Network (SkeGCNN) and the
Skeleton-Regularized Deep Implicit Surface Network (SkeDISN), which
respectivelybuild upon and improve over the existing frameworks of explicit
mesh deformation and implicit field learning for the downstream
surfacereconstruction task. We conduct thorough experiments that verify the
efficacy of our proposed SkeletonNet. SkeGCNN and SkeDISNoutperform existing
methods as well, and they have their own merits when measured by different
metrics. Additional results ingeneralized task settings further demonstrate the
usefulness of our proposed methods. We have made both our implementation
codeand the ShapeNet-Skeleton dataset publicly available at ble at
https://github.com/tangjiapeng/SkeletonNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Semi-Supervised Gross Target Volume of Nasopharyngeal Carcinoma Segmentation via Uncertainty Rectified Pyramid Consistency. (arXiv:2012.07042v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1">Xiangde Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_W/0/1/0/all/0/1">Wenjun Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jieneng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_T/0/1/0/all/0/1">Tao Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yinan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shichuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nianyong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Guotai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shaoting Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07042">
                                    <div class="article-summary-box-inner">
                                        <span>Gross Target Volume (GTV) segmentation plays an irreplaceable role in
radiotherapy planning for Nasopharyngeal Carcinoma (NPC). Despite that
Convolutional Neural Networks (CNN) have achieved good performance for this
task, they rely on a large set of labeled images for training, which is
expensive and time-consuming to acquire. In this paper, we propose a novel
framework with Uncertainty Rectified Pyramid Consistency (URPC) regularization
for semi-supervised NPC GTV segmentation. Concretely, we extend a backbone
segmentation network to produce pyramid predictions at different scales. The
pyramid predictions network (PPNet) is supervised by the ground truth of
labeled images and a multi-scale consistency loss for unlabeled images,
motivated by the fact that prediction at different scales for the same input
should be similar and consistent. However, due to the different resolution of
these predictions, encouraging them to be consistent at each pixel directly has
low robustness and may lose some fine details. To address this problem, we
further design a novel uncertainty rectifying module to enable the framework to
gradually learn from meaningful and reliable consensual regions at different
scales. Experimental results on a dataset with 258 NPC MR images showed that
with only 10% or 20% images labeled, our method largely improved the
segmentation performance by leveraging the unlabeled images, and it also
outperformed five state-of-the-art semi-supervised segmentation methods.
Moreover, when only 50% images labeled, URPC achieved an average Dice score of
82.74% that was close to fully supervised learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regressive Domain Adaptation for Unsupervised Keypoint Detection. (arXiv:2103.06175v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Junguang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yifei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Ximei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yufeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianmin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1">Mingsheng Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06175">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation (DA) aims at transferring knowledge from a labeled source
domain to an unlabeled target domain. Though many DA theories and algorithms
have been proposed, most of them are tailored into classification settings and
may fail in regression tasks, especially in the practical keypoint detection
task. To tackle this difficult but significant task, we present a method of
regressive domain adaptation (RegDA) for unsupervised keypoint detection.
Inspired by the latest theoretical work, we first utilize an adversarial
regressor to maximize the disparity on the target domain and train a feature
generator to minimize this disparity. However, due to the high dimension of the
output space, this regressor fails to detect samples that deviate from the
support of the source. To overcome this problem, we propose two important
ideas. First, based on our observation that the probability density of the
output space is sparse, we introduce a spatial probability distribution to
describe this sparsity and then use it to guide the learning of the adversarial
regressor. Second, to alleviate the optimization difficulty in the
high-dimensional space, we innovatively convert the minimax game in the
adversarial training to the minimization of two opposite goals. Extensive
experiments show that our method brings large improvement by 8% to 11% in terms
of PCK on different datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sign-Agnostic Implicit Learning of Surface Self-Similarities for Shape Modeling and Reconstruction from Raw Point Clouds. (arXiv:2012.07498v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenbin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1">Jiabao Lei</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1">Yuxin Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianguo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_K/0/1/0/all/0/1">Kui Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.07498">
                                    <div class="article-summary-box-inner">
                                        <span>Shape modeling and reconstruction from raw point clouds of objects stand as a
fundamental challenge in vision and graphics research. Classical methods
consider analytic shape priors; however, their performance degraded when the
scanned points deviate from the ideal conditions of cleanness and completeness.
Important progress has been recently made by data-driven approaches, which
learn global and/or local models of implicit surface representations from
auxiliary sets of training shapes. Motivated from a universal phenomenon that
self-similar shape patterns of local surface patches repeat across the entire
surface of an object, we aim to push forward the data-driven strategies and
propose to learn a local implicit surface network for a shared, adaptive
modeling of the entire surface for a direct surface reconstruction from raw
point cloud; we also enhance the leveraging of surface self-similarities by
improving correlations among the optimized latent codes of individual surface
patches. Given that orientations of raw points could be unavailable or noisy,
we extend sign agnostic learning into our local implicit model, which enables
our recovery of signed implicit fields of local surfaces from the unsigned
inputs. We term our framework as Sign-Agnostic Implicit Learning of Surface
Self-Similarities (SAIL-S3). With a global post-optimization of local sign
flipping, SAIL-S3 is able to directly model raw, un-oriented point clouds and
reconstruct high-quality object surfaces. Experiments show its superiority over
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effective Training of Convolutional Neural Networks with Low-bitwidth Weights and Activations. (arXiv:1908.04680v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhuang_B/0/1/0/all/0/1">Bohan Zhuang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingqiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1">Ian Reid</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1">Chunhua Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.04680">
                                    <div class="article-summary-box-inner">
                                        <span>This paper tackles the problem of training a deep convolutional neural
network of both low-bitwidth weights and activations. Optimizing a
low-precision network is very challenging due to the non-differentiability of
the quantizer, which may result in substantial accuracy loss. To address this,
we propose three practical approaches, including (i) progressive quantization;
(ii) stochastic precision; and (iii) joint knowledge distillation to improve
the network training. First, for progressive quantization, we propose two
schemes to progressively find good local minima. Specifically, we propose to
first optimize a net with quantized weights and subsequently quantize
activations. This is in contrast to the traditional methods which optimize them
simultaneously. Furthermore, we propose a second progressive quantization
scheme which gradually decreases the bit-width from high-precision to
low-precision during training. Second, to alleviate the excessive training
burden due to the multi-round training stages, we further propose a one-stage
stochastic precision strategy to randomly sample and quantize sub-networks
while keeping other parts in full-precision. Finally, we adopt a novel learning
scheme to jointly train a full-precision model alongside the low-precision one.
By doing so, the full-precision model provides hints to guide the low-precision
model training and significantly improves the performance of the low-precision
network. Extensive experiments on various datasets (e.g., CIFAR-100, ImageNet)
show the effectiveness of the proposed methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Signed Distance Function Computation from an Implicit Surface. (arXiv:2104.08057v2 [cs.GR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fayolle_P/0/1/0/all/0/1">Pierre-Alain Fayolle</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08057">
                                    <div class="article-summary-box-inner">
                                        <span>We describe in this short note a technique to convert an implicit surface
into a Signed Distance Function (SDF) while exactly preserving the zero
level-set of the implicit. The proposed approach relies on embedding the input
implicit in the final layer of a neural network, which is trained to minimize a
loss function characterizing the SDF.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly- and Semi-Supervised Probabilistic Segmentation and Quantification of Ultrasound Needle-Reverberation Artifacts to Allow Better AI Understanding of Tissue Beneath Needles. (arXiv:2011.11958v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hung_A/0/1/0/all/0/1">Alex Ling Yu Hung</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_E/0/1/0/all/0/1">Edward Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Galeotti_J/0/1/0/all/0/1">John Galeotti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.11958">
                                    <div class="article-summary-box-inner">
                                        <span>Ultrasound image quality has continually been improving. However, when
needles or other metallic objects are operating inside the tissue, the
resulting reverberation artifacts can severely corrupt the surrounding image
quality. Such effects are challenging for existing computer vision algorithms
for medical image analysis. Needle reverberation artifacts can be hard to
identify at times and affect various pixel values to different degrees. The
boundaries of such artifacts are ambiguous, leading to disagreement among human
experts labeling the artifacts. We propose a weakly- and semi-supervised,
probabilistic needle-and-reverberation-artifact segmentation algorithm to
separate the desired tissue-based pixel values from the superimposed artifacts.
Our method models the intensity decay of artifact intensities and is designed
to minimize the human labeling error. We demonstrate the applicability of the
approach and compare it against other segmentation algorithms. Our method is
capable of differentiating between the reverberations from artifact-free
patches as well as of modeling the intensity fall-off in the artifacts. Our
method matches state-of-the-art artifact segmentation performance and sets a
new standard in estimating the per-pixel contributions of artifact vs
underlying anatomy, especially in the immediately adjacent regions between
reverberation lines. Our algorithm is also able to improve the performance
downstream image analysis algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Descriptor Enhancement via Self-Labelling Triplets for Visual Data Association. (arXiv:2011.10471v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shaoul_Y/0/1/0/all/0/1">Yorai Shaoul</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Katherine Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ok_K/0/1/0/all/0/1">Kyel Ok</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_N/0/1/0/all/0/1">Nicholas Roy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10471">
                                    <div class="article-summary-box-inner">
                                        <span>Object-level data association is central to robotic applications such as
tracking-by-detection and object-level simultaneous localization and mapping.
While current learned visual data association methods outperform hand-crafted
algorithms, many rely on large collections of domain-specific training examples
that can be difficult to obtain without prior knowledge. Additionally, such
methods often remain fixed during inference-time and do not harness observed
information to better their performance. We propose a self-supervised method
for incrementally refining visual descriptors to improve performance in the
task of object-level visual data association. Our method optimizes deep
descriptor generators online, by continuously training a widely available image
classification network pre-trained with domain-independent data. We show that
earlier layers in the network outperform later-stage layers for the data
association task while also allowing for a 94% reduction in the number of
parameters, enabling the online optimization. We show that self-labelling
challenging triplets--choosing positive examples separated by large temporal
distances and negative examples close in the descriptor space--improves the
quality of the learned descriptors for the multi-object tracking task. Finally,
we demonstrate that our approach surpasses other visual data-association
methods applied to a tracking-by-detection task, and show that it provides
better performance-gains when compared to other methods that attempt to adapt
to observed information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepActsNet: Spatial and Motion features from Face, Hands, and Body Combined with Convolutional and Graph Networks for Improved Action Recognition. (arXiv:2009.09818v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Asif_U/0/1/0/all/0/1">Umar Asif</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehta_D/0/1/0/all/0/1">Deval Mehta</a>, <a href="http://arxiv.org/find/cs/1/au:+Cavallar_S/0/1/0/all/0/1">Stefan von Cavallar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jianbin Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Harrer_S/0/1/0/all/0/1">Stefan Harrer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.09818">
                                    <div class="article-summary-box-inner">
                                        <span>Existing action recognition methods mainly focus on joint and bone
information in human body skeleton data due to its robustness to complex
backgrounds and dynamic characteristics of the environments. In this paper, we
combine body skeleton data with spatial and motion features from face and two
hands, and present &quot;Deep Action Stamps (DeepActs)&quot;, a novel data representation
to encode actions from video sequences. We also present &quot;DeepActsNet&quot;, a deep
learning based ensemble model which learns convolutional and structural
features from Deep Action Stamps for highly accurate action recognition.
Experiments on three challenging action recognition datasets (NTU60, NTU120,
and SYSU) show that the proposed model trained using Deep Action Stamps produce
considerable improvements in the action recognition accuracy with less
computational cost compared to the state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MANTRA: Memory Augmented Networks for Multiple Trajectory Prediction. (arXiv:2006.03340v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marchetti_F/0/1/0/all/0/1">Francesco Marchetti</a>, <a href="http://arxiv.org/find/cs/1/au:+Becattini_F/0/1/0/all/0/1">Federico Becattini</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidenari_L/0/1/0/all/0/1">Lorenzo Seidenari</a>, <a href="http://arxiv.org/find/cs/1/au:+Bimbo_A/0/1/0/all/0/1">Alberto Del Bimbo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.03340">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous vehicles are expected to drive in complex scenarios with several
independent non cooperating agents. Path planning for safely navigating in such
environments can not just rely on perceiving present location and motion of
other agents. It requires instead to predict such variables in a far enough
future. In this paper we address the problem of multimodal trajectory
prediction exploiting a Memory Augmented Neural Network. Our method learns past
and future trajectory embeddings using recurrent neural networks and exploits
an associative external memory to store and retrieve such embeddings.
Trajectory prediction is then performed by decoding in-memory future encodings
conditioned with the observed past. We incorporate scene knowledge in the
decoding state by learning a CNN on top of semantic scene maps. Memory growth
is limited by learning a writing controller based on the predictive capability
of existing embeddings. We show that our method is able to natively perform
multi-modal trajectory prediction obtaining state-of-the art results on three
datasets. Moreover, thanks to the non-parametric nature of the memory module,
we show how once trained our system can continuously improve by ingesting novel
patterns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Learning of Domain Invariant Features for Depth Estimation. (arXiv:2106.02594v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akada_H/0/1/0/all/0/1">Hiroyasu Akada</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1">Shariq Farooq Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Alhashim_I/0/1/0/all/0/1">Ibraheem Alhashim</a>, <a href="http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1">Peter Wonka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02594">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle the problem of unsupervised synthetic-to-realistic domain
adaptation for single image depth estimation. An essential building block of
single image depth estimation is an encoder-decoder task network that takes RGB
images as input and produces depth maps as output. In this paper, we propose a
novel training strategy to force the task network to learn domain invariant
representations in a self-supervised manner. Specifically, we extend
self-supervised learning from traditional representation learning, which works
on images from a single domain, to domain invariant representation learning,
which works on images from two different domains by utilizing an image-to-image
translation network. Firstly, we use our bidirectional image-to-image
translation network to transfer domain-specific styles between synthetic and
real domains. This style transfer operation allows us to obtain similar images
from the different domains. Secondly, we jointly train our task network and
Siamese network with the same images from the different domains to obtain
domain invariance for the task network. Finally, we fine-tune the task network
using labeled synthetic and unlabeled real-world data. Our training strategy
yields improved generalization capability in the real-world domain. We carry
out an extensive evaluation on two popular datasets for depth estimation, KITTI
and Make3D. The results demonstrate that our proposed method outperforms the
state-of-the-art both qualitatively and quantitatively. The source code and
model weights will be made available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improve the Interpretability of Attention: A Fast, Accurate, and Interpretable High-Resolution Attention Model. (arXiv:2106.02566v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gomez_T/0/1/0/all/0/1">Tristan Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1">Suiyi Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Freour_T/0/1/0/all/0/1">Thomas Fr&#xe9;our</a>, <a href="http://arxiv.org/find/cs/1/au:+Mouchere_H/0/1/0/all/0/1">Harold Mouch&#xe8;re</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02566">
                                    <div class="article-summary-box-inner">
                                        <span>The prevalence of employing attention mechanisms has brought along concerns
on the interpretability of attention distributions. Although it provides
insights about how a model is operating, utilizing attention as the explanation
of model predictions is still highly dubious. The community is still seeking
more interpretable strategies for better identifying local active regions that
contribute the most to the final decision. To improve the interpretability of
existing attention models, we propose a novel Bilinear Representative
Non-Parametric Attention (BR-NPA) strategy that captures the task-relevant
human-interpretable information. The target model is first distilled to have
higher-resolution intermediate feature maps. From which, representative
features are then grouped based on local pairwise feature similarity, to
produce finer-grained, more precise attention maps highlighting task-relevant
parts of the input. The obtained attention maps are ranked according to the
&#x60;active level&#x27; of the compound feature, which provides information regarding
the important level of the highlighted regions. The proposed model can be
easily adapted in a wide variety of modern deep models, where classification is
involved. It is also more accurate, faster, and with a smaller memory footprint
than usual neural attention modules. Extensive experiments showcase more
comprehensive visual explanations compared to the state-of-the-art
visualization model across multiple tasks including few-shot classification,
person re-identification, fine-grained image classification. The proposed
visualization model sheds imperative light on how neural networks &#x60;pay their
attention&#x27; differently in different tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Embedded Deep Regularized Block HSIC Thermomics for Early Diagnosis of Breast Cancer. (arXiv:2106.02106v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yousefi_B/0/1/0/all/0/1">Bardia Yousefi</a>, <a href="http://arxiv.org/find/eess/1/au:+Sharifipour_H/0/1/0/all/0/1">Hossein Memarzadeh Sharifipour</a>, <a href="http://arxiv.org/find/eess/1/au:+Maldague_X/0/1/0/all/0/1">Xavier P.V. Maldague</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02106">
                                    <div class="article-summary-box-inner">
                                        <span>Thermography has been used extensively as a complementary diagnostic tool in
breast cancer detection. Among thermographic methods matrix factorization (MF)
techniques show an unequivocal capability to detect thermal patterns
corresponding to vasodilation in cancer cases. One of the biggest challenges in
such techniques is selecting the best representation of the thermal basis. In
this study, an embedding method is proposed to address this problem and
Deep-semi-nonnegative matrix factorization (Deep-SemiNMF) for thermography is
introduced, then tested for 208 breast cancer screening cases. First, we apply
Deep-SemiNMF to infrared images to extract low-rank thermal representations for
each case. Then, we embed low-rank bases to obtain one basis for each patient.
After that, we extract 300 thermal imaging features, called thermomics, to
decode imaging information for the automatic diagnostic model. We reduced the
dimensionality of thermomics by spanning them onto Hilbert space using RBF
kernel and select the three most efficient features using the block Hilbert
Schmidt Independence Criterion Lasso (block HSIC Lasso). The preserved thermal
heterogeneity successfully classified asymptomatic versus symptomatic patients
applying a random forest model (cross-validated accuracy of 71.36%
(69.42%-73.3%)).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Methods for Vessel Trajectory Prediction based on Recurrent Neural Networks. (arXiv:2101.02486v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Capobianco_S/0/1/0/all/0/1">Samuele Capobianco</a>, <a href="http://arxiv.org/find/cs/1/au:+Millefiori_L/0/1/0/all/0/1">Leonardo M. Millefiori</a>, <a href="http://arxiv.org/find/cs/1/au:+Forti_N/0/1/0/all/0/1">Nicola Forti</a>, <a href="http://arxiv.org/find/cs/1/au:+Braca_P/0/1/0/all/0/1">Paolo Braca</a>, <a href="http://arxiv.org/find/cs/1/au:+Willett_P/0/1/0/all/0/1">Peter Willett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02486">
                                    <div class="article-summary-box-inner">
                                        <span>Data-driven methods open up unprecedented possibilities for maritime
surveillance using Automatic Identification System (AIS) data. In this work, we
explore deep learning strategies using historical AIS observations to address
the problem of predicting future vessel trajectories with a prediction horizon
of several hours. We propose novel sequence-to-sequence vessel trajectory
prediction models based on encoder-decoder recurrent neural networks (RNNs)
that are trained on historical trajectory data to predict future trajectory
samples given previous observations. The proposed architecture combines Long
Short-Term Memory (LSTM) RNNs for sequence modeling to encode the observed data
and generate future predictions with different intermediate aggregation layers
to capture space-time dependencies in sequential data. Experimental results on
vessel trajectories from an AIS dataset made freely available by the Danish
Maritime Authority show the effectiveness of deep-learning methods for
trajectory prediction based on sequence-to-sequence neural networks, which
achieve better performance than baseline approaches based on linear regression
or on the Multi-Layer Perceptron (MLP) architecture. The comparative evaluation
of results shows: i) the superiority of attention pooling over static pooling
for the specific application, and ii) the remarkable performance improvement
that can be obtained with labeled trajectories, i.e., when predictions are
conditioned on a low-level context representation encoded from the sequence of
past observations, as well as on additional inputs (e.g., port of departure or
arrival) about the vessel&#x27;s high-level intention, which may be available from
AIS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Deep Domain Adaptation for LiDAR Perception. (arXiv:2106.02377v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Triess_L/0/1/0/all/0/1">Larissa T. Triess</a>, <a href="http://arxiv.org/find/cs/1/au:+Dreissig_M/0/1/0/all/0/1">Mariella Dreissig</a>, <a href="http://arxiv.org/find/cs/1/au:+Rist_C/0/1/0/all/0/1">Christoph B. Rist</a>, <a href="http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1">J. Marius Z&#xf6;llner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02377">
                                    <div class="article-summary-box-inner">
                                        <span>Scalable systems for automated driving have to reliably cope with an
open-world setting. This means, the perception systems are exposed to drastic
domain shifts, like changes in weather conditions, time-dependent aspects, or
geographic regions. Covering all domains with annotated data is impossible
because of the endless variations of domains and the time-consuming and
expensive annotation process. Furthermore, fast development cycles of the
system additionally introduce hardware changes, such as sensor types and
vehicle setups, and the required knowledge transfer from simulation. To enable
scalable automated driving, it is therefore crucial to address these domain
shifts in a robust and efficient manner. Over the last years, a vast amount of
different domain adaptation techniques evolved. There already exists a number
of survey papers for domain adaptation on camera images, however, a survey for
LiDAR perception is absent. Nevertheless, LiDAR is a vital sensor for automated
driving that provides detailed 3D scans of the vehicle&#x27;s surroundings. To
stimulate future research, this paper presents a comprehensive review of recent
progress in domain adaptation methods and formulates interesting research
questions specifically targeted towards LiDAR perception.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Prospective Observational Study to Investigate Performance of a Chest X-ray Artificial Intelligence Diagnostic Support Tool Across 12 U.S. Hospitals. (arXiv:2106.02118v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Ju Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1">Le Peng</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1">Taihui Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Adila_D/0/1/0/all/0/1">Dyah Adila</a>, <a href="http://arxiv.org/find/eess/1/au:+Zaiman_Z/0/1/0/all/0/1">Zach Zaiman</a>, <a href="http://arxiv.org/find/eess/1/au:+Melton_G/0/1/0/all/0/1">Genevieve B. Melton</a>, <a href="http://arxiv.org/find/eess/1/au:+Ingraham_N/0/1/0/all/0/1">Nicholas Ingraham</a>, <a href="http://arxiv.org/find/eess/1/au:+Murray_E/0/1/0/all/0/1">Eric Murray</a>, <a href="http://arxiv.org/find/eess/1/au:+Boley_D/0/1/0/all/0/1">Daniel Boley</a>, <a href="http://arxiv.org/find/eess/1/au:+Switzer_S/0/1/0/all/0/1">Sean Switzer</a>, <a href="http://arxiv.org/find/eess/1/au:+Burns_J/0/1/0/all/0/1">John L. Burns</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1">Kun Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Allen_T/0/1/0/all/0/1">Tadashi Allen</a>, <a href="http://arxiv.org/find/eess/1/au:+Steenburg_S/0/1/0/all/0/1">Scott D. Steenburg</a>, <a href="http://arxiv.org/find/eess/1/au:+Gichoya_J/0/1/0/all/0/1">Judy Wawira Gichoya</a>, <a href="http://arxiv.org/find/eess/1/au:+Kummerfeld_E/0/1/0/all/0/1">Erich Kummerfeld</a>, <a href="http://arxiv.org/find/eess/1/au:+Tignanelli_C/0/1/0/all/0/1">Christopher Tignanelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02118">
                                    <div class="article-summary-box-inner">
                                        <span>Importance: An artificial intelligence (AI)-based model to predict COVID-19
likelihood from chest x-ray (CXR) findings can serve as an important adjunct to
accelerate immediate clinical decision making and improve clinical decision
making. Despite significant efforts, many limitations and biases exist in
previously developed AI diagnostic models for COVID-19. Utilizing a large set
of local and international CXR images, we developed an AI model with high
performance on temporal and external validation.

Conclusions and Relevance: AI-based diagnostic tools may serve as an adjunct,
but not replacement, for clinical decision support of COVID-19 diagnosis, which
largely hinges on exposure history, signs, and symptoms. While AI-based tools
have not yet reached full diagnostic potential in COVID-19, they may still
offer valuable information to clinicians taken into consideration along with
clinical signs and symptoms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Procedural World Generation Framework for Systematic Evaluation of Continual Learning. (arXiv:2106.02585v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hess_T/0/1/0/all/0/1">Timm Hess</a>, <a href="http://arxiv.org/find/cs/1/au:+Mundt_M/0/1/0/all/0/1">Martin Mundt</a>, <a href="http://arxiv.org/find/cs/1/au:+Pliushch_I/0/1/0/all/0/1">Iuliia Pliushch</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramesh_V/0/1/0/all/0/1">Visvanathan Ramesh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02585">
                                    <div class="article-summary-box-inner">
                                        <span>Several families of continual learning techniques have been proposed to
alleviate catastrophic interference in deep neural network training on
non-stationary data. However, a comprehensive comparison and analysis of
limitations remains largely open due to the inaccessibility to suitable
datasets. Empirical examination not only varies immensely between individual
works, it further currently relies on contrived composition of benchmarks
through subdivision and concatenation of various prevalent static vision
datasets. In this work, our goal is to bridge this gap by introducing a
computer graphics simulation framework that repeatedly renders only upcoming
urban scene fragments in an endless real-time procedural world generation
process. At its core lies a modular parametric generative model with adaptable
generative factors. The latter can be used to flexibly compose data streams,
which significantly facilitates a detailed analysis and allows for effortless
investigation of various continual learning schemes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERT based sentiment analysis: A software engineering perspective. (arXiv:2106.02581v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Batra_H/0/1/0/all/0/1">Himanshu Batra</a>, <a href="http://arxiv.org/find/cs/1/au:+Punn_N/0/1/0/all/0/1">Narinder Singh Punn</a>, <a href="http://arxiv.org/find/cs/1/au:+Sonbhadra_S/0/1/0/all/0/1">Sanjay Kumar Sonbhadra</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1">Sonali Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02581">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment analysis can provide a suitable lead for the tools used in software
engineering along with the API recommendation systems and relevant libraries to
be used. In this context, the existing tools like SentiCR, SentiStrength-SE,
etc. exhibited low f1-scores that completely defeats the purpose of deployment
of such strategies, thereby there is enough scope of performance improvement.
Recent advancements show that transformer based pre-trained models (e.g., BERT,
RoBERTa, ALBERT, etc.) have displayed better results in the text classification
task. Following this context, the present research explores different
BERT-based models to analyze the sentences in GitHub comments, Jira comments,
and Stack Overflow posts. The paper presents three different strategies to
analyse BERT based model for sentiment analysis, where in the first strategy
the BERT based pre-trained models are fine-tuned; in the second strategy an
ensemble model is developed from BERT variants; and in the third strategy a
compressed model (Distil BERT) is used. The experimental results show that the
BERT based ensemble approach and the compressed BERT model attain improvements
by 6-12% over prevailing tools for the F1 measure on all three datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MERLOT: Multimodal Neural Script Knowledge Models. (arXiv:2106.02636v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1">Rowan Zellers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Ximing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1">Jack Hessel</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youngjae Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jae Sung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jize Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02636">
                                    <div class="article-summary-box-inner">
                                        <span>As humans, we understand events in the visual world contextually, performing
multimodal reasoning across time to make inferences about the past, present,
and future. We introduce MERLOT, a model that learns multimodal script
knowledge by watching millions of YouTube videos with transcribed speech -- in
an entirely label-free, self-supervised manner. By pretraining with a mix of
both frame-level (spatial) and video-level (temporal) objectives, our model not
only learns to match images to temporally corresponding words, but also to
contextualize what is happening globally over time. As a result, MERLOT
exhibits strong out-of-the-box representations of temporal commonsense, and
achieves state-of-the-art performance on 12 different video QA datasets when
finetuned. It also transfers well to the world of static images, allowing
models to reason about the dynamic context behind visual scenes. On Visual
Commonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,
outperforming state-of-the-art models of similar size by over 3%, even those
that make heavy use of auxiliary supervised data (like object bounding boxes).

Ablation analyses demonstrate the complementary importance of: 1) training on
videos versus static images; 2) scaling the magnitude and diversity of the
pretraining video corpus; and 3) using diverse objectives that encourage
full-stack multimodal reasoning, from the recognition to cognition level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AI Driven Road Maintenance Inspection. (arXiv:2106.02567v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1">Ratnajit Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Iqbal_H/0/1/0/all/0/1">Haris Iqbal</a>, <a href="http://arxiv.org/find/cs/1/au:+Marzban_S/0/1/0/all/0/1">Shabbir Marzban</a>, <a href="http://arxiv.org/find/cs/1/au:+Badar_A/0/1/0/all/0/1">Ahmed Badar</a>, <a href="http://arxiv.org/find/cs/1/au:+Brouns_T/0/1/0/all/0/1">Terence Brouns</a>, <a href="http://arxiv.org/find/cs/1/au:+Gowda_S/0/1/0/all/0/1">Shruthi Gowda</a>, <a href="http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1">Elahe Arani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1">Bahram Zonooz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02567">
                                    <div class="article-summary-box-inner">
                                        <span>Road infrastructure maintenance inspection is typically a labour-intensive
and critical task to ensure the safety of all the road users. In this work, we
propose a detailed methodology to use state-of-the-art techniques in artificial
intelligence and computer vision to automate a sizeable portion of the
maintenance inspection subtasks and reduce the labour costs. The proposed
methodology uses state-of-the-art computer vision techniques such as object
detection and semantic segmentation to automate inspections on primary road
structures such as the road surface, markings, barriers (guardrails) and
traffic signs. The models are mostly trained on commercially viable datasets
and augmented with proprietary data. We demonstrate that our AI models can not
only automate and scale maintenance inspections on primary road structures but
also result in higher recall compared to traditional manual inspections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pose and Semantic Map Based Probabilistic Forecast of Vulnerable Road Users&#x27; Trajectories. (arXiv:2106.02598v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kress_V/0/1/0/all/0/1">Viktor Kress</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeske_F/0/1/0/all/0/1">Fabian Jeske</a>, <a href="http://arxiv.org/find/cs/1/au:+Zernetsch_S/0/1/0/all/0/1">Stefan Zernetsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Doll_K/0/1/0/all/0/1">Konrad Doll</a>, <a href="http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1">Bernhard Sick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02598">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, an approach for probabilistic trajectory forecasting of
vulnerable road users (VRUs) is presented, which considers past movements and
the surrounding scene. Past movements are represented by 3D poses reflecting
the posture and movements of individual body parts. The surrounding scene is
modeled in the form of semantic maps showing, e.g., the course of streets,
sidewalks, and the occurrence of obstacles. The forecasts are generated in
grids discretizing the space and in the form of arbitrary discrete probability
distributions. The distributions are evaluated in terms of their reliability,
sharpness, and positional accuracy. We compare our method with an approach that
provides forecasts in the form of Gaussian distributions and discuss the
respective advantages and disadvantages. Thereby, we investigate the impact of
using poses and semantic maps. With a technique called spatial label smoothing,
our approach achieves reliable forecasts. Overall, the poses have a positive
impact on the forecasts. The semantic maps offer the opportunity to adapt the
probability distributions to the individual situation, although at the
considered forecasted time horizon of 2.52 s they play a minor role compared to
the past movements of the VRU. Our method is evaluated on a dataset recorded in
inner-city traffic using a research vehicle. The dataset is made publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SOUP-GAN: Super-Resolution MRI Using Generative Adversarial Networks. (arXiv:2106.02599v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Zhang_K/0/1/0/all/0/1">Kuan Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_H/0/1/0/all/0/1">Haoji Hu</a>, <a href="http://arxiv.org/find/eess/1/au:+Philbrick_K/0/1/0/all/0/1">Kenneth Philbrick</a>, <a href="http://arxiv.org/find/eess/1/au:+Conte_G/0/1/0/all/0/1">Gian Marco Conte</a>, <a href="http://arxiv.org/find/eess/1/au:+Sobek_J/0/1/0/all/0/1">Joseph D. Sobek</a>, <a href="http://arxiv.org/find/eess/1/au:+Rouzrokh_P/0/1/0/all/0/1">Pouria Rouzrokh</a>, <a href="http://arxiv.org/find/eess/1/au:+Erickson_B/0/1/0/all/0/1">Bradley J. Erickson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02599">
                                    <div class="article-summary-box-inner">
                                        <span>There is a growing demand for high-resolution (HR) medical images in both the
clinical and research applications. Image quality is inevitably traded off with
the acquisition time for better patient comfort, lower examination costs, dose,
and fewer motion-induced artifacts. For many image-based tasks, increasing the
apparent resolution in the perpendicular plane to produce multi-planar
reformats or 3D images is commonly used. Single image super-resolution (SR) is
a promising technique to provide HR images based on unsupervised learning to
increase resolution of a 2D image, but there are few reports on 3D SR. Further,
perceptual loss is proposed in the literature to better capture the textual
details and edges than using pixel-wise loss functions, by comparing the
semantic distances in the high-dimensional feature space of a pre-trained 2D
network (e.g., VGG). However, it is not clear how one should generalize it to
3D medical images, and the attendant implications are still unclear. In this
paper, we propose a framework called SOUP-GAN: Super-resolution Optimized Using
Perceptual-tuned Generative Adversarial Network (GAN), in order to produce
thinner slice (e.g., high resolution in the &#x27;Z&#x27; plane) medical images with
anti-aliasing and deblurring. The proposed method outperforms other
conventional resolution-enhancement methods and previous SR work on medical
images upon both qualitative and quantitative comparisons. Specifically, we
examine the model in terms of its generalization for various SR ratios and
imaging modalities. By addressing those limitations, our model shows promise as
a novel 3D SR interpolation technique, providing potential applications in both
clinical and research settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ADTrack: Target-Aware Dual Filter Learning for Real-Time Anti-Dark UAV Tracking. (arXiv:2106.02495v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bowen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1">Changhong Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_F/0/1/0/all/0/1">Fangqiang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Junjie Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1">Fuling Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02495">
                                    <div class="article-summary-box-inner">
                                        <span>Prior correlation filter (CF)-based tracking methods for unmanned aerial
vehicles (UAVs) have virtually focused on tracking in the daytime. However,
when the night falls, the trackers will encounter more harsh scenes, which can
easily lead to tracking failure. In this regard, this work proposes a novel
tracker with anti-dark function (ADTrack). The proposed method integrates an
efficient and effective low-light image enhancer into a CF-based tracker.
Besides, a target-aware mask is simultaneously generated by virtue of image
illumination variation. The target-aware mask can be applied to jointly train a
target-focused filter that assists the context filter for robust tracking.
Specifically, ADTrack adopts dual regression, where the context filter and the
target-focused filter restrict each other for dual filter learning. Exhaustive
experiments are conducted on typical dark sceneries benchmark, consisting of 37
typical night sequences from authoritative benchmarks, i.e., UAVDark, and our
newly constructed benchmark UAVDark70. The results have shown that ADTrack
favorably outperforms other state-of-the-art trackers and achieves a real-time
speed of 34 frames/s on a single CPU, greatly extending robust UAV tracking to
night scenes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAFLOW: Conditional Autoregressive Flows. (arXiv:2106.02531v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1">Georgios Batzolis</a>, <a href="http://arxiv.org/find/cs/1/au:+Carioni_M/0/1/0/all/0/1">Marcello Carioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Etmann_C/0/1/0/all/0/1">Christian Etmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Afyouni_S/0/1/0/all/0/1">Soroosh Afyouni</a>, <a href="http://arxiv.org/find/cs/1/au:+Kourtzi_Z/0/1/0/all/0/1">Zoe Kourtzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola Bibiane Sch&#xf6;nlieb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02531">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce CAFLOW, a new diverse image-to-image translation model that
simultaneously leverages the power of auto-regressive modeling and the modeling
efficiency of conditional normalizing flows. We transform the conditioning
image into a sequence of latent encodings using a multi-scale normalizing flow
and repeat the process for the conditioned image. We model the conditional
distribution of the latent encodings by modeling the auto-regressive
distributions with an efficient multi-scale normalizing flow, where each
conditioning factor affects image synthesis at its respective resolution scale.
Our proposed framework performs well on a range of image-to-image translation
tasks. It outperforms former designs of conditional flows because of its
expressive auto-regressive structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Image Local Autoregressive Transformer. (arXiv:2106.02514v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1">Chenjie Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1">Yuxin Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengrong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Chengming Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1">XiangYang Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02514">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, AutoRegressive (AR) models for the whole image generation empowered
by transformers have achieved comparable or even better performance to
Generative Adversarial Networks (GANs). Unfortunately, directly applying such
AR models to edit/change local image regions, may suffer from the problems of
missing global information, slow inference speed, and information leakage of
local guidance. To address these limitations, we propose a novel model -- image
Local Autoregressive Transformer (iLAT), to better facilitate the locally
guided image synthesis. Our iLAT learns the novel local discrete
representations, by the newly proposed local autoregressive (LA) transformer of
the attention mask and convolution mechanism. Thus iLAT can efficiently
synthesize the local image regions by key guidance information. Our iLAT is
evaluated on various locally guided image syntheses, such as pose-guided person
image synthesis and face editing. Both the quantitative and qualitative results
show the efficacy of our model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Aligning Pretraining for Detection via Object-Level Contrastive Learning. (arXiv:2106.02637v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Fangyun Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1">Yue Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhirong Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1">Han Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1">Stephen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02637">
                                    <div class="article-summary-box-inner">
                                        <span>Image-level contrastive representation learning has proven to be highly
effective as a generic model for transfer learning. Such generality for
transfer learning, however, sacrifices specificity if we are interested in a
certain downstream task. We argue that this could be sub-optimal and thus
advocate a design principle which encourages alignment between the
self-supervised pretext task and the downstream task. In this paper, we follow
this principle with a pretraining method specifically designed for the task of
object detection. We attain alignment in the following three aspects: 1)
object-level representations are introduced via selective search bounding boxes
as object proposals; 2) the pretraining network architecture incorporates the
same dedicated modules used in the detection pipeline (e.g. FPN); 3) the
pretraining is equipped with object detection properties such as object-level
translation invariance and scale invariance. Our method, called Selective
Object COntrastive learning (SoCo), achieves state-of-the-art results for
transfer performance on COCO detection using a Mask R-CNN framework. Code and
models will be made available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SOLQ: Segmenting Objects by Learning Queries. (arXiv:2106.02351v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1">Bin Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_F/0/1/0/all/0/1">Fangao Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tiancai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiangyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yichen Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02351">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an end-to-end framework for instance segmentation.
Based on the recently introduced DETR [1], our method, termed SOLQ, segments
objects by learning unified queries. In SOLQ, each query represents one object
and has multiple representations: class, location and mask. The object queries
learned perform classification, box regression and mask encoding simultaneously
in an unified vector form. During training phase, the mask vectors encoded are
supervised by the compression coding of raw spatial masks. In inference time,
mask vectors produced can be directly transformed to spatial masks by the
inverse process of compression coding. Experimental results show that SOLQ can
achieve state-of-the-art performance, surpassing most of existing approaches.
Moreover, the joint learning of unified query representation can greatly
improve the detection performance of original DETR. We hope our SOLQ can serve
as a strong baseline for the Transformer-based instance segmentation. Code is
available at https://github.com/megvii-research/SOLQ.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval. (arXiv:2106.02400v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Manh-Duy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Binh T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurrin_C/0/1/0/all/0/1">Cathal Gurrin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02400">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional approaches to image-text retrieval mainly focus on indexing
visual objects appearing in pictures but ignore the interactions between these
objects. Such objects occurrences and interactions are equivalently useful and
important in this field as they are usually mentioned in the text. Scene graph
presentation is a suitable method for the image-text matching challenge and
obtained good results due to its ability to capture the inter-relationship
information. Both images and text are represented in scene graph levels and
formulate the retrieval challenge as a scene graph matching challenge. In this
paper, we introduce the Local and Global Scene Graph Matching (LGSGM) model
that enhances the state-of-the-art method by integrating an extra graph
convolution network to capture the general information of a graph.
Specifically, for a pair of scene graphs of an image and its caption, two
separate models are used to learn the features of each graph&#x27;s nodes and edges.
Then a Siamese-structure graph convolution model is employed to embed graphs
into vector forms. We finally combine the graph-level and the vector-level to
calculate the similarity of this image-text pair. The empirical experiments
show that our enhancement with the combination of levels can improve the
performance of the baseline method by increasing the recall by more than 10% on
the Flickr30k dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid attention network based on progressive embedding scale-context for crowd counting. (arXiv:2106.02324v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1">Fusen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sang_J/0/1/0/all/0/1">Jun Sang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhongyuan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sang_N/0/1/0/all/0/1">Nong Sang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02324">
                                    <div class="article-summary-box-inner">
                                        <span>The existing crowd counting methods usually adopted attention mechanism to
tackle background noise, or applied multi-level features or multi-scales
context fusion to tackle scale variation. However, these approaches deal with
these two problems separately. In this paper, we propose a Hybrid Attention
Network (HAN) by employing Progressive Embedding Scale-context (PES)
information, which enables the network to simultaneously suppress noise and
adapt head scale variation. We build the hybrid attention mechanism through
paralleling spatial attention and channel attention module, which makes the
network to focus more on the human head area and reduce the interference of
background objects. Besides, we embed certain scale-context to the hybrid
attention along the spatial and channel dimensions for alleviating these
counting errors caused by the variation of perspective and head scale. Finally,
we propose a progressive learning strategy through cascading multiple hybrid
attention modules with embedding different scale-context, which can gradually
integrate different scale-context information into the current feature map from
global to local. Ablation experiments provides that the network architecture
can gradually learn multi-scale features and suppress background noise.
Extensive experiments demonstrate that HANet obtain state-of-the-art counting
performance on four mainstream datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Gastric Histopathology Subsize Image Database (GasHisSDB) for Classification Algorithm Test: from Linear Regression to Visual Transformer. (arXiv:2106.02473v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weiming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoyan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoyuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wanli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changhao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1">Marcin Grzegorzek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02473">
                                    <div class="article-summary-box-inner">
                                        <span>GasHisSDB is a New Gastric Histopathology Subsize Image Database with a total
of 245196 images. GasHisSDB is divided into 160*160 pixels sub-database,
120*120 pixels sub-database and 80*80 pixels sub-database. GasHisSDB is made to
realize the function of valuating image classification. In order to prove that
the methods of different periods in the field of image classification have
discrepancies on GasHisSDB, we select a variety of classifiers for evaluation.
Seven classical machine learning classifiers, three CNN classifiers and a novel
transformer-based classifier are selected for testing on image classification
tasks. GasHisSDB is available at the
URL:https://github.com/NEUhwm/GasHisSDB.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controlling False Positive/Negative Rates for Deep-Learning-Based Prostate Cancer Detection on Multiparametric MR images. (arXiv:2106.02385v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Min_Z/0/1/0/all/0/1">Zhe Min</a>, <a href="http://arxiv.org/find/eess/1/au:+Bianco_F/0/1/0/all/0/1">Fernando J. Bianco</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_Q/0/1/0/all/0/1">Qianye Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Rodell_R/0/1/0/all/0/1">Rachael Rodell</a>, <a href="http://arxiv.org/find/eess/1/au:+Yan_W/0/1/0/all/0/1">Wen Yan</a>, <a href="http://arxiv.org/find/eess/1/au:+Barratt_D/0/1/0/all/0/1">Dean Barratt</a>, <a href="http://arxiv.org/find/eess/1/au:+Hu_Y/0/1/0/all/0/1">Yipeng Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02385">
                                    <div class="article-summary-box-inner">
                                        <span>Prostate cancer (PCa) is one of the leading causes of death for men
worldwide. Multi-parametric magnetic resonance (mpMR) imaging has emerged as a
non-invasive diagnostic tool for detecting and localising prostate tumours by
specialised radiologists. These radiological examinations, for example, for
differentiating malignant lesions from benign prostatic hyperplasia in
transition zones and for defining the boundaries of clinically significant
cancer, remain challenging and highly skill-and-experience-dependent. We first
investigate experimental results in developing object detection neural networks
that are trained to predict the radiological assessment, using these
high-variance labels. We further argue that such a computer-assisted diagnosis
(CAD) system needs to have the ability to control the false-positive rate (FPR)
or false-negative rate (FNR), in order to be usefully deployed in a clinical
workflow, informing clinical decisions without further human intervention. This
work proposes a novel PCa detection network that incorporates a lesion-level
cost-sensitive loss and an additional slice-level loss based on a
lesion-to-slice mapping function, to manage the lesion- and slice-level costs,
respectively. Our experiments based on 290 clinical patients concludes that 1)
The lesion-level FNR was effectively reduced from 0.19 to 0.10 and the
lesion-level FPR was reduced from 1.03 to 0.66 by changing the lesion-level
cost; 2) The slice-level FNR was reduced from 0.19 to 0.00 by taking into
account the slice-level cost; (3) Both lesion-level and slice-level FNRs were
reduced with lower FP/FPR by changing the lesion-level or slice-level costs,
compared with post-training threshold adjustment using networks without the
proposed cost-aware training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human-Adversarial Visual Question Answering. (arXiv:2106.02280v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheng_S/0/1/0/all/0/1">Sasha Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1">Amanpreet Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Goswami_V/0/1/0/all/0/1">Vedanuj Goswami</a>, <a href="http://arxiv.org/find/cs/1/au:+Magana_J/0/1/0/all/0/1">Jose Alberto Lopez Magana</a>, <a href="http://arxiv.org/find/cs/1/au:+Galuba_W/0/1/0/all/0/1">Wojciech Galuba</a>, <a href="http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1">Devi Parikh</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02280">
                                    <div class="article-summary-box-inner">
                                        <span>Performance on the most commonly used Visual Question Answering dataset (VQA
v2) is starting to approach human accuracy. However, in interacting with
state-of-the-art VQA models, it is clear that the problem is far from being
solved. In order to stress test VQA models, we benchmark them against
human-adversarial examples. Human subjects interact with a state-of-the-art VQA
model, and for each image in the dataset, attempt to find a question where the
model&#x27;s predicted answer is incorrect. We find that a wide range of
state-of-the-art models perform poorly when evaluated on these examples. We
conduct an extensive analysis of the collected adversarial examples and provide
guidance on future research directions. We hope that this Adversarial VQA
(AdVQA) benchmark can help drive progress in the field and advance the state of
the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MASA-SR: Matching Acceleration and Spatial Adaptation for Reference-Based Image Super-Resolution. (arXiv:2106.02299v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_L/0/1/0/all/0/1">Liying Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenbo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_X/0/1/0/all/0/1">Xin Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiangbo Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1">Jiaya Jia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02299">
                                    <div class="article-summary-box-inner">
                                        <span>Reference-based image super-resolution (RefSR) has shown promising success in
recovering high-frequency details by utilizing an external reference image
(Ref). In this task, texture details are transferred from the Ref image to the
low-resolution (LR) image according to their point- or patch-wise
correspondence. Therefore, high-quality correspondence matching is critical. It
is also desired to be computationally efficient. Besides, existing RefSR
methods tend to ignore the potential large disparity in distributions between
the LR and Ref images, which hurts the effectiveness of the information
utilization. In this paper, we propose the MASA network for RefSR, where two
novel modules are designed to address these problems. The proposed Match &amp;
Extraction Module significantly reduces the computational cost by a
coarse-to-fine correspondence matching scheme. The Spatial Adaptation Module
learns the difference of distribution between the LR and Ref images, and remaps
the distribution of Ref features to that of LR features in a spatially adaptive
way. This scheme makes the network robust to handle different reference images.
Extensive quantitative and qualitative experiments validate the effectiveness
of our proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Correspondence with Transformers. (arXiv:2106.02520v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1">Seokju Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1">Sunghwan Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeon_S/0/1/0/all/0/1">Sangryul Jeon</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Yunsung Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Sohn_K/0/1/0/all/0/1">Kwanghoon Sohn</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Seungryong Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02520">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel cost aggregation network, called Cost Aggregation with
Transformers (CATs), to find dense correspondences between semantically similar
images with additional challenges posed by large intra-class appearance and
geometric variations. Compared to previous hand-crafted or CNN-based methods
addressing the cost aggregation stage, which either lack robustness to severe
deformations or inherit the limitation of CNNs that fail to discriminate
incorrect matches due to limited receptive fields, CATs explore global
consensus among initial correlation map with the help of some architectural
designs that allow us to exploit full potential of self-attention mechanism.
Specifically, we include appearance affinity modelling to disambiguate the
initial correlation maps and multi-level aggregation to benefit from
hierarchical feature representations within Transformer-based aggregator, and
combine with swapping self-attention and residual connections not only to
enforce consistent matching, but also to ease the learning process. We conduct
experiments to demonstrate the effectiveness of the proposed model over the
latest methods and provide extensive ablation studies. Code and trained models
will be made available at https://github.com/SunghwanHong/CATs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hallucination In Object Detection -- A Study In Visual Part Verification. (arXiv:2106.02523v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kayhan_O/0/1/0/all/0/1">Osman Semih Kayhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vredebregt_B/0/1/0/all/0/1">Bart Vredebregt</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1">Jan C. van Gemert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02523">
                                    <div class="article-summary-box-inner">
                                        <span>We show that object detectors can hallucinate and detect missing objects;
potentially even accurately localized at their expected, but non-existing,
position. This is particularly problematic for applications that rely on visual
part verification: detecting if an object part is present or absent. We show
how popular object detectors hallucinate objects in a visual part verification
task and introduce the first visual part verification dataset: DelftBikes,
which has 10,000 bike photographs, with 22 densely annotated parts per image,
where some parts may be missing. We explicitly annotated an extra object state
label for each part to reflect if a part is missing or intact. We propose to
evaluate visual part verification by relying on recall and compare popular
object detectors on DelftBikes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Covering Polygons is Even Harder. (arXiv:2106.02335v1 [cs.CG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abrahamsen_M/0/1/0/all/0/1">Mikkel Abrahamsen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02335">
                                    <div class="article-summary-box-inner">
                                        <span>In the MINIMUM CONVEX COVER (MCC) problem, we are given a simple polygon
$\mathcal P$ and an integer $k$, and the question is if there exist $k$ convex
polygons whose union is $\mathcal P$. It is known that MCC is
$\mathsf{NP}$-hard [Culberson &amp; Reckhow: Covering polygons is hard, FOCS
1988/Journal of Algorithms 1994] and in $\exists\mathbb{R}$ [O&#x27;Rourke: The
complexity of computing minimum convex covers for polygons, Allerton 1982]. We
prove that MCC is $\exists\mathbb{R}$-hard, and the problem is thus
$\exists\mathbb{R}$-complete. In other words, the problem is equivalent to
deciding whether a system of polynomial equations and inequalities with integer
coefficients has a real solution.

If a cover for our constructed polygon exists, then so does a cover
consisting entirely of triangles. As a byproduct, we therefore also establish
that it is $\exists\mathbb{R}$-complete to decide whether $k$ triangles cover a
given polygon.

The issue that it was not known if finding a minimum cover is in
$\mathsf{NP}$ has repeatedly been raised in the literature, and it was
mentioned as a &quot;long-standing open question&quot; already in 2001 [Eidenbenz &amp;
Widmayer: An approximation algorithm for minimum convex cover with logarithmic
performance guarantee, ESA 2001/SIAM Journal on Computing 2003]. We prove that
assuming the widespread belief that $\mathsf{NP}\neq\exists\mathbb{R}$, the
problem is not in $\mathsf{NP}$.

An implication of the result is that many natural approaches to finding small
covers are bound to give suboptimal solutions in some cases, since irrational
coordinates of arbitrarily high algebraic degree can be needed for the corners
of the pieces in an optimal solution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RoadMap: A Light-Weight Semantic Map for Visual Localization towards Autonomous Driving. (arXiv:2106.02527v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1">Tong Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yuxin Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tongqing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yilun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1">Qing Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02527">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate localization is of crucial importance for autonomous driving tasks.
Nowadays, we have seen a lot of sensor-rich vehicles (e.g. Robo-taxi) driving
on the street autonomously, which rely on high-accurate sensors (e.g. Lidar and
RTK GPS) and high-resolution map. However, low-cost production cars cannot
afford such high expenses on sensors and maps. How to reduce costs? How do
sensor-rich vehicles benefit low-cost cars? In this paper, we proposed a
light-weight localization solution, which relies on low-cost cameras and
compact visual semantic maps. The map is easily produced and updated by
sensor-rich vehicles in a crowd-sourced way. Specifically, the map consists of
several semantic elements, such as lane line, crosswalk, ground sign, and stop
line on the road surface. We introduce the whole framework of on-vehicle
mapping, on-cloud maintenance, and user-end localization. The map data is
collected and preprocessed on vehicles. Then, the crowd-sourced data is
uploaded to a cloud server. The mass data from multiple vehicles are merged on
the cloud so that the semantic map is updated in time. Finally, the semantic
map is compressed and distributed to production cars, which use this map for
localization. We validate the performance of the proposed map in real-world
experiments and compare it against other algorithms. The average size of the
semantic map is $36$ kb/km. We highlight that this framework is a reliable and
practical localization solution for autonomous driving.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporally coherent video anonymization through GAN inpainting. (arXiv:2106.02328v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balaji_T/0/1/0/all/0/1">Thangapavithraa Balaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Blies_P/0/1/0/all/0/1">Patrick Blies</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_G/0/1/0/all/0/1">Georg G&#xf6;ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitsch_R/0/1/0/all/0/1">Raphael Mitsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Wasserer_M/0/1/0/all/0/1">Marcel Wasserer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1">Torsten Sch&#xf6;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02328">
                                    <div class="article-summary-box-inner">
                                        <span>This work tackles the problem of temporally coherent face anonymization in
natural video streams.We propose JaGAN, a two-stage system starting with
detecting and masking out faces with black image patches in all individual
frames of the video. The second stage leverages a privacy-preserving Video
Generative Adversarial Network designed to inpaint the missing image patches
with artificially generated faces. Our initial experiments reveal that image
based generative models are not capable of inpainting patches showing temporal
coherent appearance across neighboring video frames. To address this issue we
introduce a newly curated video collection, which is made publicly available
for the research community along with this paper. We also introduce the
Identity Invariance Score IdI as a means to quantify temporal coherency between
neighboring frames.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fine-Grained Visual Classification of Plant Species In The Wild: Object Detection as A Reinforced Means of Attention. (arXiv:2106.02141v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keaton_M/0/1/0/all/0/1">Matthew R. Keaton</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaveri_R/0/1/0/all/0/1">Ram J. Zaveri</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovur_M/0/1/0/all/0/1">Meghana Kovur</a>, <a href="http://arxiv.org/find/cs/1/au:+Henderson_C/0/1/0/all/0/1">Cole Henderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Adjeroh_D/0/1/0/all/0/1">Donald A. Adjeroh</a>, <a href="http://arxiv.org/find/cs/1/au:+Doretto_G/0/1/0/all/0/1">Gianfranco Doretto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02141">
                                    <div class="article-summary-box-inner">
                                        <span>Plant species identification in the wild is a difficult problem in part due
to the high variability of the input data, but also because of complications
induced by the long-tail effects of the datasets distribution. Inspired by the
most recent fine-grained visual classification approaches which are based on
attention to mitigate the effects of data variability, we explore the idea of
using object detection as a form of attention. We introduce a bottom-up
approach based on detecting plant organs and fusing the predictions of a
variable number of organ-based species classifiers. We also curate a new
dataset with a long-tail distribution for evaluating plant organ detection and
organ-based species identification, which is publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis of the robustness of NMF algorithms. (arXiv:2106.02213v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diaz_A/0/1/0/all/0/1">Alex D&#xed;az</a>, <a href="http://arxiv.org/find/cs/1/au:+Steele_D/0/1/0/all/0/1">Damian Steele</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02213">
                                    <div class="article-summary-box-inner">
                                        <span>We examine three non-negative matrix factorization techniques; L2-norm,
L1-norm, and L2,1-norm. Our aim is to establish the performance of these
different approaches, and their robustness in real-world applications such as
feature selection while managing computational complexity, sensitivity to noise
and more. We thoroughly examine each approach from a theoretical perspective,
and examine the performance of each using a series of experiments drawing on
both the ORL and YaleB datasets. We examine the Relative Reconstruction Errors
(RRE), Average Accuracy and Normalized Mutual Information (NMI) as criteria
under a range of simulated noise scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subdivision-Based Mesh Convolution Networks. (arXiv:2106.02285v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shi-Min Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zheng-Ning Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Meng-Hao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jun-Xiong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiahui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1">Tai-Jiang Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1">Ralph R. Martin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02285">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have made great breakthroughs in 2D
computer vision. However, the irregular structure of meshes makes it hard to
exploit the power of CNNs directly. A subdivision surface provides a
hierarchical multi-resolution structure, and each face in a closed 2-manifold
triangle mesh is exactly adjacent to three faces. Motivated by these two
properties, this paper introduces a novel and flexible CNN framework, named
SubdivNet, for 3D triangle meshes with Loop subdivision sequence connectivity.
Making an analogy between mesh faces and pixels in a 2D image allows us to
present a mesh convolution operator to aggregate local features from adjacent
faces. By exploiting face neighborhoods, this convolution can support standard
2D convolutional network concepts, e.g. variable kernel size, stride, and
dilation. Based on the multi-resolution hierarchy, we propose a spatial uniform
pooling layer which merges four faces into one and an upsampling method which
splits one face into four. As a result, many popular 2D CNN architectures can
be readily adapted to processing 3D meshes. Meshes with arbitrary connectivity
can be remeshed to hold Loop subdivision sequence connectivity via
self-parameterization, making SubdivNet a general approach. Experiments on mesh
classification, segmentation, correspondence, and retrieval from the real-world
demonstrate the effectiveness and efficiency of SubdivNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DOCTOR: A Simple Method for Detecting Misclassification Errors. (arXiv:2106.02395v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Granese_F/0/1/0/all/0/1">Federica Granese</a>, <a href="http://arxiv.org/find/cs/1/au:+Romanelli_M/0/1/0/all/0/1">Marco Romanelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorla_D/0/1/0/all/0/1">Daniele Gorla</a>, <a href="http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1">Catuscia Palamidessi</a>, <a href="http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1">Pablo Piantanida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02395">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) have shown to perform very well on large scale
object recognition problems and lead to widespread use for real-world
applications, including situations where DNN are implemented as &quot;black boxes&quot;.
A promising approach to secure their use is to accept decisions that are likely
to be correct while discarding the others. In this work, we propose DOCTOR, a
simple method that aims to identify whether the prediction of a DNN classifier
should (or should not) be trusted so that, consequently, it would be possible
to accept it or to reject it. Two scenarios are investigated: Totally Black Box
(TBB) where only the soft-predictions are available and Partially Black Box
(PBB) where gradient-propagation to perform input pre-processing is allowed.
Empirically, we show that DOCTOR outperforms all state-of-the-art methods on
various well-known images and sentiment analysis datasets. In particular, we
observe a reduction of up to $4\%$ of the false rejection rate (FRR) in the PBB
scenario. DOCTOR can be applied to any pre-trained model, it does not require
prior information about the underlying dataset and is as simple as the simplest
available methods in the literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Associating Objects with Transformers for Video Object Segmentation. (arXiv:2106.02638v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zongxin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02638">
                                    <div class="article-summary-box-inner">
                                        <span>This paper investigates how to realize better and more efficient embedding
learning to tackle the semi-supervised video object segmentation under
challenging multi-object scenarios. The state-of-the-art methods learn to
decode features with a single positive object and thus have to match and
segment each target separately under multi-object scenarios, consuming multiple
times computing resources. To solve the problem, we propose an Associating
Objects with Transformers (AOT) approach to match and decode multiple objects
uniformly. In detail, AOT employs an identification mechanism to associate
multiple targets into the same high-dimensional embedding space. Thus, we can
simultaneously process the matching and segmentation decoding of multiple
objects as efficiently as processing a single object. For sufficiently modeling
multi-object association, a Long Short-Term Transformer is designed for
constructing hierarchical matching and propagation. We conduct extensive
experiments on both multi-object and single-object benchmarks to examine AOT
variant networks with different complexities. Particularly, our AOT-L
outperforms all the state-of-the-art competitors on three popular benchmarks,
i.e., YouTube-VOS (83.7% J&amp;F), DAVIS 2017 (83.0%), and DAVIS 2016 (91.0%),
while keeping better multi-object efficiency. Meanwhile, our AOT-T can maintain
real-time multi-object speed on above benchmarks. We ranked 1st in the 3rd
Large-scale Video Object Segmentation Challenge. The code will be publicly
available at https://github.com/z-x-yang/AOT.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Segmentation via Cycle-Consistent Transformer. (arXiv:2106.02320v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Gengwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_G/0/1/0/all/0/1">Guoliang Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02320">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot segmentation aims to train a segmentation model that can fast adapt
to novel classes with few exemplars. The conventional training paradigm is to
learn to make predictions on query images conditioned on the features from
support images. Previous methods only utilized the semantic-level prototypes of
support images as the conditional information. These methods cannot utilize all
pixel-wise support information for the query predictions, which is however
critical for the segmentation task. In this paper, we focus on utilizing
pixel-wise relationships between support and target images to facilitate the
few-shot semantic segmentation task. We design a novel Cycle-Consistent
Transformer (CyCTR) module to aggregate pixel-wise support features into query
ones. CyCTR performs cross-attention between features from different images,
i.e. support and query images. We observe that there may exist unexpected
irrelevant pixel-level support features. Directly performing cross-attention
may aggregate these features from support to query and bias the query features.
Thus, we propose using a novel cycle-consistent attention mechanism to filter
out possible harmful support features and encourage query features to attend to
the most informative pixels from support images. Experiments on all few-shot
segmentation benchmarks demonstrate that our proposed CyCTR leads to remarkable
improvement compared to previous state-of-the-art methods. Specifically, on
Pascal-$5^i$ and COCO-$20^i$ datasets, we achieve 66.6% and 45.6% mIoU for
5-shot segmentation, outperforming previous state-of-the-art by 4.6% and 7.1%
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NMS-Loss: Learning with Non-Maximum Suppression for Crowded Pedestrian Detection. (arXiv:2106.02426v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Zekun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1">Zheng Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1">Sixiao Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yabiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yanwei Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02426">
                                    <div class="article-summary-box-inner">
                                        <span>Non-Maximum Suppression (NMS) is essential for object detection and affects
the evaluation results by incorporating False Positives (FP) and False
Negatives (FN), especially in crowd occlusion scenes. In this paper, we raise
the problem of weak connection between the training targets and the evaluation
metrics caused by NMS and propose a novel NMS-Loss making the NMS procedure can
be trained end-to-end without any additional network parameters. Our NMS-Loss
punishes two cases when FP is not suppressed and FN is wrongly eliminated by
NMS. Specifically, we propose a pull loss to pull predictions with the same
target close to each other, and a push loss to push predictions with different
targets away from each other. Experimental results show that with the help of
NMS-Loss, our detector, namely NMS-Ped, achieves impressive results with Miss
Rate of 5.92% on Caltech dataset and 10.08% on CityPersons dataset, which are
both better than state-of-the-art competitors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Glance-and-Gaze Vision Transformer. (arXiv:2106.02277v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qihang Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yingda Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yutong Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yongyi Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1">Alan Yuille</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1">Wei Shen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02277">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there emerges a series of vision Transformers, which show superior
performance with a more compact model size than conventional convolutional
neural networks, thanks to the strong ability of Transformers to model
long-range dependencies. However, the advantages of vision Transformers also
come with a price: Self-attention, the core part of Transformer, has a
quadratic complexity to the input sequence length. This leads to a dramatic
increase of computation and memory cost with the increase of sequence length,
thus introducing difficulties when applying Transformers to the vision tasks
that require dense predictions based on high-resolution feature maps. In this
paper, we propose a new vision Transformer, named Glance-and-Gaze Transformer
(GG-Transformer), to address the aforementioned issues. It is motivated by the
Glance and Gaze behavior of human beings when recognizing objects in natural
scenes, with the ability to efficiently model both long-range dependencies and
local context. In GG-Transformer, the Glance and Gaze behavior is realized by
two parallel branches: The Glance branch is achieved by performing
self-attention on the adaptively-dilated partitions of the input, which leads
to a linear complexity while still enjoying a global receptive field; The Gaze
branch is implemented by a simple depth-wise convolutional layer, which
compensates local image context to the features obtained by the Glance
mechanism. We empirically demonstrate our method achieves consistently superior
performance over previous state-of-the-art Transformers on various vision tasks
and benchmarks. The codes and models will be made available at
https://github.com/yucornetto/GG-Transformer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ukiyo-e Analysis and Creativity with Attribute and Geometry Annotation. (arXiv:2106.02267v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yingtao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1">Tarin Clanuwat</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_C/0/1/0/all/0/1">Chikahiko Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1">Asanobu Kitamoto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02267">
                                    <div class="article-summary-box-inner">
                                        <span>The study of Ukiyo-e, an important genre of pre-modern Japanese art, focuses
on the object and style like other artwork researches. Such study has benefited
from the renewed interest by the machine learning community in culturally
important topics, leading to interdisciplinary works including collections of
images, quantitative approaches, and machine learning-based creativities. They,
however, have several drawbacks, and it remains challenging to integrate these
works into a comprehensive view. To bridge this gap, we propose a holistic
approach We first present a large-scale Ukiyo-e dataset with coherent semantic
labels and geometric annotations, then show its value in a quantitative study
of Ukiyo-e paintings&#x27; object using these labels and annotations. We further
demonstrate the machine learning methods could help style study through soft
color decomposition of Ukiyo-e, and finally provides joint insights into object
and style by composing sketches and colors using colorization. Dataset
available at https://github.com/rois-codh/arc-ukiyoe-faces</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">History Encoding Representation Design for Human Intention Inference. (arXiv:2106.02222v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhuo Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1">Masayoshi Tomizuka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02222">
                                    <div class="article-summary-box-inner">
                                        <span>In this extended abstract, we investigate the design of learning
representation for human intention inference. In our designed human intention
prediction task, we propose a history encoding representation that is both
interpretable and effective for prediction. Through extensive experiments, we
show our prediction framework with a history encoding representation design is
successful on the human intention prediction problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RL-DARTS: Differentiable Architecture Search for Reinforcement Learning. (arXiv:2106.02229v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Miao_Y/0/1/0/all/0/1">Yingjie Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xingyou Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Daiyi Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1">Summer Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Brevdo_E/0/1/0/all/0/1">Eugene Brevdo</a>, <a href="http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1">Aleksandra Faust</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02229">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce RL-DARTS, one of the first applications of Differentiable
Architecture Search (DARTS) in reinforcement learning (RL) to search for
convolutional cells, applied to the Procgen benchmark. We outline the initial
difficulties of applying neural architecture search techniques in RL, and
demonstrate that by simply replacing the image encoder with a DARTS supernet,
our search method is sample-efficient, requires minimal extra compute
resources, and is also compatible with off-policy and on-policy RL algorithms,
needing only minor changes in preexisting code. Surprisingly, we find that the
supernet can be used as an actor for inference to generate replay data in
standard RL training loops, and thus train end-to-end. Throughout this training
process, we show that the supernet gradually learns better cells, leading to
alternative architectures which can be highly competitive against manually
designed policies, but also verify previous design choices for RL policies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-volution: On the unification of convolution and self-attention. (arXiv:2106.02253v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xuanhong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ni_B/0/1/0/all/0/1">Bingbing Ni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02253">
                                    <div class="article-summary-box-inner">
                                        <span>Convolution and self-attention are acting as two fundamental building blocks
in deep neural networks, where the former extracts local image features in a
linear way while the latter non-locally encodes high-order contextual
relationships. Though essentially complementary to each other, i.e.,
first-/high-order, stat-of-the-art architectures, i.e., CNNs or transformers
lack a principled way to simultaneously apply both operations in a single
computational module, due to their heterogeneous computing pattern and
excessive burden of global dot-product for visual tasks. In this work, we
theoretically derive a global self-attention approximation scheme, which
approximates a self-attention via the convolution operation on transformed
features. Based on the approximated scheme, we establish a multi-branch
elementary module composed of both convolution and self-attention operation,
capable of unifying both local and non-local feature interaction. Importantly,
once trained, this multi-branch module could be conditionally converted into a
single standard convolution operation via structural re-parameterization,
rendering a pure convolution styled operator named X-volution, ready to be
plugged into any modern networks as an atomic operation. Extensive experiments
demonstrate that the proposed X-volution, achieves highly competitive visual
understanding improvements (+1.2% top-1 accuracy on ImageNet classification,
+1.7 box AP and +1.5 mask AP on COCO detection and segmentation).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CNNs and GANs in MRI-based cross-modality medical image estimation. (arXiv:2106.02198v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fard_A/0/1/0/all/0/1">Azin Shokraei Fard</a>, <a href="http://arxiv.org/find/eess/1/au:+Reutens_D/0/1/0/all/0/1">David C. Reutens</a>, <a href="http://arxiv.org/find/eess/1/au:+Vegh_V/0/1/0/all/0/1">Viktor Vegh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02198">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-modality image estimation involves the generation of images of one
medical imaging modality from that of another modality. Convolutional neural
networks (CNNs) have been shown to be useful in identifying, characterising and
extracting image patterns. Generative adversarial networks (GANs) use CNNs as
generators and estimated images are discriminated as true or false based on an
additional network. CNNs and GANs within the image estimation framework may be
considered more generally as deep learning approaches, since imaging data tends
to be large, leading to a larger number of network weights. Almost all research
in the CNN/GAN image estimation literature has involved the use of MRI data
with the other modality primarily being PET or CT. This review provides an
overview of the use of CNNs and GANs for MRI-based cross-modality medical image
estimation. We outline the neural networks implemented, and detail network
constructs employed for CNN and GAN image-to-image estimators. Motivations
behind cross-modality image estimation are provided as well. GANs appear to
provide better utility in cross-modality image estimation in comparison with
CNNs, a finding drawn based on our analysis involving metrics comparing
estimated and actual images. Our final remarks highlight key challenges faced
by the cross-modality medical image estimation field, and suggestions for
future research are outlined.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Question Rewriting for Increasing Response Rate. (arXiv:2106.02257v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jiayi Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xilian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02257">
                                    <div class="article-summary-box-inner">
                                        <span>When a human asks questions online, or when a conversational virtual agent
asks human questions, questions triggering emotions or with details might more
likely to get responses or answers. we explore how to automatically rewrite
natural language questions to improve the response rate from people. In
particular, a new task of Visual Question Rewriting(VQR) task is introduced to
explore how visual information can be used to improve the new questions. A data
set containing around 4K bland questions, attractive questions and images
triples is collected. We developed some baseline sequence to sequence models
and more advanced transformer based models, which take a bland question and a
related image as input and output a rewritten question that is expected to be
more attractive. Offline experiments and mechanical Turk based evaluations show
that it is possible to rewrite bland questions in a more detailed and
attractive way to increase the response rate, and images can be helpful.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ASCNet: Self-supervised Video Representation Learning with Appearance-Speed Consistency. (arXiv:2106.02342v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1">Deng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wenhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weiwen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1">Dongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhihua Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiangmiao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_M/0/1/0/all/0/1">Mingkui Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_E/0/1/0/all/0/1">Errui Ding</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02342">
                                    <div class="article-summary-box-inner">
                                        <span>We study self-supervised video representation learning, which is a
challenging task due to 1) a lack of labels for explicit supervision and 2)
unstructured and noisy visual information. Existing methods mainly use
contrastive loss with video clips as the instances and learn visual
representation by discriminating instances from each other, but they require
careful treatment of negative pairs by relying on large batch sizes, memory
banks, extra modalities, or customized mining strategies, inevitably including
noisy data. In this paper, we observe that the consistency between positive
samples is the key to learn robust video representations. Specifically, we
propose two tasks to learn the appearance and speed consistency, separately.
The appearance consistency task aims to maximize the similarity between two
clips of the same video with different playback speeds. The speed consistency
task aims to maximize the similarity between two clips with the same playback
speed but different appearance information. We show that joint optimization of
the two tasks consistently improves the performance on downstream tasks, e.g.,
action recognition and video retrieval. Remarkably, for action recognition on
the UCF-101 dataset, we achieve 90.8% accuracy without using any additional
modalities or negative pairs for unsupervised pretraining, outperforming the
ImageNet supervised pre-trained model. Codes and models will be available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Adversarial Learning for Deep Semi-Supervised Facial Action Unit Recognition. (arXiv:2106.02258v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shangfei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1">Yanan Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_G/0/1/0/all/0/1">Guozhu Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_B/0/1/0/all/0/1">Bowen Pan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02258">
                                    <div class="article-summary-box-inner">
                                        <span>Current works formulate facial action unit (AU) recognition as a supervised
learning problem, requiring fully AU-labeled facial images during training. It
is challenging if not impossible to provide AU annotations for large numbers of
facial images. Fortunately, AUs appear on all facial images, whether manually
labeled or not, satisfy the underlying anatomic mechanisms and human behavioral
habits. In this paper, we propose a deep semi-supervised framework for facial
action unit recognition from partially AU-labeled facial images. Specifically,
the proposed deep semi-supervised AU recognition approach consists of a deep
recognition network and a discriminator D. The deep recognition network R
learns facial representations from large-scale facial images and AU classifiers
from limited ground truth AU labels. The discriminator D is introduced to
enforce statistical similarity between the AU distribution inherent in ground
truth AU labels and the distribution of the predicted AU labels from labeled
and unlabeled facial images. The deep recognition network aims to minimize
recognition loss from the labeled facial images, to faithfully represent
inherent AU distribution for both labeled and unlabeled facial images, and to
confuse the discriminator. During training, the deep recognition network R and
the discriminator D are optimized alternately. Thus, the inherent AU
distributions caused by underlying anatomic mechanisms are leveraged to
construct better feature representations and AU classifiers from partially
AU-labeled data during training. Experiments on two benchmark databases
demonstrate that the proposed approach successfully captures AU distributions
through adversarial learning and outperforms state-of-the-art AU recognition
work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Specular reflections removal in colposcopic images based on neural networks: Supervised training with no ground truth previous knowledge. (arXiv:2106.02221v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Jimenez_Martin_L/0/1/0/all/0/1">Lauren Jimenez-Martin</a>, <a href="http://arxiv.org/find/eess/1/au:+Perez_D/0/1/0/all/0/1">Daniel A. Vald&#xe9;s P&#xe9;rez</a>, <a href="http://arxiv.org/find/eess/1/au:+Asteasuainzarra_A/0/1/0/all/0/1">Ana M. Solares Asteasuainzarra</a>, <a href="http://arxiv.org/find/eess/1/au:+Leonard_L/0/1/0/all/0/1">Ludwig Leonard</a>, <a href="http://arxiv.org/find/eess/1/au:+Diaz_Romanach_M/0/1/0/all/0/1">Marta L. Baguer D&#xed;az-Roma&#xf1;ach</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02221">
                                    <div class="article-summary-box-inner">
                                        <span>Cervical cancer is a malignant tumor that seriously threatens women&#x27;s health,
and is one of the most common that affects women worldwide. For its early
detection, colposcopic images of the cervix are used for searching for possible
injuries or abnormalities. An inherent characteristic of these images is the
presence of specular reflections (brightness) that make it difficult to observe
some regions, which might imply a misdiagnosis. In this paper, a new strategy
based on neural networks is introduced for eliminating specular reflections and
estimating the unobserved anatomical cervix portion under the bright zones. We
present a supervised learning method, despite not knowing the ground truth from
the beginning, based on training a neural network to learn how to restore any
hidden region of colposcopic images. Once the specular reflections are
identified, they are removed from the image and the previously trained network
is used to fulfill these deleted areas. The quality of the processed images was
evaluated quantitatively and qualitatively. In 21 of the 22 evaluated images,
the detected specular reflections were totally eliminated, whereas, in the
remaining one, these reflections were almost completely eliminated. The
distribution of the colors and the content of the restored images are similar
to those of the originals. The evaluation carried out by a specialist in Cervix
Pathology concluded that, after eliminating the specular reflections, the
anatomical and physiological elements of the cervix are observable in the
restored images, which facilitates the medical diagnosis of cervical
pathologies. Our method has the potential to improve the early detection of
cervical cancer.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tackling the Background Bias in Sparse Object Detection via Cropped Windows. (arXiv:2106.02288v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varga_L/0/1/0/all/0/1">Leon Amadeus Varga</a>, <a href="http://arxiv.org/find/cs/1/au:+Zell_A/0/1/0/all/0/1">Andreas Zell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02288">
                                    <div class="article-summary-box-inner">
                                        <span>Object detection on Unmanned Aerial Vehicles (UAVs) is still a challenging
task. The recordings are mostly sparse and contain only small objects. In this
work, we propose a simple tiling method that improves the detection capability
in the remote sensing case without modifying the model itself. By reducing the
background bias and enabling the usage of higher image resolutions during
training, our method can improve the performance of models substantially. The
procedure was validated on three different data sets and outperformed similar
approaches in performance and speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Draw: Emergent Communication through Sketching. (arXiv:2106.02067v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mihai_D/0/1/0/all/0/1">Daniela Mihai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hare_J/0/1/0/all/0/1">Jonathon Hare</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02067">
                                    <div class="article-summary-box-inner">
                                        <span>Evidence that visual communication preceded written language and provided a
basis for it goes back to prehistory, in forms such as cave and rock paintings
depicting traces of our distant ancestors. Emergent communication research has
sought to explore how agents can learn to communicate in order to
collaboratively solve tasks. Existing research has focused on language, with a
learned communication channel transmitting sequences of discrete tokens between
the agents. In this work, we explore a visual communication channel between
agents that are allowed to draw with simple strokes. Our agents are
parameterised by deep neural networks, and the drawing procedure is
differentiable, allowing for end-to-end training. In the framework of a
referential communication game, we demonstrate that agents can not only
successfully learn to communicate by drawing, but with appropriate inductive
biases, can do so in a fashion that humans can interpret. We hope to encourage
future research to consider visual communication as a more flexible and
directly interpretable alternative of training collaborative agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Barcode Method for Generative Model Evaluation driven by Topological Data Analysis. (arXiv:2106.02207v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jang_R/0/1/0/all/0/1">Ryoungwoo Jang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1">Minjee Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Eun_D/0/1/0/all/0/1">Da-in Eun</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyungjin Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1">Jiyeon Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1">Namkug Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02207">
                                    <div class="article-summary-box-inner">
                                        <span>Evaluating the performance of generative models in image synthesis is a
challenging task. Although the Fr\&#x27;echet Inception Distance is a widely
accepted evaluation metric, it integrates different aspects (e.g., fidelity and
diversity) of synthesized images into a single score and assumes the normality
of embedded vectors. Recent methods such as precision-and-recall and its
variants such as density-and-coverage have been developed to separate fidelity
and diversity based on k-nearest neighborhood methods. In this study, we
propose an algorithm named barcode, which is inspired by the topological data
analysis and is almost free of assumption and hyperparameter selections. In
extensive experiments on real-world datasets as well as theoretical approach on
high-dimensional normal samples, it was found that the &#x27;usual&#x27; normality
assumption of embedded vectors has several drawbacks. The experimental results
demonstrate that barcode outperforms other methods in evaluating fidelity and
diversity of GAN outputs. Official codes can be found in
https://github.com/minjeekim00/Barcode.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Laplacian-Based Dimensionality Reduction Including Spectral Clustering, Laplacian Eigenmap, Locality Preserving Projection, Graph Embedding, and Diffusion Map: Tutorial and Survey. (arXiv:2106.02154v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1">Benyamin Ghojogh</a>, <a href="http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1">Ali Ghodsi</a>, <a href="http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1">Fakhri Karray</a>, <a href="http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1">Mark Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02154">
                                    <div class="article-summary-box-inner">
                                        <span>This is a tutorial and survey paper for nonlinear dimensionality and feature
extraction methods which are based on the Laplacian of graph of data. We first
introduce adjacency matrix, definition of Laplacian matrix, and the
interpretation of Laplacian. Then, we cover the cuts of graph and spectral
clustering which applies clustering in a subspace of data. Different
optimization variants of Laplacian eigenmap and its out-of-sample extension are
explained. Thereafter, we introduce the locality preserving projection and its
kernel variant as linear special cases of Laplacian eigenmap. Versions of graph
embedding are then explained which are generalized versions of Laplacian
eigenmap and locality preserving projection. Finally, diffusion map is
introduced which is a method based on Laplacian of data and random walks on the
data graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Learning via Persistency of Excitation. (arXiv:2106.02078v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1">Kaustubh Sridhar</a>, <a href="http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1">Oleg Sokolsky</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1">Insup Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1">James Weimer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02078">
                                    <div class="article-summary-box-inner">
                                        <span>Improving adversarial robustness of neural networks remains a major
challenge. Fundamentally, training a network is a parameter estimation problem.
In adaptive control theory, maintaining persistency of excitation (PoE) is
integral to ensuring convergence of parameter estimates in dynamical systems to
their robust optima. In this work, we show that network training using gradient
descent is equivalent to a dynamical system parameter estimation problem.
Leveraging this relationship, we prove a sufficient condition for PoE of
gradient descent is achieved when the learning rate is less than the inverse of
the Lipschitz constant of the gradient of loss function. We provide an
efficient technique for estimating the corresponding Lipschitz constant using
extreme value theory and demonstrate that by only scaling the learning rate
schedule we can increase adversarial accuracy by up to 15% on benchmark
datasets. Our approach also universally increases the adversarial accuracy by
0.1% to 0.3% in various state-of-the-art adversarially trained models on the
AutoAttack benchmark, where every small margin of improvement is significant.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems. (arXiv:2005.12964v9 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jianxin Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.12964">
                                    <div class="article-summary-box-inner">
                                        <span>Deep candidate generation (DCG) that narrows down the collection of relevant
items from billions to hundreds via representation learning has become
prevalent in industrial recommender systems. Standard approaches approximate
maximum likelihood estimation (MLE) through sampling for better scalability and
address the problem of DCG in a way similar to language modeling. However, live
recommender systems face severe exposure bias and have a vocabulary several
orders of magnitude larger than that of natural language, implying that MLE
will preserve and even exacerbate the exposure bias in the long run in order to
faithfully fit the observed samples. In this paper, we theoretically prove that
a popular choice of contrastive loss is equivalent to reducing the exposure
bias via inverse propensity weighting, which provides a new perspective for
understanding the effectiveness of contrastive learning. Based on the
theoretical discovery, we design CLRec, a contrastive learning method to
improve DCG in terms of fairness, effectiveness and efficiency in recommender
systems with extremely large candidate size. We further improve upon CLRec and
propose Multi-CLRec, for accurate multi-intention aware bias reduction. Our
methods have been successfully deployed in Taobao, where at least four-month
online A/B tests and offline analyses demonstrate its substantial improvements,
including a dramatic reduction in the Matthew effect.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval. (arXiv:2106.02400v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Manh-Duy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Binh T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurrin_C/0/1/0/all/0/1">Cathal Gurrin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02400">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional approaches to image-text retrieval mainly focus on indexing
visual objects appearing in pictures but ignore the interactions between these
objects. Such objects occurrences and interactions are equivalently useful and
important in this field as they are usually mentioned in the text. Scene graph
presentation is a suitable method for the image-text matching challenge and
obtained good results due to its ability to capture the inter-relationship
information. Both images and text are represented in scene graph levels and
formulate the retrieval challenge as a scene graph matching challenge. In this
paper, we introduce the Local and Global Scene Graph Matching (LGSGM) model
that enhances the state-of-the-art method by integrating an extra graph
convolution network to capture the general information of a graph.
Specifically, for a pair of scene graphs of an image and its caption, two
separate models are used to learn the features of each graph&#x27;s nodes and edges.
Then a Siamese-structure graph convolution model is employed to embed graphs
into vector forms. We finally combine the graph-level and the vector-level to
calculate the similarity of this image-text pair. The empirical experiments
show that our enhancement with the combination of levels can improve the
performance of the baseline method by increasing the recall by more than 10% on
the Flickr30k dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">New Insights into Metric Optimization for Ranking-based Recommendation. (arXiv:2106.02545v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Roger Zhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Urbano_J/0/1/0/all/0/1">Juli&#xe1;n Urbano</a>, <a href="http://arxiv.org/find/cs/1/au:+Hanjalic_A/0/1/0/all/0/1">Alan Hanjalic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02545">
                                    <div class="article-summary-box-inner">
                                        <span>Direct optimization of IR metrics has often been adopted as an approach to
devise and develop ranking-based recommender systems. Most methods following
this approach aim at optimizing the same metric being used for evaluation,
under the assumption that this will lead to the best performance. A number of
studies of this practice bring this assumption, however, into question. In this
paper, we dig deeper into this issue in order to learn more about the effects
of the choice of the metric to optimize on the performance of a ranking-based
recommender system. We present an extensive experimental study conducted on
different datasets in both pairwise and listwise learning-to-rank scenarios, to
compare the relative merit of four popular IR metrics, namely RR, AP, nDCG and
RBP, when used for optimization and assessment of recommender systems in
various combinations. For the first three, we follow the practice of loss
function formulation available in literature. For the fourth one, we propose
novel loss functions inspired by RBP for both the pairwise and listwise
scenario. Our results confirm that the best performance is indeed not
necessarily achieved when optimizing the same metric being used for evaluation.
In fact, we find that RBP-inspired losses perform at least as well as other
metrics in a consistent way, and offer clear benefits in several cases.
Interesting to see is that RBP-inspired losses, while improving the
recommendation performance for all uses, may lead to an individual performance
gain that is correlated with the activity level of a user in interacting with
items. The more active the users, the more they benefit. Overall, our results
challenge the assumption behind the current research practice of optimizing and
evaluating the same metric, and point to RBP-based optimization instead as a
promising alternative when learning to rank in the recommendation context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Fine-Grained Review-based Transformer Model for Personalized Product Search. (arXiv:2004.09424v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bi_K/0/1/0/all/0/1">Keping Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ai_Q/0/1/0/all/0/1">Qingyao Ai</a>, <a href="http://arxiv.org/find/cs/1/au:+Croft_W/0/1/0/all/0/1">W. Bruce Croft</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.09424">
                                    <div class="article-summary-box-inner">
                                        <span>Product search has been a crucial entry point to serve people shopping
online. Most existing personalized product models follow the paradigm of
representing and matching user intents and items in the semantic space, where
finer-grained matching is totally discarded and the ranking of an item cannot
be explained further than just user/item level similarity. In addition, while
some models in existing studies have created dynamic user representations based
on search context, their representations for items are static across all search
sessions. This makes every piece of information about the item always equally
important in representing the item during matching with various user intents.
Aware of the above limitations, we propose a review-based transformer model
(RTM) for personalized product search, which encodes the sequence of query,
user reviews, and item reviews with a transformer architecture. RTM conducts
review-level matching between the user and item, where each review has a
dynamic effect according to the context in the sequence. This makes it possible
to identify useful reviews to explain the scoring. Experimental results show
that RTM significantly outperforms state-of-the-art personalized product search
baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Elastic Embeddings for Customizing On-Device Recommenders. (arXiv:2106.02223v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1">Tong Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1">Hongzhi Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1">Yujia Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02223">
                                    <div class="article-summary-box-inner">
                                        <span>In today&#x27;s context, deploying data-driven services like recommendation on
edge devices instead of cloud servers becomes increasingly attractive due to
privacy and network latency concerns. A common practice in building compact
on-device recommender systems is to compress their embeddings which are
normally the cause of excessive parameterization. However, despite the vast
variety of devices and their associated memory constraints, existing
memory-efficient recommender systems are only specialized for a fixed memory
budget in every design and training life cycle, where a new model has to be
retrained to obtain the optimal performance while adapting to a smaller/larger
memory budget. In this paper, we present a novel lightweight recommendation
paradigm that allows a well-trained recommender to be customized for arbitrary
device-specific memory constraints without retraining. The core idea is to
compose elastic embeddings for each item, where an elastic embedding is the
concatenation of a set of embedding blocks that are carefully chosen by an
automated search function. Correspondingly, we propose an innovative approach,
namely recommendation with universally learned elastic embeddings (RULE). To
ensure the expressiveness of all candidate embedding blocks, RULE enforces a
diversity-driven regularization when learning different embedding blocks. Then,
a performance estimator-based evolutionary search function is designed,
allowing for efficient specialization of elastic embeddings under any memory
constraint for on-device recommendation. Extensive experiments on real-world
datasets reveal the superior performance of RULE under tight memory budgets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using Social Media Background to Improve Cold-start Recommendation Deep Models. (arXiv:2106.02256v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yihong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Maekawa_T/0/1/0/all/0/1">Takuya Maekawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Hara_T/0/1/0/all/0/1">Takahiro Hara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02256">
                                    <div class="article-summary-box-inner">
                                        <span>In recommender systems, a cold-start problem occurs when there is no past
interaction record associated with the user or item. Typical solutions to the
cold-start problem make use of contextual information, such as user demographic
attributes or product descriptions. A group of works have shown that social
media background can help predicting temporal phenomenons such as product sales
and stock price movements. In this work, our goal is to investigate whether
social media background can be used as extra contextual information to improve
recommendation models. Based on an existing deep neural network model, we
proposed a method to represent temporal social media background as embeddings
and fuse them as an extra component in the model. We conduct experimental
evaluations on a real-world e-commerce dataset and a Twitter dataset. The
results show that our method of fusing social media background with the
existing model does generally improve recommendation performance. In some cases
the recommendation accuracy measured by hit-rate@K doubles after fusing with
social media background. Our findings can be beneficial for future recommender
system designs that consider complex temporal information representing social
interests.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Facade-X: an opinionated approach to SPARQL anything. (arXiv:2106.02361v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Daga_E/0/1/0/all/0/1">Enrico Daga</a>, <a href="http://arxiv.org/find/cs/1/au:+Asprino_L/0/1/0/all/0/1">Luigi Asprino</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulholland_P/0/1/0/all/0/1">Paul Mulholland</a>, <a href="http://arxiv.org/find/cs/1/au:+Gangemi_A/0/1/0/all/0/1">Aldo Gangemi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02361">
                                    <div class="article-summary-box-inner">
                                        <span>The Semantic Web research community understood since its beginning how
crucial it is to equip practitioners with methods to transform non-RDF
resources into RDF. Proposals focus on either engineering content
transformations or accessing non-RDF resources with SPARQL. Existing solutions
require users to learn specific mapping languages (e.g. RML), to know how to
query and manipulate a variety of source formats (e.g. XPATH, JSON-Path), or to
combine multiple languages (e.g. SPARQL Generate). In this paper, we explore an
alternative solution and contribute a general-purpose meta-model for converting
non-RDF resources into RDF: Facade-X. Our approach can be implemented by
overriding the SERVICE operator and does not require to extend the SPARQL
syntax. We compare our approach with the state of art methods RML and SPARQL
Generate and show how our solution has lower learning demands and cognitive
complexity, and it is cheaper to implement and maintain, while having
comparable extensibility and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A General Method for Event Detection on Social Media. (arXiv:2106.02250v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yihong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shirakawa_M/0/1/0/all/0/1">Masumi Shirakawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Hara_T/0/1/0/all/0/1">Takahiro Hara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02250">
                                    <div class="article-summary-box-inner">
                                        <span>Event detection on social media has attracted a number of researches, given
the recent availability of large volumes of social media discussions. Previous
works on social media event detection either assume a specific type of event,
or assume certain behavior of observed variables. In this paper, we propose a
general method for event detection on social media that makes few assumptions.
The main assumption we make is that when an event occurs, affected semantic
aspects will behave differently from its usual behavior. We generalize the
representation of time units based on word embeddings of social media text, and
propose an algorithm to detect events in time series in a general sense. In the
experimental evaluation, we use a novel setting to test if our method and
baseline methods can exhaustively catch all real-world news in the test period.
The evaluation results show that when the event is quite unusual with regard to
the base social media discussion, it can be captured more effectively with our
method. Our method can be easily implemented and can be treated as a starting
point for more specific applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-language Sentence Selection via Data Augmentation and Rationale Training. (arXiv:2106.02293v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yanda Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kedzie_C/0/1/0/all/0/1">Chris Kedzie</a>, <a href="http://arxiv.org/find/cs/1/au:+Nair_S/0/1/0/all/0/1">Suraj Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Galuscakova_P/0/1/0/all/0/1">Petra Galu&#x161;&#x10d;&#xe1;kov&#xe1;</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Oard_D/0/1/0/all/0/1">Douglas W. Oard</a>, <a href="http://arxiv.org/find/cs/1/au:+McKeown_K/0/1/0/all/0/1">Kathleen McKeown</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02293">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes an approach to cross-language sentence selection in a
low-resource setting. It uses data augmentation and negative sampling
techniques on noisy parallel sentence data to directly learn a cross-lingual
embedding-based query relevance model. Results show that this approach performs
as well as or better than multiple state-of-the-art machine translation +
monolingual retrieval systems trained on the same parallel data. Moreover, when
a rationale training secondary objective is applied to encourage the model to
match word alignment hints from a phrase-based statistical machine translation
model, consistent improvements are seen across three language pairs
(English-Somali, English-Swahili and English-Tagalog) over a variety of
state-of-the-art baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-optimal Offline and Streaming Algorithms for Learning Non-Linear Dynamical Systems. (arXiv:2105.11558v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Prateek Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowshik_S/0/1/0/all/0/1">Suhas S Kowshik</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagaraj_D/0/1/0/all/0/1">Dheeraj Nagaraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1">Praneeth Netrapalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11558">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the setting of vector valued non-linear dynamical systems
$X_{t+1} &#x3D; \phi(A^* X_t) + \eta_t$, where $\eta_t$ is unbiased noise and $\phi
: \mathbb{R} \to \mathbb{R}$ is a known link function that satisfies certain
{\em expansivity property}. The goal is to learn $A^*$ from a single trajectory
$X_1,\cdots,X_T$ of {\em dependent or correlated} samples. While the problem is
well-studied in the linear case, where $\phi$ is identity, with optimal error
rates even for non-mixing systems, existing results in the non-linear case hold
only for mixing systems. In this work, we improve existing results for learning
nonlinear systems in a number of ways: a) we provide the first offline
algorithm that can learn non-linear dynamical systems without the mixing
assumption, b) we significantly improve upon the sample complexity of existing
results for mixing systems, c) in the much harder one-pass, streaming setting
we study a SGD with Reverse Experience Replay ($\mathsf{SGD-RER}$) method, and
demonstrate that for mixing systems, it achieves the same sample complexity as
our offline algorithm, d) we justify the expansivity assumption by showing that
for the popular ReLU link function -- a non-expansive but easy to learn link
function with i.i.d. samples -- any method would require exponentially many
samples (with respect to dimension of $X_t$) from the dynamical system. We
validate our results via. simulations and demonstrate that a naive application
of SGD can be highly sub-optimal. Indeed, our work demonstrates that for
correlated data, specialized methods designed for the dependency structure in
data can significantly outperform standard SGD based methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Equilibrium and non-Equilibrium regimes in the learning of Restricted Boltzmann Machines. (arXiv:2105.13889v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Decelle_A/0/1/0/all/0/1">Aur&#xe9;lien Decelle</a>, <a href="http://arxiv.org/find/cs/1/au:+Furtlehner_C/0/1/0/all/0/1">Cyril Furtlehner</a>, <a href="http://arxiv.org/find/cs/1/au:+Seoane_B/0/1/0/all/0/1">Beatriz Seoane</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13889">
                                    <div class="article-summary-box-inner">
                                        <span>Training Restricted Boltzmann Machines (RBMs) has been challenging for a long
time due to the difficulty of computing precisely the log-likelihood gradient.
Over the past decades, many works have proposed more or less successful
training recipes but without studying the crucial quantity of the problem: the
mixing time i.e. the number of Monte Carlo iterations needed to sample new
configurations from a model. In this work, we show that this mixing time plays
a crucial role in the dynamics and stability of the trained model, and that
RBMs operate in two well-defined regimes, namely equilibrium and
out-of-equilibrium, depending on the interplay between this mixing time of the
model and the number of steps, $k$, used to approximate the gradient. We
further show empirically that this mixing time increases with the learning,
which often implies a transition from one regime to another as soon as $k$
becomes smaller than this time. In particular, we show that using the popular
$k$ (persistent) contrastive divergence approaches, with $k$ small, the
dynamics of the learned model are extremely slow and often dominated by strong
out-of-equilibrium effects. On the contrary, RBMs trained in equilibrium
display faster dynamics, and a smooth convergence to dataset-like
configurations during the sampling. Finally we discuss how to exploit in
practice both regimes depending on the task one aims to fulfill: (i) short $k$s
can be used to generate convincing samples in short times, (ii) large $k$ (or
increasingly large) must be used to learn the correct equilibrium distribution
of the RBM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Online-Bandit Strategies for Minimax Learning Problems. (arXiv:2105.13939v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roux_C/0/1/0/all/0/1">Christophe Roux</a>, <a href="http://arxiv.org/find/cs/1/au:+Wirth_E/0/1/0/all/0/1">Elias Wirth</a>, <a href="http://arxiv.org/find/cs/1/au:+Pokutta_S/0/1/0/all/0/1">Sebastian Pokutta</a>, <a href="http://arxiv.org/find/cs/1/au:+Kerdreux_T/0/1/0/all/0/1">Thomas Kerdreux</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13939">
                                    <div class="article-summary-box-inner">
                                        <span>Several learning problems involve solving min-max problems, e.g., empirical
distributional robust learning or learning with non-standard aggregated losses.
More specifically, these problems are convex-linear problems where the
minimization is carried out over the model parameters $w\in\mathcal{W}$ and the
maximization over the empirical distribution $p\in\mathcal{K}$ of the training
set indexes, where $\mathcal{K}$ is the simplex or a subset of it. To design
efficient methods, we let an online learning algorithm play against a
(combinatorial) bandit algorithm. We argue that the efficiency of such
approaches critically depends on the structure of $\mathcal{K}$ and propose two
properties of $\mathcal{K}$ that facilitate designing efficient algorithms. We
focus on a specific family of sets $\mathcal{S}_{n,k}$ encompassing various
learning applications and provide high-probability convergence guarantees to
the minimax values.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A nearly Blackwell-optimal policy gradient method. (arXiv:2105.13609v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dewanto_V/0/1/0/all/0/1">Vektor Dewanto</a>, <a href="http://arxiv.org/find/cs/1/au:+Gallagher_M/0/1/0/all/0/1">Marcus Gallagher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.13609">
                                    <div class="article-summary-box-inner">
                                        <span>For continuing environments, reinforcement learning methods commonly maximize
a discounted reward criterion with discount factor close to 1 in order to
approximate the steady-state reward (the gain). However, such a criterion only
considers the long-run performance, ignoring the transient behaviour. In this
work, we develop a policy gradient method that optimizes the gain, then the
bias (which indicates the transient performance and is important to capably
select from policies with equal gain). We derive expressions that enable
sampling for the gradient of the bias, and its preconditioning Fisher matrix.
We further propose an algorithm that solves the corresponding bi-level
optimization using a logarithmic barrier. Experimental results provide insights
into the fundamental mechanisms of our proposal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascading Bandit under Differential Privacy. (arXiv:2105.11126v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jing Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Baoxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_S/0/1/0/all/0/1">Shuo Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.11126">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies \emph{differential privacy (DP)} and \emph{local
differential privacy (LDP)} in cascading bandits. Under DP, we propose an
algorithm which guarantees $\epsilon$-indistinguishability and a regret of
$\mathcal{O}((\frac{\log T}{\epsilon})^{1+\xi})$ for an arbitrarily small
$\xi$. This is a significant improvement from the previous work of
$\mathcal{O}(\frac{\log^3 T}{\epsilon})$ regret. Under
($\epsilon$,$\delta$)-LDP, we relax the $K^2$ dependence through the tradeoff
between privacy budget $\epsilon$ and error probability $\delta$, and obtain a
regret of $\mathcal{O}(\frac{K\log (1/\delta) \log T}{\epsilon^2})$, where $K$
is the size of the arm subset. This result holds for both Gaussian mechanism
and Laplace mechanism by analyses on the composition. Our results extend to
combinatorial semi-bandit. We show respective lower bounds for DP and LDP
cascading bandits. Extensive experiments corroborate our theoretic findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feedback Capacity and a Variant of the Kalman Filter with ARMA Gaussian Noises: Explicit Bounds and Feedback Coding Design. (arXiv:2001.03108v6 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1">Song Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Quanyan Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.03108">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we relate a feedback channel with any finite-order
autoregressive moving-average (ARMA) Gaussian noises to a variant of the Kalman
filter. In light of this, we obtain relatively explicit lower bounds on the
feedback capacity for such colored Gaussian noises, and the bounds are seen to
be consistent with various existing results in the literature. Meanwhile, this
variant of the Kalman filter also leads to explicit recursive coding schemes
with clear structures to achieve the lower bounds. In general, our results
provide an alternative perspective while pointing to potentially tighter bounds
for the feedback capacity problem.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Value Function is All You Need: A Unified Learning Framework for Ride Hailing Platforms. (arXiv:2105.08791v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1">Xiaocheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_Z/0/1/0/all/0/1">Zhiwei Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yansheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1">Dingyuan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_B/0/1/0/all/0/1">Bingchen Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_Y/0/1/0/all/0/1">Yongxin Tong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hongtu Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jieping Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08791">
                                    <div class="article-summary-box-inner">
                                        <span>Large ride-hailing platforms, such as DiDi, Uber and Lyft, connect tens of
thousands of vehicles in a city to millions of ride demands throughout the day,
providing great promises for improving transportation efficiency through the
tasks of order dispatching and vehicle repositioning. Existing studies,
however, usually consider the two tasks in simplified settings that hardly
address the complex interactions between the two, the real-time fluctuations
between supply and demand, and the necessary coordinations due to the
large-scale nature of the problem. In this paper we propose a unified
value-based dynamic learning framework (V1D3) for tackling both tasks. At the
center of the framework is a globally shared value function that is updated
continuously using online experiences generated from real-time platform
transactions. To improve the sample-efficiency and the robustness, we further
propose a novel periodic ensemble method combining the fast online learning
with a large-scale offline training scheme that leverages the abundant
historical driver trajectory data. This allows the proposed framework to adapt
quickly to the highly dynamic environment, to generalize robustly to recurrent
patterns and to drive implicit coordinations among the population of managed
vehicles. Extensive experiments based on real-world datasets show considerably
improvements over other recently proposed methods on both tasks. Particularly,
V1D3 outperforms the first prize winners of both dispatching and repositioning
tracks in the KDD Cup 2020 RL competition, achieving state-of-the-art results
on improving both total driver income and user experience related metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sigma-Delta and Distributed Noise-Shaping Quantization Methods for Random Fourier Features. (arXiv:2106.02614v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jinjie Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cloninger_A/0/1/0/all/0/1">Alexander Cloninger</a>, <a href="http://arxiv.org/find/cs/1/au:+Saab_R/0/1/0/all/0/1">Rayan Saab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02614">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the use of low bit-depth Sigma-Delta and distributed noise-shaping
methods for quantizing the Random Fourier features (RFFs) associated with
shift-invariant kernels. We prove that our quantized RFFs -- even in the case
of $1$-bit quantization -- allow a high accuracy approximation of the
underlying kernels, and the approximation error decays at least polynomially
fast as the dimension of the RFFs increases. We also show that the quantized
RFFs can be further compressed, yielding an excellent trade-off between memory
use and accuracy. Namely, the approximation error now decays exponentially as a
function of the bits used. Moreover, we empirically show by testing the
performance of our methods on several machine learning tasks that our method
compares favorably to other state of the art quantization methods in this
context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ES-ENAS: Controller-Based Architecture Search for Evolutionary Reinforcement Learning. (arXiv:2101.07415v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xingyou Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1">Krzysztof Choromanski</a>, <a href="http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1">Jack Parker-Holder</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yunhao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Daiyi Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_D/0/1/0/all/0/1">Deepali Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1">Wenbo Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1">Aldo Pacchiano</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarlos_T/0/1/0/all/0/1">Tamas Sarlos</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yuxiang Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.07415">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce ES-ENAS, a simple yet general evolutionary joint optimization
procedure by combining continuous optimization via Evolutionary Strategies (ES)
and combinatorial optimization via Efficient NAS (ENAS) in a highly scalable
and intuitive way. Our main insight is noticing that ES is already a highly
distributed algorithm involving hundreds of forward passes which can not only
be used for training neural network weights, but also for jointly training a
NAS controller, both in a blackbox fashion. By doing so, we also bridge the gap
from NAS research in supervised learning settings to the reinforcement learning
scenario through this relatively simple marriage between two different yet
common lines of research. We demonstrate the utility and effectiveness of our
method over a large search space by training highly combinatorial neural
network architectures for RL problems in continuous control, via edge pruning
and quantization. We also incorporate a wide variety of popular techniques from
modern NAS literature including multiobjective optimization along with various
controller methods, to showcase their promise in the RL field and discuss
possible extensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SmartON: Just-in-Time Active Event Detection on Energy Harvesting Systems. (arXiv:2103.00749v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Luo_Y/0/1/0/all/0/1">Yubo Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Nirjon_S/0/1/0/all/0/1">Shahriar Nirjon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00749">
                                    <div class="article-summary-box-inner">
                                        <span>We propose SmartON, a batteryless system that learns to wake up proactively
at the right moment in order to detect events of interest. It does so by
adapting the duty cycle to match the distribution of event arrival times under
the constraints of harvested energy. While existing energy harvesting systems
either wake up periodically at a fixed rate to sense and process the data, or
wake up only in accordance with the availability of the energy source, SmartON
employs a three-phase learning framework to learn the energy harvesting pattern
as well as the pattern of events at run-time, and uses that knowledge to wake
itself up when events are most likely to occur. The three-phase learning
framework enables rapid adaptation to environmental changes in both short and
long terms. Being able to remain asleep more often than a CTID
(charging-then-immediate-discharging) wake-up system and adapt to the event
pattern, SmartON is able to reduce energy waste, increase energy efficiency,
and capture more events. To realize SmartON we have developed a dedicated
hardware platform whose power management module activates capacitors on-the-fly
to dynamically increase its storage capacitance. We conduct both
simulation-driven and real-system experiments to demonstrate that SmartON
captures 1X--7X more events and is 8X--17X more energy-efficient than a CTID
system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Convergent and Dimension-Independent First-Order Algorithm for Min-Max Optimization. (arXiv:2006.12376v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keswani_V/0/1/0/all/0/1">Vijay Keswani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mangoubi_O/0/1/0/all/0/1">Oren Mangoubi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachdeva_S/0/1/0/all/0/1">Sushant Sachdeva</a>, <a href="http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1">Nisheeth K. Vishnoi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12376">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the recent work of Mangoubi and Vishnoi (STOC 2021), we propose
a variant of the min-max optimization framework where the max-player is
constrained to update the maximization variable in a greedy manner until it
reaches a *first-order* stationary point. We present an algorithm that provably
converges to an approximate local equilibrium for our framework from any
initialization and for nonconvex-nonconcave loss functions. Compared to the
second-order algorithm of Mangoubi and Vishnoi, whose iteration bound is
polynomial in the dimension, our algorithm is first-order and its iteration
bound is independent of dimension. We empirically evaluate our algorithm on
challenging nonconvex-nonconcave test-functions and loss functions that arise
in GAN training. Our algorithm converges on these test functions and, when used
to train GANs on synthetic and real-world datasets, trains stably and avoids
mode collapse.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperparameter Optimization Is Deceiving Us, and How to Stop It. (arXiv:2102.03034v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cooper_A/0/1/0/all/0/1">A. Feder Cooper</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yucheng Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Forde_J/0/1/0/all/0/1">Jessica Zosa Forde</a>, <a href="http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1">Christopher De Sa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03034">
                                    <div class="article-summary-box-inner">
                                        <span>Recent empirical work shows that inconsistent results, based on choice of
hyperparameter optimization (HPO) configuration, are a widespread problem in ML
research. When comparing two algorithms J and K, searching one subspace can
yield the conclusion that J outperforms K, whereas searching another can entail
the opposite. In short, the way we choose hyperparameters can deceive us. We
provide a theoretical complement to this prior work, arguing that, to avoid
such deception, the process of drawing conclusions from HPO should be made more
rigorous. We call this process epistemic hyperparameter optimization (EHPO),
and put forth a logical framework to capture its semantics and how it can lead
to inconsistent conclusions about performance. Our framework enables us to
prove EHPO methods that are guaranteed to be defended against deception. We
demonstrate its utility by proving and empirically validating a defended
variant of random search.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Exploration via Axiomatic Bargaining. (arXiv:2106.02553v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1">Jackie Baek</a>, <a href="http://arxiv.org/find/cs/1/au:+Farias_V/0/1/0/all/0/1">Vivek F. Farias</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02553">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the consideration of fairly sharing the cost of exploration
between multiple groups in learning problems, we develop the Nash bargaining
solution in the context of multi-armed bandits. Specifically, the &#x27;grouped&#x27;
bandit associated with any multi-armed bandit problem associates, with each
time step, a single group from some finite set of groups. The utility gained by
a given group under some learning policy is naturally viewed as the reduction
in that group&#x27;s regret relative to the regret that group would have incurred
&#x27;on its own&#x27;. We derive policies that yield the Nash bargaining solution
relative to the set of incremental utilities possible under any policy. We show
that on the one hand, the &#x27;price of fairness&#x27; under such policies is limited,
while on the other hand, regret optimal policies are arbitrarily unfair under
generic conditions. Our theoretical development is complemented by a case study
on contextual bandits for warfarin dosing where we are concerned with the cost
of exploration across multiple races and age groups.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Influence Estimation and Maximization via Neural Mean-Field Dynamics. (arXiv:2106.02608v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shushan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1">Hongyuan Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_X/0/1/0/all/0/1">Xiaojing Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02608">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel learning framework using neural mean-field (NMF) dynamics
for inference and estimation problems on heterogeneous diffusion networks. Our
new framework leverages the Mori-Zwanzig formalism to obtain an exact evolution
equation of the individual node infection probabilities, which renders a delay
differential equation with memory integral approximated by learnable time
convolution operators. Directly using information diffusion cascade data, our
framework can simultaneously learn the structure of the diffusion network and
the evolution of node infection probabilities. Connections between parameter
learning and optimal control are also established, leading to a rigorous and
implementable algorithm for training NMF. Moreover, we show that the projected
gradient descent method can be employed to solve the challenging influence
maximization problem, where the gradient is computed extremely fast by
integrating NMF forward in time just once in each iteration. Extensive
empirical studies show that our approach is versatile and robust to variations
of the underlying diffusion network models, and significantly outperform
existing approaches in accuracy and efficiency on both synthetic and real-world
data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Graph Models for Retrosynthesis Prediction. (arXiv:2006.07038v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Somnath_V/0/1/0/all/0/1">Vignesh Ram Somnath</a>, <a href="http://arxiv.org/find/cs/1/au:+Bunne_C/0/1/0/all/0/1">Charlotte Bunne</a>, <a href="http://arxiv.org/find/cs/1/au:+Coley_C/0/1/0/all/0/1">Connor W. Coley</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>, <a href="http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1">Regina Barzilay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.07038">
                                    <div class="article-summary-box-inner">
                                        <span>Retrosynthesis prediction is a fundamental problem in organic synthesis,
where the task is to identify precursor molecules that can be used to
synthesize a target molecule. A key consideration in building neural models for
this task is aligning model design with strategies adopted by chemists.
Building on this viewpoint, this paper introduces a graph-based approach that
capitalizes on the idea that the graph topology of precursor molecules is
largely unaltered during a chemical reaction. The model first predicts the set
of graph edits transforming the target into incomplete molecules called
synthons. Next, the model learns to expand synthons into complete molecules by
attaching relevant leaving groups. This decomposition simplifies the
architecture, making its predictions more interpretable, and also amenable to
manual correction. Our model achieves a top-1 accuracy of $53.7\%$,
outperforming previous template-free and semi-template-based methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Procedural World Generation Framework for Systematic Evaluation of Continual Learning. (arXiv:2106.02585v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hess_T/0/1/0/all/0/1">Timm Hess</a>, <a href="http://arxiv.org/find/cs/1/au:+Mundt_M/0/1/0/all/0/1">Martin Mundt</a>, <a href="http://arxiv.org/find/cs/1/au:+Pliushch_I/0/1/0/all/0/1">Iuliia Pliushch</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramesh_V/0/1/0/all/0/1">Visvanathan Ramesh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02585">
                                    <div class="article-summary-box-inner">
                                        <span>Several families of continual learning techniques have been proposed to
alleviate catastrophic interference in deep neural network training on
non-stationary data. However, a comprehensive comparison and analysis of
limitations remains largely open due to the inaccessibility to suitable
datasets. Empirical examination not only varies immensely between individual
works, it further currently relies on contrived composition of benchmarks
through subdivision and concatenation of various prevalent static vision
datasets. In this work, our goal is to bridge this gap by introducing a
computer graphics simulation framework that repeatedly renders only upcoming
urban scene fragments in an endless real-time procedural world generation
process. At its core lies a modular parametric generative model with adaptable
generative factors. The latter can be used to flexibly compose data streams,
which significantly facilitates a detailed analysis and allows for effortless
investigation of various continual learning schemes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causally-motivated Shortcut Removal Using Auxiliary Labels. (arXiv:2105.06422v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Makar_M/0/1/0/all/0/1">Maggie Makar</a>, <a href="http://arxiv.org/find/cs/1/au:+Packer_B/0/1/0/all/0/1">Ben Packer</a>, <a href="http://arxiv.org/find/cs/1/au:+Moldovan_D/0/1/0/all/0/1">Dan Moldovan</a>, <a href="http://arxiv.org/find/cs/1/au:+Blalock_D/0/1/0/all/0/1">Davis Blalock</a>, <a href="http://arxiv.org/find/cs/1/au:+Halpern_Y/0/1/0/all/0/1">Yoni Halpern</a>, <a href="http://arxiv.org/find/cs/1/au:+DAmour_A/0/1/0/all/0/1">Alexander D&#x27;Amour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06422">
                                    <div class="article-summary-box-inner">
                                        <span>Robustness to certain forms of distribution shift is a key concern in many ML
applications. Often, robustness can be formulated as enforcing invariances to
particular interventions on the data generating process. Here, we study a
flexible, causally-motivated approach to enforcing such invariances, paying
special attention to shortcut learning, where a robust predictor can achieve
optimal i.i.d generalization in principle, but instead it relies on spurious
correlations or shortcuts in practice. Our approach uses auxiliary labels,
typically available at training time, to enforce conditional independences
between the latent factors that determine these labels. We show both
theoretically and empirically that causally-motivated regularization schemes
(a) lead to more robust estimators that generalize well under distribution
shift, and (b) have better finite sample efficiency compared to usual
regularization schemes, even in the absence of distribution shifts. Our
analysis highlights important theoretical properties of training techniques
commonly used in causal inference, fairness, and disentanglement literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Growing 3D Artefacts and Functional Machines with Neural Cellular Automata. (arXiv:2103.08737v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sudhakaran_S/0/1/0/all/0/1">Shyam Sudhakaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Grbic_D/0/1/0/all/0/1">Djordje Grbic</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Siyan Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Katona_A/0/1/0/all/0/1">Adam Katona</a>, <a href="http://arxiv.org/find/cs/1/au:+Najarro_E/0/1/0/all/0/1">Elias Najarro</a>, <a href="http://arxiv.org/find/cs/1/au:+Glanois_C/0/1/0/all/0/1">Claire Glanois</a>, <a href="http://arxiv.org/find/cs/1/au:+Risi_S/0/1/0/all/0/1">Sebastian Risi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.08737">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Cellular Automata (NCAs) have been proven effective in simulating
morphogenetic processes, the continuous construction of complex structures from
very few starting cells. Recent developments in NCAs lie in the 2D domain,
namely reconstructing target images from a single pixel or infinitely growing
2D textures. In this work, we propose an extension of NCAs to 3D, utilizing 3D
convolutions in the proposed neural network architecture. Minecraft is selected
as the environment for our automaton since it allows the generation of both
static structures and moving machines. We show that despite their simplicity,
NCAs are capable of growing complex entities such as castles, apartment blocks,
and trees, some of which are composed of over 3,000 blocks. Additionally, when
trained for regeneration, the system is able to regrow parts of simple
functional machines, significantly expanding the capabilities of simulated
morphogenetic systems. The code for the experiment in this paper can be found
at: https://github.com/real-itu/3d-artefacts-nca.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How do Quadratic Regularizers Prevent Catastrophic Forgetting: The Role of Interpolation. (arXiv:2102.02805v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lubana_E/0/1/0/all/0/1">Ekdeep Singh Lubana</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_P/0/1/0/all/0/1">Puja Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Koutra_D/0/1/0/all/0/1">Danai Koutra</a>, <a href="http://arxiv.org/find/cs/1/au:+Dick_R/0/1/0/all/0/1">Robert P. Dick</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02805">
                                    <div class="article-summary-box-inner">
                                        <span>Catastrophic forgetting undermines the effectiveness of deep neural networks
(DNNs) in scenarios such as continual learning and lifelong learning. While
several methods have been proposed to tackle this problem, there is limited
work explaining why these methods work well. This paper has the goal of better
explaining a popularly used technique for avoiding catastrophic forgetting:
quadratic regularization. We show that quadratic regularizers prevent
forgetting of past tasks by interpolating current and previous values of model
parameters at every training iteration. Over multiple training iterations, this
interpolation operation reduces the learning rates of more important model
parameters, thereby minimizing their movement. Our analysis also reveals two
drawbacks of quadratic regularization: (a) dependence of parameter
interpolation on training hyperparameters, which often leads to training
instability and (b) assignment of lower importance to deeper layers, which are
generally the place forgetting occurs in DNNs. Via a simple modification to the
order of operations, we show these drawbacks can be easily avoided, resulting
in 6.2% higher average accuracy at 4.5% lower average forgetting. Code
available at \url{https://github.com/EkdeepSLubana/QRforgetting}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates. (arXiv:1905.09997v5 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vaswani_S/0/1/0/all/0/1">Sharan Vaswani</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishkin_A/0/1/0/all/0/1">Aaron Mishkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Laradji_I/0/1/0/all/0/1">Issam Laradji</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1">Mark Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1">Gauthier Gidel</a>, <a href="http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1">Simon Lacoste-Julien</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.09997">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works have shown that stochastic gradient descent (SGD) achieves the
fast convergence rates of full-batch gradient descent for over-parameterized
models satisfying certain interpolation conditions. However, the step-size used
in these works depends on unknown quantities and SGD&#x27;s practical performance
heavily relies on the choice of this step-size. We propose to use line-search
techniques to automatically set the step-size when training models that can
interpolate the data. In the interpolation setting, we prove that SGD with a
stochastic variant of the classic Armijo line-search attains the deterministic
convergence rates for both convex and strongly-convex functions. Under
additional assumptions, SGD with Armijo line-search is shown to achieve fast
convergence for non-convex functions. Furthermore, we show that stochastic
extra-gradient with a Lipschitz line-search attains linear convergence for an
important class of non-convex functions and saddle-point problems satisfying
interpolation. To improve the proposed methods&#x27; practical performance, we give
heuristics to use larger step-sizes and acceleration. We compare the proposed
algorithms against numerous optimization methods on standard classification
tasks using both kernel methods and deep networks. The proposed methods result
in competitive performance across all models and datasets, while being robust
to the precise choices of hyper-parameters. For multi-class classification
using deep networks, SGD with Armijo line-search results in both faster
convergence and better generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Effects of Quantisation on Model Uncertainty in Bayesian Neural Networks. (arXiv:2102.11062v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ferianc_M/0/1/0/all/0/1">Martin Ferianc</a>, <a href="http://arxiv.org/find/cs/1/au:+Maji_P/0/1/0/all/0/1">Partha Maji</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattina_M/0/1/0/all/0/1">Matthew Mattina</a>, <a href="http://arxiv.org/find/cs/1/au:+Rodrigues_M/0/1/0/all/0/1">Miguel Rodrigues</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11062">
                                    <div class="article-summary-box-inner">
                                        <span>Bayesian neural networks (BNNs) are making significant progress in many
research areas where decision-making needs to be accompanied by uncertainty
estimation. Being able to quantify uncertainty while making decisions is
essential for understanding when the model is over-/under-confident, and hence
BNNs are attracting interest in safety-critical applications, such as
autonomous driving, healthcare, and robotics. Nevertheless, BNNs have not been
as widely used in industrial practice, mainly because of their increased memory
and compute costs. In this work, we investigate quantisation of BNNs by
compressing 32-bit floating-point weights and activations to their integer
counterparts, that has already been successful in reducing the compute demand
in standard pointwise neural networks. We study three types of quantised BNNs,
we evaluate them under a wide range of different settings, and we empirically
demonstrate that a uniform quantisation scheme applied to BNNs does not
substantially decrease their quality of uncertainty estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collection and harmonization of system logs and prototypal Analytics services with the Elastic (ELK) suite at the INFN-CNAF computing centre. (arXiv:2106.02612v1 [cs.DC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diotalevi_T/0/1/0/all/0/1">Tommaso Diotalevi</a>, <a href="http://arxiv.org/find/cs/1/au:+Falabella_A/0/1/0/all/0/1">Antonio Falabella</a>, <a href="http://arxiv.org/find/cs/1/au:+Martelli_B/0/1/0/all/0/1">Barbara Martelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Michelotto_D/0/1/0/all/0/1">Diego Michelotto</a>, <a href="http://arxiv.org/find/cs/1/au:+Morganti_L/0/1/0/all/0/1">Lucia Morganti</a>, <a href="http://arxiv.org/find/cs/1/au:+Bonacorsi_D/0/1/0/all/0/1">Daniele Bonacorsi</a>, <a href="http://arxiv.org/find/cs/1/au:+Giommi_L/0/1/0/all/0/1">Luca Giommi</a>, <a href="http://arxiv.org/find/cs/1/au:+Tisbeni_S/0/1/0/all/0/1">Simone Rossi Tisbeni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02612">
                                    <div class="article-summary-box-inner">
                                        <span>The distributed Grid infrastructure for High Energy Physics experiments at
the Large Hadron Collider (LHC) in Geneva comprises a set of computing centres,
spread all over the world, as part of the Worldwide LHC Computing Grid (WLCG).
In Italy, the Tier-1 functionalities are served by the INFN-CNAF data center,
which provides also computing and storage resources to more than twenty non-LHC
experiments. For this reason, a high amount of logs are collected each day from
various sources, which are highly heterogeneous and difficult to harmonize. In
this contribution, a working implementation of a system that collects, parses
and displays the log information from CNAF data sources and the investigation
of a Machine Learning based predictive maintenance system, is presented.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Multi-aspect Detection of Misinformation using Hierarchical Joint Decomposition. (arXiv:2005.04310v2 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1">Sara Abdali</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Neil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1">Evangelos E. Papalexakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.04310">
                                    <div class="article-summary-box-inner">
                                        <span>Distinguishing between misinformation and real information is one of the most
challenging problems in today&#x27;s interconnected world. The vast majority of the
state-of-the-art in detecting misinformation is fully supervised, requiring a
large number of high-quality human annotations. However, the availability of
such annotations cannot be taken for granted, since it is very costly,
time-consuming, and challenging to do so in a way that keeps up with the
proliferation of misinformation. In this work, we are interested in exploring
scenarios where the number of annotations is limited. In such scenarios, we
investigate how tapping on a diverse number of resources that characterize a
news article, henceforth referred to as &quot;aspects&quot; can compensate for the lack
of labels. In particular, our contributions in this paper are twofold: 1) We
propose the use of three different aspects: article content, context of social
sharing behaviors, and host website/domain features, and 2) We introduce a
principled tensor based embedding framework that combines all those aspects
effectively. We propose HiJoD a 2-level decomposition pipeline which not only
outperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter
and Politifact datasets respectively but also is an order of magnitude faster
than similar ensemble approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fundamental tradeoffs between memorization and robustness in random features and neural tangent regimes. (arXiv:2106.02630v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Dohmatob_E/0/1/0/all/0/1">Elvis Dohmatob</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02630">
                                    <div class="article-summary-box-inner">
                                        <span>This work studies the (non)robustness of two-layer neural networks in various
high-dimensional linearized regimes. We establish fundamental trade-offs
between memorization and robustness, as measured by the Sobolev-seminorm of the
model w.r.t the data distribution, i.e the square root of the average squared
$L_2$-norm of the gradients of the model w.r.t the its input. More precisely,
if $n$ is the number of training examples, $d$ is the input dimension, and $k$
is the number of hidden neurons in a two-layer neural network, we prove for a
large class of activation functions that, if the model memorizes even a
fraction of the training, then its Sobolev-seminorm is lower-bounded by (i)
$\sqrt{n}$ in case of infinite-width random features (RF) or neural tangent
kernel (NTK) with $d \gtrsim n$; (ii) $\sqrt{n}$ in case of finite-width RF
with proportionate scaling of $d$ and $k$; and (iii) $\sqrt{n/k}$ in case of
finite-width NTK with proportionate scaling of $d$ and $k$. Moreover, all of
these lower-bounds are tight: they are attained by the min-norm / least-squares
interpolator (when $n$, $d$, and $k$ are in the appropriate interpolating
regime). All our results hold as soon as data is log-concave isotropic, and
there is label-noise, i.e the target variable is not a deterministic function
of the data / features. We empirically validate our theoretical results with
experiments. Accidentally, these experiments also reveal for the first time,
(iv) a multiple-descent phenomenon in the robustness of the min-norm
interpolator.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DoubleML -- An Object-Oriented Implementation of Double Machine Learning in R. (arXiv:2103.09603v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bach_P/0/1/0/all/0/1">Philipp Bach</a>, <a href="http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1">Victor Chernozhukov</a>, <a href="http://arxiv.org/find/stat/1/au:+Kurz_M/0/1/0/all/0/1">Malte S. Kurz</a>, <a href="http://arxiv.org/find/stat/1/au:+Spindler_M/0/1/0/all/0/1">Martin Spindler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09603">
                                    <div class="article-summary-box-inner">
                                        <span>The R package DoubleML implements the double/debiased machine learning
framework of Chernozhukov et al. (2018). It provides functionalities to
estimate parameters in causal models based on machine learning methods. The
double machine learning framework consist of three key ingredients: Neyman
orthogonality, high-quality machine learning estimation and sample splitting.
Estimation of nuisance components can be performed by various state-of-the-art
machine learning methods that are available in the mlr3 ecosystem. DoubleML
makes it possible to perform inference in a variety of causal models, including
partially linear and interactive regression models and their extensions to
instrumental variable estimation. The object-oriented implementation of
DoubleML enables a high flexibility for the model specification and makes it
easily extendable. This paper serves as an introduction to the double machine
learning framework and the R package DoubleML. In reproducible code examples
with simulated and real data sets, we demonstrate how DoubleML users can
perform valid inference based on machine learning methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-Precision Reinforcement Learning: Running Soft Actor-Critic in Half Precision. (arXiv:2102.13565v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bjorck_J/0/1/0/all/0/1">Johan Bjorck</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1">Christopher De Sa</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1">Carla P. Gomes</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1">Kilian Q. Weinberger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13565">
                                    <div class="article-summary-box-inner">
                                        <span>Low-precision training has become a popular approach to reduce compute
requirements, memory footprint, and energy consumption in supervised learning.
In contrast, this promising approach has not yet enjoyed similarly widespread
adoption within the reinforcement learning (RL) community, partly because RL
agents can be notoriously hard to train even in full precision. In this paper
we consider continuous control with the state-of-the-art SAC agent and
demonstrate that a na\&quot;ive adaptation of low-precision methods from supervised
learning fails. We propose a set of six modifications, all straightforward to
implement, that leaves the underlying agent and its hyperparameters unchanged
but improves the numerical stability dramatically. The resulting modified SAC
agent has lower memory and compute requirements while matching full-precision
rewards, demonstrating that low-precision training can substantially accelerate
state-of-the-art RL without parameter tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Natural Way to Overcome the Catastrophic Forgetting in Neural Networks. (arXiv:2005.07107v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kutalev_A/0/1/0/all/0/1">Alexey Kutalev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.07107">
                                    <div class="article-summary-box-inner">
                                        <span>Not so long ago, a method was discovered that successfully overcomes the
catastrophic forgetting in neural networks. Although we know about the cases of
using this method to preserve skills when adapting pre-trained networks to
particular tasks, it has not obtained widespread distribution yet. In this
paper, we would like to propose an alternative method of overcoming
catastrophic forgetting based on the total absolute signal passing through each
connection in the network. This method has a simple implementation and seems to
us essentially close to the processes occurring in the brain of animals to
preserve previously learned skills during subsequent learning. We hope that the
ease of implementation of this method will serve its wide application.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Relevance-Guided Modeling of Object Dynamics for Reinforcement Learning. (arXiv:2003.01384v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Agnew_W/0/1/0/all/0/1">William Agnew</a>, <a href="http://arxiv.org/find/cs/1/au:+Domingos_P/0/1/0/all/0/1">Pedro Domingos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.01384">
                                    <div class="article-summary-box-inner">
                                        <span>Current deep reinforcement learning (RL) approaches incorporate minimal prior
knowledge about the environment, limiting computational and sample efficiency.
\textit{Objects} provide a succinct and causal description of the world, and
many recent works have proposed unsupervised object representation learning
using priors and losses over static object properties like visual consistency.
However, object dynamics and interactions are also critical cues for
objectness. In this paper we propose a framework for reasoning about object
dynamics and behavior to rapidly determine minimal and task-specific object
representations. To demonstrate the need to reason over object behavior and
dynamics, we introduce a suite of RGBD MuJoCo object collection and avoidance
tasks that, while intuitive and visually simple, confound state-of-the-art
unsupervised object representation learning algorithms. We also highlight the
potential of this framework on several Atari games, using our object
representation and standard RL and planning algorithms to learn dramatically
faster than existing deep RL algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fundamental Limits of Controlled Stochastic Dynamical Systems: An Information-Theoretic Approach. (arXiv:2012.12174v6 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fang_S/0/1/0/all/0/1">Song Fang</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhu_Q/0/1/0/all/0/1">Quanyan Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12174">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we examine the fundamental performance limitations in the
control of stochastic dynamical systems; more specifically, we derive generic
$\mathcal{L}_p$ bounds that hold for any causal (stabilizing) controllers and
any stochastic disturbances, by an information-theoretic analysis. We first
consider the scenario where the plant (i.e., the dynamical system to be
controlled) is linear time-invariant, and it is seen in general that the lower
bounds are characterized by the unstable poles (or nonminimum-phase zeros) of
the plant as well as the conditional entropy of the disturbance. We then
analyze the setting where the plant is assumed to be (strictly) causal, for
which case the lower bounds are determined by the conditional entropy of the
disturbance. We also discuss the special cases of $p &#x3D; 2$ and $p &#x3D; \infty$,
which correspond to minimum-variance control and controlling the maximum
deviations, respectively. In addition, we investigate the power-spectral
characterization of the lower bounds as well as its relation to the
Kolmogorov-Szeg\&quot;o formula.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MUSBO: Model-based Uncertainty Regularized and Sample Efficient Batch Optimization for Deployment Constrained Reinforcement Learning. (arXiv:2102.11448v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1">DiJia Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Mulvey_J/0/1/0/all/0/1">John M. Mulvey</a>, <a href="http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1">H. Vincent Poor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11448">
                                    <div class="article-summary-box-inner">
                                        <span>In many contemporary applications such as healthcare, finance, robotics, and
recommendation systems, continuous deployment of new policies for data
collection and online learning is either cost ineffective or impractical. We
consider a setting that lies between pure offline reinforcement learning (RL)
and pure online RL called deployment constrained RL in which the number of
policy deployments for data sampling is limited. To solve this challenging
task, we propose a new algorithmic learning framework called Model-based
Uncertainty regularized and Sample Efficient Batch Optimization (MUSBO). Our
framework discovers novel and high quality samples for each deployment to
enable efficient data collection. During each offline training session, we
bootstrap the policy update by quantifying the amount of uncertainty within our
collected data. In the high support region (low uncertainty), we encourage our
policy by taking an aggressive update. In the low support region (high
uncertainty) when the policy bootstraps into the out-of-distribution region, we
downweight it by our estimated uncertainty quantification. Experimental results
show that MUSBO achieves state-of-the-art performance in the deployment
constrained RL setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FjORD: Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout. (arXiv:2102.13451v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Horvath_S/0/1/0/all/0/1">Samuel Horvath</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskaridis_S/0/1/0/all/0/1">Stefanos Laskaridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Almeida_M/0/1/0/all/0/1">Mario Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Leontiadis_I/0/1/0/all/0/1">Ilias Leontiadis</a>, <a href="http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1">Stylianos I. Venieris</a>, <a href="http://arxiv.org/find/cs/1/au:+Lane_N/0/1/0/all/0/1">Nicholas D. Lane</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13451">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning (FL) has been gaining significant traction across
different ML tasks, ranging from vision to keyboard predictions. In large-scale
deployments, client heterogeneity is a fact, and constitutes a primary problem
for fairness, training performance and accuracy. Although significant efforts
have been made into tackling statistical data heterogeneity, the diversity in
the processing capabilities and network bandwidth of clients, termed as system
heterogeneity, has remained largely unexplored. Current solutions either
disregard a large portion of available devices or set a uniform limit on the
model&#x27;s capacity, restricted by the least capable participants. In this work,
we introduce Ordered Dropout, a mechanism that achieves an ordered, nested
representation of knowledge in Neural Networks and enables the extraction of
lower footprint submodels without the need of retraining. We further show that
for linear maps our Ordered Dropout is equivalent to SVD. We employ this
technique, along with a self-distillation methodology, in the realm of FL in a
framework called FjORD. FjORD alleviates the problem of client system
heterogeneity by tailoring the model width to the client&#x27;s capabilities.
Extensive evaluation on both CNNs and RNNs across diverse modalities shows that
FjORD consistently leads to significant performance gains over state-of-the-art
baselines, while maintaining its nested structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KACC: A Multi-task Benchmark for Knowledge Abstraction, Concretization and Completion. (arXiv:2004.13631v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shengding Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lv_X/0/1/0/all/0/1">Xin Lv</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jie Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juanzi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.13631">
                                    <div class="article-summary-box-inner">
                                        <span>A comprehensive knowledge graph (KG) contains an instance-level entity graph
and an ontology-level concept graph. The two-view KG provides a testbed for
models to &quot;simulate&quot; human&#x27;s abilities on knowledge abstraction,
concretization, and completion (KACC), which are crucial for human to recognize
the world and manage learned knowledge. Existing studies mainly focus on
partial aspects of KACC. In order to promote thorough analyses for KACC
abilities of models, we propose a unified KG benchmark by improving existing
benchmarks in terms of dataset scale, task coverage, and difficulty.
Specifically, we collect new datasets that contain larger concept graphs,
abundant cross-view links as well as dense entity graphs. Based on the
datasets, we propose novel tasks such as multi-hop knowledge abstraction (MKA),
multi-hop knowledge concretization (MKC) and then design a comprehensive
benchmark. For MKA and MKC tasks, we further annotate multi-hop hierarchical
triples as harder samples. The experimental results of existing methods
demonstrate the challenges of our benchmark. The resource is available at
https://github.com/thunlp/KACC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning One Representation to Optimize All Rewards. (arXiv:2103.07945v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Touati_A/0/1/0/all/0/1">Ahmed Touati</a>, <a href="http://arxiv.org/find/cs/1/au:+Ollivier_Y/0/1/0/all/0/1">Yann Ollivier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.07945">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce the forward-backward (FB) representation of the dynamics of a
reward-free Markov decision process. It provides explicit near-optimal policies
for any reward specified a posteriori. During an unsupervised phase, we use
reward-free interactions with the environment to learn two representations via
off-the-shelf deep learning methods and temporal difference (TD) learning. In
the test phase, a reward representation is estimated either from observations
or an explicit reward description (e.g., a target state). The optimal policy
for that reward is directly obtained from these representations, with no
planning. We assume access to an exploration scheme or replay buffer for the
first phase.

The unsupervised FB loss is well-principled: if training is perfect, the
policies obtained are provably optimal for any reward function. With imperfect
training, the sub-optimality is proportional to the unsupervised approximation
error. The FB representation learns long-range relationships between states and
actions, via a predictive occupancy map, without having to synthesize states as
in model-based approaches.

This is a step towards learning controllable agents in arbitrary black-box
stochastic environments. This approach compares well to goal-oriented RL
algorithms on discrete and continuous mazes, pixel-based MsPacman, and the
FetchReach virtual robot arm. We also illustrate how the agent can immediately
adapt to new tasks beyond goal-oriented RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive Learning for Debiased Candidate Generation in Large-Scale Recommender Systems. (arXiv:2005.12964v9 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jianxin Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jianwei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.12964">
                                    <div class="article-summary-box-inner">
                                        <span>Deep candidate generation (DCG) that narrows down the collection of relevant
items from billions to hundreds via representation learning has become
prevalent in industrial recommender systems. Standard approaches approximate
maximum likelihood estimation (MLE) through sampling for better scalability and
address the problem of DCG in a way similar to language modeling. However, live
recommender systems face severe exposure bias and have a vocabulary several
orders of magnitude larger than that of natural language, implying that MLE
will preserve and even exacerbate the exposure bias in the long run in order to
faithfully fit the observed samples. In this paper, we theoretically prove that
a popular choice of contrastive loss is equivalent to reducing the exposure
bias via inverse propensity weighting, which provides a new perspective for
understanding the effectiveness of contrastive learning. Based on the
theoretical discovery, we design CLRec, a contrastive learning method to
improve DCG in terms of fairness, effectiveness and efficiency in recommender
systems with extremely large candidate size. We further improve upon CLRec and
propose Multi-CLRec, for accurate multi-intention aware bias reduction. Our
methods have been successfully deployed in Taobao, where at least four-month
online A/B tests and offline analyses demonstrate its substantial improvements,
including a dramatic reduction in the Matthew effect.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Convex Optimization Perspective for Learning from Dynamically Revealed Preferences. (arXiv:2008.10460v3 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Chen_V/0/1/0/all/0/1">Violet Xinying Chen</a>, <a href="http://arxiv.org/find/math/1/au:+Kilinc_Karzan_F/0/1/0/all/0/1">Fatma K&#x131;l&#x131;n&#xe7;-Karzan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.10460">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of online learning (OL) from revealed preferences: a
learner wishes to learn a non-strategic agent&#x27;s private utility function
through observing the agent&#x27;s utility-maximizing actions in a changing
environment. We adopt an online inverse optimization setup, where the learner
observes a stream of agent&#x27;s actions in an online fashion and the learning
performance is measured by regret associated with a loss function. We first
characterize a special but broad class of agent&#x27;s utility functions, then
utilize this structure in designing a new convex loss function. We establish
that the regret with respect to our new loss function also bounds the regret
with respect to all other usual loss functions in the literature. This allows
us to design a flexible OL framework that enables a unified treatment of loss
functions and supports a variety of online convex optimization algorithms. We
demonstrate with theoretical and empirical evidence that our framework based on
the new loss function (in particular online Mirror Descent) has significant
advantages in terms of regret performance and solution time over other OL
algorithms from the literature and bypasses the previous technical assumptions
as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Active Covering. (arXiv:2106.02552v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Heinrich Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rostamizadeh_A/0/1/0/all/0/1">Afshin Rostamizadeh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02552">
                                    <div class="article-summary-box-inner">
                                        <span>We analyze the problem of active covering, where the learner is given an
unlabeled dataset and can sequentially label query examples. The objective is
to label query all of the positive examples in the fewest number of total label
queries. We show under standard non-parametric assumptions that a classical
support estimator can be repurposed as an offline algorithm attaining an excess
query cost of $\widetilde{\Theta}(n^{D/(D+1)})$ compared to the optimal
learner, where $n$ is the number of datapoints and $D$ is the dimension. We
then provide a simple active learning method that attains an improved excess
query cost of $\widetilde{O}(n^{(D-1)/D})$. Furthermore, the proposed
algorithms only require access to the positive labeled examples, which in
certain settings provides additional computational and privacy benefits.
Finally, we show that the active learning method consistently outperforms
offline methods as well as a variety of baselines on a wide range of benchmark
image-based datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Equivalence of Dataflow Graphs via Rewrite Rules Using a Graph-to-Sequence Neural Model. (arXiv:2002.06799v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1">Steve Kommrusch</a>, <a href="http://arxiv.org/find/cs/1/au:+Barollet_T/0/1/0/all/0/1">Th&#xe9;o Barollet</a>, <a href="http://arxiv.org/find/cs/1/au:+Pouchet_L/0/1/0/all/0/1">Louis-No&#xeb;l Pouchet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.06799">
                                    <div class="article-summary-box-inner">
                                        <span>In this work we target the problem of provably computing the equivalence
between two programs represented as dataflow graphs. To this end, we formalize
the problem of equivalence between two programs as finding a set of
semantics-preserving rewrite rules from one into the other, such that after the
rewrite the two programs are structurally identical, and therefore trivially
equivalent. We then develop the first graph-to-sequence neural network system
for program equivalence, trained to produce such rewrite sequences from a
carefully crafted automatic example generation algorithm. We extensively
evaluate our system on a rich multi-type linear algebra expression language,
using arbitrary combinations of 100+ graph-rewriting axioms of equivalence. Our
system outputs via inference a correct rewrite sequence for 96% of the 10,000
program pairs isolated for testing, using 30-term programs. And in all cases,
the validity of the sequence produced and therefore the provable assertion of
program equivalence is computable, in negligible time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MERLOT: Multimodal Neural Script Knowledge Models. (arXiv:2106.02636v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zellers_R/0/1/0/all/0/1">Rowan Zellers</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Ximing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hessel_J/0/1/0/all/0/1">Jack Hessel</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Youngjae Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jae Sung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1">Jize Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02636">
                                    <div class="article-summary-box-inner">
                                        <span>As humans, we understand events in the visual world contextually, performing
multimodal reasoning across time to make inferences about the past, present,
and future. We introduce MERLOT, a model that learns multimodal script
knowledge by watching millions of YouTube videos with transcribed speech -- in
an entirely label-free, self-supervised manner. By pretraining with a mix of
both frame-level (spatial) and video-level (temporal) objectives, our model not
only learns to match images to temporally corresponding words, but also to
contextualize what is happening globally over time. As a result, MERLOT
exhibits strong out-of-the-box representations of temporal commonsense, and
achieves state-of-the-art performance on 12 different video QA datasets when
finetuned. It also transfers well to the world of static images, allowing
models to reason about the dynamic context behind visual scenes. On Visual
Commonsense Reasoning, MERLOT answers questions correctly with 80.6% accuracy,
outperforming state-of-the-art models of similar size by over 3%, even those
that make heavy use of auxiliary supervised data (like object bounding boxes).

Ablation analyses demonstrate the complementary importance of: 1) training on
videos versus static images; 2) scaling the magnitude and diversity of the
pretraining video corpus; and 3) using diverse objectives that encourage
full-stack multimodal reasoning, from the recognition to cognition level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Estimation of Derivatives Using Plug-in KRR Estimators. (arXiv:2006.01350v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Liu_Z/0/1/0/all/0/1">Zejian Liu</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1">Meng Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.01350">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of estimating the derivatives of the regression
function, which has a wide range of applications as a key nonparametric
functional of unknown functions. Standard analysis may be tailored to specific
derivative orders, and parameter tuning remains a daunting challenge
particularly for high-order derivatives. In this article, we propose a simple
plug-in kernel ridge regression (KRR) estimator in nonparametric regression
with random design that is broadly applicable for multi-dimensional support and
arbitrary mixed-partial derivatives. We provide a non-asymptotic analysis to
study the behavior of the proposed estimator, leading to two error bounds for a
general class of kernels under the strong $L_\infty$ norm. In a concrete
example specialized to kernels with polynomially decaying eigenvalues, the
proposed estimator recovers the minimax optimal rate up to a logarithmic factor
for estimating derivatives of functions in H\&quot;older class. Interestingly, the
proposed estimator achieves the optimal rate of convergence with the same
choice of tuning parameter for any order of derivatives. Hence, the proposed
estimator enjoys a remarkable \textit{plug-in property} for derivatives in that
it automatically adapts to the order of derivatives to be estimated, enabling
easy tuning in practice. Our simulation studies show favorable finite sample
performance of the proposed method relative to several existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Aggregation Functions. (arXiv:2012.08482v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pellegrini_G/0/1/0/all/0/1">Giovanni Pellegrini</a>, <a href="http://arxiv.org/find/cs/1/au:+Tibo_A/0/1/0/all/0/1">Alessandro Tibo</a>, <a href="http://arxiv.org/find/cs/1/au:+Frasconi_P/0/1/0/all/0/1">Paolo Frasconi</a>, <a href="http://arxiv.org/find/cs/1/au:+Passerini_A/0/1/0/all/0/1">Andrea Passerini</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaeger_M/0/1/0/all/0/1">Manfred Jaeger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08482">
                                    <div class="article-summary-box-inner">
                                        <span>Learning on sets is increasingly gaining attention in the machine learning
community, due to its widespread applicability. Typically, representations over
sets are computed by using fixed aggregation functions such as sum or maximum.
However, recent results showed that universal function representation by sum-
(or max-) decomposition requires either highly discontinuous (and thus poorly
learnable) mappings, or a latent dimension equal to the maximum number of
elements in the set. To mitigate this problem, we introduce a learnable
aggregation function (LAF) for sets of arbitrary cardinality. LAF can
approximate several extensively used aggregators (such as average, sum,
maximum) as well as more complex functions (e.g., variance and skewness). We
report experiments on semi-synthetic and real data showing that LAF outperforms
state-of-the-art sum- (max-) decomposition architectures such as DeepSets and
library-based architectures like Principal Neighborhood Aggregation, and can be
effectively combined with attention-based architectures.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Editing Conditional Radiance Fields. (arXiv:2105.06466v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Steven Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiuming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhoutong Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Richard Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun-Yan Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Russell_B/0/1/0/all/0/1">Bryan Russell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06466">
                                    <div class="article-summary-box-inner">
                                        <span>A neural radiance field (NeRF) is a scene model supporting high-quality view
synthesis, optimized per scene. In this paper, we explore enabling user editing
of a category-level NeRF - also known as a conditional radiance field - trained
on a shape category. Specifically, we introduce a method for propagating coarse
2D user scribbles to the 3D space, to modify the color or shape of a local
region. First, we propose a conditional radiance field that incorporates new
modular network components, including a shape branch that is shared across
object instances. Observing multiple instances of the same category, our model
learns underlying part semantics without any supervision, thereby allowing the
propagation of coarse 2D user scribbles to the entire 3D region (e.g., chair
seat). Next, we propose a hybrid network update strategy that targets specific
network components, which balances efficiency and accuracy. During user
interaction, we formulate an optimization problem that both satisfies the
user&#x27;s constraints and preserves the original object structure. We demonstrate
our approach on various editing tasks over three shape datasets and show that
it outperforms prior neural editing approaches. Finally, we edit the appearance
and shape of a real photograph and show that the edit propagates to
extrapolated novel views.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Importance Weighted Policy Learning and Adaptation. (arXiv:2009.04875v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Galashov_A/0/1/0/all/0/1">Alexandre Galashov</a>, <a href="http://arxiv.org/find/cs/1/au:+Sygnowski_J/0/1/0/all/0/1">Jakub Sygnowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Desjardins_G/0/1/0/all/0/1">Guillaume Desjardins</a>, <a href="http://arxiv.org/find/cs/1/au:+Humplik_J/0/1/0/all/0/1">Jan Humplik</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasenclever_L/0/1/0/all/0/1">Leonard Hasenclever</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_R/0/1/0/all/0/1">Rae Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1">Yee Whye Teh</a>, <a href="http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1">Nicolas Heess</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.04875">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to exploit prior experience to solve novel problems rapidly is a
hallmark of biological learning systems and of great practical importance for
artificial ones. In the meta reinforcement learning literature much recent work
has focused on the problem of optimizing the learning process itself. In this
paper we study a complementary approach which is conceptually simple, general,
modular and built on top of recent improvements in off-policy learning. The
framework is inspired by ideas from the probabilistic inference literature and
combines robust off-policy learning with a behavior prior, or default behavior
that constrains the space of solutions and serves as a bias for exploration; as
well as a representation for the value function, both of which are easily
learned from a number of training tasks in a multi-task scenario. Our approach
achieves competitive adaptation performance on hold-out tasks compared to meta
reinforcement learning baselines and can scale to complex sparse-reward
scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Some observations on high-dimensional partial differential equations with Barron data. (arXiv:2012.01484v3 [math.AP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+E_W/0/1/0/all/0/1">Weinan E</a>, <a href="http://arxiv.org/find/math/1/au:+Wojtowytsch_S/0/1/0/all/0/1">Stephan Wojtowytsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01484">
                                    <div class="article-summary-box-inner">
                                        <span>We use explicit representation formulas to show that solutions to certain
partial differential equations lie in Barron spaces or multilayer spaces if the
PDE data lie in such function spaces. Consequently, these solutions can be
represented efficiently using artificial neural networks, even in high
dimension. Conversely, we present examples in which the solution fails to lie
in the function space associated to a neural network under consideration.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why does CTC result in peaky behavior?. (arXiv:2105.14849v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1">Albert Zeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1">Ralf Schl&#xfc;ter</a>, <a href="http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1">Hermann Ney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14849">
                                    <div class="article-summary-box-inner">
                                        <span>The peaky behavior of CTC models is well known experimentally. However, an
understanding about why peaky behavior occurs is missing, and whether this is a
good property. We provide a formal analysis of the peaky behavior and gradient
descent convergence properties of the CTC loss and related training criteria.
Our analysis provides a deep understanding why peaky behavior occurs and when
it is suboptimal. On a simple example which should be trivial to learn for any
model, we prove that a feed-forward neural network trained with CTC from
uniform initialization converges towards peaky behavior with a 100% error rate.
Our analysis further explains why CTC only works well together with the blank
label. We further demonstrate that peaky behavior does not occur on other
related losses including a label prior model, and that this improves
convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regular Expressions for Fast-response COVID-19 Text Classification. (arXiv:2102.09507v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1">Igor L. Markov</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jacqueline Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Vagner_A/0/1/0/all/0/1">Adam Vagner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09507">
                                    <div class="article-summary-box-inner">
                                        <span>Text classifiers are at the core of many NLP applications and use a variety
of algorithmic approaches and software. This paper introduces infrastructure
and methodologies for text classifiers based on large-scale regular
expressions. In particular, we describe how Facebook determines if a given
piece of text - anything from a hashtag to a post - belongs to a narrow topic
such as COVID-19. To fully define a topic and evaluate classifier performance
we employ human-guided iterations of keyword discovery, but do not require
labeled data. For COVID-19, we build two sets of regular expressions: (1) for
66 languages, with 99% precision and recall &gt;50%, (2) for the 11 most common
languages, with precision &gt;90% and recall &gt;90%. Regular expressions enable
low-latency queries from multiple platforms. Response to challenges like
COVID-19 is fast and so are revisions. Comparisons to a DNN classifier show
explainable results, higher precision and recall, and less overfitting. Our
learnings can be applied to other narrow-topic classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Model-agnostic and Scalable Counterfactual Explanations via Reinforcement Learning. (arXiv:2106.02597v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samoilescu_R/0/1/0/all/0/1">Robert-Florian Samoilescu</a>, <a href="http://arxiv.org/find/cs/1/au:+Looveren_A/0/1/0/all/0/1">Arnaud Van Looveren</a>, <a href="http://arxiv.org/find/cs/1/au:+Klaise_J/0/1/0/all/0/1">Janis Klaise</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02597">
                                    <div class="article-summary-box-inner">
                                        <span>Counterfactual instances are a powerful tool to obtain valuable insights into
automated decision processes, describing the necessary minimal changes in the
input space to alter the prediction towards a desired target. Most previous
approaches require a separate, computationally expensive optimization procedure
per instance, making them impractical for both large amounts of data and
high-dimensional data. Moreover, these methods are often restricted to certain
subclasses of machine learning models (e.g. differentiable or tree-based
models). In this work, we propose a deep reinforcement learning approach that
transforms the optimization procedure into an end-to-end learnable process,
allowing us to generate batches of counterfactual instances in a single forward
pass. Our experiments on real-world data show that our method i) is
model-agnostic (does not assume differentiability), relying only on feedback
from model predictions; ii) allows for generating target-conditional
counterfactual instances; iii) allows for flexible feature range constraints
for numerical and categorical attributes, including the immutability of
protected features (e.g. gender, race); iv) is easily extended to other data
modalities such as images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NF-GNN: Network Flow Graph Neural Networks for Malware Detection and Classification. (arXiv:2103.03939v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Busch_J/0/1/0/all/0/1">Julian Busch</a>, <a href="http://arxiv.org/find/cs/1/au:+Kocheturov_A/0/1/0/all/0/1">Anton Kocheturov</a>, <a href="http://arxiv.org/find/cs/1/au:+Tresp_V/0/1/0/all/0/1">Volker Tresp</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidl_T/0/1/0/all/0/1">Thomas Seidl</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03939">
                                    <div class="article-summary-box-inner">
                                        <span>Malicious software (malware) poses an increasing threat to the security of
communication systems as the number of interconnected mobile devices increases
exponentially. While some existing malware detection and classification
approaches successfully leverage network traffic data, they treat network flows
between pairs of endpoints independently and thus fail to leverage rich
communication patterns present in the complete network. Our approach first
extracts flow graphs and subsequently classifies them using a novel edge
feature-based graph neural network model. We present three variants of our base
model, which support malware detection and classification in supervised and
unsupervised settings. We evaluate our approach on flow graphs that we extract
from a recently published dataset for mobile malware detection that addresses
several issues with previously available datasets. Experiments on four
different prediction tasks consistently demonstrate the advantages of our
approach and show that our graph neural network model can boost detection
performance by a significant margin.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Maximum Likelihood Training of Score-Based Diffusion Models. (arXiv:2101.09258v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Song_Y/0/1/0/all/0/1">Yang Song</a>, <a href="http://arxiv.org/find/stat/1/au:+Durkan_C/0/1/0/all/0/1">Conor Durkan</a>, <a href="http://arxiv.org/find/stat/1/au:+Murray_I/0/1/0/all/0/1">Iain Murray</a>, <a href="http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09258">
                                    <div class="article-summary-box-inner">
                                        <span>Score-based diffusion models synthesize samples by reversing a stochastic
process that diffuses data to noise, and are trained by minimizing a weighted
combination of score matching losses. The log-likelihood of score-based models
can be tractably computed through a connection to continuous normalizing flows,
but log-likelihood is not directly optimized by the weighted combination of
score matching losses. We show that for a specific weighting scheme, the
objective upper bounds the negative log-likelihood, thus enabling approximate
maximum likelihood training of score-based models. We empirically observe that
maximum likelihood training consistently improves the likelihood of score-based
models across multiple datasets, stochastic processes, and model architectures.
Our best models achieve negative log-likelihoods of 2.74 and 3.76 bits/dim on
CIFAR-10 and down-sampled ImageNet, outperforming all existing likelihood-based
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Alert Classification for the ALeRCE Broker System: The Real-time Stamp Classifier. (arXiv:2008.03309v2 [astro-ph.IM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Carrasco_Davis_R/0/1/0/all/0/1">Rodrigo Carrasco-Davis</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Reyes_E/0/1/0/all/0/1">Esteban Reyes</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Valenzuela_C/0/1/0/all/0/1">Camilo Valenzuela</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Forster_F/0/1/0/all/0/1">Francisco F&#xf6;rster</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Estevez_P/0/1/0/all/0/1">Pablo A. Est&#xe9;vez</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Pignata_G/0/1/0/all/0/1">Giuliano Pignata</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Bauer_F/0/1/0/all/0/1">Franz E. Bauer</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Reyes_I/0/1/0/all/0/1">Ignacio Reyes</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sanchez_Saez_P/0/1/0/all/0/1">Paula S&#xe1;nchez-S&#xe1;ez</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Cabrera_Vives_G/0/1/0/all/0/1">Guillermo Cabrera-Vives</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Eyheramendy_S/0/1/0/all/0/1">Susana Eyheramendy</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Catelan_M/0/1/0/all/0/1">M&#xe1;rcio Catelan</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Arredondo_J/0/1/0/all/0/1">Javier Arredondo</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Castillo_Navarrete_E/0/1/0/all/0/1">Ernesto Castillo-Navarrete</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Rodriguez_Mancini_D/0/1/0/all/0/1">Diego Rodr&#xed;guez-Mancini</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Ruz_Mieres_D/0/1/0/all/0/1">Daniela Ruz-Mieres</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Moya_A/0/1/0/all/0/1">Alberto Moya</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sabatini_Gacitua_L/0/1/0/all/0/1">Luis Sabatini-Gacit&#xfa;a</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Sepulveda_Cobo_C/0/1/0/all/0/1">Crist&#xf3;bal Sep&#xfa;lveda-Cobo</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Mahabal_A/0/1/0/all/0/1">Ashish A. Mahabal</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Silva_Farfan_J/0/1/0/all/0/1">Javier Silva-Farf&#xe1;n</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Camacho_Iniquez_E/0/1/0/all/0/1">Ernesto Camacho-I&#xf1;iquez</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Galbany_L/0/1/0/all/0/1">Llu&#xed;s Galbany</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03309">
                                    <div class="article-summary-box-inner">
                                        <span>We present a real-time stamp classifier of astronomical events for the ALeRCE
(Automatic Learning for the Rapid Classification of Events) broker. The
classifier is based on a convolutional neural network, trained on alerts
ingested from the Zwicky Transient Facility (ZTF). Using only the
\textit{science, reference} and \textit{difference} images of the first
detection as inputs, along with the metadata of the alert as features, the
classifier is able to correctly classify alerts from active galactic nuclei,
supernovae (SNe), variable stars, asteroids and bogus classes, with high
accuracy ($\sim$94\%) in a balanced test set. In order to find and analyze SN
candidates selected by our classifier from the ZTF alert stream, we designed
and deployed a visualization tool called SN Hunter, where relevant information
about each possible SN is displayed for the experts to choose among candidates
to report to the Transient Name Server database. From June 26th 2019 to
February 28th 2021, we have reported 6846 SN candidates to date (11.8
candidates per day on average), of which 971 have been confirmed
spectroscopically. Our ability to report objects using only a single detection
means that 70\% of the reported SNe occurred within one day after the first
detection. ALeRCE has only reported candidates not otherwise detected or
selected by other groups, therefore adding new early transients to the bulk of
objects available for early follow-up. Our work represents an important
milestone toward rapid alert classifications with the next generation of large
etendue telescopes, such as the Vera C. Rubin Observatory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Defending Democracy: Using Deep Learning to Identify and Prevent Misinformation. (arXiv:2106.02607v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trivedi_A/0/1/0/all/0/1">Anusua Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Suhm_A/0/1/0/all/0/1">Alyssa Suhm</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahankal_P/0/1/0/all/0/1">Prathamesh Mahankal</a>, <a href="http://arxiv.org/find/cs/1/au:+Mukuntharaj_S/0/1/0/all/0/1">Subhiksha Mukuntharaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Parab_M/0/1/0/all/0/1">Meghana D. Parab</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohan_M/0/1/0/all/0/1">Malvika Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Berger_M/0/1/0/all/0/1">Meredith Berger</a>, <a href="http://arxiv.org/find/cs/1/au:+Sethumadhavan_A/0/1/0/all/0/1">Arathi Sethumadhavan</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaiman_A/0/1/0/all/0/1">Ashish Jaiman</a>, <a href="http://arxiv.org/find/cs/1/au:+Dodhia_R/0/1/0/all/0/1">Rahul Dodhia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02607">
                                    <div class="article-summary-box-inner">
                                        <span>The rise in online misinformation in recent years threatens democracies by
distorting authentic public discourse and causing confusion, fear, and even, in
extreme cases, violence. There is a need to understand the spread of false
content through online networks for developing interventions that disrupt
misinformation before it achieves virality. Using a Deep Bidirectional
Transformer for Language Understanding (BERT) and propagation graphs, this
study classifies and visualizes the spread of misinformation on a social media
network using publicly available Twitter data. The results confirm prior
research around user clusters and the virality of false content while improving
the precision of deep learning models for misinformation detection. The study
further demonstrates the suitability of BERT for providing a scalable model for
false information detection, which can contribute to the development of more
timely and accurate interventions to slow the spread of misinformation in
online environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image Enhanced Rotation Prediction for Self-Supervised Learning. (arXiv:1912.11603v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Yamaguchi_S/0/1/0/all/0/1">Shin&#x27;ya Yamaguchi</a>, <a href="http://arxiv.org/find/stat/1/au:+Kanai_S/0/1/0/all/0/1">Sekitoshi Kanai</a>, <a href="http://arxiv.org/find/stat/1/au:+Shioda_T/0/1/0/all/0/1">Tetsuya Shioda</a>, <a href="http://arxiv.org/find/stat/1/au:+Takeda_S/0/1/0/all/0/1">Shoichiro Takeda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.11603">
                                    <div class="article-summary-box-inner">
                                        <span>The rotation prediction (Rotation) is a simple pretext-task for
self-supervised learning (SSL), where models learn useful representations for
target vision tasks by solving pretext-tasks. Although Rotation captures
information of object shapes, it hardly captures information of textures. To
tackle this problem, we introduce a novel pretext-task called image enhanced
rotation prediction (IE-Rot) for SSL. IE-Rot simultaneously solves Rotation and
another pretext-task based on image enhancement (e.g., sharpening and
solarizing) while maintaining simplicity. Through the simultaneous prediction
of rotation and image enhancement, models learn representations to capture the
information of not only object shapes but also textures. Our experimental
results show that IE-Rot models outperform Rotation on various standard
benchmarks including ImageNet classification, PASCAL-VOC detection, and COCO
detection/segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bilinear Classes: A Structural Framework for Provable Generalization in RL. (arXiv:2103.10897v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon S. Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham M. Kakade</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jason D. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Lovett_S/0/1/0/all/0/1">Shachar Lovett</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahajan_G/0/1/0/all/0/1">Gaurav Mahajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1">Wen Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1">Ruosong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10897">
                                    <div class="article-summary-box-inner">
                                        <span>This work introduces Bilinear Classes, a new structural framework, which
permit generalization in reinforcement learning in a wide variety of settings
through the use of function approximation. The framework incorporates nearly
all existing models in which a polynomial sample complexity is achievable, and,
notably, also includes new models, such as the Linear $Q^*/V^*$ model in which
both the optimal $Q$-function and the optimal $V$-function are linear in some
known feature space. Our main result provides an RL algorithm which has
polynomial sample complexity for Bilinear Classes; notably, this sample
complexity is stated in terms of a reduction to the generalization error of an
underlying supervised learning sub-problem. These bounds nearly match the best
known sample complexity bounds for existing models. Furthermore, this framework
also extends to the infinite dimensional (RKHS) setting: for the the Linear
$Q^*/V^*$ model, linear MDPs, and linear mixture MDPs, we provide sample
complexities that have no explicit dependence on the explicit feature dimension
(which could be infinite), but instead depends only on information theoretic
quantities.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fundamental Limits of Prediction, Generalization, and Recursion: An Entropic-Innovations Perspective. (arXiv:2001.03813v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fang_S/0/1/0/all/0/1">Song Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1">Quanyan Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.03813">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we examine the fundamental performance limits of prediction,
with or without side information. More specifically, we derive generic lower
bounds on the $\mathcal{L}_p$ norms of the prediction errors that are valid for
any prediction algorithms and for any data distributions. Meanwhile, we combine
the entropic analysis from information theory and the innovations approach from
prediction/estimation theory to characterize the conditions (in terms of, e.g.,
directed information or mutual information) to achieve the bounds. We also
investigate the implications of the results in analyzing the fundamental limits
of generalization in fitting (learning) problems from the perspective of
prediction with side information, as well as the fundamental limits of
recursive algorithms by viewing them as generalized prediction problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Slice Low-Rank Tensor Decomposition Based Multi-Atlas Segmentation: Application to Automatic Pathological Liver CT Segmentation. (arXiv:2102.12056v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Shi_C/0/1/0/all/0/1">Changfa Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Xian_M/0/1/0/all/0/1">Min Xian</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhou_X/0/1/0/all/0/1">Xiancheng Zhou</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_H/0/1/0/all/0/1">Haotian Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Cheng_H/0/1/0/all/0/1">Heng-Da Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12056">
                                    <div class="article-summary-box-inner">
                                        <span>Liver segmentation from abdominal CT images is an essential step for liver
cancer computer-aided diagnosis and surgical planning. However, both the
accuracy and robustness of existing liver segmentation methods cannot meet the
requirements of clinical applications. In particular, for the common clinical
cases where the liver tissue contains major pathology, current segmentation
methods show poor performance. In this paper, we propose a novel low-rank
tensor decomposition (LRTD) based multi-atlas segmentation (MAS) framework that
achieves accurate and robust pathological liver segmentation of CT images.
Firstly, we propose a multi-slice LRTD scheme to recover the underlying
low-rank structure embedded in 3D medical images. It performs the LRTD on small
image segments consisting of multiple consecutive image slices. Then, we
present an LRTD-based atlas construction method to generate tumor-free liver
atlases that mitigates the performance degradation of liver segmentation due to
the presence of tumors. Finally, we introduce an LRTD-based MAS algorithm to
derive patient-specific liver atlases for each test image, and to achieve
accurate pairwise image registration and label propagation. Extensive
experiments on three public databases of pathological liver cases validate the
effectiveness of the proposed method. Both qualitative and quantitative results
demonstrate that, in the presence of major pathology, the proposed method is
more accurate and robust than state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Difficulty of Unbiased Alpha Divergence Minimization. (arXiv:2010.09541v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Geffner_T/0/1/0/all/0/1">Tomas Geffner</a>, <a href="http://arxiv.org/find/stat/1/au:+Domke_J/0/1/0/all/0/1">Justin Domke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09541">
                                    <div class="article-summary-box-inner">
                                        <span>Several approximate inference algorithms have been proposed to minimize an
alpha-divergence between an approximating distribution and a target
distribution. Many of these algorithms introduce bias, the magnitude of which
becomes problematic in high dimensions. Other algorithms are unbiased. These
often seem to suffer from high variance, but little is rigorously known. In
this work we study unbiased methods for alpha-divergence minimization through
the Signal-to-Noise Ratio (SNR) of the gradient estimator. We study several
representative scenarios where strong analytical results are possible, such as
fully-factorized or Gaussian distributions. We find that when alpha is not
zero, the SNR worsens exponentially in the dimensionality of the problem. This
casts doubt on the practicality of these methods. We empirically confirm these
theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Iterative Graph Matching. (arXiv:2106.02206v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Linfeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hughes_M/0/1/0/all/0/1">Michael C. Hughes</a>, <a href="http://arxiv.org/find/cs/1/au:+Hassoun_S/0/1/0/all/0/1">Soha Hassoun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Li-Ping Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02206">
                                    <div class="article-summary-box-inner">
                                        <span>Recent works leveraging Graph Neural Networks to approach graph matching
tasks have shown promising results. Recent progress in learning discrete
distributions poses new opportunities for learning graph matching models. In
this work, we propose a new model, Stochastic Iterative Graph MAtching (SIGMA),
to address the graph matching problem. Our model defines a distribution of
matchings for a graph pair so the model can explore a wide range of possible
matchings. We further introduce a novel multi-step matching procedure, which
learns how to refine a graph pair&#x27;s matching results incrementally. The model
also includes dummy nodes so that the model does not have to find matchings for
nodes without correspondence. We fit this model to data via scalable stochastic
optimization. We conduct extensive experiments across synthetic graph datasets
as well as biochemistry and computer vision applications. Across all tasks, our
results show that SIGMA can produce significantly improved graph matching
results compared to state-of-the-art models. Ablation studies verify that each
of our components (stochastic training, iterative matching, and dummy nodes)
offers noticeable improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detect the Interactions that Matter in Matter: Geometric Attention for Many-Body Systems. (arXiv:2106.02549v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Frank_T/0/1/0/all/0/1">Thorben Frank</a>, <a href="http://arxiv.org/find/cs/1/au:+Chmiela_S/0/1/0/all/0/1">Stefan Chmiela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02549">
                                    <div class="article-summary-box-inner">
                                        <span>Attention mechanisms are developing into a viable alternative to
convolutional layers as elementary building block of NNs. Their main advantage
is that they are not restricted to capture local dependencies in the input, but
can draw arbitrary connections. This unprecedented capability coincides with
the long-standing problem of modeling global atomic interactions in molecular
force fields and other many-body problems. In its original formulation,
however, attention is not applicable to the continuous domains in which the
atoms live. For this purpose we propose a variant to describe geometric
relations for arbitrary atomic configurations in Euclidean space that also
respects all relevant physical symmetries. We furthermore demonstrate, how the
successive application of our learned attention matrices effectively translates
the molecular geometry into a set of individual atomic contributions
on-the-fly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PCA Initialization for Approximate Message Passing in Rotationally Invariant Models. (arXiv:2106.02356v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Mondelli_M/0/1/0/all/0/1">Marco Mondelli</a>, <a href="http://arxiv.org/find/stat/1/au:+Venkataramanan_R/0/1/0/all/0/1">Ramji Venkataramanan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02356">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of estimating a rank-$1$ signal in the presence of
rotationally invariant noise-a class of perturbations more general than
Gaussian noise. Principal Component Analysis (PCA) provides a natural
estimator, and sharp results on its performance have been obtained in the
high-dimensional regime. Recently, an Approximate Message Passing (AMP)
algorithm has been proposed as an alternative estimator with the potential to
improve the accuracy of PCA. However, the existing analysis of AMP requires an
initialization that is both correlated with the signal and independent of the
noise, which is often unrealistic in practice. In this work, we combine the two
methods, and propose to initialize AMP with PCA. Our main result is a rigorous
asymptotic characterization of the performance of this estimator. Both the AMP
algorithm and its analysis differ from those previously derived in the Gaussian
setting: at every iteration, our AMP algorithm requires a specific term to
account for PCA initialization, while in the Gaussian case, PCA initialization
affects only the first iteration of AMP. The proof is based on a two-phase
artificial AMP that first approximates the PCA estimator and then mimics the
true AMP. Our numerical simulations show an excellent agreement between AMP
results and theoretical predictions, and suggest an interesting open direction
on achieving Bayes-optimal performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Streaming Linear System Identification with Reverse Experience Replay. (arXiv:2103.05896v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Prateek Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowshik_S/0/1/0/all/0/1">Suhas S Kowshik</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagaraj_D/0/1/0/all/0/1">Dheeraj Nagaraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1">Praneeth Netrapalli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.05896">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of estimating a linear time-invariant (LTI) dynamical
system from a single trajectory via streaming algorithms, which is encountered
in several applications including reinforcement learning (RL) and time-series
analysis. While the LTI system estimation problem is well-studied in the {\em
offline} setting, the practically important streaming/online setting has
received little attention. Standard streaming methods like stochastic gradient
descent (SGD) are unlikely to work since streaming points can be highly
correlated. In this work, we propose a novel streaming algorithm, SGD with
Reverse Experience Replay ($\mathsf{SGD}-\mathsf{RER}$), that is inspired by
the experience replay (ER) technique popular in the RL literature.
$\mathsf{SGD}-\mathsf{RER}$ divides data into small buffers and runs SGD
backwards on the data stored in the individual buffers. We show that this
algorithm exactly deconstructs the dependency structure and obtains information
theoretically optimal guarantees for both parameter error and prediction error.
Thus, we provide the first -- to the best of our knowledge -- optimal SGD-style
algorithm for the classical problem of linear system identification with a
first order oracle. Furthermore, $\mathsf{SGD}-\mathsf{RER}$ can be applied to
more general settings like sparse LTI identification with known sparsity
pattern, and non-linear dynamical systems. Our work demonstrates that the
knowledge of data dependency structure can aid us in designing statistically
and computationally efficient algorithms which can &quot;decorrelate&quot; streaming
samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning phylogenetic trees as hyperbolic point configurations. (arXiv:2104.11430v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wilson_B/0/1/0/all/0/1">Benjamin Wilson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.11430">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel method for the inference of phylogenetic trees that
utilises point configurations on hyperbolic space as its optimisation
landscape. Each taxon corresponds to a point of the point configuration, while
the evolutionary distance between taxa is represented by the geodesic distance
between their corresponding points. The point configuration is iteratively
modified to increase an objective function that additively combines pairwise
log-likelihood terms. After convergence, the final tree is derived from the
inter-point distances using a standard distance-based method. The objective
function, which is shown to mimic the log-likelihood on tree space, is a
differentiable function on a Riemannian manifold. Thus gradient-based
optimisation techniques can be applied, avoiding the need for combinatorial
rearrangements of tree topology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sobolev Norm Learning Rates for Conditional Mean Embeddings. (arXiv:2105.07446v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Talwai_P/0/1/0/all/0/1">Prem Talwai</a>, <a href="http://arxiv.org/find/stat/1/au:+Shameli_A/0/1/0/all/0/1">Ali Shameli</a>, <a href="http://arxiv.org/find/stat/1/au:+Simchi_Levi_D/0/1/0/all/0/1">David Simchi-Levi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07446">
                                    <div class="article-summary-box-inner">
                                        <span>We develop novel learning rates for conditional mean embeddings by applying
the theory of interpolation for reproducing kernel Hilbert spaces (RKHS). We
derive explicit, adaptive convergence rates for the sample estimator under the
misspecifed setting, where the target operator is not Hilbert-Schmidt or
bounded with respect to the input/output RKHSs. We demonstrate that in certain
parameter regimes, we can achieve uniform convergence rates in the output RKHS.
We hope our analyses will allow the much broader application of conditional
mean embeddings to more complex ML/RL settings involving infinite dimensional
RKHSs and continuous state spaces.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Representation formulas and pointwise properties for Barron functions. (arXiv:2006.05982v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+E_W/0/1/0/all/0/1">Weinan E</a>, <a href="http://arxiv.org/find/stat/1/au:+Wojtowytsch_S/0/1/0/all/0/1">Stephan Wojtowytsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05982">
                                    <div class="article-summary-box-inner">
                                        <span>We study the natural function space for infinitely wide two-layer neural
networks with ReLU activation (Barron space) and establish different
representation formulae. In two cases, we describe the space explicitly up to
isomorphism.

Using a convenient representation, we study the pointwise properties of
two-layer networks and show that functions whose singular set is fractal or
curved (for example distance functions from smooth submanifolds) cannot be
represented by infinitely wide two-layer networks with finite path-norm. We use
this structure theorem to show that the only $C^1$-diffeomorphisms which Barron
space are affine.

Furthermore, we show that every Barron function can be decomposed as the sum
of a bounded and a positively one-homogeneous function and that there exist
Barron functions which decay rapidly at infinity and are globally
Lebesgue-integrable. This result suggests that two-layer neural networks may be
able to approximate a greater variety of functions than commonly believed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Be Considerate: Objectives, Side Effects, and Deciding How to Act. (arXiv:2106.02617v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alamdari_P/0/1/0/all/0/1">Parand Alizadeh Alamdari</a>, <a href="http://arxiv.org/find/cs/1/au:+Klassen_T/0/1/0/all/0/1">Toryn Q. Klassen</a>, <a href="http://arxiv.org/find/cs/1/au:+Icarte_R/0/1/0/all/0/1">Rodrigo Toro Icarte</a>, <a href="http://arxiv.org/find/cs/1/au:+McIlraith_S/0/1/0/all/0/1">Sheila A. McIlraith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02617">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work in AI safety has highlighted that in sequential decision making,
objectives are often underspecified or incomplete. This gives discretion to the
acting agent to realize the stated objective in ways that may result in
undesirable outcomes. We contend that to learn to act safely, a reinforcement
learning (RL) agent should include contemplation of the impact of its actions
on the wellbeing and agency of others in the environment, including other
acting agents and reactive processes. We endow RL agents with the ability to
contemplate such impact by augmenting their reward based on expectation of
future return by others in the environment, providing different criteria for
characterizing impact. We further endow these agents with the ability to
differentially factor this impact into their decision making, manifesting
behavior that ranges from self-centred to self-less, as demonstrated by
experiments in gridworld environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enabling Lightweight Fine-tuning for Pre-trained Language Model Compression based on Matrix Product Operators. (arXiv:2106.02205v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Peiyu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1">Ze-Feng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1">Z.Y. Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1">Zhong-Yi Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02205">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel pre-trained language models (PLM) compression
approach based on the matrix product operator (short as MPO) from quantum
many-body physics. It can decompose an original matrix into central tensors
(containing the core information) and auxiliary tensors (with only a small
proportion of parameters). With the decomposed MPO structure, we propose a
novel fine-tuning strategy by only updating the parameters from the auxiliary
tensors, and design an optimization algorithm for MPO-based approximation over
stacked network architectures. Our approach can be applied to the original or
the compressed PLMs in a general way, which derives a lighter network and
significantly reduces the parameters to be fine-tuned. Extensive experiments
have demonstrated the effectiveness of the proposed approach in model
compression, especially the reduction in finetuning parameters (91% reduction
on average).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improve the Interpretability of Attention: A Fast, Accurate, and Interpretable High-Resolution Attention Model. (arXiv:2106.02566v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gomez_T/0/1/0/all/0/1">Tristan Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_S/0/1/0/all/0/1">Suiyi Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Freour_T/0/1/0/all/0/1">Thomas Fr&#xe9;our</a>, <a href="http://arxiv.org/find/cs/1/au:+Mouchere_H/0/1/0/all/0/1">Harold Mouch&#xe8;re</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02566">
                                    <div class="article-summary-box-inner">
                                        <span>The prevalence of employing attention mechanisms has brought along concerns
on the interpretability of attention distributions. Although it provides
insights about how a model is operating, utilizing attention as the explanation
of model predictions is still highly dubious. The community is still seeking
more interpretable strategies for better identifying local active regions that
contribute the most to the final decision. To improve the interpretability of
existing attention models, we propose a novel Bilinear Representative
Non-Parametric Attention (BR-NPA) strategy that captures the task-relevant
human-interpretable information. The target model is first distilled to have
higher-resolution intermediate feature maps. From which, representative
features are then grouped based on local pairwise feature similarity, to
produce finer-grained, more precise attention maps highlighting task-relevant
parts of the input. The obtained attention maps are ranked according to the
&#x60;active level&#x27; of the compound feature, which provides information regarding
the important level of the highlighted regions. The proposed model can be
easily adapted in a wide variety of modern deep models, where classification is
involved. It is also more accurate, faster, and with a smaller memory footprint
than usual neural attention modules. Extensive experiments showcase more
comprehensive visual explanations compared to the state-of-the-art
visualization model across multiple tasks including few-shot classification,
person re-identification, fine-grained image classification. The proposed
visualization model sheds imperative light on how neural networks &#x60;pay their
attention&#x27; differently in different tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">AI Driven Road Maintenance Inspection. (arXiv:2106.02567v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mukherjee_R/0/1/0/all/0/1">Ratnajit Mukherjee</a>, <a href="http://arxiv.org/find/cs/1/au:+Iqbal_H/0/1/0/all/0/1">Haris Iqbal</a>, <a href="http://arxiv.org/find/cs/1/au:+Marzban_S/0/1/0/all/0/1">Shabbir Marzban</a>, <a href="http://arxiv.org/find/cs/1/au:+Badar_A/0/1/0/all/0/1">Ahmed Badar</a>, <a href="http://arxiv.org/find/cs/1/au:+Brouns_T/0/1/0/all/0/1">Terence Brouns</a>, <a href="http://arxiv.org/find/cs/1/au:+Gowda_S/0/1/0/all/0/1">Shruthi Gowda</a>, <a href="http://arxiv.org/find/cs/1/au:+Arani_E/0/1/0/all/0/1">Elahe Arani</a>, <a href="http://arxiv.org/find/cs/1/au:+Zonooz_B/0/1/0/all/0/1">Bahram Zonooz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02567">
                                    <div class="article-summary-box-inner">
                                        <span>Road infrastructure maintenance inspection is typically a labour-intensive
and critical task to ensure the safety of all the road users. In this work, we
propose a detailed methodology to use state-of-the-art techniques in artificial
intelligence and computer vision to automate a sizeable portion of the
maintenance inspection subtasks and reduce the labour costs. The proposed
methodology uses state-of-the-art computer vision techniques such as object
detection and semantic segmentation to automate inspections on primary road
structures such as the road surface, markings, barriers (guardrails) and
traffic signs. The models are mostly trained on commercially viable datasets
and augmented with proprietary data. We demonstrate that our AI models can not
only automate and scale maintenance inspections on primary road structures but
also result in higher recall compared to traditional manual inspections.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contracting Neural-Newton Solver. (arXiv:2106.02543v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chevalier_S/0/1/0/all/0/1">Samuel Chevalier</a>, <a href="http://arxiv.org/find/cs/1/au:+Stiasny_J/0/1/0/all/0/1">Jochen Stiasny</a>, <a href="http://arxiv.org/find/cs/1/au:+Chatzivasileiadis_S/0/1/0/all/0/1">Spyros Chatzivasileiadis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02543">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in deep learning have set the focus on neural networks (NNs)
that can successfully replace traditional numerical solvers in many
applications, achieving impressive computing gains. One such application is
time domain simulation, which is indispensable for the design, analysis and
operation of many engineering systems. Simulating dynamical systems with
implicit Newton-based solvers is a computationally heavy task, as it requires
the solution of a parameterized system of differential and algebraic equations
at each time step. A variety of NN-based methodologies have been shown to
successfully approximate the dynamical trajectories computed by numerical time
domain solvers at a fraction of the time. However, so far no previous NN-based
model has explicitly captured the fact that any predicted point on the time
domain trajectory also represents the fixed point of the numerical solver
itself. As we show, explicitly capturing this property can lead to
significantly increased NN accuracy and much smaller NN sizes. In this paper,
we model the Newton solver at the heart of an implicit Runge-Kutta integrator
as a contracting map iteratively seeking this fixed point. Our primary
contribution is to develop a recurrent NN simulation tool, termed the
Contracting Neural-Newton Solver (CoNNS), which explicitly captures the
contracting nature of these Newton iterations. To build CoNNS, we train a
feedforward NN and mimic this contraction behavior by embedding a series of
training constraints which guarantee the mapping provided by the NN satisfies
the Banach fixed-point theorem; thus, we are able to prove that successive
passes through the NN are guaranteed to converge to a unique, fixed point.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph-based Deep Learning for Communication Networks: A Survey. (arXiv:2106.02533v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1">Weiwei Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02533">
                                    <div class="article-summary-box-inner">
                                        <span>Communication networks are important infrastructures in contemporary society.
There are still many challenges that are not fully solved and new solutions are
proposed continuously in this active research area. In recent years, to model
the network topology, graph-based deep learning has achieved state-of-the-art
performance in a series of problems in communication networks. In this survey,
we review the rapidly growing body of research using different graph-based deep
learning models, e.g. graph convolutional and graph attention networks, in
various problems from different communication networks, e.g. wireless networks,
wired networks, and software-defined networks. We also present a well-organized
list of the problem and solution for each study and identify future research
directions. To the best of our knowledge, this paper is the first survey that
focuses on the application of graph-based deep learning methods in
communication networks. To track the follow-up research, a public GitHub
repository is created, where the relevant papers will be updated continuously.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning-based synthetic-CT generation in radiotherapy and PET: a review. (arXiv:2102.02734v2 [physics.med-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Spadea_M/0/1/0/all/0/1">Maria Francesca Spadea</a>, <a href="http://arxiv.org/find/physics/1/au:+Maspero_M/0/1/0/all/0/1">Matteo Maspero</a>, <a href="http://arxiv.org/find/physics/1/au:+Zaffino_P/0/1/0/all/0/1">Paolo Zaffino</a>, <a href="http://arxiv.org/find/physics/1/au:+Seco_J/0/1/0/all/0/1">Joao Seco</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02734">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, deep learning (DL)-based methods for the generation of synthetic
computed tomography (sCT) have received significant research attention as an
alternative to classical ones. We present here a systematic review of these
methods by grouping them into three categories, according to their clinical
applications: I) To replace CT in magnetic resonance (MR)-based treatment
planning. II) Facilitate cone-beam computed tomography (CBCT)-based
image-guided adaptive radiotherapy. III) Derive attenuation maps for the
correction of positron emission tomography (PET). Appropriate database
searching was performed on journal articles published between January 2014 and
December 2020. The DL methods&#x27; key characteristics were extracted from each
eligible study, and a comprehensive comparison among network architectures and
metrics was reported. A detailed review of each category was given,
highlighting essential contributions, identifying specific challenges, and
summarising the achievements. Lastly, the statistics of all the cited works
from various aspects were analysed, revealing the popularity and future trends,
and the potential of DL-based sCT generation. The current status of DL-based
sCT generation was evaluated, assessing the clinical readiness of the presented
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bag of Tricks for Node Classification with Graph Neural Networks. (arXiv:2103.13355v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yangkun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1">Jiarui Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Weinan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wipf_D/0/1/0/all/0/1">David Wipf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.13355">
                                    <div class="article-summary-box-inner">
                                        <span>Over the past few years, graph neural networks (GNN) and label
propagation-based methods have made significant progress in addressing node
classification tasks on graphs. However, in addition to their reliance on
elaborate architectures and algorithms, there are several key technical details
that are frequently overlooked, and yet nonetheless can play a vital role in
achieving satisfactory performance. In this paper, we first summarize a series
of existing tricks-of-the-trade, and then propose several new ones related to
label usage, loss function formulation, and model design that can significantly
improve various GNN architectures. We empirically evaluate their impact on
final node classification accuracy by conducting ablation studies and
demonstrate consistently-improved performance, often to an extent that
outweighs the gains from more dramatic changes in the underlying GNN
architecture. Notably, many of the top-ranked models on the Open Graph
Benchmark (OGB) leaderboard benefit from our techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fairness-Aware Unsupervised Feature Selection. (arXiv:2106.02216v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1">Xiaoying Xing</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hongfu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chen Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jundong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02216">
                                    <div class="article-summary-box-inner">
                                        <span>Feature selection is a prevalent data preprocessing paradigm for various
learning tasks. Due to the expensive cost of acquiring supervision information,
unsupervised feature selection sparks great interests recently. However,
existing unsupervised feature selection algorithms do not have fairness
considerations and suffer from a high risk of amplifying discrimination by
selecting features that are over associated with protected attributes such as
gender, race, and ethnicity. In this paper, we make an initial investigation of
the fairness-aware unsupervised feature selection problem and develop a
principled framework, which leverages kernel alignment to find a subset of
high-quality features that can best preserve the information in the original
feature space while being minimally correlated with protected attributes.
Specifically, different from the mainstream in-processing debiasing methods,
our proposed framework can be regarded as a model-agnostic debiasing strategy
that eliminates biases and discrimination before downstream learning algorithms
are involved. Experimental results on multiple real-world datasets demonstrate
that our framework achieves a good trade-off between utility maximization and
fairness promotion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convergence of Gradient Algorithms for Nonconvex C^{1+alpha} Cost Functions. (arXiv:2012.00628v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1">Zixuan Wang</a>, <a href="http://arxiv.org/find/math/1/au:+Tang_S/0/1/0/all/0/1">Shanjian Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00628">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is concerned with convergence of stochastic gradient algorithms
with momentum terms in the nonconvex setting. A class of stochastic momentum
methods, including stochastic gradient descent, heavy ball, and Nesterov&#x27;s
accelerated gradient, is analyzed in a general framework under mild
assumptions. Based on the convergence result of expected gradients, we prove
the almost sure convergence by a detailed discussion of the effects of momentum
and the number of upcrossings. It is worth noting that there are not additional
restrictions imposed on the objective function and stepsize. Another
improvement over previous results is that the existing Lipschitz condition of
the gradient is relaxed into the condition of Holder continuity. As a
byproduct, we apply a localization procedure to extend our results to
stochastic stepsizes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inferring Granger Causality from Irregularly Sampled Time Series. (arXiv:2106.02600v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1">Song Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yao Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Josef_C/0/1/0/all/0/1">Christopher S. Josef</a>, <a href="http://arxiv.org/find/cs/1/au:+Kamaleswaran_R/0/1/0/all/0/1">Rishikesan Kamaleswaran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02600">
                                    <div class="article-summary-box-inner">
                                        <span>Continuous, automated surveillance systems that incorporate machine learning
models are becoming increasingly more common in healthcare environments. These
models can capture temporally dependent changes across multiple patient
variables and can enhance a clinician&#x27;s situational awareness by providing an
early warning alarm of an impending adverse event such as sepsis. However, most
commonly used methods, e.g., XGBoost, fail to provide an interpretable
mechanism for understanding why a model produced a sepsis alarm at a given
time. The black-box nature of many models is a severe limitation as it prevents
clinicians from independently corroborating those physiologic features that
have contributed to the sepsis alarm. To overcome this limitation, we propose a
generalized linear model (GLM) approach to fit a Granger causal graph based on
the physiology of several major sepsis-associated derangements (SADs). We adopt
a recently developed stochastic monotone variational inequality-based estimator
coupled with forwarding feature selection to learn the graph structure from
both continuous and discrete-valued as well as regularly and irregularly
sampled time series. Most importantly, we develop a non-asymptotic upper bound
on the estimation error for any monotone link function in the GLM. We conduct
real-data experiments and demonstrate that our proposed method can achieve
comparable performance to popular and powerful prediction methods such as
XGBoost while simultaneously maintaining a high level of interpretability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering. (arXiv:2106.02634v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1">Vincent Sitzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezchikov_S/0/1/0/all/0/1">Semon Rezchikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1">William T. Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1">Fredo Durand</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02634">
                                    <div class="article-summary-box-inner">
                                        <span>Inferring representations of 3D scenes from 2D observations is a fundamental
problem of computer graphics, computer vision, and artificial intelligence.
Emerging 3D-structured neural scene representations are a promising approach to
3D scene understanding. In this work, we propose a novel neural scene
representation, Light Field Networks or LFNs, which represent both geometry and
appearance of the underlying 3D scene in a 360-degree, four-dimensional light
field parameterized via a neural implicit representation. Rendering a ray from
an LFN requires only a *single* network evaluation, as opposed to hundreds of
evaluations per ray for ray-marching or volumetric based renderers in
3D-structured neural scene representations. In the setting of simple scenes, we
leverage meta-learning to learn a prior over LFNs that enables multi-view
consistent light field reconstruction from as little as a single image
observation. This results in dramatic reductions in time and memory complexity,
and enables real-time rendering. The cost of storing a 360-degree light field
via an LFN is two orders of magnitude lower than conventional methods such as
the Lumigraph. Utilizing the analytical differentiability of neural implicit
representations and a novel parameterization of light space, we further
demonstrate the extraction of sparse depth maps from LFNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Syntactic Probes Probe Syntax? Experiments with Jabberwocky Probing. (arXiv:2106.02559v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1">Rowan Hall Maudslay</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02559">
                                    <div class="article-summary-box-inner">
                                        <span>Analysing whether neural language models encode linguistic information has
become popular in NLP. One method of doing so, which is frequently cited to
support the claim that models like BERT encode syntax, is called probing;
probes are small supervised models trained to extract linguistic information
from another model&#x27;s output. If a probe is able to predict a particular
structure, it is argued that the model whose output it is trained on must have
implicitly learnt to encode it. However, drawing a generalisation about a
model&#x27;s linguistic knowledge about a specific phenomena based on what a probe
is able to learn may be problematic: in this work, we show that semantic cues
in training data means that syntactic probes do not properly isolate syntax. We
generate a new corpus of semantically nonsensical but syntactically well-formed
Jabberwocky sentences, which we use to evaluate two probes trained on normal
data. We train the probes on several popular language models (BERT, GPT, and
RoBERTa), and find that in all settings they perform worse when evaluated on
these data, for one probe by an average of 15.4 UUAS points absolute. Although
in most cases they still outperform the baselines, their lead is reduced
substantially, e.g. by 53% in the case of BERT for one probe. This begs the
question: what empirical scores constitute knowing syntax?</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ViViT: Curvature access through the generalized Gauss-Newton&#x27;s low-rank structure. (arXiv:2106.02624v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dangel_F/0/1/0/all/0/1">Felix Dangel</a>, <a href="http://arxiv.org/find/cs/1/au:+Tatzel_L/0/1/0/all/0/1">Lukas Tatzel</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1">Philipp Hennig</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02624">
                                    <div class="article-summary-box-inner">
                                        <span>Curvature in form of the Hessian or its generalized Gauss-Newton (GGN)
approximation is valuable for algorithms that rely on a local model for the
loss to train, compress, or explain deep networks. Existing methods based on
implicit multiplication via automatic differentiation or Kronecker-factored
block diagonal approximations do not consider noise in the mini-batch. We
present ViViT, a curvature model that leverages the GGN&#x27;s low-rank structure
without further approximations. It allows for efficient computation of
eigenvalues, eigenvectors, as well as per-sample first- and second-order
directional derivatives. The representation is computed in parallel with
gradients in one backward pass and offers a fine-grained cost-accuracy
trade-off, which allows it to scale. As examples for ViViT&#x27;s usefulness, we
investigate the directional gradients and curvatures during training, and how
noise information can be used to improve the stability of second-order methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consensus Multiplicative Weights Update: Learning to Learn using Projector-based Game Signatures. (arXiv:2106.02615v1 [cs.GT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vadori_N/0/1/0/all/0/1">Nelson Vadori</a>, <a href="http://arxiv.org/find/cs/1/au:+Savani_R/0/1/0/all/0/1">Rahul Savani</a>, <a href="http://arxiv.org/find/cs/1/au:+Spooner_T/0/1/0/all/0/1">Thomas Spooner</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganesh_S/0/1/0/all/0/1">Sumitra Ganesh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02615">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, Optimistic Multiplicative Weights Update (OMWU) was proven to be
the first constant step-size algorithm in the online no-regret framework to
enjoy last-iterate convergence to Nash Equilibria in the constrained zero-sum
bimatrix case, where weights represent the probabilities of playing pure
strategies. We introduce the second such algorithm, \textit{Consensus MWU}, for
which we prove local convergence and show empirically that it enjoys faster and
more robust convergence than OMWU. Our algorithm shows the importance of a new
object, the \textit{simplex Hessian}, as well as of the interaction of the game
with the (eigen)space of vectors summing to zero, which we believe future
research can build on. As for OMWU, CMWU has convergence guarantees in the
zero-sum case only, but Cheung and Piliouras (2020) recently showed that OMWU
and MWU display opposite convergence properties depending on whether the game
is zero-sum or cooperative. Inspired by this work and the recent literature on
learning to optimize for single functions, we extend CMWU to non zero-sum games
by introducing a new framework for online learning in games, where the update
rule&#x27;s gradient and Hessian coefficients along a trajectory are learnt by a
reinforcement learning policy that is conditioned on the nature of the game:
\textit{the game signature}. We construct the latter using a new canonical
decomposition of two-player games into eight components corresponding to
commutative projection operators, generalizing and unifying recent game
concepts studied in the literature. We show empirically that our new learning
policy is able to exploit the game signature across a wide range of game types.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Robustness of QA Models to Challenge Sets with Variational Question-Answer Pair Generation. (arXiv:2004.03238v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shinoda_K/0/1/0/all/0/1">Kazutoshi Shinoda</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1">Saku Sugawara</a>, <a href="http://arxiv.org/find/cs/1/au:+Aizawa_A/0/1/0/all/0/1">Akiko Aizawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.03238">
                                    <div class="article-summary-box-inner">
                                        <span>Question answering (QA) models for reading comprehension have achieved
human-level accuracy on in-distribution test sets. However, they have been
demonstrated to lack robustness to challenge sets, whose distribution is
different from that of training sets. Existing data augmentation methods
mitigate this problem by simply augmenting training sets with synthetic
examples sampled from the same distribution as the challenge sets. However,
these methods assume that the distribution of a challenge set is known a
priori, making them less applicable to unseen challenge sets. In this study, we
focus on question-answer pair generation (QAG) to mitigate this problem. While
most existing QAG methods aim to improve the quality of synthetic examples, we
conjecture that diversity-promoting QAG can mitigate the sparsity of training
sets and lead to better robustness. We present a variational QAG model that
generates multiple diverse QA pairs from a paragraph. Our experiments show that
our method can improve the accuracy of 12 challenge sets, as well as the
in-distribution accuracy. Our code and data are available at
https://github.com/KazutoshiShinoda/VQAG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Empirical Objective Functions for MCMC Proposal Optimization. (arXiv:2106.02104v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cannella_C/0/1/0/all/0/1">Chris Cannella</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1">Vahid Tarokh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02104">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce and demonstrate a semi-empirical procedure for determining
approximate objective functions suitable for optimizing arbitrarily
parameterized proposal distributions in MCMC methods. Our proposed Ab Initio
objective functions consist of the weighted combination of functions following
constraints on their global optima and of coordinate invariance that we argue
should be upheld by general measures of MCMC efficiency for use in proposal
optimization. The coefficients of Ab Initio objective functions are determined
so as to recover the optimal MCMC behavior prescribed by established
theoretical analysis for chosen reference problems. Our experimental results
demonstrate that Ab Initio objective functions maintain favorable performance
and preferable optimization behavior compared to existing objective functions
for MCMC optimization when optimizing highly expressive proposal distributions.
We argue that Ab Initio objective functions are sufficiently robust to enable
the confident optimization of MCMC proposal distributions parameterized by deep
generative networks that extend beyond the traditional limitations of
individual MCMC schemes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Visual Question Rewriting for Increasing Response Rate. (arXiv:2106.02257v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jiayi Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xilian Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02257">
                                    <div class="article-summary-box-inner">
                                        <span>When a human asks questions online, or when a conversational virtual agent
asks human questions, questions triggering emotions or with details might more
likely to get responses or answers. we explore how to automatically rewrite
natural language questions to improve the response rate from people. In
particular, a new task of Visual Question Rewriting(VQR) task is introduced to
explore how visual information can be used to improve the new questions. A data
set containing around 4K bland questions, attractive questions and images
triples is collected. We developed some baseline sequence to sequence models
and more advanced transformer based models, which take a bland question and a
related image as input and output a rewritten question that is expected to be
more attractive. Offline experiments and mechanical Turk based evaluations show
that it is possible to rewrite bland questions in a more detailed and
attractive way to increase the response rate, and images can be helpful.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Principled change point detection via representation learning. (arXiv:2106.02602v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Romanenkova_E/0/1/0/all/0/1">Evgenia Romanenkova</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1">Alexey Zaytsev</a>, <a href="http://arxiv.org/find/cs/1/au:+Zainulin_R/0/1/0/all/0/1">Ramil Zainulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Morozov_M/0/1/0/all/0/1">Matvey Morozov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02602">
                                    <div class="article-summary-box-inner">
                                        <span>Change points are abrupt alterations in the distribution of sequential data.
A change-point detection (CPD) model aims at quick detection of such changes.
Classic approaches perform poorly for semi-structured sequential data because
of the absence of adequate data representation learning. To deal with it, we
introduce a principled differentiable loss function that considers the
specificity of the CPD task. The theoretical results suggest that this function
approximates well classic rigorous solutions. For such loss function, we
propose an end-to-end method for the training of deep representation learning
CPD models. Our experiments provide evidence that the proposed approach
improves baseline results of change point detection for various data types,
including real-world videos and image sequences, and improve representations
for them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning transition times in event sequences: the Event-Based Hidden Markov Model of disease progression. (arXiv:2011.01023v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wijeratne_P/0/1/0/all/0/1">Peter A. Wijeratne</a>, <a href="http://arxiv.org/find/cs/1/au:+Alexander_D/0/1/0/all/0/1">Daniel C. Alexander</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.01023">
                                    <div class="article-summary-box-inner">
                                        <span>Progressive diseases worsen over time and are characterised by monotonic
change in features that track disease progression. Here we connect ideas from
two formerly separate methodologies -- event-based and hidden Markov modelling
-- to derive a new generative model of disease progression. Our model can
uniquely infer the most likely group-level sequence and timing of events
(natural history) from limited datasets. Moreover, it can infer and predict
individual-level trajectories (prognosis) even when data are missing, giving it
high clinical utility. Here we derive the model and provide an inference scheme
based on the expectation maximisation algorithm. We use clinical, imaging and
biofluid data from the Alzheimer&#x27;s Disease Neuroimaging Initiative to
demonstrate the validity and utility of our model. First, we train our model to
uncover a new group-level sequence of feature changes in Alzheimer&#x27;s disease
over a period of ${\sim}17.3$ years. Next, we demonstrate that our model
provides improved utility over a continuous time hidden Markov model by area
under the receiver operator characteristic curve ${\sim}0.23$. Finally, we
demonstrate that our model maintains predictive accuracy with up to $50\%$
missing data. These results support the clinical validity of our model and its
broader utility in resource-limited medical applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topological Graph Neural Networks. (arXiv:2102.07835v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Horn_M/0/1/0/all/0/1">Max Horn</a>, <a href="http://arxiv.org/find/cs/1/au:+Brouwer_E/0/1/0/all/0/1">Edward De Brouwer</a>, <a href="http://arxiv.org/find/cs/1/au:+Moor_M/0/1/0/all/0/1">Michael Moor</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreau_Y/0/1/0/all/0/1">Yves Moreau</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1">Bastian Rieck</a>, <a href="http://arxiv.org/find/cs/1/au:+Borgwardt_K/0/1/0/all/0/1">Karsten Borgwardt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07835">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) are a powerful architecture for tackling graph
learning tasks, yet have been shown to be oblivious to eminent substructures,
such as cycles. We present TOGL, a novel layer that incorporates global
topological information of a graph using persistent homology. TOGL can be
easily integrated into any type of GNN and is strictly more expressive in terms
of the Weisfeiler--Lehman test of isomorphism. Augmenting GNNs with our layer
leads to beneficial predictive performance for graph and node classification
tasks, both on synthetic data sets, which can be classified by humans using
their topology but not by ordinary GNNs, and on real-world data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Homological Time Series Analysis of Sensor Signals from Power Plants. (arXiv:2106.02493v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Melodia_L/0/1/0/all/0/1">Luciano Melodia</a>, <a href="http://arxiv.org/find/cs/1/au:+Lenz_R/0/1/0/all/0/1">Richard Lenz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02493">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we use topological data analysis techniques to construct a
suitable neural network classifier for the task of learning sensor signals of
entire power plants according to their reference designation system. We use
representations of persistence diagrams to derive necessary preprocessing steps
and visualize the large amounts of data. We derive architectures with deep
one-dimensional convolutional layers combined with stacked long short-term
memories as residual networks suitable for processing the persistence features.
We combine three separate sub-networks, obtaining as input the time series
itself and a representation of the persistent homology for the zeroth and first
dimension. We give a mathematical derivation for most of the used
hyper-parameters. For validation, numerical experiments were performed with
sensor data from four power plants of the same construction type.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Distributional Sliced Embedding Discrepancy for Incomparable Distributions. (arXiv:2106.02542v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alaya_M/0/1/0/all/0/1">Mokhtar Z. Alaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Gasso_G/0/1/0/all/0/1">Gilles Gasso</a>, <a href="http://arxiv.org/find/cs/1/au:+Berar_M/0/1/0/all/0/1">Maxime Berar</a>, <a href="http://arxiv.org/find/cs/1/au:+Rakotomamonjy_A/0/1/0/all/0/1">Alain Rakotomamonjy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02542">
                                    <div class="article-summary-box-inner">
                                        <span>Gromov-Wasserstein (GW) distance is a key tool for manifold learning and
cross-domain learning, allowing the comparison of distributions that do not
live in the same metric space. Because of its high computational complexity,
several approximate GW distances have been proposed based on entropy
regularization or on slicing, and one-dimensional GW computation. In this
paper, we propose a novel approach for comparing two incomparable
distributions, that hinges on the idea of distributional slicing, embeddings,
and on computing the closed-form Wasserstein distance between the sliced
distributions. We provide a theoretical analysis of this new divergence, called
distributional sliced embedding (DSE) discrepancy, and we show that it
preserves several interesting properties of GW distance including
rotation-invariance. We show that the embeddings involved in DSE can be
efficiently learned. Finally, we provide a large set of experiments
illustrating the behavior of DSE as a divergence in the context of generative
modeling and in query framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning Guarantees for Online Receding Horizon Learning Control. (arXiv:2010.11327v12 [eess.SY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Muthirayan_D/0/1/0/all/0/1">Deepan Muthirayan</a>, <a href="http://arxiv.org/find/eess/1/au:+Khargonekar_P/0/1/0/all/0/1">Pramod P. Khargonekar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11327">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we provide provable regret guarantees for an online
meta-learning receding horizon control algorithm in an iterative control
setting. We consider the setting where, in each iteration the system to be
controlled is a linear deterministic system that is different and unknown, the
cost for the controller in an iteration is a general additive cost function and
there are affine control input constraints. By analysing conditions under which
sub-linear regret is achievable, we prove that the online receding horizon
controller achieves a regret for the controller cost and constraint violation
that are $\tilde{O}(T^{3/4})$ with respect to the best policy that satisfies
the control input control constraints, when the preview of the cost functions
is limited to an interval and the interval size is doubled from one to the
next. We then show that the average of the regret for the controller cost and
constraint violation with respect to the same policy vary as
$\tilde{O}((1+1/\sqrt{N})T^{3/4})$ with the number of iterations $N$, under the
same setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable COVID-19 Chest X-Ray Classification via Orthogonality Constraint. (arXiv:2102.08360v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1">Ella Y. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Som_A/0/1/0/all/0/1">Anirudh Som</a>, <a href="http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1">Ankita Shukla</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1">Hongjun Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Turaga_P/0/1/0/all/0/1">Pavan Turaga</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08360">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have increasingly been used as an auxiliary tool in
healthcare applications, due to their ability to improve performance of several
diagnosis tasks. However, these methods are not widely adopted in clinical
settings due to the practical limitations in the reliability, generalizability,
and interpretability of deep learning based systems. As a result, methods have
been developed that impose additional constraints during network training to
gain more control as well as improve interpretabilty, facilitating their
acceptance in healthcare community. In this work, we investigate the benefit of
using Orthogonal Spheres (OS) constraint for classification of COVID-19 cases
from chest X-ray images. The OS constraint can be written as a simple
orthonormality term which is used in conjunction with the standard
cross-entropy loss during classification network training. Previous studies
have demonstrated significant benefits in applying such constraints to deep
learning models. Our findings corroborate these observations, indicating that
the orthonormality loss function effectively produces improved semantic
localization via GradCAM visualizations, enhanced classification performance,
and reduced model calibration error. Our approach achieves an improvement in
accuracy of 1.6% and 4.8% for two- and three-class classification,
respectively; similar results are found for models with data augmentation
applied. In addition to these findings, our work also presents a new
application of the OS regularizer in healthcare, increasing the post-hoc
interpretability and performance of deep learning models for COVID-19
classification to facilitate adoption of these methods in clinical settings. We
also identify the limitations of our strategy that can be explored for further
research in future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Holistic Approach to Interpretability in Financial Lending: Models, Visualizations, and Summary-Explanations. (arXiv:2106.02605v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1">Chaofan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kangcheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudin_C/0/1/0/all/0/1">Cynthia Rudin</a>, <a href="http://arxiv.org/find/cs/1/au:+Shaposhnik_Y/0/1/0/all/0/1">Yaron Shaposhnik</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sijia Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02605">
                                    <div class="article-summary-box-inner">
                                        <span>Lending decisions are usually made with proprietary models that provide
minimally acceptable explanations to users. In a future world without such
secrecy, what decision support tools would one want to use for justified
lending decisions? This question is timely, since the economy has dramatically
shifted due to a pandemic, and a massive number of new loans will be necessary
in the short term. We propose a framework for such decisions, including a
globally interpretable machine learning model, an interactive visualization of
it, and several types of summaries and explanations for any given decision. The
machine learning model is a two-layer additive risk model, which resembles a
two-layer neural network, but is decomposable into subscales. In this model,
each node in the first (hidden) layer represents a meaningful subscale model,
and all of the nonlinearities are transparent. Our online visualization tool
allows exploration of this model, showing precisely how it came to its
conclusion. We provide three types of explanations that are simpler than, but
consistent with, the global model: case-based reasoning explanations that use
neighboring past cases, a set of features that were the most important for the
model&#x27;s prediction, and summary-explanations that provide a customized sparse
explanation for any particular lending decision made by the model. Our
framework earned the FICO recognition award for the Explainable Machine
Learning Challenge, which was the first public challenge in the domain of
explainable machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Approximation Algorithms for Sparse Principal Component Analysis. (arXiv:2006.12748v2 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_A/0/1/0/all/0/1">Agniva Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Drineas_P/0/1/0/all/0/1">Petros Drineas</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1">David P. Woodruff</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Samson Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.12748">
                                    <div class="article-summary-box-inner">
                                        <span>Principal component analysis (PCA) is a widely used dimension reduction
technique in machine learning and multivariate statistics. To improve the
interpretability of PCA, various approaches to obtain sparse principal
direction loadings have been proposed, which are termed Sparse Principal
Component Analysis (SPCA). In this paper, we present thresholding as a provably
accurate, polynomial time, approximation algorithm for the SPCA problem,
without imposing any restrictive assumptions on the input covariance matrix.
Our first thresholding algorithm using the Singular Value Decomposition is
conceptually simple; is faster than current state-of-the-art; and performs well
in practice. On the negative side, our (novel) theoretical bounds do not
accurately predict the strong practical performance of this approach. The
second algorithm solves a well-known semidefinite programming relaxation and
then uses a novel, two step, deterministic thresholding scheme to compute a
sparse principal vector. It works very well in practice and, remarkably, this
solid practical performance is accurately predicted by our theoretical bounds,
which bridge the theory-practice gap better than current state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bonsai-Net: One-Shot Neural Architecture Search via Differentiable Pruners. (arXiv:2006.09264v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Geada_R/0/1/0/all/0/1">Rob Geada</a>, <a href="http://arxiv.org/find/cs/1/au:+Prangle_D/0/1/0/all/0/1">Dennis Prangle</a>, <a href="http://arxiv.org/find/cs/1/au:+McGough_A/0/1/0/all/0/1">Andrew Stephen McGough</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.09264">
                                    <div class="article-summary-box-inner">
                                        <span>One-shot Neural Architecture Search (NAS) aims to minimize the computational
expense of discovering state-of-the-art models. However, in the past year
attention has been drawn to the comparable performance of naive random search
across the same search spaces used by leading NAS algorithms. To address this,
we explore the effects of drastically relaxing the NAS search space, and we
present Bonsai-Net, an efficient one-shot NAS method to explore our relaxed
search space. Bonsai-Net is built around a modified differential pruner and can
consistently discover state-of-the-art architectures that are significantly
better than random search with fewer parameters than other state-of-the-art
methods. Additionally, Bonsai-Net performs simultaneous model search and
training, dramatically reducing the total time it takes to generate
fully-trained models from scratch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Manifold-Aware Deep Clustering: Maximizing Angles between Embedding Vectors Based on Regular Simplex. (arXiv:2106.02331v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Tanaka_K/0/1/0/all/0/1">Keitaro Tanaka</a>, <a href="http://arxiv.org/find/eess/1/au:+Sawata_R/0/1/0/all/0/1">Ryosuke Sawata</a>, <a href="http://arxiv.org/find/eess/1/au:+Takahashi_S/0/1/0/all/0/1">Shusuke Takahashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02331">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new deep clustering (DC) method called manifold-aware
DC (M-DC) that can enhance hyperspace utilization more effectively than the
original DC. The original DC has a limitation in that a pair of two speakers
has to be embedded having an orthogonal relationship due to its use of the
one-hot vector-based loss function, while our method derives a unique loss
function aimed at maximizing the target angle in the hyperspace based on the
nature of a regular simplex. Our proposed loss imposes a higher penalty than
the original DC when the speaker is assigned incorrectly. The change from DC to
M-DC can be easily achieved by rewriting just one term in the loss function of
DC, without any other modifications to the network architecture or model
parameters. As such, our method has high practicability because it does not
affect the original inference part. The experimental results show that the
proposed method improves the performances of the original DC and its expansion
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multitask Online Mirror Descent. (arXiv:2106.02393v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cesa_Bianchi_N/0/1/0/all/0/1">Nicol&#xf2; Cesa-Bianchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Laforgue_P/0/1/0/all/0/1">Pierre Laforgue</a>, <a href="http://arxiv.org/find/cs/1/au:+Paudice_A/0/1/0/all/0/1">Andrea Paudice</a>, <a href="http://arxiv.org/find/cs/1/au:+Pontil_M/0/1/0/all/0/1">Massimiliano Pontil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02393">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce and analyze MT-OMD, a multitask generalization of Online Mirror
Descent (OMD) which operates by sharing updates between tasks. We prove that
the regret of MT-OMD is of order $\sqrt{1 + \sigma^2(N-1)}\sqrt{T}$, where
$\sigma^2$ is the task variance according to the geometry induced by the
regularizer, $N$ is the number of tasks, and $T$ is the time horizon. Whenever
tasks are similar, that is, $\sigma^2 \le 1$, this improves upon the
$\sqrt{NT}$ bound obtained by running independent OMDs on each task. Our
multitask extensions of Online Gradient Descent and Exponentiated Gradient, two
important instances of OMD, are shown to enjoy closed-form updates, making them
easy to use in practice. Finally, we provide numerical experiments on four
real-world datasets which support our theoretical findings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discovery of Causal Additive Models in the Presence of Unobserved Variables. (arXiv:2106.02234v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maeda_T/0/1/0/all/0/1">Takashi Nicholas Maeda</a>, <a href="http://arxiv.org/find/cs/1/au:+Shimizu_S/0/1/0/all/0/1">Shohei Shimizu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02234">
                                    <div class="article-summary-box-inner">
                                        <span>Causal discovery from data affected by unobserved variables is an important
but difficult problem to solve. The effects that unobserved variables have on
the relationships between observed variables are more complex in nonlinear
cases than in linear cases. In this study, we focus on causal additive models
in the presence of unobserved variables. Causal additive models exhibit
structural equations that are additive in the variables and error terms. We
take into account the presence of not only unobserved common causes but also
unobserved intermediate variables. Our theoretical results show that, when the
causal relationships are nonlinear and there are unobserved variables, it is
not possible to identify all the causal relationships between observed
variables through regression and independence tests. However, our theoretical
results also show that it is possible to avoid incorrect inferences. We propose
a method to identify all the causal relationships that are theoretically
possible to identify without being biased by unobserved variables. The
empirical results using artificial data and simulated functional magnetic
resonance imaging (fMRI) data show that our method effectively infers causal
structures in the presence of unobserved variables.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Top-$k$ Regularization for Supervised Feature Selection. (arXiv:2106.02197v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xinxing Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1">Qiang Cheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02197">
                                    <div class="article-summary-box-inner">
                                        <span>Feature selection identifies subsets of informative features and reduces
dimensions in the original feature space, helping provide insights into data
generation or a variety of domain problems. Existing methods mainly depend on
feature scoring functions or sparse regularizations; nonetheless, they have
limited ability to reconcile the representativeness and inter-correlations of
features. In this paper, we introduce a novel, simple yet effective
regularization approach, named top-$k$ regularization, to supervised feature
selection in regression and classification tasks. Structurally, the top-$k$
regularization induces a sub-architecture on the architecture of a learning
model to boost its ability to select the most informative features and model
complex nonlinear relationships simultaneously. Theoretically, we derive and
mathematically prove a uniform approximation error bound for using this
approach to approximate high-dimensional sparse functions. Extensive
experiments on a wide variety of benchmarking datasets show that the top-$k$
regularization is effective and stable for supervised feature selection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably Strict Generalisation Benefit for Invariance in Kernel Methods. (arXiv:2106.02346v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Elesedy_B/0/1/0/all/0/1">Bryn Elesedy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02346">
                                    <div class="article-summary-box-inner">
                                        <span>It is a commonly held belief that enforcing invariance improves
generalisation. Although this approach enjoys widespread popularity, it is only
very recently that a rigorous theoretical demonstration of this benefit has
been established. In this work we build on the function space perspective of
Elesedy and Zaidi arXiv:2102.10333 to derive a strictly non-zero generalisation
benefit of incorporating invariance in kernel ridge regression when the target
is invariant to the action of a compact group. We study invariance enforced by
feature averaging and find that generalisation is governed by a notion of
effective dimension that arises from the interplay between the kernel and the
group. In building towards this result, we find that the action of the group
induces an orthogonal decomposition of both the reproducing kernel Hilbert
space and its kernel, which may be of interest in its own right.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimal Rates of (Locally) Differentially Private Heavy-tailed Multi-Armed Bandits. (arXiv:2106.02575v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1">Youming Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yulian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02575">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we study the problem of stochastic multi-armed bandits (MAB) in
the (local) differential privacy (DP/LDP) model. Unlike the previous results
which need to assume bounded reward distributions, here we mainly focus on the
case the reward distribution of each arm only has $(1+v)$-th moment with some
$v\in (0, 1]$. In the first part, we study the problem in the central
$\epsilon$-DP model. We first provide a near-optimal result by developing a
private and robust Upper Confidence Bound (UCB) algorithm. Then, we improve the
result via a private and robust version of the Successive Elimination (SE)
algorithm. Finally, we show that the instance-dependent regret bound of our
improved algorithm is optimal by showing its lower bound. In the second part of
the paper, we study the problem in the $\epsilon$-LDP model. We propose an
algorithm which could be seen as locally private and robust version of the SE
algorithm, and show it could achieve (near) optimal rates for both
instance-dependent and instance-independent regrets. All of the above results
can also reveal the differences between the problem of private MAB with bounded
rewards and heavy-tailed rewards. To achieve these (near) optimal rates, we
develop several new hard instances and private robust estimators as byproducts,
which might could be used to other related problems. Finally, experimental
results also support our theoretical analysis and show the effectiveness of our
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regressive Domain Adaptation for Unsupervised Keypoint Detection. (arXiv:2103.06175v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Junguang Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1">Yifei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Ximei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yufeng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianmin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1">Mingsheng Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.06175">
                                    <div class="article-summary-box-inner">
                                        <span>Domain adaptation (DA) aims at transferring knowledge from a labeled source
domain to an unlabeled target domain. Though many DA theories and algorithms
have been proposed, most of them are tailored into classification settings and
may fail in regression tasks, especially in the practical keypoint detection
task. To tackle this difficult but significant task, we present a method of
regressive domain adaptation (RegDA) for unsupervised keypoint detection.
Inspired by the latest theoretical work, we first utilize an adversarial
regressor to maximize the disparity on the target domain and train a feature
generator to minimize this disparity. However, due to the high dimension of the
output space, this regressor fails to detect samples that deviate from the
support of the source. To overcome this problem, we propose two important
ideas. First, based on our observation that the probability density of the
output space is sparse, we introduce a spatial probability distribution to
describe this sparsity and then use it to guide the learning of the adversarial
regressor. Second, to alleviate the optimization difficulty in the
high-dimensional space, we innovatively convert the minimax game in the
adversarial training to the minimization of two opposite goals. Extensive
experiments show that our method brings large improvement by 8% to 11% in terms
of PCK on different datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Wide Network Learning with Differential Privacy. (arXiv:2103.01294v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huanyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mironov_I/0/1/0/all/0/1">Ilya Mironov</a>, <a href="http://arxiv.org/find/cs/1/au:+Hejazinia_M/0/1/0/all/0/1">Meisam Hejazinia</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01294">
                                    <div class="article-summary-box-inner">
                                        <span>Despite intense interest and considerable effort, the current generation of
neural networks suffers a significant loss of accuracy under most practically
relevant privacy training regimes. One particularly challenging class of neural
networks are the wide ones, such as those deployed for NLP typeahead prediction
or recommender systems. Observing that these models share something in
common--an embedding layer that reduces the dimensionality of the input--we
focus on developing a general approach towards training these models that takes
advantage of the sparsity of the gradients. More abstractly, we address the
problem of differentially private empirical risk minimization (ERM) for models
that admit sparse gradients. We demonstrate that for non-convex ERM problems,
the loss is logarithmically dependent on the number of parameters, in contrast
with polynomial dependence for the general case. Following the same intuition,
we propose a novel algorithm for privately training neural networks. Finally,
we provide an empirical study of a DP wide neural network on a real-world
dataset, which has been rarely explored in the previous work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cybersecurity Threats in Connected and Automated Vehicles based Federated Learning Systems. (arXiv:2102.13256v3 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mallah_R/0/1/0/all/0/1">Ranwa Al Mallah</a>, <a href="http://arxiv.org/find/cs/1/au:+Badu_Marfo_G/0/1/0/all/0/1">Godwin Badu-Marfo</a>, <a href="http://arxiv.org/find/cs/1/au:+Farooq_B/0/1/0/all/0/1">Bilal Farooq</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13256">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning (FL) is a machine learning technique that aims at training
an algorithm across decentralized entities holding their local data private.
Wireless mobile networks allow users to communicate with other fixed or mobile
users. The road traffic network represents an infrastructure-based
configuration of a wireless mobile network where the Connected and Automated
Vehicles (CAV) represent the communicating entities. Applying FL in a wireless
mobile network setting gives rise to a new threat in the mobile environment
that is very different from the traditional fixed networks. The threat is due
to the intrinsic characteristics of the wireless medium and is caused by the
characteristics of the vehicular networks such as high node-mobility and
rapidly changing topology. Most cyber defense techniques depend on highly
reliable and connected networks. This paper explores falsified information
attacks, which target the FL process that is ongoing at the RSU. We identified
a number of attack strategies conducted by the malicious CAVs to disrupt the
training of the global model in vehicular networks. We show that the attacks
were able to increase the convergence time and decrease the accuracy the model.
We demonstrate that our attacks bypass FL defense strategies in their primary
form and highlight the need for novel poisoning resilience defense mechanisms
in the wireless mobile setting of the future road networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedCCEA : A Practical Approach of Client Contribution Evaluation for Federated Learning. (arXiv:2106.02310v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shyn_S/0/1/0/all/0/1">Sung Kuk Shyn</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Donghee Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1">Kwangsu Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02310">
                                    <div class="article-summary-box-inner">
                                        <span>Client contribution evaluation, also known as data valuation, is a crucial
approach in federated learning(FL) for client selection and incentive
allocation. However, due to restrictions of accessibility of raw data, only
limited information such as local weights and local data size of each client is
open for quantifying the client contribution. Using data size from available
information, we introduce an empirical evaluation method called Federated
Client Contribution Evaluation through Accuracy Approximation(FedCCEA). This
method builds the Accuracy Approximation Model(AAM), which estimates a
simulated test accuracy using inputs of sampled data size and extracts the
clients&#x27; data quality and data size to measure client contribution. FedCCEA
strengthens some advantages: (1) enablement of data size selection to the
clients, (2) feasible evaluation time regardless of the number of clients, and
(3) precise estimation in non-IID settings. We demonstrate the superiority of
FedCCEA compared to previous methods through several experiments: client
contribution distribution, client removal, and robustness test to partial
participation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Network Surrogate Models for Absorptivity and Emissivity Spectra of Multiple Elements. (arXiv:2106.02528v1 [physics.plasm-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Wal_M/0/1/0/all/0/1">Michael D. Vander Wal</a> (1), <a href="http://arxiv.org/find/physics/1/au:+McClarren_R/0/1/0/all/0/1">Ryan G. McClarren</a> (1), <a href="http://arxiv.org/find/physics/1/au:+Humbird_K/0/1/0/all/0/1">Kelli D. Humbird</a> (2) ((1) University of Notre Dame, (2) Lawrence Livermore National Laboratory)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02528">
                                    <div class="article-summary-box-inner">
                                        <span>Simulations of high energy density physics are expensive in terms of
computational resources. In particular, the computation of opacities of
plasmas, which are needed to accurately compute radiation transport in the
non-local thermal equilibrium (NLTE) regime, are expensive to the point of
easily requiring multiple times the sum-total compute time of all other
components of the simulation. As such, there is great interest in finding ways
to accelerate NLTE computations. Previous work has demonstrated that a
combination of fully-connected autoencoders and a deep jointly-informed neural
network (DJINN) can successfully replace the standard NLTE calculations for the
opacity of krypton. This work expands this idea to multiple elements in
demonstrating that individual surrogate models can be also be generated for
other elements with the focus being on creating autoencoders that can
accurately encode and decode the absorptivity and emissivity spectra.
Furthermore, this work shows that multiple elements across a large range of
atomic numbers can be combined into a single autoencoder when using a
convolutional autoencoder while maintaining accuracy that is comparable to
individual fully-connected autoencoders. Lastly, it is demonstrated that DJINN
can effectively learn the latent space of a convolutional autoencoder that can
encode multiple elements allowing the combination to effectively function as a
surrogate model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Analysis of the robustness of NMF algorithms. (arXiv:2106.02213v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diaz_A/0/1/0/all/0/1">Alex D&#xed;az</a>, <a href="http://arxiv.org/find/cs/1/au:+Steele_D/0/1/0/all/0/1">Damian Steele</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02213">
                                    <div class="article-summary-box-inner">
                                        <span>We examine three non-negative matrix factorization techniques; L2-norm,
L1-norm, and L2,1-norm. Our aim is to establish the performance of these
different approaches, and their robustness in real-world applications such as
feature selection while managing computational complexity, sensitivity to noise
and more. We thoroughly examine each approach from a theoretical perspective,
and examine the performance of each using a series of experiments drawing on
both the ORL and YaleB datasets. We examine the Relative Reconstruction Errors
(RRE), Average Accuracy and Normalized Mutual Information (NMI) as criteria
under a range of simulated noise scenarios.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation of Local Model-Agnostic Explanations Using Ground Truth. (arXiv:2106.02488v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rahnama_A/0/1/0/all/0/1">Amir Hossein Akhavan Rahnama</a>, <a href="http://arxiv.org/find/cs/1/au:+Butepage_J/0/1/0/all/0/1">Judith Butepage</a>, <a href="http://arxiv.org/find/cs/1/au:+Geurts_P/0/1/0/all/0/1">Pierre Geurts</a>, <a href="http://arxiv.org/find/cs/1/au:+Bostrom_H/0/1/0/all/0/1">Henrik Bostrom</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02488">
                                    <div class="article-summary-box-inner">
                                        <span>Explanation techniques are commonly evaluated using human-grounded methods,
limiting the possibilities for large-scale evaluations and rapid progress in
the development of new techniques. We propose a functionally-grounded
evaluation procedure for local model-agnostic explanation techniques. In our
approach, we generate ground truth for explanations when the black-box model is
Logistic Regression and Gaussian Naive Bayes and compare how similar each
explanation is to the extracted ground truth. In our empirical study,
explanations of Local Interpretable Model-agnostic Explanations (LIME), SHapley
Additive exPlanations (SHAP), and Local Permutation Importance (LPI) are
compared in terms of how similar they are to the extracted ground truth. In the
case of Logistic Regression, we find that the performance of the explanation
techniques is highly dependent on the normalization of the data. In contrast,
Local Permutation Importance outperforms the other techniques on Naive Bayes,
irrespective of normalization. We hope that this work lays the foundation for
further research into functionally-grounded evaluation methods for explanation
techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Deep Local and Global Scene-Graph Matching for Image-Text Retrieval. (arXiv:2106.02400v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1">Manh-Duy Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_B/0/1/0/all/0/1">Binh T. Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurrin_C/0/1/0/all/0/1">Cathal Gurrin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02400">
                                    <div class="article-summary-box-inner">
                                        <span>Conventional approaches to image-text retrieval mainly focus on indexing
visual objects appearing in pictures but ignore the interactions between these
objects. Such objects occurrences and interactions are equivalently useful and
important in this field as they are usually mentioned in the text. Scene graph
presentation is a suitable method for the image-text matching challenge and
obtained good results due to its ability to capture the inter-relationship
information. Both images and text are represented in scene graph levels and
formulate the retrieval challenge as a scene graph matching challenge. In this
paper, we introduce the Local and Global Scene Graph Matching (LGSGM) model
that enhances the state-of-the-art method by integrating an extra graph
convolution network to capture the general information of a graph.
Specifically, for a pair of scene graphs of an image and its caption, two
separate models are used to learn the features of each graph&#x27;s nodes and edges.
Then a Siamese-structure graph convolution model is employed to embed graphs
into vector forms. We finally combine the graph-level and the vector-level to
calculate the similarity of this image-text pair. The empirical experiments
show that our enhancement with the combination of levels can improve the
performance of the baseline method by increasing the recall by more than 10% on
the Flickr30k dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Event Classification with Multi-step Machine Learning. (arXiv:2106.02301v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saito_M/0/1/0/all/0/1">Masahiko Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Kishimoto_T/0/1/0/all/0/1">Tomoe Kishimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaneta_Y/0/1/0/all/0/1">Yuya Kaneta</a>, <a href="http://arxiv.org/find/cs/1/au:+Itoh_T/0/1/0/all/0/1">Taichi Itoh</a>, <a href="http://arxiv.org/find/cs/1/au:+Umeda_Y/0/1/0/all/0/1">Yoshiaki Umeda</a>, <a href="http://arxiv.org/find/cs/1/au:+Tanaka_J/0/1/0/all/0/1">Junichi Tanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Iiyama_Y/0/1/0/all/0/1">Yutaro Iiyama</a>, <a href="http://arxiv.org/find/cs/1/au:+Sawada_R/0/1/0/all/0/1">Ryu Sawada</a>, <a href="http://arxiv.org/find/cs/1/au:+Terashi_K/0/1/0/all/0/1">Koji Terashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02301">
                                    <div class="article-summary-box-inner">
                                        <span>The usefulness and value of Multi-step Machine Learning (ML), where a task is
organized into connected sub-tasks with known intermediate inference goals, as
opposed to a single large model learned end-to-end without intermediate
sub-tasks, is presented. Pre-optimized ML models are connected and better
performance is obtained by re-optimizing the connected one. The selection of an
ML model from several small ML model candidates for each sub-task has been
performed by using the idea based on Neural Architecture Search (NAS). In this
paper, Differentiable Architecture Search (DARTS) and Single Path One-Shot NAS
(SPOS-NAS) are tested, where the construction of loss functions is improved to
keep all ML models smoothly learning. Using DARTS and SPOS-NAS as an
optimization and selection as well as the connections for multi-step machine
learning systems, we find that (1) such a system can quickly and successfully
select highly performant model combinations, and (2) the selected models are
consistent with baseline algorithms, such as grid search, and their outputs are
well controlled.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Equal Gender Representation in the Annotations of Toxic Language Detection. (arXiv:2106.02183v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Excell_E/0/1/0/all/0/1">Elizabeth Excell</a>, <a href="http://arxiv.org/find/cs/1/au:+Moubayed_N/0/1/0/all/0/1">Noura Al Moubayed</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02183">
                                    <div class="article-summary-box-inner">
                                        <span>Classifiers tend to propagate biases present in the data on which they are
trained. Hence, it is important to understand how the demographic identities of
the annotators of comments affect the fairness of the resulting model. In this
paper, we focus on the differences in the ways men and women annotate comments
for toxicity, investigating how these differences result in models that amplify
the opinions of male annotators. We find that the BERT model as-sociates toxic
comments containing offensive words with male annotators, causing the model to
predict 67.7% of toxic comments as having been annotated by men. We show that
this disparity between gender predictions can be mitigated by removing
offensive words and highly toxic comments from the training data. We then apply
the learned associations between gender and language to toxic language
classifiers, finding that models trained exclusively on female-annotated data
perform 1.8% better than those trained solely on male-annotated data and that
training models on data after removing all offensive words reduces bias in the
model by 55.5% while increasing the sensitivity by 0.4%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Collapse Under MSE Loss: Proximity to and Dynamics on the Central Path. (arXiv:2106.02073v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">X.Y. Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Papyan_V/0/1/0/all/0/1">Vardan Papyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Donoho_D/0/1/0/all/0/1">David L. Donoho</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02073">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work [Papyan, Han, and Donoho, 2020] discovered a phenomenon called
Neural Collapse (NC) that occurs pervasively in today&#x27;s deep net training
paradigm of driving cross-entropy loss towards zero. In this phenomenon, the
last-layer features collapse to their class-means, both the classifiers and
class-means collapse to the same Simplex Equiangular Tight Frame (ETF), and the
behavior of the last-layer classifier converges to that of the
nearest-class-mean decision rule. Since then, follow-ups-such as Mixon et al.
[2020] and Poggio and Liao [2020a,b]-formally analyzed this inductive bias by
replacing the hard-to-study cross-entropy by the more tractable mean squared
error (MSE) loss. But, these works stopped short of demonstrating the empirical
reality of MSE-NC on benchmark datasets and canonical networks-as had been done
in Papyan, Han, and Donoho [2020] for the cross-entropy loss. In this work, we
establish the empirical reality of MSE-NC by reporting experimental
observations for three prototypical networks and five canonical datasets with
code for reproducing NC. Following this, we develop three main contributions
inspired by MSE-NC. Firstly, we show a new theoretical decomposition of the MSE
loss into (A) a term assuming the last-layer classifier is exactly the
least-squares or Webb and Lowe [1990] classifier and (B) a term capturing the
deviation from this least-squares classifier. Secondly, we exhibit experiments
on canonical datasets and networks demonstrating that, during training,
term-(B) is negligible. This motivates a new theoretical construct: the central
path, where the linear classifier stays MSE-optimal-for the given feature
activations-throughout the dynamics. Finally, through our study of continually
renormalized gradient flow along the central path, we produce closed-form
dynamics that predict full Neural Collapse in an unconstrained features model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can convolutional ResNets approximately preserve input distances? A frequency analysis perspective. (arXiv:2106.02469v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1">Lewis Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Amersfoort_J/0/1/0/all/0/1">Joost van Amersfoort</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1">Haiwen Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1">Stephen Roberts</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02469">
                                    <div class="article-summary-box-inner">
                                        <span>ResNets constrained to be bi-Lipschitz, that is, approximately distance
preserving, have been a crucial component of recently proposed techniques for
deterministic uncertainty quantification in neural models. We show that
theoretical justifications for recent regularisation schemes trying to enforce
such a constraint suffer from a crucial flaw -- the theoretical link between
the regularisation scheme used and bi-Lipschitzness is only valid under
conditions which do not hold in practice, rendering existing theory of limited
use, despite the strong empirical performance of these models. We provide a
theoretical explanation for the effectiveness of these regularisation schemes
using a frequency analysis perspective, showing that under mild conditions
these schemes will enforce a lower Lipschitz bound on the low-frequency
projection of images. We then provide empirical evidence supporting our
theoretical claims, and perform further experiments which demonstrate that our
broader conclusions appear to hold when some of the mathematical assumptions of
our proof are relaxed, corresponding to the setup used in prior work. In
addition, we present a simple constructive algorithm to search for counter
examples to the distance preservation condition, and discuss possible
implications of our theory for future model design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intelligent Transportation Systems to Mitigate Road Traffic Congestion. (arXiv:2106.02315v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Hamadeh_N/0/1/0/all/0/1">Nizar Hamadeh</a>, <a href="http://arxiv.org/find/eess/1/au:+Karouni_A/0/1/0/all/0/1">Ali Karouni</a>, <a href="http://arxiv.org/find/eess/1/au:+Farhat_Z/0/1/0/all/0/1">Zeinab Farhat</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghor_H/0/1/0/all/0/1">Hussein El Ghor</a>, <a href="http://arxiv.org/find/eess/1/au:+Ghor_M/0/1/0/all/0/1">Mohamad El Ghor</a>, <a href="http://arxiv.org/find/eess/1/au:+Katea_I/0/1/0/all/0/1">Israa Katea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02315">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent transport systems have efficiently and effectively proved
themselves in settling up the problem of traffic congestion around the world.
The multi-agent based transportation system is one of the most important
intelligent transport systems, which represents an interaction among the
neighbouring vehicles, drivers, roads, infrastructure and vehicles. In this
paper, two traffic management models have been created to mitigate congestion
and to ensure that emergency vehicles arrive as quickly as possible. A
tool-chain SUMO-JADE is employed to create a microscopic simulation symbolizing
the interactions of traffic. The simulation model has showed a significant
reduction of at least 50% in the average time delay and thus a real improvement
in the entire journey time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Guided Visual Exploration of Relations in Data Sets. (arXiv:1905.02515v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Puolamaki_K/0/1/0/all/0/1">Kai Puolam&#xe4;ki</a>, <a href="http://arxiv.org/find/stat/1/au:+Oikarinen_E/0/1/0/all/0/1">Emilia Oikarinen</a>, <a href="http://arxiv.org/find/stat/1/au:+Henelius_A/0/1/0/all/0/1">Andreas Henelius</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.02515">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient explorative data analysis systems must take into account both what
a user knows and wants to know. This paper proposes a principled framework for
interactive visual exploration of relations in data, through views most
informative given the user&#x27;s current knowledge and objectives. The user can
input pre-existing knowledge of relations in the data and also formulate
specific exploration interests, which are then taken into account in the
exploration. The idea is to steer the exploration process towards the interests
of the user, instead of showing uninteresting or already known relations. The
user&#x27;s knowledge is modelled by a distribution over data sets parametrised by
subsets of rows and columns of data, called tile constraints. We provide a
computationally efficient implementation of this concept based on constrained
randomisation. Furthermore, we describe a novel dimensionality reduction method
for finding the views most informative to the user, which at the limit of no
background knowledge and with generic objectives reduces to PCA. We show that
the method is suitable for interactive use and is robust to noise, outperforms
standard projection pursuit visualisation methods, and gives understandable and
useful results in analysis of real-world data. We provide an open-source
implementation of the framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tractable Regularization of Probabilistic Circuits. (arXiv:2106.02264v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Anji Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1">Guy Van den Broeck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02264">
                                    <div class="article-summary-box-inner">
                                        <span>Probabilistic Circuits (PCs) are a promising avenue for probabilistic
modeling. They combine advantages of probabilistic graphical models (PGMs) with
those of neural networks (NNs). Crucially, however, they are tractable
probabilistic models, supporting efficient and exact computation of many
probabilistic inference queries, such as marginals and MAP. Further, since PCs
are structured computation graphs, they can take advantage of
deep-learning-style parameter updates, which greatly improves their
scalability. However, this innovation also makes PCs prone to overfitting,
which has been observed in many standard benchmarks. Despite the existence of
abundant regularization techniques for both PGMs and NNs, they are not
effective enough when applied to PCs. Instead, we re-think regularization for
PCs and propose two intuitive techniques, data softening and entropy
regularization, that both take advantage of PCs&#x27; tractability and still have an
efficient implementation as a computation graph. Specifically, data softening
provides a principled way to add uncertainty in datasets in closed form, which
implicitly regularizes PC parameters. To learn parameters from a softened
dataset, PCs only need linear time by virtue of their tractability. In entropy
regularization, the exact entropy of the distribution encoded by a PC can be
regularized directly, which is again infeasible for most other density
estimation models. We show that both methods consistently improve the
generalization performance of a wide variety of PCs. Moreover, when paired with
a simple PC structure, we achieved state-of-the-art results on 10 out of 20
standard discrete density estimation benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Deep Domain Adaptation for LiDAR Perception. (arXiv:2106.02377v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Triess_L/0/1/0/all/0/1">Larissa T. Triess</a>, <a href="http://arxiv.org/find/cs/1/au:+Dreissig_M/0/1/0/all/0/1">Mariella Dreissig</a>, <a href="http://arxiv.org/find/cs/1/au:+Rist_C/0/1/0/all/0/1">Christoph B. Rist</a>, <a href="http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1">J. Marius Z&#xf6;llner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02377">
                                    <div class="article-summary-box-inner">
                                        <span>Scalable systems for automated driving have to reliably cope with an
open-world setting. This means, the perception systems are exposed to drastic
domain shifts, like changes in weather conditions, time-dependent aspects, or
geographic regions. Covering all domains with annotated data is impossible
because of the endless variations of domains and the time-consuming and
expensive annotation process. Furthermore, fast development cycles of the
system additionally introduce hardware changes, such as sensor types and
vehicle setups, and the required knowledge transfer from simulation. To enable
scalable automated driving, it is therefore crucial to address these domain
shifts in a robust and efficient manner. Over the last years, a vast amount of
different domain adaptation techniques evolved. There already exists a number
of survey papers for domain adaptation on camera images, however, a survey for
LiDAR perception is absent. Nevertheless, LiDAR is a vital sensor for automated
driving that provides detailed 3D scans of the vehicle&#x27;s surroundings. To
stimulate future research, this paper presents a comprehensive review of recent
progress in domain adaptation methods and formulates interesting research
questions specifically targeted towards LiDAR perception.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularizing Deep Networks with Semantic Data Augmentation. (arXiv:2007.10538v5 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yulin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1">Gao Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1">Shiji Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1">Xuran Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yitong Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Cheng Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.10538">
                                    <div class="article-summary-box-inner">
                                        <span>Data augmentation is widely known as a simple yet surprisingly effective
technique for regularizing deep networks. Conventional data augmentation
schemes, e.g., flipping, translation or rotation, are low-level,
data-independent and class-agnostic operations, leading to limited diversity
for augmented samples. To this end, we propose a novel semantic data
augmentation algorithm to complement traditional approaches. The proposed
method is inspired by the intriguing property that deep networks are effective
in learning linearized features, i.e., certain directions in the deep feature
space correspond to meaningful semantic transformations, e.g., changing the
background or view angle of an object. Based on this observation, translating
training samples along many such directions in the feature space can
effectively augment the dataset for more diversity. To implement this idea, we
first introduce a sampling based method to obtain semantically meaningful
directions efficiently. Then, an upper bound of the expected cross-entropy (CE)
loss on the augmented training set is derived by assuming the number of
augmented samples goes to infinity, yielding a highly efficient algorithm. In
fact, we show that the proposed implicit semantic data augmentation (ISDA)
algorithm amounts to minimizing a novel robust CE loss, which adds minimal
extra computational cost to a normal training procedure. In addition to
supervised learning, ISDA can be applied to semi-supervised learning tasks
under the consistency regularization framework, where ISDA amounts to
minimizing the upper bound of the expected KL-divergence between the augmented
features and the original features. Although being simple, ISDA consistently
improves the generalization performance of popular deep models (e.g., ResNets
and DenseNets) on a variety of datasets, i.e., CIFAR-10, CIFAR-100, SVHN,
ImageNet, and Cityscapes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Privately Learning Mixtures of Axis-Aligned Gaussians. (arXiv:2106.02162v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aden_Ali_I/0/1/0/all/0/1">Ishaq Aden-Ali</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashtiani_H/0/1/0/all/0/1">Hassan Ashtiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Liaw_C/0/1/0/all/0/1">Christopher Liaw</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02162">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of learning mixtures of Gaussians under the
constraint of approximate differential privacy. We prove that
$\widetilde{O}(k^2 d \log^{3/2}(1/\delta) / \alpha^2 \varepsilon)$ samples are
sufficient to learn a mixture of $k$ axis-aligned Gaussians in $\mathbb{R}^d$
to within total variation distance $\alpha$ while satisfying $(\varepsilon,
\delta)$-differential privacy. This is the first result for privately learning
mixtures of unbounded axis-aligned (or even unbounded univariate) Gaussians. If
the covariance matrices of each of the Gaussians is the identity matrix, we
show that $\widetilde{O}(kd/\alpha^2 + kd \log(1/\delta) / \alpha \varepsilon)$
samples are sufficient.

Recently, the &quot;local covering&quot; technique of Bun, Kamath, Steinke, and Wu has
been successfully used for privately learning high-dimensional Gaussians with a
known covariance matrix and extended to privately learning general
high-dimensional Gaussians by Aden-Ali, Ashtiani, and Kamath. Given these
positive results, this approach has been proposed as a promising direction for
privately learning mixtures of Gaussians. Unfortunately, we show that this is
not possible.

We design a new technique for privately learning mixture distributions. A
class of distributions $\mathcal{F}$ is said to be list-decodable if there is
an algorithm that, given &quot;heavily corrupted&quot; samples from $f\in \mathcal{F}$,
outputs a list of distributions, $\widehat{\mathcal{F}}$, such that one of the
distributions in $\widehat{\mathcal{F}}$ approximates $f$. We show that if
$\mathcal{F}$ is privately list-decodable, then we can privately learn mixtures
of distributions in $\mathcal{F}$. Finally, we show axis-aligned Gaussian
distributions are privately list-decodable, thereby proving mixtures of such
distributions are privately learnable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Materials Representation and Transfer Learning for Multi-Property Prediction. (arXiv:2106.02225v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1">Shufeng Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Guevarra_D/0/1/0/all/0/1">Dan Guevarra</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1">Carla P. Gomes</a>, <a href="http://arxiv.org/find/cs/1/au:+Gregoire_J/0/1/0/all/0/1">John M. Gregoire</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02225">
                                    <div class="article-summary-box-inner">
                                        <span>The adoption of machine learning in materials science has rapidly transformed
materials property prediction. Hurdles limiting full capitalization of recent
advancements in machine learning include the limited development of methods to
learn the underlying interactions of multiple elements, as well as the
relationships among multiple properties, to facilitate property prediction in
new composition spaces. To address these issues, we introduce the Hierarchical
Correlation Learning for Multi-property Prediction (H-CLMP) framework that
seamlessly integrates (i) prediction using only a material&#x27;s composition, (ii)
learning and exploitation of correlations among target properties in
multi-target regression, and (iii) leveraging training data from tangential
domains via generative transfer learning. The model is demonstrated for
prediction of spectral optical absorption of complex metal oxides spanning 69
3-cation metal oxide composition spaces. H-CLMP accurately predicts non-linear
composition-property relationships in composition spaces for which no training
data is available, which broadens the purview of machine learning to the
discovery of materials with exceptional properties. This achievement results
from the principled integration of latent embedding learning, property
correlation learning, generative transfer learning, and attention models. The
best performance is obtained using H-CLMP with Transfer learning (H-CLMP(T))
wherein a generative adversarial network is trained on computational density of
states data and deployed in the target domain to augment prediction of optical
absorption from composition. H-CLMP(T) aggregates multiple knowledge sources
with a framework that is well-suited for multi-target regression across the
physical sciences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Temporally coherent video anonymization through GAN inpainting. (arXiv:2106.02328v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balaji_T/0/1/0/all/0/1">Thangapavithraa Balaji</a>, <a href="http://arxiv.org/find/cs/1/au:+Blies_P/0/1/0/all/0/1">Patrick Blies</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_G/0/1/0/all/0/1">Georg G&#xf6;ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitsch_R/0/1/0/all/0/1">Raphael Mitsch</a>, <a href="http://arxiv.org/find/cs/1/au:+Wasserer_M/0/1/0/all/0/1">Marcel Wasserer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schon_T/0/1/0/all/0/1">Torsten Sch&#xf6;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02328">
                                    <div class="article-summary-box-inner">
                                        <span>This work tackles the problem of temporally coherent face anonymization in
natural video streams.We propose JaGAN, a two-stage system starting with
detecting and masking out faces with black image patches in all individual
frames of the video. The second stage leverages a privacy-preserving Video
Generative Adversarial Network designed to inpaint the missing image patches
with artificially generated faces. Our initial experiments reveal that image
based generative models are not capable of inpainting patches showing temporal
coherent appearance across neighboring video frames. To address this issue we
introduce a newly curated video collection, which is made publicly available
for the research community along with this paper. We also introduce the
Identity Invariance Score IdI as a means to quantify temporal coherency between
neighboring frames.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Entity Concept-enhanced Few-shot Relation Extraction. (arXiv:2106.02401v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Shan Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongfei Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1">Guanglin Niu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qinghua Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Pu_S/0/1/0/all/0/1">Shiliang Pu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02401">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot relation extraction (FSRE) is of great importance in long-tail
distribution problem, especially in special domain with low-resource data. Most
existing FSRE algorithms fail to accurately classify the relations merely based
on the information of the sentences together with the recognized entity pairs,
due to limited samples and lack of knowledge. To address this problem, in this
paper, we proposed a novel entity CONCEPT-enhanced FEw-shot Relation Extraction
scheme (ConceptFERE), which introduces the inherent concepts of entities to
provide clues for relation prediction and boost the relations classification
performance. Firstly, a concept-sentence attention module is developed to
select the most appropriate concept from multiple concepts of each entity by
calculating the semantic similarity between sentences and concepts. Secondly, a
self-attention based fusion module is presented to bridge the gap of concept
embedding and sentence embedding from different semantic spaces. Extensive
experiments on the FSRE benchmark dataset FewRel have demonstrated the
effectiveness and the superiority of the proposed ConceptFERE scheme as
compared to the state-of-the-art baselines. Code is available at
https://github.com/LittleGuoKe/ConceptFERE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Counterfactual Graph Learning for Link Prediction. (arXiv:2106.02172v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tong Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1">Gang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Daheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1">Wenhao Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Meng Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02172">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to predict missing links is important for many graph-based
applications. Existing methods were designed to learn the observed association
between two sets of variables: (1) the observed graph structure and (2) the
existence of link between a pair of nodes. However, the causal relationship
between these variables was ignored and we visit the possibility of learning it
by simply asking a counterfactual question: &quot;would the link exist or not if the
observed graph structure became different?&quot; To answer this question by causal
inference, we consider the information of the node pair as context, global
graph structural properties as treatment, and link existence as outcome. In
this work, we propose a novel link prediction method that enhances graph
learning by the counterfactual inference. It creates counterfactual links from
the observed ones, and our method learns representations from both of them.
Experiments on a number of benchmark datasets show that our proposed method
achieves the state-of-the-art performance on link prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Proving Equivalence Between Complex Expressions Using Graph-to-Sequence Neural Models. (arXiv:2106.02452v1 [cs.PL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kommrusch_S/0/1/0/all/0/1">Steve Kommrusch</a>, <a href="http://arxiv.org/find/cs/1/au:+Barollet_T/0/1/0/all/0/1">Th&#xe9;o Barollet</a>, <a href="http://arxiv.org/find/cs/1/au:+Pouchet_L/0/1/0/all/0/1">Louis-No&#xeb;l Pouchet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02452">
                                    <div class="article-summary-box-inner">
                                        <span>We target the problem of provably computing the equivalence between two
complex expression trees. To this end, we formalize the problem of equivalence
between two such programs as finding a set of semantics-preserving rewrite
rules from one into the other, such that after the rewrite the two programs are
structurally identical, and therefore trivially equivalent.We then develop a
graph-to-sequence neural network system for program equivalence, trained to
produce such rewrite sequences from a carefully crafted automatic example
generation algorithm. We extensively evaluate our system on a rich multi-type
linear algebra expression language, using arbitrary combinations of 100+
graph-rewriting axioms of equivalence. Our machine learning system guarantees
correctness for all true negatives, and ensures 0 false positive by design. It
outputs via inference a valid proof of equivalence for 93% of the 10,000
equivalent expression pairs isolated for testing, using up to 50-term
expressions. In all cases, the validity of the sequence produced and therefore
the provable assertion of program equivalence is always computable, in
negligible time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic gradient descent with noise of machine learning type. Part II: Continuous time analysis. (arXiv:2106.02588v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wojtowytsch_S/0/1/0/all/0/1">Stephan Wojtowytsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02588">
                                    <div class="article-summary-box-inner">
                                        <span>The representation of functions by artificial neural networks depends on a
large number of parameters in a non-linear fashion. Suitable parameters of
these are found by minimizing a &#x27;loss functional&#x27;, typically by stochastic
gradient descent (SGD) or an advanced SGD-based algorithm.

In a continuous time model for SGD with noise that follows the &#x27;machine
learning scaling&#x27;, we show that in a certain noise regime, the optimization
algorithm prefers &#x27;flat&#x27; minima of the objective function in a sense which is
different from the flat minimum selection of continuous time SGD with
homogeneous noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Signed Cumulative Distribution Transform for 1-D Signal Analysis and Classification. (arXiv:2106.02146v1 [cs.IT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aldroubi_A/0/1/0/all/0/1">Akram Aldroubi</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1">Rocio Diaz Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Medri_I/0/1/0/all/0/1">Ivan Medri</a>, <a href="http://arxiv.org/find/cs/1/au:+Rohde_G/0/1/0/all/0/1">Gustavo K. Rohde</a>, <a href="http://arxiv.org/find/cs/1/au:+Thareja_S/0/1/0/all/0/1">Sumati Thareja</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02146">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a new mathematical signal transform that is especially
suitable for decoding information related to non-rigid signal displacements. We
provide a measure theoretic framework to extend the existing Cumulative
Distribution Transform [ACHA 45 (2018), no. 3, 616-641] to arbitrary (signed)
signals on $\overline{\mathbb{R}}$. We present both forward (analysis) and
inverse (synthesis) formulas for the transform, and describe several of its
properties including translation, scaling, convexity, linear separability and
others. Finally, we describe a metric in transform space, and demonstrate the
application of the transform in classifying (detecting) signals under random
displacements.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fuzzy Clustering with Similarity Queries. (arXiv:2106.02212v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huleihel_W/0/1/0/all/0/1">Wasim Huleihel</a>, <a href="http://arxiv.org/find/cs/1/au:+Mazumdar_A/0/1/0/all/0/1">Arya Mazumdar</a>, <a href="http://arxiv.org/find/cs/1/au:+Pal_S/0/1/0/all/0/1">Soumyabrata Pal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02212">
                                    <div class="article-summary-box-inner">
                                        <span>The fuzzy or soft $k$-means objective is a popular generalization of the
well-known $k$-means problem, extending the clustering capability of the
$k$-means to datasets that are uncertain, vague, and otherwise hard to cluster.
In this paper, we propose a semi-supervised active clustering framework, where
the learner is allowed to interact with an oracle (domain expert), asking for
the similarity between a certain set of chosen items. We study the query and
computational complexities of clustering in this framework. We prove that
having a few of such similarity queries enables one to get a polynomial-time
approximation algorithm to an otherwise conjecturally NP-hard problem. In
particular, we provide probabilistic algorithms for fuzzy clustering in this
setting that asks $O(\mathsf{poly}(k)\log n)$ similarity queries and run with
polynomial-time-complexity, where $n$ is the number of items. The fuzzy
$k$-means objective is nonconvex, with $k$-means as a special case, and is
equivalent to some other generic nonconvex problem such as non-negative matrix
factorization. The ubiquitous Lloyd-type algorithms (or,
expectation-maximization algorithm) can get stuck at a local minima. Our
results show that by making few similarity queries, the problem becomes easier
to solve. Finally, we test our algorithms over real-world datasets, showing
their effectiveness in real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Intelligent Resource Reservation for Crowdsourced Live Video Streaming Applications in Geo-Distributed Cloud Environment. (arXiv:2106.02420v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baccour_E/0/1/0/all/0/1">Emna Baccour</a>, <a href="http://arxiv.org/find/cs/1/au:+Haouari_F/0/1/0/all/0/1">Fatima Haouari</a>, <a href="http://arxiv.org/find/cs/1/au:+Erbad_A/0/1/0/all/0/1">Aiman Erbad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Amr Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilal_K/0/1/0/all/0/1">Kashif Bilal</a>, <a href="http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1">Mohsen Guizani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamdi_M/0/1/0/all/0/1">Mounir Hamdi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02420">
                                    <div class="article-summary-box-inner">
                                        <span>Crowdsourced live video streaming (livecast) services such as Facebook Live,
YouNow, Douyu and Twitch are gaining more momentum recently. Allocating the
limited resources in a cost-effective manner while maximizing the Quality of
Service (QoS) through real-time delivery and the provision of the appropriate
representations for all viewers is a challenging problem. In our paper, we
introduce a machine-learning based predictive resource allocation framework for
geo-distributed cloud sites, considering the delay and quality constraints to
guarantee the maximum QoS for viewers and the minimum cost for content
providers. First, we present an offline optimization that decides the required
transcoding resources in distributed regions near the viewers with a trade-off
between the QoS and the overall cost. Second, we use machine learning to build
forecasting models that proactively predict the approximate transcoding
resources to be reserved at each cloud site ahead of time. Finally, we develop
a Greedy Nearest and Cheapest algorithm (GNCA) to perform the resource
allocation of real-time broadcasted videos on the rented resources. Extensive
simulations have shown that GNCA outperforms the state-of-the art resource
allocation approaches for crowdsourced live streaming by achieving more than
20% gain in terms of system cost while serving the viewers with relatively
lower latency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Beyond Target Networks: Improving Deep $Q$-learning with Functional Regularization. (arXiv:2106.02613v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Piche_A/0/1/0/all/0/1">Alexandre Pich&#xe9;</a>, <a href="http://arxiv.org/find/stat/1/au:+Marino_J/0/1/0/all/0/1">Joseph Marino</a>, <a href="http://arxiv.org/find/stat/1/au:+Marconi_G/0/1/0/all/0/1">Gian Maria Marconi</a>, <a href="http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1">Christopher Pal</a>, <a href="http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1">Mohammad Emtiyaz Khan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02613">
                                    <div class="article-summary-box-inner">
                                        <span>Target networks are at the core of recent success in Reinforcement Learning.
They stabilize the training by using old parameters to estimate the $Q$-values,
but this also limits the propagation of newly-encountered rewards which could
ultimately slow down the training. In this work, we propose an alternative
training method based on functional regularization which does not have this
deficiency. Unlike target networks, our method uses up-to-date parameters to
estimate the target $Q$-values, thereby speeding up training while maintaining
stability. Surprisingly, in some cases, we can show that target networks are a
special, restricted type of functional regularizers. Using this approach, we
show empirical improvements in sample efficiency and performance across a range
of Atari and simulated robotics environments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spatial Graph Attention and Curiosity-driven Policy for Antiviral Drug Discovery. (arXiv:2106.02190v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yulun Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Choma_N/0/1/0/all/0/1">Nicholas Choma</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Andrew Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Cashman_M/0/1/0/all/0/1">Mikaela Cashman</a>, <a href="http://arxiv.org/find/cs/1/au:+Prates_E/0/1/0/all/0/1">&#xc9;rica T. Prates</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1">Manesh Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Vergara_V/0/1/0/all/0/1">Ver&#xf3;nica G. Melesse Vergara</a>, <a href="http://arxiv.org/find/cs/1/au:+Clyde_A/0/1/0/all/0/1">Austin Clyde</a>, <a href="http://arxiv.org/find/cs/1/au:+Brettin_T/0/1/0/all/0/1">Thomas S. Brettin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jong_W/0/1/0/all/0/1">Wibe A. de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_N/0/1/0/all/0/1">Neeraj Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Head_M/0/1/0/all/0/1">Martha S. Head</a>, <a href="http://arxiv.org/find/cs/1/au:+Stevens_R/0/1/0/all/0/1">Rick L. Stevens</a>, <a href="http://arxiv.org/find/cs/1/au:+Nugent_P/0/1/0/all/0/1">Peter Nugent</a>, <a href="http://arxiv.org/find/cs/1/au:+Jacobson_D/0/1/0/all/0/1">Daniel A. Jacobson</a>, <a href="http://arxiv.org/find/cs/1/au:+Brown_J/0/1/0/all/0/1">James B. Brown</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02190">
                                    <div class="article-summary-box-inner">
                                        <span>We developed Distilled Graph Attention Policy Networks (DGAPNs), a
curiosity-driven reinforcement learning model to generate novel
graph-structured chemical representations that optimize user-defined objectives
by efficiently navigating a physically constrained domain. The framework is
examined on the task of generating molecules that are designed to bind,
noncovalently, to functional sites of SARS-CoV-2 proteins. We present a spatial
Graph Attention Network (sGAT) that leverages self-attention over both node and
edge attributes as well as encoding spatial structure -- this capability is of
considerable interest in areas such as molecular and synthetic biology and drug
discovery. An attentional policy network is then introduced to learn decision
rules for a dynamic, fragment-based chemical environment, and state-of-the-art
policy gradient techniques are employed to train the network with enhanced
stability. Exploration is efficiently encouraged by incorporating innovation
reward bonuses learned and proposed by random network distillation. In
experiments, our framework achieved outstanding results compared to
state-of-the-art algorithms, while increasing the diversity of proposed
molecules and reducing the complexity of paths to chemical synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Learning of General-Purpose Embeddings for Code Changes. (arXiv:2106.02087v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pravilov_M/0/1/0/all/0/1">Mikhail Pravilov</a>, <a href="http://arxiv.org/find/cs/1/au:+Bogomolov_E/0/1/0/all/0/1">Egor Bogomolov</a>, <a href="http://arxiv.org/find/cs/1/au:+Golubev_Y/0/1/0/all/0/1">Yaroslav Golubev</a>, <a href="http://arxiv.org/find/cs/1/au:+Bryksin_T/0/1/0/all/0/1">Timofey Bryksin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02087">
                                    <div class="article-summary-box-inner">
                                        <span>A lot of problems in the field of software engineering - bug fixing, commit
message generation, etc. - require analyzing not only the code itself but
specifically code changes. Applying machine learning models to these tasks
requires us to create numerical representations of the changes, i.e.
embeddings. Recent studies demonstrate that the best way to obtain these
embeddings is to pre-train a deep neural network in an unsupervised manner on a
large volume of unlabeled data and then further fine-tune it for a specific
task.

In this work, we propose an approach for obtaining such embeddings of code
changes during pre-training and evaluate them on two different downstream tasks
- applying changes to code and commit message generation. The pre-training
consists of the model learning to apply the given change (an edit sequence) to
the code in a correct way, and therefore requires only the code change itself.
To increase the quality of the obtained embeddings, we only consider the
changed tokens in the edit sequence. In the task of applying code changes, our
model outperforms the model that uses full edit sequences by 5.9 percentage
points in accuracy. As for the commit message generation, our model
demonstrated the same results as supervised models trained for this specific
task, which indicates that it can encode code changes well and can be improved
in the future by pre-training on a larger dataset of easily gathered code
changes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hallucination In Object Detection -- A Study In Visual Part Verification. (arXiv:2106.02523v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kayhan_O/0/1/0/all/0/1">Osman Semih Kayhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Vredebregt_B/0/1/0/all/0/1">Bart Vredebregt</a>, <a href="http://arxiv.org/find/cs/1/au:+Gemert_J/0/1/0/all/0/1">Jan C. van Gemert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02523">
                                    <div class="article-summary-box-inner">
                                        <span>We show that object detectors can hallucinate and detect missing objects;
potentially even accurately localized at their expected, but non-existing,
position. This is particularly problematic for applications that rely on visual
part verification: detecting if an object part is present or absent. We show
how popular object detectors hallucinate objects in a visual part verification
task and introduce the first visual part verification dataset: DelftBikes,
which has 10,000 bike photographs, with 22 densely annotated parts per image,
where some parts may be missing. We explicitly annotated an extra object state
label for each part to reflect if a part is missing or intact. We propose to
evaluate visual part verification by relying on recall and compare popular
object detectors on DelftBikes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustifying Reinforcement Learning Policies with $\mathcal{L}_1$ Adaptive Control. (arXiv:2106.02249v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1">Yikun Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Pan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandhi_M/0/1/0/all/0/1">Manan Gandhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1">Evangelos Theodorou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovakimyan_N/0/1/0/all/0/1">Naira Hovakimyan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02249">
                                    <div class="article-summary-box-inner">
                                        <span>A reinforcement learning (RL) policy trained in a nominal environment could
fail in a new/perturbed environment due to the existence of dynamic variations.
Existing robust methods try to obtain a fixed policy for all envisioned dynamic
variation scenarios through robust or adversarial training. These methods could
lead to conservative performance due to emphasis on the worst case, and often
involve tedious modifications to the training environment. We propose an
approach to robustifying a pre-trained non-robust RL policy with
$\mathcal{L}_1$ adaptive control. Leveraging the capability of an
$\mathcal{L}_1$ control law in the fast estimation of and active compensation
for dynamic variations, our approach can significantly improve the robustness
of an RL policy trained in a standard (i.e., non-robust) way, either in a
simulator or in the real world. Numerical experiments are provided to validate
the efficacy of the proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Good Is NLP? A Sober Look at NLP Tasks through the Lens of Social Impact. (arXiv:2106.02359v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_Z/0/1/0/all/0/1">Zhijing Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chauhan_G/0/1/0/all/0/1">Geeticka Chauhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Tse_B/0/1/0/all/0/1">Brian Tse</a>, <a href="http://arxiv.org/find/cs/1/au:+Sachan_M/0/1/0/all/0/1">Mrinmaya Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihalcea_R/0/1/0/all/0/1">Rada Mihalcea</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02359">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen many breakthroughs in natural language processing
(NLP), transitioning it from a mostly theoretical field to one with many
real-world applications. Noting the rising number of applications of other
machine learning and AI techniques with pervasive societal impact, we
anticipate the rising importance of developing NLP technologies for social
good. Inspired by theories in moral philosophy and global priorities research,
we aim to promote a guideline for social good in the context of NLP. We lay the
foundations via moral philosophy&#x27;s definition of social good, propose a
framework to evaluate NLP tasks&#x27; direct and indirect real-world impact, and
adopt the methodology of global priorities research to identify priority causes
for NLP research. Finally, we use our theoretical framework to provide some
practical guidelines for future NLP research for social good. Our data and
codes are available at this http URL</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Double Descent Optimization Pattern and Aliasing: Caveats of Noisy Labels. (arXiv:2106.02100v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dubost_F/0/1/0/all/0/1">Florian Dubost</a>, <a href="http://arxiv.org/find/cs/1/au:+Saab_K/0/1/0/all/0/1">Khaled Kamal Saab</a>, <a href="http://arxiv.org/find/cs/1/au:+Hong_E/0/1/0/all/0/1">Erin Hong</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1">Daniel Yang Fu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pike_M/0/1/0/all/0/1">Max Pike</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1">Siddharth Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1">Siyi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhaskhar_N/0/1/0/all/0/1">Nandita Bhaskhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Messer_C/0/1/0/all/0/1">Christopher Lee-Messer</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1">Daniel Rubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02100">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization plays a key role in the training of deep neural networks.
Deciding when to stop training can have a substantial impact on the performance
of the network during inference. Under certain conditions, the generalization
error can display a double descent pattern during training: the learning curve
is non-monotonic and seemingly diverges before converging again after
additional epochs. This optimization pattern can lead to early stopping
procedures to stop training before the second convergence and consequently
select a suboptimal set of parameters for the network, with worse performance
during inference. In this work, in addition to confirming that double descent
occurs with small datasets and noisy labels as evidenced by others, we show
that noisy labels must be present both in the training and generalization sets
to observe a double descent pattern. We also show that the learning rate has an
influence on double descent, and study how different optimizers and optimizer
parameters influence the apparition of double descent. Finally, we show that
increasing the learning rate can create an aliasing effect that masks the
double descent pattern without suppressing it. We study this phenomenon through
extensive experiments on variants of CIFAR-10 and show that they translate to a
real world application: the forecast of seizure events in epileptic patients
from continuous electroencephalographic recordings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Closer Look at the Worst-case Behavior of Multi-armed Bandit Algorithms. (arXiv:2106.02126v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kalvit_A/0/1/0/all/0/1">Anand Kalvit</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeevi_A/0/1/0/all/0/1">Assaf Zeevi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02126">
                                    <div class="article-summary-box-inner">
                                        <span>One of the key drivers of complexity in the classical (stochastic)
multi-armed bandit (MAB) problem is the difference between mean rewards in the
top two arms, also known as the instance gap. The celebrated Upper Confidence
Bound (UCB) policy is among the simplest optimism-based MAB algorithms that
naturally adapts to this gap: for a horizon of play n, it achieves optimal
O(log n) regret in instances with &quot;large&quot; gaps, and a near-optimal O(\sqrt{n
log n}) minimax regret when the gap can be arbitrarily &quot;small.&quot; This paper
provides new results on the arm-sampling behavior of UCB, leading to several
important insights. Among these, it is shown that arm-sampling rates under UCB
are asymptotically deterministic, regardless of the problem complexity. This
discovery facilitates new sharp asymptotics and a novel alternative proof for
the O(\sqrt{n log n}) minimax regret of UCB. Furthermore, the paper also
provides the first complete process-level characterization of the MAB problem
under UCB in the conventional diffusion scaling. Among other things, the
&quot;small&quot; gap worst-case lens adopted in this paper also reveals profound
distinctions between the behavior of UCB and Thompson Sampling, such as an
&quot;incomplete learning&quot; phenomenon characteristic of the latter.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAND-mask: An Enhanced Gradient Masking Strategy for the Discovery of Invariances in Domain Generalization. (arXiv:2106.02266v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shahtalebi_S/0/1/0/all/0/1">Soroosh Shahtalebi</a>, <a href="http://arxiv.org/find/cs/1/au:+Gagnon_Audet_J/0/1/0/all/0/1">Jean-Christophe Gagnon-Audet</a>, <a href="http://arxiv.org/find/cs/1/au:+Laleh_T/0/1/0/all/0/1">Touraj Laleh</a>, <a href="http://arxiv.org/find/cs/1/au:+Faramarzi_M/0/1/0/all/0/1">Mojtaba Faramarzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1">Kartik Ahuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1">Irina Rish</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02266">
                                    <div class="article-summary-box-inner">
                                        <span>A major bottleneck in the real-world applications of machine learning models
is their failure in generalizing to unseen domains whose data distribution is
not i.i.d to the training domains. This failure often stems from learning
non-generalizable features in the training domains that are spuriously
correlated with the label of data. To address this shortcoming, there has been
a growing surge of interest in learning good explanations that are hard to
vary, which is studied under the notion of Out-of-Distribution (OOD)
Generalization. The search for good explanations that are \textit{invariant}
across different domains can be seen as finding local (global) minimas in the
loss landscape that hold true across all of the training domains. In this
paper, we propose a masking strategy, which determines a continuous weight
based on the agreement of gradients that flow in each edge of network, in order
to control the amount of update received by the edge in each step of
optimization. Particularly, our proposed technique referred to as &quot;Smoothed-AND
(SAND)-masking&quot;, not only validates the agreement in the direction of gradients
but also promotes the agreement among their magnitudes to further ensure the
discovery of invariances across training domains. SAND-mask is validated over
the Domainbed benchmark for domain generalization and significantly improves
the state-of-the-art accuracy on the Colored MNIST dataset while providing
competitive results on other domain generalization datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finding and Fixing Spurious Patterns with Explanations. (arXiv:2106.02112v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Plumb_G/0/1/0/all/0/1">Gregory Plumb</a>, <a href="http://arxiv.org/find/cs/1/au:+Ribeiro_M/0/1/0/all/0/1">Marco Tulio Ribeiro</a>, <a href="http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1">Ameet Talwalkar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02112">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning models often use spurious patterns such as &quot;relying on the
presence of a person to detect a tennis racket,&quot; which do not generalize. In
this work, we present an end-to-end pipeline for identifying and mitigating
spurious patterns for image classifiers. We start by finding patterns such as
&quot;the model&#x27;s prediction for tennis racket changes 63% of the time if we hide
the people.&quot; Then, if a pattern is spurious, we mitigate it via a novel form of
data augmentation. We demonstrate that this approach identifies a diverse set
of spurious patterns and that it mitigates them by producing a model that is
both more accurate on a distribution where the spurious pattern is not helpful
and more robust to distribution shift.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably Efficient Online Hyperparameter Optimization with Population-Based Bandits. (arXiv:2002.02518v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parker_Holder_J/0/1/0/all/0/1">Jack Parker-Holder</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Vu Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1">Stephen Roberts</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.02518">
                                    <div class="article-summary-box-inner">
                                        <span>Many of the recent triumphs in machine learning are dependent on well-tuned
hyperparameters. This is particularly prominent in reinforcement learning (RL)
where a small change in the configuration can lead to failure. Despite the
importance of tuning hyperparameters, it remains expensive and is often done in
a naive and laborious way. A recent solution to this problem is Population
Based Training (PBT) which updates both weights and hyperparameters in a single
training run of a population of agents. PBT has been shown to be particularly
effective in RL, leading to widespread use in the field. However, PBT lacks
theoretical guarantees since it relies on random heuristics to explore the
hyperparameter space. This inefficiency means it typically requires vast
computational resources, which is prohibitive for many small and medium sized
labs. In this work, we introduce the first provably efficient PBT-style
algorithm, Population-Based Bandits (PB2). PB2 uses a probabilistic model to
guide the search in an efficient way, making it possible to discover high
performing hyperparameter configurations with far fewer agents than typically
required by PBT. We show in a series of RL experiments that PB2 is able to
achieve high performance with a modest computational budget.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Laplacian-Based Dimensionality Reduction Including Spectral Clustering, Laplacian Eigenmap, Locality Preserving Projection, Graph Embedding, and Diffusion Map: Tutorial and Survey. (arXiv:2106.02154v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Ghojogh_B/0/1/0/all/0/1">Benyamin Ghojogh</a>, <a href="http://arxiv.org/find/stat/1/au:+Ghodsi_A/0/1/0/all/0/1">Ali Ghodsi</a>, <a href="http://arxiv.org/find/stat/1/au:+Karray_F/0/1/0/all/0/1">Fakhri Karray</a>, <a href="http://arxiv.org/find/stat/1/au:+Crowley_M/0/1/0/all/0/1">Mark Crowley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02154">
                                    <div class="article-summary-box-inner">
                                        <span>This is a tutorial and survey paper for nonlinear dimensionality and feature
extraction methods which are based on the Laplacian of graph of data. We first
introduce adjacency matrix, definition of Laplacian matrix, and the
interpretation of Laplacian. Then, we cover the cuts of graph and spectral
clustering which applies clustering in a subspace of data. Different
optimization variants of Laplacian eigenmap and its out-of-sample extension are
explained. Thereafter, we introduce the locality preserving projection and its
kernel variant as linear special cases of Laplacian eigenmap. Versions of graph
embedding are then explained which are generalized versions of Laplacian
eigenmap and locality preserving projection. Finally, diffusion map is
introduced which is a method based on Laplacian of data and random walks on the
data graph.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nara: Learning Network-Aware Resource Allocation Algorithms for Cloud Data Centres. (arXiv:2106.02412v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shabka_Z/0/1/0/all/0/1">Zacharaya Shabka</a>, <a href="http://arxiv.org/find/cs/1/au:+Zervas_G/0/1/0/all/0/1">Georgios Zervas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02412">
                                    <div class="article-summary-box-inner">
                                        <span>Data centres (DCs) underline many prominent future technological trends such
as distributed training of large scale machine learning models and
internet-of-things based platforms. DCs will soon account for over 3\% of
global energy demand, so efficient use of DC resources is essential. Robust DC
networks (DCNs) are essential to form the large scale systems needed to handle
this demand, but can bottleneck how efficiently DC-server resources can be used
when servers with insufficient connectivity between them cannot be jointly
allocated to a job. However, allocating servers&#x27; resources whilst accounting
for their inter-connectivity maps to an NP-hard combinatorial optimisation
problem, and so is often ignored in DC resource management schemes. We present
Nara, a framework based on reinforcement learning (RL) and graph neural
networks (GNN) to learn network-aware allocation policies that increase the
number of requests allocated over time compared to previous methods. Unique to
our solution is the use of a GNN to generate representations of server-nodes in
the DCN, which are then interpreted as actions by a RL policy-network which
chooses from which servers resources will be allocated to incoming requests.
Nara is agnostic to the topology size and shape and is trained end-to-end. The
method can accept up to 33\% more requests than the best baseline when deployed
on DCNs with up to the order of $10\times$ more compute nodes than the DCN seen
during training and is able to maintain its policy&#x27;s performance on DCNs with
the order of $100\times$ more servers than seen during training. It also
generalises to unseen DCN topologies with varied network structure and unseen
request distributions without re-training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Schr\&quot;odinger Bridges via Maximum Likelihood. (arXiv:2106.02081v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Vargas_F/0/1/0/all/0/1">Francisco Vargas</a>, <a href="http://arxiv.org/find/stat/1/au:+Thodoroff_P/0/1/0/all/0/1">Pierre Thodoroff</a>, <a href="http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1">Neil D. Lawrence</a>, <a href="http://arxiv.org/find/stat/1/au:+Lamacraft_A/0/1/0/all/0/1">Austen Lamacraft</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02081">
                                    <div class="article-summary-box-inner">
                                        <span>The Schr\&quot;odinger bridge problem (SBP) finds the most likely stochastic
evolution between two probability distributions given a prior stochastic
evolution. As well as applications in the natural sciences, problems of this
kind have important applications in machine learning such as dataset alignment
and hypothesis testing. Whilst the theory behind this problem is relatively
mature, scalable numerical recipes to estimate the Schr\&quot;odinger bridge remain
an active area of research. We prove an equivalence between the SBP and maximum
likelihood estimation enabling direct application of successful machine
learning techniques. We propose a numerical procedure to estimate SBPs using
Gaussian process and demonstrate the practical usage of our approach in
numerical simulations and experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ambulatory blood pressure monitoring versus office blood pressure measurement: Are there sex differences?. (arXiv:2106.02392v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Miladinovic_A/0/1/0/all/0/1">Aleksandar Miladinovi&#x107;</a>, <a href="http://arxiv.org/find/eess/1/au:+Ajcevic_M/0/1/0/all/0/1">Milo&#x161; Aj&#x10d;evi&#x107;</a>, <a href="http://arxiv.org/find/eess/1/au:+Siveri_G/0/1/0/all/0/1">Giulia Siveri</a>, <a href="http://arxiv.org/find/eess/1/au:+Liguori_L/0/1/0/all/0/1">Laura Liguori</a>, <a href="http://arxiv.org/find/eess/1/au:+Pascazio_L/0/1/0/all/0/1">Lorenzo Pascazio</a>, <a href="http://arxiv.org/find/eess/1/au:+Accardo_A/0/1/0/all/0/1">Agostino Accardo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02392">
                                    <div class="article-summary-box-inner">
                                        <span>The accurate measurement of blood pressure (BP) is an important prerequisite
for the reliable diagnosis and efficient management of hypertension and other
medical conditions. Office Blood Pressure Measurement (OBP) is a technique
performed in-office with the sphygmomanometer, while Ambulatory Blood Pressure
Monitoring (ABPM) is a technique that measures blood pressure during 24h. The
BP fluctuations also depend on other factors such as physical activity,
temperature, mood, age, sex, any pathologies, a hormonal activity that may
intrinsically influence the differences between OBP and ABPM. The aim of this
study is to examine the possible influence of sex on the discrepancies between
OBP and ABPM in 872 subjects with known or suspected hypertension. A
significant correlation was observed between OBP and ABPM mean values
calculated during the day, night and 24h (ABPMday, ABPMnight, ABPM24h) in both
groups (p&lt;0.0001). The main finding of this study is that no difference between
sexes was observed in the relation between OBP and mean ABMP values except
between systolic OBP and systolic ABPM during the night. In addition, this
study showed a moderate correlation between BPs obtained with the two
approaches with a great dispersion around the regression line which suggests
that the two approaches cannot be used interchangeably.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Teaching keyword spotters to spot new keywords with limited examples. (arXiv:2106.02443v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Awasthi_A/0/1/0/all/0/1">Abhijeet Awasthi</a>, <a href="http://arxiv.org/find/eess/1/au:+Kilgour_K/0/1/0/all/0/1">Kevin Kilgour</a>, <a href="http://arxiv.org/find/eess/1/au:+Rom_H/0/1/0/all/0/1">Hassan Rom</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02443">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to recognize new keywords with just a few examples is essential for
personalizing keyword spotting (KWS) models to a user&#x27;s choice of keywords.
However, modern KWS models are typically trained on large datasets and
restricted to a small vocabulary of keywords, limiting their transferability to
a broad range of unseen keywords. Towards easily customizable KWS models, we
present KeySEM (Keyword Speech EMbedding), a speech embedding model pre-trained
on the task of recognizing a large number of keywords. Speech representations
offered by KeySEM are highly effective for learning new keywords from a limited
number of examples. Comparisons with a diverse range of related work across
several datasets show that our method achieves consistently superior
performance with fewer training examples. Although KeySEM was pre-trained only
on English utterances, the performance gains also extend to datasets from four
other languages indicating that KeySEM learns useful representations well
aligned with the task of keyword spotting. Finally, we demonstrate KeySEM&#x27;s
ability to learn new keywords sequentially without requiring to re-train on
previously learned keywords. Our experimental observations suggest that KeySEM
is well suited to on-device environments where post-deployment learning and
ease of customization are often desirable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Out-of-Distribution Generalization in Kernel Regression. (arXiv:2106.02261v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Canatar_A/0/1/0/all/0/1">Abdulkadir Canatar</a>, <a href="http://arxiv.org/find/stat/1/au:+Bordelon_B/0/1/0/all/0/1">Blake Bordelon</a>, <a href="http://arxiv.org/find/stat/1/au:+Pehlevan_C/0/1/0/all/0/1">Cengiz Pehlevan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02261">
                                    <div class="article-summary-box-inner">
                                        <span>In real word applications, data generating process for training a machine
learning model often differs from what the model encounters in the test stage.
Understanding how and whether machine learning models generalize under such
distributional shifts have been a theoretical challenge. Here, we study
generalization in kernel regression when the training and test distributions
are different using methods from statistical physics. Using the replica method,
we derive an analytical formula for the out-of-distribution generalization
error applicable to any kernel and real datasets. We identify an overlap matrix
that quantifies the mismatch between distributions for a given kernel as a key
determinant of generalization performance under distribution shift. Using our
analytical expressions we elucidate various generalization phenomena including
possible improvement in generalization when there is a mismatch. We develop
procedures for optimizing training and test distributions for a given data
budget to find best and worst case generalizations under the shift. We present
applications of our theory to real and synthetic datasets and for many kernels.
We compare results of our theory applied to Neural Tangent Kernel with
simulations of wide networks and show agreement. We analyze linear regression
in further depth.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Prospective Observational Study to Investigate Performance of a Chest X-ray Artificial Intelligence Diagnostic Support Tool Across 12 U.S. Hospitals. (arXiv:2106.02118v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sun_J/0/1/0/all/0/1">Ju Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Peng_L/0/1/0/all/0/1">Le Peng</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_T/0/1/0/all/0/1">Taihui Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Adila_D/0/1/0/all/0/1">Dyah Adila</a>, <a href="http://arxiv.org/find/eess/1/au:+Zaiman_Z/0/1/0/all/0/1">Zach Zaiman</a>, <a href="http://arxiv.org/find/eess/1/au:+Melton_G/0/1/0/all/0/1">Genevieve B. Melton</a>, <a href="http://arxiv.org/find/eess/1/au:+Ingraham_N/0/1/0/all/0/1">Nicholas Ingraham</a>, <a href="http://arxiv.org/find/eess/1/au:+Murray_E/0/1/0/all/0/1">Eric Murray</a>, <a href="http://arxiv.org/find/eess/1/au:+Boley_D/0/1/0/all/0/1">Daniel Boley</a>, <a href="http://arxiv.org/find/eess/1/au:+Switzer_S/0/1/0/all/0/1">Sean Switzer</a>, <a href="http://arxiv.org/find/eess/1/au:+Burns_J/0/1/0/all/0/1">John L. Burns</a>, <a href="http://arxiv.org/find/eess/1/au:+Huang_K/0/1/0/all/0/1">Kun Huang</a>, <a href="http://arxiv.org/find/eess/1/au:+Allen_T/0/1/0/all/0/1">Tadashi Allen</a>, <a href="http://arxiv.org/find/eess/1/au:+Steenburg_S/0/1/0/all/0/1">Scott D. Steenburg</a>, <a href="http://arxiv.org/find/eess/1/au:+Gichoya_J/0/1/0/all/0/1">Judy Wawira Gichoya</a>, <a href="http://arxiv.org/find/eess/1/au:+Kummerfeld_E/0/1/0/all/0/1">Erich Kummerfeld</a>, <a href="http://arxiv.org/find/eess/1/au:+Tignanelli_C/0/1/0/all/0/1">Christopher Tignanelli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02118">
                                    <div class="article-summary-box-inner">
                                        <span>Importance: An artificial intelligence (AI)-based model to predict COVID-19
likelihood from chest x-ray (CXR) findings can serve as an important adjunct to
accelerate immediate clinical decision making and improve clinical decision
making. Despite significant efforts, many limitations and biases exist in
previously developed AI diagnostic models for COVID-19. Utilizing a large set
of local and international CXR images, we developed an AI model with high
performance on temporal and external validation.

Conclusions and Relevance: AI-based diagnostic tools may serve as an adjunct,
but not replacement, for clinical decision support of COVID-19 diagnosis, which
largely hinges on exposure history, signs, and symptoms. While AI-based tools
have not yet reached full diagnostic potential in COVID-19, they may still
offer valuable information to clinicians taken into consideration along with
clinical signs and symptoms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ukiyo-e Analysis and Creativity with Attribute and Geometry Annotation. (arXiv:2106.02267v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yingtao Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Clanuwat_T/0/1/0/all/0/1">Tarin Clanuwat</a>, <a href="http://arxiv.org/find/cs/1/au:+Suzuki_C/0/1/0/all/0/1">Chikahiko Suzuki</a>, <a href="http://arxiv.org/find/cs/1/au:+Kitamoto_A/0/1/0/all/0/1">Asanobu Kitamoto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02267">
                                    <div class="article-summary-box-inner">
                                        <span>The study of Ukiyo-e, an important genre of pre-modern Japanese art, focuses
on the object and style like other artwork researches. Such study has benefited
from the renewed interest by the machine learning community in culturally
important topics, leading to interdisciplinary works including collections of
images, quantitative approaches, and machine learning-based creativities. They,
however, have several drawbacks, and it remains challenging to integrate these
works into a comprehensive view. To bridge this gap, we propose a holistic
approach We first present a large-scale Ukiyo-e dataset with coherent semantic
labels and geometric annotations, then show its value in a quantitative study
of Ukiyo-e paintings&#x27; object using these labels and annotations. We further
demonstrate the machine learning methods could help style study through soft
color decomposition of Ukiyo-e, and finally provides joint insights into object
and style by composing sketches and colors using colorization. Dataset
available at https://github.com/rois-codh/arc-ukiyoe-faces</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Disentangling Dense Multi-Cable Knots. (arXiv:2106.02252v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Viswanath_V/0/1/0/all/0/1">Vainavi Viswanath</a>, <a href="http://arxiv.org/find/cs/1/au:+Grannen_J/0/1/0/all/0/1">Jennifer Grannen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sundaresan_P/0/1/0/all/0/1">Priya Sundaresan</a>, <a href="http://arxiv.org/find/cs/1/au:+Thananjeyan_B/0/1/0/all/0/1">Brijen Thananjeyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Balakrishna_A/0/1/0/all/0/1">Ashwin Balakrishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Novoseller_E/0/1/0/all/0/1">Ellen Novoseller</a>, <a href="http://arxiv.org/find/cs/1/au:+Ichnowski_J/0/1/0/all/0/1">Jeffrey Ichnowski</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskey_M/0/1/0/all/0/1">Michael Laskey</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1">Ken Goldberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02252">
                                    <div class="article-summary-box-inner">
                                        <span>Disentangling two or more cables requires many steps to remove crossings
between and within cables. We formalize the problem of disentangling multiple
cables and present an algorithm, Iterative Reduction Of Non-planar Multiple
cAble kNots (IRON-MAN), that outputs robot actions to remove crossings from
multi-cable knotted structures. We instantiate this algorithm with a learned
perception system, inspired by prior work in single-cable untying that given an
image input, can disentangle two-cable twists, three-cable braids, and knots of
two or three cables, such as overhand, square, carrick bend, sheet bend, crown,
and fisherman&#x27;s knots. IRON-MAN keeps track of task-relevant keypoints
corresponding to target cable endpoints and crossings and iteratively
disentangles the cables by identifying and undoing crossings that are critical
to knot structure. Using a da Vinci surgical robot, we experimentally evaluate
the effectiveness of IRON-MAN on untangling multi-cable knots of types that
appear in the training data, as well as generalizing to novel classes of
multi-cable knots. Results suggest that IRON-MAN is effective in disentangling
knots involving up to three cables with 80.5% success and generalizing to knot
types that are not present during training, with cables of both distinct or
identical colors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Switching State Space Model (DS$^3$M) for Nonlinear Time Series Forecasting with Regime Switching. (arXiv:2106.02329v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiuqin Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Ying Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02329">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a deep switching state space model (DS$^3$M) for efficient
inference and forecasting of nonlinear time series with irregularly switching
among various regimes. The switching among regimes is captured by both discrete
and continuous latent variables with recurrent neural networks. The model is
estimated with variational inference using a reparameterization trick. We test
the approach on a variety of simulated and real datasets. In all cases, DS$^3$M
achieves competitive performance compared to several state-of-the-art methods
(e.g. GRU, SRNN, DSARF, SNLDS), with superior forecasting accuracy, convincing
interpretability of the discrete latent variables, and powerful representation
of the continuous latent variables for different kinds of time series.
Specifically, the MAPE values increase by 0.09\% to 15.71\% against the
second-best performing alternative models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Multi-Armed Bandits with Unrestricted Delay Distributions. (arXiv:2106.02436v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lancewicki_T/0/1/0/all/0/1">Tal Lancewicki</a>, <a href="http://arxiv.org/find/cs/1/au:+Segal_S/0/1/0/all/0/1">Shahar Segal</a>, <a href="http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1">Tomer Koren</a>, <a href="http://arxiv.org/find/cs/1/au:+Mansour_Y/0/1/0/all/0/1">Yishay Mansour</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02436">
                                    <div class="article-summary-box-inner">
                                        <span>We study the stochastic Multi-Armed Bandit (MAB) problem with random delays
in the feedback received by the algorithm. We consider two settings: the
reward-dependent delay setting, where realized delays may depend on the
stochastic rewards, and the reward-independent delay setting. Our main
contribution is algorithms that achieve near-optimal regret in each of the
settings, with an additional additive dependence on the quantiles of the delay
distribution. Our results do not make any assumptions on the delay
distributions: in particular, we do not assume they come from any parametric
family of distributions and allow for unbounded support and expectation; we
further allow for infinite delays where the algorithm might occasionally not
observe any feedback.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Subdivision-Based Mesh Convolution Networks. (arXiv:2106.02285v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shi-Min Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zheng-Ning Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1">Meng-Hao Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_J/0/1/0/all/0/1">Jun-Xiong Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiahui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mu_T/0/1/0/all/0/1">Tai-Jiang Mu</a>, <a href="http://arxiv.org/find/cs/1/au:+Martin_R/0/1/0/all/0/1">Ralph R. Martin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02285">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) have made great breakthroughs in 2D
computer vision. However, the irregular structure of meshes makes it hard to
exploit the power of CNNs directly. A subdivision surface provides a
hierarchical multi-resolution structure, and each face in a closed 2-manifold
triangle mesh is exactly adjacent to three faces. Motivated by these two
properties, this paper introduces a novel and flexible CNN framework, named
SubdivNet, for 3D triangle meshes with Loop subdivision sequence connectivity.
Making an analogy between mesh faces and pixels in a 2D image allows us to
present a mesh convolution operator to aggregate local features from adjacent
faces. By exploiting face neighborhoods, this convolution can support standard
2D convolutional network concepts, e.g. variable kernel size, stride, and
dilation. Based on the multi-resolution hierarchy, we propose a spatial uniform
pooling layer which merges four faces into one and an upsampling method which
splits one face into four. As a result, many popular 2D CNN architectures can
be readily adapted to processing 3D meshes. Meshes with arbitrary connectivity
can be remeshed to hold Loop subdivision sequence connectivity via
self-parameterization, making SubdivNet a general approach. Experiments on mesh
classification, segmentation, correspondence, and retrieval from the real-world
demonstrate the effectiveness and efficiency of SubdivNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RL-DARTS: Differentiable Architecture Search for Reinforcement Learning. (arXiv:2106.02229v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Miao_Y/0/1/0/all/0/1">Yingjie Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xingyou Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1">Daiyi Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yue_S/0/1/0/all/0/1">Summer Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Brevdo_E/0/1/0/all/0/1">Eugene Brevdo</a>, <a href="http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1">Aleksandra Faust</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02229">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce RL-DARTS, one of the first applications of Differentiable
Architecture Search (DARTS) in reinforcement learning (RL) to search for
convolutional cells, applied to the Procgen benchmark. We outline the initial
difficulties of applying neural architecture search techniques in RL, and
demonstrate that by simply replacing the image encoder with a DARTS supernet,
our search method is sample-efficient, requires minimal extra compute
resources, and is also compatible with off-policy and on-policy RL algorithms,
needing only minor changes in preexisting code. Surprisingly, we find that the
supernet can be used as an actor for inference to generate replay data in
standard RL training loops, and thus train end-to-end. Throughout this training
process, we show that the supernet gradually learns better cells, leading to
alternative architectures which can be highly competitive against manually
designed policies, but also verify previous design choices for RL policies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Learning-based Optimal Market Bidding Strategy for Price-Maker Energy Storage. (arXiv:2106.02396v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Badoual_M/0/1/0/all/0/1">Mathilde D. Badoual</a>, <a href="http://arxiv.org/find/eess/1/au:+Moura_S/0/1/0/all/0/1">Scott J. Moura</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02396">
                                    <div class="article-summary-box-inner">
                                        <span>Load serving entities with storage units reach sizes and performances that
can significantly impact clearing prices in electricity markets. Nevertheless,
price endogeneity is rarely considered in storage bidding strategies and
modeling the electricity market is a challenging task. Meanwhile, model-free
reinforcement learning such as the Actor-Critic are becoming increasingly
popular for designing energy system controllers. Yet implementation frequently
requires lengthy, data-intense, and unsafe trial-and-error training. To fill
these gaps, we implement an online Supervised Actor-Critic (SAC) algorithm,
supervised with a model-based controller -- Model Predictive Control (MPC). The
energy storage agent is trained with this algorithm to optimally bid while
learning and adjusting to its impact on the market clearing prices. We compare
the supervised Actor-Critic algorithm with the MPC algorithm as a supervisor,
finding that the former reaps higher profits via learning. Our contribution,
thus, is an online and safe SAC algorithm that outperforms the current
model-based state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Barlow Twins: A self-supervised representation learning framework for graphs. (arXiv:2106.02466v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bielak_P/0/1/0/all/0/1">Piotr Bielak</a>, <a href="http://arxiv.org/find/cs/1/au:+Kajdanowicz_T/0/1/0/all/0/1">Tomasz Kajdanowicz</a>, <a href="http://arxiv.org/find/cs/1/au:+Chawla_N/0/1/0/all/0/1">Nitesh V. Chawla</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02466">
                                    <div class="article-summary-box-inner">
                                        <span>The self-supervised learning (SSL) paradigm is an essential exploration area,
which tries to eliminate the need for expensive data labeling. Despite the
great success of SSL methods in computer vision and natural language
processing, most of them employ contrastive learning objectives that require
negative samples, which are hard to define. This becomes even more challenging
in the case of graphs and is a bottleneck for achieving robust representations.
To overcome such limitations, we propose a framework for self-supervised graph
representation learning -- Graph Barlow Twins, which utilizes a
cross-correlation-based loss function instead of negative samples. Moreover, it
does not rely on non-symmetric neural network architectures -- in contrast to
state-of-the-art self-supervised graph representation learning method BGRL. We
show that our method achieves as competitive results as BGRL, best
self-supervised methods, and fully supervised ones while requiring
substantially fewer hyperparameters and converging in an order of magnitude
training steps earlier.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning. (arXiv:2106.02584v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kossen_J/0/1/0/all/0/1">Jannik Kossen</a>, <a href="http://arxiv.org/find/cs/1/au:+Band_N/0/1/0/all/0/1">Neil Band</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyle_C/0/1/0/all/0/1">Clare Lyle</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1">Aidan N. Gomez</a>, <a href="http://arxiv.org/find/cs/1/au:+Rainforth_T/0/1/0/all/0/1">Tom Rainforth</a>, <a href="http://arxiv.org/find/cs/1/au:+Gal_Y/0/1/0/all/0/1">Yarin Gal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02584">
                                    <div class="article-summary-box-inner">
                                        <span>We challenge a common assumption underlying most supervised deep learning:
that a model makes a prediction depending only on its parameters and the
features of a single input. To this end, we introduce a general-purpose deep
learning architecture that takes as input the entire dataset instead of
processing one datapoint at a time. Our approach uses self-attention to reason
about relationships between datapoints explicitly, which can be seen as
realizing non-parametric models using parametric attention mechanisms. However,
unlike conventional non-parametric models, we let the model learn end-to-end
from the data how to make use of other datapoints for prediction. Empirically,
our models solve cross-datapoint lookup and complex reasoning tasks unsolvable
by traditional deep learning models. We show highly competitive results on
tabular data, early results on CIFAR-10, and give insight into how the model
makes use of the interactions between points.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DRIBO: Robust Deep Reinforcement Learning via Multi-View Information Bottleneck. (arXiv:2102.13268v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Jiameng Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenchao Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13268">
                                    <div class="article-summary-box-inner">
                                        <span>Deep reinforcement learning (DRL) agents are often sensitive to visual
changes that were unseen in their training environments. To address this
problem, we leverage the sequential nature of RL to learn robust
representations that encode only task-relevant information from observations
based on the unsupervised multi-view setting. Specifically, we introduce an
auxiliary objective based on the multi-view in-formation bottleneck (MIB)
principle which quantifies the amount of task-irrelevant information and
encourages learning representations that are both predictive of the future and
less sensitive to task-irrelevant distractions. This enables us to train
high-performance policies that are robust to visual distractions and can
generalize to unseen environments. We demonstrate that our approach can achieve
SOTA performance on diverse visual control tasks on the DeepMind Control Suite,
even when the background is replaced with natural videos. In addition, we show
that our approach outperforms well-established baselines for generalization to
unseen environments on the Procgen benchmark. Our code is open-sourced and
available at https://github.com/JmfanBU/DRIBO.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Forward Super-Resolution: How Can GANs Learn Hierarchical Generative Models for Real-World Distributions. (arXiv:2106.02619v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1">Zeyuan Allen-Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuanzhi Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02619">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks (GANs) are among the most successful models
for learning high-complexity, real-world distributions. However, in theory, due
to the highly non-convex, non-concave landscape of the minmax training
objective, GAN remains one of the least understood deep learning models. In
this work, we formally study how GANs can efficiently learn certain
hierarchically generated distributions that are close to the distribution of
images in practice. We prove that when a distribution has a structure that we
refer to as Forward Super-Resolution, then simply training generative
adversarial networks using gradient descent ascent (GDA) can indeed learn this
distribution efficiently, both in terms of sample and time complexities. We
also provide concrete empirical evidence that not only our assumption &quot;forward
super-resolution&quot; is very natural in practice, but also the underlying learning
mechanisms that we study in this paper (to allow us efficiently train GAN via
GDA in theory) simulates the actual learning process of GANs in practice on
real-world problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Contextual Learners for Protein Networks. (arXiv:2106.02246v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1">Michelle M. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1">Marinka Zitnik</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02246">
                                    <div class="article-summary-box-inner">
                                        <span>Spatial context is central to understanding health and disease. Yet reference
protein interaction networks lack such contextualization, thereby limiting the
study of where protein interactions likely occur in the human body.
Contextualized protein interactions could better characterize genes with
disease-specific interactions and elucidate diseases&#x27; manifestation in specific
cell types. Here, we introduce AWARE, a graph neural message passing approach
to inject cellular and tissue context into protein embeddings. AWARE optimizes
for a multi-scale embedding space, whose structure reflects the topology of
cell type specific networks. We construct a multi-scale network of the Human
Cell Atlas and apply AWARE to learn protein, cell type, and tissue embeddings
that uphold cell type and tissue hierarchies. We demonstrate AWARE on the novel
task of predicting whether a gene is associated with a disease and where it
most likely manifests in the human body. AWARE embeddings outperform global
embeddings by at least 12.5%, highlighting the importance of contextual
learners for protein networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CAFLOW: Conditional Autoregressive Flows. (arXiv:2106.02531v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Batzolis_G/0/1/0/all/0/1">Georgios Batzolis</a>, <a href="http://arxiv.org/find/cs/1/au:+Carioni_M/0/1/0/all/0/1">Marcello Carioni</a>, <a href="http://arxiv.org/find/cs/1/au:+Etmann_C/0/1/0/all/0/1">Christian Etmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Afyouni_S/0/1/0/all/0/1">Soroosh Afyouni</a>, <a href="http://arxiv.org/find/cs/1/au:+Kourtzi_Z/0/1/0/all/0/1">Zoe Kourtzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1">Carola Bibiane Sch&#xf6;nlieb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02531">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce CAFLOW, a new diverse image-to-image translation model that
simultaneously leverages the power of auto-regressive modeling and the modeling
efficiency of conditional normalizing flows. We transform the conditioning
image into a sequence of latent encodings using a multi-scale normalizing flow
and repeat the process for the conditioned image. We model the conditional
distribution of the latent encodings by modeling the auto-regressive
distributions with an efficient multi-scale normalizing flow, where each
conditioning factor affects image synthesis at its respective resolution scale.
Our proposed framework performs well on a range of image-to-image translation
tasks. It outperforms former designs of conditional flows because of its
expressive auto-regressive structure.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generative Text Modeling through Short Run Inference. (arXiv:2106.02513v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1">Bo Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nijkamp_E/0/1/0/all/0/1">Erik Nijkamp</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1">Tian Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Ying Nian Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02513">
                                    <div class="article-summary-box-inner">
                                        <span>Latent variable models for text, when trained successfully, accurately model
the data distribution and capture global semantic and syntactic features of
sentences. The prominent approach to train such models is variational
autoencoders (VAE). It is nevertheless challenging to train and often results
in a trivial local optimum where the latent variable is ignored and its
posterior collapses into the prior, an issue known as posterior collapse.
Various techniques have been proposed to mitigate this issue. Most of them
focus on improving the inference model to yield latent codes of higher quality.
The present work proposes a short run dynamics for inference. It is initialized
from the prior distribution of the latent variable and then runs a small number
(e.g., 20) of Langevin dynamics steps guided by its posterior distribution. The
major advantage of our method is that it does not require a separate inference
model or assume simple geometry of the posterior distribution, thus rendering
an automatic, natural and flexible inference engine. We show that the models
trained with short run dynamics more accurately model the data, compared to
strong language model and VAE baselines, and exhibit no sign of posterior
collapse. Analyses of the latent space show that interpolation in the latent
space is able to generate coherent sentences with smooth transition and
demonstrate improved classification over strong baselines with latent features
from unsupervised pretraining. These results together expose a well-structured
latent space of our generative model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Influence of cognitive, geographical, and collaborative proximity on knowledge production of Canadian nanotechnology. (arXiv:2106.02110v1 [physics.soc-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Neira_E/0/1/0/all/0/1">Elva Luz Crespo Neira</a>, <a href="http://arxiv.org/find/physics/1/au:+Ebadi_A/0/1/0/all/0/1">Ashkan Ebadi</a>, <a href="http://arxiv.org/find/physics/1/au:+Beaudry_C/0/1/0/all/0/1">Catherine Beaudry</a>, <a href="http://arxiv.org/find/physics/1/au:+Schiffauerova_A/0/1/0/all/0/1">Andrea Schiffauerova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02110">
                                    <div class="article-summary-box-inner">
                                        <span>Incorporating existing knowledge is vital for innovating, discovering, and
generating new ideas. Knowledge production through research and invention is
the key to scientific and technological development. As an emerging technology,
nanotechnology has already proved its great potential for the global economy,
attracting considerable federal investments. Canada is reported as one of the
major players in producing nanotechnology research. In this paper, we focused
on the main drivers of knowledge production and diffusion by analyzing Canadian
nanotechnology researchers. We hypothesized that knowledge production in
Canadian nanotechnology is influenced by three key proximity factors, namely
cognitive, geographical, and collaborative. Using statistical analysis, social
network analysis, and machine learning techniques we comprehensively assessed
the influence of the proximity factors on academic knowledge production. Our
results not only prove a significant impact of the three key proximity factors
but also their predictive potential.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain-Adversarial and Conditional State Space Model for Imitation Learning. (arXiv:2001.11628v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Okumura_R/0/1/0/all/0/1">Ryo Okumura</a>, <a href="http://arxiv.org/find/cs/1/au:+Okada_M/0/1/0/all/0/1">Masashi Okada</a>, <a href="http://arxiv.org/find/cs/1/au:+Taniguchi_T/0/1/0/all/0/1">Tadahiro Taniguchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.11628">
                                    <div class="article-summary-box-inner">
                                        <span>State representation learning (SRL) in partially observable Markov decision
processes has been studied to learn abstract features of data useful for robot
control tasks. For SRL, acquiring domain-agnostic states is essential for
achieving efficient imitation learning. Without these states, imitation
learning is hampered by domain-dependent information useless for control.
However, existing methods fail to remove such disturbances from the states when
the data from experts and agents show large domain shifts. To overcome this
issue, we propose a domain-adversarial and conditional state space model
(DAC-SSM) that enables control systems to obtain domain-agnostic and task- and
dynamics-aware states. DAC-SSM jointly optimizes the state inference,
observation reconstruction, forward dynamics, and reward models. To remove
domain-dependent information from the states, the model is trained with domain
discriminators in an adversarial manner, and the reconstruction is conditioned
on domain labels. We experimentally evaluated the model predictive control
performance via imitation learning for continuous control of sparse reward
tasks in simulators and compared it with the performance of the existing SRL
method. The agents from DAC-SSM achieved performance comparable to experts and
more than twice the baselines. We conclude domain-agnostic states are essential
for imitation learning that has large domain shifts and can be obtained using
DAC-SSM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Regularization and Reparameterization Avoid Vanishing Gradients in Sigmoid-Type Networks. (arXiv:2106.02260v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ven_L/0/1/0/all/0/1">Leni Ven</a>, <a href="http://arxiv.org/find/cs/1/au:+Lederer_J/0/1/0/all/0/1">Johannes Lederer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02260">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning requires several design choices, such as the nodes&#x27; activation
functions and the widths, types, and arrangements of the layers. One
consideration when making these choices is the vanishing-gradient problem,
which is the phenomenon of algorithms getting stuck at suboptimal points due to
small gradients. In this paper, we revisit the vanishing-gradient problem in
the context of sigmoid-type activation. We use mathematical arguments to
highlight two different sources of the phenomenon, namely large individual
parameters and effects across layers, and to illustrate two simple remedies,
namely regularization and rescaling. We then demonstrate the effectiveness of
the two remedies in practice. In view of the vanishing-gradient problem being a
main reason why tanh and other sigmoid-type activation has become much less
popular than relu-type activation, our results bring sigmoid-type activation
back to the table.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Price graphs: Utilizing the structural information of financial time series for stock prediction. (arXiv:2106.02522v1 [q-fin.ST])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-fin/1/au:+Wu_J/0/1/0/all/0/1">Junran Wu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Xu_K/0/1/0/all/0/1">Ke Xu</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Chen_X/0/1/0/all/0/1">Xueyuan Chen</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Li_S/0/1/0/all/0/1">Shangzhe Li</a>, <a href="http://arxiv.org/find/q-fin/1/au:+Zhao_J/0/1/0/all/0/1">Jichang Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02522">
                                    <div class="article-summary-box-inner">
                                        <span>Stock prediction, with the purpose of forecasting the future price trends of
stocks, is crucial for maximizing profits from stock investments. While great
research efforts have been devoted to exploiting deep neural networks for
improved stock prediction, the existing studies still suffer from two major
issues. First, the long-range dependencies in time series are not sufficiently
captured. Second, the chaotic property of financial time series fundamentally
lowers prediction performance. In this study, we propose a novel framework to
address both issues regarding stock prediction. Specifically, in terms of
transforming time series into complex networks, we convert market price series
into graphs. Then, structural information, referring to associations among
temporal points and the node weights, is extracted from the mapped graphs to
resolve the problems regarding long-range dependencies and the chaotic
property. We take graph embeddings to represent the associations among temporal
points as the prediction model inputs. Node weights are used as a priori
knowledge to enhance the learning of temporal attention. The effectiveness of
our proposed framework is validated using real-world stock data, and our
approach obtains the best performance among several state-of-the-art
benchmarks. Moreover, in the conducted trading simulations, our framework
further obtains the highest cumulative profits. Our results supplement the
existing applications of complex network methods in the financial realm and
provide insightful implications for investment applications regarding decision
support in financial markets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adam in Private: Secure and Fast Training of Deep Neural Networks with Adaptive Moment Estimation. (arXiv:2106.02203v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Attrapadung_N/0/1/0/all/0/1">Nuttapong Attrapadung</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamada_K/0/1/0/all/0/1">Koki Hamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikarashi_D/0/1/0/all/0/1">Dai Ikarashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kikuchi_R/0/1/0/all/0/1">Ryo Kikuchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Matsuda_T/0/1/0/all/0/1">Takahiro Matsuda</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishina_I/0/1/0/all/0/1">Ibuki Mishina</a>, <a href="http://arxiv.org/find/cs/1/au:+Morita_H/0/1/0/all/0/1">Hiraku Morita</a>, <a href="http://arxiv.org/find/cs/1/au:+Schuldt_J/0/1/0/all/0/1">Jacob C. N. Schuldt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02203">
                                    <div class="article-summary-box-inner">
                                        <span>Privacy-preserving machine learning (PPML) aims at enabling machine learning
(ML) algorithms to be used on sensitive data. We contribute to this line of
research by proposing a framework that allows efficient and secure evaluation
of full-fledged state-of-the-art ML algorithms via secure multi-party
computation (MPC). This is in contrast to most prior works, which substitute ML
algorithms with approximated &quot;MPC-friendly&quot; variants. A drawback of the latter
approach is that fine-tuning of the combined ML and MPC algorithms is required,
which might lead to less efficient algorithms or inferior quality ML. This is
an issue for secure deep neural networks (DNN) training in particular, as this
involves arithmetic algorithms thought to be &quot;MPC-unfriendly&quot;, namely, integer
division, exponentiation, inversion, and square root. In this work, we propose
secure and efficient protocols for the above seemingly MPC-unfriendly
computations. Our protocols are three-party protocols in the honest-majority
setting, and we propose both passively secure and actively secure with abort
variants. A notable feature of our protocols is that they simultaneously
provide high accuracy and efficiency. This framework enables us to efficiently
and securely compute modern ML algorithms such as Adam and the softmax function
&quot;as is&quot;, without resorting to approximations. As a result, we obtain secure DNN
training that outperforms state-of-the-art three-party systems; our full
training is up to 6.7 times faster than just the online phase of the recently
proposed FALCON@PETS&#x27;21 on a standard benchmark network. We further perform
measurements on real-world DNNs, AlexNet and VGG16. The performance of our
framework is up to a factor of about 12-14 faster for AlexNet and 46-48 faster
for VGG16 to achieve an accuracy of 70% and 75%, respectively, when compared to
FALCON.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition. (arXiv:2106.02302v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Meng_Z/0/1/0/all/0/1">Zhong Meng</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Kanda_N/0/1/0/all/0/1">Naoyuki Kanda</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_L/0/1/0/all/0/1">Liang Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1">Xie Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Ye_G/0/1/0/all/0/1">Guoli Ye</a>, <a href="http://arxiv.org/find/eess/1/au:+Sun_E/0/1/0/all/0/1">Eric Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_J/0/1/0/all/0/1">Jinyu Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Gong_Y/0/1/0/all/0/1">Yifan Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02302">
                                    <div class="article-summary-box-inner">
                                        <span>Integrating external language models (LMs) into end-to-end (E2E) models
remains a challenging task for domain-adaptive speech recognition. Recently,
internal language model estimation (ILME)-based LM fusion has shown significant
word error rate (WER) reduction from Shallow Fusion by subtracting a weighted
internal LM score from an interpolation of E2E model and external LM scores
during beam search. However, on different test sets, the optimal LM
interpolation weights vary over a wide range and have to be tuned extensively
on well-matched validation sets. In this work, we perform LM fusion in the
minimum WER (MWER) training of an E2E model to obviate the need for LM weights
tuning during inference. Besides MWER training with Shallow Fusion (MWER-SF),
we propose a novel MWER training with ILME (MWER-ILME) where the ILME-based
fusion is conducted to generate N-best hypotheses and their posteriors.
Additional gradient is induced when internal LM is engaged in MWER-ILME loss
computation. During inference, LM weights pre-determined in MWER training
enable robust LM integrations on test sets from different domains. Experimented
with 30K-hour trained transformer transducers, MWER-ILME achieves on average
8.8% and 5.8% relative WER reductions from MWER and MWER-SF training,
respectively, on 6 different test sets</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the emergence of simplex symmetry in the final and penultimate layers of neural network classifiers. (arXiv:2012.05420v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+E_W/0/1/0/all/0/1">Weinan E</a>, <a href="http://arxiv.org/find/cs/1/au:+Wojtowytsch_S/0/1/0/all/0/1">Stephan Wojtowytsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05420">
                                    <div class="article-summary-box-inner">
                                        <span>A recent numerical study observed that neural network classifiers enjoy a
large degree of symmetry in the penultimate layer. Namely, if $h(x) &#x3D; Af(x) +b$
where $A$ is a linear map and $f$ is the output of the penultimate layer of the
network (after activation), then all data points $x_{i, 1}, \dots, x_{i, N_i}$
in a class $C_i$ are mapped to a single point $y_i$ by $f$ and the points $y_i$
are located at the vertices of a regular $k-1$-dimensional standard simplex in
a high-dimensional Euclidean space.

We explain this observation analytically in toy models for highly expressive
deep neural networks. In complementary examples, we demonstrate rigorously that
even the final output of the classifier $h$ is not uniform over data samples
from a class $C_i$ if $h$ is a shallow network (or if the deeper layers do not
bring the data samples into a convenient geometric configuration).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DOCTOR: A Simple Method for Detecting Misclassification Errors. (arXiv:2106.02395v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Granese_F/0/1/0/all/0/1">Federica Granese</a>, <a href="http://arxiv.org/find/cs/1/au:+Romanelli_M/0/1/0/all/0/1">Marco Romanelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Gorla_D/0/1/0/all/0/1">Daniele Gorla</a>, <a href="http://arxiv.org/find/cs/1/au:+Palamidessi_C/0/1/0/all/0/1">Catuscia Palamidessi</a>, <a href="http://arxiv.org/find/cs/1/au:+Piantanida_P/0/1/0/all/0/1">Pablo Piantanida</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02395">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks (DNNs) have shown to perform very well on large scale
object recognition problems and lead to widespread use for real-world
applications, including situations where DNN are implemented as &quot;black boxes&quot;.
A promising approach to secure their use is to accept decisions that are likely
to be correct while discarding the others. In this work, we propose DOCTOR, a
simple method that aims to identify whether the prediction of a DNN classifier
should (or should not) be trusted so that, consequently, it would be possible
to accept it or to reject it. Two scenarios are investigated: Totally Black Box
(TBB) where only the soft-predictions are available and Partially Black Box
(PBB) where gradient-propagation to perform input pre-processing is allowed.
Empirically, we show that DOCTOR outperforms all state-of-the-art methods on
various well-known images and sentiment analysis datasets. In particular, we
observe a reduction of up to $4\%$ of the false rejection rate (FRR) in the PBB
scenario. DOCTOR can be applied to any pre-trained model, it does not require
prior information about the underlying dataset and is as simple as the simplest
available methods in the literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adaptive Epidemic Forecasting and Community Risk Evaluation of COVID-19. (arXiv:2106.02094v1 [cs.CY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gopalakrishnan_V/0/1/0/all/0/1">Vishrawas Gopalakrishnan</a>, <a href="http://arxiv.org/find/cs/1/au:+Navalekar_S/0/1/0/all/0/1">Sayali Navalekar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1">Pan Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Hooley_R/0/1/0/all/0/1">Ryan Hooley</a>, <a href="http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1">Jacob Miller</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_R/0/1/0/all/0/1">Raman Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1">Ajay Deshpande</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bianco_S/0/1/0/all/0/1">Simone Bianco</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaufman_J/0/1/0/all/0/1">James H. Kaufman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02094">
                                    <div class="article-summary-box-inner">
                                        <span>Pandemic control measures like lock-down, restrictions on restaurants and
gatherings, social-distancing have shown to be effective in curtailing the
spread of COVID-19. However, their sustained enforcement has negative economic
effects. To craft strategies and policies that reduce the hardship on the
people and the economy while being effective against the pandemic, authorities
need to understand the disease dynamics at the right geo-spatial granularity.
Considering factors like the hospitals&#x27; ability to handle the fluctuating
demands, evaluating various reopening scenarios, and accurate forecasting of
cases are vital to decision making. Towards this end, we present a flexible
end-to-end solution that seamlessly integrates public health data with tertiary
client data to accurately estimate the risk of reopening a community. At its
core lies a state-of-the-art prediction model that auto-captures changing
trends in transmission and mobility. Benchmarking against various published
baselines confirm the superiority of our forecasting algorithm. Combined with
the ability to extend to multiple client-specific requirements and perform
deductive reasoning through counter-factual analysis, this solution provides
actionable insights to multiple client domains ranging from government to
educational institutions, hospitals, and commercial establishments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using latent space regression to analyze and leverage compositionality in GANs. (arXiv:2103.10426v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chai_L/0/1/0/all/0/1">Lucy Chai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wulff_J/0/1/0/all/0/1">Jonas Wulff</a>, <a href="http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1">Phillip Isola</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10426">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, Generative Adversarial Networks have become ubiquitous in
both research and public perception, but how GANs convert an unstructured
latent code to a high quality output is still an open question. In this work,
we investigate regression into the latent space as a probe to understand the
compositional properties of GANs. We find that combining the regressor and a
pretrained generator provides a strong image prior, allowing us to create
composite images from a collage of random image parts at inference time while
maintaining global consistency. To compare compositional properties across
different generators, we measure the trade-offs between reconstruction of the
unrealistic input and image quality of the regenerated samples. We find that
the regression approach enables more localized editing of individual image
parts compared to direct editing in the latent space, and we conduct
experiments to quantify this independence effect. Our method is agnostic to the
semantics of edits, and does not require labels or predefined concepts during
training. Beyond image composition, our method extends to a number of related
applications, such as image inpainting or example-based image editing, which we
demonstrate on several GANs and datasets, and because it uses only a single
forward pass, it can operate in real-time. Code is available on our project
page: https://chail.github.io/latent-composition/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adiabatic Quantum Feature Selection for Sparse Linear Regression. (arXiv:2106.02357v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Desu_S/0/1/0/all/0/1">Surya Sai Teja Desu</a>, <a href="http://arxiv.org/find/cs/1/au:+Srijith_P/0/1/0/all/0/1">P.K. Srijith</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_M/0/1/0/all/0/1">M.V. Panduranga Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Sivadasan_N/0/1/0/all/0/1">Naveen Sivadasan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02357">
                                    <div class="article-summary-box-inner">
                                        <span>Linear regression is a popular machine learning approach to learn and predict
real valued outputs or dependent variables from independent variables or
features. In many real world problems, its beneficial to perform sparse linear
regression to identify important features helpful in predicting the dependent
variable. It not only helps in getting interpretable results but also avoids
overfitting when the number of features is large, and the amount of data is
small. The most natural way to achieve this is by using &#x60;best subset selection&#x27;
which penalizes non-zero model parameters by adding $\ell_0$ norm over
parameters to the least squares loss. However, this makes the objective
function non-convex and intractable even for a small number of features. This
paper aims to address the intractability of sparse linear regression with
$\ell_0$ norm using adiabatic quantum computing, a quantum computing paradigm
that is particularly useful for solving optimization problems faster. We
formulate the $\ell_0$ optimization problem as a Quadratic Unconstrained Binary
Optimization (QUBO) problem and solve it using the D-Wave adiabatic quantum
computer. We study and compare the quality of QUBO solution on synthetic and
real world datasets. The results demonstrate the effectiveness of the proposed
adiabatic quantum computing approach in finding the optimal solution. The QUBO
solution matches the optimal solution for a wide range of sparsity penalty
values across the datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CLIP: A Dataset for Extracting Action Items for Physicians from Hospital Discharge Notes. (arXiv:2106.02524v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mullenbach_J/0/1/0/all/0/1">James Mullenbach</a>, <a href="http://arxiv.org/find/cs/1/au:+Pruksachatkun_Y/0/1/0/all/0/1">Yada Pruksachatkun</a>, <a href="http://arxiv.org/find/cs/1/au:+Adler_S/0/1/0/all/0/1">Sean Adler</a>, <a href="http://arxiv.org/find/cs/1/au:+Seale_J/0/1/0/all/0/1">Jennifer Seale</a>, <a href="http://arxiv.org/find/cs/1/au:+Swartz_J/0/1/0/all/0/1">Jordan Swartz</a>, <a href="http://arxiv.org/find/cs/1/au:+McKelvey_T/0/1/0/all/0/1">T. Greg McKelvey</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1">Hui Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sontag_D/0/1/0/all/0/1">David Sontag</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02524">
                                    <div class="article-summary-box-inner">
                                        <span>Continuity of care is crucial to ensuring positive health outcomes for
patients discharged from an inpatient hospital setting, and improved
information sharing can help. To share information, caregivers write discharge
notes containing action items to share with patients and their future
caregivers, but these action items are easily lost due to the lengthiness of
the documents. In this work, we describe our creation of a dataset of clinical
action items annotated over MIMIC-III, the largest publicly available dataset
of real clinical notes. This dataset, which we call CLIP, is annotated by
physicians and covers 718 documents representing 100K sentences. We describe
the task of extracting the action items from these documents as multi-aspect
extractive summarization, with each aspect representing a type of action to be
taken. We evaluate several machine learning models on this task, and show that
the best models exploit in-domain language model pre-training on 59K
unannotated documents, and incorporate context from neighboring sentences. We
also propose an approach to pre-training data selection that allows us to
explore the trade-off between size and domain-specificity of pre-training
datasets for this task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online reinforcement learning with sparse rewards through an active inference capsule. (arXiv:2106.02390v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Noel_A/0/1/0/all/0/1">Alejandro Daniel Noel</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Hoof_C/0/1/0/all/0/1">Charel van Hoof</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Millidge_B/0/1/0/all/0/1">Beren Millidge</a> (2) ((1) Delft University of Technology, (2) University of Oxford)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02390">
                                    <div class="article-summary-box-inner">
                                        <span>Intelligent agents must pursue their goals in complex environments with
partial information and often limited computational capacity. Reinforcement
learning methods have achieved great success by creating agents that optimize
engineered reward functions, but which often struggle to learn in sparse-reward
environments, generally require many environmental interactions to perform
well, and are typically computationally very expensive. Active inference is a
model-based approach that directs agents to explore uncertain states while
adhering to a prior model of their goal behaviour. This paper introduces an
active inference agent which minimizes the novel free energy of the expected
future. Our model is capable of solving sparse-reward problems with a very high
sample efficiency due to its objective function, which encourages directed
exploration of uncertain states. Moreover, our model is computationally very
light and can operate in a fully online manner while achieving comparable
performance to offline RL methods. We showcase the capabilities of our model by
solving the mountain car problem, where we demonstrate its superior exploration
properties and its robustness to observation noise, which in fact improves
performance. We also introduce a novel method for approximating the prior model
from the reward function, which simplifies the expression of complex objectives
and improves performance over previous active inference approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Earth Mover&#x27;s Pinball Loss: Quantiles for Histogram-Valued Regression. (arXiv:2106.02051v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+List_F/0/1/0/all/0/1">Florian List</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02051">
                                    <div class="article-summary-box-inner">
                                        <span>Although ubiquitous in the sciences, histogram data have not received much
attention by the Deep Learning community. Whilst regression and classification
tasks for scalar and vector data are routinely solved by neural networks, a
principled approach for estimating histogram labels as a function of an input
vector or image is lacking in the literature. We present a dedicated method for
Deep Learning-based histogram regression, which incorporates cross-bin
information and yields distributions over possible histograms, expressed by
$\tau$-quantiles of the cumulative histogram in each bin. The crux of our
approach is a new loss function obtained by applying the pinball loss to the
cumulative histogram, which for 1D histograms reduces to the Earth Mover&#x27;s
distance (EMD) in the special case of the median ($\tau &#x3D; 0.5$), and
generalizes it to arbitrary quantiles. We validate our method with an
illustrative toy example, a football-related task, and an astrophysical
computer vision problem. We show that with our loss function, the accuracy of
the predicted median histograms is very similar to the standard EMD case (and
higher than for per-bin loss functions such as cross-entropy), while the
predictions become much more informative at almost no additional computational
cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How to select and use tools? : Active Perception of Target Objects Using Multimodal Deep Learning. (arXiv:2106.02445v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saito_N/0/1/0/all/0/1">Namiko Saito</a>, <a href="http://arxiv.org/find/cs/1/au:+Ogata_T/0/1/0/all/0/1">Tetsuya Ogata</a>, <a href="http://arxiv.org/find/cs/1/au:+Funabashi_S/0/1/0/all/0/1">Satoshi Funabashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mori_H/0/1/0/all/0/1">Hiroki Mori</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugano_S/0/1/0/all/0/1">Shigeki Sugano</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02445">
                                    <div class="article-summary-box-inner">
                                        <span>Selection of appropriate tools and use of them when performing daily tasks is
a critical function for introducing robots for domestic applications. In
previous studies, however, adaptability to target objects was limited, making
it difficult to accordingly change tools and adjust actions. To manipulate
various objects with tools, robots must both understand tool functions and
recognize object characteristics to discern a tool-object-action relation. We
focus on active perception using multimodal sensorimotor data while a robot
interacts with objects, and allow the robot to recognize their extrinsic and
intrinsic characteristics. We construct a deep neural networks (DNN) model that
learns to recognize object characteristics, acquires tool-object-action
relations, and generates motions for tool selection and handling. As an example
tool-use situation, the robot performs an ingredients transfer task, using a
turner or ladle to transfer an ingredient from a pot to a bowl. The results
confirm that the robot recognizes object characteristics and servings even when
the target ingredients are unknown. We also examine the contributions of
images, force, and tactile data and show that learning a variety of multimodal
information results in rich perception for tool use.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum Perceptron Revisited: Computational-Statistical Tradeoffs. (arXiv:2106.02496v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Roget_M/0/1/0/all/0/1">Mathieu Roget</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Molfetta_G/0/1/0/all/0/1">Giuseppe Di Molfetta</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kadri_H/0/1/0/all/0/1">Hachem Kadri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02496">
                                    <div class="article-summary-box-inner">
                                        <span>Quantum machine learning algorithms could provide significant speed-ups over
their classical counterparts; however, whether they could also achieve good
generalization remains unclear. Recently, two quantum perceptron models which
give a quadratic improvement over the classical perceptron algorithm using
Grover&#x27;s search have been proposed by Wiebe et al. arXiv:1602.04799 . While the
first model reduces the complexity with respect to the size of the training
set, the second one improves the bound on the number of mistakes made by the
perceptron. In this paper, we introduce a hybrid quantum-classical perceptron
algorithm with lower complexity and better generalization ability than the
classical perceptron. We show a quadratic improvement over the classical
perceptron in both the number of samples and the margin of the data. We derive
a bound on the expected error of the hypothesis returned by our algorithm,
which compares favorably to the one obtained with the classical online
perceptron. We use numerical experiments to illustrate the trade-off between
computational complexity and statistical accuracy in quantum perceptron
learning and discuss some of the key practical issues surrounding the
implementation of quantum perceptron models into near-term quantum devices,
whose practical implementation represents a serious challenge due to inherent
noise. However, the potential benefits make correcting this worthwhile.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">F-Drop&amp;Match: GANs with a Dead Zone in the High-Frequency Domain. (arXiv:2106.02343v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yamaguchi_S/0/1/0/all/0/1">Shin&#x27;ya Yamaguchi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanai_S/0/1/0/all/0/1">Sekitoshi Kanai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02343">
                                    <div class="article-summary-box-inner">
                                        <span>Generative adversarial networks built from deep convolutional neural networks
(GANs) lack the ability to exactly replicate the high-frequency components of
natural images. To alleviate this issue, we introduce two novel training
techniques called frequency dropping (F-Drop) and frequency matching (F-Match).
The key idea of F-Drop is to filter out unnecessary high-frequency components
from the input images of the discriminators. This simple modification prevents
the discriminators from being confused by perturbations of the high-frequency
components. In addition, F-Drop makes the GANs focus on fitting in the
low-frequency domain, in which there are the dominant components of natural
images. F-Match minimizes the difference between real and fake images in the
frequency domain for generating more realistic images. F-Match is implemented
as a regularization term in the objective functions of the generators; it
penalizes the batch mean error in the frequency domain. F-Match helps the
generators to fit in the high-frequency domain filtered out by F-Drop to the
real image. We experimentally demonstrate that the combination of F-Drop and
F-Match improves the generative performance of GANs in both the frequency and
spatial domain on multiple image benchmarks (CIFAR, TinyImageNet, STL-10,
CelebA, and ImageNet).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Debiasing a First-order Heuristic for Approximate Bi-level Optimization. (arXiv:2106.02487v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Likhosherstov_V/0/1/0/all/0/1">Valerii Likhosherstov</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1">Xingyou Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1">Krzysztof Choromanski</a>, <a href="http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1">Jared Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1">Adrian Weller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02487">
                                    <div class="article-summary-box-inner">
                                        <span>Approximate bi-level optimization (ABLO) consists of (outer-level)
optimization problems, involving numerical (inner-level) optimization loops.
While ABLO has many applications across deep learning, it suffers from time and
memory complexity proportional to the length $r$ of its inner optimization
loop. To address this complexity, an earlier first-order method (FOM) was
proposed as a heuristic that omits second derivative terms, yielding
significant speed gains and requiring only constant memory. Despite FOM&#x27;s
popularity, there is a lack of theoretical understanding of its convergence
properties. We contribute by theoretically characterizing FOM&#x27;s gradient bias
under mild assumptions. We further demonstrate a rich family of examples where
FOM-based SGD does not converge to a stationary point of the ABLO objective. We
address this concern by proposing an unbiased FOM (UFOM) enjoying constant
memory complexity as a function of $r$. We characterize the introduced
time-variance tradeoff, demonstrate convergence bounds, and find an optimal
UFOM for a given ABLO problem. Finally, we propose an efficient adaptive UFOM
scheme.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Dialogue Learning for Spoken Conversational Question Answering. (arXiv:2106.02182v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_N/0/1/0/all/0/1">Nuo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+You_C/0/1/0/all/0/1">Chenyu You</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_Y/0/1/0/all/0/1">Yuexian Zou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02182">
                                    <div class="article-summary-box-inner">
                                        <span>In spoken conversational question answering (SCQA), the answer to the
corresponding question is generated by retrieving and then analyzing a fixed
spoken document, including multi-part conversations. Most SCQA systems have
considered only retrieving information from ordered utterances. However, the
sequential order of dialogue is important to build a robust spoken
conversational question answering system, and the changes of utterances order
may severely result in low-quality and incoherent corpora. To this end, we
introduce a self-supervised learning approach, including incoherence
discrimination, insertion detection, and question prediction, to explicitly
capture the coreference resolution and dialogue coherence among spoken
documents. Specifically, we design a joint learning framework where the
auxiliary self-supervised tasks can enable the pre-trained SCQA systems towards
more coherent and meaningful spoken dialogue learning. We also utilize the
proposed self-supervised learning tasks to capture intra-sentence coherence.
Experimental results demonstrate that our proposed method provides more
coherent, meaningful, and appropriate responses, yielding superior performance
gains compared to the original pre-trained language models. Our method achieves
state-of-the-art results on the Spoken-CoQA dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fre-GAN: Adversarial Frequency-consistent Audio Synthesis. (arXiv:2106.02297v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1">Ji-Hoon Kim</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1">Sang-Hoon Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_J/0/1/0/all/0/1">Ji-Hyun Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_S/0/1/0/all/0/1">Seong-Whan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02297">
                                    <div class="article-summary-box-inner">
                                        <span>Although recent works on neural vocoder have improved the quality of
synthesized audio, there still exists a gap between generated and ground-truth
audio in frequency space. This difference leads to spectral artifacts such as
hissing noise or robotic sound, and thus degrades the sample quality. In this
paper, we propose Fre-GAN which achieves frequency-consistent audio synthesis
with highly improved generation quality. Specifically, we first present
resolution-connected generator and resolution-wise discriminators, which help
learn various scales of spectral distributions over multiple frequency bands.
Additionally, to reproduce high-frequency components accurately, we leverage
discrete wavelet transform in the discriminators. From our experiments, Fre-GAN
achieves high-fidelity waveform generation with a gap of only 0.03 MOS compared
to ground-truth audio while outperforming standard models in quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Heterogeneous Noisy Short Signal Camouflage in Multi-Domain Environment Decision-Making. (arXiv:2106.02044v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1">Piyush K. Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02044">
                                    <div class="article-summary-box-inner">
                                        <span>Data transmission between two or more digital devices in industry and
government demands secure and agile technology. Digital information
distribution often requires deployment of Internet of Things (IoT) devices and
Data Fusion techniques which have also gained popularity in both, civilian and
military environments, such as, emergence of Smart Cities and Internet of
Battlefield Things (IoBT). This usually requires capturing and consolidating
data from multiple sources. Because datasets do not necessarily originate from
identical sensors, fused data typically results in a complex Big Data problem.
Due to potentially sensitive nature of IoT datasets, Blockchain technology is
used to facilitate secure sharing of IoT datasets, which allows digital
information to be distributed, but not copied. However, blockchain has several
limitations related to complexity, scalability, and excessive energy
consumption. We propose an approach to hide information (sensor signal) by
transforming it to an image or an audio signal. In one of the latest attempts
to the military modernization, we investigate sensor fusion approach by
investigating the challenges of enabling an intelligent identification and
detection operation and demonstrates the feasibility of the proposed Deep
Learning and Anomaly Detection models that can support future application for
specific hand gesture alert system from wearable devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Next Generation Multitarget Trackers: Random Finite Set Methods vs Transformer-based Deep Learning. (arXiv:2104.00734v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pinto_J/0/1/0/all/0/1">Juliano Pinto</a>, <a href="http://arxiv.org/find/cs/1/au:+Hess_G/0/1/0/all/0/1">Georg Hess</a>, <a href="http://arxiv.org/find/cs/1/au:+Ljungbergh_W/0/1/0/all/0/1">William Ljungbergh</a>, <a href="http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1">Yuxuan Xia</a>, <a href="http://arxiv.org/find/cs/1/au:+Svensson_L/0/1/0/all/0/1">Lennart Svensson</a>, <a href="http://arxiv.org/find/cs/1/au:+Wymeersch_H/0/1/0/all/0/1">Henk Wymeersch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.00734">
                                    <div class="article-summary-box-inner">
                                        <span>Multitarget Tracking (MTT) is the problem of tracking the states of an
unknown number of objects using noisy measurements, with important applications
to autonomous driving, surveillance, robotics, and others. In the model-based
Bayesian setting, there are conjugate priors that enable us to express the
multi-object posterior in closed form, which could theoretically provide
Bayes-optimal estimates. However, the posterior involves a super-exponential
growth of the number of hypotheses over time, forcing state-of-the-art methods
to resort to approximations for remaining tractable, which can impact their
performance in complex scenarios. Model-free methods based on deep-learning
provide an attractive alternative, as they can, in principle, learn the optimal
filter from data, but to the best of our knowledge were never compared to
current state-of-the-art Bayesian filters, specially not in contexts where
accurate models are available. In this paper, we propose a high-performing
deep-learning method for MTT based on the Transformer architecture and compare
it to two state-of-the-art Bayesian filters, in a setting where we assume the
correct model is provided. Although this gives an edge to the model-based
filters, it also allows us to generate unlimited training data. We show that
the proposed model outperforms state-of-the-art Bayesian filters in complex
scenarios, while matching their performance in simpler cases, which validates
the applicability of deep-learning also in the model-based regime. The code for
all our implementations is made available at
https://github.com/JulianoLagana/MT3 .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near-Optimal Confidence Sequences for Bounded Random Variables. (arXiv:2006.05022v3 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Kuchibhotla_A/0/1/0/all/0/1">Arun Kumar Kuchibhotla</a>, <a href="http://arxiv.org/find/math/1/au:+Zheng_Q/0/1/0/all/0/1">Qinqing Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05022">
                                    <div class="article-summary-box-inner">
                                        <span>Many inference problems, such as sequential decision problems like A/B
testing, adaptive sampling schemes like bandit selection, are often online in
nature. The fundamental problem for online inference is to provide a sequence
of confidence intervals that are valid uniformly over the growing-into-infinity
sample sizes. To address this question, we provide a near-optimal confidence
sequence for bounded random variables by utilizing Bentkus&#x27; concentration
results. We show that it improves on the existing approaches that use the
Cram{\&#x27;e}r-Chernoff technique such as the Hoeffding, Bernstein, and Bennett
inequalities. The resulting confidence sequence is confirmed to be favorable in
both synthetic coverage problems and an application to adaptive stopping
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Learning via Persistency of Excitation. (arXiv:2106.02078v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Sridhar_K/0/1/0/all/0/1">Kaustubh Sridhar</a>, <a href="http://arxiv.org/find/stat/1/au:+Sokolsky_O/0/1/0/all/0/1">Oleg Sokolsky</a>, <a href="http://arxiv.org/find/stat/1/au:+Lee_I/0/1/0/all/0/1">Insup Lee</a>, <a href="http://arxiv.org/find/stat/1/au:+Weimer_J/0/1/0/all/0/1">James Weimer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02078">
                                    <div class="article-summary-box-inner">
                                        <span>Improving adversarial robustness of neural networks remains a major
challenge. Fundamentally, training a network is a parameter estimation problem.
In adaptive control theory, maintaining persistency of excitation (PoE) is
integral to ensuring convergence of parameter estimates in dynamical systems to
their robust optima. In this work, we show that network training using gradient
descent is equivalent to a dynamical system parameter estimation problem.
Leveraging this relationship, we prove a sufficient condition for PoE of
gradient descent is achieved when the learning rate is less than the inverse of
the Lipschitz constant of the gradient of loss function. We provide an
efficient technique for estimating the corresponding Lipschitz constant using
extreme value theory and demonstrate that by only scaling the learning rate
schedule we can increase adversarial accuracy by up to 15% on benchmark
datasets. Our approach also universally increases the adversarial accuracy by
0.1% to 0.3% in various state-of-the-art adversarially trained models on the
AutoAttack benchmark, where every small margin of improvement is significant.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Musical Prosody-Driven Emotion Classification: Interpreting Vocalists Portrayal of Emotions Through Machine Learning. (arXiv:2106.02556v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nicholas_F/0/1/0/all/0/1">Farris Nicholas</a>, <a href="http://arxiv.org/find/cs/1/au:+Brian_M/0/1/0/all/0/1">Model Brian</a>, <a href="http://arxiv.org/find/cs/1/au:+Richard_S/0/1/0/all/0/1">Savery Richard</a>, <a href="http://arxiv.org/find/cs/1/au:+Gil_W/0/1/0/all/0/1">Weinberg Gil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02556">
                                    <div class="article-summary-box-inner">
                                        <span>The task of classifying emotions within a musical track has received
widespread attention within the Music Information Retrieval (MIR) community.
Music emotion recognition has traditionally relied on the use of acoustic
features, verbal features, and metadata-based filtering. The role of musical
prosody remains under-explored despite several studies demonstrating a strong
connection between prosody and emotion. In this study, we restrict the input of
traditional machine learning algorithms to the features of musical prosody.
Furthermore, our proposed approach builds upon the prior by classifying
emotions under an expanded emotional taxonomy, using the Geneva Wheel of
Emotion. We utilize a methodology for individual data collection from
vocalists, and personal ground truth labeling by the artist themselves. We
found that traditional machine learning algorithms when limited to the features
of musical prosody (1) achieve high accuracies for a single singer, (2)
maintain high accuracy when the dataset is expanded to multiple singers, and
(3) achieve high accuracies when trained on a reduced subset of the total
features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Strategyproof Learning: Building Trustworthy User-Generated Datasets. (arXiv:2106.02398v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Farhadkhani_S/0/1/0/all/0/1">Sadegh Farhadkhani</a>, <a href="http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1">Rachid Guerraoui</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoang_L/0/1/0/all/0/1">L&#xea;-Nguy&#xea;n Hoang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02398">
                                    <div class="article-summary-box-inner">
                                        <span>Today&#x27;s large-scale machine learning algorithms harness massive amounts of
user-generated data to train large models. However, especially in the context
of content recommendation with enormous social, economical and political
incentives to promote specific views, products or ideologies, strategic users
might be tempted to fabricate or mislabel data in order to bias algorithms in
their favor. Unfortunately, today&#x27;s learning schemes strongly incentivize such
strategic data misreporting. This is a major concern, as it endangers the
trustworthiness of the entire training datasets, and questions the safety of
any algorithm trained on such datasets. In this paper, we show that, perhaps
surprisingly, incentivizing data misreporting is not a fatality. We propose the
first personalized collaborative learning framework, Licchavi, with provable
strategyproofness guarantees through a careful design of the underlying loss
function. Interestingly, we also prove that Licchavi is Byzantine resilient: it
tolerates a minority of users that provide arbitrary data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Local Adaptivity in Federated Learning: Convergence and Consistency. (arXiv:2106.02305v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jianyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Garrett_Z/0/1/0/all/0/1">Zachary Garrett</a>, <a href="http://arxiv.org/find/cs/1/au:+Charles_Z/0/1/0/all/0/1">Zachary Charles</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Luyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_G/0/1/0/all/0/1">Gauri Joshi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02305">
                                    <div class="article-summary-box-inner">
                                        <span>The federated learning (FL) framework trains a machine learning model using
decentralized data stored at edge client devices by periodically aggregating
locally trained models. Popular optimization algorithms of FL use vanilla
(stochastic) gradient descent for both local updates at clients and global
updates at the aggregating server. Recently, adaptive optimization methods such
as AdaGrad have been studied for server updates. However, the effect of using
adaptive optimization methods for local updates at clients is not yet
understood. We show in both theory and practice that while local adaptive
methods can accelerate convergence, they can cause a non-vanishing solution
bias, where the final converged solution may be different from the stationary
point of the global objective function. We propose correction techniques to
overcome this inconsistency and complement the local adaptive methods for FL.
Extensive experiments on realistic federated training tasks show that the
proposed algorithms can achieve faster convergence and higher test accuracy
than the baselines without local adaptivity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COLD: Concurrent Loads Disaggregator for Non-Intrusive Load Monitoring. (arXiv:2106.02352v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kamyshev_I/0/1/0/all/0/1">Ilia Kamyshev</a>, <a href="http://arxiv.org/find/eess/1/au:+Kriukov_D/0/1/0/all/0/1">Dmitrii Kriukov</a>, <a href="http://arxiv.org/find/eess/1/au:+Gryazina_E/0/1/0/all/0/1">Elena Gryazina</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02352">
                                    <div class="article-summary-box-inner">
                                        <span>The modern artificial intelligence techniques show the outstanding
performances in the field of Non-Intrusive Load Monitoring (NILM). However, the
problem related to the identification of a large number of appliances working
simultaneously is underestimated. One of the reasons is the absence of a
specific data. In this research we propose the Synthesizer of Normalized
Signatures (SNS) algorithm to simulate the aggregated consumption with up to 10
concurrent loads. The results show that the synthetic data provides the models
with at least as a powerful identification accuracy as the real-world
measurements. We have developed the neural architecture named Concurrent Loads
Disaggregator (COLD) which is relatively simple and easy to understand in
comparison to the previous approaches. Our model allows identifying from 1 to
10 appliances working simultaneously with mean F1-score 78.95%. The source code
of the experiments performed is available at
https://github.com/arx7ti/cold-nilm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differentiable Dynamic Quantization with Mixed Precision and Adaptive Resolution. (arXiv:2106.02295v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhaoyang_Z/0/1/0/all/0/1">Zhang Zhaoyang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wenqi_S/0/1/0/all/0/1">Shao Wenqi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jinwei_G/0/1/0/all/0/1">Gu Jinwei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiaogang_W/0/1/0/all/0/1">Wang Xiaogang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_L/0/1/0/all/0/1">Luo Ping</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02295">
                                    <div class="article-summary-box-inner">
                                        <span>Model quantization is challenging due to many tedious hyper-parameters such
as precision (bitwidth), dynamic range (minimum and maximum discrete values)
and stepsize (interval between discrete values). Unlike prior arts that
carefully tune these values, we present a fully differentiable approach to
learn all of them, named Differentiable Dynamic Quantization (DDQ), which has
several benefits. (1) DDQ is able to quantize challenging lightweight
architectures like MobileNets, where different layers prefer different
quantization parameters. (2) DDQ is hardware-friendly and can be easily
implemented using low-precision matrix-vector multiplication, making it capable
in many hardware such as ARM. (3) Extensive experiments show that DDQ
outperforms prior arts on many networks and benchmarks, especially when models
are already efficient and compact. e.g., DDQ is the first approach that
achieves lossless 4-bit quantization for MobileNetV2 on ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning domain-agnostic visual representation for computational pathology using medically-irrelevant style transfer augmentation. (arXiv:2102.01678v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yamashita_R/0/1/0/all/0/1">Rikiya Yamashita</a>, <a href="http://arxiv.org/find/eess/1/au:+Long_J/0/1/0/all/0/1">Jin Long</a>, <a href="http://arxiv.org/find/eess/1/au:+Banda_S/0/1/0/all/0/1">Snikitha Banda</a>, <a href="http://arxiv.org/find/eess/1/au:+Shen_J/0/1/0/all/0/1">Jeanne Shen</a>, <a href="http://arxiv.org/find/eess/1/au:+Rubin_D/0/1/0/all/0/1">Daniel L. Rubin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01678">
                                    <div class="article-summary-box-inner">
                                        <span>Suboptimal generalization of machine learning models on unseen data is a key
challenge which hampers the clinical applicability of such models to medical
imaging. Although various methods such as domain adaptation and domain
generalization have evolved to combat this challenge, learning robust and
generalizable representations is core to medical image understanding, and
continues to be a problem. Here, we propose STRAP (Style TRansfer Augmentation
for histoPathology), a form of data augmentation based on random style transfer
from non-medical style source such as artistic paintings, for learning
domain-agnostic visual representations in computational pathology. Style
transfer replaces the low-level texture content of an image with the
uninformative style of randomly selected style source image, while preserving
the original high-level semantic content. This improves robustness to domain
shift and can be used as a simple yet powerful tool for learning
domain-agnostic representations. We demonstrate that STRAP leads to
state-of-the-art performance, particularly in the presence of domain shifts, on
two particular classification tasks in computational pathology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transferable and Distributed User Association Policies for 5G and Beyond Networks. (arXiv:2106.02540v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sana_M/0/1/0/all/0/1">Mohamed Sana</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietro_N/0/1/0/all/0/1">Nicola di Pietro</a>, <a href="http://arxiv.org/find/cs/1/au:+Strinati_E/0/1/0/all/0/1">Emilio Calvanese Strinati</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02540">
                                    <div class="article-summary-box-inner">
                                        <span>We study the problem of user association, namely finding the optimal
assignment of user equipment to base stations to achieve a targeted network
performance. In this paper, we focus on the knowledge transferability of
association policies. Indeed, traditional non-trivial user association schemes
are often scenario-specific or deployment-specific and require a policy
re-design or re-learning when the number or the position of the users change.
In contrast, transferability allows to apply a single user association policy,
devised for a specific scenario, to other distinct user deployments, without
needing a substantial re-learning or re-design phase and considerably reducing
its computational and management complexity. To achieve transferability, we
first cast user association as a multi-agent reinforcement learning problem.
Then, based on a neural attention mechanism that we specifically conceived for
this context, we propose a novel distributed policy network architecture, which
is transferable among users with zero-shot generalization capability i.e.,
without requiring additional training.Numerical results show the effectiveness
of our solution in terms of overall network communication rate, outperforming
centralized benchmarks even when the number of users doubles with respect to
the initial training point.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shape-Preserving Dimensionality Reduction : An Algorithm and Measures of Topological Equivalence. (arXiv:2106.02096v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1">Byeongsu Yu</a>, <a href="http://arxiv.org/find/stat/1/au:+You_K/0/1/0/all/0/1">Kisung You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02096">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a linear dimensionality reduction technique preserving
topological features via persistent homology. The method is designed to find
linear projection $L$ which preserves the persistent diagram of a point cloud
$\mathbb{X}$ via simulated annealing. The projection $L$ induces a set of
canonical simplicial maps from the Rips (or \v{C}ech) filtration of
$\mathbb{X}$ to that of $L\mathbb{X}$. In addition to the distance between
persistent diagrams, the projection induces a map between filtrations, called
filtration homomorphism. Using the filtration homomorphism, one can measure the
difference between shapes of two filtrations directly comparing simplicial
complexes with respect to quasi-isomorphism $\mu_{\operatorname{quasi-iso}}$ or
strong homotopy equivalence $\mu_{\operatorname{equiv}}$. These
$\mu_{\operatorname{quasi-iso}}$ and $\mu_{\operatorname{equiv}}$ measures how
much portion of corresponding simplicial complexes is quasi-isomorphic or
homotopy equivalence respectively. We validate the effectiveness of our
framework with simple examples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Hard Optimization Problems: A Data Generation Perspective. (arXiv:2106.02601v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Kotary_J/0/1/0/all/0/1">James Kotary</a>, <a href="http://arxiv.org/find/math/1/au:+Fioretto_F/0/1/0/all/0/1">Ferdinando Fioretto</a>, <a href="http://arxiv.org/find/math/1/au:+Hentenryck_P/0/1/0/all/0/1">Pascal Van Hentenryck</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02601">
                                    <div class="article-summary-box-inner">
                                        <span>Optimization problems are ubiquitous in our societies and are present in
almost every segment of the economy. Most of these optimization problems are
NP-hard and computationally demanding, often requiring approximate solutions
for large-scale instances. Machine learning frameworks that learn to
approximate solutions to such hard optimization problems are a potentially
promising avenue to address these difficulties, particularly when many closely
related problem instances must be solved repeatedly. Supervised learning
frameworks can train a model using the outputs of pre-solved instances.
However, when the outputs are themselves approximations, when the optimization
problem has symmetric solutions, and/or when the solver uses randomization,
solutions to closely related instances may exhibit large differences and the
learning task can become inherently more difficult. This paper demonstrates
this critical challenge, connects the volatility of the training data to the
ability of a model to approximate it, and proposes a method for producing
(exact or approximate) solutions to optimization problems that are more
amenable to supervised learning tasks. The effectiveness of the method is
tested on hard non-linear nonconvex and discrete combinatorial problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Slice-Aware Representations with Mixture of Attentions. (arXiv:2106.02363v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1">Sungjin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1">Sunghyun Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Han Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1">Young-Bum Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarikaya_R/0/1/0/all/0/1">Ruhi Sarikaya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02363">
                                    <div class="article-summary-box-inner">
                                        <span>Real-world machine learning systems are achieving remarkable performance in
terms of coarse-grained metrics like overall accuracy and F-1 score. However,
model improvement and development often require fine-grained modeling on
individual data subsets or slices, for instance, the data slices where the
models have unsatisfactory results. In practice, it gives tangible values for
developing such models that can pay extra attention to critical or interested
slices while retaining the original overall performance. This work extends the
recent slice-based learning (SBL)~\cite{chen2019slice} with a mixture of
attentions (MoA) to learn slice-aware dual attentive representations. We
empirically show that the MoA approach outperforms the baseline method as well
as the original SBL approach on monitored slices with two natural language
understanding (NLU) tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fluctuation-dissipation Type Theorem in Stochastic Linear Learning. (arXiv:2106.02220v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_M/0/1/0/all/0/1">Manhyung Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jeonghyeok Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1">Taewoong Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jung Hoon Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02220">
                                    <div class="article-summary-box-inner">
                                        <span>The fluctuation-dissipation theorem (FDT) is a simple yet powerful
consequence of the first-order differential equation governing the dynamics of
systems subject simultaneously to dissipative and stochastic forces. The linear
learning dynamics, in which the input vector maps to the output vector by a
linear matrix whose elements are the subject of learning, has a stochastic
version closely mimicking the Langevin dynamics when a full-batch gradient
descent scheme is replaced by that of stochastic gradient descent. We derive a
generalized FDT for the stochastic linear learning dynamics and verify its
validity among the well-known machine learning data sets such as MNIST,
CIFAR-10 and EMNIST.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning. (arXiv:2106.02097v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mingde Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhen Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luan_S/0/1/0/all/0/1">Sitao Luan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shuyuan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1">Doina Precup</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02097">
                                    <div class="article-summary-box-inner">
                                        <span>We present an end-to-end, model-based deep reinforcement learning agent which
dynamically attends to relevant parts of its state, in order to plan and to
generalize better out-of-distribution. The agent&#x27;s architecture uses a set
representation and a bottleneck mechanism, forcing the number of entities to
which the agent attends at each planning step to be small. In experiments with
customized MiniGrid environments with different dynamics, we observe that the
design allows agents to learn to plan effectively, by attending to the relevant
objects, leading to better out-of-distribution generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Architecture Search via Bregman Iterations. (arXiv:2106.02479v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bungert_L/0/1/0/all/0/1">Leon Bungert</a>, <a href="http://arxiv.org/find/cs/1/au:+Roith_T/0/1/0/all/0/1">Tim Roith</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenbrinck_D/0/1/0/all/0/1">Daniel Tenbrinck</a>, <a href="http://arxiv.org/find/cs/1/au:+Burger_M/0/1/0/all/0/1">Martin Burger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02479">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel strategy for Neural Architecture Search (NAS) based on
Bregman iterations. Starting from a sparse neural network our gradient-based
one-shot algorithm gradually adds relevant parameters in an inverse scale space
manner. This allows the network to choose the best architecture in the search
space which makes it well-designed for a given task, e.g., by adding neurons or
skip connections. We demonstrate that using our approach one can unveil, for
instance, residual autoencoders for denoising, deblurring, and classification
tasks. Code is available at https://github.com/TimRoith/BregmanLearning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Little Robustness Goes a Long Way: Leveraging Universal Features for Targeted Transfer Attacks. (arXiv:2106.02105v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Springer_J/0/1/0/all/0/1">Jacob M. Springer</a>, <a href="http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1">Melanie Mitchell</a>, <a href="http://arxiv.org/find/cs/1/au:+Kenyon_G/0/1/0/all/0/1">Garrett T. Kenyon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02105">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial examples for neural network image classifiers are known to be
transferable: examples optimized to be misclassified by a source classifier are
often misclassified as well by classifiers with different architectures.
However, targeted adversarial examples -- optimized to be classified as a
chosen target class -- tend to be less transferable between architectures.
While prior research on constructing transferable targeted attacks has focused
on improving the optimization procedure, in this work we examine the role of
the source classifier. Here, we show that training the source classifier to be
&quot;slightly robust&quot; -- that is, robust to small-magnitude adversarial examples --
substantially improves the transferability of targeted attacks, even between
architectures as different as convolutional neural networks and transformers.
We argue that this result supports a non-intuitive hypothesis: on the spectrum
from non-robust (standard) to highly robust classifiers, those that are only
slightly robust exhibit the most universal features -- ones that tend to
overlap with the features learned by other classifiers trained on the same
dataset. The results we present provide insight into the nature of adversarial
examples as well as the mechanisms underlying so-called &quot;robust&quot; classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Celebrating Diversity in Shared Multi-Agent Reinforcement Learning. (arXiv:2106.02195v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenghao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+WU_C/0/1/0/all/0/1">Chengjie WU</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tonghan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1">Qianchuan Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chongjie Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02195">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, deep multi-agent reinforcement learning (MARL) has shown the
promise to solve complex cooperative tasks. Its success is partly because of
parameter sharing among agents. However, such sharing may lead agents to behave
similarly and limit their coordination capacity. In this paper, we aim to
introduce diversity in both optimization and representation of shared
multi-agent reinforcement learning. Specifically, we propose an
information-theoretical regularization to maximize the mutual information
between agents&#x27; identities and their trajectories, encouraging extensive
exploration and diverse individualized behaviors. In representation, we
incorporate agent-specific modules in the shared neural network architecture,
which are regularized by L1-norm to promote learning sharing among agents while
keeping necessary diversity. Empirical results show that our method achieves
state-of-the-art performance on Google Research Football and super hard
StarCraft II micromanagement tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Surprising Power of Graph Neural Networks with Random Node Initialization. (arXiv:2010.01179v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abboud_R/0/1/0/all/0/1">Ralph Abboud</a>, <a href="http://arxiv.org/find/cs/1/au:+Ceylan_I/0/1/0/all/0/1">&#x130;smail &#x130;lkan Ceylan</a>, <a href="http://arxiv.org/find/cs/1/au:+Grohe_M/0/1/0/all/0/1">Martin Grohe</a>, <a href="http://arxiv.org/find/cs/1/au:+Lukasiewicz_T/0/1/0/all/0/1">Thomas Lukasiewicz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01179">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks (GNNs) are effective models for representation learning
on relational data. However, standard GNNs are limited in their expressive
power, as they cannot distinguish graphs beyond the capability of the
Weisfeiler-Leman graph isomorphism heuristic. In order to break this
expressiveness barrier, GNNs have been enhanced with random node initialization
(RNI), where the idea is to train and run the models with randomized initial
node features. In this work, we analyze the expressive power of GNNs with RNI,
and prove that these models are universal, a first such result for GNNs not
relying on computationally demanding higher-order properties. This universality
result holds even with partially randomized initial node features, and
preserves the invariance properties of GNNs in expectation. We then empirically
analyze the effect of RNI on GNNs, based on carefully constructed datasets. Our
empirical findings support the superior performance of GNNs with RNI over
standard GNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The impact of using biased performance metrics on software defect prediction research. (arXiv:2103.10201v3 [cs.SE] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1">Jingxiu Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shepperd_M/0/1/0/all/0/1">Martin Shepperd</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.10201">
                                    <div class="article-summary-box-inner">
                                        <span>Context: Software engineering researchers have undertaken many experiments
investigating the potential of software defect prediction algorithms.
Unfortunately, some widely used performance metrics are known to be
problematic, most notably F1, but nevertheless F1 is widely used.

Objective: To investigate the potential impact of using F1 on the validity of
this large body of research.

Method: We undertook a systematic review to locate relevant experiments and
then extract all pairwise comparisons of defect prediction performance using F1
and the un-biased Matthews correlation coefficient (MCC).

Results: We found a total of 38 primary studies. These contain 12,471 pairs
of results. Of these, 21.95% changed direction when the MCC metric is used
instead of the biased F1 metric. Unfortunately, we also found evidence
suggesting that F1 remains widely used in software defect prediction research.

Conclusions: We reiterate the concerns of statisticians that the F1 is a
problematic metric outside of an information retrieval context, since we are
concerned about both classes (defect-prone and not defect-prone units). This
inappropriate usage has led to a substantial number (more than one fifth) of
erroneous (in terms of direction) results. Therefore we urge researchers to (i)
use an unbiased metric and (ii) publish detailed results including confusion
matrices such that alternative analyses become possible.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel Semi-supervised Framework for Call Center Agent Malpractice Detection via Neural Feature Learning. (arXiv:2106.02433v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href="http://arxiv.org/find/cs/1/au:+Iheme_L/0/1/0/all/0/1">Leonardo Obinna Iheme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02433">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents a practical solution to the problem of call center agent
malpractice. A semi-supervised framework comprising of non-linear power
transformation, neural feature learning and k-means clustering is outlined. We
put these building blocks together and tune the parameters so that the best
performance was obtained. The data used in the experiments is obtained from our
in-house call center. It is made up of recorded agent-customer conversations
which have been annotated using a convolutional neural network based segmenter.
The methods provided a means of tuning the parameters of the neural network to
achieve a desirable result. We show that, using our proposed framework, it is
possible to significantly reduce the malpractice classification error of a
k-means-only clustering model which would serve the same purpose. Additionally,
by presenting the amount of silence per call as a key performance indicator, we
show that the proposed system has enhanced agents performance at our call
center since deployment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Identifying Misinformation from Website Screenshots. (arXiv:2102.07849v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdali_S/0/1/0/all/0/1">Sara Abdali</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurav_R/0/1/0/all/0/1">Rutuja Gurav</a>, <a href="http://arxiv.org/find/cs/1/au:+Menon_S/0/1/0/all/0/1">Siddharth Menon</a>, <a href="http://arxiv.org/find/cs/1/au:+Fonseca_D/0/1/0/all/0/1">Daniel Fonseca</a>, <a href="http://arxiv.org/find/cs/1/au:+Entezari_N/0/1/0/all/0/1">Negin Entezari</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1">Neil Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1">Evangelos E. Papalexakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07849">
                                    <div class="article-summary-box-inner">
                                        <span>Can the look and the feel of a website give information about the
trustworthiness of an article? In this paper, we propose to use a promising,
yet neglected aspect in detecting the misinformativeness: the overall look of
the domain webpage. To capture this overall look, we take screenshots of news
articles served by either misinformative or trustworthy web domains and
leverage a tensor decomposition based semi-supervised classification technique.
The proposed approach i.e., VizFake is insensitive to a number of image
transformations such as converting the image to grayscale, vectorizing the
image and losing some parts of the screenshots. VizFake leverages a very small
amount of known labels, mirroring realistic and practical scenarios, where
labels (especially for known misinformative articles), are scarce and quickly
become dated. The F1 score of VizFake on a dataset of 50k screenshots of news
articles spanning more than 500 domains is roughly 85% using only 5% of ground
truth labels. Furthermore, tensor representations of VizFake, obtained in an
unsupervised manner, allow for exploratory analysis of the data that provides
valuable insights into the problem. Finally, we compare VizFake with deep
transfer learning, since it is a very popular black-box approach for image
classification and also well-known text text-based methods. VizFake achieves
competitive accuracy with deep transfer learning models while being two orders
of magnitude faster and not requiring laborious hyper-parameter tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation. (arXiv:2106.02170v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bhati_S/0/1/0/all/0/1">Saurabhchand Bhati</a>, <a href="http://arxiv.org/find/eess/1/au:+Villalba_J/0/1/0/all/0/1">Jes&#xfa;s Villalba</a>, <a href="http://arxiv.org/find/eess/1/au:+Zelasko_P/0/1/0/all/0/1">Piotr &#x17b;elasko</a>, <a href="http://arxiv.org/find/eess/1/au:+Moro_Velazquez_L/0/1/0/all/0/1">Laureano Moro-Velazquez</a>, <a href="http://arxiv.org/find/eess/1/au:+Dehak_N/0/1/0/all/0/1">Najim Dehak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02170">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic detection of phoneme or word-like units is one of the core
objectives in zero-resource speech processing. Recent attempts employ
self-supervised training methods, such as contrastive predictive coding (CPC),
where the next frame is predicted given past context. However, CPC only looks
at the audio signal&#x27;s frame-level structure. We overcome this limitation with a
segmental contrastive predictive coding (SCPC) framework that can model the
signal structure at a higher level e.g. at the phoneme level. In this
framework, a convolutional neural network learns frame-level representation
from the raw waveform via noise-contrastive estimation (NCE). A differentiable
boundary detector finds variable-length segments, which are then used to
optimize a segment encoder via NCE to learn segment representations. The
differentiable boundary detector allows us to train frame-level and
segment-level encoders jointly. Typically, phoneme and word segmentation are
treated as separate tasks. We unify them and experimentally show that our
single model outperforms existing phoneme and word segmentation methods on
TIMIT and Buckeye datasets. We analyze the impact of boundary threshold and
when is the right time to include the segmental loss in the learning process.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">$\ell_2$-norm Flow Diffusion in Near-Linear Time. (arXiv:2105.14629v2 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Li Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_R/0/1/0/all/0/1">Richard Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Di Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14629">
                                    <div class="article-summary-box-inner">
                                        <span>Diffusion is a fundamental graph procedure and has been a basic building
block in a wide range of theoretical and empirical applications such as graph
partitioning and semi-supervised learning on graphs. In this paper, we study
computationally efficient diffusion primitives beyond random walk.

We design an $\widetilde{O}(m)$-time randomized algorithm for the
$\ell_2$-norm flow diffusion problem, a recently proposed diffusion model based
on network flow with demonstrated graph clustering related applications both in
theory and in practice. Examples include finding locally-biased low conductance
cuts. Using a known connection between the optimal dual solution of the flow
diffusion problem and the local cut structure, our algorithm gives an
alternative approach for finding such cuts in nearly linear time.

From a technical point of view, our algorithm contributes a novel way of
dealing with inequality constraints in graph optimization problems. It adapts
the high-level algorithmic framework of nearly linear time Laplacian system
solvers, but requires several new tools: vertex elimination under constraints,
a new family of graph ultra-sparsifiers, and accelerated proximal gradient
methods with inexact proximal mapping computation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Extreme sparsity gives rise to functional specialization. (arXiv:2106.02626v1 [q-bio.NC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Bena_G/0/1/0/all/0/1">Gabriel B&#xe9;na</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Goodman_D/0/1/0/all/0/1">Dan F. M. Goodman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02626">
                                    <div class="article-summary-box-inner">
                                        <span>Modularity of neural networks -- both biological and artificial -- can be
thought of either structurally or functionally, and the relationship between
these is an open question. We show that enforcing structural modularity via
sparse connectivity between two dense sub-networks which need to communicate to
solve the task leads to functional specialization of the sub-networks, but only
at extreme levels of sparsity. With even a moderate number of interconnections,
the sub-networks become functionally entangled. Defining functional
specialization is in itself a challenging problem without a universally agreed
solution. To address this, we designed three different measures of
specialization (based on weight masks, retraining and correlation) and found
them to qualitatively agree. Our results have implications in both neuroscience
and machine learning. For neuroscience, it shows that we cannot conclude that
there is functional modularity simply by observing moderate levels of
structural modularity: knowing the brain&#x27;s connectome is not sufficient for
understanding how it breaks down into functional modules. For machine learning,
using structure to promote functional modularity -- which may be important for
robustness and generalization -- may require extremely narrow bottlenecks
between modules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Incomplete Graph Representation and Learning via Partial Graph Neural Networks. (arXiv:2003.10130v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1">Bo Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Ziyan Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.10130">
                                    <div class="article-summary-box-inner">
                                        <span>Graph Neural Networks (GNNs) are gaining increasing attention on graph data
learning tasks in recent years. However, in many applications, graph may be
coming in an incomplete form where attributes of graph nodes are partially
unknown/missing. Existing GNNs are generally designed on complete graphs which
can not deal with attribute-incomplete graph data directly. To address this
problem, we develop a novel partial aggregation based GNNs, named Partial Graph
Neural Networks (PaGNNs), for attribute-incomplete graph representation and
learning. Our work is motivated by the observation that the neighborhood
aggregation function in standard GNNs can be equivalently viewed as the
neighborhood reconstruction formulation. Based on it, we define two novel
partial aggregation (reconstruction) functions on incomplete graph and derive
PaGNNs for incomplete graph data learning. Extensive experiments on several
datasets demonstrate the effectiveness and efficiency of the proposed PaGNNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Trajectory Representation Learning for Zero-Shot Generalization in RL. (arXiv:2106.02193v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mazoure_B/0/1/0/all/0/1">Bogdan Mazoure</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmed_A/0/1/0/all/0/1">Ahmed M. Ahmed</a>, <a href="http://arxiv.org/find/cs/1/au:+MacAlpine_P/0/1/0/all/0/1">Patrick MacAlpine</a>, <a href="http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1">R Devon Hjelm</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolobov_A/0/1/0/all/0/1">Andrey Kolobov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02193">
                                    <div class="article-summary-box-inner">
                                        <span>A highly desirable property of a reinforcement learning (RL) agent -- and a
major difficulty for deep RL approaches -- is the ability to generalize
policies learned on a few tasks over a high-dimensional observation space to
similar tasks not seen during training. Many promising approaches to this
challenge consider RL as a process of training two functions simultaneously: a
complex nonlinear encoder that maps high-dimensional observations to a latent
representation space, and a simple linear policy over this space. We posit that
a superior encoder for zero-shot generalization in RL can be trained by using
solely an auxiliary SSL objective if the training process encourages the
encoder to map behaviorally similar observations to similar representations, as
reward-based signal can cause overfitting in the encoder (Raileanu et al.,
2021). We propose Cross-Trajectory Representation Learning (CTRL), a method
that runs within an RL agent and conditions its encoder to recognize behavioral
similarity in observations by applying a novel SSL objective to pairs of
trajectories from the agent&#x27;s policies. CTRL can be viewed as having the same
effect as inducing a pseudo-bisimulation metric but, crucially, avoids the use
of rewards and associated overfitting risks. Our experiments ablate various
components of CTRL and demonstrate that in combination with PPO it achieves
better generalization performance on the challenging Procgen benchmark suite
(Cobbe et al., 2020).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Light Field Networks: Neural Scene Representations with Single-Evaluation Rendering. (arXiv:2106.02634v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sitzmann_V/0/1/0/all/0/1">Vincent Sitzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezchikov_S/0/1/0/all/0/1">Semon Rezchikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1">William T. Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1">Joshua B. Tenenbaum</a>, <a href="http://arxiv.org/find/cs/1/au:+Durand_F/0/1/0/all/0/1">Fredo Durand</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02634">
                                    <div class="article-summary-box-inner">
                                        <span>Inferring representations of 3D scenes from 2D observations is a fundamental
problem of computer graphics, computer vision, and artificial intelligence.
Emerging 3D-structured neural scene representations are a promising approach to
3D scene understanding. In this work, we propose a novel neural scene
representation, Light Field Networks or LFNs, which represent both geometry and
appearance of the underlying 3D scene in a 360-degree, four-dimensional light
field parameterized via a neural implicit representation. Rendering a ray from
an LFN requires only a *single* network evaluation, as opposed to hundreds of
evaluations per ray for ray-marching or volumetric based renderers in
3D-structured neural scene representations. In the setting of simple scenes, we
leverage meta-learning to learn a prior over LFNs that enables multi-view
consistent light field reconstruction from as little as a single image
observation. This results in dramatic reductions in time and memory complexity,
and enables real-time rendering. The cost of storing a 360-degree light field
via an LFN is two orders of magnitude lower than conventional methods such as
the Lumigraph. Utilizing the analytical differentiability of neural implicit
representations and a novel parameterization of light space, we further
demonstrate the extraction of sparse depth maps from LFNs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Intelligent Resource Reservation for Crowdsourced Live Video Streaming Applications in Geo-Distributed Cloud Environment. (arXiv:2106.02420v1 [cs.NI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baccour_E/0/1/0/all/0/1">Emna Baccour</a>, <a href="http://arxiv.org/find/cs/1/au:+Haouari_F/0/1/0/all/0/1">Fatima Haouari</a>, <a href="http://arxiv.org/find/cs/1/au:+Erbad_A/0/1/0/all/0/1">Aiman Erbad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mohamed_A/0/1/0/all/0/1">Amr Mohamed</a>, <a href="http://arxiv.org/find/cs/1/au:+Bilal_K/0/1/0/all/0/1">Kashif Bilal</a>, <a href="http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1">Mohsen Guizani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamdi_M/0/1/0/all/0/1">Mounir Hamdi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02420">
                                    <div class="article-summary-box-inner">
                                        <span>Crowdsourced live video streaming (livecast) services such as Facebook Live,
YouNow, Douyu and Twitch are gaining more momentum recently. Allocating the
limited resources in a cost-effective manner while maximizing the Quality of
Service (QoS) through real-time delivery and the provision of the appropriate
representations for all viewers is a challenging problem. In our paper, we
introduce a machine-learning based predictive resource allocation framework for
geo-distributed cloud sites, considering the delay and quality constraints to
guarantee the maximum QoS for viewers and the minimum cost for content
providers. First, we present an offline optimization that decides the required
transcoding resources in distributed regions near the viewers with a trade-off
between the QoS and the overall cost. Second, we use machine learning to build
forecasting models that proactively predict the approximate transcoding
resources to be reserved at each cloud site ahead of time. Finally, we develop
a Greedy Nearest and Cheapest algorithm (GNCA) to perform the resource
allocation of real-time broadcasted videos on the rented resources. Extensive
simulations have shown that GNCA outperforms the state-of-the art resource
allocation approaches for crowdsourced live streaming by achieving more than
20% gain in terms of system cost while serving the viewers with relatively
lower latency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-04">2021-06-04</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LearnDA: Learnable Knowledge-Guided Data Augmentation for Event Causality Identification. (arXiv:2106.01649v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1">Xinyu Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1">Pengfei Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yubo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Weihua Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuguang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01649">
                                    <div class="article-summary-box-inner">
                                        <span>Modern models for event causality identification (ECI) are mainly based on
supervised learning, which are prone to the data lacking problem.
Unfortunately, the existing NLP-related augmentation methods cannot directly
produce the available data required for this task. To solve the data lacking
problem, we introduce a new approach to augment training data for event
causality identification, by iteratively generating new examples and
classifying event causality in a dual learning framework. On the one hand, our
approach is knowledge-guided, which can leverage existing knowledge bases to
generate well-formed new sentences. On the other hand, our approach employs a
dual mechanism, which is a learnable augmentation framework and can
interactively adjust the generation process to generate task-related sentences.
Experimental results on two benchmarks EventStoryLine and Causal-TimeBank show
that 1) our method can augment suitable task-related training data for ECI; 2)
our method outperforms previous methods on EventStoryLine and Causal-TimeBank
(+2.5 and +2.1 points on F1 value respectively).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Event Causality Identification via Self-Supervised Representation Learning on External Causal Statement. (arXiv:2106.01654v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zuo_X/0/1/0/all/0/1">Xinyu Zuo</a>, <a href="http://arxiv.org/find/cs/1/au:+Cao_P/0/1/0/all/0/1">Pengfei Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yubo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1">Kang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jun Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Weihua Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuguang Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01654">
                                    <div class="article-summary-box-inner">
                                        <span>Current models for event causality identification (ECI) mainly adopt a
supervised framework, which heavily rely on labeled data for training.
Unfortunately, the scale of current annotated datasets is relatively limited,
which cannot provide sufficient support for models to capture useful indicators
from causal statements, especially for handing those new, unseen cases. To
alleviate this problem, we propose a novel approach, shortly named CauSeRL,
which leverages external causal statements for event causality identification.
First of all, we design a self-supervised framework to learn context-specific
causal patterns from external causal statements. Then, we adopt a contrastive
transfer strategy to incorporate the learned context-specific causal patterns
into the target ECI model. Experimental results show that our method
significantly outperforms previous methods on EventStoryLine and
Causal-TimeBank (+2.0 and +3.4 points on F1 value respectively).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia. (arXiv:2106.01601v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1">Nanyun Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01601">
                                    <div class="article-summary-box-inner">
                                        <span>Human activities can be seen as sequences of events, which are crucial to
understanding societies. Disproportional event distribution for different
demographic groups can manifest and amplify social stereotypes, and potentially
jeopardize the ability of members in some groups to pursue certain goals. In
this paper, we present the first event-centric study of gender biases in a
Wikipedia corpus. To facilitate the study, we curate a corpus of career and
personal life descriptions with demographic information consisting of 7,854
fragments from 10,412 celebrities. Then we detect events with a
state-of-the-art event detection model, calibrate the results using
strategically generated templates, and extract events that have asymmetric
associations with genders. Our study discovers that the Wikipedia pages tend to
intermingle personal life events with professional events for females but not
for males, which calls for the awareness of the Wikipedia community to
formalize guidelines and train the editors to mind the implicit biases that
contributors carry. Our work also lays the foundation for future works on
quantifying and discovering event biases at the corpus level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Corporate core values and social responsibility: What really matters to whom. (arXiv:2106.01644v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Barchiesi_M/0/1/0/all/0/1">M. A. Barchiesi</a>, <a href="http://arxiv.org/find/cs/1/au:+Colladon_A/0/1/0/all/0/1">A. Fronzetti Colladon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01644">
                                    <div class="article-summary-box-inner">
                                        <span>This study uses an innovative measure, the Semantic Brand Score, to assess
the interest of stakeholders in different company core values. Among others, we
focus on corporate social responsibility (CSR) core value statements, and on
the attention they receive from five categories of stakeholders (customers,
company communication teams, employees, associations and media). Combining big
data methods and tools of Social Network Analysis and Text Mining, we analyzed
about 58,000 Italian tweets and found that different stakeholders have
different prevailing interests. CSR gets much less attention than expected.
Core values related to customers and employees are in the foreground.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language Generation. (arXiv:2106.01597v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maurya_K/0/1/0/all/0/1">Kaushal Kumar Maurya</a>, <a href="http://arxiv.org/find/cs/1/au:+Desarkar_M/0/1/0/all/0/1">Maunendra Sankar Desarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kano_Y/0/1/0/all/0/1">Yoshinobu Kano</a>, <a href="http://arxiv.org/find/cs/1/au:+Deepshikha_K/0/1/0/all/0/1">Kumari Deepshikha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01597">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the recent advancement in NLP research, cross-lingual transfer for
natural language generation is relatively understudied. In this work, we
transfer supervision from high resource language (HRL) to multiple low-resource
languages (LRLs) for natural language generation (NLG). We consider four NLG
tasks (text summarization, question generation, news headline generation, and
distractor generation) and three syntactically diverse languages, i.e.,
English, Hindi, and Japanese. We propose an unsupervised cross-lingual language
generation framework (called ZmBART) that does not use any parallel or
pseudo-parallel/back-translated data. In this framework, we further pre-train
mBART sequence-to-sequence denoising auto-encoder model with an auxiliary task
using monolingual data of three languages. The objective function of the
auxiliary task is close to the target tasks which enriches the multi-lingual
latent representation of mBART and provides good initialization for target
tasks. Then, this model is fine-tuned with task-specific supervised English
data and directly evaluated with low-resource languages in the Zero-shot
setting. To overcome catastrophic forgetting and spurious correlation issues,
we applied freezing model component and data argumentation approaches
respectively. This simple modeling approach gave us promising results.We
experimented with few-shot training (with 1000 supervised data points) which
boosted the model performance further. We performed several ablations and
cross-lingual transferability analyses to demonstrate the robustness of ZmBART.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tail-to-Tail Non-Autoregressive Sequence Prediction for Chinese Grammatical Error Correction. (arXiv:2106.01609v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1">Piji Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shuming Shi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01609">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the problem of Chinese Grammatical Error Correction (CGEC) and
present a new framework named Tail-to-Tail (\textbf{TtT}) non-autoregressive
sequence prediction to address the deep issues hidden in CGEC. Considering that
most tokens are correct and can be conveyed directly from source to target, and
the error positions can be estimated and corrected based on the bidirectional
context information, thus we employ a BERT-initialized Transformer Encoder as
the backbone model to conduct information modeling and conveying. Considering
that only relying on the same position substitution cannot handle the
variable-length correction cases, various operations such substitution,
deletion, insertion, and local paraphrasing are required jointly. Therefore, a
Conditional Random Fields (CRF) layer is stacked on the up tail to conduct
non-autoregressive sequence prediction by modeling the token dependencies.
Since most tokens are correct and easily to be predicted/conveyed to the
target, then the models may suffer from a severe class imbalance issue. To
alleviate this problem, focal loss penalty strategies are integrated into the
loss functions. Moreover, besides the typical fix-length error correction
datasets, we also construct a variable-length corpus to conduct experiments.
Experimental results on standard datasets, especially on the variable-length
datasets, demonstrate the effectiveness of TtT in terms of sentence-level
Accuracy, Precision, Recall, and F1-Measure on tasks of error Detection and
Correction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparing Acoustic-based Approaches for Alzheimer&#x27;s Disease Detection. (arXiv:2106.01555v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Balagopalan_A/0/1/0/all/0/1">Aparna Balagopalan</a>, <a href="http://arxiv.org/find/cs/1/au:+Novikova_J/0/1/0/all/0/1">Jekaterina Novikova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01555">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the performance and generalizability of three
approaches for AD detection from speech on the recent ADReSSo challenge
dataset: 1) using conventional acoustic features 2) using novel pre-trained
acoustic embeddings 3) combining acoustic features and embeddings. We find that
while feature-based approaches have a higher precision, classification
approaches relying on the combination of embeddings and features prove to have
a higher, and more balanced performance across multiple metrics of performance.
Our best model, using such a combined approach, outperforms the acoustic
baseline in the challenge by 2.8\%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grounding Complex Navigational Instructions Using Scene Graphs. (arXiv:2106.01607v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1">Michiel de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1">Satyapriya Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Anuva Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01607">
                                    <div class="article-summary-box-inner">
                                        <span>Training a reinforcement learning agent to carry out natural language
instructions is limited by the available supervision, i.e. knowing when the
instruction has been carried out. We adapt the CLEVR visual question answering
dataset to generate complex natural language navigation instructions and
accompanying scene graphs, yielding an environment-agnostic supervised dataset.
To demonstrate the use of this data set, we map the scenes to the VizDoom
environment and use the architecture in \citet{gatedattention} to train an
agent to carry out these more complex language instructions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatically Detecting Cyberbullying Comments on Online Game Forums. (arXiv:2106.01598v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vo_H/0/1/0/all/0/1">Hanh Hong-Phuc Vo</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_H/0/1/0/all/0/1">Hieu Trung Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Luu_S/0/1/0/all/0/1">Son T. Luu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01598">
                                    <div class="article-summary-box-inner">
                                        <span>Online game forums are popular to most of game players. They use it to
communicate and discuss the strategy of the game, or even to make friends.
However, game forums also contain abusive and harassment speech, disturbing and
threatening players. Therefore, it is necessary to automatically detect and
remove cyberbullying comments to keep the game forum clean and friendly. We use
the Cyberbullying dataset collected from World of Warcraft (WoW) and League of
Legends (LoL) forums and train classification models to automatically detect
whether a comment of a player is abusive or not. The result obtains 82.69% of
macro F1-score for LoL forum and 83.86% of macro F1-score for WoW forum by the
Toxic-BERT model on the Cyberbullying dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discovering Chatbot&#x27;s Self-Disclosure&#x27;s Impact on User Trust, Affinity, and Recommendation Effectiveness. (arXiv:2106.01666v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_K/0/1/0/all/0/1">Kai-Hui Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1">Weiyan Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Oh_Y/0/1/0/all/0/1">Yoojung Oh</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jingwen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhou Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01666">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, chatbots have been empowered to engage in social
conversations with humans and have the potential to elicit people to disclose
their personal experiences, opinions, and emotions. However, how and to what
extent people respond to chabots&#x27; self-disclosure remain less known. In this
work, we designed a social chatbot with three self-disclosure levels that
conducted small talks and provided relevant recommendations to people. 372
MTurk participants were randomized to one of the four groups with different
self-disclosure levels to converse with the chatbot on two topics, movies, and
COVID-19. We found that people&#x27;s self-disclosure level was strongly reciprocal
to a chatbot&#x27;s self-disclosure level. Chatbots&#x27; self-disclosure also positively
impacted engagement and users&#x27; perception of the bot and led to a more
effective recommendation such that participants enjoyed and agreed more with
the recommendations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-shot Knowledge Graph-to-Text Generation with Pretrained Language Models. (arXiv:2106.01623v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junyi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_T/0/1/0/all/0/1">Tianyi Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wayne Xin Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Z/0/1/0/all/0/1">Zhicheng Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_N/0/1/0/all/0/1">Nicholas Jing Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1">Ji-Rong Wen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01623">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies how to automatically generate a natural language text that
describes the facts in knowledge graph (KG). Considering the few-shot setting,
we leverage the excellent capacities of pretrained language models (PLMs) in
language understanding and generation. We make three major technical
contributions, namely representation alignment for bridging the semantic gap
between KG encodings and PLMs, relation-biased KG linearization for deriving
better input representations, and multi-task learning for learning the
correspondence between KG and text. Extensive experiments on three benchmark
datasets have demonstrated the effectiveness of our model on KG-to-text
generation task. In particular, our model outperforms all comparison methods on
both fully-supervised and few-shot settings. Our code and datasets are
available at https://github.com/RUCAIBox/Few-Shot-KG2Text.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discriminative Reasoning for Document-level Relation Extraction. (arXiv:2106.01562v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1">Wang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1">Kehai Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1">Tiejun Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01562">
                                    <div class="article-summary-box-inner">
                                        <span>Document-level relation extraction (DocRE) models generally use graph
networks to implicitly model the reasoning skill (i.e., pattern recognition,
logical reasoning, coreference reasoning, etc.) related to the relation between
one entity pair in a document. In this paper, we propose a novel discriminative
reasoning framework to explicitly model the paths of these reasoning skills
between each entity pair in this document. Thus, a discriminative reasoning
network is designed to estimate the relation probability distribution of
different reasoning paths based on the constructed graph and vectorized
document contexts for each entity pair, thereby recognizing their relation.
Experimental results show that our method outperforms the previous
state-of-the-art performance on the large-scale DocRE dataset. The code is
publicly available at https://github.com/xwjim/DRN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Limitations of Limited Context for Constituency Parsing. (arXiv:2106.01580v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuchen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1">Andrej Risteski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01580">
                                    <div class="article-summary-box-inner">
                                        <span>Incorporating syntax into neural approaches in NLP has a multitude of
practical and scientific benefits. For instance, a language model that is
syntax-aware is likely to be able to produce better samples; even a
discriminative model like BERT with a syntax module could be used for core NLP
tasks like unsupervised syntactic parsing. Rapid progress in recent years was
arguably spurred on by the empirical success of the Parsing-Reading-Predict
architecture of (Shen et al., 2018a), later simplified by the Order Neuron LSTM
of (Shen et al., 2019). Most notably, this is the first time neural approaches
were able to successfully perform unsupervised syntactic parsing (evaluated by
various metrics like F-1 score).

However, even heuristic (much less fully mathematical) understanding of why
and when these architectures work is lagging severely behind. In this work, we
answer representational questions raised by the architectures in (Shen et al.,
2018a, 2019), as well as some transition-based syntax-aware language models
(Dyer et al., 2016): what kind of syntactic structure can current neural
approaches to syntax represent? Concretely, we ground this question in the
sandbox of probabilistic context-free-grammars (PCFGs), and identify a key
aspect of the representational power of these approaches: the amount and
directionality of context that the predictor has access to when forced to make
parsing decision. We show that with limited context (either bounded, or
unidirectional), there are PCFGs, for which these approaches cannot represent
the max-likelihood parse; conversely, if the context is unlimited, they can
represent the max-likelihood parse of any PCFG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adjacency List Oriented Relational Fact Extraction via Adaptive Multi-task Learning. (arXiv:2106.01559v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_F/0/1/0/all/0/1">Fubang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhuoren Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_Y/0/1/0/all/0/1">Yangyang Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Changlong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaozhong Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01559">
                                    <div class="article-summary-box-inner">
                                        <span>Relational fact extraction aims to extract semantic triplets from
unstructured text. In this work, we show that all of the relational fact
extraction models can be organized according to a graph-oriented analytical
perspective. An efficient model, aDjacency lIst oRiented rElational faCT
(DIRECT), is proposed based on this analytical framework. To alleviate
challenges of error propagation and sub-task loss equilibrium, DIRECT employs a
novel adaptive multi-task learning strategy with dynamic sub-task loss
balancing. Extensive experiments are conducted on two benchmark datasets, and
results prove that the proposed model outperforms a series of state-of-the-art
(SoTA) models for relational triplet extraction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generate, Prune, Select: A Pipeline for Counterspeech Generation against Online Hate Speech. (arXiv:2106.01625v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Wanzheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1">Suma Bhat</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01625">
                                    <div class="article-summary-box-inner">
                                        <span>Countermeasures to effectively fight the ever increasing hate speech online
without blocking freedom of speech is of great social interest. Natural
Language Generation (NLG), is uniquely capable of developing scalable
solutions. However, off-the-shelf NLG methods are primarily
sequence-to-sequence neural models and they are limited in that they generate
commonplace, repetitive and safe responses regardless of the hate speech (e.g.,
&quot;Please refrain from using such language.&quot;) or irrelevant responses, making
them ineffective for de-escalating hateful conversations. In this paper, we
design a three-module pipeline approach to effectively improve the diversity
and relevance. Our proposed pipeline first generates various counterspeech
candidates by a generative model to promote diversity, then filters the
ungrammatical ones using a BERT model, and finally selects the most relevant
counterspeech response using a novel retrieval-based method. Extensive
Experiments on three representative datasets demonstrate the efficacy of our
approach in generating diverse and relevant counterspeech.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systematic Investigation of KB-Text Embedding Alignment at Scale. (arXiv:2106.01586v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1">Vardaan Pahuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yu Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahrami_M/0/1/0/all/0/1">Mehdi Bahrami</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei-Peng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yu Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01586">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge bases (KBs) and text often contain complementary knowledge: KBs
store structured knowledge that can support long range reasoning, while text
stores more comprehensive and timely knowledge in an unstructured way.
Separately embedding the individual knowledge sources into vector spaces has
demonstrated tremendous successes in encoding the respective knowledge, but how
to jointly embed and reason with both knowledge sources to fully leverage the
complementary information is still largely an open problem. We conduct a
large-scale, systematic investigation of aligning KB and text embeddings for
joint reasoning. We set up a novel evaluation framework with two evaluation
tasks, few-shot link prediction and analogical reasoning, and evaluate an array
of KB-text embedding alignment methods. We also demonstrate how such alignment
can infuse textual information into KB embeddings for more accurate link
prediction on emerging entities and events, using COVID-19 as a case study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Cognitive Regularizer for Language Modeling. (arXiv:2105.07144v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Jason Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1">Clara Meister</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07144">
                                    <div class="article-summary-box-inner">
                                        <span>The uniform information density (UID) hypothesis, which posits that speakers
behaving optimally tend to distribute information uniformly across a linguistic
signal, has gained traction in psycholinguistics as an explanation for certain
syntactic, morphological, and prosodic choices. In this work, we explore
whether the UID hypothesis can be operationalized as an inductive bias for
statistical language modeling. Specifically, we augment the canonical MLE
objective for training language models with a regularizer that encodes UID. In
experiments on ten languages spanning five language families, we find that
using UID regularization consistently improves perplexity in language models,
having a larger effect when training data is limited. Moreover, via an analysis
of generated sequences, we find that UID-regularized language models have other
desirable properties, e.g., they generate text that is more lexically diverse.
Our results not only suggest that UID is a reasonable inductive bias for
language modeling, but also provide an alternative validation of the UID
hypothesis using modern-day NLP tools.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Joint Retrieval and Generation Training for Grounded Text Generation. (arXiv:2105.06597v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yizhe Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Siqi Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1">Xiang Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1">Yuwei Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Brockett_C/0/1/0/all/0/1">Chris Brockett</a>, <a href="http://arxiv.org/find/cs/1/au:+Galley_M/0/1/0/all/0/1">Michel Galley</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Dolan_B/0/1/0/all/0/1">Bill Dolan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06597">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in large-scale pre-training such as GPT-3 allow seemingly
high quality text to be generated from a given prompt. However, such generation
systems often suffer from problems of hallucinated facts, and are not
inherently designed to incorporate useful external information. Grounded
generation models appear to offer remedies, but their training typically relies
on rarely-available parallel data where corresponding information-relevant
documents are provided for context. We propose a framework that alleviates this
data constraint by jointly training a grounded generator and document retriever
on the language model signal. The model learns to reward retrieval of the
documents with the highest utility in generation, and attentively combines them
using a Mixture-of-Experts (MoE) ensemble to generate follow-on text. We
demonstrate that both generator and retriever can take advantage of this joint
training and work synergistically to produce more informative and relevant text
in both prose and dialogue generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Societal Biases in Language Generation: Progress and Challenges. (arXiv:2105.04054v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sheng_E/0/1/0/all/0/1">Emily Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Natarajan_P/0/1/0/all/0/1">Premkumar Natarajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1">Nanyun Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04054">
                                    <div class="article-summary-box-inner">
                                        <span>Technology for language generation has advanced rapidly, spurred by
advancements in pre-training large models on massive amounts of data and the
need for intelligent agents to communicate in a natural manner. While
techniques can effectively generate fluent text, they can also produce
undesirable societal biases that can have a disproportionately negative impact
on marginalized populations. Language generation presents unique challenges for
biases in terms of direct user interaction and the structure of decoding
techniques. To better understand these challenges, we present a survey on
societal biases in language generation, focusing on how data and techniques
contribute to biases and progress towards reducing biases. Motivated by a lack
of studies on biases from decoding techniques, we also conduct experiments to
quantify the effects of these techniques. By further discussing general trends
and open challenges, we call to attention promising directions for research and
the importance of fairness and inclusivity considerations for language
generation applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERT Busters: Outlier Dimensions that Disrupt Transformers. (arXiv:2105.06990v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovaleva_O/0/1/0/all/0/1">Olga Kovaleva</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulshreshtha_S/0/1/0/all/0/1">Saurabh Kulshreshtha</a>, <a href="http://arxiv.org/find/cs/1/au:+Rogers_A/0/1/0/all/0/1">Anna Rogers</a>, <a href="http://arxiv.org/find/cs/1/au:+Rumshisky_A/0/1/0/all/0/1">Anna Rumshisky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06990">
                                    <div class="article-summary-box-inner">
                                        <span>Multiple studies have shown that Transformers are remarkably robust to
pruning. Contrary to this received wisdom, we demonstrate that pre-trained
Transformer encoders are surprisingly fragile to the removal of a very small
number of features in the layer outputs (&lt;0.0001% of model weights). In case of
BERT and other pre-trained encoder Transformers, the affected component is the
scaling factors and biases in the LayerNorm. The outliers are high-magnitude
normalization parameters that emerge early in pre-training and show up
consistently in the same dimensional position throughout the model. We show
that disabling them significantly degrades both the MLM loss and the downstream
task performance. This effect is observed across several BERT-family models and
other popular pre-trained Transformer architectures, including BART, XLNet and
ELECTRA; we also show a similar effect in GPT-2.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts. (arXiv:2105.03023v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1">Alisa Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sap_M/0/1/0/all/0/1">Maarten Sap</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1">Ximing Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1">Swabha Swayamdipta</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhagavatula_C/0/1/0/all/0/1">Chandra Bhagavatula</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1">Yejin Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03023">
                                    <div class="article-summary-box-inner">
                                        <span>Despite recent advances in natural language generation, it remains
challenging to control attributes of generated text. We propose DExperts:
Decoding-time Experts, a decoding-time method for controlled text generation
that combines a pretrained language model with &quot;expert&quot; LMs and/or
&quot;anti-expert&quot; LMs in a product of experts. Intuitively, under the ensemble,
tokens only get high probability if they are considered likely by the experts,
and unlikely by the anti-experts. We apply DExperts to language detoxification
and sentiment-controlled generation, where we outperform existing controllable
generation methods on both automatic and human evaluations. Moreover, because
DExperts operates only on the output of the pretrained LM, it is effective with
(anti-)experts of smaller size, including when operating on GPT-3. Our work
highlights the promise of tuning small LMs on text with (un)desirable
attributes for efficient decoding-time steering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WeNet: Production oriented Streaming and Non-streaming End-to-End Speech Recognition Toolkit. (arXiv:2102.01547v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1">Zhuoyuan Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Di Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1">Binbin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1">Fan Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Chao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1">Zhendong Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaoyu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1">Lei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Lei_X/0/1/0/all/0/1">Xin Lei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01547">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose an open source, production first, and production
ready speech recognition toolkit called WeNet in which a new two-pass approach
is implemented to unify streaming and non-streaming end-to-end (E2E) speech
recognition in a single model. The main motivation of WeNet is to close the gap
between the research and the production of E2E speechrecognition models. WeNet
provides an efficient way to ship ASR applications in several real-world
scenarios, which is the main difference and advantage to other open source E2E
speech recognition toolkits. In our toolkit, a new two-pass method is
implemented. Our method propose a dynamic chunk-based attention strategy of the
the transformer layers to allow arbitrary right context length modifies in
hybrid CTC/attention architecture. The inference latency could be easily
controlled by only changing the chunk size. The CTC hypotheses are then
rescored by the attention decoder to get the final result. Our experiments on
the AISHELL-1 dataset using WeNet show that, our model achieves 5.03\% relative
character error rate (CER) reduction in non-streaming ASR compared to a
standard non-streaming transformer. After model quantification, our model
perform reasonable RTF and latency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Crossing the Conversational Chasm: A Primer on Natural Language Processing for Multilingual Task-Oriented Dialogue Systems. (arXiv:2104.08570v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Razumovskaia_E/0/1/0/all/0/1">Evgeniia Razumovskaia</a>, <a href="http://arxiv.org/find/cs/1/au:+Glavas_G/0/1/0/all/0/1">Goran Glava&#x161;</a>, <a href="http://arxiv.org/find/cs/1/au:+Majewska_O/0/1/0/all/0/1">Olga Majewska</a>, <a href="http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1">Edoardo M. Ponti</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1">Anna Korhonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08570">
                                    <div class="article-summary-box-inner">
                                        <span>In task-oriented dialogue (ToD), a user holds a conversation with an
artificial agent to complete a concrete task. Although this technology
represents one of the central objectives of AI and has been the focus of ever
more intense research and development efforts, it is currently limited to a few
narrow domains (e.g., food ordering, ticket booking) and a handful of languages
(e.g., English, Chinese). This work provides an extensive overview of existing
methods and resources in multilingual ToD as an entry point to this exciting
and emerging field. We find that the most critical factor preventing the
creation of truly multilingual ToD systems is the lack of datasets in most
languages for both training and evaluation. In fact, acquiring annotations or
human feedback for each component of modular systems or for data-hungry
end-to-end systems is expensive and tedious. Hence, state-of-the-art approaches
to multilingual ToD mostly rely on (zero- or few-shot) cross-lingual transfer
from resource-rich languages (almost exclusively English), either by means of
machine translation or multilingual representations. These approaches are
currently viable only for typologically similar languages and languages with
parallel / monolingual corpora available. On the other hand, their
effectiveness beyond these boundaries is doubtful or hard to assess due to the
lack of linguistically diverse benchmarks (especially for natural language
generation and end-to-end evaluation). To overcome this limitation, we draw
parallels between components of the ToD pipeline and other NLP tasks, which can
inspire solutions for learning in low-resource scenarios. Finally, we list
additional challenges that multilinguality poses for related areas (such as
speech and human-centred evaluation), and indicate future directions that hold
promise to further expand language coverage and dialogue capabilities of
current ToD systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchmarking Commercial Intent Detection Services with Practice-Driven Evaluations. (arXiv:2012.03929v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_H/0/1/0/all/0/1">Haode Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1">Lin Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Sood_A/0/1/0/all/0/1">Atin Sood</a>, <a href="http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1">Abhishek Shah</a>, <a href="http://arxiv.org/find/cs/1/au:+Kunc_L/0/1/0/all/0/1">Ladislav Kunc</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1">Mo Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Potdar_S/0/1/0/all/0/1">Saloni Potdar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03929">
                                    <div class="article-summary-box-inner">
                                        <span>Intent detection is a key component of modern goal-oriented dialog systems
that accomplish a user task by predicting the intent of users&#x27; text input.
There are three primary challenges in designing robust and accurate intent
detection models. First, typical intent detection models require a large amount
of labeled data to achieve high accuracy. Unfortunately, in practical scenarios
it is more common to find small, unbalanced, and noisy datasets. Secondly, even
with large training data, the intent detection models can see a different
distribution of test data when being deployed in the real world, leading to
poor accuracy. Finally, a practical intent detection model must be
computationally efficient in both training and single query inference so that
it can be used continuously and re-trained frequently. We benchmark intent
detection methods on a variety of datasets. Our results show that Watson
Assistant&#x27;s intent detection model outperforms other commercial solutions and
is comparable to large pretrained language models while requiring only a
fraction of computational resources and training data. Watson Assistant
demonstrates a higher degree of robustness when the training and test
distributions differ.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Learning of KB Queries in Task-Oriented Dialogs. (arXiv:2005.00123v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raghu_D/0/1/0/all/0/1">Dinesh Raghu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Nikhil Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1">Mausam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00123">
                                    <div class="article-summary-box-inner">
                                        <span>Task-oriented dialog (TOD) systems often need to formulate knowledge base
(KB) queries corresponding to the user intent and use the query results to
generate system responses. Existing approaches require dialog datasets to
explicitly annotate these KB queries -- these annotations can be time
consuming, and expensive. In response, we define the novel problems of
predicting the KB query and training the dialog agent, without explicit KB
query annotation. For query prediction, we propose a reinforcement learning
(RL) baseline, which rewards the generation of those queries whose KB results
cover the entities mentioned in subsequent dialog. Further analysis reveals
that correlation among query attributes in KB can significantly confuse memory
augmented policy optimization (MAPO), an existing state of the art RL agent. To
address this, we improve the MAPO baseline with simple but important
modifications suited to our task. To train the full TOD system for our setting,
we propose a pipelined approach: it independently predicts when to make a KB
query (query position predictor), then predicts a KB query at the predicted
position (query predictor), and uses the results of predicted query in
subsequent dialog (next response predictor). Overall, our work proposes first
solutions to our novel problem, and our analysis highlights the research
challenges in training TOD systems without query annotation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LyricJam: A system for generating lyrics for live instrumental music. (arXiv:2106.01960v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vechtomova_O/0/1/0/all/0/1">Olga Vechtomova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahu_G/0/1/0/all/0/1">Gaurav Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_D/0/1/0/all/0/1">Dhruv Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01960">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a real-time system that receives a live audio stream from a jam
session and generates lyric lines that are congruent with the live music being
played. Two novel approaches are proposed to align the learned latent spaces of
audio and text representations that allow the system to generate novel lyric
lines matching live instrumental music. One approach is based on adversarial
alignment of latent representations of audio and lyrics, while the other
approach learns to transfer the topology from the music latent space to the
lyric latent space. A user study with music artists using the system showed
that the system was useful not only in lyric composition, but also encouraged
the artists to improvise and find new musical expressions. Another user study
demonstrated that users preferred the lines generated using the proposed
methods to the lines generated by a baseline model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Shortformer: Better Language Modeling using Shorter Inputs. (arXiv:2012.15832v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Press_O/0/1/0/all/0/1">Ofir Press</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1">Mike Lewis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15832">
                                    <div class="article-summary-box-inner">
                                        <span>Increasing the input length has been a driver of progress in language
modeling with transformers. We identify conditions where shorter inputs are not
harmful, and achieve perplexity and efficiency improvements through two new
methods that decrease input length. First, we show that initially training a
model on short subsequences before moving on to longer ones both reduces
overall training time and, surprisingly, substantially improves perplexity.
Second, we show how to improve the efficiency of recurrence methods in
transformers, which let models condition on previously processed tokens when
generating sequences that exceed the maximal length the transformer can handle
at once. Existing methods require computationally expensive relative position
embeddings; we introduce a simple alternative of adding absolute position
embeddings to queries and keys instead of to word embeddings, which efficiently
produces superior results. We show that these recurrent models also benefit
from short input lengths. Combining these techniques speeds up training by a
factor of 1.65, reduces memory usage, and substantially improves perplexity on
WikiText-103, without adding any parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIRE: Separate Intra- and Inter-sentential Reasoning for Document-level Relation Extraction. (arXiv:2106.01709v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1">Shuang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuting Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1">Baobao Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01709">
                                    <div class="article-summary-box-inner">
                                        <span>Document-level relation extraction has attracted much attention in recent
years. It is usually formulated as a classification problem that predicts
relations for all entity pairs in the document. However, previous works
indiscriminately represent intra- and inter-sentential relations in the same
way, confounding the different patterns for predicting them. Besides, they
create a document graph and use paths between entities on the graph as clues
for logical reasoning. However, not all entity pairs can be connected with a
path and have the correct logical reasoning paths in their graph. Thus many
cases of logical reasoning cannot be covered. This paper proposes an effective
architecture, SIRE, to represent intra- and inter-sentential relations in
different ways. We design a new and straightforward form of logical reasoning
module that can cover more logical reasoning chains. Experiments on the public
datasets show SIRE outperforms the previous state-of-the-art methods. Further
analysis shows that our predictions are reliable and explainable. Our code is
available at https://github.com/DreamInvoker/SIRE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations. (arXiv:2106.01978v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Dou Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_L/0/1/0/all/0/1">Lingwei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Huai_X/0/1/0/all/0/1">Xiaoyong Huai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01978">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion Recognition in Conversations (ERC) has gained increasing attention
for developing empathetic machines. Recently, many approaches have been devoted
to perceiving conversational context by deep learning models. However, these
approaches are insufficient in understanding the context due to lacking the
ability to extract and integrate emotional clues. In this work, we propose
novel Contextual Reasoning Networks (DialogueCRN) to fully understand the
conversational context from a cognitive perspective. Inspired by the Cognitive
Theory of Emotion, we design multi-turn reasoning modules to extract and
integrate emotional clues. The reasoning module iteratively performs an
intuitive retrieving process and a conscious reasoning process, which imitates
human unique cognitive thinking. Extensive experiments on three public
benchmark datasets demonstrate the effectiveness and superiority of the
proposed model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reordering Examples Helps during Priming-based Few-Shot Learning. (arXiv:2106.01751v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1">Sawan Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1">Partha Talukdar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01751">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to learn from limited data, or few-shot learning, is a desirable
and often critical requirement for NLP systems. While many existing methods do
poorly at learning from a handful of examples, large pretrained language models
have recently been shown to be efficient few-shot learners. One approach to
few-shot learning, which does not require finetuning of model parameters, is to
augment the language model&#x27;s input with priming text which is typically
constructed using task specific descriptions and examples. In this work, we
further explore priming-based few-shot learning, with focus on using examples
as prompts. We show that presenting examples in the right order is key for
generalization. We introduce PERO (Prompting with Examples in the Right Order),
where we formulate few-shot learning as search over the set of permutations of
the training examples. We show that PERO can learn to generalize efficiently
using as few as 10 examples, in contrast to existing approaches. While the
newline token is a natural choice for separating the examples in the prompt, we
show that learning a new separator token can potentially provide further gains
in performance. We demonstrate the effectiveness of the proposed method on the
tasks of sentiment classification, natural language inference and fact
retrieval. Finally, we analyze the learned prompts to reveal novel insights,
including the idea that two training examples in the right order alone can
provide competitive performance for sentiment classification and natural
language inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Does BERT Solve Commonsense Task via Commonsense Knowledge?. (arXiv:2008.03945v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Leyang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1">Sijie Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yue Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.03945">
                                    <div class="article-summary-box-inner">
                                        <span>BERT has been used for solving commonsense tasks such as CommonsenseQA. While
prior research has found that BERT does contain commonsense information to some
extent, there has been work showing that pre-trained models can rely on
spurious associations (e.g., data bias) rather than key cues in solving
sentiment classification and other problems. We quantitatively investigate the
presence of structural commonsense cues in BERT when solving commonsense tasks,
and the importance of such cues for the model prediction. Using two different
measures, we find that BERT does use relevant knowledge for solving the task,
and the presence of commonsense knowledge is positively correlated to the model
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GL-GIN: Fast and Accurate Non-Autoregressive Model for Joint Multiple Intent Detection and Slot Filling. (arXiv:2106.01925v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_L/0/1/0/all/0/1">Libo Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1">Fuxuan Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_T/0/1/0/all/0/1">Tianbao Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1">Wanxiang Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1">Ting Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01925">
                                    <div class="article-summary-box-inner">
                                        <span>Multi-intent SLU can handle multiple intents in an utterance, which has
attracted increasing attention. However, the state-of-the-art joint models
heavily rely on autoregressive approaches, resulting in two issues: slow
inference speed and information leakage. In this paper, we explore a
non-autoregressive model for joint multiple intent detection and slot filling,
achieving more fast and accurate. Specifically, we propose a Global-Locally
Graph Interaction Network (GL-GIN) where a local slot-aware graph interaction
layer is proposed to model slot dependency for alleviating uncoordinated slots
problem while a global intent-slot graph interaction layer is introduced to
model the interaction between multiple intents and all slots in the utterance.
Experimental results on two public datasets show that our framework achieves
state-of-the-art performance while being 11.5 times faster.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection. (arXiv:2012.15761v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1">Bertie Vidgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1">Tristan Thrush</a>, <a href="http://arxiv.org/find/cs/1/au:+Waseem_Z/0/1/0/all/0/1">Zeerak Waseem</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15761">
                                    <div class="article-summary-box-inner">
                                        <span>We present a human-and-model-in-the-loop process for dynamically generating
datasets and training better performing and more robust hate detection models.
We provide a new dataset of ~40,000 entries, generated and labelled by trained
annotators over four rounds of dynamic data creation. It includes ~15,000
challenging perturbations and each hateful entry has fine-grained labels for
the type and target of hate. Hateful entries make up 54% of the dataset, which
is substantially higher than comparable datasets. We show that model
performance is substantially improved using this approach. Models trained on
later rounds of data collection perform better on test sets and are harder for
annotators to trick. They also perform better on HateCheck, a suite of
functional tests for online hate detection. We provide the code, dataset and
annotation guidelines for other researchers to use. Accepted at ACL 2021.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Case Study of Spanish Text Transformations for Twitter Sentiment Analysis. (arXiv:2106.02009v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tellez_E/0/1/0/all/0/1">Eric S. Tellez</a>, <a href="http://arxiv.org/find/cs/1/au:+Miranda_Jimenez_S/0/1/0/all/0/1">Sabino Miranda-Jim&#xe9;nez</a>, <a href="http://arxiv.org/find/cs/1/au:+Graff_M/0/1/0/all/0/1">Mario Graff</a>, <a href="http://arxiv.org/find/cs/1/au:+Moctezuma_D/0/1/0/all/0/1">Daniela Moctezuma</a>, <a href="http://arxiv.org/find/cs/1/au:+Siodia_O/0/1/0/all/0/1">Oscar S. Siodia</a>, <a href="http://arxiv.org/find/cs/1/au:+Villasenor_E/0/1/0/all/0/1">Elio A. Villase&#xf1;or</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02009">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment analysis is a text mining task that determines the polarity of a
given text, i.e., its positiveness or negativeness. Recently, it has received a
lot of attention given the interest in opinion mining in micro-blogging
platforms. These new forms of textual expressions present new challenges to
analyze text given the use of slang, orthographic and grammatical errors, among
others. Along with these challenges, a practical sentiment classifier should be
able to handle efficiently large workloads.

The aim of this research is to identify which text transformations
(lemmatization, stemming, entity removal, among others), tokenizers (e.g.,
words $n$-grams), and tokens weighting schemes impact the most the accuracy of
a classifier (Support Vector Machine) trained on two Spanish corpus. The
methodology used is to exhaustively analyze all the combinations of the text
transformations and their respective parameters to find out which
characteristics the best performing classifiers have in common. Furthermore,
among the different text transformations studied, we introduce a novel approach
based on the combination of word based $n$-grams and character based $q$-grams.
The results show that this novel combination of words and characters produces a
classifier that outperforms the traditional word based combination by $11.17\%$
and $5.62\%$ on the INEGI and TASS&#x27;15 dataset, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Refinement of Cross-Lingual Word Embeddings. (arXiv:1911.03070v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1">Michelle Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mozhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1">Benjamin Van Durme</a>, <a href="http://arxiv.org/find/cs/1/au:+Findlater_L/0/1/0/all/0/1">Leah Findlater</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1">Jordan Boyd-Graber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.03070">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-lingual word embeddings transfer knowledge between languages: models
trained on high-resource languages can predict in low-resource languages. We
introduce CLIME, an interactive system to quickly refine cross-lingual word
embeddings for a given classification problem. First, CLIME ranks words by
their salience to the downstream task. Then, users mark similarity between
keywords and their nearest neighbors in the embedding space. Finally, CLIME
updates the embeddings using the annotations. We evaluate CLIME on identifying
health-related text in four low-resource languages: Ilocano, Sinhalese,
Tigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word
semantics and have higher test accuracy than the original embeddings. CLIME
often improves accuracy faster than an active learning baseline and can be
easily combined with active learning to improve results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Three Sentences Are All You Need: Local Path Enhanced Document Relation Extraction. (arXiv:2106.01793v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Quzhe Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Shengqi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yansong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1">Yuan Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1">Yuxuan Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dongyan Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01793">
                                    <div class="article-summary-box-inner">
                                        <span>Document-level Relation Extraction (RE) is a more challenging task than
sentence RE as it often requires reasoning over multiple sentences. Yet, human
annotators usually use a small number of sentences to identify the relationship
between a given entity pair. In this paper, we present an embarrassingly simple
but effective method to heuristically select evidence sentences for
document-level RE, which can be easily combined with BiLSTM to achieve good
performance on benchmark datasets, even better than fancy graph neural network
based methods. We have released our code at
https://github.com/AndrewZhe/Three-Sentences-Are-All-You-Need.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic-WER: A Unified Metric for the Evaluation of ASR Transcript for End Usability. (arXiv:2106.02016v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1">Somnath Roy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02016">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in supervised, semi-supervised and self-supervised deep
learning algorithms have shown significant improvement in the performance of
automatic speech recognition(ASR) systems. The state-of-the-art systems have
achieved a word error rate (WER) less than 5%. However, in the past,
researchers have argued the non-suitability of the WER metric for the
evaluation of ASR systems for downstream tasks such as spoken language
understanding (SLU) and information retrieval. The reason is that the WER works
at the surface level and does not include any syntactic and semantic
knowledge.The current work proposes Semantic-WER (SWER), a metric to evaluate
the ASR transcripts for downstream applications in general. The SWER can be
easily customized for any down-stream task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CCPM: A Chinese Classical Poetry Matching Dataset. (arXiv:2106.01979v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wenhao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_F/0/1/0/all/0/1">Fanchao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1">Maosong Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1">Xiaoyuan Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jiarui Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01979">
                                    <div class="article-summary-box-inner">
                                        <span>Poetry is one of the most important art forms of human languages. Recently
many studies have focused on incorporating some linguistic features of poetry,
such as style and sentiment, into its understanding or generation system.
However, there is no focus on understanding or evaluating the semantics of
poetry. Therefore, we propose a novel task to assess a model&#x27;s semantic
understanding of poetry by poem matching. Specifically, this task requires the
model to select one line of Chinese classical poetry among four candidates
according to the modern Chinese translation of a line of poetry. To construct
this dataset, we first obtain a set of parallel data of Chinese classical
poetry and modern Chinese translation. Then we retrieve similar lines of poetry
with the lines in a poetry corpus as negative choices. We name the dataset
Chinese Classical Poetry Matching Dataset (CCPM) and release it at
https://github.com/THUNLP-AIPoet/CCPM. We hope this dataset can further enhance
the study on incorporating deep semantics into the understanding and generation
system of Chinese classical poetry. We also preliminarily run two variants of
BERT on this dataset as the baselines for this dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bilingual Alignment Pre-training for Zero-shot Cross-lingual Transfer. (arXiv:2106.01732v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Ziqing Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_W/0/1/0/all/0/1">Wentao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1">Yiming Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1">Jiani Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Che_W/0/1/0/all/0/1">Wanxiang Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Shijin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01732">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual pre-trained models have achieved remarkable transfer performance
by pre-trained on rich kinds of languages. Most of the models such as mBERT are
pre-trained on unlabeled corpora. The static and contextual embeddings from the
models could not be aligned very well. In this paper, we aim to improve the
zero-shot cross-lingual transfer performance by aligning the embeddings better.
We propose a pre-training task named Alignment Language Model (AlignLM), which
uses the statistical alignment information as the prior knowledge to guide
bilingual word prediction. We evaluate our method on multilingual machine
reading comprehension and natural language interface tasks. The results show
AlignLM can improve the zero-shot performance significantly on MLQA and XNLI
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">E2E-VLP: End-to-End Vision-Language Pre-training Enhanced by Visual Learning. (arXiv:2106.01804v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haiyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1">Ming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1">Bin Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Songfang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Wenming Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01804">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-language pre-training (VLP) on large-scale image-text pairs has
achieved huge success for the cross-modal downstream tasks. The most existing
pre-training methods mainly adopt a two-step training procedure, which firstly
employs a pre-trained object detector to extract region-based visual features,
then concatenates the image representation and text embedding as the input of
Transformer to train. However, these methods face problems of using
task-specific visual representation of the specific object detector for generic
cross-modal understanding, and the computation inefficiency of two-stage
pipeline. In this paper, we propose the first end-to-end vision-language
pre-trained model for both V+L understanding and generation, namely E2E-VLP,
where we build a unified Transformer framework to jointly learn visual
representation, and semantic alignments between image and text. We incorporate
the tasks of object detection and image captioning into pre-training with a
unified Transformer encoder-decoder architecture for enhancing visual learning.
An extensive set of experiments have been conducted on well-established
vision-language downstream tasks to demonstrate the effectiveness of this novel
VLP paradigm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EmoDNN: Understanding emotions from short texts through a deep neural network ensemble. (arXiv:2106.01706v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamran_S/0/1/0/all/0/1">Sara Kamran</a>, <a href="http://arxiv.org/find/cs/1/au:+Zall_R/0/1/0/all/0/1">Raziyeh Zall</a>, <a href="http://arxiv.org/find/cs/1/au:+Kangavari_M/0/1/0/all/0/1">Mohammad Reza Kangavari</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1">Saeid Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmani_S/0/1/0/all/0/1">Sana Rahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1">Wen Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01706">
                                    <div class="article-summary-box-inner">
                                        <span>The latent knowledge in the emotions and the opinions of the individuals that
are manifested via social networks are crucial to numerous applications
including social management, dynamical processes, and public security.
Affective computing, as an interdisciplinary research field, linking artificial
intelligence to cognitive inference, is capable to exploit emotion-oriented
knowledge from brief contents. The textual contents convey hidden information
such as personality and cognition about corresponding authors that can
determine both correlations and variations between users. Emotion recognition
from brief contents should embrace the contrast between authors where the
differences in personality and cognition can be traced within emotional
expressions. To tackle this challenge, we devise a framework that, on the one
hand, infers latent individual aspects, from brief contents and, on the other
hand, presents a novel ensemble classifier equipped with dynamic dropout
convnets to extract emotions from textual context. To categorize short text
contents, our proposed method conjointly leverages cognitive factors and
exploits hidden information. We utilize the outcome vectors in a novel
embedding model to foster emotion-pertinent features that are collectively
assembled by lexicon inductions. Experimental results show that compared to
other competitors, our proposed model can achieve a higher performance in
recognizing emotion from noisy contents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Representing Syntax and Composition with Geometric Transformations. (arXiv:2106.01904v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bertolini_L/0/1/0/all/0/1">Lorenzo Bertolini</a>, <a href="http://arxiv.org/find/cs/1/au:+Weeds_J/0/1/0/all/0/1">Julie Weeds</a>, <a href="http://arxiv.org/find/cs/1/au:+Weir_D/0/1/0/all/0/1">David Weir</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Q/0/1/0/all/0/1">Qiwei Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01904">
                                    <div class="article-summary-box-inner">
                                        <span>The exploitation of syntactic graphs (SyGs) as a word&#x27;s context has been
shown to be beneficial for distributional semantic models (DSMs), both at the
level of individual word representations and in deriving phrasal
representations via composition. However, notwithstanding the potential
performance benefit, the syntactically-aware DSMs proposed to date have huge
numbers of parameters (compared to conventional DSMs) and suffer from data
sparsity. Furthermore, the encoding of the SyG links (i.e., the syntactic
relations) has been largely limited to linear maps. The knowledge graphs&#x27;
literature, on the other hand, has proposed light-weight models employing
different geometric transformations (GTs) to encode edges in a knowledge graph
(KG). Our work explores the possibility of adopting this family of models to
encode SyGs. Furthermore, we investigate which GT better encodes syntactic
relations, so that these representations can be used to enhance phrase-level
composition via syntactic contextualisation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Hallucinated Content in Conditional Neural Sequence Generation. (arXiv:2011.02593v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chunting Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jiatao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1">Mona Diab</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzman_P/0/1/0/all/0/1">Paco Guzman</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghazvininejad_M/0/1/0/all/0/1">Marjan Ghazvininejad</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.02593">
                                    <div class="article-summary-box-inner">
                                        <span>Neural sequence models can generate highly fluent sentences, but recent
studies have also shown that they are also prone to hallucinate additional
content not supported by the input. These variety of fluent but wrong outputs
are particularly problematic, as it will not be possible for users to tell they
are being presented incorrect content. To detect these errors, we propose a
task to predict whether each token in the output sequence is hallucinated (not
contained in the input) and collect new manually annotated evaluation sets for
this task. We also introduce a method for learning to detect hallucinations
using pretrained language models fine tuned on synthetic data that includes
automatically inserted hallucinations Experiments on machine translation (MT)
and abstractive summarization demonstrate that our proposed approach
consistently outperforms strong baselines on all benchmark datasets. We further
demonstrate how to use the token-level hallucination labels to define a
fine-grained loss over the target sequence in low-resource MT and achieve
significant improvements over strong baseline methods. We also apply our method
to word-level quality estimation for MT and show its effectiveness in both
supervised and unsupervised settings. Codes and data available at
https://github.com/violet-zct/fairseq-detect-hallucination.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Case for Translation-Invariant Self-Attention in Transformer-Based Language Models. (arXiv:2106.01950v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wennberg_U/0/1/0/all/0/1">Ulme Wennberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01950">
                                    <div class="article-summary-box-inner">
                                        <span>Mechanisms for encoding positional information are central for
transformer-based language models. In this paper, we analyze the position
embeddings of existing language models, finding strong evidence of translation
invariance, both for the embeddings themselves and for their effect on
self-attention. The degree of translation invariance increases during training
and correlates positively with model performance. Our findings lead us to
propose translation-invariant self-attention (TISA), which accounts for the
relative position between tokens in an interpretable fashion without needing
conventional position embeddings. Our proposal has several theoretical
advantages over existing position-representation approaches. Experiments show
that it improves on regular ALBERT on GLUE tasks, while only adding orders of
magnitude less positional parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Provably Secure Generative Linguistic Steganography. (arXiv:2106.02011v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Siyu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zhongliang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinshuai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongfeng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02011">
                                    <div class="article-summary-box-inner">
                                        <span>Generative linguistic steganography mainly utilized language models and
applied steganographic sampling (stegosampling) to generate high-security
steganographic text (stegotext). However, previous methods generally lead to
statistical differences between the conditional probability distributions of
stegotext and natural text, which brings about security risks. In this paper,
to further ensure security, we present a novel provably secure generative
linguistic steganographic method ADG, which recursively embeds secret
information by Adaptive Dynamic Grouping of tokens according to their
probability given by an off-the-shelf language model. We not only prove the
security of ADG mathematically, but also conduct extensive experiments on three
public corpora to further verify its imperceptibility. The experimental results
reveal that the proposed method is able to generate stegotext with nearly
perfect security.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SOCCER: An Information-Sparse Discourse State Tracking Collection in the Sports Commentary Domain. (arXiv:2106.01972v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Ruochen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1">Carsten Eickhoff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01972">
                                    <div class="article-summary-box-inner">
                                        <span>In the pursuit of natural language understanding, there has been a long
standing interest in tracking state changes throughout narratives. Impressive
progress has been made in modeling the state of transaction-centric dialogues
and procedural texts. However, this problem has been less intensively studied
in the realm of general discourse where ground truth descriptions of states may
be loosely defined and state changes are less densely distributed over
utterances. This paper proposes to turn to simplified, fully observable systems
that show some of these properties: Sports events. We curated 2,263 soccer
matches including time-stamped natural language commentary accompanied by
discrete events such as a team scoring goals, switching players or being
penalized with cards. We propose a new task formulation where, given paragraphs
of commentary of a game at different timestamps, the system is asked to
recognize the occurrence of in-game events. This domain allows for rich
descriptions of state while avoiding the complexities of many other real-world
settings. As an initial point of performance measurement, we include two
baseline methods from the perspectives of sentence classification with temporal
dependence and current state-of-the-art generative model, respectively, and
demonstrate that even sophisticated existing methods struggle on the state
tracking task when the definition of state broadens or non-event chatter
becomes prevalent.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Distantly-Labeled Rationales in Neural Network Models. (arXiv:2106.01809v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Quzhe Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Shengqi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yansong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dongyan Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01809">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies strive to incorporate various human rationales into neural
networks to improve model performance, but few pay attention to the quality of
the rationales. Most existing methods distribute their models&#x27; focus to
distantly-labeled rationale words entirely and equally, while ignoring the
potential important non-rationale words and not distinguishing the importance
of different rationale words. In this paper, we propose two novel auxiliary
loss functions to make better use of distantly-labeled rationales, which
encourage models to maintain their focus on important words beyond labeled
rationales (PINs) and alleviate redundant training on non-helpful rationales
(NoIRs). Experiments on two representative classification tasks show that our
proposed methods can push a classification model to effectively learn crucial
clues from non-perfect rationales while maintaining the ability to spread its
focus to other unlabeled important words, thus significantly outperform
existing methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fingerprinting Fine-tuned Language Models in the Wild. (arXiv:2106.01703v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diwan_N/0/1/0/all/0/1">Nirav Diwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravorty_T/0/1/0/all/0/1">Tanmoy Chakravorty</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiq_Z/0/1/0/all/0/1">Zubair Shafiq</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01703">
                                    <div class="article-summary-box-inner">
                                        <span>There are concerns that the ability of language models (LMs) to generate high
quality synthetic text can be misused to launch spam, disinformation, or
propaganda. Therefore, the research community is actively working on developing
approaches to detect whether a given text is organic or synthetic. While this
is a useful first step, it is important to be able to further fingerprint the
author LM to attribute its origin. Prior work on fingerprinting LMs is limited
to attributing synthetic text generated by a handful (usually &lt; 10) of
pre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad
of ways (e.g., on a domain-specific text corpus) before being used to generate
synthetic text. It is challenging to fingerprinting fine-tuned LMs because the
universe of fine-tuned LMs is much larger in realistic scenarios. To address
this challenge, we study the problem of large-scale fingerprinting of
fine-tuned LMs in the wild. Using a real-world dataset of synthetic text
generated by 108 different fine-tuned LMs, we conduct comprehensive experiments
to demonstrate the limitations of existing fingerprinting approaches. Our
results show that fine-tuning itself is the most effective in attributing the
synthetic text generated by fine-tuned LMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages. (arXiv:2010.09322v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Diwan_A/0/1/0/all/0/1">Anuj Diwan</a>, <a href="http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09322">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents a seemingly simple but effective technique to improve
low-resource ASR systems for phonetic languages. By identifying sets of
acoustically similar graphemes in these languages, we first reduce the output
alphabet of the ASR system using linguistically meaningful reductions and then
reconstruct the original alphabet using a standalone module. We demonstrate
that this lessens the burden and improves the performance of low-resource
end-to-end ASR systems (because only reduced-alphabet predictions are needed)
and that it is possible to design a very simple but effective reconstruction
module that recovers sequences in the original alphabet from sequences in the
reduced alphabet. We present a finite state transducer-based reconstruction
module that operates on the 1-best ASR hypothesis in the reduced alphabet. We
demonstrate the efficacy of our proposed technique using ASR systems for two
Indian languages, Gujarati and Telugu. With access to only 10 hrs of speech
data, we obtain relative WER reductions of up to 7% compared to systems that do
not use any reduction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Template-Based Named Entity Recognition Using BART. (arXiv:2106.01760v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Leyang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jian Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1">Sen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yue Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01760">
                                    <div class="article-summary-box-inner">
                                        <span>There is a recent interest in investigating few-shot NER, where the
low-resource target domain has different label sets compared with a
resource-rich source domain. Existing methods use a similarity-based metric.
However, they cannot make full use of knowledge transfer in NER model
parameters. To address the issue, we propose a template-based method for NER,
treating NER as a language model ranking problem in a sequence-to-sequence
framework, where original sentences and statement templates filled by candidate
named entity span are regarded as the source sequence and the target sequence,
respectively. For inference, the model is required to classify each candidate
span based on the corresponding template scores. Our experiments demonstrate
that the proposed method achieves 92.55% F1 score on the CoNLL03 (rich-resource
task), and significantly better than fine-tuning BERT 10.88%, 15.34%, and
11.73% F1 score on the MIT Movie, the MIT Restaurant, and the ATIS
(low-resource task), respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Defending against Backdoor Attacks in Natural Language Generation. (arXiv:2106.01810v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1">Chun Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xiaoya Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1">Yuxian Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1">Xiaofei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1">Xiang Ao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1">Tianwei Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01810">
                                    <div class="article-summary-box-inner">
                                        <span>The frustratingly fragile nature of neural network models make current
natural language generation (NLG) systems prone to backdoor attacks and
generate malicious sequences that could be sexist or offensive. Unfortunately,
little effort has been invested to how backdoor attacks can affect current NLG
models and how to defend against these attacks. In this work, we investigate
this problem on two important NLG tasks, machine translation and dialogue
generation. By giving a formal definition for backdoor attack and defense, and
developing corresponding benchmarks, we design methods to attack NLG models,
which achieve high attack success to ask NLG models to generate malicious
sequences. To defend against these attacks, we propose to detect the attack
trigger by examining the effect of deleting or replacing certain words on the
generation outputs, which we find successful for certain types of attacks. We
will discuss the limitation of this work, and hope this work can raise the
awareness of backdoor risks concealed in deep NLG systems. (Code and data are
available at https://github.com/ShannonAI/backdoor_nlg.)</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SimCLS: A Simple Framework for Contrastive Learning of Abstractive Summarization. (arXiv:2106.01890v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yixin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01890">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present a conceptually simple while empirically powerful
framework for abstractive summarization, SimCLS, which can bridge the gap
between the learning objective and evaluation metrics resulting from the
currently dominated sequence-to-sequence learning framework by formulating text
generation as a reference-free evaluation problem (i.e., quality estimation)
assisted by contrastive learning. Experimental results show that, with minor
modification over existing top-scoring systems, SimCLS can improve the
performance of existing top-performing models by a large margin. Particularly,
2.51 absolute improvement against BART and 2.50 over PEGASUS w.r.t ROUGE-1 on
the CNN/DailyMail dataset, driving the state-of-the-art performance to a new
level. We have open-sourced our codes and results:
https://github.com/yixinL7/SimCLS. Results of our proposed models have been
deployed into ExplainaBoard platform, which allows researchers to understand
our systems in a more fine-grained way.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantifying language changes surrounding mental health on Twitter. (arXiv:2106.01481v1 [physics.soc-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Stupinski_A/0/1/0/all/0/1">Anne Marie Stupinski</a>, <a href="http://arxiv.org/find/physics/1/au:+Alshaabi_T/0/1/0/all/0/1">Thayer Alshaabi</a>, <a href="http://arxiv.org/find/physics/1/au:+Arnold_M/0/1/0/all/0/1">Michael V. Arnold</a>, <a href="http://arxiv.org/find/physics/1/au:+Adams_J/0/1/0/all/0/1">Jane Lydia Adams</a>, <a href="http://arxiv.org/find/physics/1/au:+Minot_J/0/1/0/all/0/1">Joshua R. Minot</a>, <a href="http://arxiv.org/find/physics/1/au:+Price_M/0/1/0/all/0/1">Matthew Price</a>, <a href="http://arxiv.org/find/physics/1/au:+Dodds_P/0/1/0/all/0/1">Peter Sheridan Dodds</a>, <a href="http://arxiv.org/find/physics/1/au:+Danforth_C/0/1/0/all/0/1">Christopher M. Danforth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01481">
                                    <div class="article-summary-box-inner">
                                        <span>Mental health challenges are thought to afflict around 10% of the global
population each year, with many going untreated due to stigma and limited
access to services. Here, we explore trends in words and phrases related to
mental health through a collection of 1- , 2-, and 3-grams parsed from a data
stream of roughly 10% of all English tweets since 2012. We examine temporal
dynamics of mental health language, finding that the popularity of the phrase
&#x27;mental health&#x27; increased by nearly two orders of magnitude between 2012 and
2018. We observe that mentions of &#x27;mental health&#x27; spike annually and reliably
due to mental health awareness campaigns, as well as unpredictably in response
to mass shootings, celebrities dying by suicide, and popular fictional stories
portraying suicide. We find that the level of positivity of messages containing
&#x27;mental health&#x27;, while stable through the growth period, has declined recently.
Finally, we use the ratio of original tweets to retweets to quantify the
fraction of appearances of mental health language due to social amplification.
Since 2015, mentions of mental health have become increasingly due to retweets,
suggesting that stigma associated with discussion of mental health on Twitter
has diminished with time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Shared Semantic Space for Speech-to-Text Translation. (arXiv:2105.03095v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_C/0/1/0/all/0/1">Chi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Mingxuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lei Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03095">
                                    <div class="article-summary-box-inner">
                                        <span>Having numerous potential applications and great impact, end-to-end speech
translation (ST) has long been treated as an independent task, failing to fully
draw strength from the rapid advances of its sibling - text machine translation
(MT). With text and audio inputs represented differently, the modality gap has
rendered MT data and its end-to-end models incompatible with their ST
counterparts. In observation of this obstacle, we propose to bridge this
representation gap with Chimera. By projecting audio and text features to a
common semantic representation, Chimera unifies MT and ST tasks and boosts the
performance on ST benchmarks, MuST-C and Augmented Librispeech, to a new
state-of-the-art. Specifically, Chimera obtains 27.1 BLEU on MuST-C EN-DE,
improving the SOTA by a +1.9 BLEU margin. Further experimental analyses
demonstrate that the shared semantic space indeed conveys common knowledge
between these two tasks and thus paves a new way for augmenting training
resources across modalities. Code, data, and resources are available at
https://github.com/Glaciohound/Chimera-ST.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Improved Baseline for Sentence-level Relation Extraction. (arXiv:2102.01373v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1">Wenxuan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Muhao Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01373">
                                    <div class="article-summary-box-inner">
                                        <span>Sentence-level relation extraction (RE) aims at identifying the relationship
between two entities in a sentence. Many efforts have been devoted to this
problem, while the best performing methods are still far from perfect. In this
paper, we revisit two problems that affect the performance of existing RE
models, namely entity representation and noisy or ill-defined labels. Our
improved baseline model, incorporated with entity representations with typed
markers, achieves an F1 of 74.6% on TACRED, significantly outperforms previous
SOTA methods. Furthermore, the presented new baseline achieves an F1 of 91.1%
on the refined Re-TACRED dataset, demonstrating that the pre-trained language
models achieve unexpectedly high performance on this task. We release our code
to the community for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Knowing More About Questions Can Help: Improving Calibration in Question Answering. (arXiv:2106.01494v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shujian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_C/0/1/0/all/0/1">Chengyue Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1">Eunsol Choi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01494">
                                    <div class="article-summary-box-inner">
                                        <span>We study calibration in question answering, estimating whether model
correctly predicts answer for each question. Unlike prior work which mainly
rely on the model&#x27;s confidence score, our calibrator incorporates information
about the input example (e.g., question and the evidence context). Together
with data augmentation via back translation, our simple approach achieves 5-10%
gains in calibration accuracy on reading comprehension benchmarks. Furthermore,
we present the first calibration study in the open retrieval setting, comparing
the calibration accuracy of retrieval-based span prediction models and answer
generation models. Here again, our approach shows consistent gains over
calibrators relying on the model confidence. Our simple and efficient
calibrator can be easily adapted to many tasks and model architectures, showing
robust gains in all settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MPC-BERT: A Pre-Trained Language Model for Multi-Party Conversation Understanding. (arXiv:2106.01541v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jia-Chen Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_C/0/1/0/all/0/1">Chongyang Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_Z/0/1/0/all/0/1">Zhen-Hua Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1">Can Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1">Xiubo Geng</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Daxin Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01541">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, various neural models for multi-party conversation (MPC) have
achieved impressive improvements on a variety of tasks such as addressee
recognition, speaker identification and response prediction. However, these
existing methods on MPC usually represent interlocutors and utterances
individually and ignore the inherent complicated structure in MPC which may
provide crucial interlocutor and utterance semantics and would enhance the
conversation understanding process. To this end, we present MPC-BERT, a
pre-trained model for MPC understanding that considers learning who says what
to whom in a unified model with several elaborated self-supervised tasks.
Particularly, these tasks can be generally categorized into (1) interlocutor
structure modeling including reply-to utterance recognition, identical speaker
searching and pointer consistency distinction, and (2) utterance semantics
modeling including masked shared utterance restoration and shared node
detection. We evaluate MPC-BERT on three downstream tasks including addressee
recognition, speaker identification and response selection. Experimental
results show that MPC-BERT outperforms previous methods by large margins and
achieves new state-of-the-art performance on all three downstream tasks at two
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Luna: Linear Unified Nested Attention. (arXiv:2106.01540v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xuezhe Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1">Xiang Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sinong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chunting Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01540">
                                    <div class="article-summary-box-inner">
                                        <span>The quadratic computational and memory complexities of the Transformer&#x27;s
attention mechanism have limited its scalability for modeling long sequences.
In this paper, we propose Luna, a linear unified nested attention mechanism
that approximates softmax attention with two nested linear attention functions,
yielding only linear (as opposed to quadratic) time and space complexity.
Specifically, with the first attention function, Luna packs the input sequence
into a sequence of fixed length. Then, the packed sequence is unpacked using
the second attention function. As compared to a more traditional attention
mechanism, Luna introduces an additional sequence with a fixed length as input
and an additional corresponding output, which allows Luna to perform attention
operation linearly, while also storing adequate contextual information. We
perform extensive evaluations on three benchmarks of sequence modeling tasks:
long-context sequence modeling, neural machine translation and masked language
modeling for large-scale pretraining. Competitive or even better experimental
results demonstrate both the effectiveness and efficiency of Luna compared to a
variety</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERT meets LIWC: Exploring State-of-the-Art Language Models for Predicting Communication Behavior in Couples&#x27; Conflict Interactions. (arXiv:2106.01536v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biggiogera_J/0/1/0/all/0/1">Jacopo Biggiogera</a>, <a href="http://arxiv.org/find/cs/1/au:+Boateng_G/0/1/0/all/0/1">George Boateng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilpert_P/0/1/0/all/0/1">Peter Hilpert</a>, <a href="http://arxiv.org/find/cs/1/au:+Vowels_M/0/1/0/all/0/1">Matthew Vowels</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodenmann_G/0/1/0/all/0/1">Guy Bodenmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Neysari_M/0/1/0/all/0/1">Mona Neysari</a>, <a href="http://arxiv.org/find/cs/1/au:+Nussbeck_F/0/1/0/all/0/1">Fridtjof Nussbeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowatsch_T/0/1/0/all/0/1">Tobias Kowatsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01536">
                                    <div class="article-summary-box-inner">
                                        <span>Many processes in psychology are complex, such as dyadic interactions between
two interacting partners (e.g. patient-therapist, intimate relationship
partners). Nevertheless, many basic questions about interactions are difficult
to investigate because dyadic processes can be within a person and between
partners, they are based on multimodal aspects of behavior and unfold rapidly.
Current analyses are mainly based on the behavioral coding method, whereby
human coders annotate behavior based on a coding schema. But coding is
labor-intensive, expensive, slow, focuses on few modalities. Current approaches
in psychology use LIWC for analyzing couples&#x27; interactions. However, advances
in natural language processing such as BERT could enable the development of
systems to potentially automate behavioral coding, which in turn could
substantially improve psychological research. In this work, we train machine
learning models to automatically predict positive and negative communication
behavioral codes of 368 German-speaking Swiss couples during an 8-minute
conflict interaction on a fine-grained scale (10-seconds sequences) using
linguistic features and paralinguistic features derived with openSMILE. Our
results show that both simpler TF-IDF features as well as more complex BERT
features performed better than LIWC, and that adding paralinguistic features
did not improve the performance. These results suggest it might be time to
consider modern alternatives to LIWC, the de facto linguistic features in
psychology, for prediction tasks in couples research. This work is a further
step towards the automated coding of couples&#x27; behavior which could enhance
couple research and therapy, and be utilized for other dyadic interactions as
well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;You made me feel this way&quot;: Investigating Partners&#x27; Influence in Predicting Emotions in Couples&#x27; Conflict Interactions using Speech Data. (arXiv:2106.01526v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Boateng_G/0/1/0/all/0/1">George Boateng</a>, <a href="http://arxiv.org/find/cs/1/au:+Hilpert_P/0/1/0/all/0/1">Peter Hilpert</a>, <a href="http://arxiv.org/find/cs/1/au:+Bodenmann_G/0/1/0/all/0/1">Guy Bodenmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Neysari_M/0/1/0/all/0/1">Mona Neysari</a>, <a href="http://arxiv.org/find/cs/1/au:+Kowatsch_T/0/1/0/all/0/1">Tobias Kowatsch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01526">
                                    <div class="article-summary-box-inner">
                                        <span>How romantic partners interact with each other during a conflict influences
how they feel at the end of the interaction and is predictive of whether the
partners stay together in the long term. Hence understanding the emotions of
each partner is important. Yet current approaches that are used include
self-reports which are burdensome and hence limit the frequency of this data
collection. Automatic emotion prediction could address this challenge. Insights
from psychology research indicate that partners&#x27; behaviors influence each
other&#x27;s emotions in conflict interaction and hence, the behavior of both
partners could be considered to better predict each partner&#x27;s emotion. However,
it is yet to be investigated how doing so compares to only using each partner&#x27;s
own behavior in terms of emotion prediction performance. In this work, we used
BERT to extract linguistic features (i.e., what partners said) and openSMILE to
extract paralinguistic features (i.e., how they said it) from a data set of 368
German-speaking Swiss couples (N &#x3D; 736 individuals) which were videotaped
during an 8-minutes conflict interaction in the laboratory. Based on those
features, we trained machine learning models to predict if partners feel
positive or negative after the conflict interaction. Our results show that
including the behavior of the other partner improves the prediction
performance. Furthermore, for men, considering how their female partners spoke
is most important and for women considering what their male partner said is
most important in getting better prediction performance. This work is a step
towards automatically recognizing each partners&#x27; emotion based on the behavior
of both, which would enable a better understanding of couples in research,
therapy, and the real world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Fine-Grained Entity Types with Box Embeddings. (arXiv:2101.00345v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Onoe_Y/0/1/0/all/0/1">Yasumasa Onoe</a>, <a href="http://arxiv.org/find/cs/1/au:+Boratko_M/0/1/0/all/0/1">Michael Boratko</a>, <a href="http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1">Andrew McCallum</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1">Greg Durrett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00345">
                                    <div class="article-summary-box-inner">
                                        <span>Neural entity typing models typically represent fine-grained entity types as
vectors in a high-dimensional space, but such spaces are not well-suited to
modeling these types&#x27; complex interdependencies. We study the ability of box
embeddings, which embed concepts as d-dimensional hyperrectangles, to capture
hierarchies of types even when these relationships are not defined explicitly
in the ontology. Our model represents both types and entity mentions as boxes.
Each mention and its context are fed into a BERT-based model to embed that
mention in our box space; essentially, this model leverages typological clues
present in the surface text to hypothesize a type representation for the
mention. Box containment can then be used to derive both the posterior
probability of a mention exhibiting a given type and the conditional
probability relations between types themselves. We compare our approach with a
vector-based typing model and observe state-of-the-art performance on several
entity typing benchmarks. In addition to competitive typing performance, our
box-based model shows better performance in prediction consistency (predicting
a supertype and a subtype together) and confidence (i.e., calibration),
demonstrating that the box-based model captures the latent type hierarchies
better than the vector-based model does.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Training Multilingual Pre-trained Language Model with Byte-level Subwords. (arXiv:2101.09469v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1">Junqiu Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yinpeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xin Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.09469">
                                    <div class="article-summary-box-inner">
                                        <span>The pre-trained language models have achieved great successes in various
natural language understanding (NLU) tasks due to its capacity to capture the
deep contextualized information in text by pre-training on large-scale corpora.
One of the fundamental components in pre-trained language models is the
vocabulary, especially for training multilingual models on many different
languages. In the technical report, we present our practices on training
multilingual pre-trained language models with BBPE: Byte-Level BPE (i.e., Byte
Pair Encoding). In the experiment, we adopted the architecture of NEZHA as the
underlying pre-trained language model and the results show that NEZHA trained
with byte-level subwords consistently outperforms Google multilingual BERT and
vanilla NEZHA by a notable margin in several multilingual NLU tasks. We release
the source code of our byte-level vocabulary building tools and the
multilingual pre-trained language models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dissecting Generation Modes for Abstractive Summarization Models via Ablation and Attribution. (arXiv:2106.01518v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1">Jiacheng Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1">Greg Durrett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01518">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the prominence of neural abstractive summarization models, we know
little about how they actually form summaries and how to understand where their
decisions come from. We propose a two-step method to interpret summarization
model decisions. We first analyze the model&#x27;s behavior by ablating the full
model to categorize each decoder decision into one of several generation modes:
roughly, is the model behaving like a language model, is it relying heavily on
the input, or is it somewhere in between? After isolating decisions that do
depend on the input, we explore interpreting these decisions using several
different attribution methods. We compare these techniques based on their
ability to select content and reconstruct the model&#x27;s predicted token from
perturbations of the input, thus revealing whether highlighted attributions are
truly important for the generation of the next token. While this machinery can
be broadly useful even beyond summarization, we specifically demonstrate its
capability to identify phrases the summarization model has memorized and
determine where in the training pipeline this memorization happened, as well as
study complex generation phenomena like sentence fusion on a per-instance
basis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating the Efficacy of Summarization Evaluation across Languages. (arXiv:2106.01478v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Koto_F/0/1/0/all/0/1">Fajri Koto</a>, <a href="http://arxiv.org/find/cs/1/au:+Lau_J/0/1/0/all/0/1">Jey Han Lau</a>, <a href="http://arxiv.org/find/cs/1/au:+Baldwin_T/0/1/0/all/0/1">Timothy Baldwin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01478">
                                    <div class="article-summary-box-inner">
                                        <span>While automatic summarization evaluation methods developed for English are
routinely applied to other languages, this is the first attempt to
systematically quantify their panlinguistic efficacy. We take a summarization
corpus for eight different languages, and manually annotate generated summaries
for focus (precision) and coverage (recall). Based on this, we evaluate 19
summarization evaluation metrics, and find that using multilingual BERT within
BERTScore performs well across all languages, at a level above that for
English.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SMURF: SeMantic and linguistic UndeRstanding Fusion for Caption Evaluation via Typicality Analysis. (arXiv:2106.01444v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feinglass_J/0/1/0/all/0/1">Joshua Feinglass</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yezhou Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01444">
                                    <div class="article-summary-box-inner">
                                        <span>The open-ended nature of visual captioning makes it a challenging area for
evaluation. The majority of proposed models rely on specialized training to
improve human-correlation, resulting in limited adoption, generalizability, and
explainabilty. We introduce &quot;typicality&quot;, a new formulation of evaluation
rooted in information theory, which is uniquely suited for problems lacking a
definite ground truth. Typicality serves as our framework to develop a novel
semantic comparison, SPARCS, as well as referenceless fluency evaluation
metrics. Over the course of our analysis, two separate dimensions of fluency
naturally emerge: style, captured by metric SPURTS, and grammar, captured in
the form of grammatical outlier penalties. Through extensive experiments and
ablation studies on benchmark datasets, we show how these decomposed dimensions
of semantics and fluency provide greater system-level insight into captioner
differences. Our proposed metrics along with their combination, SMURF, achieve
state-of-the-art correlation with human judgment when compared with other
rule-based evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-based Contextual Language Model Adaptation for Speech Recognition. (arXiv:2106.01451v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Martinez_R/0/1/0/all/0/1">Richard Diehl Martinez</a>, <a href="http://arxiv.org/find/cs/1/au:+Novotney_S/0/1/0/all/0/1">Scott Novotney</a>, <a href="http://arxiv.org/find/cs/1/au:+Bulyko_I/0/1/0/all/0/1">Ivan Bulyko</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastrow_A/0/1/0/all/0/1">Ariya Rastrow</a>, <a href="http://arxiv.org/find/cs/1/au:+Stolcke_A/0/1/0/all/0/1">Andreas Stolcke</a>, <a href="http://arxiv.org/find/cs/1/au:+Gandhe_A/0/1/0/all/0/1">Ankur Gandhe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01451">
                                    <div class="article-summary-box-inner">
                                        <span>Language modeling (LM) for automatic speech recognition (ASR) does not
usually incorporate utterance level contextual information. For some domains
like voice assistants, however, additional context, such as the time at which
an utterance was spoken, provides a rich input signal. We introduce an
attention mechanism for training neural speech recognition language models on
both text and non-linguistic contextual data. When applied to a large
de-identified dataset of utterances collected by a popular voice assistant
platform, our method reduces perplexity by 7.0% relative over a standard LM
that does not incorporate contextual information. When evaluated on utterances
extracted from the long tail of the dataset, our method improves perplexity by
9.0% relative over a standard LM and by over 2.8% relative when compared to a
state-of-the-art model for contextual LM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Select: A Fully Attentive Approach for Novel Object Captioning. (arXiv:2106.01424v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cagrandi_M/0/1/0/all/0/1">Marco Cagrandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cornia_M/0/1/0/all/0/1">Marcella Cornia</a>, <a href="http://arxiv.org/find/cs/1/au:+Stefanini_M/0/1/0/all/0/1">Matteo Stefanini</a>, <a href="http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1">Lorenzo Baraldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1">Rita Cucchiara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01424">
                                    <div class="article-summary-box-inner">
                                        <span>Image captioning models have lately shown impressive results when applied to
standard datasets. Switching to real-life scenarios, however, constitutes a
challenge due to the larger variety of visual concepts which are not covered in
existing training sets. For this reason, novel object captioning (NOC) has
recently emerged as a paradigm to test captioning models on objects which are
unseen during the training phase. In this paper, we present a novel approach
for NOC that learns to select the most relevant objects of an image, regardless
of their adherence to the training set, and to constrain the generative process
of a language model accordingly. Our architecture is fully-attentive and
end-to-end trainable, also when incorporating constraints. We perform
experiments on the held-out COCO dataset, where we demonstrate improvements
over the state of the art, both in terms of adaptability to novel objects and
caption quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?. (arXiv:2106.01465v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jieyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1">Daniel Khashabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1">Tushar Khot</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1">Ashish Sabharwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01465">
                                    <div class="article-summary-box-inner">
                                        <span>Is it possible to use natural language to intervene in a model&#x27;s behavior and
alter its prediction in a desired way? We investigate the effectiveness of
natural language interventions for reading-comprehension systems, studying this
in the context of social stereotypes. Specifically, we propose a new language
understanding task, Linguistic Ethical Interventions (LEI), where the goal is
to amend a question-answering (QA) model&#x27;s unethical behavior by communicating
context-specific principles of ethics and equity to it. To this end, we build
upon recent methods for quantifying a system&#x27;s social stereotypes, augmenting
them with different kinds of ethical interventions and the desired model
behavior under such interventions. Our zero-shot evaluation finds that even
today&#x27;s powerful neural language models are extremely poor ethical-advice
takers, that is, they respond surprisingly little to ethical interventions even
though these interventions are stated as simple sentences. Few-shot learning
improves model behavior but remains far from the desired outcome, especially
when evaluated for various types of generalization. Our new task thus poses a
novel language understanding challenge for the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lightweight Adapter Tuning for Multilingual Speech Translation. (arXiv:2106.01463v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1">Hang Le</a>, <a href="http://arxiv.org/find/cs/1/au:+Pino_J/0/1/0/all/0/1">Juan Pino</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Changhan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jiatao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwab_D/0/1/0/all/0/1">Didier Schwab</a>, <a href="http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1">Laurent Besacier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01463">
                                    <div class="article-summary-box-inner">
                                        <span>Adapter modules were recently introduced as an efficient alternative to
fine-tuning in NLP. Adapter tuning consists in freezing pretrained parameters
of a model and injecting lightweight modules between layers, resulting in the
addition of only a small number of task-specific trainable parameters. While
adapter tuning was investigated for multilingual neural machine translation,
this paper proposes a comprehensive analysis of adapters for multilingual
speech translation (ST). Starting from different pre-trained models (a
multilingual ST trained on parallel data or a multilingual BART (mBART) trained
on non-parallel multilingual data), we show that adapters can be used to: (a)
efficiently specialize ST to specific language pairs with a low extra cost in
terms of parameters, and (b) transfer from an automatic speech recognition
(ASR) task and an mBART pre-trained model to a multilingual ST task.
Experiments show that adapter tuning offer competitive results to full
fine-tuning, while being much more parameter-efficient.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Preliminary Study of a Two-Stage Paradigm for Preserving Speaker Identity in Dysarthric Voice Conversion. (arXiv:2106.01415v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wen-Chin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_K/0/1/0/all/0/1">Kazuhiro Kobayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1">Yu-Huai Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1">Ching-Feng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1">Yu Tsao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hsin-Min Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Toda_T/0/1/0/all/0/1">Tomoki Toda</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01415">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a new paradigm for maintaining speaker identity in dysarthric
voice conversion (DVC). The poor quality of dysarthric speech can be greatly
improved by statistical VC, but as the normal speech utterances of a dysarthria
patient are nearly impossible to collect, previous work failed to recover the
individuality of the patient. In light of this, we suggest a novel, two-stage
approach for DVC, which is highly flexible in that no normal speech of the
patient is required. First, a powerful parallel sequence-to-sequence model
converts the input dysarthric speech into a normal speech of a reference
speaker as an intermediate product, and a nonparallel, frame-wise VC model
realized with a variational autoencoder then converts the speaker identity of
the reference speech back to that of the patient while assumed to be capable of
preserving the enhanced quality. We investigate several design options.
Experimental evaluation results demonstrate the potential of our approach to
improving the quality of the dysarthric speech while maintaining the speaker
identity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can vectors read minds better than experts? Comparing data augmentation strategies for the automated scoring of children&#x27;s mindreading ability. (arXiv:2106.01635v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovatchev_V/0/1/0/all/0/1">Venelin Kovatchev</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_P/0/1/0/all/0/1">Phillip Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Mark Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Devine_R/0/1/0/all/0/1">Rory Devine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01635">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we implement and compare 7 different data augmentation
strategies for the task of automatic scoring of children&#x27;s ability to
understand others&#x27; thoughts, feelings, and desires (or &quot;mindreading&quot;).

We recruit in-domain experts to re-annotate augmented samples and determine
to what extent each strategy preserves the original rating. We also carry out
multiple experiments to measure how much each augmentation strategy improves
the performance of automatic scoring systems. To determine the capabilities of
automatic systems to generalize to unseen data, we create UK-MIND-20 - a new
corpus of children&#x27;s performance on tests of mindreading, consisting of 10,320
question-answer pairs.

We obtain a new state-of-the-art performance on the MIND-CA corpus, improving
macro-F1-score by 6 points. Results indicate that both the number of training
examples and the quality of the augmentation strategies affect the performance
of the systems. The task-specific augmentations generally outperform
task-agnostic augmentations. Automatic augmentations based on vectors (GloVe,
FastText) perform the worst.

We find that systems trained on MIND-CA generalize well to UK-MIND-20. We
demonstrate that data augmentation strategies also improve the performance on
unseen data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TVDIM: Enhancing Image Self-Supervised Pretraining via Noisy Text Data. (arXiv:2106.01797v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qin_P/0/1/0/all/0/1">Pengda Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuhong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01797">
                                    <div class="article-summary-box-inner">
                                        <span>Among ubiquitous multimodal data in the real world, text is the modality
generated by human, while image reflects the physical world honestly. In a
visual understanding application, machines are expected to understand images
like human. Inspired by this, we propose a novel self-supervised learning
method, named Text-enhanced Visual Deep InfoMax (TVDIM), to learn better visual
representations by fully utilizing the naturally-existing multimodal data. Our
core idea of self-supervised learning is to maximize the mutual information
between features extracted from multiple views of a shared context to a
rational degree. Different from previous methods which only consider multiple
views from a single modality, our work produces multiple views from different
modalities, and jointly optimizes the mutual information for features pairs of
intra-modality and inter-modality. Considering the information gap between
inter-modality features pairs from data noise, we adopt a \emph{ranking-based}
contrastive learning to optimize the mutual information. During evaluation, we
directly use the pre-trained visual representations to complete various image
classification tasks. Experimental results show that, TVDIM significantly
outperforms previous visual self-supervised methods when processing the same
set of images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dataset and Baselines for Multilingual Reply Suggestion. (arXiv:2106.02017v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mozhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deb_B/0/1/0/all/0/1">Budhaditya Deb</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1">Guoqing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1">Milad Shokouhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1">Ahmed Hassan Awadallah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02017">
                                    <div class="article-summary-box-inner">
                                        <span>Reply suggestion models help users process emails and chats faster. Previous
work only studies English reply suggestion. Instead, we present MRS, a
multilingual reply suggestion dataset with ten languages. MRS can be used to
compare two families of models: 1) retrieval models that select the reply from
a fixed set and 2) generation models that produce the reply from scratch.
Therefore, MRS complements existing cross-lingual generalization benchmarks
that focus on classification and sequence labeling tasks. We build a generation
model and a retrieval model as baselines for MRS. The two models have different
strengths in the monolingual setting, and they require different strategies to
generalize across languages. MRS is publicly available at
https://github.com/zhangmozhi/mrs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Generative Pre-trained Language Models Serve as Knowledge Bases for Closed-book QA?. (arXiv:2106.01561v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cunxiang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pai Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yue Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01561">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has investigated the interesting question using pre-trained
language models (PLMs) as knowledge bases for answering open questions.
However, existing work is limited in using small benchmarks with high
test-train overlaps. We construct a new dataset of closed-book QA using SQuAD,
and investigate the performance of BART. Experiments show that it is
challenging for BART to remember training facts in high precision, and also
challenging to answer closed-book questions even if relevant knowledge is
retained. Some promising directions are found, including decoupling the
knowledge memorizing process and the QA finetune process, forcing the model to
recall relevant knowledge when question answering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Spoken Term Discovery Based on Re-clustering of Hypothesized Speech Segments with Siamese and Triplet Networks. (arXiv:2011.14062v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sung_M/0/1/0/all/0/1">Man-Ling Sung</a>, <a href="http://arxiv.org/find/eess/1/au:+Lee_T/0/1/0/all/0/1">Tan Lee</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14062">
                                    <div class="article-summary-box-inner">
                                        <span>Spoken term discovery from untranscribed speech audio could be achieved via a
two-stage process. In the first stage, the unlabelled speech is decoded into a
sequence of subword units that are learned and modelled in an unsupervised
manner. In the second stage, partial sequence matching and clustering are
performed on the decoded subword sequences, resulting in a set of discovered
words or phrases. A limitation of this approach is that the results of subword
decoding could be erroneous, and the errors would impact the subsequent steps.
While Siamese/Triplet network is one approach to learn segment representations
that can improve the discovery process, the challenge in spoken term discovery
under a complete unsupervised scenario is that training examples are
unavailable. In this paper, we propose to generate training examples from
initial hypothesized sequence clusters. The Siamese/Triplet network is trained
on the hypothesized examples to measure the similarity between two speech
segments and hereby perform re-clustering of all hypothesized subword sequences
to achieve spoken term discovery. Experimental results show that the proposed
approach is effective in obtaining training examples for Siamese and Triplet
networks, improving the efficacy of spoken term discovery as compared with the
original two-stage method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Auto-tagging of Short Conversational Sentences using Transformer Methods. (arXiv:2106.01735v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tasar_D/0/1/0/all/0/1">D. Emre Ta&#x15f;ar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozdil_U/0/1/0/all/0/1">Umut &#xd6;zdil</a>, <a href="http://arxiv.org/find/cs/1/au:+Akca_M/0/1/0/all/0/1">M. Fatih Akca</a>, <a href="http://arxiv.org/find/cs/1/au:+Olmez_O/0/1/0/all/0/1">O&#x11f;uzhan &#xd6;lmez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gulum_S/0/1/0/all/0/1">Semih G&#xfc;l&#xfc;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutal_S/0/1/0/all/0/1">Se&#xe7;ilay Kutal</a>, <a href="http://arxiv.org/find/cs/1/au:+Belhan_C/0/1/0/all/0/1">Ceren Belhan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01735">
                                    <div class="article-summary-box-inner">
                                        <span>The problem of categorizing short speech sentences according to their
semantic features with high accuracy is a subject studied in natural language
processing. In this study, a data set created with samples classified in 46
different categories was used. Examples consist of sentences taken from chat
conversations between a company&#x27;s customer representatives and the company&#x27;s
website visitors. The primary purpose is to automatically tag questions and
requests from visitors in the most accurate way for 46 predetermined categories
for use in a chat application to generate meaningful answers to the questions
asked by the website visitors. For this, different BERT models and one GPT-2
model, pre-trained in Turkish, were preferred. The classification performances
of the relevant models were analyzed in detail and reported accordingly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attacking Text Classifiers via Sentence Rewriting Sampler. (arXiv:2104.08453v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1">Lei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Veeramachaneni_K/0/1/0/all/0/1">Kalyan Veeramachaneni</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08453">
                                    <div class="article-summary-box-inner">
                                        <span>Most adversarial attack methods on text classification can change the
classifier&#x27;s prediction by synonym substitution. We propose the adversarial
sentence rewriting sampler (ASRS), which rewrites the whole sentence to
generate more similar and higher-quality adversarial examples. Our method
achieves a better attack success rate on 4 out of 7 datasets, as well as
significantly better sentence quality on all 7 datasets. ASRS is an
indispensable supplement to the existing attack methods, because classifiers
cannot resist the attack from ASRS unless they are trained on adversarial
examples found by ASRS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Improved Model for Voicing Silent Speech. (arXiv:2106.01933v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gaddy_D/0/1/0/all/0/1">David Gaddy</a>, <a href="http://arxiv.org/find/eess/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01933">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present an improved model for voicing silent speech, where
audio is synthesized from facial electromyography (EMG) signals. To give our
model greater flexibility to learn its own input features, we directly use EMG
signals as input in the place of hand-designed features used by prior work. Our
model uses convolutional layers to extract features from the signals and
Transformer layers to propagate information across longer distances. To provide
better signal for learning, we also introduce an auxiliary task of predicting
phoneme labels in addition to predicting speech audio features. On an open
vocabulary intelligibility evaluation, our model improves the state of the art
for this task by an absolute 25.8%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively Inspired Orthographic Adversarial Attacks. (arXiv:2106.01452v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keller_Y/0/1/0/all/0/1">Yannik Keller</a>, <a href="http://arxiv.org/find/cs/1/au:+Mackensen_J/0/1/0/all/0/1">Jan Mackensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1">Steffen Eger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01452">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial attacks expose important blind spots of deep learning systems.
While word- and sentence-level attack scenarios mostly deal with finding
semantic paraphrases of the input that fool NLP models, character-level attacks
typically insert typos into the input stream. It is commonly thought that these
are easier to defend via spelling correction modules. In this work, we show
that both a standard spellchecker and the approach of Pruthi et al. (2019),
which trains to defend against insertions, deletions and swaps, perform poorly
on the character-level benchmark recently proposed in Eger and Benz (2020)
which includes more challenging attacks such as visual and phonetic
perturbations and missing word segmentations. In contrast, we show that an
untrained iterative approach which combines context-independent character-level
information with context-dependent information from BERT&#x27;s masked language
modeling can perform on par with human crowd-workers from Amazon Mechanical
Turk (AMT) supervised via 3-shot learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CitationIE: Leveraging the Citation Graph for Scientific Information Extraction. (arXiv:2106.01560v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Viswanathan_V/0/1/0/all/0/1">Vijay Viswanathan</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1">Pengfei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01560">
                                    <div class="article-summary-box-inner">
                                        <span>Automatically extracting key information from scientific documents has the
potential to help scientists work more efficiently and accelerate the pace of
scientific progress. Prior work has considered extracting document-level entity
clusters and relations end-to-end from raw scientific text, which can improve
literature search and help identify methods and materials for a given problem.
Despite the importance of this task, most existing works on scientific
information extraction (SciIE) consider extraction solely based on the content
of an individual paper, without considering the paper&#x27;s place in the broader
literature. In contrast to prior work, we augment our text representations by
leveraging a complementary source of document context: the citation graph of
referential links between citing and cited papers. On a test set of
English-language scientific documents, we show that simple ways of utilizing
the structure and content of the citation graph can each lead to significant
gains in different scientific information extraction tasks. When these tasks
are combined, we observe a sizable improvement in end-to-end information
extraction over the state-of-the-art, suggesting the potential for future work
along this direction. We release software tools to facilitate citation-aware
SciIE development.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">To Point or Not to Point: Understanding How Abstractive Summarizers Paraphrase Text. (arXiv:2106.01581v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wilber_M/0/1/0/all/0/1">Matt Wilber</a>, <a href="http://arxiv.org/find/cs/1/au:+Timkey_W/0/1/0/all/0/1">William Timkey</a>, <a href="http://arxiv.org/find/cs/1/au:+Schijndel_M/0/1/0/all/0/1">Marten Van Schijndel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01581">
                                    <div class="article-summary-box-inner">
                                        <span>Abstractive neural summarization models have seen great improvements in
recent years, as shown by ROUGE scores of the generated summaries. But despite
these improved metrics, there is limited understanding of the strategies
different models employ, and how those strategies relate their understanding of
language. To understand this better, we run several experiments to characterize
how one popular abstractive model, the pointer-generator model of See et al.
(2017), uses its explicit copy/generation switch to control its level of
abstraction (generation) vs extraction (copying). On an extractive-biased
dataset, the model utilizes syntactic boundaries to truncate sentences that are
otherwise often copied verbatim. When we modify the copy/generation switch and
force the model to generate, only simple paraphrasing abilities are revealed
alongside factual inaccuracies and hallucinations. On an abstractive-biased
dataset, the model copies infrequently but shows similarly limited abstractive
abilities. In line with previous research, these results suggest that
abstractive summarization models lack the semantic understanding necessary to
generate paraphrases that are both abstractive and faithful to the source
document.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PsyQA: A Chinese Dataset for Generating Long Counseling Text for Mental Health Support. (arXiv:2106.01702v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Hao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhenru Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Chujie Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01702">
                                    <div class="article-summary-box-inner">
                                        <span>Great research interests have been attracted to devise AI services that are
able to provide mental health support. However, the lack of corpora is a main
obstacle to this research, particularly in Chinese language. In this paper, we
propose PsyQA, a Chinese dataset of psychological health support in the form of
question and answer pair. PsyQA is crawled from a Chinese mental health service
platform, and contains 22K questions and 56K long and well-structured answers.
Based on the psychological counseling theories, we annotate a portion of answer
texts with typical strategies for providing support, and further present
in-depth analysis of both lexical features and strategy patterns in the
counseling answers. We also evaluate the performance of generating counseling
answers with the generative pretrained models. Results show that utilizing
strategies enhances the fluency and helpfulness of generated answers, but there
is still a large space for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UnitedQA: A Hybrid Approach for Open Domain Question Answering. (arXiv:2101.00178v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cheng_H/0/1/0/all/0/1">Hao Cheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yelong Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xiaodong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1">Pengcheng He</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Weizhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00178">
                                    <div class="article-summary-box-inner">
                                        <span>To date, most of recent work under the retrieval-reader framework for
open-domain QA focuses on either extractive or generative reader exclusively.
In this paper, we study a hybrid approach for leveraging the strengths of both
models. We apply novel techniques to enhance both extractive and generative
readers built upon recent pretrained neural language models, and find that
proper training methods can provide large improvement over previous
state-of-the-art models. We demonstrate that a simple hybrid approach by
combining answers from both readers can efficiently take advantages of
extractive and generative answer inference strategies and outperforms single
models as well as homogeneous ensembles. Our approach outperforms previous
state-of-the-art models by 3.3 and 2.7 points in exact match on
NaturalQuestions and TriviaQA respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MedNLI Is Not Immune: Natural Language Inference Artifacts in the Clinical Domain. (arXiv:2106.01491v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Herlihy_C/0/1/0/all/0/1">Christine Herlihy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudinger_R/0/1/0/all/0/1">Rachel Rudinger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01491">
                                    <div class="article-summary-box-inner">
                                        <span>Crowdworker-constructed natural language inference (NLI) datasets have been
found to contain statistical artifacts associated with the annotation process
that allow hypothesis-only classifiers to achieve better-than-random
performance (Poliak et al., 2018; Gururanganet et al., 2018; Tsuchiya, 2018).
We investigate whether MedNLI, a physician-annotated dataset with premises
extracted from clinical notes, contains such artifacts (Romanov and Shivade,
2018). We find that entailed hypotheses contain generic versions of specific
concepts in the premise, as well as modifiers related to responsiveness,
duration, and probability. Neutral hypotheses feature conditions and behaviors
that co-occur with, or cause, the condition(s) in the premise. Contradiction
hypotheses feature explicit negation of the premise and implicit negation via
assertion of good health. Adversarial filtering demonstrates that performance
degrades when evaluated on the difficult subset. We provide partition
information and recommendations for alternative dataset construction strategies
for knowledge-intensive domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Learning of Remote Sensing Scene Representations Using Contrastive Multiview Coding. (arXiv:2104.07070v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stojnic_V/0/1/0/all/0/1">Vladan Stojni&#x107;</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Risojevic_V/0/1/0/all/0/1">Vladimir Risojevi&#x107;</a> (1) ((1) Faculty of Electrical Engineering, University of Banja Luka, Bosnia and Herzegovina)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.07070">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years self-supervised learning has emerged as a promising candidate
for unsupervised representation learning. In the visual domain its applications
are mostly studied in the context of images of natural scenes. However, its
applicability is especially interesting in specific areas, like remote sensing
and medicine, where it is hard to obtain huge amounts of labeled data. In this
work, we conduct an extensive analysis of the applicability of self-supervised
learning in remote sensing image classification. We analyze the influence of
the number and domain of images used for self-supervised pre-training on the
performance on downstream tasks. We show that, for the downstream task of
remote sensing image classification, using self-supervised pre-training on
remote sensing images can give better results than using supervised
pre-training on images of natural scenes. Besides, we also show that
self-supervised pre-training can be easily extended to multispectral images
producing even better results on our downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large-Scale Spatio-Temporal Person Re-identification: Algorithm and Benchmark. (arXiv:2105.15076v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shu_X/0/1/0/all/0/1">Xiujun Shu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shiliang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xianghao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuanqi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Ge Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15076">
                                    <div class="article-summary-box-inner">
                                        <span>Person re-identification (re-ID) in the scenario with large spatial and
temporal spans has not been fully explored. This is partially because that,
existing benchmark datasets were mainly collected with limited spatial and
temporal ranges, e.g., using videos recorded in a few days by cameras in a
specific region of the campus. Such limited spatial and temporal ranges make it
hard to simulate the difficulties of person re-ID in real scenarios. In this
work, we contribute a novel Large-scale Spatio-Temporal (LaST) person re-ID
dataset, including 10,860 identities with more than 224k images. Compared with
existing datasets, LaST presents more challenging and high-diversity reID
settings, and significantly larger spatial and temporal ranges. For instance,
each person can appear in different cities or countries, and in various time
slots from daytime to night, and in different seasons from spring to winter. To
our best knowledge, LaST is a novel person re-ID dataset with the largest
spatiotemporal ranges. Based on LaST, we verified its challenge by conducting a
comprehensive performance evaluation of 14 re-ID algorithms. We further propose
an easy-to-implement baseline that works well on such challenging re-ID
setting. We also verified that models pre-trained on LaST can generalize well
on existing datasets with short-term and cloth-changing scenarios. We expect
LaST to inspire future works toward more realistic and challenging re-ID tasks.
More information about the dataset is available at
https://github.com/shuxjweb/last.git.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A remark on a paper of Krotov and Hopfield [arXiv:2008.06996]. (arXiv:2105.15034v2 [q-bio.NC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Tang_F/0/1/0/all/0/1">Fei Tang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kopp_M/0/1/0/all/0/1">Michael Kopp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15034">
                                    <div class="article-summary-box-inner">
                                        <span>In their recent paper titled &quot;Large Associative Memory Problem in
Neurobiology and Machine Learning&quot; [arXiv:2008.06996] the authors gave a
biologically plausible microscopic theory from which one can recover many dense
associative memory models discussed in the literature. We show that the layers
of the recent &quot;MLP-mixer&quot; [arXiv:2105.01601] as well as the essentially
equivalent model in [arXiv:2105.02723] are amongst them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation. (arXiv:2105.04447v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Bing Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Cheng Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Giancola_S/0/1/0/all/0/1">Silvio Giancola</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04447">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a novel scene flow estimation approach to capture and infer 3D
motions from point clouds. Estimating 3D motions for point clouds is
challenging, since a point cloud is unordered and its density is significantly
non-uniform. Such unstructured data poses difficulties in matching
corresponding points between point clouds, leading to inaccurate flow
estimation. We propose a novel architecture named Sparse
Convolution-Transformer Network (SCTN) that equips the sparse convolution with
the transformer. Specifically, by leveraging the sparse convolution, SCTN
transfers irregular point cloud into locally consistent flow features for
estimating continuous and consistent motions within an object/local object
part. We further propose to explicitly learn point relations using a point
transformer module, different from exiting methods. We show that the learned
relation-based contextual information is rich and helpful for matching
corresponding points, benefiting scene flow estimation. In addition, a novel
loss function is proposed to adaptively encourage flow consistency according to
feature similarity. Extensive experiments demonstrate that our proposed
approach achieves a new state of the art in scene flow estimation. Our approach
achieves an error of 0.038 and 0.037 (EPE3D) on FlyingThings3D and KITTI Scene
Flow respectively, which significantly outperforms previous methods by large
margins.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CFPNet: Channel-wise Feature Pyramid for Real-Time Semantic Segmentation. (arXiv:2103.12212v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lou_A/0/1/0/all/0/1">Ange Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Loew_M/0/1/0/all/0/1">Murray Loew</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12212">
                                    <div class="article-summary-box-inner">
                                        <span>Real-time semantic segmentation is playing a more important role in computer
vision, due to the growing demand for mobile devices and autonomous driving.
Therefore, it is very important to achieve a good trade-off among performance,
model size and inference speed. In this paper, we propose a Channel-wise
Feature Pyramid (CFP) module to balance those factors. Based on the CFP module,
we built CFPNet for real-time semantic segmentation which applied a series of
dilated convolution channels to extract effective features. Experiments on
Cityscapes and CamVid datasets show that the proposed CFPNet achieves an
effective combination of those factors. For the Cityscapes test dataset, CFPNet
achieves 70.1% class-wise mIoU with only 0.55 million parameters and 2.5 MB
memory. The inference speed can reach 30 FPS on a single RTX 2080Ti GPU with a
1024x2048-pixel image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dynamic radiomics: a new methodology to extract quantitative time-related features from tomographic images. (arXiv:2011.00454v3 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Che_F/0/1/0/all/0/1">Fengying Che</a>, <a href="http://arxiv.org/find/eess/1/au:+Shi_R/0/1/0/all/0/1">Ruichuan Shi</a>, <a href="http://arxiv.org/find/eess/1/au:+Wu_J/0/1/0/all/0/1">Jian Wu</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_H/0/1/0/all/0/1">Haoran Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_S/0/1/0/all/0/1">Shuqin Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Chen_W/0/1/0/all/0/1">Weixing Chen</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1">Hao Zhang</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_Z/0/1/0/all/0/1">Zhi Li</a>, <a href="http://arxiv.org/find/eess/1/au:+Cui_X/0/1/0/all/0/1">Xiaoyu Cui</a> (Member, IEEE)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00454">
                                    <div class="article-summary-box-inner">
                                        <span>The feature extraction methods of radiomics are mainly based on static
tomographic images at a certain moment, while the occurrence and development of
disease is a dynamic process that cannot be fully reflected by only static
characteristics. This study proposes a new dynamic radiomics feature extraction
workflow that uses time-dependent tomographic images of the same patient,
focuses on the changes in image features over time, and then quantifies them as
new dynamic features for diagnostic or prognostic evaluation. We first define
the mathematical paradigm of dynamic radiomics and introduce three specific
methods that can describe the transformation process of features over time.
Three different clinical problems are used to validate the performance of the
proposed dynamic feature with conventional 2D and 3D static features.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Panoramic annular SLAM with loop closure and global optimization. (arXiv:2102.13400v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Hao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weijian Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1">Kailun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1">Jian Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1">Kaiwei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13400">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose panoramic annular simultaneous localization and
mapping (PA-SLAM), a visual SLAM system based on panoramic annular lens. A
hybrid point selection strategy is put forward in the tracking front-end, which
ensures repeatability of keypoints and enables loop closure detection based on
the bag-of-words approach. Every detected loop candidate is verified
geometrically and the $Sim(3)$ relative pose constraint is estimated to perform
pose graph optimization and global bundle adjustment in the back-end. A
comprehensive set of experiments on real-world datasets demonstrates that the
hybrid point selection strategy allows reliable loop closure detection, and the
accumulated error and scale drift have been significantly reduced via global
optimization, enabling PA-SLAM to reach state-of-the-art accuracy while
maintaining high robustness and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints. (arXiv:2102.12827v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1">Maura Pintor</a>, <a href="http://arxiv.org/find/cs/1/au:+Roli_F/0/1/0/all/0/1">Fabio Roli</a>, <a href="http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1">Wieland Brendel</a>, <a href="http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1">Battista Biggio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12827">
                                    <div class="article-summary-box-inner">
                                        <span>Evaluating adversarial robustness amounts to finding the minimum perturbation
needed to have an input sample misclassified. The inherent complexity of the
underlying optimization requires current gradient-based attacks to be carefully
tuned, initialized, and possibly executed for many computationally-demanding
iterations, even if specialized to a given perturbation model. In this work, we
overcome these limitations by proposing a fast minimum-norm (FMN) attack that
works with different $\ell_p$-norm perturbation models ($p&#x3D;0, 1, 2, \infty$),
is robust to hyperparameter choices, does not require adversarial starting
points, and converges within few lightweight steps. It works by iteratively
finding the sample misclassified with maximum confidence within an
$\ell_p$-norm constraint of size $\epsilon$, while adapting $\epsilon$ to
minimize the distance of the current sample to the decision boundary. Extensive
experiments show that FMN significantly outperforms existing attacks in terms
of convergence speed and computation time, while reporting comparable or even
smaller perturbation sizes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Equilibrium Architectures for Inverse Problems in Imaging. (arXiv:2102.07944v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gilton_D/0/1/0/all/0/1">Davis Gilton</a>, <a href="http://arxiv.org/find/eess/1/au:+Ongie_G/0/1/0/all/0/1">Gregory Ongie</a>, <a href="http://arxiv.org/find/eess/1/au:+Willett_R/0/1/0/all/0/1">Rebecca Willett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07944">
                                    <div class="article-summary-box-inner">
                                        <span>Recent efforts on solving inverse problems in imaging via deep neural
networks use architectures inspired by a fixed number of iterations of an
optimization method. The number of iterations is typically quite small due to
difficulties in training networks corresponding to more iterations; the
resulting solvers cannot be run for more iterations at test time without
incurring significant errors. This paper describes an alternative approach
corresponding to an infinite number of iterations, yielding a consistent
improvement in reconstruction accuracy above state-of-the-art alternatives and
where the computational budget can be selected at test time to optimize
context-dependent trade-offs between accuracy and computation. The proposed
approach leverages ideas from Deep Equilibrium Models, where the fixed-point
iteration is constructed to incorporate a known forward model and insights from
classical optimization-based reconstruction methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TryOnGAN: Body-Aware Try-On via Layered Interpolation. (arXiv:2101.02285v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lewis_K/0/1/0/all/0/1">Kathleen M Lewis</a>, <a href="http://arxiv.org/find/cs/1/au:+Varadharajan_S/0/1/0/all/0/1">Srivatsan Varadharajan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kemelmacher_Shlizerman_I/0/1/0/all/0/1">Ira Kemelmacher-Shlizerman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.02285">
                                    <div class="article-summary-box-inner">
                                        <span>Given a pair of images-target person and garment on another person-we
automatically generate the target person in the given garment. Previous methods
mostly focused on texture transfer via paired data training, while overlooking
body shape deformations, skin color, and seamless blending of garment with the
person. This work focuses on those three components, while also not requiring
paired data training. We designed a pose conditioned StyleGAN2 architecture
with a clothing segmentation branch that is trained on images of people wearing
garments. Once trained, we propose a new layered latent space interpolation
method that allows us to preserve and synthesize skin color and target body
shape while transferring the garment from a different person. We demonstrate
results on high resolution 512x512 images, and extensively compare to state of
the art in try-on on both latent space generated and real images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectroscopic Approach to Correction and Visualisation of Bright-Field Light Transmission Microscopy Biological Data. (arXiv:1903.06519v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Platonova_G/0/1/0/all/0/1">Ganna Platonova</a>, <a href="http://arxiv.org/find/eess/1/au:+Stys_D/0/1/0/all/0/1">Dalibor Stys</a>, <a href="http://arxiv.org/find/eess/1/au:+Soucek_P/0/1/0/all/0/1">Pavel Soucek</a>, <a href="http://arxiv.org/find/eess/1/au:+Lonhus_K/0/1/0/all/0/1">Kirill Lonhus</a>, <a href="http://arxiv.org/find/eess/1/au:+Valenta_J/0/1/0/all/0/1">Jan Valenta</a>, <a href="http://arxiv.org/find/eess/1/au:+Rychtarikova_R/0/1/0/all/0/1">Renata Rychtarikova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1903.06519">
                                    <div class="article-summary-box-inner">
                                        <span>The most realistic information about the transparent sample such as a live
cell can be obtained only using bright-field light microscopy. At
high-intensity pulsing LED illumination, we captured a primary
12-bit-per-channel (bpc) response froman observed sample using a bright-field
wide-field microscope equipped with a high-resolution (4872x3248) image sensor.
In order to suppress data distortions originating from the light interactions
with elements in the optical path, poor sensor reproduction (geometrical
defects of the camera sensor and some peculiarities of sensor sensitivity),
this uncompressed 12-bpc data underwent a kind of correction after simultaneous
calibration of all the parts of the experimental arrangement. Moreover, the
final intensities of the corrected images are proportional to the photon fluxes
detected by a camera sensor. It can be visualized in 8-bpc intensity depth
after the Least Information Loss compression [Lect. Notes Bioinform. 9656, 527
(2016)].</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Tiny CNN Architecture for Medical Face Mask Detection for Resource-Constrained Endpoints. (arXiv:2011.14858v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohan_P/0/1/0/all/0/1">Puranjay Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1">Aditya Jyoti Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Chirania_A/0/1/0/all/0/1">Abhay Chirania</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14858">
                                    <div class="article-summary-box-inner">
                                        <span>The world is going through one of the most dangerous pandemics of all time
with the rapid spread of the novel coronavirus (COVID-19). According to the
World Health Organisation, the most effective way to thwart the transmission of
coronavirus is to wear medical face masks. Monitoring the use of face masks in
public places has been a challenge because manual monitoring could be unsafe.
This paper proposes an architecture for detecting medical face masks for
deployment on resource-constrained endpoints having extremely low memory
footprints. A small development board with an ARM Cortex-M7 microcontroller
clocked at 480 Mhz and having just 496 KB of framebuffer RAM, has been used for
the deployment of the model. Using the TensorFlow Lite framework, the model is
quantized to further reduce its size. The proposed model is 138 KB post
quantization and runs at the inference speed of 30 FPS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Person Detection in 2D Range Data using a Calibrated Camera. (arXiv:2012.08890v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_D/0/1/0/all/0/1">Dan Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Steinweg_M/0/1/0/all/0/1">Mats Steinweg</a>, <a href="http://arxiv.org/find/cs/1/au:+Hermans_A/0/1/0/all/0/1">Alexander Hermans</a>, <a href="http://arxiv.org/find/cs/1/au:+Leibe_B/0/1/0/all/0/1">Bastian Leibe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.08890">
                                    <div class="article-summary-box-inner">
                                        <span>Deep learning is the essential building block of state-of-the-art person
detectors in 2D range data. However, only a few annotated datasets are
available for training and testing these deep networks, potentially limiting
their performance when deployed in new environments or with different LiDAR
models. We propose a method, which uses bounding boxes from an image-based
detector (e.g. Faster R-CNN) on a calibrated camera to automatically generate
training labels (called pseudo-labels) for 2D LiDAR-based person detectors.
Through experiments on the JackRabbot dataset with two detector models, DROW3
and DR-SPAAM, we show that self-supervised detectors, trained or fine-tuned
with pseudo-labels, outperform detectors trained only on a different dataset.
Combined with robust training techniques, the self-supervised detectors reach a
performance close to the ones trained using manual annotations of the target
dataset. Our method is an effective way to improve person detectors during
deployment without any additional labeling effort, and we release our source
code to support relevant robotic applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exposing Backdoors in Robust Machine Learning Models. (arXiv:2003.00865v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soremekun_E/0/1/0/all/0/1">Ezekiel Soremekun</a>, <a href="http://arxiv.org/find/cs/1/au:+Udeshi_S/0/1/0/all/0/1">Sakshi Udeshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chattopadhyay_S/0/1/0/all/0/1">Sudipta Chattopadhyay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.00865">
                                    <div class="article-summary-box-inner">
                                        <span>The introduction of robust optimisation has pushed the state-of-the-art in
defending against adversarial attacks. However, the behaviour of such
optimisation has not been studied in the light of a fundamentally different
class of attacks called backdoors. In this paper, we demonstrate that
adversarially robust models are susceptible to backdoor attacks. Subsequently,
we observe that backdoors are reflected in the feature representation of such
models. Then, this observation is leveraged to detect backdoor-infected models
via a detection technique called AEGIS. Specifically, AEGIS uses feature
clustering to effectively detect backdoor-infected robust Deep Neural Networks
(DNNs). In our evaluation of several visible and hidden backdoor triggers on
major classification tasks using CIFAR-10, MNIST and FMNIST datasets, AEGIS
effectively detects robust DNNs infected with backdoors. AEGIS detects a
backdoor-infected model with 91.6% accuracy, without any false positives.
Furthermore, AEGIS detects the targeted class in the backdoor-infected model
with a reasonably low (11.1%) false positive rate. Our investigation reveals
that salient features of adversarially robust DNNs break the stealthy nature of
backdoor attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty-Aware Few-Shot Image Classification. (arXiv:2010.04525v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhizheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1">Cuiling Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhibo Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1">Shih-Fu Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04525">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot image classification learns to recognize new categories from limited
labelled data. Metric learning based approaches have been widely investigated,
where a query sample is classified by finding the nearest prototype from the
support set based on their feature similarities. A neural network has different
uncertainties on its calculated similarities of different pairs. Understanding
and modeling the uncertainty on the similarity could promote the exploitation
of limited samples in few-shot optimization. In this work, we propose
Uncertainty-Aware Few-Shot framework for image classification by modeling
uncertainty of the similarities of query-support pairs and performing
uncertainty-aware optimization. Particularly, we exploit such uncertainty by
converting observed similarities to probabilistic representations and
incorporate them to the loss for more effective optimization. In order to
jointly consider the similarities between a query and the prototypes in a
support set, a graph-based model is utilized to estimate the uncertainty of the
pairs. Extensive experiments show our proposed method brings significant
improvements on top of a strong baseline and achieves the state-of-the-art
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TorchIO: a Python library for efficient loading, preprocessing, augmentation and patch-based sampling of medical images in deep learning. (arXiv:2003.04696v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Perez_Garcia_F/0/1/0/all/0/1">Fernando P&#xe9;rez-Garc&#xed;a</a>, <a href="http://arxiv.org/find/eess/1/au:+Sparks_R/0/1/0/all/0/1">Rachel Sparks</a>, <a href="http://arxiv.org/find/eess/1/au:+Ourselin_S/0/1/0/all/0/1">S&#xe9;bastien Ourselin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.04696">
                                    <div class="article-summary-box-inner">
                                        <span>Processing of medical images such as MRI or CT presents unique challenges
compared to RGB images typically used in computer vision. These include a lack
of labels for large datasets, high computational costs, and metadata to
describe the physical properties of voxels. Data augmentation is used to
artificially increase the size of the training datasets. Training with image
patches decreases the need for computational power. Spatial metadata needs to
be carefully taken into account in order to ensure a correct alignment of
volumes.

We present TorchIO, an open-source Python library to enable efficient
loading, preprocessing, augmentation and patch-based sampling of medical images
for deep learning. TorchIO follows the style of PyTorch and integrates standard
medical image processing libraries to efficiently process images during
training of neural networks. TorchIO transforms can be composed, reproduced,
traced and extended. We provide multiple generic preprocessing and augmentation
operations as well as simulation of MRI-specific artifacts.

Source code, comprehensive tutorials and extensive documentation for TorchIO
can be found at https://github.com/fepegar/torchio. The package can be
installed from the Python Package Index running &#x27;pip install torchio&#x27;. It
includes a command-line interface which allows users to apply transforms to
image files without using Python. Additionally, we provide a graphical
interface within a TorchIO extension in 3D Slicer to visualize the effects of
transforms.

TorchIO was developed to help researchers standardize medical image
processing pipelines and allow them to focus on the deep learning experiments.
It encourages open science, as it supports reproducibility and is version
controlled so that the software can be cited precisely. Due to its modularity,
the library is compatible with other frameworks for deep learning with medical
images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations. (arXiv:2106.01548v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangning Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01548">
                                    <div class="article-summary-box-inner">
                                        <span>Vision Transformers (ViTs) and MLPs signal further efforts on replacing
hand-wired features or inductive biases with general-purpose neural
architectures. Existing works empower the models by massive data, such as
large-scale pretraining and/or repeated strong data augmentations, and still
report optimization-related problems (e.g., sensitivity to initialization and
learning rate). Hence, this paper investigates ViTs and MLP-Mixers from the
lens of loss geometry, intending to improve the models&#x27; data efficiency at
training and generalization at inference. Visualization and Hessian reveal
extremely sharp local minima of converged models. By promoting smoothness with
a recently proposed sharpness-aware optimizer, we substantially improve the
accuracy and robustness of ViTs and MLP-Mixers on various tasks spanning
supervised, adversarial, contrastive, and transfer learning (e.g., +5.3\% and
+11.0\% top-1 accuracy on ImageNet for ViT-B/16 and Mixer-B/16, respectively,
with the simple Inception-style preprocessing). We show that the improved
smoothness attributes to sparser active neurons in the first few layers. The
resultant ViTs outperform ResNets of similar size and throughput when trained
from scratch on ImageNet without large-scale pretraining or strong data
augmentations. They also possess more perceptive attention maps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SSMD: Semi-Supervised Medical Image Detection with Adaptive Consistency and Heterogeneous Perturbation. (arXiv:2106.01544v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Hong-Yu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chengdi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haofeng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1">Gang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Weimin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yizhou Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01544">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-Supervised classification and segmentation methods have been widely
investigated in medical image analysis. Both approaches can improve the
performance of fully-supervised methods with additional unlabeled data.
However, as a fundamental task, semi-supervised object detection has not gained
enough attention in the field of medical image analysis. In this paper, we
propose a novel Semi-Supervised Medical image Detector (SSMD). The motivation
behind SSMD is to provide free yet effective supervision for unlabeled data, by
regularizing the predictions at each position to be consistent. To achieve the
above idea, we develop a novel adaptive consistency cost function to regularize
different components in the predictions. Moreover, we introduce heterogeneous
perturbation strategies that work in both feature space and image space, so
that the proposed detector is promising to produce powerful image
representations and robust predictions. Extensive experimental results show
that the proposed SSMD achieves the state-of-the-art performance at a wide
range of settings. We also demonstrate the strength of each proposed module
with comprehensive ablation studies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Personalizing Pre-trained Models. (arXiv:2106.01499v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mina Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Srivatsa_P/0/1/0/all/0/1">P Srivatsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Rane_A/0/1/0/all/0/1">Advait Rane</a>, <a href="http://arxiv.org/find/cs/1/au:+Chenniappa_S/0/1/0/all/0/1">Shriram Chenniappa</a>, <a href="http://arxiv.org/find/cs/1/au:+Hazariwala_A/0/1/0/all/0/1">Asadali Hazariwala</a>, <a href="http://arxiv.org/find/cs/1/au:+Maes_P/0/1/0/all/0/1">Pattie Maes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01499">
                                    <div class="article-summary-box-inner">
                                        <span>Self-supervised or weakly supervised models trained on large-scale datasets
have shown sample-efficient transfer to diverse datasets in few-shot settings.
We consider how upstream pretrained models can be leveraged for downstream
few-shot, multilabel, and continual learning tasks. Our model CLIPPER (CLIP
PERsonalized) uses image representations from CLIP, a large-scale image
representation learning model trained using weak natural language supervision.
We developed a technique, called Multi-label Weight Imprinting (MWI), for
multi-label, continual, and few-shot learning, and CLIPPER uses MWI with image
representations from CLIP. We evaluated CLIPPER on 10 single-label and 5
multi-label datasets. Our model shows robust and competitive performance, and
we set new benchmarks for few-shot, multi-label, and continual learning. Our
lightweight technique is also compute-efficient and enables privacy-preserving
applications as the data is not sent to the upstream model for fine-tuning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transferable Adversarial Examples for Anchor Free Object Detection. (arXiv:2106.01618v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1">Quanyu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_B/0/1/0/all/0/1">Bin Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1">Siwei Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Bin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Youbing Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qi Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xi Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01618">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks have been demonstrated to be vulnerable to adversarial
attacks: subtle perturbation can completely change prediction result. The
vulnerability has led to a surge of research in this direction, including
adversarial attacks on object detection networks. However, previous studies are
dedicated to attacking anchor-based object detectors. In this paper, we present
the first adversarial attack on anchor-free object detectors. It conducts
category-wise, instead of previously instance-wise, attacks on object
detectors, and leverages high-level semantic information to efficiently
generate transferable adversarial examples, which can also be transferred to
attack other object detectors, even anchor-based detectors such as Faster
R-CNN. Experimental results on two benchmark datasets demonstrate that our
proposed method achieves state-of-the-art performance and transferability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Domain First Person Audio-Visual Action Recognition through Relative Norm Alignment. (arXiv:2106.01689v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Planamente_M/0/1/0/all/0/1">Mirco Planamente</a>, <a href="http://arxiv.org/find/cs/1/au:+Plizzari_C/0/1/0/all/0/1">Chiara Plizzari</a>, <a href="http://arxiv.org/find/cs/1/au:+Alberti_E/0/1/0/all/0/1">Emanuele Alberti</a>, <a href="http://arxiv.org/find/cs/1/au:+Caputo_B/0/1/0/all/0/1">Barbara Caputo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01689">
                                    <div class="article-summary-box-inner">
                                        <span>First person action recognition is an increasingly researched topic because
of the growing popularity of wearable cameras. This is bringing to light
cross-domain issues that are yet to be addressed in this context. Indeed, the
information extracted from learned representations suffers from an intrinsic
environmental bias. This strongly affects the ability to generalize to unseen
scenarios, limiting the application of current methods in real settings where
trimmed labeled data are not available during training. In this work, we
propose to leverage over the intrinsic complementary nature of audio-visual
signals to learn a representation that works well on data seen during training,
while being able to generalize across different domains. To this end, we
introduce an audio-visual loss that aligns the contributions from the two
modalities by acting on the magnitude of their feature norm representations.
This new loss, plugged into a minimal multi-modal action recognition
architecture, leads to strong results in cross-domain first person action
recognition, as demonstrated by extensive experiments on the popular
EPIC-Kitchens dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GMAIR: Unsupervised Object Detection Based on Spatial Attention and Gaussian Mixture. (arXiv:2106.01722v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1">Weijin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yao Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1">Linfeng Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_L/0/1/0/all/0/1">Lizeth Patricia Aguirre Sanchez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01722">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies on unsupervised object detection based on spatial attention
have achieved promising results. Models, such as AIR and SPAIR, output &quot;what&quot;
and &quot;where&quot; latent variables that represent the attributes and locations of
objects in a scene, respectively. Most of the previous studies concentrate on
the &quot;where&quot; localization performance; however, we claim that acquiring &quot;what&quot;
object attributes is also essential for representation learning. This paper
presents a framework, GMAIR, for unsupervised object detection. It incorporates
spatial attention and a Gaussian mixture in a unified deep generative model.
GMAIR can locate objects in a scene and simultaneously cluster them without
supervision. Furthermore, we analyze the &quot;what&quot; latent variables and clustering
process. Finally, we evaluate our model on MultiMNIST and Fruit2D datasets and
show that GMAIR achieves competitive results on localization and clustering
compared to state-of-the-art methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PDPGD: Primal-Dual Proximal Gradient Descent Adversarial Attack. (arXiv:2106.01538v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Matyasko_A/0/1/0/all/0/1">Alexander Matyasko</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_L/0/1/0/all/0/1">Lap-Pui Chau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01538">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art deep neural networks are sensitive to small input
perturbations. Since the discovery of this intriguing vulnerability, many
defence methods have been proposed that attempt to improve robustness to
adversarial noise. Fast and accurate attacks are required to compare various
defence methods. However, evaluating adversarial robustness has proven to be
extremely challenging. Existing norm minimisation adversarial attacks require
thousands of iterations (e.g. Carlini &amp; Wagner attack), are limited to the
specific norms (e.g. Fast Adaptive Boundary), or produce sub-optimal results
(e.g. Brendel &amp; Bethge attack). On the other hand, PGD attack, which is fast,
general and accurate, ignores the norm minimisation penalty and solves a
simpler perturbation-constrained problem. In this work, we introduce a fast,
general and accurate adversarial attack that optimises the original non-convex
constrained minimisation problem. We interpret optimising the Lagrangian of the
adversarial attack optimisation problem as a two-player game: the first player
minimises the Lagrangian wrt the adversarial noise; the second player maximises
the Lagrangian wrt the regularisation penalty. Our attack algorithm
simultaneously optimises primal and dual variables to find the minimal
adversarial perturbation. In addition, for non-smooth $l_p$-norm minimisation,
such as $l_{\infty}$-, $l_1$-, and $l_0$-norms, we introduce primal-dual
proximal gradient descent attack. We show in the experiments that our attack
outperforms current state-of-the-art $l_{\infty}$-, $l_2$-, $l_1$-, and
$l_0$-attacks on MNIST, CIFAR-10 and Restricted ImageNet datasets against
unregularised and adversarially trained models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deconfounded Video Moment Retrieval with Causal Intervention. (arXiv:2106.01534v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xun Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_F/0/1/0/all/0/1">Fuli Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_W/0/1/0/all/0/1">Wei Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Meng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chua_T/0/1/0/all/0/1">Tat-Seng Chua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01534">
                                    <div class="article-summary-box-inner">
                                        <span>We tackle the task of video moment retrieval (VMR), which aims to localize a
specific moment in a video according to a textual query. Existing methods
primarily model the matching relationship between query and moment by complex
cross-modal interactions. Despite their effectiveness, current models mostly
exploit dataset biases while ignoring the video content, thus leading to poor
generalizability. We argue that the issue is caused by the hidden confounder in
VMR, {i.e., temporal location of moments}, that spuriously correlates the model
input and prediction. How to design robust matching models against the temporal
location biases is crucial but, as far as we know, has not been studied yet for
VMR.

To fill the research gap, we propose a causality-inspired VMR framework that
builds structural causal model to capture the true effect of query and video
content on the prediction. Specifically, we develop a Deconfounded Cross-modal
Matching (DCM) method to remove the confounding effects of moment location. It
first disentangles moment representation to infer the core feature of visual
content, and then applies causal intervention on the disentangled multimodal
input based on backdoor adjustment, which forces the model to fairly
incorporate each possible location of the target into consideration. Extensive
experiments clearly show that our approach can achieve significant improvement
over the state-of-the-art methods in terms of both accuracy and generalization
(Codes:
\color{blue}{\url{https://github.com/Xun-Yang/Causal_Video_Moment_Retrieval}}</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Barbershop: GAN-based Image Compositing using Segmentation Masks. (arXiv:2106.01505v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1">Peihao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdal_R/0/1/0/all/0/1">Rameen Abdal</a>, <a href="http://arxiv.org/find/cs/1/au:+Femiani_J/0/1/0/all/0/1">John Femiani</a>, <a href="http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1">Peter Wonka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01505">
                                    <div class="article-summary-box-inner">
                                        <span>Seamlessly blending features from multiple images is extremely challenging
because of complex relationships in lighting, geometry, and partial occlusion
which cause coupling between different parts of the image. Even though recent
work on GANs enables synthesis of realistic hair or faces, it remains difficult
to combine them into a single, coherent, and plausible image rather than a
disjointed set of image patches. We present a novel solution to image blending,
particularly for the problem of hairstyle transfer, based on GAN-inversion. We
propose a novel latent space for image blending which is better at preserving
detail and encoding spatial information, and propose a new GAN-embedding
algorithm which is able to slightly modify images to conform to a common
segmentation mask. Our novel representation enables the transfer of the visual
properties from multiple reference images including specific details such as
moles and wrinkles, and because we do image blending in a latent-space we are
able to synthesize images that are coherent. Our approach avoids blending
artifacts present in other approaches and finds a globally consistent image.
Our results demonstrate a significant improvement over the current state of the
art in a user study, with users preferring our blending solution over 95
percent of the time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One Representation to Rule Them All: Identifying Out-of-Support Examples in Few-shot Learning with Generic Representations. (arXiv:2106.01423v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1">Henry Kvinge</a>, <a href="http://arxiv.org/find/cs/1/au:+Howland_S/0/1/0/all/0/1">Scott Howland</a>, <a href="http://arxiv.org/find/cs/1/au:+Courts_N/0/1/0/all/0/1">Nico Courts</a>, <a href="http://arxiv.org/find/cs/1/au:+Phillips_L/0/1/0/all/0/1">Lauren A. Phillips</a>, <a href="http://arxiv.org/find/cs/1/au:+Buckheit_J/0/1/0/all/0/1">John Buckheit</a>, <a href="http://arxiv.org/find/cs/1/au:+New_Z/0/1/0/all/0/1">Zachary New</a>, <a href="http://arxiv.org/find/cs/1/au:+Skomski_E/0/1/0/all/0/1">Elliott Skomski</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jung H. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_S/0/1/0/all/0/1">Sandeep Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Hibler_J/0/1/0/all/0/1">Jessica Hibler</a>, <a href="http://arxiv.org/find/cs/1/au:+Corley_C/0/1/0/all/0/1">Courtney D. Corley</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodas_N/0/1/0/all/0/1">Nathan O. Hodas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01423">
                                    <div class="article-summary-box-inner">
                                        <span>The field of few-shot learning has made remarkable strides in developing
powerful models that can operate in the small data regime. Nearly all of these
methods assume every unlabeled instance encountered will belong to a handful of
known classes for which one has examples. This can be problematic for
real-world use cases where one routinely finds &#x27;none-of-the-above&#x27; examples. In
this paper we describe this challenge of identifying what we term
&#x27;out-of-support&#x27; (OOS) examples. We describe how this problem is subtly
different from out-of-distribution detection and describe a new method of
identifying OOS examples within the Prototypical Networks framework using a
fixed point which we call the generic representation. We show that our method
outperforms other existing approaches in the literature as well as other
approaches that we propose in this paper. Finally, we investigate how the use
of such a generic point affects the geometry of a model&#x27;s feature space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Memorization in Adversarial Training. (arXiv:2106.01606v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yinpeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Ke Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1">Tianyu Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zhijie Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01606">
                                    <div class="article-summary-box-inner">
                                        <span>It is well known that deep learning models have a propensity for fitting the
entire training set even with random labels, which requires memorization of
every training sample. In this paper, we investigate the memorization effect in
adversarial training (AT) for promoting a deeper understanding of capacity,
convergence, generalization, and especially robust overfitting of adversarially
trained classifiers. We first demonstrate that deep networks have sufficient
capacity to memorize adversarial examples of training data with completely
random labels, but not all AT algorithms can converge under the extreme
circumstance. Our study of AT with random labels motivates further analyses on
the convergence and generalization of AT. We find that some AT methods suffer
from a gradient instability issue, and the recently suggested complexity
measures cannot explain robust generalization by considering models trained on
random labels. Furthermore, we identify a significant drawback of memorization
in AT that it could result in robust overfitting. We then propose a new
mitigation algorithm motivated by detailed memorization analyses. Extensive
experiments on various datasets validate the effectiveness of the proposed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NTIRE 2021 Challenge on High Dynamic Range Imaging: Dataset, Methods and Results. (arXiv:2106.01439v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Perez_Pellitero_E/0/1/0/all/0/1">Eduardo P&#xe9;rez-Pellitero</a>, <a href="http://arxiv.org/find/cs/1/au:+Catley_Chandar_S/0/1/0/all/0/1">Sibi Catley-Chandar</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonardis_A/0/1/0/all/0/1">Ale&#x161; Leonardis</a>, <a href="http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01439">
                                    <div class="article-summary-box-inner">
                                        <span>This paper reviews the first challenge on high-dynamic range (HDR) imaging
that was part of the New Trends in Image Restoration and Enhancement (NTIRE)
workshop, held in conjunction with CVPR 2021. This manuscript focuses on the
newly introduced dataset, the proposed methods and their results. The challenge
aims at estimating a HDR image from one or multiple respective low-dynamic
range (LDR) observations, which might suffer from under- or over-exposed
regions and different sources of noise. The challenge is composed by two
tracks: In Track 1 only a single LDR image is provided as input, whereas in
Track 2 three differently-exposed LDR images with inter-frame motion are
available. In both tracks, the ultimate goal is to achieve the best objective
HDR reconstruction in terms of PSNR with respect to a ground-truth image,
evaluated both directly and with a canonical tonemapping operation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Transferability of Adversarial Examples with New Iteration Framework and Input Dropout. (arXiv:2106.01617v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1">Pengfei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Linyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Ruoxi Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_K/0/1/0/all/0/1">Kai Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shuhao Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1">Guoen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1">Bin Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01617">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks(DNNs) is vulnerable to be attacked by adversarial
examples. Black-box attack is the most threatening attack. At present,
black-box attack methods mainly adopt gradient-based iterative attack methods,
which usually limit the relationship between the iteration step size, the
number of iterations, and the maximum perturbation. In this paper, we propose a
new gradient iteration framework, which redefines the relationship between the
above three. Under this framework, we easily improve the attack success rate of
DI-TI-MIM. In addition, we propose a gradient iterative attack method based on
input dropout, which can be well combined with our framework. We further
propose a multi dropout rate version of this method. Experimental results show
that our best method can achieve attack success rate of 96.2\% for defense
model on average, which is higher than the state-of-the-art gradient-based
attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grounding Complex Navigational Instructions Using Scene Graphs. (arXiv:2106.01607v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1">Michiel de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1">Satyapriya Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Anuva Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01607">
                                    <div class="article-summary-box-inner">
                                        <span>Training a reinforcement learning agent to carry out natural language
instructions is limited by the available supervision, i.e. knowing when the
instruction has been carried out. We adapt the CLEVR visual question answering
dataset to generate complex natural language navigation instructions and
accompanying scene graphs, yielding an environment-agnostic supervised dataset.
To demonstrate the use of this data set, we map the scenes to the VizDoom
environment and use the architecture in \citet{gatedattention} to train an
agent to carry out these more complex language instructions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Imperceptible Adversarial Examples for Fake Image Detection. (arXiv:2106.01615v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liao_Q/0/1/0/all/0/1">Quanyu Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuezun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_B/0/1/0/all/0/1">Bin Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_B/0/1/0/all/0/1">Bin Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1">Siwei Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_Y/0/1/0/all/0/1">Youbing Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qi Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xi Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01615">
                                    <div class="article-summary-box-inner">
                                        <span>Fooling people with highly realistic fake images generated with Deepfake or
GANs brings a great social disturbance to our society. Many methods have been
proposed to detect fake images, but they are vulnerable to adversarial
perturbations -- intentionally designed noises that can lead to the wrong
prediction. Existing methods of attacking fake image detectors usually generate
adversarial perturbations to perturb almost the entire image. This is redundant
and increases the perceptibility of perturbations. In this paper, we propose a
novel method to disrupt the fake image detection by determining key pixels to a
fake image detector and attacking only the key pixels, which results in the
$L_0$ and the $L_2$ norms of adversarial perturbations much less than those of
existing works. Experiments on two public datasets with three fake image
detectors indicate that our proposed method achieves state-of-the-art
performance in both white-box and black-box attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Not All Knowledge Is Created Equal. (arXiv:2106.01489v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziyun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinshao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haojin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Di Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Robertson_N/0/1/0/all/0/1">Neil M. Robertson</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1">David A. Clifton</a>, <a href="http://arxiv.org/find/cs/1/au:+Meinel_C/0/1/0/all/0/1">Christoph Meinel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01489">
                                    <div class="article-summary-box-inner">
                                        <span>Mutual knowledge distillation (MKD) improves a model by distilling knowledge
from another model. However, not all knowledge is certain and correct,
especially under adverse conditions. For example, label noise usually leads to
less reliable models due to the undesired memorisation [1, 2]. Wrong knowledge
misleads the learning rather than helps. This problem can be handled by two
aspects: (i) improving the reliability of a model where the knowledge is from
(i.e., knowledge source&#x27;s reliability); (ii) selecting reliable knowledge for
distillation. In the literature, making a model more reliable is widely studied
while selective MKD receives little attention. Therefore, we focus on studying
selective MKD and highlight its importance in this work.

Concretely, a generic MKD framework, Confident knowledge selection followed
by Mutual Distillation (CMD), is designed. The key component of CMD is a
generic knowledge selection formulation, making the selection threshold either
static (CMD-S) or progressive (CMD-P). Additionally, CMD covers two special
cases: zero knowledge and all knowledge, leading to a unified MKD framework. We
empirically find CMD-P performs better than CMD-S. The main reason is that a
model&#x27;s knowledge upgrades and becomes confident as the training progresses.

Extensive experiments are present to demonstrate the effectiveness of CMD and
thoroughly justify the design of CMD. For example, CMD-P obtains new
state-of-the-art results in robustness against label noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Container: Context Aggregation Network. (arXiv:2106.01401v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_P/0/1/0/all/0/1">Peng Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiasen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Hongsheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mottaghi_R/0/1/0/all/0/1">Roozbeh Mottaghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1">Aniruddha Kembhavi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01401">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional neural networks (CNNs) are ubiquitous in computer vision, with
a myriad of effective and efficient variations. Recently, Transformers --
originally introduced in natural language processing -- have been increasingly
adopted in computer vision. While early adopters continue to employ CNN
backbones, the latest networks are end-to-end CNN-free Transformer solutions. A
recent surprising finding shows that a simple MLP based solution without any
traditional convolutional or Transformer components can produce effective
visual representations. While CNNs, Transformers and MLP-Mixers may be
considered as completely disparate architectures, we provide a unified view
showing that they are in fact special cases of a more general method to
aggregate spatial context in a neural network stack. We present the \model
(CONText AggregatIon NEtwoRk), a general-purpose building block for multi-head
context aggregation that can exploit long-range interactions \emph{a la}
Transformers while still exploiting the inductive bias of the local convolution
operation leading to faster convergence speeds, often seen in CNNs. In contrast
to Transformer-based methods that do not scale well to downstream tasks that
rely on larger input image resolutions, our efficient network, named
\modellight, can be employed in object detection and instance segmentation
networks such as DETR, RetinaNet and Mask-RCNN to obtain an impressive
detection mAP of 38.9, 43.8, 45.1 and mask mAP of 41.3, providing large
improvements of 6.6, 7.3, 6.9 and 6.6 pts respectively, compared to a ResNet-50
backbone with a comparable compute and parameter size. Our method also achieves
promising results on self-supervised learning compared to DeiT on the DINO
framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepCompress: Efficient Point Cloud Geometry Compression. (arXiv:2106.01504v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Killea_R/0/1/0/all/0/1">Ryan Killea</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bastani_S/0/1/0/all/0/1">Saeed Bastani</a>, <a href="http://arxiv.org/find/cs/1/au:+McLachlan_P/0/1/0/all/0/1">Paul McLachlan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01504">
                                    <div class="article-summary-box-inner">
                                        <span>Point clouds are a basic data type that is increasingly of interest as 3D
content becomes more ubiquitous. Applications using point clouds include
virtual, augmented, and mixed reality and autonomous driving. We propose a more
efficient deep learning-based encoder architecture for point clouds compression
that incorporates principles from established 3D object detection and image
compression architectures. Through an ablation study, we show that
incorporating the learned activation function from Computational Efficient
Neural Image Compression (CENIC) and designing more parameter-efficient
convolutional blocks yields dramatic gains in efficiency and performance. Our
proposed architecture incorporates Generalized Divisive Normalization
activations and propose a spatially separable InceptionV4-inspired block. We
then evaluate rate-distortion curves on the standard JPEG Pleno 8i Voxelized
Full Bodies dataset to evaluate our model&#x27;s performance. Our proposed
modifications outperform the baseline approaches by a small margin in terms of
Bjontegard delta rate and PSNR values, yet reduces necessary encoder
convolution operations by 8 percent and reduces total encoder parameters by 20
percent. Our proposed architecture, when considered on its own, has a small
penalty of 0.02 percent in Chamfer&#x27;s Distance and 0.32 percent increased bit
rate in Point to Plane Distance for the same peak signal-to-noise ratio.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CT-Net: Channel Tensorization Network for Video Classification. (arXiv:2106.01603v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Kunchang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xianhang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yali Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01603">
                                    <div class="article-summary-box-inner">
                                        <span>3D convolution is powerful for video classification but often computationally
expensive, recent studies mainly focus on decomposing it on spatial-temporal
and/or channel dimensions. Unfortunately, most approaches fail to achieve a
preferable balance between convolutional efficiency and feature-interaction
sufficiency. For this reason, we propose a concise and novel Channel
Tensorization Network (CT-Net), by treating the channel dimension of input
feature as a multiplication of K sub-dimensions. On one hand, it naturally
factorizes convolution in a multiple dimension way, leading to a light
computation burden. On the other hand, it can effectively enhance feature
interaction from different channels, and progressively enlarge the 3D receptive
field of such interaction to boost classification accuracy. Furthermore, we
equip our CT-Module with a Tensor Excitation (TE) mechanism. It can learn to
exploit spatial, temporal and channel attention in a high-dimensional manner,
to improve the cooperative power of all the feature dimensions in our
CT-Module. Finally, we flexibly adapt ResNet as our CT-Net. Extensive
experiments are conducted on several challenging video benchmarks, e.g.,
Kinetics-400, Something-Something V1 and V2. Our CT-Net outperforms a number of
recent SOTA approaches, in terms of accuracy and/or efficiency. The codes and
models will be available on https://github.com/Andy1621/CT-Net.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noise Doesn&#x27;t Lie: Towards Universal Detection of Deep Inpainting. (arXiv:2106.01532v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1">Ang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_Q/0/1/0/all/0/1">Qiuhong Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xingjun Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Weng_H/0/1/0/all/0/1">Haiqin Weng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zong_Z/0/1/0/all/0/1">Zhiyuan Zong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xue_F/0/1/0/all/0/1">Feng Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1">Rui Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01532">
                                    <div class="article-summary-box-inner">
                                        <span>Deep image inpainting aims to restore damaged or missing regions in an image
with realistic contents. While having a wide range of applications such as
object removal and image recovery, deep inpainting techniques also have the
risk of being manipulated for image forgery. A promising countermeasure against
such forgeries is deep inpainting detection, which aims to locate the inpainted
regions in an image. In this paper, we make the first attempt towards universal
detection of deep inpainting, where the detection network can generalize well
when detecting different deep inpainting methods. To this end, we first propose
a novel data generation approach to generate a universal training dataset,
which imitates the noise discrepancies exist in real versus inpainted image
contents to train universal detectors. We then design a Noise-Image
Cross-fusion Network (NIX-Net) to effectively exploit the discriminative
information contained in both the images and their noise patterns. We
empirically show, on multiple benchmark datasets, that our approach outperforms
existing detection methods by a large margin and generalize well to unseen deep
inpainting techniques. Our universal training dataset can also significantly
boost the generalizability of existing detection methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Select: A Fully Attentive Approach for Novel Object Captioning. (arXiv:2106.01424v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cagrandi_M/0/1/0/all/0/1">Marco Cagrandi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cornia_M/0/1/0/all/0/1">Marcella Cornia</a>, <a href="http://arxiv.org/find/cs/1/au:+Stefanini_M/0/1/0/all/0/1">Matteo Stefanini</a>, <a href="http://arxiv.org/find/cs/1/au:+Baraldi_L/0/1/0/all/0/1">Lorenzo Baraldi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cucchiara_R/0/1/0/all/0/1">Rita Cucchiara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01424">
                                    <div class="article-summary-box-inner">
                                        <span>Image captioning models have lately shown impressive results when applied to
standard datasets. Switching to real-life scenarios, however, constitutes a
challenge due to the larger variety of visual concepts which are not covered in
existing training sets. For this reason, novel object captioning (NOC) has
recently emerged as a paradigm to test captioning models on objects which are
unseen during the training phase. In this paper, we present a novel approach
for NOC that learns to select the most relevant objects of an image, regardless
of their adherence to the training set, and to constrain the generative process
of a language model accordingly. Our architecture is fully-attentive and
end-to-end trainable, also when incorporating constraints. We perform
experiments on the held-out COCO dataset, where we demonstrate improvements
over the state of the art, both in terms of adaptability to novel objects and
caption quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiscale Domain Adaptive YOLO for Cross-Domain Object Detection. (arXiv:2106.01483v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hnewa_M/0/1/0/all/0/1">Mazin Hnewa</a>, <a href="http://arxiv.org/find/cs/1/au:+Radha_H/0/1/0/all/0/1">Hayder Radha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01483">
                                    <div class="article-summary-box-inner">
                                        <span>The area of domain adaptation has been instrumental in addressing the domain
shift problem encountered by many applications. This problem arises due to the
difference between the distributions of source data used for training in
comparison with target data used during realistic testing scenarios. In this
paper, we introduce a novel MultiScale Domain Adaptive YOLO (MS-DAYOLO)
framework that employs multiple domain adaptation paths and corresponding
domain classifiers at different scales of the recently introduced YOLOv4 object
detector to generate domain-invariant features. We train and test our proposed
method using popular datasets. Our experiments show significant improvements in
object detection performance when training YOLOv4 using the proposed MS-DAYOLO
and when tested on target data representing challenging weather conditions for
autonomous driving applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes. (arXiv:2106.01487v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1">Aditya Kusupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallingford_M/0/1/0/all/0/1">Matthew Wallingford</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanujan_V/0/1/0/all/0/1">Vivek Ramanujan</a>, <a href="http://arxiv.org/find/cs/1/au:+Somani_R/0/1/0/all/0/1">Raghav Somani</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jae Sung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1">Krishna Pillutla</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Prateek Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham Kakade</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01487">
                                    <div class="article-summary-box-inner">
                                        <span>Learning binary representations of instances and classes is a classical
problem with several high potential applications. In modern settings, the
compression of high-dimensional neural representations to low-dimensional
binary codes is a challenging task and often require large bit-codes to be
accurate. In this work, we propose a novel method for Learning Low-dimensional
binary Codes (LLC) for instances as well as classes. Our method does not
require any side-information, like annotated attributes or label meta-data, and
learns extremely low-dimensional binary codes (~20 bits for ImageNet-1K). The
learnt codes are super-efficient while still ensuring nearly optimal
classification accuracy for ResNet50 on ImageNet-1K. We demonstrate that the
learnt codes capture intrinsically important features in the data, by
discovering an intuitive taxonomy over classes. We further quantitatively
measure the quality of our codes by applying it to the efficient image
retrieval as well as out-of-distribution (OOD) detection problems. For
ImageNet-100 retrieval problem, our learnt binary codes outperform 16 bit
HashNet using only 10 bits and also are as accurate as 10 dimensional real
representations. Finally, our learnt binary codes can perform OOD detection,
out-of-the-box, as accurately as a baseline that needs ~3000 samples to tune
its threshold, while we require none. Code and pre-trained models are available
at https://github.com/RAIVNLab/LLC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spline Positional Encoding for Learning 3D Implicit Signed Distance Fields. (arXiv:2106.01553v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1">Peng-Shuai Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yu-Qi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tong_X/0/1/0/all/0/1">Xin Tong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01553">
                                    <div class="article-summary-box-inner">
                                        <span>Multilayer perceptrons (MLPs) have been successfully used to represent 3D
shapes implicitly and compactly, by mapping 3D coordinates to the corresponding
signed distance values or occupancy values. In this paper, we propose a novel
positional encoding scheme, called Spline Positional Encoding, to map the input
coordinates to a high dimensional space before passing them to MLPs, for
helping to recover 3D signed distance fields with fine-scale geometric details
from unorganized 3D point clouds. We verified the superiority of our approach
over other positional encoding schemes on tasks of 3D shape reconstruction from
input point clouds and shape space learning. The efficacy of our approach
extended to image reconstruction is also demonstrated and evaluated.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">3D Hand Pose Estimation via Regularized Graph Representation Learning. (arXiv:1912.01875v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yiming He</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wei Hu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1912.01875">
                                    <div class="article-summary-box-inner">
                                        <span>This paper addresses the problem of 3D hand pose estimation from a monocular
RGB image. While previous methods have shown great success, the structure of
hands has not been fully exploited, which is critical in pose estimation. To
this end, we propose a regularized graph representation learning under a
conditional adversarial learning framework for 3D hand pose estimation, aiming
to capture structural inter-dependencies of hand joints. In particular, we
estimate an initial hand pose from a parametric hand model as a prior of hand
structure, which regularizes the inference of the structural deformation in the
prior pose for accurate graph representation learning via residual graph
convolution. To optimize the hand structure further, we propose two
bone-constrained loss functions, which characterize the morphable structure of
hand poses explicitly. Also, we introduce an adversarial learning framework
conditioned on the input image with a multi-source discriminator, which imposes
the structural constraints onto the distribution of generated 3D hand poses for
anthropomorphically valid hand poses. Extensive experiments demonstrate that
our model sets the new state-of-the-art in 3D hand pose estimation from a
monocular image on five standard benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Reference-based Super-Resolution via C2-Matching. (arXiv:2106.01863v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuming Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1">Kelvin C.K. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xintao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1">Chen Change Loy</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01863">
                                    <div class="article-summary-box-inner">
                                        <span>Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising
paradigm to enhance a low-resolution (LR) input image by introducing an
additional high-resolution (HR) reference image. Existing Ref-SR methods mostly
rely on implicit correspondence matching to borrow HR textures from reference
images to compensate for the information loss in input images. However,
performing local transfer is difficult because of two gaps between input and
reference images: the transformation gap (e.g. scale and rotation) and the
resolution gap (e.g. HR and LR). To tackle these challenges, we propose
C2-Matching in this work, which produces explicit robust matching crossing
transformation and resolution. 1) For the transformation gap, we propose a
contrastive correspondence network, which learns transformation-robust
correspondences using augmented views of the input image. 2) For the resolution
gap, we adopt a teacher-student correlation distillation, which distills
knowledge from the easier HR-HR matching to guide the more ambiguous LR-HR
matching. 3) Finally, we design a dynamic aggregation module to address the
potential misalignment issue. In addition, to faithfully evaluate the
performance of Ref-SR under a realistic setting, we contribute the
Webly-Referenced SR (WR-SR) dataset, mimicking the practical usage scenario.
Extensive experiments demonstrate that our proposed C2-Matching significantly
outperforms state of the arts by over 1dB on the standard CUFED5 benchmark.
Notably, it also shows great generalizability on WR-SR dataset as well as
robustness across large scale and rotation transformations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence. (arXiv:2106.01883v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaojiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jirui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_Q/0/1/0/all/0/1">Qi Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wentao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01883">
                                    <div class="article-summary-box-inner">
                                        <span>Existing rotated object detectors are mostly inherited from the horizontal
detection paradigm, as the latter has evolved into a well-developed area.
However, these detectors are difficult to perform prominently in high-precision
detection due to the limitation of current regression loss design, especially
for objects with large aspect ratios. Taking the perspective that horizontal
detection is a special case for rotated object detection, in this paper, we are
motivated to change the design of rotation regression loss from induction
paradigm to deduction methodology, in terms of the relation between rotation
and horizontal detection. We show that one essential challenge is how to
modulate the coupled parameters in the rotation regression loss, as such the
estimated parameters can influence to each other during the dynamic joint
optimization, in an adaptive and synergetic way. Specifically, we first convert
the rotated bounding box into a 2-D Gaussian distribution, and then calculate
the Kullback-Leibler Divergence (KLD) between the Gaussian distributions as the
regression loss. By analyzing the gradient of each parameter, we show that KLD
(and its derivatives) can dynamically adjust the parameter gradients according
to the characteristics of the object. It will adjust the importance (gradient
weight) of the angle parameter according to the aspect ratio. This mechanism
can be vital for high-precision detection as a slight angle error would cause a
serious accuracy drop for large aspect ratios objects. More importantly, we
have proved that KLD is scale invariant. We further show that the KLD loss can
be degenerated into the popular $l_{n}$-norm loss for horizontal detection.
Experimental results on seven datasets using different detectors show its
consistent superiority, and codes are available at
https://github.com/yangxue0827/RotationDetection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control. (arXiv:2106.02019v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1">Marc Habermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudnev_V/0/1/0/all/0/1">Viktor Rudnev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_K/0/1/0/all/0/1">Kripasindhu Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jiatao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02019">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Neural Actor (NA), a new method for high-quality synthesis of
humans from arbitrary viewpoints and under arbitrary controllable poses. Our
method is built upon recent neural scene representation and rendering works
which learn representations of geometry and appearance from only 2D images.
While existing works demonstrated compelling rendering of static scenes and
playback of dynamic scenes, photo-realistic reconstruction and rendering of
humans with neural implicit methods, in particular under user-controlled novel
poses, is still difficult. To address this problem, we utilize a coarse body
model as the proxy to unwarp the surrounding 3D space into a canonical pose. A
neural radiance field learns pose-dependent geometric deformations and pose-
and view-dependent appearance effects in the canonical space from multi-view
video input. To synthesize novel views of high fidelity dynamic geometry and
appearance, we leverage 2D texture maps defined on the body model as latent
variables for predicting residual deformations and the dynamic appearance.
Experiments demonstrate that our method achieves better quality than the
state-of-the-arts on playback as well as novel pose synthesis, and can even
generalize well to new poses that starkly differ from the training poses.
Furthermore, our method also supports body shape control of the synthesized
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simultaneous Multi-View Object Recognition and Grasping in Open-Ended Domains. (arXiv:2106.01866v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kasaei_H/0/1/0/all/0/1">Hamidreza Kasaei</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Sha Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Sasso_R/0/1/0/all/0/1">Remo Sasso</a>, <a href="http://arxiv.org/find/cs/1/au:+Kasaei_M/0/1/0/all/0/1">Mohammadreza Kasaei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01866">
                                    <div class="article-summary-box-inner">
                                        <span>A robot working in human-centric environments needs to know which kind of
objects exist in the scene, where they are, and how to grasp and manipulate
various objects in different situations to help humans in everyday tasks.
Therefore, object recognition and grasping are two key functionalities for such
robots. Most state-of-the-art tackles object recognition and grasping as two
separate problems while both use visual input. Furthermore, the knowledge of
the robot is fixed after the training phase. In such cases, if the robot faces
new object categories, it must retrain from scratch to incorporate new
information without catastrophic interference. To address this problem, we
propose a deep learning architecture with augmented memory capacities to handle
open-ended object recognition and grasping simultaneously. In particular, our
approach takes multi-views of an object as input and jointly estimates
pixel-wise grasp configuration as well as a deep scale- and rotation-invariant
representation as outputs. The obtained representation is then used for
open-ended object recognition through a meta-active learning technique. We
demonstrate the ability of our approach to grasp never-seen-before objects and
to rapidly learn new object categories using very few examples on-site in both
simulation and real-world settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single Image Depth Estimation using Wavelet Decomposition. (arXiv:2106.02022v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramamonjisoa_M/0/1/0/all/0/1">Micha&#xeb;l Ramamonjisoa</a>, <a href="http://arxiv.org/find/cs/1/au:+Firman_M/0/1/0/all/0/1">Michael Firman</a>, <a href="http://arxiv.org/find/cs/1/au:+Watson_J/0/1/0/all/0/1">Jamie Watson</a>, <a href="http://arxiv.org/find/cs/1/au:+Lepetit_V/0/1/0/all/0/1">Vincent Lepetit</a>, <a href="http://arxiv.org/find/cs/1/au:+Turmukhambetov_D/0/1/0/all/0/1">Daniyar Turmukhambetov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02022">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel method for predicting accurate depths from monocular
images with high efficiency. This optimal efficiency is achieved by exploiting
wavelet decomposition, which is integrated in a fully differentiable
encoder-decoder architecture. We demonstrate that we can reconstruct
high-fidelity depth maps by predicting sparse wavelet coefficients. In contrast
with previous works, we show that wavelet coefficients can be learned without
direct supervision on coefficients. Instead we supervise only the final depth
image that is reconstructed through the inverse wavelet transform. We
additionally show that wavelet coefficients can be learned in fully
self-supervised scenarios, without access to ground-truth depth. Finally, we
apply our method to different state-of-the-art monocular depth estimation
models, in each case giving similar or better results compared to the original
model, while requiring less than half the multiply-adds in the decoder network.
Code at https://github.com/nianticlabs/wavelet-monodepth</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning Based Analysis of Prostate Cancer from MP-MRI. (arXiv:2106.01835v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Neto_P/0/1/0/all/0/1">Pedro C. Neto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01835">
                                    <div class="article-summary-box-inner">
                                        <span>The diagnosis of prostate cancer faces a problem with overdiagnosis that
leads to damaging side effects due to unnecessary treatment. Research has shown
that the use of multi-parametric magnetic resonance images to conduct biopsies
can drastically help to mitigate the overdiagnosis, thus reducing the side
effects on healthy patients. This study aims to investigate the use of deep
learning techniques to explore computer-aid diagnosis based on MRI as input.
Several diagnosis problems ranging from classification of lesions as being
clinically significant or not to the detection and segmentation of lesions are
addressed with deep learning based approaches.

This thesis tackled two main problems regarding the diagnosis of prostate
cancer. Firstly, XmasNet was used to conduct two large experiments on the
classification of lesions. Secondly, detection and segmentation experiments
were conducted, first on the prostate and afterward on the prostate cancer
lesions. The former experiments explored the lesions through a two-dimensional
space, while the latter explored models to work with three-dimensional inputs.
For this task, the 3D models explored were the 3D U-Net and a pretrained 3D
ResNet-18. A rigorous analysis of all these problems was conducted with a total
of two networks, two cropping techniques, two resampling techniques, two crop
sizes, five input sizes and data augmentations experimented for lesion
classification. While for segmentation two models, two input sizes and data
augmentations were experimented. However, while the binary classification of
the clinical significance of lesions and the detection and segmentation of the
prostate already achieve the desired results (0.870 AUC and 0.915 dice score
respectively), the classification of the PIRADS score and the segmentation of
lesions still have a large margin to improve (0.664 accuracy and 0.690 dice
score respectively).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anticipative Video Transformer. (arXiv:2106.02036v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Girdhar_R/0/1/0/all/0/1">Rohit Girdhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1">Kristen Grauman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02036">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Anticipative Video Transformer (AVT), an end-to-end
attention-based video modeling architecture that attends to the previously
observed video in order to anticipate future actions. We train the model
jointly to predict the next action in a video sequence, while also learning
frame feature encoders that are predictive of successive future frames&#x27;
features. Compared to existing temporal aggregation strategies, AVT has the
advantage of both maintaining the sequential progression of observed actions
while still capturing long-range dependencies--both critical for the
anticipation task. Through extensive experiments, we show that AVT obtains the
best reported performance on four popular action anticipation benchmarks:
EpicKitchens-55, EpicKitchens-100, EGTEA Gaze+, and 50-Salads, including
outperforming all submissions to the EpicKitchens-100 CVPR&#x27;21 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Denoising and Optical and SAR Image Classifications Based on Feature Extraction and Sparse Representation. (arXiv:2106.01896v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Balnarsaiah_B/0/1/0/all/0/1">Battula Balnarsaiah</a>, <a href="http://arxiv.org/find/eess/1/au:+Rajitha_G/0/1/0/all/0/1">G Rajitha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01896">
                                    <div class="article-summary-box-inner">
                                        <span>Optical image data have been used by the Remote Sensing workforce to study
land use and cover since such data is easily interpretable. Synthetic Aperture
Radar (SAR) has the characteristic of obtaining images during all-day,
all-weather and provides object information that is different from visible and
infrared sensors. However, SAR images have more speckle noise and fewer
dimensions. This paper presents a method for denoising, feature extraction and
compares classifications of Optical and SAR images. The image was denoised
using K-Singular Value Decomposition (K-SVD) algorithm. A method to map the
extraordinary goal signatures to be had withinside the SAR or Optical image
using support vector machine (SVM) through offering given the enter facts to
the supervised classifier. Initially, the Gray Level Histogram (GLH) and Gray
Level Co-occurrence Matrix (GLCM) are used for feature extraction. Secondly,
the extracted feature vectors from the first step were combined using
correlation analysis to reduce the dimensionality of the feature spaces.
Thirdly, the Classification of SAR images was done in Sparse Representations
Classification (SRC). The above-mentioned classifications techniques were
developed and performance parameters are accuracy and Kappa Coefficient
calculated using MATLAB 2018a.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification. (arXiv:2106.02034v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Benlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02034">
                                    <div class="article-summary-box-inner">
                                        <span>Attention is sparse in vision transformers. We observe the final prediction
in vision transformers is only based on a subset of most informative tokens,
which is sufficient for accurate image recognition. Based on this observation,
we propose a dynamic token sparsification framework to prune redundant tokens
progressively and dynamically based on the input. Specifically, we devise a
lightweight prediction module to estimate the importance score of each token
given the current features. The module is added to different layers to prune
redundant tokens hierarchically. To optimize the prediction module in an
end-to-end manner, we propose an attention masking strategy to differentiably
prune a token by blocking its interactions with other tokens. Benefiting from
the nature of self-attention, the unstructured sparse tokens are still hardware
friendly, which makes our framework easy to achieve actual speed-up. By
hierarchically pruning 66% of the input tokens, our method greatly reduces
31%~37% FLOPs and improves the throughput by over 40% while the drop of
accuracy is within 0.5% for various vision transformers. Equipped with the
dynamic token sparsification framework, DynamicViT models can achieve very
competitive complexity/accuracy trade-offs compared to state-of-the-art CNNs
and vision transformers on ImageNet. Code is available at
https://github.com/raoyongming/DynamicViT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partial Graph Reasoning for Neural Network Regularization. (arXiv:2106.01805v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tiange Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chaoyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Hongliang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Weidong Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01805">
                                    <div class="article-summary-box-inner">
                                        <span>Regularizers helped deep neural networks prevent feature co-adaptations.
Dropout,as a commonly used regularization technique, stochastically disables
neuron ac-tivations during network optimization. However, such complete feature
disposal can affect the feature representation and network understanding.
Toward betterdescriptions of latent representations, we present DropGraph that
learns regularization function by constructing a stand-alone graph from the
backbone features. DropGraph first samples stochastic spatial feature vectors
and then incorporates graph reasoning methods to generate feature map
distortions. This add-on graph regularizes the network during training and can
be completely skipped during inference. We provide intuitions on the linkage
between graph reasoning andDropout with further discussions on how partial
graph reasoning method reduces feature correlations. To this end, we
extensively study the modeling of graphvertex dependencies and the utilization
of the graph for distorting backbone featuremaps. DropGraph was validated on
four tasks with a total of 7 different datasets.The experimental results show
that our method outperforms other state-of-the-art regularizers while leaving
the base model structure unmodified during inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Separated-Spectral-Distribution Estimation Based on Bayesian Inference with Single RGB Camera. (arXiv:2106.01861v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kinoshita_Y/0/1/0/all/0/1">Yuma Kinoshita</a>, <a href="http://arxiv.org/find/eess/1/au:+Kiya_H/0/1/0/all/0/1">Hitoshi Kiya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01861">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel method for separately estimating spectral
distributions from images captured by a typical RGB camera. The proposed method
allows us to separately estimate a spectral distribution of illumination,
reflectance, or camera sensitivity, while recent hyperspectral cameras are
limited to capturing a joint spectral distribution from a scene. In addition,
the use of Bayesian inference makes it possible to take into account prior
information of both spectral distributions and image noise as probability
distributions. As a result, the proposed method can estimate spectral
distributions in a unified way, and it can enhance the robustness of the
estimation against noise, which conventional spectral-distribution estimation
methods cannot. The use of Bayesian inference also enables us to obtain the
confidence of estimation results. In an experiment, the proposed method is
shown not only to outperform conventional estimation methods in terms of RMSE
but also to be robust against noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effort-free Automated Skeletal Abnormality Detection of Rat Fetuses on Whole-body Micro-CT Scans. (arXiv:2106.01830v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fukuda_A/0/1/0/all/0/1">Akihiro Fukuda</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1">Changhee Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Hakamada_K/0/1/0/all/0/1">Kazumi Hakamada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01830">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning-based fast and quantitative automated screening plays a key
role in analyzing human bones on Computed Tomography (CT) scans. However,
despite the requirement in drug safety assessment, such research is rare on
animal fetus micro-CT scans due to its laborious data collection and
annotation. Therefore, we propose various bone feature engineering techniques
to thoroughly automate the skeletal localization/labeling/abnormality detection
of rat fetuses on whole-body micro-CT scans with minimum effort. Despite
limited training data of 49 fetuses, in skeletal labeling and abnormality
detection, we achieve accuracy of 0.900 and 0.810, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsharp Mask Guided Filtering. (arXiv:2106.01428v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1">Zenglin Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yunlu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Gavves_E/0/1/0/all/0/1">Efstratios Gavves</a>, <a href="http://arxiv.org/find/cs/1/au:+Mettes_P/0/1/0/all/0/1">Pascal Mettes</a>, <a href="http://arxiv.org/find/cs/1/au:+Snoek_C/0/1/0/all/0/1">Cees G.M. Snoek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01428">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of this paper is guided image filtering, which emphasizes the
importance of structure transfer during filtering by means of an additional
guidance image. Where classical guided filters transfer structures using
hand-designed functions, recent guided filters have been considerably advanced
through parametric learning of deep networks. The state-of-the-art leverages
deep networks to estimate the two core coefficients of the guided filter. In
this work, we posit that simultaneously estimating both coefficients is
suboptimal, resulting in halo artifacts and structure inconsistencies. Inspired
by unsharp masking, a classical technique for edge enhancement that requires
only a single coefficient, we propose a new and simplified formulation of the
guided filter. Our formulation enjoys a filtering prior from a low-pass filter
and enables explicit structure transfer by estimating a single coefficient.
Based on our proposed formulation, we introduce a successive guided filtering
network, which provides multiple filtering results from a single network,
allowing for a trade-off between accuracy and efficiency. Extensive ablations,
comparisons and analysis show the effectiveness and efficiency of our
formulation and network, resulting in state-of-the-art results across filtering
tasks like upsampling, denoising, and cross-modality filtering. Code is
available at \url{https://github.com/shizenglin/Unsharp-Mask-Guided-Filtering}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeRFactor: Neural Factorization of Shape and Reflectance Under an Unknown Illumination. (arXiv:2106.01970v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiuming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivasan_P/0/1/0/all/0/1">Pratul P. Srinivasan</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1">Boyang Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Debevec_P/0/1/0/all/0/1">Paul Debevec</a>, <a href="http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1">William T. Freeman</a>, <a href="http://arxiv.org/find/cs/1/au:+Barron_J/0/1/0/all/0/1">Jonathan T. Barron</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01970">
                                    <div class="article-summary-box-inner">
                                        <span>We address the problem of recovering the shape and spatially-varying
reflectance of an object from posed multi-view images of the object illuminated
by one unknown lighting condition. This enables the rendering of novel views of
the object under arbitrary environment lighting and editing of the object&#x27;s
material properties. The key to our approach, which we call Neural Radiance
Factorization (NeRFactor), is to distill the volumetric geometry of a Neural
Radiance Field (NeRF) [Mildenhall et al. 2020] representation of the object
into a surface representation and then jointly refine the geometry while
solving for the spatially-varying reflectance and the environment lighting.
Specifically, NeRFactor recovers 3D neural fields of surface normals, light
visibility, albedo, and Bidirectional Reflectance Distribution Functions
(BRDFs) without any supervision, using only a re-rendering loss, simple
smoothness priors, and a data-driven BRDF prior learned from real-world BRDF
measurements. By explicitly modeling light visibility, NeRFactor is able to
separate shadows from albedo and synthesize realistic soft or hard shadows
under arbitrary lighting conditions. NeRFactor is able to recover convincing 3D
models for free-viewpoint relighting in this challenging and underconstrained
capture setup for both synthetic and real scenes. Qualitative and quantitative
experiments show that NeRFactor outperforms classic and deep learning-based
state of the art across various tasks. Our code and data are available at
people.csail.mit.edu/xiuming/projects/nerfactor/.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controllable Person Image Synthesis with Spatially-Adaptive Warped Normalization. (arXiv:2105.14739v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jichao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Siarohin_A/0/1/0/all/0/1">Aliaksandr Siarohin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1">Hao Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1">Jingjing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Sangineto_E/0/1/0/all/0/1">Enver Sangineto</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sebe_N/0/1/0/all/0/1">Nicu Sebe</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14739">
                                    <div class="article-summary-box-inner">
                                        <span>Controllable person image generation aims to produce realistic human images
with desirable attributes (e.g., the given pose, cloth textures or hair style).
However, the large spatial misalignment between the source and target images
makes the standard architectures for image-to-image translation not suitable
for this task. Most of the state-of-the-art architectures avoid the alignment
step during the generation, which causes many artifacts, especially for person
images with complex textures. To solve this problem, we introduce a novel
Spatially-Adaptive Warped Normalization (SAWN), which integrates a learned
flow-field to warp modulation parameters. This allows us to align person
spatial-adaptive styles with pose features efficiently. Moreover, we propose a
novel self-training part replacement strategy to refine the pretrained model
for the texture-transfer task, significantly improving the quality of the
generated cloth and the preservation ability of irrelevant regions. Our
experimental results on the widely used DeepFashion dataset demonstrate a
significant improvement of the proposed method over the state-of-the-art
methods on both pose-transfer and texture-transfer tasks. The source code is
available at https://github.com/zhangqianhui/Sawn.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Wheat Head Dataset 2021: more diversity to improve the benchmarking of wheat head localization methods. (arXiv:2105.07660v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+David_E/0/1/0/all/0/1">Etienne David</a>, <a href="http://arxiv.org/find/cs/1/au:+Serouart_M/0/1/0/all/0/1">Mario Serouart</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_D/0/1/0/all/0/1">Daniel Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Madec_S/0/1/0/all/0/1">Simon Madec</a>, <a href="http://arxiv.org/find/cs/1/au:+Velumani_K/0/1/0/all/0/1">Kaaviya Velumani</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shouyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Espinosa_F/0/1/0/all/0/1">Francisco Pinto Espinosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiee_S/0/1/0/all/0/1">Shahameh Shafiee</a>, <a href="http://arxiv.org/find/cs/1/au:+Tahir_I/0/1/0/all/0/1">Izzat S. A. Tahir</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsujimoto_H/0/1/0/all/0/1">Hisashi Tsujimoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Nasuda_S/0/1/0/all/0/1">Shuhei Nasuda</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1">Bangyou Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Kichgessner_N/0/1/0/all/0/1">Norbert Kichgessner</a>, <a href="http://arxiv.org/find/cs/1/au:+Aasen_H/0/1/0/all/0/1">Helge Aasen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hund_A/0/1/0/all/0/1">Andreas Hund</a>, <a href="http://arxiv.org/find/cs/1/au:+Sadhegi_Tehran_P/0/1/0/all/0/1">Pouria Sadhegi-Tehran</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagasawa_K/0/1/0/all/0/1">Koichi Nagasawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishikawa_G/0/1/0/all/0/1">Goro Ishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Dandrifosse_S/0/1/0/all/0/1">S&#xe9;bastien Dandrifosse</a>, <a href="http://arxiv.org/find/cs/1/au:+Carlier_A/0/1/0/all/0/1">Alexis Carlier</a>, <a href="http://arxiv.org/find/cs/1/au:+Mercatoris_B/0/1/0/all/0/1">Benoit Mercatoris</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuroki_K/0/1/0/all/0/1">Ken Kuroki</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haozhou Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ishii_M/0/1/0/all/0/1">Masanori Ishii</a>, <a href="http://arxiv.org/find/cs/1/au:+Badhon_M/0/1/0/all/0/1">Minhajul A. Badhon</a>, <a href="http://arxiv.org/find/cs/1/au:+Pozniak_C/0/1/0/all/0/1">Curtis Pozniak</a>, <a href="http://arxiv.org/find/cs/1/au:+LeBauer_D/0/1/0/all/0/1">David Shaner LeBauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Lilimo_M/0/1/0/all/0/1">Morten Lilimo</a>, <a href="http://arxiv.org/find/cs/1/au:+Poland_J/0/1/0/all/0/1">Jesse Poland</a>, <a href="http://arxiv.org/find/cs/1/au:+Chapman_S/0/1/0/all/0/1">Scott Chapman</a>, <a href="http://arxiv.org/find/cs/1/au:+Solan_B/0/1/0/all/0/1">Benoit de Solan</a>, <a href="http://arxiv.org/find/cs/1/au:+Baret_F/0/1/0/all/0/1">Fr&#xe9;d&#xe9;ric Baret</a>, <a href="http://arxiv.org/find/cs/1/au:+Stavness_I/0/1/0/all/0/1">Ian Stavness</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1">Wei Guo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07660">
                                    <div class="article-summary-box-inner">
                                        <span>The Global Wheat Head Detection (GWHD) dataset was created in 2020 and has
assembled 193,634 labelled wheat heads from 4,700 RGB images acquired from
various acquisition platforms and 7 countries/institutions. With an associated
competition hosted in Kaggle, GWHD has successfully attracted attention from
both the computer vision and agricultural science communities. From this first
experience in 2020, a few avenues for improvements have been identified,
especially from the perspective of data size, head diversity and label
reliability. To address these issues, the 2020 dataset has been reexamined,
relabeled, and augmented by adding 1,722 images from 5 additional countries,
allowing for 81,553 additional wheat heads to be added. We now release a new
version of the Global Wheat Head Detection (GWHD) dataset in 2021, which is
bigger, more diverse, and less noisy than the 2020 version. The GWHD 2021 is
now publicly available at this http URL and a new data challenge
has been organized on AIcrowd to make use of this updated dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semantic Palette: Guiding Scene Generation with Class Proportions. (arXiv:2106.01629v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Moing_G/0/1/0/all/0/1">Guillaume Le Moing</a>, <a href="http://arxiv.org/find/cs/1/au:+Vu_T/0/1/0/all/0/1">Tuan-Hung Vu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_H/0/1/0/all/0/1">Himalaya Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Perez_P/0/1/0/all/0/1">Patrick P&#xe9;rez</a>, <a href="http://arxiv.org/find/cs/1/au:+Cord_M/0/1/0/all/0/1">Matthieu Cord</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01629">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the recent progress of generative adversarial networks (GANs) at
synthesizing photo-realistic images, producing complex urban scenes remains a
challenging problem. Previous works break down scene generation into two
consecutive phases: unconditional semantic layout synthesis and image synthesis
conditioned on layouts. In this work, we propose to condition layout generation
as well for higher semantic control: given a vector of class proportions, we
generate layouts with matching composition. To this end, we introduce a
conditional framework with novel architecture designs and learning objectives,
which effectively accommodates class proportions to guide the scene generation
process. The proposed architecture also allows partial layout editing with
interesting applications. Thanks to the semantic control, we can produce
layouts close to the real distribution, helping enhance the whole scene
generation process. On different metrics and urban scene benchmarks, our models
outperform existing baselines. Moreover, we demonstrate the merit of our
approach for data augmentation: semantic segmenters trained on real
layout-image pairs along with additional ones generated by our approach
outperform models only trained on real pairs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning Based Texture Analysis of Patella from X-Rays for Detecting Patellofemoral Osteoarthritis. (arXiv:2106.01700v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bayramoglu_N/0/1/0/all/0/1">Neslihan Bayramoglu</a>, <a href="http://arxiv.org/find/eess/1/au:+Nieminen_M/0/1/0/all/0/1">Miika T. Nieminen</a>, <a href="http://arxiv.org/find/eess/1/au:+Saarakkala_S/0/1/0/all/0/1">Simo Saarakkala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01700">
                                    <div class="article-summary-box-inner">
                                        <span>Objective is to assess the ability of texture features for detecting
radiographic patellofemoral osteoarthritis (PFOA) from knee lateral view
radiographs. We used lateral view knee radiographs from MOST public use
datasets (n &#x3D; 5507 knees). Patellar region-of-interest (ROI) was automatically
detected using landmark detection tool (BoneFinder). Hand-crafted features,
based on LocalBinary Patterns (LBP), were then extracted to describe the
patellar texture. First, a machine learning model (Gradient Boosting Machine)
was trained to detect radiographic PFOA from the LBP features. Furthermore, we
used end-to-end trained deep convolutional neural networks (CNNs) directly on
the texture patches for detecting the PFOA. The proposed classification models
were eventually compared with more conventional reference models that use
clinical assessments and participant characteristics such as age, sex, body
mass index(BMI), the total WOMAC score, and tibiofemoral Kellgren-Lawrence (KL)
grade. Atlas-guided visual assessment of PFOA status by expert readers provided
in the MOST public use datasets was used as a classification outcome for the
models. Performance of prediction models was assessed using the area under the
receiver operating characteristic curve (ROC AUC), the area under the
precision-recall (PR) curve-average precision (AP)-, and Brier score in the
stratified 5-fold cross validation setting.Of the 5507 knees, 953 (17.3%) had
PFOA. AUC and AP for the strongest reference model including age, sex, BMI,
WOMAC score, and tibiofemoral KL grade to predict PFOA were 0.817 and 0.487,
respectively. Textural ROI classification using CNN significantly improved the
prediction performance (ROC AUC&#x3D; 0.889, AP&#x3D; 0.714). We present the first study
that analyses patellar bone texture for diagnosing PFOA. Our results
demonstrates the potential of using texture features of patella to predict
PFOA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. (arXiv:2010.11929v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1">Alexey Dosovitskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Weissenborn_D/0/1/0/all/0/1">Dirk Weissenborn</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1">Thomas Unterthiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1">Mostafa Dehghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Minderer_M/0/1/0/all/0/1">Matthias Minderer</a>, <a href="http://arxiv.org/find/cs/1/au:+Heigold_G/0/1/0/all/0/1">Georg Heigold</a>, <a href="http://arxiv.org/find/cs/1/au:+Gelly_S/0/1/0/all/0/1">Sylvain Gelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1">Jakob Uszkoreit</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11929">
                                    <div class="article-summary-box-inner">
                                        <span>While the Transformer architecture has become the de-facto standard for
natural language processing tasks, its applications to computer vision remain
limited. In vision, attention is either applied in conjunction with
convolutional networks, or used to replace certain components of convolutional
networks while keeping their overall structure in place. We show that this
reliance on CNNs is not necessary and a pure transformer applied directly to
sequences of image patches can perform very well on image classification tasks.
When pre-trained on large amounts of data and transferred to multiple mid-sized
or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision
Transformer (ViT) attains excellent results compared to state-of-the-art
convolutional networks while requiring substantially fewer computational
resources to train.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robotic Inspection and 3D GPR-based Reconstruction for Underground Utilities. (arXiv:2106.01907v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Feng_J/0/1/0/all/0/1">Jinglun Feng</a>, <a href="http://arxiv.org/find/eess/1/au:+Yang_L/0/1/0/all/0/1">Liang Yang</a>, <a href="http://arxiv.org/find/eess/1/au:+Biao_J/0/1/0/all/0/1">Jiang Biao</a>, <a href="http://arxiv.org/find/eess/1/au:+Xiao_J/0/1/0/all/0/1">Jizhong Xiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01907">
                                    <div class="article-summary-box-inner">
                                        <span>Ground Penetrating Radar (GPR) is an effective non-destructive evaluation
(NDE) device for inspecting and surveying subsurface objects (i.e., rebars,
utility pipes) in complex environments. However, the current practice for GPR
data collection requires a human inspector to move a GPR cart along pre-marked
grid lines and record the GPR data in both X and Y directions for
post-processing by 3D GPR imaging software. It is time-consuming and tedious
work to survey a large area. Furthermore, identifying the subsurface targets
depends on the knowledge of an experienced engineer, who has to make manual and
subjective interpretation that limits the GPR applications, especially in
large-scale scenarios. In addition, the current GPR imaging technology is not
intuitive, and not for normal users to understand, and not friendly to
visualize. To address the above challenges, this paper presents a novel robotic
system to collect GPR data, interpret GPR data, localize the underground
utilities, reconstruct and visualize the underground objects&#x27; dense point cloud
model in a user-friendly manner. This system is composed of three modules: 1) a
vision-aided Omni-directional robotic data collection platform, which enables
the GPR antenna to scan the target area freely with an arbitrary trajectory
while using a visual-inertial-based positioning module tags the GPR
measurements with positioning information; 2) a deep neural network (DNN)
migration module to interpret the raw GPR B-scan image into a cross-section of
object model; 3) a DNN-based 3D reconstruction method, i.e., GPRNet, to
generate underground utility model represented as fine 3D point cloud.
Comparative studies on synthetic and field GPR raw data with various
incompleteness and noise are performed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-Guided Supervised Contrastive Learning for Semantic Segmentation. (arXiv:2106.01596v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Ho Hin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yucheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_S/0/1/0/all/0/1">Shunxing Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1">Bennett A. Landman</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1">Yuankai Huo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01596">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning has shown superior performance in embedding global and
spatial invariant features in computer vision (e.g., image classification).
However, its overall success of embedding local and spatial variant features is
still limited, especially for semantic segmentation. In a per-pixel prediction
task, more than one label can exist in a single image for segmentation (e.g.,
an image contains both cat, dog, and grass), thereby it is difficult to define
&#x27;positive&#x27; or &#x27;negative&#x27; pairs in a canonical contrastive learning setting. In
this paper, we propose an attention-guided supervised contrastive learning
approach to highlight a single semantic object every time as the target. With
our design, the same image can be embedded to different semantic clusters with
semantic attention (i.e., coerce semantic masks) as an additional input
channel. To achieve such attention, a novel two-stage training strategy is
presented. We evaluate the proposed method on multi-organ medical image
segmentation task, as our major task, with both in-house data and BTCV 2015
datasets. Comparing with the supervised and semi-supervised training
state-of-the-art in the backbone of ResNet-50, our proposed pipeline yields
substantial improvement of 5.53% and 6.09% in Dice score for both medical image
segmentation cohorts respectively. The performance of the proposed method on
natural images is assessed via PASCAL VOC 2012 dataset, and achieves 2.75%
substantial improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Comparison for Anti-noise Robustness of Deep Learning Classification Methods on a Tiny Object Image Dataset: from Convolutional Neural Network to Visual Transformer and Performer. (arXiv:2106.01927v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1">Ao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Haoyuan Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hechen Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1">Peng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Weiming Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wanli Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zou_S/0/1/0/all/0/1">Shuojia Zou</a>, <a href="http://arxiv.org/find/cs/1/au:+Grzegorzek_M/0/1/0/all/0/1">Marcin Grzegorzek</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01927">
                                    <div class="article-summary-box-inner">
                                        <span>Image classification has achieved unprecedented advance with the the rapid
development of deep learning. However, the classification of tiny object images
is still not well investigated. In this paper, we first briefly review the
development of Convolutional Neural Network and Visual Transformer in deep
learning, and introduce the sources and development of conventional noises and
adversarial attacks. Then we use various models of Convolutional Neural Network
and Visual Transformer to conduct a series of experiments on the image dataset
of tiny objects (sperms and impurities), and compare various evaluation metrics
in the experimental results to obtain a model with stable performance. Finally,
we discuss the problems in the classification of tiny objects and make a
prospect for the classification of tiny objects in the future.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simultaneous Corn and Soybean Yield Prediction from Remote Sensing Data Using Deep Transfer Learning. (arXiv:2012.03129v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khaki_S/0/1/0/all/0/1">Saeed Khaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hieu Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lizhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03129">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale crop yield estimation is, in part, made possible due to the
availability of remote sensing data allowing for the continuous monitoring of
crops throughout their growth cycle. Having this information allows
stakeholders the ability to make real-time decisions to maximize yield
potential. Although various models exist that predict yield from remote sensing
data, there currently does not exist an approach that can estimate yield for
multiple crops simultaneously, and thus leads to more accurate predictions. A
model that predicts the yield of multiple crops and concurrently considers the
interaction between multiple crop yields. We propose a new convolutional neural
network model called YieldNet which utilizes a novel deep learning framework
that uses transfer learning between corn and soybean yield predictions by
sharing the weights of the backbone feature extractor. Additionally, to
consider the multi-target response variable, we propose a new loss function. We
conduct our experiment using data from 1,132 counties for corn and 1,076
counties for soybean across the United States. Numerical results demonstrate
that our proposed method accurately predicts corn and soybean yield from one to
four months before the harvest with a MAE being 8.74% and 8.70% of the average
yield, respectively, and is competitive to other state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">APES: Audiovisual Person Search in Untrimmed Video. (arXiv:2106.01667v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Alcazar_J/0/1/0/all/0/1">Juan Leon Alcazar</a>, <a href="http://arxiv.org/find/cs/1/au:+Mai_L/0/1/0/all/0/1">Long Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Perazzi_F/0/1/0/all/0/1">Federico Perazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Joon-Young Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Arbelaez_P/0/1/0/all/0/1">Pablo Arbelaez</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghanem_B/0/1/0/all/0/1">Bernard Ghanem</a>, <a href="http://arxiv.org/find/cs/1/au:+Heilbron_F/0/1/0/all/0/1">Fabian Caba Heilbron</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01667">
                                    <div class="article-summary-box-inner">
                                        <span>Humans are arguably one of the most important subjects in video streams, many
real-world applications such as video summarization or video editing workflows
often require the automatic search and retrieval of a person of interest.
Despite tremendous efforts in the person reidentification and retrieval
domains, few works have developed audiovisual search strategies. In this paper,
we present the Audiovisual Person Search dataset (APES), a new dataset composed
of untrimmed videos whose audio (voices) and visual (faces) streams are densely
annotated. APES contains over 1.9K identities labeled along 36 hours of video,
making it the largest dataset available for untrimmed audiovisual person
search. A key property of APES is that it includes dense temporal annotations
that link faces to speech segments of the same identity. To showcase the
potential of our new dataset, we propose an audiovisual baseline and benchmark
for person retrieval. Our study shows that modeling audiovisual cues benefits
the recognition of people&#x27;s identities. To enable reproducibility and promote
future research, the dataset annotations and baseline code are available at:
https://github.com/fuankarion/audiovisual-person-search</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks. (arXiv:2106.01862v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paredes_Valles_F/0/1/0/all/0/1">Federico Paredes-Vall&#xe9;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Hagenaars_J/0/1/0/all/0/1">Jesse Hagenaars</a>, <a href="http://arxiv.org/find/cs/1/au:+Croon_G/0/1/0/all/0/1">Guido de Croon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01862">
                                    <div class="article-summary-box-inner">
                                        <span>Neuromorphic sensing and computing hold a promise for highly energy-efficient
and high-bandwidth-sensor processing. A major challenge for neuromorphic
computing is that learning algorithms for traditional artificial neural
networks (ANNs) do not transfer directly to spiking neural networks (SNNs) due
to the discrete spikes and more complex neuronal dynamics. As a consequence,
SNNs have not yet been successfully applied to complex, large-scale tasks. In
this article, we focus on the self-supervised learning problem of optical flow
estimation from event-based camera inputs, and investigate the changes that are
necessary to the state-of-the-art ANN training pipeline in order to
successfully tackle it with SNNs. More specifically, we first modify the input
event representation to encode a much smaller time slice with minimal explicit
temporal information. Consequently, we make the network&#x27;s neuronal dynamics and
recurrent connections responsible for integrating information over time.
Moreover, we reformulate the self-supervised loss function for event-based
optical flow to improve its convexity. We perform experiments with various
types of recurrent ANNs and SNNs using the proposed pipeline. Concerning SNNs,
we investigate the effects of elements such as parameter initialization and
optimization, surrogate gradient shape, and adaptive neuronal mechanisms. We
find that initialization and surrogate gradient width play a crucial part in
enabling learning with sparse inputs, while the inclusion of adaptivity and
learnable neuronal parameters can improve performance. We show that the
performance of the proposed ANNs and SNNs are on par with that of the current
state-of-the-art ANNs trained in a self-supervised manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptation for Facial Expression Classifier via Domain Discrimination and Gradient Reversal. (arXiv:2106.01467v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhmetov_K/0/1/0/all/0/1">Kamil Akhmetov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01467">
                                    <div class="article-summary-box-inner">
                                        <span>Bringing empathy to a computerized system could significantly improve the
quality of human-computer communications, as soon as machines would be able to
understand customer intentions and better serve their needs. According to
different studies (Literature Review), visual information is one of the most
important channels of human interaction and contains significant behavioral
signals, that may be captured from facial expressions. Therefore, it is
consistent and natural that the research in the field of Facial Expression
Recognition (FER) has acquired increased interest over the past decade due to
having diverse application area including health-care, sociology, psychology,
driver-safety, virtual reality, cognitive sciences, security, entertainment,
marketing, etc. We propose a new architecture for the task of FER and examine
the impact of domain discrimination loss regularization on the learning
process. With regard to observations, including both classical training
conditions and unsupervised domain adaptation scenarios, important aspects of
the considered domain adaptation approach integration are traced. The results
may serve as a foundation for further research in the field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SMURF: SeMantic and linguistic UndeRstanding Fusion for Caption Evaluation via Typicality Analysis. (arXiv:2106.01444v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feinglass_J/0/1/0/all/0/1">Joshua Feinglass</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yezhou Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01444">
                                    <div class="article-summary-box-inner">
                                        <span>The open-ended nature of visual captioning makes it a challenging area for
evaluation. The majority of proposed models rely on specialized training to
improve human-correlation, resulting in limited adoption, generalizability, and
explainabilty. We introduce &quot;typicality&quot;, a new formulation of evaluation
rooted in information theory, which is uniquely suited for problems lacking a
definite ground truth. Typicality serves as our framework to develop a novel
semantic comparison, SPARCS, as well as referenceless fluency evaluation
metrics. Over the course of our analysis, two separate dimensions of fluency
naturally emerge: style, captured by metric SPURTS, and grammar, captured in
the form of grammatical outlier penalties. Through extensive experiments and
ablation studies on benchmark datasets, we show how these decomposed dimensions
of semantics and fluency provide greater system-level insight into captioner
differences. Our proposed metrics along with their combination, SMURF, achieve
state-of-the-art correlation with human judgment when compared with other
rule-based evaluation metrics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generalized Domain Adaptation. (arXiv:2106.01656v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mitsuzumi_Y/0/1/0/all/0/1">Yu Mitsuzumi</a>, <a href="http://arxiv.org/find/cs/1/au:+Irie_G/0/1/0/all/0/1">Go Irie</a>, <a href="http://arxiv.org/find/cs/1/au:+Ikami_D/0/1/0/all/0/1">Daiki Ikami</a>, <a href="http://arxiv.org/find/cs/1/au:+Shibata_T/0/1/0/all/0/1">Takashi Shibata</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01656">
                                    <div class="article-summary-box-inner">
                                        <span>Many variants of unsupervised domain adaptation (UDA) problems have been
proposed and solved individually. Its side effect is that a method that works
for one variant is often ineffective for or not even applicable to another,
which has prevented practical applications. In this paper, we give a general
representation of UDA problems, named Generalized Domain Adaptation (GDA). GDA
covers the major variants as special cases, which allows us to organize them in
a comprehensive framework. Moreover, this generalization leads to a new
challenging setting where existing methods fail, such as when domain labels are
unknown, and class labels are only partially given to each domain. We propose a
novel approach to the new setting. The key to our approach is self-supervised
class-destructive learning, which enables the learning of class-invariant
representations and domain-adversarial classifiers without using any domain
labels. Extensive experiments using three benchmark datasets demonstrate that
our method outperforms the state-of-the-art UDA methods in the new setting and
that it is competitive in existing UDA variations as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noisy Labels are Treasure: Mean-Teacher-Assisted Confident Learning for Hepatic Vessel Segmentation. (arXiv:2106.01860v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xu_Z/0/1/0/all/0/1">Zhe Xu</a>, <a href="http://arxiv.org/find/eess/1/au:+Lu_D/0/1/0/all/0/1">Donghuan Lu</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_Y/0/1/0/all/0/1">Yixin Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Luo_J/0/1/0/all/0/1">Jie Luo</a>, <a href="http://arxiv.org/find/eess/1/au:+Jagadeesan_J/0/1/0/all/0/1">Jayender Jagadeesan</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_K/0/1/0/all/0/1">Kai Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Zheng_Y/0/1/0/all/0/1">Yefeng Zheng</a>, <a href="http://arxiv.org/find/eess/1/au:+Li_X/0/1/0/all/0/1">Xiu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01860">
                                    <div class="article-summary-box-inner">
                                        <span>Manually segmenting the hepatic vessels from Computer Tomography (CT) is far
more expertise-demanding and laborious than other structures due to the
low-contrast and complex morphology of vessels, resulting in the extreme lack
of high-quality labeled data. Without sufficient high-quality annotations, the
usual data-driven learning-based approaches struggle with deficient training.
On the other hand, directly introducing additional data with low-quality
annotations may confuse the network, leading to undesirable performance
degradation. To address this issue, we propose a novel mean-teacher-assisted
confident learning framework to robustly exploit the noisy labeled data for the
challenging hepatic vessel segmentation task. Specifically, with the adapted
confident learning assisted by a third party, i.e., the weight-averaged teacher
model, the noisy labels in the additional low-quality dataset can be
transformed from &quot;encumbrance&quot; to &quot;treasure&quot; via progressive pixel-wise
soft-correction, thus providing productive guidance. Extensive experiments
using two public datasets demonstrate the superiority of the proposed framework
as well as the effectiveness of each component.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards urban scenes understanding through polarization cues. (arXiv:2106.01717v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Blanchon_M/0/1/0/all/0/1">Marc Blanchon</a>, <a href="http://arxiv.org/find/cs/1/au:+Sidibe_D/0/1/0/all/0/1">D&#xe9;sir&#xe9; Sidib&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Morel_O/0/1/0/all/0/1">Olivier Morel</a>, <a href="http://arxiv.org/find/cs/1/au:+Seulin_R/0/1/0/all/0/1">Ralph Seulin</a>, <a href="http://arxiv.org/find/cs/1/au:+Meriaudeau_F/0/1/0/all/0/1">Fabrice Meriaudeau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01717">
                                    <div class="article-summary-box-inner">
                                        <span>Autonomous robotics is critically affected by the robustness of its scene
understanding algorithms. We propose a two-axis pipeline based on polarization
indices to analyze dynamic urban scenes. As robots evolve in unknown
environments, they are prone to encountering specular obstacles. Usually,
specular phenomena are rarely taken into account by algorithms which causes
misinterpretations and erroneous estimates. By exploiting all the light
properties, systems can greatly increase their robustness to events. In
addition to the conventional photometric characteristics, we propose to include
polarization sensing.

We demonstrate in this paper that the contribution of polarization
measurement increases both the performances of segmentation and the quality of
depth estimation. Our polarimetry-based approaches are compared here with other
state-of-the-art RGB-centric methods showing interest of using polarization
imaging.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1">Boris N. Oreshkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1">Florent Bocquelet</a>, <a href="http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1">F&#xe9;lix H. Harvey</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1">Bay Raitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1">Dominic Laflamme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01981">
                                    <div class="article-summary-box-inner">
                                        <span>Our work focuses on the development of a learnable neural representation of
human pose for advanced AI assisted animation tooling. Specifically, we tackle
the problem of constructing a full static human pose based on sparse and
variable user inputs (e.g. locations and/or orientations of a subset of body
joints). To solve this problem, we propose a novel neural architecture that
combines residual connections with prototype encoding of a partially specified
pose to create a new complete pose from the learned latent space. We show that
our architecture outperforms a baseline based on Transformer, both in terms of
accuracy and computational efficiency. Additionally, we develop a user
interface to integrate our neural model in Unity, a real-time 3D development
platform. Furthermore, we introduce two new datasets representing the static
human pose modeling problem, based on high-quality human motion capture data,
which will be released publicly along with model code.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Scale Feature Aggregation by Cross-Scale Pixel-to-Region Relation Operation for Semantic Segmentation. (arXiv:2106.01744v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1">Yechao Bai</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Ziyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1">Lyuyu Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1">Hongliang Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Ang_M/0/1/0/all/0/1">Marcelo H. Ang Jr</a>, <a href="http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1">Daniela Rus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01744">
                                    <div class="article-summary-box-inner">
                                        <span>Exploiting multi-scale features has shown great potential in tackling
semantic segmentation problems. The aggregation is commonly done with sum or
concatenation (concat) followed by convolutional (conv) layers. However, it
fully passes down the high-level context to the following hierarchy without
considering their interrelation. In this work, we aim to enable the low-level
feature to aggregate the complementary context from adjacent high-level feature
maps by a cross-scale pixel-to-region relation operation. We leverage
cross-scale context propagation to make the long-range dependency capturable
even by the high-resolution low-level features. To this end, we employ an
efficient feature pyramid network to obtain multi-scale features. We propose a
Relational Semantics Extractor (RSE) and Relational Semantics Propagator (RSP)
for context extraction and propagation respectively. Then we stack several RSP
into an RSP head to achieve the progressive top-down distribution of the
context. Experiment results on two challenging datasets Cityscapes and COCO
demonstrate that the RSP head performs competitively on both semantic
segmentation and panoptic segmentation with high efficiency. It outperforms
DeeplabV3 [1] by 0.7% with 75% fewer FLOPs (multiply-adds) in the semantic
segmentation task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pathology-Aware Generative Adversarial Networks for Medical Image Augmentation. (arXiv:2106.01915v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1">Changhee Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01915">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) can play a key role in Medical Image
Analysis under large-scale annotated datasets. However, preparing such massive
dataset is demanding. In this context, Generative Adversarial Networks (GANs)
can generate realistic but novel samples, and thus effectively cover the real
image distribution. In terms of interpolation, the GAN-based medical image
augmentation is reliable because medical modalities can display the human
body&#x27;s strong anatomical consistency at fixed position while clearly reflecting
inter-subject variability; thus, we propose to use noise-to-image GANs (e.g.,
random noise samples to diverse pathological images) for (i) medical Data
Augmentation (DA) and (ii) physician training. Regarding the DA, the
GAN-generated images can improve Computer-Aided Diagnosis based on supervised
learning. For the physician training, the GANs can display novel desired
pathological images and help train medical trainees despite
infrastructural/legal constraints. This thesis contains four GAN projects
aiming to present such novel applications&#x27; clinical relevance in collaboration
with physicians. Whereas the methods are more generally applicable, this thesis
only explores a few oncological applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Neural Network(CNN/ConvNet) in Stock Price Movement Prediction. (arXiv:2106.01920v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhardwaj_K/0/1/0/all/0/1">Kunal Bhardwaj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01920">
                                    <div class="article-summary-box-inner">
                                        <span>With technological advancements and the exponential growth of data, we have
been unfolding different capabilities of neural networks in different sectors.
In this paper, I have tried to use a specific type of Neural Network known as
Convolutional Neural Network(CNN/ConvNet) in the stock market. In other words,
I have tried to construct and train a convolutional neural network on past
stock prices data and then tried to predict the movement of stock price i.e.
whether the stock price would rise or fall, in the coming time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Less is More: Sparse Sampling for Dense Reaction Predictions. (arXiv:2106.01764v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1">Kezhou Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xiaohan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1">Zhedong Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Linchao Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01764">
                                    <div class="article-summary-box-inner">
                                        <span>Obtaining viewer responses from videos can be useful for creators and
streaming platforms to analyze the video performance and improve the future
user experience. In this report, we present our method for 2021 Evoked
Expression from Videos Challenge. In particular, our model utilizes both audio
and image modalities as inputs to predict emotion changes of viewers. To model
long-range emotion changes, we use a GRU-based model to predict one sparse
signal with 1Hz. We observe that the emotion changes are smooth. Therefore, the
final dense prediction is obtained via linear interpolating the signal, which
is robust to the prediction fluctuation. Albeit simple, the proposed method has
achieved pearson&#x27;s correlation score of 0.04430 on the final private test set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Advances in Classifying the Stages of Diabetic Retinopathy Using Convolutional Neural Networks in Low Memory Edge Devices. (arXiv:2106.01739v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Paul_A/0/1/0/all/0/1">Aditya Jyoti Paul</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01739">
                                    <div class="article-summary-box-inner">
                                        <span>Diabetic Retinopathy (DR) is a severe complication that may lead to retinal
vascular damage and is one of the leading causes of vision impairment and
blindness. DR broadly is classified into two stages - non-proliferative (NPDR),
where there are almost no symptoms, except a few microaneurysms, and
proliferative (PDR) involving a huge number of microaneurysms and hemorrhages,
soft and hard exudates, neo-vascularization, macular ischemia or a combination
of these, making it easier to detect. More specifically, DR is usually
classified into five levels, labeled 0-4, from 0 indicating no DR to 4 which is
most severe. This paper firstly presents a discussion on the risk factors of
the disease, then surveys the recent literature on the topic followed by
examining certain techniques which were found to be highly effective in
improving the prognosis accuracy. Finally, a convolutional neural network model
is proposed to detect all the stages of DR on a low-memory edge
microcontroller. The model has a size of just 5.9 MB, accuracy and F1 score
both of 94% and an inference speed of about 20 frames per second.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">You Never Cluster Alone. (arXiv:2106.01908v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuming Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Ziyi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Menghan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jie Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01908">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in self-supervised learning with instance-level contrastive
objectives facilitate unsupervised clustering. However, a standalone datum is
not perceiving the context of the holistic cluster, and may undergo sub-optimal
assignment. In this paper, we extend the mainstream contrastive learning
paradigm to a cluster-level scheme, where all the data subjected to the same
cluster contribute to a unified representation that encodes the context of each
data group. Contrastive learning with this representation then rewards the
assignment of each datum. To implement this vision, we propose twin-contrast
clustering (TCC). We define a set of categorical variables as clustering
assignment confidence, which links the instance-level learning track with the
cluster-level one. On one hand, with the corresponding assignment variables
being the weight, a weighted aggregation along the data points implements the
set representation of a cluster. We further propose heuristic cluster
augmentation equivalents to enable cluster-level contrastive learning. On the
other hand, we derive the evidence lower-bound of the instance-level
contrastive objective with the assignments. By reparametrizing the assignment
variables, TCC is trained end-to-end, requiring no alternating steps. Extensive
experiments show that TCC outperforms the state-of-the-art on challenging
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarially Adaptive Normalization for Single Domain Generalization. (arXiv:2106.01899v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xinjie Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1">Qifei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_J/0/1/0/all/0/1">Junjie Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1">Feng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1">Mingyuan Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01899">
                                    <div class="article-summary-box-inner">
                                        <span>Single domain generalization aims to learn a model that performs well on many
unseen domains with only one domain data for training. Existing works focus on
studying the adversarial domain augmentation (ADA) to improve the model&#x27;s
generalization capability. The impact on domain generalization of the
statistics of normalization layers is still underinvestigated. In this paper,
we propose a generic normalization approach, adaptive standardization and
rescaling normalization (ASR-Norm), to complement the missing part in previous
works. ASR-Norm learns both the standardization and rescaling statistics via
neural networks. This new form of normalization can be viewed as a generic form
of the traditional normalizations. When trained with ADA, the statistics in
ASR-Norm are learned to be adaptive to the data coming from different domains,
and hence improves the model generalization performance across domains,
especially on the target domain with large discrepancy from the source domain.
The experimental results show that ASR-Norm can bring consistent improvement to
the state-of-the-art ADA approaches by 1.6%, 2.7%, and 6.3% averagely on the
Digits, CIFAR-10-C, and PACS benchmarks, respectively. As a generic tool, the
improvement introduced by ASR-Norm is agnostic to the choice of ADA methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast improvement of TEM image with low-dose electrons by deep learning. (arXiv:2106.01718v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Katsuno_H/0/1/0/all/0/1">Hiroyasu Katsuno</a>, <a href="http://arxiv.org/find/eess/1/au:+Kimura_Y/0/1/0/all/0/1">Yuki Kimura</a>, <a href="http://arxiv.org/find/eess/1/au:+Yamazaki_T/0/1/0/all/0/1">Tomoya Yamazaki</a>, <a href="http://arxiv.org/find/eess/1/au:+Takigawa_I/0/1/0/all/0/1">Ichigaku Takigawa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01718">
                                    <div class="article-summary-box-inner">
                                        <span>Low-electron-dose observation is indispensable for observing various samples
using a transmission electron microscope; consequently, image processing has
been used to improve transmission electron microscopy (TEM) images. To apply
such image processing to in situ observations, we here apply a convolutional
neural network to TEM imaging. Using a dataset that includes short-exposure
images and long-exposure images, we develop a pipeline for processed
short-exposure images, based on end-to-end training. The quality of images
acquired with a total dose of approximately 5 e- per pixel becomes comparable
to that of images acquired with a total dose of approximately 1000 e- per
pixel. Because the conversion time is approximately 8 ms, in situ observation
at 125 fps is possible. This imaging technique enables in situ observation of
electron-beam-sensitive specimens.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">E2E-VLP: End-to-End Vision-Language Pre-training Enhanced by Visual Learning. (arXiv:2106.01804v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1">Haiyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1">Ming Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chenliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1">Bin Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Songfang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiao_W/0/1/0/all/0/1">Wenming Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01804">
                                    <div class="article-summary-box-inner">
                                        <span>Vision-language pre-training (VLP) on large-scale image-text pairs has
achieved huge success for the cross-modal downstream tasks. The most existing
pre-training methods mainly adopt a two-step training procedure, which firstly
employs a pre-trained object detector to extract region-based visual features,
then concatenates the image representation and text embedding as the input of
Transformer to train. However, these methods face problems of using
task-specific visual representation of the specific object detector for generic
cross-modal understanding, and the computation inefficiency of two-stage
pipeline. In this paper, we propose the first end-to-end vision-language
pre-trained model for both V+L understanding and generation, namely E2E-VLP,
where we build a unified Transformer framework to jointly learn visual
representation, and semantic alignments between image and text. We incorporate
the tasks of object detection and image captioning into pre-training with a
unified Transformer encoder-decoder architecture for enhancing visual learning.
An extensive set of experiments have been conducted on well-established
vision-language downstream tasks to demonstrate the effectiveness of this novel
VLP paradigm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Rankings for Recommendation in Matching Markets. (arXiv:2106.01941v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Bayoumi_M/0/1/0/all/0/1">Magd Bayoumi</a>, <a href="http://arxiv.org/find/cs/1/au:+Joachims_T/0/1/0/all/0/1">Thorsten Joachims</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01941">
                                    <div class="article-summary-box-inner">
                                        <span>Based on the success of recommender systems in e-commerce, there is growing
interest in their use in matching markets (e.g., labor). While this holds
potential for improving market fluidity and fairness, we show in this paper
that naively applying existing recommender systems to matching markets is
sub-optimal. Considering the standard process where candidates apply and then
get evaluated by employers, we present a new recommendation framework to model
this interaction mechanism and propose efficient algorithms for computing
personalized rankings in this setting. We show that the optimal rankings need
to not only account for the potentially divergent preferences of candidates and
employers, but they also need to account for capacity constraints. This makes
conventional ranking systems that merely rank by some local score (e.g.,
one-sided or reciprocal relevance) highly sub-optimal -- not only for an
individual user, but also for societal goals (e.g., low unemployment). To
address this shortcoming, we propose the first method for jointly optimizing
the rankings for all candidates in the market to explicitly maximize social
welfare. In addition to the theoretical derivation, we evaluate the method both
on simulated environments and on data from a real-world
networking-recommendation system that we built and fielded at a large computer
science conference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EmoDNN: Understanding emotions from short texts through a deep neural network ensemble. (arXiv:2106.01706v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamran_S/0/1/0/all/0/1">Sara Kamran</a>, <a href="http://arxiv.org/find/cs/1/au:+Zall_R/0/1/0/all/0/1">Raziyeh Zall</a>, <a href="http://arxiv.org/find/cs/1/au:+Kangavari_M/0/1/0/all/0/1">Mohammad Reza Kangavari</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1">Saeid Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmani_S/0/1/0/all/0/1">Sana Rahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1">Wen Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01706">
                                    <div class="article-summary-box-inner">
                                        <span>The latent knowledge in the emotions and the opinions of the individuals that
are manifested via social networks are crucial to numerous applications
including social management, dynamical processes, and public security.
Affective computing, as an interdisciplinary research field, linking artificial
intelligence to cognitive inference, is capable to exploit emotion-oriented
knowledge from brief contents. The textual contents convey hidden information
such as personality and cognition about corresponding authors that can
determine both correlations and variations between users. Emotion recognition
from brief contents should embrace the contrast between authors where the
differences in personality and cognition can be traced within emotional
expressions. To tackle this challenge, we devise a framework that, on the one
hand, infers latent individual aspects, from brief contents and, on the other
hand, presents a novel ensemble classifier equipped with dynamic dropout
convnets to extract emotions from textual context. To categorize short text
contents, our proposed method conjointly leverages cognitive factors and
exploits hidden information. We utilize the outcome vectors in a novel
embedding model to foster emotion-pertinent features that are collectively
assembled by lexicon inductions. Experimental results show that compared to
other competitors, our proposed model can achieve a higher performance in
recognizing emotion from noisy contents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Query Logs for Privacy Studies: On Deriving Search Queries from Questions. (arXiv:2004.02023v3 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Biega_A/0/1/0/all/0/1">Asia J. Biega</a>, <a href="http://arxiv.org/find/cs/1/au:+Schmidt_J/0/1/0/all/0/1">Jana Schmidt</a>, <a href="http://arxiv.org/find/cs/1/au:+Roy_R/0/1/0/all/0/1">Rishiraj Saha Roy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.02023">
                                    <div class="article-summary-box-inner">
                                        <span>Translating verbose information needs into crisp search queries is a
phenomenon that is ubiquitous but hardly understood. Insights into this process
could be valuable in several applications, including synthesizing large
privacy-friendly query logs from public Web sources which are readily available
to the academic research community. In this work, we take a step towards
understanding query formulation by tapping into the rich potential of community
question answering (CQA) forums. Specifically, we sample natural language (NL)
questions spanning diverse themes from the Stack Exchange platform, and conduct
a large-scale conversion experiment where crowdworkers submit search queries
they would use when looking for equivalent information. We provide a careful
analysis of this data, accounting for possible sources of bias during
conversion, along with insights into user-specific linguistic patterns and
search behaviors. We release a dataset of 7,000 question-query pairs from this
study to facilitate further research on query understanding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JIZHI: A Fast and Cost-Effective Model-As-A-Service System for Web-Scale Online Inference at Baidu. (arXiv:2106.01674v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qian Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1">Xiaochao Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hao Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guangxing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenlin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guobao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zhiwei Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1">Daxiang Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01674">
                                    <div class="article-summary-box-inner">
                                        <span>In modern internet industries, deep learning based recommender systems have
became an indispensable building block for a wide spectrum of applications,
such as search engine, news feed, and short video clips. However, it remains
challenging to carry the well-trained deep models for online real-time
inference serving, with respect to the time-varying web-scale traffics from
billions of users, in a cost-effective manner. In this work, we present JIZHI -
a Model-as-a-Service system - that per second handles hundreds of millions of
online inference requests to huge deep models with more than trillions of
sparse parameters, for over twenty real-time recommendation services at Baidu,
Inc. In JIZHI, the inference workflow of every recommendation request is
transformed to a Staged Event-Driven Pipeline (SEDP), where each node in the
pipeline refers to a staged computation or I/O intensive task processor. With
traffics of real-time inference requests arrived, each modularized processor
can be run in a fully asynchronized way and managed separately. Besides, JIZHI
introduces heterogeneous and hierarchical storage to further accelerate the
online inference process by reducing unnecessary computations and potential
data access latency induced by ultra-sparse model parameters. Moreover, an
intelligent resource manager has been deployed to maximize the throughput of
JIZHI over the shared infrastructure by searching the optimal resource
allocation plan from historical logs and fine-tuning the load shedding policies
over intermediate system feedback. Extensive experiments have been done to
demonstrate the advantages of JIZHI from the perspectives of end-to-end service
latency, system-wide throughput, and resource consumption. JIZHI has helped
Baidu saved more than ten million US dollars in hardware and utility costs
while handling 200% more traffics without sacrificing inference efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What and How long: Prediction of Mobile App Engagement. (arXiv:2106.01490v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yuan Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1">Ke Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Pelleg_D/0/1/0/all/0/1">Dan Pelleg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01490">
                                    <div class="article-summary-box-inner">
                                        <span>User engagement is crucial to the long-term success of a mobile app. Several
metrics, such as dwell time, have been used for measuring user engagement.
However, how to effectively predict user engagement in the context of mobile
apps is still an open research question. For example, do the mobile usage
contexts (e.g.,~time of day) in which users access mobile apps impact their
dwell time? Answers to such questions could help mobile operating system and
publishers to optimize advertising and service placement. In this paper, we
first conduct an empirical study for assessing how user characteristics,
temporal features, and the short/long-term contexts contribute to gains in
predicting users&#x27; app dwell time on the population level. The comprehensive
analysis is conducted on large app usage logs collected through a mobile
advertising company. The dataset covers more than 12K anonymous users and 1.3
million log events. Based on the analysis, we further investigate a novel
mobile app engagement prediction problem -- can we predict simultaneously what
app the user will use next and how long he/she will stay on that app? We
propose several strategies for this joint prediction problem and demonstrate
that our model can improve the performance significantly when compared with the
state-of-the-art baselines. Our work can help mobile system developers in
designing a better and more engagement-aware mobile app user experience.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">You Never Cluster Alone. (arXiv:2106.01908v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1">Yuming Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1">Ziyi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1">Menghan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_J/0/1/0/all/0/1">Jie Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1">Philip H.S. Torr</a>, <a href="http://arxiv.org/find/cs/1/au:+Shao_L/0/1/0/all/0/1">Ling Shao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01908">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in self-supervised learning with instance-level contrastive
objectives facilitate unsupervised clustering. However, a standalone datum is
not perceiving the context of the holistic cluster, and may undergo sub-optimal
assignment. In this paper, we extend the mainstream contrastive learning
paradigm to a cluster-level scheme, where all the data subjected to the same
cluster contribute to a unified representation that encodes the context of each
data group. Contrastive learning with this representation then rewards the
assignment of each datum. To implement this vision, we propose twin-contrast
clustering (TCC). We define a set of categorical variables as clustering
assignment confidence, which links the instance-level learning track with the
cluster-level one. On one hand, with the corresponding assignment variables
being the weight, a weighted aggregation along the data points implements the
set representation of a cluster. We further propose heuristic cluster
augmentation equivalents to enable cluster-level contrastive learning. On the
other hand, we derive the evidence lower-bound of the instance-level
contrastive objective with the assignments. By reparametrizing the assignment
variables, TCC is trained end-to-end, requiring no alternating steps. Extensive
experiments show that TCC outperforms the state-of-the-art on challenging
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Case for Translation-Invariant Self-Attention in Transformer-Based Language Models. (arXiv:2106.01950v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wennberg_U/0/1/0/all/0/1">Ulme Wennberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Henter_G/0/1/0/all/0/1">Gustav Eje Henter</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01950">
                                    <div class="article-summary-box-inner">
                                        <span>Mechanisms for encoding positional information are central for
transformer-based language models. In this paper, we analyze the position
embeddings of existing language models, finding strong evidence of translation
invariance, both for the embeddings themselves and for their effect on
self-attention. The degree of translation invariance increases during training
and correlates positively with model performance. Our findings lead us to
propose translation-invariant self-attention (TISA), which accounts for the
relative position between tokens in an interpretable fashion without needing
conventional position embeddings. Our proposal has several theoretical
advantages over existing position-representation approaches. Experiments show
that it improves on regular ALBERT on GLUE tasks, while only adding orders of
magnitude less positional parameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural Actor: Neural Free-view Synthesis of Human Actors with Pose Control. (arXiv:2106.02019v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lingjie Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Habermann_M/0/1/0/all/0/1">Marc Habermann</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudnev_V/0/1/0/all/0/1">Viktor Rudnev</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_K/0/1/0/all/0/1">Kripasindhu Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_J/0/1/0/all/0/1">Jiatao Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02019">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Neural Actor (NA), a new method for high-quality synthesis of
humans from arbitrary viewpoints and under arbitrary controllable poses. Our
method is built upon recent neural scene representation and rendering works
which learn representations of geometry and appearance from only 2D images.
While existing works demonstrated compelling rendering of static scenes and
playback of dynamic scenes, photo-realistic reconstruction and rendering of
humans with neural implicit methods, in particular under user-controlled novel
poses, is still difficult. To address this problem, we utilize a coarse body
model as the proxy to unwarp the surrounding 3D space into a canonical pose. A
neural radiance field learns pose-dependent geometric deformations and pose-
and view-dependent appearance effects in the canonical space from multi-view
video input. To synthesize novel views of high fidelity dynamic geometry and
appearance, we leverage 2D texture maps defined on the body model as latent
variables for predicting residual deformations and the dynamic appearance.
Experiments demonstrate that our method achieves better quality than the
state-of-the-arts on playback as well as novel pose synthesis, and can even
generalize well to new poses that starkly differ from the training poses.
Furthermore, our method also supports body shape control of the synthesized
results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A New Multilabel System for Automatic Music Emotion Recognition. (arXiv:1905.12629v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paolizzo_F/0/1/0/all/0/1">Fabio Paolizzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Pichierri_N/0/1/0/all/0/1">Natalia Pichierri</a>, <a href="http://arxiv.org/find/cs/1/au:+Casali_D/0/1/0/all/0/1">Daniele Casali</a>, <a href="http://arxiv.org/find/cs/1/au:+Giardino_D/0/1/0/all/0/1">Daniele Giardino</a>, <a href="http://arxiv.org/find/cs/1/au:+Matta_M/0/1/0/all/0/1">Marco Matta</a>, <a href="http://arxiv.org/find/cs/1/au:+Costantini_G/0/1/0/all/0/1">Giovanni Costantini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.12629">
                                    <div class="article-summary-box-inner">
                                        <span>Achieving advancements in automatic recognition of emotions that music can
induce require considering multiplicity and simultaneity of emotions.
Comparison of different machine learning algorithms performing multilabel and
multiclass classification is the core of our work. The study analyzes the
implementation of the Geneva Emotional Music Scale 9 in the Emotify music
dataset and investigates its adoption from a machine-learning perspective. We
approach the scenario of emotions expression/induction through music as a
multilabel and multiclass problem, where multiple emotion labels can be adopted
for the same music track by each annotator (multilabel), and each emotion can
be identified or not in the music (multiclass). The aim is the automatic
recognition of induced emotions through music.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anticipative Video Transformer. (arXiv:2106.02036v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Girdhar_R/0/1/0/all/0/1">Rohit Girdhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1">Kristen Grauman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02036">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Anticipative Video Transformer (AVT), an end-to-end
attention-based video modeling architecture that attends to the previously
observed video in order to anticipate future actions. We train the model
jointly to predict the next action in a video sequence, while also learning
frame feature encoders that are predictive of successive future frames&#x27;
features. Compared to existing temporal aggregation strategies, AVT has the
advantage of both maintaining the sequential progression of observed actions
while still capturing long-range dependencies--both critical for the
anticipation task. Through extensive experiments, we show that AVT obtains the
best reported performance on four popular action anticipation benchmarks:
EpicKitchens-55, EpicKitchens-100, EGTEA Gaze+, and 50-Salads, including
outperforming all submissions to the EpicKitchens-100 CVPR&#x27;21 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convergent Graph Solvers. (arXiv:2106.01680v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Junyoung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1">Jinhyun Choo</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jinkyoo Park</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01680">
                                    <div class="article-summary-box-inner">
                                        <span>We propose the convergent graph solver (CGS), a deep learning method that
learns iterative mappings to predict the properties of a graph system at its
stationary state (fixed point) with guaranteed convergence. CGS systematically
computes the fixed points of a target graph system and decodes them to estimate
the stationary properties of the system without the prior knowledge of existing
solvers or intermediate solutions. The forward propagation of CGS proceeds in
three steps: (1) constructing the input dependent linear contracting iterative
maps, (2) computing the fixed-points of the linear maps, and (3) decoding the
fixed-points to estimate the properties. The contractivity of the constructed
linear maps guarantees the existence and uniqueness of the fixed points
following the Banach fixed point theorem. To train CGS efficiently, we also
derive a tractable analytical expression for its gradient by leveraging the
implicit function theorem. We evaluate the performance of CGS by applying it to
various network-analytic and graph benchmark problems. The results indicate
that CGS has competitive capabilities for predicting the stationary properties
of graph systems, irrespective of whether the target systems are linear or
non-linear. CGS also shows high performance for graph classification problems
where the existence or the meaning of a fixed point is hard to be clearly
defined, which highlights the potential of CGS as a general graph neural
network architecture.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Reference-based Super-Resolution via C2-Matching. (arXiv:2106.01863v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yuming Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1">Kelvin C.K. Chan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xintao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Loy_C/0/1/0/all/0/1">Chen Change Loy</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Ziwei Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01863">
                                    <div class="article-summary-box-inner">
                                        <span>Reference-based Super-Resolution (Ref-SR) has recently emerged as a promising
paradigm to enhance a low-resolution (LR) input image by introducing an
additional high-resolution (HR) reference image. Existing Ref-SR methods mostly
rely on implicit correspondence matching to borrow HR textures from reference
images to compensate for the information loss in input images. However,
performing local transfer is difficult because of two gaps between input and
reference images: the transformation gap (e.g. scale and rotation) and the
resolution gap (e.g. HR and LR). To tackle these challenges, we propose
C2-Matching in this work, which produces explicit robust matching crossing
transformation and resolution. 1) For the transformation gap, we propose a
contrastive correspondence network, which learns transformation-robust
correspondences using augmented views of the input image. 2) For the resolution
gap, we adopt a teacher-student correlation distillation, which distills
knowledge from the easier HR-HR matching to guide the more ambiguous LR-HR
matching. 3) Finally, we design a dynamic aggregation module to address the
potential misalignment issue. In addition, to faithfully evaluate the
performance of Ref-SR under a realistic setting, we contribute the
Webly-Referenced SR (WR-SR) dataset, mimicking the practical usage scenario.
Extensive experiments demonstrate that our proposed C2-Matching significantly
outperforms state of the arts by over 1dB on the standard CUFED5 benchmark.
Notably, it also shows great generalizability on WR-SR dataset as well as
robustness across large scale and rotation transformations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Grounding Complex Navigational Instructions Using Scene Graphs. (arXiv:2106.01607v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jong_M/0/1/0/all/0/1">Michiel de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Krishna_S/0/1/0/all/0/1">Satyapriya Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1">Anuva Agarwal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01607">
                                    <div class="article-summary-box-inner">
                                        <span>Training a reinforcement learning agent to carry out natural language
instructions is limited by the available supervision, i.e. knowing when the
instruction has been carried out. We adapt the CLEVR visual question answering
dataset to generate complex natural language navigation instructions and
accompanying scene graphs, yielding an environment-agnostic supervised dataset.
To demonstrate the use of this data set, we map the scenes to the VizDoom
environment and use the architecture in \citet{gatedattention} to train an
agent to carry out these more complex language instructions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fingerprinting Fine-tuned Language Models in the Wild. (arXiv:2106.01703v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diwan_N/0/1/0/all/0/1">Nirav Diwan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakravorty_T/0/1/0/all/0/1">Tanmoy Chakravorty</a>, <a href="http://arxiv.org/find/cs/1/au:+Shafiq_Z/0/1/0/all/0/1">Zubair Shafiq</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01703">
                                    <div class="article-summary-box-inner">
                                        <span>There are concerns that the ability of language models (LMs) to generate high
quality synthetic text can be misused to launch spam, disinformation, or
propaganda. Therefore, the research community is actively working on developing
approaches to detect whether a given text is organic or synthetic. While this
is a useful first step, it is important to be able to further fingerprint the
author LM to attribute its origin. Prior work on fingerprinting LMs is limited
to attributing synthetic text generated by a handful (usually &lt; 10) of
pre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad
of ways (e.g., on a domain-specific text corpus) before being used to generate
synthetic text. It is challenging to fingerprinting fine-tuned LMs because the
universe of fine-tuned LMs is much larger in realistic scenarios. To address
this challenge, we study the problem of large-scale fingerprinting of
fine-tuned LMs in the wild. Using a real-world dataset of synthetic text
generated by 108 different fine-tuned LMs, we conduct comprehensive experiments
to demonstrate the limitations of existing fingerprinting approaches. Our
results show that fine-tuning itself is the most effective in attributing the
synthetic text generated by fine-tuned LMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DNA-GCN: Graph convolutional networks for predicting DNA-protein binding. (arXiv:2106.01836v1 [q-bio.GN])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Guo_Y/0/1/0/all/0/1">Yuhang Guo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Luo_X/0/1/0/all/0/1">Xiao Luo</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Chen_L/0/1/0/all/0/1">Liang Chen</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Deng_M/0/1/0/all/0/1">Minghua Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01836">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting DNA-protein binding is an important and classic problem in
bioinformatics. Convolutional neural networks have outperformed conventional
methods in modeling the sequence specificity of DNA-protein binding. However,
none of the studies has utilized graph convolutional networks for motif
inference. In this work, we propose to use graph convolutional networks for
motif inference. We build a sequence k-mer graph for the whole dataset based on
k-mer co-occurrence and k-mer sequence relationship and then learn DNA Graph
Convolutional Network (DNA-GCN) for the whole dataset. Our DNA-GCN is
initialized with a one-hot representation for all nodes, and it then jointly
learns the embeddings for both k-mers and sequences, as supervised by the known
labels of sequences. We evaluate our model on 50 datasets from ENCODE. DNA-GCN
shows its competitive performance compared with the baseline model. Besides, we
analyze our model and design several different architectures to help fit
different datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-supervised Conditional Density Estimation for Imputation and Classification of Incomplete Instances. (arXiv:2106.01708v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1">Buliao Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01708">
                                    <div class="article-summary-box-inner">
                                        <span>Incomplete instances with various missing attributes in many real-world
scenes have brought challenges to the classification task. There are some
missing values imputation methods to fill the missing values with substitute
values before classification. However, the separation between imputation and
classification may lead to inferior performance since label information are
ignored during imputation. Moreover, these imputation methods tend to
initialize these missing values with strong prior assumptions, while the
unreliability of such initialization is rarely considered. To tackle these
problems, a novel semi-supervised conditional normalizing flow (SSCFlow) is
proposed in this paper. SSCFlow explicitly utilizes the observed labels to
facilitate the imputation and classification simultaneously by employing a
semi-supervised algorithm to estimate the conditional probability density of
missing values. Moreover, SSCFlow takes the initialized missing values as
corrupted initial imputation and iteratively reconstructs their latent
representations with an overcomplete denoising autoencoder to approximate the
true conditional probability density of missing values. Experiments have been
conducted with real-world datasets to demonstrate the robustness and efficiency
of the proposed algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Advances in Classifying the Stages of Diabetic Retinopathy Using Convolutional Neural Networks in Low Memory Edge Devices. (arXiv:2106.01739v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Paul_A/0/1/0/all/0/1">Aditya Jyoti Paul</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01739">
                                    <div class="article-summary-box-inner">
                                        <span>Diabetic Retinopathy (DR) is a severe complication that may lead to retinal
vascular damage and is one of the leading causes of vision impairment and
blindness. DR broadly is classified into two stages - non-proliferative (NPDR),
where there are almost no symptoms, except a few microaneurysms, and
proliferative (PDR) involving a huge number of microaneurysms and hemorrhages,
soft and hard exudates, neo-vascularization, macular ischemia or a combination
of these, making it easier to detect. More specifically, DR is usually
classified into five levels, labeled 0-4, from 0 indicating no DR to 4 which is
most severe. This paper firstly presents a discussion on the risk factors of
the disease, then surveys the recent literature on the topic followed by
examining certain techniques which were found to be highly effective in
improving the prognosis accuracy. Finally, a convolutional neural network model
is proposed to detect all the stages of DR on a low-memory edge
microcontroller. The model has a size of just 5.9 MB, accuracy and F1 score
both of 94% and an inference speed of about 20 frames per second.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A remark on a paper of Krotov and Hopfield [arXiv:2008.06996]. (arXiv:2105.15034v2 [q-bio.NC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Tang_F/0/1/0/all/0/1">Fei Tang</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Kopp_M/0/1/0/all/0/1">Michael Kopp</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15034">
                                    <div class="article-summary-box-inner">
                                        <span>In their recent paper titled &quot;Large Associative Memory Problem in
Neurobiology and Machine Learning&quot; [arXiv:2008.06996] the authors gave a
biologically plausible microscopic theory from which one can recover many dense
associative memory models discussed in the literature. We show that the layers
of the recent &quot;MLP-mixer&quot; [arXiv:2105.01601] as well as the essentially
equivalent model in [arXiv:2105.02723] are amongst them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Membership Inference Attacks on Deep Regression Models for Neuroimaging. (arXiv:2105.02866v2 [q-bio.QM] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Gupta_U/0/1/0/all/0/1">Umang Gupta</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Stripelis_D/0/1/0/all/0/1">Dimitris Stripelis</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lam_P/0/1/0/all/0/1">Pradeep K. Lam</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Thompson_P/0/1/0/all/0/1">Paul M. Thompson</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Ambite_J/0/1/0/all/0/1">Jos&#xe9; Luis Ambite</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Steeg_G/0/1/0/all/0/1">Greg Ver Steeg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.02866">
                                    <div class="article-summary-box-inner">
                                        <span>Ensuring the privacy of research participants is vital, even more so in
healthcare environments. Deep learning approaches to neuroimaging require large
datasets, and this often necessitates sharing data between multiple sites,
which is antithetical to the privacy objectives. Federated learning is a
commonly proposed solution to this problem. It circumvents the need for data
sharing by sharing parameters during the training process. However, we
demonstrate that allowing access to parameters may leak private information
even if data is never directly shared. In particular, we show that it is
possible to infer if a sample was used to train the model given only access to
the model prediction (black-box) or access to the model itself (white-box) and
some leaked samples from the training data distribution. Such attacks are
commonly referred to as Membership Inference attacks. We show realistic
Membership Inference attacks on deep learning models trained for 3D
neuroimaging tasks in a centralized as well as decentralized setup. We
demonstrate feasible attacks on brain age prediction models (deep learning
models that predict a person&#x27;s age from their brain MRI scan). We correctly
identified whether an MRI scan was used in model training with a 60% to over
80% success rate depending on model complexity and security assumptions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Last iterate convergence of SGD for Least-Squares in the Interpolation regime. (arXiv:2102.03183v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Varre_A/0/1/0/all/0/1">Aditya Varre</a>, <a href="http://arxiv.org/find/cs/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1">Loucas Pillaud-Vivien</a>, <a href="http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1">Nicolas Flammarion</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.03183">
                                    <div class="article-summary-box-inner">
                                        <span>Motivated by the recent successes of neural networks that have the ability to
fit the data perfectly and generalize well, we study the noiseless model in the
fundamental least-squares setup. We assume that an optimum predictor fits
perfectly inputs and outputs $\langle \theta_* , \phi(X) \rangle &#x3D; Y$, where
$\phi(X)$ stands for a possibly infinite dimensional non-linear feature map. To
solve this problem, we consider the estimator given by the last iterate of
stochastic gradient descent (SGD) with constant step-size. In this context, our
contribution is two fold: (i) from a (stochastic) optimization perspective, we
exhibit an archetypal problem where we can show explicitly the convergence of
SGD final iterate for a non-strongly convex problem with constant step-size
whereas usual results use some form of average and (ii) from a statistical
perspective, we give explicit non-asymptotic convergence rates in the
over-parameterized setting and leverage a fine-grained parameterization of the
problem to exhibit polynomial rates that can be faster than $O(1/T)$. The link
with reproducing kernel Hilbert spaces is established.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Communication-Efficient Distributed SVD via Local Power Iterations. (arXiv:2002.08014v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1">Xiang Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1">Shusen Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Chen_K/0/1/0/all/0/1">Kun Chen</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1">Zhihua Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.08014">
                                    <div class="article-summary-box-inner">
                                        <span>We study distributed computing of the truncated singular value decomposition
problem. We develop an algorithm that we call \texttt{LocalPower} for improving
communication efficiency. Specifically, we uniformly partition the dataset
among $m$ nodes and alternate between multiple (precisely $p$) local power
iterations and one global aggregation. In the aggregation, we propose to weight
each local eigenvector matrix with orthogonal Procrustes transformation (OPT).
As a practical surrogate of OPT, sign-fixing, which uses a diagonal matrix with
$\pm 1$ entries as weights, has better computation complexity and stability in
experiments. We theoretically show that under certain assumptions
\texttt{LocalPower} lowers the required number of communications by a factor of
$p$ to reach a constant accuracy. We also show that the strategy of
periodically decaying $p$ helps obtain high-precision solutions. We conduct
experiments to demonstrate the effectiveness of \texttt{LocalPower}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Stochastic Moving-Average Estimators for Non-Convex Optimization. (arXiv:2104.14840v2 [math.OC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Guo_Z/0/1/0/all/0/1">Zhishuai Guo</a>, <a href="http://arxiv.org/find/math/1/au:+Xu_Y/0/1/0/all/0/1">Yi Xu</a>, <a href="http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1">Wotao Yin</a>, <a href="http://arxiv.org/find/math/1/au:+Jin_R/0/1/0/all/0/1">Rong Jin</a>, <a href="http://arxiv.org/find/math/1/au:+Yang_T/0/1/0/all/0/1">Tianbao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14840">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we demonstrate the power of a widely used stochastic estimator
based on moving average (SEMA) on a range of stochastic non-convex optimization
problems, which only requires {\bf a general unbiased stochastic oracle}. We
analyze various stochastic methods (existing or newly proposed) based on the
{\bf variance recursion property} of SEMA for three families of non-convex
optimization, namely standard stochastic non-convex minimization, stochastic
non-convex strongly-concave min-max optimization, and stochastic bilevel
optimization. Our contributions include: (i) for standard stochastic non-convex
minimization, we present a simple and intuitive proof of convergence for a
family Adam-style methods (including Adam) with an increasing or large
&quot;momentum&quot; parameter for the first-order moment, which gives an alternative yet
more natural way to guarantee Adam converge; (ii) for stochastic non-convex
strongly-concave min-max optimization, we present a single-loop stochastic
gradient descent ascent method based on the moving average estimators and
establish its oracle complexity of $O(1/\epsilon^4)$ without using a large
mini-batch size, addressing a gap in the literature; (iii) for stochastic
bilevel optimization, we present a single-loop stochastic method based on the
moving average estimators and establish its oracle complexity of $\widetilde
O(1/\epsilon^4)$ without computing the inverse or SVD of the Hessian matrix,
improving state-of-the-art results. For all these problems, we also establish a
variance diminishing result for the used stochastic gradient estimators.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. (arXiv:2010.11929v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1">Alexey Dosovitskiy</a>, <a href="http://arxiv.org/find/cs/1/au:+Beyer_L/0/1/0/all/0/1">Lucas Beyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolesnikov_A/0/1/0/all/0/1">Alexander Kolesnikov</a>, <a href="http://arxiv.org/find/cs/1/au:+Weissenborn_D/0/1/0/all/0/1">Dirk Weissenborn</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_X/0/1/0/all/0/1">Xiaohua Zhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1">Thomas Unterthiner</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1">Mostafa Dehghani</a>, <a href="http://arxiv.org/find/cs/1/au:+Minderer_M/0/1/0/all/0/1">Matthias Minderer</a>, <a href="http://arxiv.org/find/cs/1/au:+Heigold_G/0/1/0/all/0/1">Georg Heigold</a>, <a href="http://arxiv.org/find/cs/1/au:+Gelly_S/0/1/0/all/0/1">Sylvain Gelly</a>, <a href="http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1">Jakob Uszkoreit</a>, <a href="http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1">Neil Houlsby</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11929">
                                    <div class="article-summary-box-inner">
                                        <span>While the Transformer architecture has become the de-facto standard for
natural language processing tasks, its applications to computer vision remain
limited. In vision, attention is either applied in conjunction with
convolutional networks, or used to replace certain components of convolutional
networks while keeping their overall structure in place. We show that this
reliance on CNNs is not necessary and a pure transformer applied directly to
sequences of image patches can perform very well on image classification tasks.
When pre-trained on large amounts of data and transferred to multiple mid-sized
or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision
Transformer (ViT) attains excellent results compared to state-of-the-art
convolutional networks while requiring substantially fewer computational
resources to train.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Policy Gradient Algorithm for Learning to Learn in Multiagent Reinforcement Learning. (arXiv:2011.00382v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Dong-Ki Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Miao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Riemer_M/0/1/0/all/0/1">Matthew Riemer</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_C/0/1/0/all/0/1">Chuangchuang Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdulhai_M/0/1/0/all/0/1">Marwa Abdulhai</a>, <a href="http://arxiv.org/find/cs/1/au:+Habibi_G/0/1/0/all/0/1">Golnaz Habibi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_Cot_S/0/1/0/all/0/1">Sebastian Lopez-Cot</a>, <a href="http://arxiv.org/find/cs/1/au:+Tesauro_G/0/1/0/all/0/1">Gerald Tesauro</a>, <a href="http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1">Jonathan P. How</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.00382">
                                    <div class="article-summary-box-inner">
                                        <span>A fundamental challenge in multiagent reinforcement learning is to learn
beneficial behaviors in a shared environment with other simultaneously learning
agents. In particular, each agent perceives the environment as effectively
non-stationary due to the changing policies of other agents. Moreover, each
agent is itself constantly learning, leading to natural non-stationarity in the
distribution of experiences encountered. In this paper, we propose a novel
meta-multiagent policy gradient theorem that directly accounts for the
non-stationary policy dynamics inherent to multiagent learning settings. This
is achieved by modeling our gradient updates to consider both an agent&#x27;s own
non-stationary policy dynamics and the non-stationary policy dynamics of other
agents in the environment. We show that our theoretically grounded approach
provides a general solution to the multiagent learning problem, which
inherently comprises all key aspects of previous state of the art approaches on
this topic. We test our method on a diverse suite of multiagent benchmarks and
demonstrate a more efficient ability to adapt to new agents as they learn than
baseline methods across the full spectrum of mixed incentive, competitive, and
cooperative domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep neural network approximation of analytic functions. (arXiv:2104.02095v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Beknazaryan_A/0/1/0/all/0/1">Aleksandr Beknazaryan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.02095">
                                    <div class="article-summary-box-inner">
                                        <span>We provide an entropy bound for the spaces of neural networks with piecewise
linear activation functions, such as the ReLU and the absolute value functions.
This bound generalizes the known entropy bound for the space of linear
functions on $\mathbb{R}^d$ and it depends on the value at the point
$(1,1,...,1)$ of the networks obtained by taking the absolute values of all
parameters of original networks. Keeping this value together with the depth,
width and the parameters of the networks to have logarithmic dependence on
$1/\varepsilon$, we $\varepsilon$-approximate functions that are analytic on
certain regions of $\mathbb{C}^d$.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MOFA: Modular Factorial Design for Hyperparameter Optimization. (arXiv:2011.09545v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiong_B/0/1/0/all/0/1">Bo Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yimin Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_H/0/1/0/all/0/1">Hanrong Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Staab_S/0/1/0/all/0/1">Steffen Staab</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Zhenguo Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.09545">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a novel and lightweight hyperparameter optimization (HPO)
method, MOdular FActorial Design (MOFA). MOFA pursues several rounds of HPO,
where each round alternates between exploration of hyperparameter space by
factorial design and exploitation of evaluation results by factorial analysis.
Each round first explores the configuration space by constructing a
low-discrepancy set of hyperparameters that cover this space well while
de-correlating hyperparameters, and then exploits evaluation results through
factorial analysis that determines which hyperparameters should be further
explored and which should become fixed in the next round. We prove that the
inference of MOFA achieves higher confidence than other sampling schemes. Each
individual round is highly parallelizable and hence offers major improvements
of efficiency compared to model-based methods. Empirical results show that MOFA
achieves better effectiveness and efficiency compared with state-of-the-art
methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Electrocardiogram synthesis. (arXiv:2103.00006v2 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Jo_Y/0/1/0/all/0/1">Yong-Yeon Jo</a>, <a href="http://arxiv.org/find/eess/1/au:+Kwon_J/0/1/0/all/0/1">Joon-Myoung Kwon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00006">
                                    <div class="article-summary-box-inner">
                                        <span>The electrocardiogram (ECG) records electrical signals in a non-invasive way
to observe the condition of the heart, typically looking at the heart from 12
different directions. Several types of the cardiac disease are diagnosed by
using 12-lead ECGs Recently, various wearable devices have enabled immediate
access to the ECG without the use of wieldy equipment. However, they only
provide ECGs with a couple of leads. This results in an inaccurate diagnosis of
cardiac disease due to lacking of required leads. We propose a deep generative
model for ECG synthesis from two asynchronous leads to ten leads. It first
represents a heart condition referring to two leads, and then generates ten
leads based on the represented heart condition. Both the rhythm and amplitude
of leads generated resemble those of the original ones, while the technique
removes noise and the baseline wander appearing in the original leads. As a
data augmentation method, our model improves the classification performance of
models compared with models using ECGs with only one or two leads.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fast Minimum-norm Adversarial Attacks through Adaptive Norm Constraints. (arXiv:2102.12827v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1">Maura Pintor</a>, <a href="http://arxiv.org/find/cs/1/au:+Roli_F/0/1/0/all/0/1">Fabio Roli</a>, <a href="http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1">Wieland Brendel</a>, <a href="http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1">Battista Biggio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12827">
                                    <div class="article-summary-box-inner">
                                        <span>Evaluating adversarial robustness amounts to finding the minimum perturbation
needed to have an input sample misclassified. The inherent complexity of the
underlying optimization requires current gradient-based attacks to be carefully
tuned, initialized, and possibly executed for many computationally-demanding
iterations, even if specialized to a given perturbation model. In this work, we
overcome these limitations by proposing a fast minimum-norm (FMN) attack that
works with different $\ell_p$-norm perturbation models ($p&#x3D;0, 1, 2, \infty$),
is robust to hyperparameter choices, does not require adversarial starting
points, and converges within few lightweight steps. It works by iteratively
finding the sample misclassified with maximum confidence within an
$\ell_p$-norm constraint of size $\epsilon$, while adapting $\epsilon$ to
minimize the distance of the current sample to the decision boundary. Extensive
experiments show that FMN significantly outperforms existing attacks in terms
of convergence speed and computation time, while reporting comparable or even
smaller perturbation sizes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Truncated Log-concave Sampling with Reflective Hamiltonian Monte Carlo. (arXiv:2102.13068v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chalkis_A/0/1/0/all/0/1">Apostolos Chalkis</a>, <a href="http://arxiv.org/find/cs/1/au:+Fisikopoulos_V/0/1/0/all/0/1">Vissarion Fisikopoulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Papachristou_M/0/1/0/all/0/1">Marios Papachristou</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsigaridas_E/0/1/0/all/0/1">Elias Tsigaridas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13068">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce Reflective Hamiltonian Monte Carlo (ReHMC), an HMC-based
algorithm, to sample from a log-concave distribution restricted to a convex
body. We prove that, starting from a warm start, the walk mixes to a
log-concave target distribution $\pi(x) \propto e^{-f(x)}$, where $f$ is
$L$-smooth and $m$-strongly-convex, within accuracy $\varepsilon$ after
$\widetilde O(\kappa d^2 \ell^2 \log (1 / \varepsilon))$ steps for a
well-rounded convex body where $\kappa &#x3D; L / m$ is the condition number of the
negative log-density, $d$ is the dimension, $\ell$ is an upper bound on the
number of reflections, and $\varepsilon$ is the accuracy parameter. We also
developed an efficient open source implementation of ReHMC and we performed an
experimental study on various high-dimensional data-sets. The experiments
suggest that ReHMC outperfroms Hit-and-Run and Coordinate-Hit-and-Run regarding
the time it needs to produce an independent sample and introduces practical
truncated sampling in thousands of dimensions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-Learning an Inference Algorithm for Probabilistic Programs. (arXiv:2103.00737v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Che_G/0/1/0/all/0/1">Gwonsoo Che</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongseok Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00737">
                                    <div class="article-summary-box-inner">
                                        <span>We present a meta-algorithm for learning a posterior-inference algorithm for
restricted probabilistic programs. Our meta-algorithm takes a training set of
probabilistic programs that describe models with observations, and attempts to
learn an efficient method for inferring the posterior of a similar program. A
key feature of our approach is the use of what we call a white-box inference
algorithm that extracts information directly from model descriptions
themselves, given as programs. Concretely, our white-box inference algorithm is
equipped with multiple neural networks, one for each type of atomic command,
and computes an approximate posterior of a given probabilistic program by
analysing individual atomic commands in the program using these networks. The
parameters of these networks are then learnt from a training set by our
meta-algorithm. We empirically demonstrate that the learnt inference algorithm
generalises well to unseen programs in terms of both interpolation and
extrapolation, and report cases where our approach may be preferable to a
state-of-the-art inference algorithm such as HMC. The overall results show the
promise as well as remaining challenges of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning from the Worst: Dynamically Generated Datasets to Improve Online Hate Detection. (arXiv:2012.15761v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vidgen_B/0/1/0/all/0/1">Bertie Vidgen</a>, <a href="http://arxiv.org/find/cs/1/au:+Thrush_T/0/1/0/all/0/1">Tristan Thrush</a>, <a href="http://arxiv.org/find/cs/1/au:+Waseem_Z/0/1/0/all/0/1">Zeerak Waseem</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15761">
                                    <div class="article-summary-box-inner">
                                        <span>We present a human-and-model-in-the-loop process for dynamically generating
datasets and training better performing and more robust hate detection models.
We provide a new dataset of ~40,000 entries, generated and labelled by trained
annotators over four rounds of dynamic data creation. It includes ~15,000
challenging perturbations and each hateful entry has fine-grained labels for
the type and target of hate. Hateful entries make up 54% of the dataset, which
is substantially higher than comparable datasets. We show that model
performance is substantially improved using this approach. Models trained on
later rounds of data collection perform better on test sets and are harder for
annotators to trick. They also perform better on HateCheck, a suite of
functional tests for online hate detection. We provide the code, dataset and
annotation guidelines for other researchers to use. Accepted at ACL 2021.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Self-Supervised Representation Ensembles for COVID-19 Cough Classification. (arXiv:2105.07566v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1">Hao Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Salim_F/0/1/0/all/0/1">Flora D. Salim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07566">
                                    <div class="article-summary-box-inner">
                                        <span>The usage of smartphone-collected respiratory sound, trained with deep
learning models, for detecting and classifying COVID-19 becomes popular
recently. It removes the need for in-person testing procedures especially for
rural regions where related medical supplies, experienced workers, and
equipment are limited. However, existing sound-based diagnostic approaches are
trained in a fully supervised manner, which requires large scale well-labelled
data. It is critical to discover new methods to leverage unlabelled respiratory
data, which can be obtained more easily. In this paper, we propose a novel
self-supervised learning enabled framework for COVID-19 cough classification. A
contrastive pre-training phase is introduced to train a Transformer-based
feature encoder with unlabelled data. Specifically, we design a random masking
mechanism to learn robust representations of respiratory sounds. The
pre-trained feature encoder is then fine-tuned in the downstream phase to
perform cough classification. In addition, different ensembles with varied
random masking rates are also explored in the downstream phase. Through
extensive evaluations, we demonstrate that the proposed contrastive
pre-training, the random masking mechanism, and the ensemble architecture
contribute to improving cough classification performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Modeling Fine-Grained Entity Types with Box Embeddings. (arXiv:2101.00345v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Onoe_Y/0/1/0/all/0/1">Yasumasa Onoe</a>, <a href="http://arxiv.org/find/cs/1/au:+Boratko_M/0/1/0/all/0/1">Michael Boratko</a>, <a href="http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1">Andrew McCallum</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrett_G/0/1/0/all/0/1">Greg Durrett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00345">
                                    <div class="article-summary-box-inner">
                                        <span>Neural entity typing models typically represent fine-grained entity types as
vectors in a high-dimensional space, but such spaces are not well-suited to
modeling these types&#x27; complex interdependencies. We study the ability of box
embeddings, which embed concepts as d-dimensional hyperrectangles, to capture
hierarchies of types even when these relationships are not defined explicitly
in the ontology. Our model represents both types and entity mentions as boxes.
Each mention and its context are fed into a BERT-based model to embed that
mention in our box space; essentially, this model leverages typological clues
present in the surface text to hypothesize a type representation for the
mention. Box containment can then be used to derive both the posterior
probability of a mention exhibiting a given type and the conditional
probability relations between types themselves. We compare our approach with a
vector-based typing model and observe state-of-the-art performance on several
entity typing benchmarks. In addition to competitive typing performance, our
box-based model shows better performance in prediction consistency (predicting
a supertype and a subtype together) and confidence (i.e., calibration),
demonstrating that the box-based model captures the latent type hierarchies
better than the vector-based model does.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Tutorial on Sparse Gaussian Processes and Variational Inference. (arXiv:2012.13962v9 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leibfried_F/0/1/0/all/0/1">Felix Leibfried</a>, <a href="http://arxiv.org/find/cs/1/au:+Dutordoir_V/0/1/0/all/0/1">Vincent Dutordoir</a>, <a href="http://arxiv.org/find/cs/1/au:+John_S/0/1/0/all/0/1">ST John</a>, <a href="http://arxiv.org/find/cs/1/au:+Durrande_N/0/1/0/all/0/1">Nicolas Durrande</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.13962">
                                    <div class="article-summary-box-inner">
                                        <span>Gaussian processes (GPs) provide a framework for Bayesian inference that can
offer principled uncertainty estimates for a large range of problems. For
example, if we consider regression problems with Gaussian likelihoods, a GP
model enjoys a posterior in closed form. However, identifying the posterior GP
scales cubically with the number of training examples and requires to store all
examples in memory. In order to overcome these obstacles, sparse GPs have been
proposed that approximate the true posterior GP with pseudo-training examples.
Importantly, the number of pseudo-training examples is user-defined and enables
control over computational and memory complexity. In the general case, sparse
GPs do not enjoy closed-form solutions and one has to resort to approximate
inference. In this context, a convenient choice for approximate inference is
variational inference (VI), where the problem of Bayesian inference is cast as
an optimization problem -- namely, to maximize a lower bound of the log
marginal likelihood. This paves the way for a powerful and versatile framework,
where pseudo-training examples are treated as optimization arguments of the
approximate posterior that are jointly identified together with hyperparameters
of the generative model (i.e. prior and likelihood). The framework can
naturally handle a wide scope of supervised learning problems, ranging from
regression with heteroscedastic and non-Gaussian likelihoods to classification
problems with discrete labels, but also multilabel problems. The purpose of
this tutorial is to provide access to the basic matter for readers without
prior knowledge in both GPs and VI. A proper exposition to the subject enables
also access to more recent advances (like importance-weighted VI as well as
interdomain, multioutput and deep GPs) that can serve as an inspiration for new
research ideas.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RetCL: A Selection-based Approach for Retrosynthesis via Contrastive Learning. (arXiv:2105.00795v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Hankook Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1">Sungsoo Ahn</a>, <a href="http://arxiv.org/find/cs/1/au:+Seo_S/0/1/0/all/0/1">Seung-Woo Seo</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">You Young Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eunho Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung-Ju Hwang</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1">Jinwoo Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00795">
                                    <div class="article-summary-box-inner">
                                        <span>Retrosynthesis, of which the goal is to find a set of reactants for
synthesizing a target product, is an emerging research area of deep learning.
While the existing approaches have shown promising results, they currently lack
the ability to consider availability (e.g., stability or purchasability) of the
reactants or generalize to unseen reaction templates (i.e., chemical reaction
rules). In this paper, we propose a new approach that mitigates the issues by
reformulating retrosynthesis into a selection problem of reactants from a
candidate set of commercially available molecules. To this end, we design an
efficient reactant selection framework, named RetCL (retrosynthesis via
contrastive learning), for enumerating all of the candidate molecules based on
selection scores computed by graph neural networks. For learning the score
functions, we also propose a novel contrastive training scheme with hard
negative mining. Extensive experiments demonstrate the benefits of the proposed
selection-based approach. For example, when all 671k reactants in the USPTO
{database} are given as candidates, our RetCL achieves top-1 exact match
accuracy of $71.3\%$ for the USPTO-50k benchmark, while a recent
transformer-based approach achieves $59.6\%$. We also demonstrate that RetCL
generalizes well to unseen templates in various settings in contrast to
template-based approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning-based Robust Motion Planning with Guaranteed Stability: A Contraction Theory Approach. (arXiv:2102.12668v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tsukamoto_H/0/1/0/all/0/1">Hiroyasu Tsukamoto</a>, <a href="http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1">Soon-Jo Chung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.12668">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents Learning-based Autonomous Guidance with RObustness and
Stability guarantees (LAG-ROS), which provides machine learning-based nonlinear
motion planners with formal robustness and stability guarantees, by designing a
differential Lyapunov function using contraction theory. LAG-ROS utilizes a
neural network to model a robust tracking controller independently of a target
trajectory, for which we show that the Euclidean distance between the target
and controlled trajectories is exponentially bounded linearly in the learning
error, even under the existence of bounded external disturbances. We also
present a convex optimization approach that minimizes the steady-state bound of
the tracking error to construct the robust control law for neural network
training. In numerical simulations, it is demonstrated that the proposed method
indeed possesses superior properties of robustness and nonlinear stability
resulting from contraction theory, whilst retaining the computational
efficiency of existing learning-based motion planners.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Provably-Efficient Model-Free Algorithm for Constrained Markov Decision Processes. (arXiv:2106.01577v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wei_H/0/1/0/all/0/1">Honghao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1">Lei Ying</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01577">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the first {\em model-free}, {\em simulator-free}
reinforcement learning algorithm for Constrained Markov Decision Processes
(CMDPs) with sublinear regret and zero constraint violation. The algorithm is
named Triple-Q because it has three key components: a Q-function (also called
action-value function) for the cumulative reward, a Q-function for the
cumulative utility for the constraint, and a virtual-Queue that
(over)-estimates the cumulative constraint violation. Under Triple-Q, at each
step, an action is chosen based on the pseudo-Q-value that is a combination of
the three Q values. The algorithm updates the reward and utility Q-values with
learning rates that depend on the visit counts to the corresponding (state,
action) pairs and are periodically reset. In the episodic CMDP setting,
Triple-Q achieves $\tilde{\cal O}\left(\frac{1 }{\delta}H^4
S^{\frac{1}{2}}A^{\frac{1}{2}}K^{\frac{4}{5}} \right)$ regret, where $K$ is the
total number of episodes, $H$ is the number of steps in each episode, $S$ is
the number of states, $A$ is the number of actions, and $\delta$ is Slater&#x27;s
constant. Furthermore, Triple-Q guarantees zero constraint violation when $K$
is sufficiently large. Finally, the computational complexity of Triple-Q is
similar to SARSA for unconstrained MDPs and is computationally efficient.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Choose a Transformer: Fourier or Galerkin. (arXiv:2105.14995v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_S/0/1/0/all/0/1">Shuhao Cao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14995">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we apply the self-attention from the state-of-the-art
Transformer in Attention Is All You Need the first time to a data-driven
operator learning problem related to partial differential equations. We put
together an effort to explain the heuristics of, and improve the efficacy of
the self-attention by demonstrating that the softmax normalization in the
scaled dot-product attention is sufficient but not necessary, and have proved
the approximation capacity of a linear variant as a Petrov-Galerkin projection.
A new layer normalization scheme is proposed to allow a scaling to propagate
through attention layers, which helps the model achieve remarkable accuracy in
operator learning tasks with unnormalized data. Finally, we present three
operator learning experiments, including the viscid Burgers&#x27; equation, an
interface Darcy flow, and an inverse interface coefficient identification
problem. All experiments validate the improvements of the newly proposed simple
attention-based operator learner over their softmax-normalized counterparts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Randomized Exploration is Near-Optimal for Tabular MDP. (arXiv:2102.09703v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiong_Z/0/1/0/all/0/1">Zhihan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Shen_R/0/1/0/all/0/1">Ruoqi Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1">Simon S. Du</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.09703">
                                    <div class="article-summary-box-inner">
                                        <span>We study exploration using randomized value functions in Thompson Sampling
(TS)-like algorithms in reinforcement learning. This type of algorithms enjoys
appealing empirical performance. We show that when we use 1) a single random
seed in each episode, and 2) a Bernstein-type magnitude of noise, we obtain a
worst-case $\widetilde{O}\left(H\sqrt{SAT}\right)$ regret bound for episodic
time-inhomogeneous Markov Decision Process where $S$ is the size of state
space, $A$ is the size of action space, $H$ is the planning horizon and $T$ is
the number of interactions. This bound polynomially improves all existing
bounds for TS-like algorithms based on randomized value functions, and for the
first time, matches the $\Omega\left(H\sqrt{SAT}\right)$ lower bound up to
logarithmic factors. Our result highlights that randomized exploration can be
near-optimal, which was previously only achieved by optimistic algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Controllable Guarantees for Fair Outcomes via Contrastive Information Estimation. (arXiv:2101.04108v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gupta_U/0/1/0/all/0/1">Umang Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferber_A/0/1/0/all/0/1">Aaron M Ferber</a>, <a href="http://arxiv.org/find/cs/1/au:+Dilkina_B/0/1/0/all/0/1">Bistra Dilkina</a>, <a href="http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1">Greg Ver Steeg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.04108">
                                    <div class="article-summary-box-inner">
                                        <span>Controlling bias in training datasets is vital for ensuring equal treatment,
or parity, between different groups in downstream applications. A naive
solution is to transform the data so that it is statistically independent of
group membership, but this may throw away too much information when a
reasonable compromise between fairness and accuracy is desired. Another common
approach is to limit the ability of a particular adversary who seeks to
maximize parity. Unfortunately, representations produced by adversarial
approaches may still retain biases as their efficacy is tied to the complexity
of the adversary used during training. To this end, we theoretically establish
that by limiting the mutual information between representations and protected
attributes, we can assuredly control the parity of any downstream classifier.
We demonstrate an effective method for controlling parity through mutual
information based on contrastive information estimators and show that they
outperform approaches that rely on variational bounds based on complex
generative models. We test our approach on UCI Adult and Heritage Health
datasets and demonstrate that our approach provides more informative
representations across a range of desired parity thresholds while providing
strong theoretical guarantees on the parity of any downstream algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Calibration and Out-of-domain Generalization. (arXiv:2102.10395v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wald_Y/0/1/0/all/0/1">Yoav Wald</a>, <a href="http://arxiv.org/find/cs/1/au:+Feder_A/0/1/0/all/0/1">Amir Feder</a>, <a href="http://arxiv.org/find/cs/1/au:+Greenfeld_D/0/1/0/all/0/1">Daniel Greenfeld</a>, <a href="http://arxiv.org/find/cs/1/au:+Shalit_U/0/1/0/all/0/1">Uri Shalit</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.10395">
                                    <div class="article-summary-box-inner">
                                        <span>Out-of-domain (OOD) generalization is a significant challenge for machine
learning models. Many techniques have been proposed to overcome this challenge,
often focused on learning models with certain invariance properties. In this
work, we draw a link between OOD performance and model calibration, arguing
that calibration across multiple domains can be viewed as a special case of an
invariant representation leading to better OOD generalization. Specifically, we
show that under certain conditions, models which achieve \emph{multi-domain
calibration} are provably free of spurious correlations. This leads us to
propose multi-domain calibration as a measurable and trainable surrogate for
the OOD performance of a classifier. We therefore introduce methods that are
easy to apply and allow practitioners to improve multi-domain calibration by
training or modifying an existing model, leading to better performance on
unseen domains. Using five datasets from the recently proposed WILDS OOD
benchmark, as well as the Colored MNIST dataset, we demonstrate that training
or tuning models so they are calibrated across multiple domains leads to
significantly improved performance on unseen test domains. We believe this
intriguing connection between calibration and OOD generalization is promising
from both a practical and theoretical point of view.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PDPGD: Primal-Dual Proximal Gradient Descent Adversarial Attack. (arXiv:2106.01538v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Matyasko_A/0/1/0/all/0/1">Alexander Matyasko</a>, <a href="http://arxiv.org/find/cs/1/au:+Chau_L/0/1/0/all/0/1">Lap-Pui Chau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01538">
                                    <div class="article-summary-box-inner">
                                        <span>State-of-the-art deep neural networks are sensitive to small input
perturbations. Since the discovery of this intriguing vulnerability, many
defence methods have been proposed that attempt to improve robustness to
adversarial noise. Fast and accurate attacks are required to compare various
defence methods. However, evaluating adversarial robustness has proven to be
extremely challenging. Existing norm minimisation adversarial attacks require
thousands of iterations (e.g. Carlini &amp; Wagner attack), are limited to the
specific norms (e.g. Fast Adaptive Boundary), or produce sub-optimal results
(e.g. Brendel &amp; Bethge attack). On the other hand, PGD attack, which is fast,
general and accurate, ignores the norm minimisation penalty and solves a
simpler perturbation-constrained problem. In this work, we introduce a fast,
general and accurate adversarial attack that optimises the original non-convex
constrained minimisation problem. We interpret optimising the Lagrangian of the
adversarial attack optimisation problem as a two-player game: the first player
minimises the Lagrangian wrt the adversarial noise; the second player maximises
the Lagrangian wrt the regularisation penalty. Our attack algorithm
simultaneously optimises primal and dual variables to find the minimal
adversarial perturbation. In addition, for non-smooth $l_p$-norm minimisation,
such as $l_{\infty}$-, $l_1$-, and $l_0$-norms, we introduce primal-dual
proximal gradient descent attack. We show in the experiments that our attack
outperforms current state-of-the-art $l_{\infty}$-, $l_2$-, $l_1$-, and
$l_0$-attacks on MNIST, CIFAR-10 and Restricted ImageNet datasets against
unregularised and adversarially trained models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dompteur: Taming Audio Adversarial Examples. (arXiv:2102.05431v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eisenhofer_T/0/1/0/all/0/1">Thorsten Eisenhofer</a>, <a href="http://arxiv.org/find/cs/1/au:+Schonherr_L/0/1/0/all/0/1">Lea Sch&#xf6;nherr</a>, <a href="http://arxiv.org/find/cs/1/au:+Frank_J/0/1/0/all/0/1">Joel Frank</a>, <a href="http://arxiv.org/find/cs/1/au:+Speckemeier_L/0/1/0/all/0/1">Lars Speckemeier</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolossa_D/0/1/0/all/0/1">Dorothea Kolossa</a>, <a href="http://arxiv.org/find/cs/1/au:+Holz_T/0/1/0/all/0/1">Thorsten Holz</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05431">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial examples seem to be inevitable. These specifically crafted inputs
allow attackers to arbitrarily manipulate machine learning systems. Even worse,
they often seem harmless to human observers. In our digital society, this poses
a significant threat. For example, Automatic Speech Recognition (ASR) systems,
which serve as hands-free interfaces to many kinds of systems, can be attacked
with inputs incomprehensible for human listeners. The research community has
unsuccessfully tried several approaches to tackle this problem. In this paper
we propose a different perspective: We accept the presence of adversarial
examples against ASR systems, but we require them to be perceivable by human
listeners. By applying the principles of psychoacoustics, we can remove
semantically irrelevant information from the ASR input and train a model that
resembles human perception more closely. We implement our idea in a tool named
DOMPTEUR and demonstrate that our augmented system, in contrast to an
unmodified baseline, successfully focuses on perceptible ranges of the input
signal. This change forces adversarial examples into the audible range, while
using minimal computational overhead and preserving benign performance. To
evaluate our approach, we construct an adaptive attacker that actively tries to
avoid our augmentations and demonstrate that adversarial examples from this
attacker remain clearly perceivable. Finally, we substantiate our claims by
performing a hearing test with crowd-sourced human listeners.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Early Abandoning and Pruning for Elastic Distances including Dynamic Time Warping. (arXiv:2102.05221v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Herrmann_M/0/1/0/all/0/1">Matthieu Herrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1">Geoffrey I. Webb</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.05221">
                                    <div class="article-summary-box-inner">
                                        <span>Nearest neighbor search under elastic distances is a key tool for time series
analysis, supporting many applications. However, straightforward
implementations of distances require $O(n^2)$ space and time complexities,
preventing these applications from scaling to long series. Much work has been
devoted to speeding up the NN search process, mostly with the development of
lower bounds, allowing to avoid costly distance computations when a given
threshold is exceeded. This threshold, provided by the similarity search
process, also allows to early abandon the computation of a distance itself.
Another approach, is to prune parts of the computation. All these techniques
are othogonal to each other. In this work, we develop a new generic strategy,
&quot;EAPruned&quot;, that tightly integrates pruning with early abandoning. We apply it
to six elastic distance measures: DTW, CDTW, WDTW, ERP, MSM and TWE, showing
substantial speedup in NN search applications. Pruning alone also shows
substantial speedup for some distances, benefiting applications beyond the
scope of NN search (e.g. requiring all pairwise distances), and hence where
early abandoning is not applicable. We~release our implementation as part of a
new C++ library for time series classification, along with easy to use
Python/Numpy bindings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Tiny CNN Architecture for Medical Face Mask Detection for Resource-Constrained Endpoints. (arXiv:2011.14858v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mohan_P/0/1/0/all/0/1">Puranjay Mohan</a>, <a href="http://arxiv.org/find/cs/1/au:+Paul_A/0/1/0/all/0/1">Aditya Jyoti Paul</a>, <a href="http://arxiv.org/find/cs/1/au:+Chirania_A/0/1/0/all/0/1">Abhay Chirania</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.14858">
                                    <div class="article-summary-box-inner">
                                        <span>The world is going through one of the most dangerous pandemics of all time
with the rapid spread of the novel coronavirus (COVID-19). According to the
World Health Organisation, the most effective way to thwart the transmission of
coronavirus is to wear medical face masks. Monitoring the use of face masks in
public places has been a challenge because manual monitoring could be unsafe.
This paper proposes an architecture for detecting medical face masks for
deployment on resource-constrained endpoints having extremely low memory
footprints. A small development board with an ARM Cortex-M7 microcontroller
clocked at 480 Mhz and having just 496 KB of framebuffer RAM, has been used for
the deployment of the model. Using the TensorFlow Lite framework, the model is
quantized to further reduce its size. The proposed model is 138 KB post
quantization and runs at the inference speed of 30 FPS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory AMP. (arXiv:2012.10861v3 [cs.IT] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Shunqi Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kurkoski_B/0/1/0/all/0/1">Brian M. Kurkoski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.10861">
                                    <div class="article-summary-box-inner">
                                        <span>Approximate message passing (AMP) is a low-cost iterative
parameter-estimation technique for certain high-dimensional linear systems with
non-Gaussian distributions. However, AMP only applies to independent
identically distributed (IID) transform matrices, but may become unreliable
(e.g. perform poorly or even diverge) for other matrix ensembles, especially
for ill-conditioned ones. To handle this difficulty, orthogonal/vector AMP
(OAMP/VAMP) was proposed for general right-unitarily-invariant matrices.
However, the Bayes-optimal OAMP/VAMP requires high-complexity linear minimum
mean square error (MMSE) estimator. This limits the application of OAMP/VAMP to
large-scale systems.

To solve the disadvantages of AMP and OAMP/VAMP, this paper proposes a memory
AMP (MAMP), in which a long-memory matched filter is proposed for interference
suppression. The complexity of MAMP is comparable to AMP. The asymptotic
Gaussianity of estimation errors in MAMP is guaranteed by the orthogonality
principle. A state evolution is derived to asymptotically characterize the
performance of MAMP. Based on state evolution, the relaxation parameters and
damping vector in MAMP are optimized. For all right-unitarily-invariant
matrices, the optimized MAMP converges to the high-complexity OAMP/VAMP, and
thus is Bayes-optimal if it has a unique fixed point. Finally, simulations are
provided to verify the validity and accuracy of the theoretical results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph convolutions that can finally model local structure. (arXiv:2011.15069v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Brossard_R/0/1/0/all/0/1">R&#xe9;my Brossard</a>, <a href="http://arxiv.org/find/cs/1/au:+Frigo_O/0/1/0/all/0/1">Oriel Frigo</a>, <a href="http://arxiv.org/find/cs/1/au:+Dehaene_D/0/1/0/all/0/1">David Dehaene</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.15069">
                                    <div class="article-summary-box-inner">
                                        <span>Despite quick progress in the last few years, recent studies have shown that
modern graph neural networks can still fail at very simple tasks, like
detecting small cycles. This hints at the fact that current networks fail to
catch information about the local structure, which is problematic if the
downstream task heavily relies on graph substructure analysis, as in the
context of chemistry. We propose a very simple correction to the now standard
GIN convolution that enables the network to detect small cycles with nearly no
cost in terms of computation time and number of parameters. Tested on real life
molecule property datasets, our model consistently improves performance on
large multi-tasked datasets over all baselines, both globally and on a per-task
setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Simultaneous Corn and Soybean Yield Prediction from Remote Sensing Data Using Deep Transfer Learning. (arXiv:2012.03129v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khaki_S/0/1/0/all/0/1">Saeed Khaki</a>, <a href="http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1">Hieu Pham</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lizhi Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.03129">
                                    <div class="article-summary-box-inner">
                                        <span>Large-scale crop yield estimation is, in part, made possible due to the
availability of remote sensing data allowing for the continuous monitoring of
crops throughout their growth cycle. Having this information allows
stakeholders the ability to make real-time decisions to maximize yield
potential. Although various models exist that predict yield from remote sensing
data, there currently does not exist an approach that can estimate yield for
multiple crops simultaneously, and thus leads to more accurate predictions. A
model that predicts the yield of multiple crops and concurrently considers the
interaction between multiple crop yields. We propose a new convolutional neural
network model called YieldNet which utilizes a novel deep learning framework
that uses transfer learning between corn and soybean yield predictions by
sharing the weights of the backbone feature extractor. Additionally, to
consider the multi-target response variable, we propose a new loss function. We
conduct our experiment using data from 1,132 counties for corn and 1,076
counties for soybean across the United States. Numerical results demonstrate
that our proposed method accurately predicts corn and soybean yield from one to
four months before the harvest with a MAE being 8.74% and 8.70% of the average
yield, respectively, and is competitive to other state-of-the-art approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-UAV Path Planning for Wireless Data Harvesting with Deep Reinforcement Learning. (arXiv:2010.12461v3 [cs.MA] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bayerlein_H/0/1/0/all/0/1">Harald Bayerlein</a>, <a href="http://arxiv.org/find/cs/1/au:+Theile_M/0/1/0/all/0/1">Mirco Theile</a>, <a href="http://arxiv.org/find/cs/1/au:+Caccamo_M/0/1/0/all/0/1">Marco Caccamo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gesbert_D/0/1/0/all/0/1">David Gesbert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12461">
                                    <div class="article-summary-box-inner">
                                        <span>Harvesting data from distributed Internet of Things (IoT) devices with
multiple autonomous unmanned aerial vehicles (UAVs) is a challenging problem
requiring flexible path planning methods. We propose a multi-agent
reinforcement learning (MARL) approach that, in contrast to previous work, can
adapt to profound changes in the scenario parameters defining the data
harvesting mission, such as the number of deployed UAVs, number, position and
data amount of IoT devices, or the maximum flying time, without the need to
perform expensive recomputations or relearn control policies. We formulate the
path planning problem for a cooperative, non-communicating, and homogeneous
team of UAVs tasked with maximizing collected data from distributed IoT sensor
nodes subject to flying time and collision avoidance constraints. The path
planning problem is translated into a decentralized partially observable Markov
decision process (Dec-POMDP), which we solve through a deep reinforcement
learning (DRL) approach, approximating the optimal UAV control policy without
prior knowledge of the challenging wireless channel characteristics in dense
urban environments. By exploiting a combination of centered global and local
map representations of the environment that are fed into convolutional layers
of the agents, we show that our proposed network architecture enables the
agents to cooperate effectively by carefully dividing the data collection task
among themselves, adapt to large complex environments and state spaces, and
make movement decisions that balance data collection goals, flight-time
efficiency, and navigation constraints. Finally, learning a control policy that
generalizes over the scenario parameter space enables us to analyze the
influence of individual parameters on collection performance and provide some
intuition about system-level benefits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning. (arXiv:2011.04820v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuijing Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_P/0/1/0/all/0/1">Peixin Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1">Weihang Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakraborty_N/0/1/0/all/0/1">Neeloy Chakraborty</a>, <a href="http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1">Katherine Driggs-Campbell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04820">
                                    <div class="article-summary-box-inner">
                                        <span>Safe and efficient navigation through human crowds is an essential capability
for mobile robots. Previous work on robot crowd navigation assumes that the
dynamics of all agents are known and well-defined. In addition, the performance
of previous methods deteriorates in partially observable environments and
environments with dense crowds. To tackle these problems, we propose
decentralized structural-Recurrent Neural Network (DS-RNN), a novel network
that reasons about spatial and temporal relationships for robot decision making
in crowd navigation. We train our network with model-free deep reinforcement
learning without any expert supervision. We demonstrate that our model
outperforms previous methods in challenging crowd navigation scenarios. We
successfully transfer the policy learned in the simulator to a real-world
TurtleBot 2i.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Constraint-Based Algorithm for the Structural Learning of Continuous-Time Bayesian Networks. (arXiv:2007.03248v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bregoli_A/0/1/0/all/0/1">Alessandro Bregoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Scutari_M/0/1/0/all/0/1">Marco Scutari</a>, <a href="http://arxiv.org/find/cs/1/au:+Stella_F/0/1/0/all/0/1">Fabio Stella</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.03248">
                                    <div class="article-summary-box-inner">
                                        <span>Dynamic Bayesian networks have been well explored in the literature as
discrete-time models: however, their continuous-time extensions have seen
comparatively little attention. In this paper, we propose the first
constraint-based algorithm for learning the structure of continuous-time
Bayesian networks. We discuss the different statistical tests and the
underlying hypotheses used by our proposal to establish conditional
independence. Furthermore, we analyze and discuss the computational complexity
of the best and worst cases for the proposed algorithm. Finally, we validate
its performance using synthetic data, and we discuss its strengths and
limitations comparing it with the score-based structure learning algorithm from
Nodelman et al. (2003). We find the latter to be more accurate in learning
networks with binary variables, while our constraint-based approach is more
accurate with variables assuming more than two values. Numerical experiments
confirm that score-based and constraint-based algorithms are comparable in
terms of computation time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-Window Data Augmentation Approach for Speech Emotion Recognition. (arXiv:2010.09895v3 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Padi_S/0/1/0/all/0/1">Sarala Padi</a>, <a href="http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1">Dinesh Manocha</a>, <a href="http://arxiv.org/find/cs/1/au:+Sriram_R/0/1/0/all/0/1">Ram D.Sriram</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09895">
                                    <div class="article-summary-box-inner">
                                        <span>We present a Multi-Window Data Augmentation (MWA-SER) approach for speech
emotion recognition. MWA-SER is a unimodal approach that focuses on two key
concepts; designing the speech augmentation method and building the deep
learning model to recognize the underlying emotion of an audio signal. Our
proposed multi-window augmentation approach generates additional data samples
from the speech signal by employing multiple window sizes in the audio feature
extraction process. We show that our augmentation method, combined with a deep
learning model, improves speech emotion recognition performance. We evaluate
the performance of our approach on three benchmark datasets: IEMOCAP, SAVEE,
and RAVDESS. We show that the multi-window model improves the SER performance
and outperforms a single-window model. The notion of finding the best window
size is an essential step in audio feature extraction. We perform extensive
experimental evaluations to find the best window choice and explore the
windowing effect for SER analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient Boosted Binary Histogram Ensemble for Large-scale Regression. (arXiv:2106.01986v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Hang_H/0/1/0/all/0/1">Hanyuan Hang</a>, <a href="http://arxiv.org/find/stat/1/au:+Huang_T/0/1/0/all/0/1">Tao Huang</a>, <a href="http://arxiv.org/find/stat/1/au:+Cai_Y/0/1/0/all/0/1">Yuchao Cai</a>, <a href="http://arxiv.org/find/stat/1/au:+Yang_H/0/1/0/all/0/1">Hanfang Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1">Zhouchen Lin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01986">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a gradient boosting algorithm for large-scale
regression problems called \textit{Gradient Boosted Binary Histogram Ensemble}
(GBBHE) based on binary histogram partition and ensemble learning. From the
theoretical perspective, by assuming the H\&quot;{o}lder continuity of the target
function, we establish the statistical convergence rate of GBBHE in the space
$C^{0,\alpha}$ and $C^{1,0}$, where a lower bound of the convergence rate for
the base learner demonstrates the advantage of boosting. Moreover, in the space
$C^{1,0}$, we prove that the number of iterations to achieve the fast
convergence rate can be reduced by using ensemble regressor as the base
learner, which improves the computational efficiency. In the experiments,
compared with other state-of-the-art algorithms such as gradient boosted
regression tree (GBRT), Breiman&#x27;s forest, and kernel-based methods, our GBBHE
algorithm shows promising performance with less running time on large-scale
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gender Bias in Depression Detection Using Audio Features. (arXiv:2010.15120v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bailey_A/0/1/0/all/0/1">Andrew Bailey</a>, <a href="http://arxiv.org/find/cs/1/au:+Plumbley_M/0/1/0/all/0/1">Mark D. Plumbley</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15120">
                                    <div class="article-summary-box-inner">
                                        <span>Depression is a large-scale mental health problem and a challenging area for
machine learning researchers in detection of depression. Datasets such as
Distress Analysis Interview Corpus - Wizard of Oz (DAIC-WOZ) have been created
to aid research in this area. However, on top of the challenges inherent in
accurately detecting depression, biases in datasets may result in skewed
classification performance. In this paper we examine gender bias in the
DAIC-WOZ dataset. We show that gender biases in DAIC-WOZ can lead to an
overreporting of performance. By different concepts from Fair Machine Learning,
such as data re-distribution, and using raw audio features, we can mitigate
against the harmful effects of bias.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DynamicViT: Efficient Vision Transformers with Dynamic Token Sparsification. (arXiv:2106.02034v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rao_Y/0/1/0/all/0/1">Yongming Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1">Wenliang Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Benlin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jiwen Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jie Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02034">
                                    <div class="article-summary-box-inner">
                                        <span>Attention is sparse in vision transformers. We observe the final prediction
in vision transformers is only based on a subset of most informative tokens,
which is sufficient for accurate image recognition. Based on this observation,
we propose a dynamic token sparsification framework to prune redundant tokens
progressively and dynamically based on the input. Specifically, we devise a
lightweight prediction module to estimate the importance score of each token
given the current features. The module is added to different layers to prune
redundant tokens hierarchically. To optimize the prediction module in an
end-to-end manner, we propose an attention masking strategy to differentiably
prune a token by blocking its interactions with other tokens. Benefiting from
the nature of self-attention, the unstructured sparse tokens are still hardware
friendly, which makes our framework easy to achieve actual speed-up. By
hierarchically pruning 66% of the input tokens, our method greatly reduces
31%~37% FLOPs and improves the throughput by over 40% while the drop of
accuracy is within 0.5% for various vision transformers. Equipped with the
dynamic token sparsification framework, DynamicViT models can achieve very
competitive complexity/accuracy trade-offs compared to state-of-the-art CNNs
and vision transformers on ImageNet. Code is available at
https://github.com/raoyongming/DynamicViT</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages. (arXiv:2010.09322v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Diwan_A/0/1/0/all/0/1">Anuj Diwan</a>, <a href="http://arxiv.org/find/eess/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09322">
                                    <div class="article-summary-box-inner">
                                        <span>This work presents a seemingly simple but effective technique to improve
low-resource ASR systems for phonetic languages. By identifying sets of
acoustically similar graphemes in these languages, we first reduce the output
alphabet of the ASR system using linguistically meaningful reductions and then
reconstruct the original alphabet using a standalone module. We demonstrate
that this lessens the burden and improves the performance of low-resource
end-to-end ASR systems (because only reduced-alphabet predictions are needed)
and that it is possible to design a very simple but effective reconstruction
module that recovers sequences in the original alphabet from sequences in the
reduced alphabet. We present a finite state transducer-based reconstruction
module that operates on the 1-best ASR hypothesis in the reduced alphabet. We
demonstrate the efficacy of our proposed technique using ASR systems for two
Indian languages, Gujarati and Telugu. With access to only 10 hrs of speech
data, we obtain relative WER reductions of up to 7% compared to systems that do
not use any reduction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameterizing Branch-and-Bound Search Trees to Learn Branching Policies. (arXiv:2002.05120v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zarpellon_G/0/1/0/all/0/1">Giulia Zarpellon</a>, <a href="http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1">Jason Jo</a>, <a href="http://arxiv.org/find/cs/1/au:+Lodi_A/0/1/0/all/0/1">Andrea Lodi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.05120">
                                    <div class="article-summary-box-inner">
                                        <span>Branch and Bound (B&amp;B) is the exact tree search method typically used to
solve Mixed-Integer Linear Programming problems (MILPs). Learning branching
policies for MILP has become an active research area, with most works proposing
to imitate the strong branching rule and specialize it to distinct classes of
problems. We aim instead at learning a policy that generalizes across
heterogeneous MILPs: our main hypothesis is that parameterizing the state of
the B&amp;B search tree can aid this type of generalization. We propose a novel
imitation learning framework, and introduce new input features and
architectures to represent branching. Experiments on MILP benchmark instances
clearly show the advantages of incorporating an explicit parameterization of
the state of the search tree to modulate the branching decisions, in terms of
both higher accuracy and smaller B&amp;B trees. The resulting policies
significantly outperform the current state-of-the-art method for &quot;learning to
branch&quot; by effectively allowing generalization to generic unseen instances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonconvex Low-Rank Tensor Completion from Noisy Data. (arXiv:1911.04436v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cai_C/0/1/0/all/0/1">Changxiao Cai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Gen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1">H. Vincent Poor</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuxin Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.04436">
                                    <div class="article-summary-box-inner">
                                        <span>We study a noisy tensor completion problem of broad practical interest,
namely, the reconstruction of a low-rank tensor from highly incomplete and
randomly corrupted observations of its entries. While a variety of prior work
has been dedicated to this problem, prior algorithms either are computationally
too expensive for large-scale applications, or come with sub-optimal
statistical guarantees. Focusing on &quot;incoherent&quot; and well-conditioned tensors
of a constant CP rank, we propose a two-stage nonconvex algorithm -- (vanilla)
gradient descent following a rough initialization -- that achieves the best of
both worlds. Specifically, the proposed nonconvex algorithm faithfully
completes the tensor and retrieves all individual tensor factors within nearly
linear time, while at the same time enjoying near-optimal statistical
guarantees (i.e. minimal sample complexity and optimal estimation accuracy).
The estimation errors are evenly spread out across all entries, thus achieving
optimal $\ell_{\infty}$ statistical accuracy. We have also discussed how to
extend our approach to accommodate asymmetric tensors. The insight conveyed
through our analysis of nonconvex optimization might have implications for
other tensor estimation problems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BraggNN: Fast X-ray Bragg Peak Analysis Using Deep Learning. (arXiv:2008.08198v2 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Liu_Z/0/1/0/all/0/1">Zhengchun Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Sharma_H/0/1/0/all/0/1">Hemant Sharma</a>, <a href="http://arxiv.org/find/eess/1/au:+Park_J/0/1/0/all/0/1">Jun-Sang Park</a>, <a href="http://arxiv.org/find/eess/1/au:+Kenesei_P/0/1/0/all/0/1">Peter Kenesei</a>, <a href="http://arxiv.org/find/eess/1/au:+Miceli_A/0/1/0/all/0/1">Antonino Miceli</a>, <a href="http://arxiv.org/find/eess/1/au:+Almer_J/0/1/0/all/0/1">Jonathan Almer</a>, <a href="http://arxiv.org/find/eess/1/au:+Kettimuthu_R/0/1/0/all/0/1">Rajkumar Kettimuthu</a>, <a href="http://arxiv.org/find/eess/1/au:+Foster_I/0/1/0/all/0/1">Ian Foster</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08198">
                                    <div class="article-summary-box-inner">
                                        <span>X-ray diffraction based microscopy techniques such as High Energy Diffraction
Microscopy rely on knowledge of the position of diffraction peaks with high
precision. These positions are typically computed by fitting the observed
intensities in area detector data to a theoretical peak shape such as
pseudo-Voigt. As experiments become more complex and detector technologies
evolve, the computational cost of such peak detection and shape fitting becomes
the biggest hurdle to the rapid analysis required for real-time feedback during
in-situ experiments. To this end, we propose BraggNN, a deep learning-based
method that can determine peak positions much more rapidly than conventional
pseudo-Voigt peak fitting. When applied to a test dataset, BraggNN gives errors
of less than 0.29 and 0.57 pixels, relative to the conventional method, for 75%
and 95% of the peaks, respectively. When applied to a real experimental
dataset, a 3D reconstruction that used peak positions computed by BraggNN
yields 15% better results on average as compared to a reconstruction obtained
using peak positions determined using conventional 2D pseudo-Voigt fitting.
Recent advances in deep learning method implementations and special-purpose
model inference accelerators allow BraggNN to deliver enormous performance
improvements relative to the conventional method, running, for example, more
than 200 times faster than a conventional method on a consumer-class GPU card
with out-of-the-box software.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic tree ensembles for regularized nonlinear regression. (arXiv:2002.03375v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+He_J/0/1/0/all/0/1">Jingyu He</a>, <a href="http://arxiv.org/find/stat/1/au:+Hahn_P/0/1/0/all/0/1">P. Richard Hahn</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.03375">
                                    <div class="article-summary-box-inner">
                                        <span>This paper develops a novel stochastic tree ensemble method for nonlinear
regression, which we refer to as XBART, short for Accelerated Bayesian Additive
Regression Trees. By combining regularization and stochastic search strategies
from Bayesian modeling with computationally efficient techniques from recursive
partitioning approaches, the new method attains state-of-the-art performance:
in many settings it is both faster and more accurate than the widely-used
XGBoost algorithm. Via careful simulation studies, we demonstrate that our new
approach provides accurate point-wise estimates of the mean function and does
so faster than popular alternatives, such as BART, XGBoost and neural networks
(using Keras). We also prove a number of basic theoretical results about the
new algorithm, including consistency of the single tree version of the model
and stationarity of the Markov chain produced by the ensemble version.
Furthermore, we demonstrate that initializing standard Bayesian additive
regression trees Markov chain Monte Carlo (MCMC) at XBART-fitted trees
considerably improves credible interval coverage and reduces total run-time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global Convergence of Multi-Agent Policy Gradient in Markov Potential Games. (arXiv:2106.01969v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Leonardos_S/0/1/0/all/0/1">Stefanos Leonardos</a>, <a href="http://arxiv.org/find/cs/1/au:+Overman_W/0/1/0/all/0/1">Will Overman</a>, <a href="http://arxiv.org/find/cs/1/au:+Panageas_I/0/1/0/all/0/1">Ioannis Panageas</a>, <a href="http://arxiv.org/find/cs/1/au:+Piliouras_G/0/1/0/all/0/1">Georgios Piliouras</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01969">
                                    <div class="article-summary-box-inner">
                                        <span>Potential games are arguably one of the most important and widely studied
classes of normal form games. They define the archetypal setting of multi-agent
coordination as all agent utilities are perfectly aligned with each other via a
common potential function. Can this intuitive framework be transplanted in the
setting of Markov Games? What are the similarities and differences between
multi-agent coordination with and without state dependence? We present a novel
definition of Markov Potential Games (MPG) that generalizes prior attempts at
capturing complex stateful multi-agent coordination. Counter-intuitively,
insights from normal-form potential games do not carry over as MPGs can consist
of settings where state-games can be zero-sum games. In the opposite direction,
Markov games where every state-game is a potential game are not necessarily
MPGs. Nevertheless, MPGs showcase standard desirable properties such as the
existence of deterministic Nash policies. In our main technical result, we
prove fast convergence of independent policy gradient to Nash policies by
adapting recent gradient dominance property arguments developed for single
agent MDPs to multi-agent learning settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Nonlinear Matrix Approximation with Radial Basis Function Components. (arXiv:2106.02018v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rebrova_E/0/1/0/all/0/1">Elizaveta Rebrova</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yu-Hang Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02018">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce and investigate matrix approximation by decomposition into a sum
of radial basis function (RBF) components. An RBF component is a generalization
of the outer product between a pair of vectors, where an RBF function replaces
the scalar multiplication between individual vector elements. Even though the
RBF functions are positive definite, the summation across components is not
restricted to convex combinations and allows us to compute the decomposition
for any real matrix that is not necessarily symmetric or positive definite. We
formulate the problem of seeking such a decomposition as an optimization
problem with a nonlinear and non-convex loss function. Several modern versions
of the gradient descent method, including their scalable stochastic
counterparts, are used to solve this problem. We provide extensive empirical
evidence of the effectiveness of the RBF decomposition and that of the
gradient-based fitting algorithm. While being conceptually motivated by
singular value decomposition (SVD), our proposed nonlinear counterpart
outperforms SVD by drastically reducing the memory required to approximate a
data matrix with the same $L_2$-error for a wide range of matrix types. For
example, it leads to 2 to 10 times memory save for Gaussian noise, graph
adjacency matrices, and kernel matrices. Moreover, this proximity-based
decomposition can offer additional interpretability in applications that
involve, e.g., capturing the inner low-dimensional structure of the data,
retaining graph connectivity structure, and preserving the acutance of images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Off-Policy Evaluation via Adaptive Weighting with Data from Contextual Bandits. (arXiv:2106.02029v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhan_R/0/1/0/all/0/1">Ruohan Zhan</a>, <a href="http://arxiv.org/find/stat/1/au:+Hadad_V/0/1/0/all/0/1">Vitor Hadad</a>, <a href="http://arxiv.org/find/stat/1/au:+Hirshberg_D/0/1/0/all/0/1">David A. Hirshberg</a>, <a href="http://arxiv.org/find/stat/1/au:+Athey_S/0/1/0/all/0/1">Susan Athey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02029">
                                    <div class="article-summary-box-inner">
                                        <span>It has become increasingly common for data to be collected adaptively, for
example using contextual bandits. Historical data of this type can be used to
evaluate other treatment assignment policies to guide future innovation or
experiments. However, policy evaluation is challenging if the target policy
differs from the one used to collect data, and popular estimators, including
doubly robust (DR) estimators, can be plagued by bias, excessive variance, or
both. In particular, when the pattern of treatment assignment in the collected
data looks little like the pattern generated by the policy to be evaluated, the
importance weights used in DR estimators explode, leading to excessive
variance.

In this paper, we improve the DR estimator by adaptively weighting
observations to control its variance. We show that a t-statistic based on our
improved estimator is asymptotically normal under certain conditions, allowing
us to form confidence intervals and test hypotheses. Using synthetic data and
public benchmarks, we provide empirical evidence for our estimator&#x27;s improved
accuracy and inferential properties relative to existing alternatives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Learning of KB Queries in Task-Oriented Dialogs. (arXiv:2005.00123v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Raghu_D/0/1/0/all/0/1">Dinesh Raghu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gupta_N/0/1/0/all/0/1">Nikhil Gupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Mausam/0/1/0/all/0/1">Mausam</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.00123">
                                    <div class="article-summary-box-inner">
                                        <span>Task-oriented dialog (TOD) systems often need to formulate knowledge base
(KB) queries corresponding to the user intent and use the query results to
generate system responses. Existing approaches require dialog datasets to
explicitly annotate these KB queries -- these annotations can be time
consuming, and expensive. In response, we define the novel problems of
predicting the KB query and training the dialog agent, without explicit KB
query annotation. For query prediction, we propose a reinforcement learning
(RL) baseline, which rewards the generation of those queries whose KB results
cover the entities mentioned in subsequent dialog. Further analysis reveals
that correlation among query attributes in KB can significantly confuse memory
augmented policy optimization (MAPO), an existing state of the art RL agent. To
address this, we improve the MAPO baseline with simple but important
modifications suited to our task. To train the full TOD system for our setting,
we propose a pipelined approach: it independently predicts when to make a KB
query (query position predictor), then predicts a KB query at the predicted
position (query predictor), and uses the results of predicted query in
subsequent dialog (next response predictor). Overall, our work proposes first
solutions to our novel problem, and our analysis highlights the research
challenges in training TOD systems without query annotation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exposing Backdoors in Robust Machine Learning Models. (arXiv:2003.00865v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Soremekun_E/0/1/0/all/0/1">Ezekiel Soremekun</a>, <a href="http://arxiv.org/find/cs/1/au:+Udeshi_S/0/1/0/all/0/1">Sakshi Udeshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chattopadhyay_S/0/1/0/all/0/1">Sudipta Chattopadhyay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.00865">
                                    <div class="article-summary-box-inner">
                                        <span>The introduction of robust optimisation has pushed the state-of-the-art in
defending against adversarial attacks. However, the behaviour of such
optimisation has not been studied in the light of a fundamentally different
class of attacks called backdoors. In this paper, we demonstrate that
adversarially robust models are susceptible to backdoor attacks. Subsequently,
we observe that backdoors are reflected in the feature representation of such
models. Then, this observation is leveraged to detect backdoor-infected models
via a detection technique called AEGIS. Specifically, AEGIS uses feature
clustering to effectively detect backdoor-infected robust Deep Neural Networks
(DNNs). In our evaluation of several visible and hidden backdoor triggers on
major classification tasks using CIFAR-10, MNIST and FMNIST datasets, AEGIS
effectively detects robust DNNs infected with backdoors. AEGIS detects a
backdoor-infected model with 91.6% accuracy, without any false positives.
Furthermore, AEGIS detects the targeted class in the backdoor-infected model
with a reasonably low (11.1%) false positive rate. Our investigation reveals
that salient features of adversarially robust DNNs break the stealthy nature of
backdoor attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Dataset and Baselines for Multilingual Reply Suggestion. (arXiv:2106.02017v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mozhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deb_B/0/1/0/all/0/1">Budhaditya Deb</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1">Guoqing Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Shokouhi_M/0/1/0/all/0/1">Milad Shokouhi</a>, <a href="http://arxiv.org/find/cs/1/au:+Awadallah_A/0/1/0/all/0/1">Ahmed Hassan Awadallah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02017">
                                    <div class="article-summary-box-inner">
                                        <span>Reply suggestion models help users process emails and chats faster. Previous
work only studies English reply suggestion. Instead, we present MRS, a
multilingual reply suggestion dataset with ten languages. MRS can be used to
compare two families of models: 1) retrieval models that select the reply from
a fixed set and 2) generation models that produce the reply from scratch.
Therefore, MRS complements existing cross-lingual generalization benchmarks
that focus on classification and sequence labeling tasks. We build a generation
model and a retrieval model as baselines for MRS. The two models have different
strengths in the monolingual setting, and they require different strategies to
generalize across languages. MRS is publicly available at
https://github.com/zhangmozhi/mrs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gaussian Processes on Hypergraphs. (arXiv:2106.01982v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Pinder_T/0/1/0/all/0/1">Thomas Pinder</a>, <a href="http://arxiv.org/find/stat/1/au:+Turnbull_K/0/1/0/all/0/1">Kathryn Turnbull</a>, <a href="http://arxiv.org/find/stat/1/au:+Nemeth_C/0/1/0/all/0/1">Christopher Nemeth</a>, <a href="http://arxiv.org/find/stat/1/au:+Leslie_D/0/1/0/all/0/1">David Leslie</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01982">
                                    <div class="article-summary-box-inner">
                                        <span>We derive a Matern Gaussian process (GP) on the vertices of a hypergraph.
This enables estimation of regression models of observed or latent values
associated with the vertices, in which the correlation and uncertainty
estimates are informed by the hypergraph structure. We further present a
framework for embedding the vertices of a hypergraph into a latent space using
the hypergraph GP. Finally, we provide a scheme for identifying a small number
of representative inducing vertices that enables scalable inference through
sparse GPs. We demonstrate the utility of our framework on three challenging
real-world problems that concern multi-class classification for the political
party affiliation of legislators on the basis of voting behaviour,
probabilistic matrix factorisation of movie reviews, and embedding a hypergraph
of animals into a low-dimensional latent space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gaussian Variational State Estimation for Nonlinear State-Space Models. (arXiv:2002.02620v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Courts_J/0/1/0/all/0/1">Jarrad Courts</a>, <a href="http://arxiv.org/find/stat/1/au:+Wills_A/0/1/0/all/0/1">Adrian Wills</a>, <a href="http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1">Thomas B. Sch&#xf6;n</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.02620">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, the problem of state estimation, in the context of both
filtering and smoothing, for nonlinear state-space models is considered. Due to
the nonlinear nature of the models, the state estimation problem is generally
intractable as it involves integrals of general nonlinear functions and the
filtered and smoothed state distributions lack closed-form solutions. As such,
it is common to approximate the state estimation problem. In this paper, we
develop an assumed Gaussian solution based on variational inference, which
offers the key advantage of a flexible, but principled, mechanism for
approximating the required distributions. Our main contribution lies in a new
formulation of the state estimation problem as an optimisation problem, which
can then be solved using standard optimisation routines that employ exact
first- and second-order derivatives. The resulting state estimation approach
involves a minimal number of assumptions and applies directly to nonlinear
systems with both Gaussian and non-Gaussian probabilistic models. The
performance of our approach is demonstrated on several examples; a challenging
scalar system, a model of a simple robotic system, and a target tracking
problem using a von Mises-Fisher distribution and outperforms alternative
assumed Gaussian approaches to state estimation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TorchIO: a Python library for efficient loading, preprocessing, augmentation and patch-based sampling of medical images in deep learning. (arXiv:2003.04696v4 [eess.IV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Perez_Garcia_F/0/1/0/all/0/1">Fernando P&#xe9;rez-Garc&#xed;a</a>, <a href="http://arxiv.org/find/eess/1/au:+Sparks_R/0/1/0/all/0/1">Rachel Sparks</a>, <a href="http://arxiv.org/find/eess/1/au:+Ourselin_S/0/1/0/all/0/1">S&#xe9;bastien Ourselin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.04696">
                                    <div class="article-summary-box-inner">
                                        <span>Processing of medical images such as MRI or CT presents unique challenges
compared to RGB images typically used in computer vision. These include a lack
of labels for large datasets, high computational costs, and metadata to
describe the physical properties of voxels. Data augmentation is used to
artificially increase the size of the training datasets. Training with image
patches decreases the need for computational power. Spatial metadata needs to
be carefully taken into account in order to ensure a correct alignment of
volumes.

We present TorchIO, an open-source Python library to enable efficient
loading, preprocessing, augmentation and patch-based sampling of medical images
for deep learning. TorchIO follows the style of PyTorch and integrates standard
medical image processing libraries to efficiently process images during
training of neural networks. TorchIO transforms can be composed, reproduced,
traced and extended. We provide multiple generic preprocessing and augmentation
operations as well as simulation of MRI-specific artifacts.

Source code, comprehensive tutorials and extensive documentation for TorchIO
can be found at https://github.com/fepegar/torchio. The package can be
installed from the Python Package Index running &#x27;pip install torchio&#x27;. It
includes a command-line interface which allows users to apply transforms to
image files without using Python. Additionally, we provide a graphical
interface within a TorchIO extension in 3D Slicer to visualize the effects of
transforms.

TorchIO was developed to help researchers standardize medical image
processing pipelines and allow them to focus on the deep learning experiments.
It encourages open science, as it supports reproducibility and is version
controlled so that the software can be cited precisely. Due to its modularity,
the library is compatible with other frameworks for deep learning with medical
images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reinforcement Learning as One Big Sequence Modeling Problem. (arXiv:2106.02039v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Janner_M/0/1/0/all/0/1">Michael Janner</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiyang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02039">
                                    <div class="article-summary-box-inner">
                                        <span>Reinforcement learning (RL) is typically concerned with estimating
single-step policies or single-step models, leveraging the Markov property to
factorize the problem in time. However, we can also view RL as a sequence
modeling problem, with the goal being to predict a sequence of actions that
leads to a sequence of high rewards. Viewed in this way, it is tempting to
consider whether powerful, high-capacity sequence prediction models that work
well in other domains, such as natural-language processing, can also provide
simple and effective solutions to the RL problem. To this end, we explore how
RL can be reframed as &quot;one big sequence modeling&quot; problem, using
state-of-the-art Transformer architectures to model distributions over
sequences of states, actions, and rewards. Addressing RL as a sequence modeling
problem significantly simplifies a range of design decisions: we no longer
require separate behavior policy constraints, as is common in prior work on
offline model-free RL, and we no longer require ensembles or other epistemic
uncertainty estimators, as is common in prior work on model-based RL. All of
these roles are filled by the same Transformer sequence model. In our
experiments, we demonstrate the flexibility of this approach across
long-horizon dynamics prediction, imitation learning, goal-conditioned RL, and
offline RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interactive Refinement of Cross-Lingual Word Embeddings. (arXiv:1911.03070v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yuan_M/0/1/0/all/0/1">Michelle Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1">Mozhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Durme_B/0/1/0/all/0/1">Benjamin Van Durme</a>, <a href="http://arxiv.org/find/cs/1/au:+Findlater_L/0/1/0/all/0/1">Leah Findlater</a>, <a href="http://arxiv.org/find/cs/1/au:+Boyd_Graber_J/0/1/0/all/0/1">Jordan Boyd-Graber</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.03070">
                                    <div class="article-summary-box-inner">
                                        <span>Cross-lingual word embeddings transfer knowledge between languages: models
trained on high-resource languages can predict in low-resource languages. We
introduce CLIME, an interactive system to quickly refine cross-lingual word
embeddings for a given classification problem. First, CLIME ranks words by
their salience to the downstream task. Then, users mark similarity between
keywords and their nearest neighbors in the embedding space. Finally, CLIME
updates the embeddings using the annotations. We evaluate CLIME on identifying
health-related text in four low-resource languages: Ilocano, Sinhalese,
Tigrinya, and Uyghur. Embeddings refined by CLIME capture more nuanced word
semantics and have higher test accuracy than the original embeddings. CLIME
often improves accuracy faster than an active learning baseline and can be
easily combined with active learning to improve results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MISIM: A Neural Code Semantics Similarity System Using the Context-Aware Semantics Structure. (arXiv:2006.05265v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ye_F/0/1/0/all/0/1">Fangke Ye</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1">Shengtian Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Venkat_A/0/1/0/all/0/1">Anand Venkat</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcus_R/0/1/0/all/0/1">Ryan Marcus</a>, <a href="http://arxiv.org/find/cs/1/au:+Tatbul_N/0/1/0/all/0/1">Nesime Tatbul</a>, <a href="http://arxiv.org/find/cs/1/au:+Tithi_J/0/1/0/all/0/1">Jesmin Jahan Tithi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hasabnis_N/0/1/0/all/0/1">Niranjan Hasabnis</a>, <a href="http://arxiv.org/find/cs/1/au:+Petersen_P/0/1/0/all/0/1">Paul Petersen</a>, <a href="http://arxiv.org/find/cs/1/au:+Mattson_T/0/1/0/all/0/1">Timothy Mattson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kraska_T/0/1/0/all/0/1">Tim Kraska</a>, <a href="http://arxiv.org/find/cs/1/au:+Dubey_P/0/1/0/all/0/1">Pradeep Dubey</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarkar_V/0/1/0/all/0/1">Vivek Sarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Gottschlich_J/0/1/0/all/0/1">Justin Gottschlich</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05265">
                                    <div class="article-summary-box-inner">
                                        <span>Code semantics similarity can be used for many tasks such as code
recommendation, automated software defect correction, and clone detection. Yet,
the accuracy of such systems has not yet reached a level of general purpose
reliability. To help address this, we present Machine Inferred Code Similarity
(MISIM), a neural code semantics similarity system consisting of two core
components: (i)MISIM uses a novel context-aware semantics structure, which was
purpose-built to lift semantics from code syntax; (ii)MISIM uses an extensible
neural code similarity scoring algorithm, which can be used for various neural
network architectures with learned parameters. We compare MISIM to four
state-of-the-art systems, including two additional hand-customized models, over
328K programs consisting of over 18 million lines of code. Our experiments show
that MISIM has 8.08% better accuracy (using MAP@R) compared to the next best
performing system.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quantum correlation alignment for unsupervised domain adaptation. (arXiv:2005.03355v4 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+He_X/0/1/0/all/0/1">Xi He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.03355">
                                    <div class="article-summary-box-inner">
                                        <span>Correlation alignment (CORAL), a representative domain adaptation (DA)
algorithm, decorrelates and aligns a labelled source domain dataset to an
unlabelled target domain dataset to minimize the domain shift such that a
classifier can be applied to predict the target domain labels. In this paper,
we implement the CORAL on quantum devices by two different methods. One method
utilizes quantum basic linear algebra subroutines (QBLAS) to implement the
CORAL with exponential speedup in the number and dimension of the given data
samples. The other method is achieved through a variational hybrid
quantum-classical procedure. In addition, the numerical experiments of the
CORAL with three different types of data sets, namely the synthetic data, the
synthetic-Iris data, the handwritten digit data, are presented to evaluate the
performance of our work. The simulation results prove that the variational
quantum correlation alignment algorithm (VQCORAL) can achieve competitive
performance compared with the classical CORAL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Survey on Optimal Transport for Machine Learning: Theory and Applications. (arXiv:2106.01963v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Torres_L/0/1/0/all/0/1">Luis Caicedo Torres</a>, <a href="http://arxiv.org/find/cs/1/au:+Pereira_L/0/1/0/all/0/1">Luiz Manella Pereira</a>, <a href="http://arxiv.org/find/cs/1/au:+Amini_M/0/1/0/all/0/1">M. Hadi Amini</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01963">
                                    <div class="article-summary-box-inner">
                                        <span>Optimal Transport (OT) theory has seen an increasing amount of attention from
the computer science community due to its potency and relevance in modeling and
machine learning. It introduces means that serve as powerful ways to compare
probability distributions with each other, as well as producing optimal
mappings to minimize cost functions. In this survey, we present a brief
introduction and history, a survey of previous work and propose directions of
future study. We will begin by looking at the history of optimal transport and
introducing the founders of this field. We then give a brief glance into the
algorithms related to OT. Then, we will follow up with a mathematical
formulation and the prerequisites to understand OT. These include Kantorovich
duality, entropic regularization, KL Divergence, and Wassertein barycenters.
Since OT is a computationally expensive problem, we then introduce the
entropy-regularized version of computing optimal mappings, which allowed OT
problems to become applicable in a wide range of machine learning problems. In
fact, the methods generated from OT theory are competitive with the current
state-of-the-art methods. We follow this up by breaking down research papers
that focus on image processing, graph learning, neural architecture search,
document representation, and domain adaptation. We close the paper with a small
section on future research. Of the recommendations presented, three main
problems are fundamental to allow OT to become widely applicable but rely
strongly on its mathematical formulation and thus are hardest to answer. Since
OT is a novel method, there is plenty of space for new research, and with more
and more competitive methods (either on an accuracy level or computational
speed level) being created, the future of applied optimal transport is bright
as it has become pervasive in machine learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Safe Active Dynamics Learning and Control: A Sequential Exploration-Exploitation Framework. (arXiv:2008.11700v3 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lew_T/0/1/0/all/0/1">Thomas Lew</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Apoorva Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Harrison_J/0/1/0/all/0/1">James Harrison</a>, <a href="http://arxiv.org/find/cs/1/au:+Bylard_A/0/1/0/all/0/1">Andrew Bylard</a>, <a href="http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1">Marco Pavone</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.11700">
                                    <div class="article-summary-box-inner">
                                        <span>Safe deployment of autonomous robots in diverse scenarios requires agents
that are capable of efficiently adapting to new environments while satisfying
constraints. In this work, we propose a practical and theoretically-justified
approach to maintaining safety in the presence of dynamics uncertainty. Our
approach leverages Bayesian meta-learning with last-layer adaptation: the
expressiveness of neural-network features trained offline, paired with
efficient last-layer online adaptation, enables the derivation of tight
confidence sets which contract around the true dynamics as the model adapts
online. We exploit these confidence sets to plan trajectories that guarantee
the safety of the system. Our approach handles problems with high dynamics
uncertainty where reaching the goal safely is initially infeasible by first
exploring to gather data and reduce uncertainty, before autonomously exploiting
the acquired information to safely perform the task. Under reasonable
assumptions, we prove that our framework has high-probability guarantees of
satisfying all constraints at all times jointly. This analysis also motivates
two regularizers of last-layer meta-learners that improve online adaptation
capabilities as well as performance by reducing the size of the confidence
sets. We extensively demonstrate our approach in simulation and on hardware.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LyricJam: A system for generating lyrics for live instrumental music. (arXiv:2106.01960v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vechtomova_O/0/1/0/all/0/1">Olga Vechtomova</a>, <a href="http://arxiv.org/find/cs/1/au:+Sahu_G/0/1/0/all/0/1">Gaurav Sahu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_D/0/1/0/all/0/1">Dhruv Kumar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01960">
                                    <div class="article-summary-box-inner">
                                        <span>We describe a real-time system that receives a live audio stream from a jam
session and generates lyric lines that are congruent with the live music being
played. Two novel approaches are proposed to align the learned latent spaces of
audio and text representations that allow the system to generate novel lyric
lines matching live instrumental music. One approach is based on adversarial
alignment of latent representations of audio and lyrics, while the other
approach learns to transfer the topology from the music latent space to the
lyric latent space. A user study with music artists using the system showed
that the system was useful not only in lyric composition, but also encouraged
the artists to improvise and find new musical expressions. Another user study
demonstrated that users preferred the lines generated using the proposed
methods to the lines generated by a baseline model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning and Variational Algorithms for Lattice Field Theory. (arXiv:2106.01975v1 [hep-lat])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/hep-lat/1/au:+Kanwar_G/0/1/0/all/0/1">Gurtej Kanwar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01975">
                                    <div class="article-summary-box-inner">
                                        <span>In lattice quantum field theory studies, parameters defining the lattice
theory must be tuned toward criticality to access continuum physics. Commonly
used Markov chain Monte Carlo (MCMC) methods suffer from critical slowing down
in this limit, restricting the precision of continuum extrapolations. Further
difficulties arise when measuring correlation functions of operators widely
separated in spacetime: for most correlation functions, an exponentially severe
signal-to-noise problem is encountered as the operators are taken to be widely
separated. This dissertation details two new techniques to address these
issues. First, we define a novel MCMC algorithm based on generative flow-based
models. Such models utilize machine learning methods to describe efficient
approximate samplers for distributions of interest. Independently drawn
flow-based samples are then used as proposals in an asymptotically exact
Metropolis-Hastings Markov chain. We address incorporating symmetries of
interest, including translational and gauge symmetries. We secondly introduce
an approach to &quot;deform&quot; Monte Carlo estimators based on contour deformations
applied to the domain of the path integral. The deformed estimators associated
with an observable give equivalent unbiased measurements of that observable,
but generically have different variances. We define families of deformed
manifolds for lattice gauge theories and introduce methods to efficiently
optimize the choice of manifold (the &quot;observifold&quot;), minimizing the deformed
observable variance. Finally, we demonstrate that flow-based MCMC can mitigate
critical slowing down and observifolds can exponentially reduce variance in
proof-of-principle applications to scalar $\phi^4$ theory and $\mathrm{U}(1)$
and $\mathrm{SU}(N)$ lattice gauge theories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Low-Rank Semidefinite Programming with Robust Loss Functions. (arXiv:1905.04629v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1">Quanming Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hangsi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_E/0/1/0/all/0/1">En-Liang Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1">James Kwok</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.04629">
                                    <div class="article-summary-box-inner">
                                        <span>In real-world applications, it is important for machine learning algorithms
to be robust against data outliers or corruptions. In this paper, we focus on
improving the robustness of a large class of learning algorithms that are
formulated as low-rank semi-definite programming (SDP) problems. Traditional
formulations use square loss, which is notorious for being sensitive to
outliers. We propose to replace this with more robust noise models, including
the $\ell_1$-loss and other nonconvex losses. However, the resultant
optimization problem becomes difficult as the objective is no longer convex or
smooth. To alleviate this problem, we design an efficient algorithm based on
majorization-minimization. The crux is on constructing a good optimization
surrogate, and we show that this surrogate can be efficiently obtained by the
alternating direction method of multipliers (ADMM). By properly monitoring
ADMM&#x27;s convergence, the proposed algorithm is empirically efficient and also
theoretically guaranteed to converge to a critical point. Extensive experiments
are performed on four machine learning applications using both synthetic and
real-world data sets. Results show that the proposed algorithm is not only fast
but also has better performance than the state-of-the-art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProtoRes: Proto-Residual Architecture for Deep Modeling of Human Pose. (arXiv:2106.01981v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1">Boris N. Oreshkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bocquelet_F/0/1/0/all/0/1">Florent Bocquelet</a>, <a href="http://arxiv.org/find/cs/1/au:+Harvey_F/0/1/0/all/0/1">F&#xe9;lix H. Harvey</a>, <a href="http://arxiv.org/find/cs/1/au:+Raitt_B/0/1/0/all/0/1">Bay Raitt</a>, <a href="http://arxiv.org/find/cs/1/au:+Laflamme_D/0/1/0/all/0/1">Dominic Laflamme</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01981">
                                    <div class="article-summary-box-inner">
                                        <span>Our work focuses on the development of a learnable neural representation of
human pose for advanced AI assisted animation tooling. Specifically, we tackle
the problem of constructing a full static human pose based on sparse and
variable user inputs (e.g. locations and/or orientations of a subset of body
joints). To solve this problem, we propose a novel neural architecture that
combines residual connections with prototype encoding of a partially specified
pose to create a new complete pose from the learned latent space. We show that
our architecture outperforms a baseline based on Transformer, both in terms of
accuracy and computational efficiency. Additionally, we develop a user
interface to integrate our neural model in Unity, a real-time 3D development
platform. Furthermore, we introduce two new datasets representing the static
human pose modeling problem, based on high-quality human motion capture data,
which will be released publicly along with model code.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepCompress: Efficient Point Cloud Geometry Compression. (arXiv:2106.01504v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Killea_R/0/1/0/all/0/1">Ryan Killea</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Bastani_S/0/1/0/all/0/1">Saeed Bastani</a>, <a href="http://arxiv.org/find/cs/1/au:+McLachlan_P/0/1/0/all/0/1">Paul McLachlan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01504">
                                    <div class="article-summary-box-inner">
                                        <span>Point clouds are a basic data type that is increasingly of interest as 3D
content becomes more ubiquitous. Applications using point clouds include
virtual, augmented, and mixed reality and autonomous driving. We propose a more
efficient deep learning-based encoder architecture for point clouds compression
that incorporates principles from established 3D object detection and image
compression architectures. Through an ablation study, we show that
incorporating the learned activation function from Computational Efficient
Neural Image Compression (CENIC) and designing more parameter-efficient
convolutional blocks yields dramatic gains in efficiency and performance. Our
proposed architecture incorporates Generalized Divisive Normalization
activations and propose a spatially separable InceptionV4-inspired block. We
then evaluate rate-distortion curves on the standard JPEG Pleno 8i Voxelized
Full Bodies dataset to evaluate our model&#x27;s performance. Our proposed
modifications outperform the baseline approaches by a small margin in terms of
Bjontegard delta rate and PSNR values, yet reduces necessary encoder
convolution operations by 8 percent and reduces total encoder parameters by 20
percent. Our proposed architecture, when considered on its own, has a small
penalty of 0.02 percent in Chamfer&#x27;s Distance and 0.32 percent increased bit
rate in Point to Plane Distance for the same peak signal-to-noise ratio.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiplierless MP-Kernel Machine For Energy-efficient Edge Devices. (arXiv:2106.01958v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1">Abhishek Ramdas Nair</a>, <a href="http://arxiv.org/find/cs/1/au:+Nath_P/0/1/0/all/0/1">Pallab Kumar Nath</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabartty_S/0/1/0/all/0/1">Shantanu Chakrabartty</a>, <a href="http://arxiv.org/find/cs/1/au:+Thakur_C/0/1/0/all/0/1">Chetan Singh Thakur</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01958">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel framework for designing multiplierless kernel machines
that can be used on resource-constrained platforms like intelligent edge
devices. The framework uses a piecewise linear (PWL) approximation based on a
margin propagation (MP) technique and uses only addition/subtraction, shift,
comparison, and register underflow/overflow operations. We propose a
hardware-friendly MP-based inference and online training algorithm that has
been optimized for a Field Programmable Gate Array (FPGA) platform. Our FPGA
implementation eliminates the need for DSP units and reduces the number of
LUTs. By reusing the same hardware for inference and training, we show that the
platform can overcome classification errors and local minima artifacts that
result from the MP approximation. Using the FPGA platform, we also show that
the proposed multiplierless MP-kernel machine demonstrates superior performance
in terms of power, performance, and area compared to other comparable
implementations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Do Neural Optimal Transport Solvers Work? A Continuous Wasserstein-2 Benchmark. (arXiv:2106.01954v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1">Alexander Korotin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lingxiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Genevay_A/0/1/0/all/0/1">Aude Genevay</a>, <a href="http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1">Justin Solomon</a>, <a href="http://arxiv.org/find/cs/1/au:+Filippov_A/0/1/0/all/0/1">Alexander Filippov</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1">Evgeny Burnaev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01954">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the recent popularity of neural network-based solvers for optimal
transport (OT), there is no standard quantitative way to evaluate their
performance. In this paper, we address this issue for quadratic-cost transport
-- specifically, computation of the Wasserstein-2 distance, a commonly-used
formulation of optimal transport in machine learning. To overcome the challenge
of computing ground truth transport maps between continuous measures needed to
assess these solvers, we use input-convex neural networks (ICNN) to construct
pairs of measures whose ground truth OT maps can be obtained analytically. This
strategy yields pairs of continuous benchmark measures in high-dimensional
spaces such as spaces of images. We thoroughly evaluate existing optimal
transport solvers using these benchmark measures. Even though these solvers
perform well in downstream tasks, many do not faithfully recover optimal
transport maps. To investigate the cause of this discrepancy, we further test
the solvers in a setting of image generation. Our study reveals crucial
limitations of existing solvers and shows that increased OT accuracy does not
necessarily correlate to better results downstream.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimization-Based Algebraic Multigrid Coarsening Using Reinforcement Learning. (arXiv:2106.01854v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Taghibakhshi_A/0/1/0/all/0/1">Ali Taghibakhshi</a>, <a href="http://arxiv.org/find/cs/1/au:+MacLachlan_S/0/1/0/all/0/1">Scott MacLachlan</a>, <a href="http://arxiv.org/find/cs/1/au:+Olson_L/0/1/0/all/0/1">Luke Olson</a>, <a href="http://arxiv.org/find/cs/1/au:+West_M/0/1/0/all/0/1">Matthew West</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01854">
                                    <div class="article-summary-box-inner">
                                        <span>Large sparse linear systems of equations are ubiquitous in science and
engineering, such as those arising from discretizations of partial differential
equations. Algebraic multigrid (AMG) methods are one of the most common methods
of solving such linear systems, with an extensive body of underlying
mathematical theory. A system of linear equations defines a graph on the set of
unknowns and each level of a multigrid solver requires the selection of an
appropriate coarse graph along with restriction and interpolation operators
that map to and from the coarse representation. The efficiency of the multigrid
solver depends critically on this selection and many selection methods have
been developed over the years. Recently, it has been demonstrated that it is
possible to directly learn the AMG interpolation and restriction operators,
given a coarse graph selection. In this paper, we consider the complementary
problem of learning to coarsen graphs for a multigrid solver. We propose a
method using a reinforcement learning (RL) agent based on graph neural networks
(GNNs), which can learn to perform graph coarsening on small training graphs
and then be applied to unstructured large graphs. We demonstrate that this
method can produce better coarse graphs than existing algorithms, even as the
graph size increases and other properties of the graph are varied. We also
propose an efficient inference procedure for performing graph coarsening that
results in linear time complexity in graph size.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Continual Learning in Deep Networks: an Analysis of the Last Layer. (arXiv:2106.01834v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1">Timoth&#xe9;e Lesort</a>, <a href="http://arxiv.org/find/cs/1/au:+George_T/0/1/0/all/0/1">Thomas George</a>, <a href="http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1">Irina Rish</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01834">
                                    <div class="article-summary-box-inner">
                                        <span>We study how different output layer types of a deep neural network learn and
forget in continual learning settings. We describe the three factors affecting
catastrophic forgetting in the output layer: (1) weights modifications, (2)
interferences, and (3) projection drift. Our goal is to provide more insights
into how different types of output layers can address (1) and (2). We also
propose potential solutions and evaluate them on several benchmarks. We show
that the best-performing output layer type depends on the data distribution
drifts or the amount of data available. In particular, in some cases where a
standard linear layer would fail, it is sufficient to change the
parametrization and get significantly better performance while still training
with SGD. Our results and analysis shed light on the dynamics of the output
layer in continual learning scenarios and help select the best-suited output
layer for a given scenario.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Near Optimal Stochastic Algorithms for Finite-Sum Unbalanced Convex-Concave Minimax Optimization. (arXiv:2106.01761v1 [math.OC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Luo_L/0/1/0/all/0/1">Luo Luo</a>, <a href="http://arxiv.org/find/math/1/au:+Xie_G/0/1/0/all/0/1">Guangzeng Xie</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_T/0/1/0/all/0/1">Tong Zhang</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_Z/0/1/0/all/0/1">Zhihua Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01761">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers stochastic first-order algorithms for convex-concave
minimax problems of the form $\min_{\bf x}\max_{\bf y}f(\bf x, \bf y)$, where
$f$ can be presented by the average of $n$ individual components which are
$L$-average smooth. For $\mu_x$-strongly-convex-$\mu_y$-strongly-concave
setting, we propose a new method which could find a $\varepsilon$-saddle point
of the problem in $\tilde{\mathcal O}
\big(\sqrt{n(\sqrt{n}+\kappa_x)(\sqrt{n}+\kappa_y)}\log(1/\varepsilon)\big)$
stochastic first-order complexity, where $\kappa_x\triangleq L/\mu_x$ and
$\kappa_y\triangleq L/\mu_y$. This upper bound is near optimal with respect to
$\varepsilon$, $n$, $\kappa_x$ and $\kappa_y$ simultaneously. In addition, the
algorithm is easily implemented and works well in practical. Our methods can be
extended to solve more general unbalanced convex-concave minimax problems and
the corresponding upper complexity bounds are also near optimal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical embedding: Beyond principal components. (arXiv:2106.01858v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tjostheim_D/0/1/0/all/0/1">Dag Tj&#xf8;stheim</a>, <a href="http://arxiv.org/find/stat/1/au:+Jullum_M/0/1/0/all/0/1">Martin Jullum</a>, <a href="http://arxiv.org/find/stat/1/au:+Loland_A/0/1/0/all/0/1">Anders L&#xf8;land</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01858">
                                    <div class="article-summary-box-inner">
                                        <span>There has been an intense recent activity in embedding of very high
dimensional and nonlinear data structures, much of it in the data science and
machine learning literature. We survey this activity in four parts. In the
first part we cover nonlinear methods such as principal curves,
multidimensional scaling, local linear methods, ISOMAP, graph based methods and
kernel based methods. The second part is concerned with topological embedding
methods, in particular mapping topological properties into persistence
diagrams. Another type of data sets with a tremendous growth is very
high-dimensional network data. The task considered in part three is how to
embed such data in a vector space of moderate dimension to make the data
amenable to traditional techniques such as cluster and classification
techniques. The final part of the survey deals with embedding in
$\mathbb{R}^2$, which is visualization. Three methods are presented: $t$-SNE,
UMAP and LargeVis based on methods in parts one, two and three, respectively.
The methods are illustrated and compared on two simulated data sets; one
consisting of a triple of noisy Ranunculoid curves, and one consisting of
networks of increasing complexity and with two types of nodes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions. (arXiv:2106.01798v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1">Mathias Niepert</a>, <a href="http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1">Pasquale Minervini</a>, <a href="http://arxiv.org/find/cs/1/au:+Franceschi_L/0/1/0/all/0/1">Luca Franceschi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01798">
                                    <div class="article-summary-box-inner">
                                        <span>Integrating discrete probability distributions and combinatorial optimization
problems into neural networks has numerous applications but poses several
challenges. We propose Implicit Maximum Likelihood Estimation (I-MLE), a
framework for end-to-end learning of models combining discrete exponential
family distributions and differentiable neural components. I-MLE is widely
applicable: it only requires the ability to compute the most probable states;
and does not rely on smooth relaxations. The framework encompasses several
approaches, such as perturbation-based implicit differentiation and recent
methods to differentiate through black-box combinatorial solvers. We introduce
a novel class of noise distributions for approximating marginals via
perturb-and-MAP. Moreover, we show that I-MLE simplifies to maximum likelihood
estimation when used in some recently studied learning settings that involve
combinatorial solvers. Experiments on several datasets suggest that I-MLE is
competitive with and often outperforms existing approaches which rely on
problem-specific relaxations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DeepOpt: Scalable Specification-based Falsification of Neural Networks using Black-Box Optimization. (arXiv:2106.01917v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bauer_Marquart_F/0/1/0/all/0/1">Fabian Bauer-Marquart</a>, <a href="http://arxiv.org/find/cs/1/au:+Leue_S/0/1/0/all/0/1">Stefan Leue</a>, <a href="http://arxiv.org/find/cs/1/au:+Schilling_C/0/1/0/all/0/1">Christian Schilling</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01917">
                                    <div class="article-summary-box-inner">
                                        <span>Decisions made by deep neural networks (DNNs) have a tremendous impact on the
dependability of the systems that they are embedded into, which is of
particular concern in the realm of safety-critical systems. In this paper we
consider specification-based falsification of DNNs with the aim to support
debugging and repair. We propose DeepOpt, a falsification technique based on
black-box optimization, which generates counterexamples from a DNN in a
refinement loop. DeepOpt can analyze input-output specifications, which makes
it more general than falsification approaches that only support robustness
specifications. The key idea is to algebraically combine the DNN with the input
and output constraints derived from the specification. We have implemented
DeepOpt and evaluated it on DNNs of varying sizes and architectures.
Experimental comparisons demonstrate DeepOpt&#x27;s precision and scalability; in
particular, DeepOpt requires very few queries to the DNN.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Graph Intervention Networks for Causal Effect Estimation. (arXiv:2106.01939v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaddour_J/0/1/0/all/0/1">Jean Kaddour</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yuchen Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kusner_M/0/1/0/all/0/1">Matt J. Kusner</a>, <a href="http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1">Ricardo Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01939">
                                    <div class="article-summary-box-inner">
                                        <span>We address the estimation of conditional average treatment effects (CATEs)
when treatments are graph-structured (e.g., molecular graphs of drugs). Given a
weak condition on the effect, we propose a plug-in estimator that decomposes
CATE estimation into separate, simpler optimization problems. Our estimator (a)
isolates the causal estimands (reducing regularization bias), and (b) allows
one to plug in arbitrary models for learning. In experiments with small-world
and molecular graphs, we show that our approach outperforms prior approaches
and is robust to varying selection biases. Our implementation is online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Improved Model for Voicing Silent Speech. (arXiv:2106.01933v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Gaddy_D/0/1/0/all/0/1">David Gaddy</a>, <a href="http://arxiv.org/find/eess/1/au:+Klein_D/0/1/0/all/0/1">Dan Klein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01933">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we present an improved model for voicing silent speech, where
audio is synthesized from facial electromyography (EMG) signals. To give our
model greater flexibility to learn its own input features, we directly use EMG
signals as input in the place of hand-designed features used by prior work. Our
model uses convolutional layers to extract features from the signals and
Transformer layers to propagate information across longer distances. To provide
better signal for learning, we also introduce an auxiliary task of predicting
phoneme labels in addition to predicting speech audio features. On an open
vocabulary intelligibility evaluation, our model improves the state of the art
for this task by an absolute 25.8%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Learning of Event-Based Optical Flow with Spiking Neural Networks. (arXiv:2106.01862v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Paredes_Valles_F/0/1/0/all/0/1">Federico Paredes-Vall&#xe9;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Hagenaars_J/0/1/0/all/0/1">Jesse Hagenaars</a>, <a href="http://arxiv.org/find/cs/1/au:+Croon_G/0/1/0/all/0/1">Guido de Croon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01862">
                                    <div class="article-summary-box-inner">
                                        <span>Neuromorphic sensing and computing hold a promise for highly energy-efficient
and high-bandwidth-sensor processing. A major challenge for neuromorphic
computing is that learning algorithms for traditional artificial neural
networks (ANNs) do not transfer directly to spiking neural networks (SNNs) due
to the discrete spikes and more complex neuronal dynamics. As a consequence,
SNNs have not yet been successfully applied to complex, large-scale tasks. In
this article, we focus on the self-supervised learning problem of optical flow
estimation from event-based camera inputs, and investigate the changes that are
necessary to the state-of-the-art ANN training pipeline in order to
successfully tackle it with SNNs. More specifically, we first modify the input
event representation to encode a much smaller time slice with minimal explicit
temporal information. Consequently, we make the network&#x27;s neuronal dynamics and
recurrent connections responsible for integrating information over time.
Moreover, we reformulate the self-supervised loss function for event-based
optical flow to improve its convexity. We perform experiments with various
types of recurrent ANNs and SNNs using the proposed pipeline. Concerning SNNs,
we investigate the effects of elements such as parameter initialization and
optimization, surrogate gradient shape, and adaptive neuronal mechanisms. We
find that initialization and surrogate gradient width play a crucial part in
enabling learning with sparse inputs, while the inclusion of adaptivity and
learnable neuronal parameters can improve performance. We show that the
performance of the proposed ANNs and SNNs are on par with that of the current
state-of-the-art ANNs trained in a self-supervised manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pathology-Aware Generative Adversarial Networks for Medical Image Augmentation. (arXiv:2106.01915v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1">Changhee Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01915">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) can play a key role in Medical Image
Analysis under large-scale annotated datasets. However, preparing such massive
dataset is demanding. In this context, Generative Adversarial Networks (GANs)
can generate realistic but novel samples, and thus effectively cover the real
image distribution. In terms of interpolation, the GAN-based medical image
augmentation is reliable because medical modalities can display the human
body&#x27;s strong anatomical consistency at fixed position while clearly reflecting
inter-subject variability; thus, we propose to use noise-to-image GANs (e.g.,
random noise samples to diverse pathological images) for (i) medical Data
Augmentation (DA) and (ii) physician training. Regarding the DA, the
GAN-generated images can improve Computer-Aided Diagnosis based on supervised
learning. For the physician training, the GANs can display novel desired
pathological images and help train medical trainees despite
infrastructural/legal constraints. This thesis contains four GAN projects
aiming to present such novel applications&#x27; clinical relevance in collaboration
with physicians. Whereas the methods are more generally applicable, this thesis
only explores a few oncological applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Convolutional Neural Network(CNN/ConvNet) in Stock Price Movement Prediction. (arXiv:2106.01920v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhardwaj_K/0/1/0/all/0/1">Kunal Bhardwaj</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01920">
                                    <div class="article-summary-box-inner">
                                        <span>With technological advancements and the exponential growth of data, we have
been unfolding different capabilities of neural networks in different sectors.
In this paper, I have tried to use a specific type of Neural Network known as
Convolutional Neural Network(CNN/ConvNet) in the stock market. In other words,
I have tried to construct and train a convolutional neural network on past
stock prices data and then tried to predict the movement of stock price i.e.
whether the stock price would rise or fall, in the coming time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sample Selection Bias in Evaluation of Prediction Performance of Causal Models. (arXiv:2106.01921v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Long_J/0/1/0/all/0/1">James P. Long</a>, <a href="http://arxiv.org/find/stat/1/au:+Ha_M/0/1/0/all/0/1">Min Jin Ha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01921">
                                    <div class="article-summary-box-inner">
                                        <span>Causal models are notoriously difficult to validate because they make
untestable assumptions regarding confounding. New scientific experiments offer
the possibility of evaluating causal models using prediction performance.
Prediction performance measures are typically robust to violations in causal
assumptions. However prediction performance does depend on the selection of
training and test sets. In particular biased training sets can lead to
optimistic assessments of model performance. In this work, we revisit the
prediction performance of several recently proposed causal models tested on a
genetic perturbation data set of Kemmeren [Kemmeren et al., 2014]. We find that
sample selection bias is likely a key driver of model performance. We propose
using a less-biased evaluation set for assessing prediction performance on
Kemmeren and compare models on this new set. In this setting, the causal model
tested have similar performance to standard association based estimators such
as Lasso. Finally we compare the performance of causal estimators in simulation
studies which reproduce the Kemmeren structure of genetic knockout experiments
but without any sample selection bias. These results provide an improved
understanding of the performance of several causal models and offer guidance on
how future studies should use Kemmeren.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lifetime policy reuse and the importance of task capacity. (arXiv:2106.01741v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bossens_D/0/1/0/all/0/1">David M. Bossens</a>, <a href="http://arxiv.org/find/cs/1/au:+Sobey_A/0/1/0/all/0/1">Adam J. Sobey</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01741">
                                    <div class="article-summary-box-inner">
                                        <span>A long-standing challenge in artificial intelligence is lifelong learning. In
lifelong learning, many tasks are presented in sequence and learners must
efficiently transfer knowledge between tasks while avoiding catastrophic
forgetting over long lifetimes. On these problems, policy reuse and other
multi-policy reinforcement learning techniques can learn many tasks. However,
they can generate many temporary or permanent policies, resulting in memory
issues. Consequently, there is a need for lifetime-scalable methods that
continually refine a policy library of a pre-defined size. This paper presents
a first approach to lifetime-scalable policy reuse. To pre-select the number of
policies, a notion of task capacity, the maximal number of tasks that a policy
can accurately solve, is proposed. To evaluate lifetime policy reuse using this
method, two state-of-the-art single-actor base-learners are compared: 1) a
value-based reinforcement learner, Deep Q-Network (DQN) or Deep Recurrent
Q-Network (DRQN); and 2) an actor-critic reinforcement learner, Proximal Policy
Optimisation (PPO) with or without Long Short-Term Memory layer. By selecting
the number of policies based on task capacity, D(R)QN achieves near-optimal
performance with 6 policies in a 27-task MDP domain and 9 policies in an
18-task POMDP domain; with fewer policies, catastrophic forgetting and negative
transfer are observed. Due to slow, monotonic improvement, PPO requires fewer
policies, 1 policy for the 27-task domain and 4 policies for the 18-task
domain, but it learns the tasks with lower accuracy than D(R)QN. These findings
validate lifetime-scalable policy reuse and suggest using D(R)QN for larger and
PPO for smaller library sizes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine learning models for DOTA 2 outcomes prediction. (arXiv:2106.01782v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhmedov_K/0/1/0/all/0/1">Kodirjon Akhmedov</a>, <a href="http://arxiv.org/find/cs/1/au:+Phan_A/0/1/0/all/0/1">Anh Huy Phan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01782">
                                    <div class="article-summary-box-inner">
                                        <span>Prediction of the real-time multiplayer online battle arena (MOBA) games&#x27;
match outcome is one of the most important and exciting tasks in Esports
analytical research. This research paper predominantly focuses on building
predictive machine and deep learning models to identify the outcome of the Dota
2 MOBA game using the new method of multi-forward steps predictions. Three
models were investigated and compared: Linear Regression (LR), Neural Networks
(NN), and a type of recurrent neural network Long Short-Term Memory (LSTM). In
order to achieve the goals, we developed a data collecting python server using
Game State Integration (GSI) to track the real-time data of the players. Once
the exploratory feature analysis and tuning hyper-parameters were done, our
models&#x27; experiments took place on different players with dissimilar backgrounds
of playing experiences. The achieved accuracy scores depend on the
multi-forward prediction parameters, which for the worse case in linear
regression 69\% but on average 82\%, while in the deep learning models hit the
utmost accuracy of prediction on average 88\% for NN, and 93\% for LSTM models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Preparation of Many-body Ground States by Time Evolution with Variational Microscopic Magnetic Fields and Incomplete Interactions. (arXiv:2106.01779v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Lu_Y/0/1/0/all/0/1">Ying Lu</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Li_Y/0/1/0/all/0/1">Yue-Min Li</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Zhou_P/0/1/0/all/0/1">Peng-Fei Zhou</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Ran_S/0/1/0/all/0/1">Shi-Ju Ran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01779">
                                    <div class="article-summary-box-inner">
                                        <span>State preparation is of fundamental importance in quantum physics, which can
be realized by constructing the quantum circuit as a unitary that transforms
the initial state to the target, or implementing a quantum control protocol to
evolve to the target state with a designed Hamiltonian. In this work, we study
the latter on quantum many-body systems by the time evolution with fixed
couplings and variational magnetic fields. In specific, we consider to prepare
the ground states of the Hamiltonians containing certain interactions that are
missing in the Hamiltonians for the time evolution. An optimization method is
proposed to optimize the magnetic fields by &quot;fine-graining&quot; the discretization
of time, in order to gain high precision and stability. The back propagation
technique is utilized to obtain the gradients of the fields against the
logarithmic fidelity. Our method is tested on preparing the ground state of
Heisenberg chain with the time evolution by the XY and Ising interactions, and
its performance surpasses two baseline methods that use local and global
optimization strategies, respectively. Our work can be applied and generalized
to other quantum models such as those defined on higher dimensional lattices.
It enlightens to reduce the complexity of the required interactions for
implementing quantum control or other tasks in quantum information and
computation by means of optimizing the magnetic fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Auto-tagging of Short Conversational Sentences using Transformer Methods. (arXiv:2106.01735v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tasar_D/0/1/0/all/0/1">D. Emre Ta&#x15f;ar</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozan_S/0/1/0/all/0/1">&#x15e;&#xfc;kr&#xfc; Ozan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ozdil_U/0/1/0/all/0/1">Umut &#xd6;zdil</a>, <a href="http://arxiv.org/find/cs/1/au:+Akca_M/0/1/0/all/0/1">M. Fatih Akca</a>, <a href="http://arxiv.org/find/cs/1/au:+Olmez_O/0/1/0/all/0/1">O&#x11f;uzhan &#xd6;lmez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gulum_S/0/1/0/all/0/1">Semih G&#xfc;l&#xfc;m</a>, <a href="http://arxiv.org/find/cs/1/au:+Kutal_S/0/1/0/all/0/1">Se&#xe7;ilay Kutal</a>, <a href="http://arxiv.org/find/cs/1/au:+Belhan_C/0/1/0/all/0/1">Ceren Belhan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01735">
                                    <div class="article-summary-box-inner">
                                        <span>The problem of categorizing short speech sentences according to their
semantic features with high accuracy is a subject studied in natural language
processing. In this study, a data set created with samples classified in 46
different categories was used. Examples consist of sentences taken from chat
conversations between a company&#x27;s customer representatives and the company&#x27;s
website visitors. The primary purpose is to automatically tag questions and
requests from visitors in the most accurate way for 46 predetermined categories
for use in a chat application to generate meaningful answers to the questions
asked by the website visitors. For this, different BERT models and one GPT-2
model, pre-trained in Turkish, were preferred. The classification performances
of the relevant models were analyzed in detail and reported accordingly.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partial Graph Reasoning for Neural Network Regularization. (arXiv:2106.01805v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1">Tiange Xiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chaoyi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yang Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siqi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_H/0/1/0/all/0/1">Hongliang Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cai_W/0/1/0/all/0/1">Weidong Cai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01805">
                                    <div class="article-summary-box-inner">
                                        <span>Regularizers helped deep neural networks prevent feature co-adaptations.
Dropout,as a commonly used regularization technique, stochastically disables
neuron ac-tivations during network optimization. However, such complete feature
disposal can affect the feature representation and network understanding.
Toward betterdescriptions of latent representations, we present DropGraph that
learns regularization function by constructing a stand-alone graph from the
backbone features. DropGraph first samples stochastic spatial feature vectors
and then incorporates graph reasoning methods to generate feature map
distortions. This add-on graph regularizes the network during training and can
be completely skipped during inference. We provide intuitions on the linkage
between graph reasoning andDropout with further discussions on how partial
graph reasoning method reduces feature correlations. To this end, we
extensively study the modeling of graphvertex dependencies and the utilization
of the graph for distorting backbone featuremaps. DropGraph was validated on
four tasks with a total of 7 different datasets.The experimental results show
that our method outperforms other state-of-the-art regularizers while leaving
the base model structure unmodified during inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Normative Model of Classifier Fusion. (arXiv:2106.01770v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Trick_S/0/1/0/all/0/1">Susanne Trick</a>, <a href="http://arxiv.org/find/cs/1/au:+Rothkopf_C/0/1/0/all/0/1">Constantin A. Rothkopf</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01770">
                                    <div class="article-summary-box-inner">
                                        <span>Combining the outputs of multiple classifiers or experts into a single
probabilistic classification is a fundamental task in machine learning with
broad applications from classifier fusion to expert opinion pooling. Here we
present a hierarchical Bayesian model of probabilistic classifier fusion based
on a new correlated Dirichlet distribution. This distribution explicitly models
positive correlations between marginally Dirichlet-distributed random vectors
thereby allowing normative modeling of correlations between base classifiers or
experts. The proposed model naturally accommodates the classic Independent
Opinion Pool and other independent fusion algorithms as special cases. It is
evaluated by uncertainty reduction and correctness of fusion on synthetic and
real-world data sets. We show that a change in performance of the fused
classifier due to uncertainty reduction can be Bayes optimal even for highly
correlated base classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Effort-free Automated Skeletal Abnormality Detection of Rat Fetuses on Whole-body Micro-CT Scans. (arXiv:2106.01830v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fukuda_A/0/1/0/all/0/1">Akihiro Fukuda</a>, <a href="http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1">Changhee Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Hakamada_K/0/1/0/all/0/1">Kazumi Hakamada</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01830">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning-based fast and quantitative automated screening plays a key
role in analyzing human bones on Computed Tomography (CT) scans. However,
despite the requirement in drug safety assessment, such research is rare on
animal fetus micro-CT scans due to its laborious data collection and
annotation. Therefore, we propose various bone feature engineering techniques
to thoroughly automate the skeletal localization/labeling/abnormality detection
of rat fetuses on whole-body micro-CT scans with minimum effort. Despite
limited training data of 49 fetuses, in skeletal labeling and abnormality
detection, we achieve accuracy of 0.900 and 0.810, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence. (arXiv:2106.01883v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xue Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiaojiang Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jirui Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ming_Q/0/1/0/all/0/1">Qi Ming</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wentao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Q/0/1/0/all/0/1">Qi Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1">Junchi Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01883">
                                    <div class="article-summary-box-inner">
                                        <span>Existing rotated object detectors are mostly inherited from the horizontal
detection paradigm, as the latter has evolved into a well-developed area.
However, these detectors are difficult to perform prominently in high-precision
detection due to the limitation of current regression loss design, especially
for objects with large aspect ratios. Taking the perspective that horizontal
detection is a special case for rotated object detection, in this paper, we are
motivated to change the design of rotation regression loss from induction
paradigm to deduction methodology, in terms of the relation between rotation
and horizontal detection. We show that one essential challenge is how to
modulate the coupled parameters in the rotation regression loss, as such the
estimated parameters can influence to each other during the dynamic joint
optimization, in an adaptive and synergetic way. Specifically, we first convert
the rotated bounding box into a 2-D Gaussian distribution, and then calculate
the Kullback-Leibler Divergence (KLD) between the Gaussian distributions as the
regression loss. By analyzing the gradient of each parameter, we show that KLD
(and its derivatives) can dynamically adjust the parameter gradients according
to the characteristics of the object. It will adjust the importance (gradient
weight) of the angle parameter according to the aspect ratio. This mechanism
can be vital for high-precision detection as a slight angle error would cause a
serious accuracy drop for large aspect ratios objects. More importantly, we
have proved that KLD is scale invariant. We further show that the KLD loss can
be degenerated into the popular $l_{n}$-norm loss for horizontal detection.
Experimental results on seven datasets using different detectors show its
consistent superiority, and codes are available at
https://github.com/yangxue0827/RotationDetection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Domain Adaptation for Facial Expression Classifier via Domain Discrimination and Gradient Reversal. (arXiv:2106.01467v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Akhmetov_K/0/1/0/all/0/1">Kamil Akhmetov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01467">
                                    <div class="article-summary-box-inner">
                                        <span>Bringing empathy to a computerized system could significantly improve the
quality of human-computer communications, as soon as machines would be able to
understand customer intentions and better serve their needs. According to
different studies (Literature Review), visual information is one of the most
important channels of human interaction and contains significant behavioral
signals, that may be captured from facial expressions. Therefore, it is
consistent and natural that the research in the field of Facial Expression
Recognition (FER) has acquired increased interest over the past decade due to
having diverse application area including health-care, sociology, psychology,
driver-safety, virtual reality, cognitive sciences, security, entertainment,
marketing, etc. We propose a new architecture for the task of FER and examine
the impact of domain discrimination loss regularization on the learning
process. With regard to observations, including both classical training
conditions and unsupervised domain adaptation scenarios, important aspects of
the considered domain adaptation approach integration are traced. The results
may serve as a foundation for further research in the field.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Drivers&#x27; Manoeuvre Modelling and Prediction for Safe HRI. (arXiv:2106.01730v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pulgarin_E/0/1/0/all/0/1">Erwin Jose Lopez Pulgarin</a>, <a href="http://arxiv.org/find/cs/1/au:+Herrmann_G/0/1/0/all/0/1">Guido Herrmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Leonards_U/0/1/0/all/0/1">Ute Leonards</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01730">
                                    <div class="article-summary-box-inner">
                                        <span>As autonomous machines such as robots and vehicles start performing tasks
involving human users, ensuring a safe interaction between them becomes an
important issue. Translating methods from human-robot interaction (HRI) studies
to the interaction between humans and other highly complex machines (e.g.
semi-autonomous vehicles) could help advance the use of those machines in
scenarios requiring human interaction. One method involves understanding human
intentions and decision-making to estimate the human&#x27;s present and near-future
actions whilst interacting with a robot. This idea originates from the
psychological concept of Theory of Mind, which has been broadly explored for
robotics and recently for autonomous and semi-autonomous vehicles. In this
work, we explored how to predict human intentions before an action is performed
by combining data from human-motion, vehicle-state and human inputs (e.g.
steering wheel, pedals). A data-driven approach based on Recurrent Neural
Network models was used to classify the current driving manoeuvre and to
predict the future manoeuvre to be performed. A state-transition model was used
with a fixed set of manoeuvres to label data recorded during the trials for
real-time applications. Models were trained and tested using drivers of
different seat preferences, driving expertise and arm-length; precision and
recall metrics over 95% for manoeuvre identification and 86% for manoeuvre
prediction were achieved, with prediction time-windows of up to 1 second for
both known and unknown test subjects. Compared to our previous results,
performance improved and manoeuvre prediction was possible for unknown test
subjects without knowing the current manoeuvre.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MINIMALIST: Mutual INformatIon Maximization for Amortized Likelihood Inference from Sampled Trajectories. (arXiv:2106.01808v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Isacchini_G/0/1/0/all/0/1">Giulio Isacchini</a>, <a href="http://arxiv.org/find/cs/1/au:+Spisak_N/0/1/0/all/0/1">Natanael Spisak</a>, <a href="http://arxiv.org/find/cs/1/au:+Nourmohammad_A/0/1/0/all/0/1">Armita Nourmohammad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mora_T/0/1/0/all/0/1">Thierry Mora</a>, <a href="http://arxiv.org/find/cs/1/au:+Walczak_A/0/1/0/all/0/1">Aleksandra M. Walczak</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01808">
                                    <div class="article-summary-box-inner">
                                        <span>Simulation-based inference enables learning the parameters of a model even
when its likelihood cannot be computed in practice. One class of methods uses
data simulated with different parameters to infer an amortized estimator for
the likelihood-to-evidence ratio, or equivalently the posterior function. We
show that this approach can be formulated in terms of mutual information
maximization between model parameters and simulated data. We use this
equivalence to reinterpret existing approaches for amortized inference, and
propose two new methods that rely on lower bounds of the mutual information. We
apply our framework to the inference of parameters of stochastic processes and
chaotic dynamical systems from sampled trajectories, using artificial neural
networks for posterior prediction. Our approach provides a unified framework
that leverages the power of mutual information estimators for inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LiMIIRL: Lightweight Multiple-Intent Inverse Reinforcement Learning. (arXiv:2106.01777v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Snoswell_A/0/1/0/all/0/1">Aaron J. Snoswell</a>, <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Surya P. N. Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Ye_N/0/1/0/all/0/1">Nan Ye</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01777">
                                    <div class="article-summary-box-inner">
                                        <span>Multiple-Intent Inverse Reinforcement Learning (MI-IRL) seeks to find a
reward function ensemble to rationalize demonstrations of different but
unlabelled intents. Within the popular expectation maximization (EM) framework
for learning probabilistic MI-IRL models, we present a warm-start strategy
based on up-front clustering of the demonstrations in feature space. Our
theoretical analysis shows that this warm-start solution produces a
near-optimal reward ensemble, provided the behavior modes satisfy mild
separation conditions. We also propose a MI-IRL performance metric that
generalizes the popular Expected Value Difference measure to directly assesses
learned rewards against the ground-truth reward ensemble. Our metric elegantly
addresses the difficulty of pairing up learned and ground truth rewards via a
min-cost flow formulation, and is efficiently computable. We also develop a
MI-IRL benchmark problem that allows for more comprehensive algorithmic
evaluations. On this problem, we find our MI-IRL warm-start strategy helps
avoid poor quality local minima reward ensembles, resulting in a significant
improvement in behavior clustering. Our extensive sensitivity analysis
demonstrates that the quality of the learned reward ensembles is improved under
various settings, including cases where our theoretical assumptions do not
necessarily hold. Finally, we demonstrate the effectiveness of our methods by
discovering distinct driving styles in a large real-world dataset of driver GPS
trajectories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">EmoDNN: Understanding emotions from short texts through a deep neural network ensemble. (arXiv:2106.01706v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamran_S/0/1/0/all/0/1">Sara Kamran</a>, <a href="http://arxiv.org/find/cs/1/au:+Zall_R/0/1/0/all/0/1">Raziyeh Zall</a>, <a href="http://arxiv.org/find/cs/1/au:+Kangavari_M/0/1/0/all/0/1">Mohammad Reza Kangavari</a>, <a href="http://arxiv.org/find/cs/1/au:+Hosseini_S/0/1/0/all/0/1">Saeid Hosseini</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahmani_S/0/1/0/all/0/1">Sana Rahmani</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1">Wen Hua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01706">
                                    <div class="article-summary-box-inner">
                                        <span>The latent knowledge in the emotions and the opinions of the individuals that
are manifested via social networks are crucial to numerous applications
including social management, dynamical processes, and public security.
Affective computing, as an interdisciplinary research field, linking artificial
intelligence to cognitive inference, is capable to exploit emotion-oriented
knowledge from brief contents. The textual contents convey hidden information
such as personality and cognition about corresponding authors that can
determine both correlations and variations between users. Emotion recognition
from brief contents should embrace the contrast between authors where the
differences in personality and cognition can be traced within emotional
expressions. To tackle this challenge, we devise a framework that, on the one
hand, infers latent individual aspects, from brief contents and, on the other
hand, presents a novel ensemble classifier equipped with dynamic dropout
convnets to extract emotions from textual context. To categorize short text
contents, our proposed method conjointly leverages cognitive factors and
exploits hidden information. We utilize the outcome vectors in a novel
embedding model to foster emotion-pertinent features that are collectively
assembled by lexicon inductions. Experimental results show that compared to
other competitors, our proposed model can achieve a higher performance in
recognizing emotion from noisy contents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIRE: Separate Intra- and Inter-sentential Reasoning for Document-level Relation Extraction. (arXiv:2106.01709v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zeng_S/0/1/0/all/0/1">Shuang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yuting Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_B/0/1/0/all/0/1">Baobao Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01709">
                                    <div class="article-summary-box-inner">
                                        <span>Document-level relation extraction has attracted much attention in recent
years. It is usually formulated as a classification problem that predicts
relations for all entity pairs in the document. However, previous works
indiscriminately represent intra- and inter-sentential relations in the same
way, confounding the different patterns for predicting them. Besides, they
create a document graph and use paths between entities on the graph as clues
for logical reasoning. However, not all entity pairs can be connected with a
path and have the correct logical reasoning paths in their graph. Thus many
cases of logical reasoning cannot be covered. This paper proposes an effective
architecture, SIRE, to represent intra- and inter-sentential relations in
different ways. We design a new and straightforward form of logical reasoning
module that can cover more logical reasoning chains. Experiments on the public
datasets show SIRE outperforms the previous state-of-the-art methods. Further
analysis shows that our predictions are reliable and explainable. Our code is
available at https://github.com/DreamInvoker/SIRE.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Risk Minimization from Adaptively Collected Data: Guarantees for Supervised and Policy Learning. (arXiv:2106.01723v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bibaut_A/0/1/0/all/0/1">Aur&#xe9;lien Bibaut</a>, <a href="http://arxiv.org/find/stat/1/au:+Chambaz_A/0/1/0/all/0/1">Antoine Chambaz</a>, <a href="http://arxiv.org/find/stat/1/au:+Dimakopoulou_M/0/1/0/all/0/1">Maria Dimakopoulou</a>, <a href="http://arxiv.org/find/stat/1/au:+Kallus_N/0/1/0/all/0/1">Nathan Kallus</a>, <a href="http://arxiv.org/find/stat/1/au:+Laan_M/0/1/0/all/0/1">Mark van der Laan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01723">
                                    <div class="article-summary-box-inner">
                                        <span>Empirical risk minimization (ERM) is the workhorse of machine learning,
whether for classification and regression or for off-policy policy learning,
but its model-agnostic guarantees can fail when we use adaptively collected
data, such as the result of running a contextual bandit algorithm. We study a
generic importance sampling weighted ERM algorithm for using adaptively
collected data to minimize the average of a loss function over a hypothesis
class and provide first-of-their-kind generalization guarantees and fast
convergence rates. Our results are based on a new maximal inequality that
carefully leverages the importance sampling structure to obtain rates with the
right dependence on the exploration rate in the data. For regression, we
provide fast rates that leverage the strong convexity of squared-error loss.
For policy learning, we provide rate-optimal regret guarantees that close an
open gap in the existing literature whenever exploration decays to zero, as is
the case for bandit-collected data. An empirical investigation validates our
theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimization Variance: Exploring Generalization Properties of DNNs. (arXiv:2106.01714v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1">Xiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1">Dongrui Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1">Bo Dai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01714">
                                    <div class="article-summary-box-inner">
                                        <span>Unlike the conventional wisdom in statistical learning theory, the test error
of a deep neural network (DNN) often demonstrates double descent: as the model
complexity increases, it first follows a classical U-shaped curve and then
shows a second descent. Through bias-variance decomposition, recent studies
revealed that the bell-shaped variance is the major cause of model-wise double
descent (when the DNN is widened gradually). This paper investigates epoch-wise
double descent, i.e., the test error of a DNN also shows double descent as the
number of training epoches increases. By extending the bias-variance analysis
to epoch-wise double descent of the zero-one loss, we surprisingly find that
the variance itself, without the bias, varies consistently with the test error.
Inspired by this result, we propose a novel metric, optimization variance (OV),
to measure the diversity of model updates caused by the stochastic gradients of
random training batches drawn in the same iteration. OV can be estimated using
samples from the training set only but correlates well with the (unknown)
\emph{test} error, and hence early stopping may be achieved without using a
validation set.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lymph Node Graph Neural Networks for Cancer Metastasis Prediction. (arXiv:2106.01711v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazmierski_M/0/1/0/all/0/1">Michal Kazmierski</a>, <a href="http://arxiv.org/find/cs/1/au:+Haibe_Kains_B/0/1/0/all/0/1">Benjamin Haibe-Kains</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01711">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting outcomes, such as survival or metastasis for individual cancer
patients is a crucial component of precision oncology. Machine learning (ML)
offers a promising way to exploit rich multi-modal data, including clinical
information and imaging to learn predictors of disease trajectory and help
inform clinical decision making. In this paper, we present a novel graph-based
approach to incorporate imaging characteristics of existing cancer spread to
local lymph nodes (LNs) as well as their connectivity patterns in a prognostic
ML model. We trained an edge-gated Graph Convolutional Network (Gated-GCN) to
accurately predict the risk of distant metastasis (DM) by propagating
information across the LN graph with the aid of soft edge attention mechanism.
In a cohort of 1570 head and neck cancer patients, the Gated-GCN achieves AUROC
of 0.757 for 2-year DM classification and $C$-index of 0.725 for lifetime DM
risk prediction, outperforming current prognostic factors as well as previous
approaches based on aggregated LN features. We also explored the importance of
graph structure and individual lymph nodes through ablation experiments and
interpretability studies, highlighting the importance of considering individual
LN characteristics as well as the relationships between regions of cancer
spread.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Representation over Dynamic Graph using Aggregation-Diffusion Mechanism. (arXiv:2106.01678v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1">Mingyi Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhiying Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1">Xiaofei Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhongjie Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01678">
                                    <div class="article-summary-box-inner">
                                        <span>Representation learning on graphs that evolve has recently received
significant attention due to its wide application scenarios, such as
bioinformatics, knowledge graphs, and social networks. The propagation of
information in graphs is important in learning dynamic graph representations,
and most of the existing methods achieve this by aggregation. However, relying
only on aggregation to propagate information in dynamic graphs can result in
delays in information propagation and thus affect the performance of the
method. To alleviate this problem, we propose an aggregation-diffusion (AD)
mechanism that actively propagates information to its neighbor by diffusion
after the node updates its embedding through the aggregation mechanism. In
experiments on two real-world datasets in the dynamic link prediction task, the
AD mechanism outperforms the baseline models that only use aggregation to
propagate information. We further conduct extensive experiments to discuss the
influence of different factors in the AD mechanism.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Machine Learning Based Texture Analysis of Patella from X-Rays for Detecting Patellofemoral Osteoarthritis. (arXiv:2106.01700v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bayramoglu_N/0/1/0/all/0/1">Neslihan Bayramoglu</a>, <a href="http://arxiv.org/find/eess/1/au:+Nieminen_M/0/1/0/all/0/1">Miika T. Nieminen</a>, <a href="http://arxiv.org/find/eess/1/au:+Saarakkala_S/0/1/0/all/0/1">Simo Saarakkala</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01700">
                                    <div class="article-summary-box-inner">
                                        <span>Objective is to assess the ability of texture features for detecting
radiographic patellofemoral osteoarthritis (PFOA) from knee lateral view
radiographs. We used lateral view knee radiographs from MOST public use
datasets (n &#x3D; 5507 knees). Patellar region-of-interest (ROI) was automatically
detected using landmark detection tool (BoneFinder). Hand-crafted features,
based on LocalBinary Patterns (LBP), were then extracted to describe the
patellar texture. First, a machine learning model (Gradient Boosting Machine)
was trained to detect radiographic PFOA from the LBP features. Furthermore, we
used end-to-end trained deep convolutional neural networks (CNNs) directly on
the texture patches for detecting the PFOA. The proposed classification models
were eventually compared with more conventional reference models that use
clinical assessments and participant characteristics such as age, sex, body
mass index(BMI), the total WOMAC score, and tibiofemoral Kellgren-Lawrence (KL)
grade. Atlas-guided visual assessment of PFOA status by expert readers provided
in the MOST public use datasets was used as a classification outcome for the
models. Performance of prediction models was assessed using the area under the
receiver operating characteristic curve (ROC AUC), the area under the
precision-recall (PR) curve-average precision (AP)-, and Brier score in the
stratified 5-fold cross validation setting.Of the 5507 knees, 953 (17.3%) had
PFOA. AUC and AP for the strongest reference model including age, sex, BMI,
WOMAC score, and tibiofemoral KL grade to predict PFOA were 0.817 and 0.487,
respectively. Textural ROI classification using CNN significantly improved the
prediction performance (ROC AUC&#x3D; 0.889, AP&#x3D; 0.714). We present the first study
that analyses patellar bone texture for diagnosing PFOA. Our results
demonstrates the potential of using texture features of patella to predict
PFOA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Probabilistic Gradient Boosting Machines for Large-Scale Probabilistic Regression. (arXiv:2106.01682v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sprangers_O/0/1/0/all/0/1">Olivier Sprangers</a>, <a href="http://arxiv.org/find/cs/1/au:+Schelter_S/0/1/0/all/0/1">Sebastian Schelter</a>, <a href="http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1">Maarten de Rijke</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01682">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient Boosting Machines (GBM) are hugely popular for solving tabular data
problems. However, practitioners are not only interested in point predictions,
but also in probabilistic predictions in order to quantify the uncertainty of
the predictions. Creating such probabilistic predictions is difficult with
existing GBM-based solutions: they either require training multiple models or
they become too computationally expensive to be useful for large-scale
settings. We propose Probabilistic Gradient Boosting Machines (PGBM), a method
to create probabilistic predictions with a single ensemble of decision trees in
a computationally efficient manner. PGBM approximates the leaf weights in a
decision tree as a random variable, and approximates the mean and variance of
each sample in a dataset via stochastic tree ensemble update equations. These
learned moments allow us to subsequently sample from a specified distribution
after training. We empirically demonstrate the advantages of PGBM compared to
existing state-of-the-art methods: (i) PGBM enables probabilistic estimates
without compromising on point performance in a single model, (ii) PGBM learns
probabilistic estimates via a single model only (and without requiring
multi-parameter boosting), and thereby offers a speedup of up to several orders
of magnitude over existing state-of-the-art methods on large datasets, and
(iii) PGBM achieves accurate probabilistic estimates in tasks with complex
differentiable loss functions, such as hierarchical time series problems, where
we observed up to 10\% improvement in point forecasting performance and up to
300\% improvement in probabilistic forecasting performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can vectors read minds better than experts? Comparing data augmentation strategies for the automated scoring of children&#x27;s mindreading ability. (arXiv:2106.01635v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kovatchev_V/0/1/0/all/0/1">Venelin Kovatchev</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_P/0/1/0/all/0/1">Phillip Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1">Mark Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Devine_R/0/1/0/all/0/1">Rory Devine</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01635">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we implement and compare 7 different data augmentation
strategies for the task of automatic scoring of children&#x27;s ability to
understand others&#x27; thoughts, feelings, and desires (or &quot;mindreading&quot;).

We recruit in-domain experts to re-annotate augmented samples and determine
to what extent each strategy preserves the original rating. We also carry out
multiple experiments to measure how much each augmentation strategy improves
the performance of automatic scoring systems. To determine the capabilities of
automatic systems to generalize to unseen data, we create UK-MIND-20 - a new
corpus of children&#x27;s performance on tests of mindreading, consisting of 10,320
question-answer pairs.

We obtain a new state-of-the-art performance on the MIND-CA corpus, improving
macro-F1-score by 6 points. Results indicate that both the number of training
examples and the quality of the augmentation strategies affect the performance
of the systems. The task-specific augmentations generally outperform
task-agnostic augmentations. Automatic augmentations based on vectors (GloVe,
FastText) perform the worst.

We find that systems trained on MIND-CA generalize well to UK-MIND-20. We
demonstrate that data augmentation strategies also improve the performance on
unseen data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Memorization in Adversarial Training. (arXiv:2106.01606v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yinpeng Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Ke Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1">Xiao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1">Tianyu Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1">Zhijie Deng</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Hang Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01606">
                                    <div class="article-summary-box-inner">
                                        <span>It is well known that deep learning models have a propensity for fitting the
entire training set even with random labels, which requires memorization of
every training sample. In this paper, we investigate the memorization effect in
adversarial training (AT) for promoting a deeper understanding of capacity,
convergence, generalization, and especially robust overfitting of adversarially
trained classifiers. We first demonstrate that deep networks have sufficient
capacity to memorize adversarial examples of training data with completely
random labels, but not all AT algorithms can converge under the extreme
circumstance. Our study of AT with random labels motivates further analyses on
the convergence and generalization of AT. We find that some AT methods suffer
from a gradient instability issue, and the recently suggested complexity
measures cannot explain robust generalization by considering models trained on
random labels. Furthermore, we identify a significant drawback of memorization
in AT that it could result in robust overfitting. We then propose a new
mitigation algorithm motivated by detailed memorization analyses. Extensive
experiments on various datasets validate the effectiveness of the proposed
method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Projection-free Graph-based Classifier Learning using Gershgorin Disc Perfect Alignment. (arXiv:2106.01642v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1">Cheng Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cheung_G/0/1/0/all/0/1">Gene Cheung</a>, <a href="http://arxiv.org/find/cs/1/au:+Tan_W/0/1/0/all/0/1">Wai-tian Tan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01642">
                                    <div class="article-summary-box-inner">
                                        <span>In semi-supervised graph-based binary classifier learning, a subset of known
labels $\hat{x}_i$ are used to infer unknown labels, assuming that the label
signal $x$ is smooth with respect to a similarity graph specified by a
Laplacian matrix. When restricting labels $x_i$ to binary values, the problem
is NP-hard. While a conventional semi-definite programming (SDP) relaxation can
be solved in polynomial time using, for example, the alternating direction
method of multipliers (ADMM), the complexity of iteratively projecting a
candidate matrix $M$ onto the positive semi-definite (PSD) cone ($M \succeq 0$)
remains high. In this paper, leveraging a recent linear algebraic theory called
Gershgorin disc perfect alignment (GDPA), we propose a fast projection-free
method by solving a sequence of linear programs (LP) instead. Specifically, we
first recast the SDP relaxation to its SDP dual, where a feasible solution $H
\succeq 0$ can be interpreted as a Laplacian matrix corresponding to a balanced
signed graph sans the last node. To achieve graph balance, we split the last
node into two that respectively contain the original positive and negative
edges, resulting in a new Laplacian $\bar{H}$. We repose the SDP dual for
solution $\bar{H}$, then replace the PSD cone constraint $\bar{H} \succeq 0$
with linear constraints derived from GDPA -- sufficient conditions to ensure
$\bar{H}$ is PSD -- so that the optimization becomes an LP per iteration.
Finally, we extract predicted labels from our converged LP solution $\bar{H}$.
Experiments show that our algorithm enjoyed a $40\times$ speedup on average
over the next fastest scheme while retaining comparable label prediction
performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NODE-GAM: Neural Generalized Additive Model for Interpretable Deep Learning. (arXiv:2106.01613v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Chun-Hao Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Caruana_R/0/1/0/all/0/1">Rich Caruana</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1">Anna Goldenberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01613">
                                    <div class="article-summary-box-inner">
                                        <span>Deployment of machine learning models in real high-risk settings (e.g.
healthcare) often depends not only on model&#x27;s accuracy but also on its
fairness, robustness and interpretability. Generalized Additive Models (GAMs)
have a long history of use in these high-risk domains, but lack desirable
features of deep learning such as differentiability and scalability. In this
work, we propose a neural GAM (NODE-GAM) and neural GA$^2$M (NODE-GA$^2$M) that
scale well to large datasets, while remaining interpretable and accurate. We
show that our proposed models have comparable accuracy to other
non-interpretable models, and outperform other GAMs on large datasets. We also
show that our models are more accurate in self-supervised learning setting when
access to labeled data is limited.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving the Transferability of Adversarial Examples with New Iteration Framework and Input Dropout. (arXiv:2106.01617v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_P/0/1/0/all/0/1">Pengfei Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Linyuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_R/0/1/0/all/0/1">Ruoxi Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_K/0/1/0/all/0/1">Kai Qiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shuhao Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1">Guoen Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_B/0/1/0/all/0/1">Bin Yan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01617">
                                    <div class="article-summary-box-inner">
                                        <span>Deep neural networks(DNNs) is vulnerable to be attacked by adversarial
examples. Black-box attack is the most threatening attack. At present,
black-box attack methods mainly adopt gradient-based iterative attack methods,
which usually limit the relationship between the iteration step size, the
number of iterations, and the maximum perturbation. In this paper, we propose a
new gradient iteration framework, which redefines the relationship between the
above three. Under this framework, we easily improve the attack success rate of
DI-TI-MIM. In addition, we propose a gradient iterative attack method based on
input dropout, which can be well combined with our framework. We further
propose a multi dropout rate version of this method. Experimental results show
that our best method can achieve attack success rate of 96.2\% for defense
model on average, which is higher than the state-of-the-art gradient-based
attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sleeping Combinatorial Bandits. (arXiv:2106.01624v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abhishek_K/0/1/0/all/0/1">Kumar Abhishek</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghalme_G/0/1/0/all/0/1">Ganesh Ghalme</a>, <a href="http://arxiv.org/find/cs/1/au:+Gujar_S/0/1/0/all/0/1">Sujit Gujar</a>, <a href="http://arxiv.org/find/cs/1/au:+Narahari_Y/0/1/0/all/0/1">Yadati Narahari</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01624">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study an interesting combination of sleeping and
combinatorial stochastic bandits. In the mixed model studied here, at each
discrete time instant, an arbitrary \emph{availability set} is generated from a
fixed set of \emph{base} arms. An algorithm can select a subset of arms from
the \emph{availability set} (sleeping bandits) and receive the corresponding
reward along with semi-bandit feedback (combinatorial bandits).

We adapt the well-known CUCB algorithm in the sleeping combinatorial bandits
setting and refer to it as \CSUCB. We prove -- under mild smoothness conditions
-- that the \CSUCB\ algorithm achieves an $O(\log (T))$ instance-dependent
regret guarantee. We further prove that (i) when the range of the rewards is
bounded, the regret guarantee of \CSUCB\ algorithm is $O(\sqrt{T \log (T)})$
and (ii) the instance-independent regret is $O(\sqrt[3]{T^2 \log(T)})$ in a
general setting. Our results are quite general and hold under general
environments -- such as non-additive reward functions, volatile arm
availability, a variable number of base-arms to be pulled -- arising in
practical applications. We validate the proven theoretical guarantees through
experiments.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JIZHI: A Fast and Cost-Effective Model-As-A-Service System for Web-Scale Online Inference at Baidu. (arXiv:2106.01674v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_Q/0/1/0/all/0/1">Qian Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jiang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1">Xiaochao Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Hao Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_G/0/1/0/all/0/1">Guangxing Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenlin Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Guobao Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zha_Z/0/1/0/all/0/1">Zhiwei Zha</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1">Daxiang Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1">Dejing Dou</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1">Haoyi Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01674">
                                    <div class="article-summary-box-inner">
                                        <span>In modern internet industries, deep learning based recommender systems have
became an indispensable building block for a wide spectrum of applications,
such as search engine, news feed, and short video clips. However, it remains
challenging to carry the well-trained deep models for online real-time
inference serving, with respect to the time-varying web-scale traffics from
billions of users, in a cost-effective manner. In this work, we present JIZHI -
a Model-as-a-Service system - that per second handles hundreds of millions of
online inference requests to huge deep models with more than trillions of
sparse parameters, for over twenty real-time recommendation services at Baidu,
Inc. In JIZHI, the inference workflow of every recommendation request is
transformed to a Staged Event-Driven Pipeline (SEDP), where each node in the
pipeline refers to a staged computation or I/O intensive task processor. With
traffics of real-time inference requests arrived, each modularized processor
can be run in a fully asynchronized way and managed separately. Besides, JIZHI
introduces heterogeneous and hierarchical storage to further accelerate the
online inference process by reducing unnecessary computations and potential
data access latency induced by ultra-sparse model parameters. Moreover, an
intelligent resource manager has been deployed to maximize the throughput of
JIZHI over the shared infrastructure by searching the optimal resource
allocation plan from historical logs and fine-tuning the load shedding policies
over intermediate system feedback. Extensive experiments have been done to
demonstrate the advantages of JIZHI from the perspectives of end-to-end service
latency, system-wide throughput, and resource consumption. JIZHI has helped
Baidu saved more than ten million US dollars in hardware and utility costs
while handling 200% more traffics without sacrificing inference efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Bandit Phase Retrieval. (arXiv:2106.01660v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Lattimore_T/0/1/0/all/0/1">Tor Lattimore</a>, <a href="http://arxiv.org/find/stat/1/au:+Hao_B/0/1/0/all/0/1">Botao Hao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01660">
                                    <div class="article-summary-box-inner">
                                        <span>We study a bandit version of phase retrieval where the learner chooses
actions $(A_t)_{t&#x3D;1}^n$ in the $d$-dimensional unit ball and the expected
reward is $\langle A_t, \theta_\star\rangle^2$ where $\theta_\star \in \mathbb
R^d$ is an unknown parameter vector. We prove that the minimax cumulative
regret in this problem is $\smash{\tilde \Theta(d \sqrt{n})}$, which improves
on the best known bounds by a factor of $\smash{\sqrt{d}}$. We also show that
the minimax simple regret is $\smash{\tilde \Theta(d / \sqrt{n})}$ and that
this is only achievable by an adaptive algorithm. Our analysis shows that an
apparently convincing heuristic for guessing lower bounds can be misleading and
that uniform bounds on the information ratio for information-directed sampling
are not sufficient for optimal regret.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Noisy student-teacher training for robust keyword spotting. (arXiv:2106.01604v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_H/0/1/0/all/0/1">Hyun-Jin Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1">Pai Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Moreno_I/0/1/0/all/0/1">Ignacio Lopez Moreno</a>, <a href="http://arxiv.org/find/cs/1/au:+Subrahmanya_N/0/1/0/all/0/1">Niranjan Subrahmanya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01604">
                                    <div class="article-summary-box-inner">
                                        <span>We propose self-training with noisy student-teacher approach for streaming
keyword spotting, that can utilize large-scale unlabeled data and aggressive
data augmentation. The proposed method applies aggressive data augmentation
(spectral augmentation) on the input of both student and teacher and utilize
unlabeled data at scale, which significantly boosts the accuracy of student
against challenging conditions. Such aggressive augmentation usually degrades
model performance when used with supervised training with hard-labeled data.
Experiments show that aggressive spec augmentation on baseline supervised
training method degrades accuracy, while the proposed self-training with noisy
student-teacher training improves accuracy of some difficult-conditioned test
sets by as much as 60%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cybersecurity Information Exchange with Privacy (CYBEX-P) and TAHOE -- A Cyberthreat Language. (arXiv:2106.01632v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sadique_F/0/1/0/all/0/1">Farhan Sadique</a>, <a href="http://arxiv.org/find/cs/1/au:+Astaburuaga_I/0/1/0/all/0/1">Ignacio Astaburuaga</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaul_R/0/1/0/all/0/1">Raghav Kaul</a>, <a href="http://arxiv.org/find/cs/1/au:+Sengupta_S/0/1/0/all/0/1">Shamik Sengupta</a>, <a href="http://arxiv.org/find/cs/1/au:+Badsha_S/0/1/0/all/0/1">Shahriar Badsha</a>, <a href="http://arxiv.org/find/cs/1/au:+Schnebly_J/0/1/0/all/0/1">James Schnebly</a>, <a href="http://arxiv.org/find/cs/1/au:+Cassell_A/0/1/0/all/0/1">Adam Cassell</a>, <a href="http://arxiv.org/find/cs/1/au:+Springer_J/0/1/0/all/0/1">Jeff Springer</a>, <a href="http://arxiv.org/find/cs/1/au:+Latourrette_N/0/1/0/all/0/1">Nancy Latourrette</a>, <a href="http://arxiv.org/find/cs/1/au:+Dascalu_S/0/1/0/all/0/1">Sergiu M. Dascalu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01632">
                                    <div class="article-summary-box-inner">
                                        <span>Cybersecurity information sharing (CIS) is envisioned to protect
organizations more effectively from advanced cyber attacks. However, a
completely automated CIS platform is not widely adopted. The major challenges
are: (1) the absence of a robust cyber threat language (CTL) and (2) the
concerns over data privacy. This work introduces Cybersecurity Information
Exchangewith Privacy (CYBEX-P), as a CIS framework, to tackle these challenges.
CYBEX-P allows organizations to share heterogeneous data with granular,
attribute based privacy control. It correlates the data to automatically
generate intuitive reports and defensive rules. To achieve such versatility, we
have developed TAHOE - a graph based CTL. TAHOE is a structure for
storing,sharing and analyzing threat data. It also intrinsically correlates the
data. We have further developed a universal Threat Data Query Language (TDQL).
In this paper, we propose the system architecture for CYBEX-P. We then discuss
its scalability and privacy features along with a use case of CYBEX-P providing
Infrastructure as a Service (IaaS). We further introduce TAHOE&amp; TDQL as better
alternatives to existing CTLs and formulate ThreatRank - an algorithm to detect
new malicious even</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Testing Directed Acyclic Graph via Structural, Supervised and Generative Adversarial Learning. (arXiv:2106.01474v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Shi_C/0/1/0/all/0/1">Chengchun Shi</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhou_Y/0/1/0/all/0/1">Yunzhe Zhou</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_L/0/1/0/all/0/1">Lexin Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01474">
                                    <div class="article-summary-box-inner">
                                        <span>In this article, we propose a new hypothesis testing method for directed
acyclic graph (DAG). While there is a rich class of DAG estimation methods,
there is a relative paucity of DAG inference solutions. Moreover, the existing
methods often impose some specific model structures such as linear models or
additive models, and assume independent data observations. Our proposed test
instead allows the associations among the random variables to be nonlinear and
the data to be time-dependent. We build the test based on some highly flexible
neural networks learners. We establish the asymptotic guarantees of the test,
while allowing either the number of subjects or the number of time points for
each subject to diverge to infinity. We demonstrate the efficacy of the test
through simulations and a brain connectivity network analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperbolically-Discounted Reinforcement Learning on Reward-Punishment Framework. (arXiv:2106.01516v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kobayashi_T/0/1/0/all/0/1">Taisuke Kobayashi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01516">
                                    <div class="article-summary-box-inner">
                                        <span>This paper proposes a new reinforcement learning with hyperbolic discounting.
Combining a new temporal difference error with the hyperbolic discounting in
recursive manner and reward-punishment framework, a new scheme to learn the
optimal policy is derived. In simulations, it is found that the proposal
outperforms the standard reinforcement learning, although the performance
depends on the design of reward and punishment. In addition, the averages of
discount factors w.r.t. reward and punishment are different from each other,
like a sign effect in animal behaviors.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Men Are Elected, Women Are Married: Events Gender Bias on Wikipedia. (arXiv:2106.01601v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jiao Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1">Nanyun Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01601">
                                    <div class="article-summary-box-inner">
                                        <span>Human activities can be seen as sequences of events, which are crucial to
understanding societies. Disproportional event distribution for different
demographic groups can manifest and amplify social stereotypes, and potentially
jeopardize the ability of members in some groups to pursue certain goals. In
this paper, we present the first event-centric study of gender biases in a
Wikipedia corpus. To facilitate the study, we curate a corpus of career and
personal life descriptions with demographic information consisting of 7,854
fragments from 10,412 celebrities. Then we detect events with a
state-of-the-art event detection model, calibrate the results using
strategically generated templates, and extract events that have asymmetric
associations with genders. Our study discovers that the Wikipedia pages tend to
intermingle personal life events with professional events for females but not
for males, which calls for the awareness of the Wikipedia community to
formalize guidelines and train the editors to mind the implicit biases that
contributors carry. Our work also lays the foundation for future works on
quantifying and discovering event biases at the corpus level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Discussion On the Validity of Manifold Learning. (arXiv:2106.01608v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1">Dai Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_A/0/1/0/all/0/1">Andi Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yi Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Junbin Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01608">
                                    <div class="article-summary-box-inner">
                                        <span>Dimensionality reduction (DR) and manifold learning (ManL) have been applied
extensively in many machine learning tasks, including signal processing, speech
recognition, and neuroinformatics. However, the understanding of whether DR and
ManL models can generate valid learning results remains unclear. In this work,
we investigate the validity of learning results of some widely used DR and ManL
methods through the chart mapping function of a manifold. We identify a
fundamental problem of these methods: the mapping functions induced by these
methods violate the basic settings of manifolds, and hence they are not
learning manifold in the mathematical sense. To address this problem, we
provide a provably correct algorithm called fixed points Laplacian mapping
(FPLM), that has the geometric guarantee to find a valid manifold
representation (up to a homeomorphism). Combining one additional
condition(orientation preserving), we discuss a sufficient condition for an
algorithm to be bijective for any d-simplex decomposition result on a
d-manifold. However, constructing such a mapping function and its computational
method satisfying these conditions is still an open problem in mathematics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hierarchical Representation Learning for Markov Decision Processes. (arXiv:2106.01655v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Steccanella_L/0/1/0/all/0/1">Lorenzo Steccanella</a>, <a href="http://arxiv.org/find/cs/1/au:+Totaro_S/0/1/0/all/0/1">Simone Totaro</a>, <a href="http://arxiv.org/find/cs/1/au:+Jonsson_A/0/1/0/all/0/1">Anders Jonsson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01655">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we present a novel method for learning hierarchical
representations of Markov decision processes. Our method works by partitioning
the state space into subsets, and defines subtasks for performing transitions
between the partitions. We formulate the problem of partitioning the state
space as an optimization problem that can be solved using gradient descent
given a set of sampled trajectories, making our method suitable for
high-dimensional problems with large state spaces. We empirically validate the
method, by showing that it can successfully learn a useful hierarchical
representation in a navigation domain. Once learned, the hierarchical
representation can be used to solve different tasks in the given domain, thus
generalizing knowledge across tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ZmBART: An Unsupervised Cross-lingual Transfer Framework for Language Generation. (arXiv:2106.01597v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maurya_K/0/1/0/all/0/1">Kaushal Kumar Maurya</a>, <a href="http://arxiv.org/find/cs/1/au:+Desarkar_M/0/1/0/all/0/1">Maunendra Sankar Desarkar</a>, <a href="http://arxiv.org/find/cs/1/au:+Kano_Y/0/1/0/all/0/1">Yoshinobu Kano</a>, <a href="http://arxiv.org/find/cs/1/au:+Deepshikha_K/0/1/0/all/0/1">Kumari Deepshikha</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01597">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the recent advancement in NLP research, cross-lingual transfer for
natural language generation is relatively understudied. In this work, we
transfer supervision from high resource language (HRL) to multiple low-resource
languages (LRLs) for natural language generation (NLG). We consider four NLG
tasks (text summarization, question generation, news headline generation, and
distractor generation) and three syntactically diverse languages, i.e.,
English, Hindi, and Japanese. We propose an unsupervised cross-lingual language
generation framework (called ZmBART) that does not use any parallel or
pseudo-parallel/back-translated data. In this framework, we further pre-train
mBART sequence-to-sequence denoising auto-encoder model with an auxiliary task
using monolingual data of three languages. The objective function of the
auxiliary task is close to the target tasks which enriches the multi-lingual
latent representation of mBART and provides good initialization for target
tasks. Then, this model is fine-tuned with task-specific supervised English
data and directly evaluated with low-resource languages in the Zero-shot
setting. To overcome catastrophic forgetting and spurious correlation issues,
we applied freezing model component and data argumentation approaches
respectively. This simple modeling approach gave us promising results.We
experimented with few-shot training (with 1000 supervised data points) which
boosted the model performance further. We performed several ablations and
cross-lingual transferability analyses to demonstrate the robustness of ZmBART.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention-Guided Supervised Contrastive Learning for Semantic Segmentation. (arXiv:2106.01596v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Ho Hin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1">Yucheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1">Qi Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1">Xin Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_S/0/1/0/all/0/1">Shunxing Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Landman_B/0/1/0/all/0/1">Bennett A. Landman</a>, <a href="http://arxiv.org/find/cs/1/au:+Huo_Y/0/1/0/all/0/1">Yuankai Huo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01596">
                                    <div class="article-summary-box-inner">
                                        <span>Contrastive learning has shown superior performance in embedding global and
spatial invariant features in computer vision (e.g., image classification).
However, its overall success of embedding local and spatial variant features is
still limited, especially for semantic segmentation. In a per-pixel prediction
task, more than one label can exist in a single image for segmentation (e.g.,
an image contains both cat, dog, and grass), thereby it is difficult to define
&#x27;positive&#x27; or &#x27;negative&#x27; pairs in a canonical contrastive learning setting. In
this paper, we propose an attention-guided supervised contrastive learning
approach to highlight a single semantic object every time as the target. With
our design, the same image can be embedded to different semantic clusters with
semantic attention (i.e., coerce semantic masks) as an additional input
channel. To achieve such attention, a novel two-stage training strategy is
presented. We evaluate the proposed method on multi-organ medical image
segmentation task, as our major task, with both in-house data and BTCV 2015
datasets. Comparing with the supervised and semi-supervised training
state-of-the-art in the backbone of ResNet-50, our proposed pipeline yields
substantial improvement of 5.53% and 6.09% in Dice score for both medical image
segmentation cohorts respectively. The performance of the proposed method on
natural images is assessed via PASCAL VOC 2012 dataset, and achieves 2.75%
substantial improvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LLC: Accurate, Multi-purpose Learnt Low-dimensional Binary Codes. (arXiv:2106.01487v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kusupati_A/0/1/0/all/0/1">Aditya Kusupati</a>, <a href="http://arxiv.org/find/cs/1/au:+Wallingford_M/0/1/0/all/0/1">Matthew Wallingford</a>, <a href="http://arxiv.org/find/cs/1/au:+Ramanujan_V/0/1/0/all/0/1">Vivek Ramanujan</a>, <a href="http://arxiv.org/find/cs/1/au:+Somani_R/0/1/0/all/0/1">Raghav Somani</a>, <a href="http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1">Jae Sung Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Pillutla_K/0/1/0/all/0/1">Krishna Pillutla</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1">Prateek Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1">Sham Kakade</a>, <a href="http://arxiv.org/find/cs/1/au:+Farhadi_A/0/1/0/all/0/1">Ali Farhadi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01487">
                                    <div class="article-summary-box-inner">
                                        <span>Learning binary representations of instances and classes is a classical
problem with several high potential applications. In modern settings, the
compression of high-dimensional neural representations to low-dimensional
binary codes is a challenging task and often require large bit-codes to be
accurate. In this work, we propose a novel method for Learning Low-dimensional
binary Codes (LLC) for instances as well as classes. Our method does not
require any side-information, like annotated attributes or label meta-data, and
learns extremely low-dimensional binary codes (~20 bits for ImageNet-1K). The
learnt codes are super-efficient while still ensuring nearly optimal
classification accuracy for ResNet50 on ImageNet-1K. We demonstrate that the
learnt codes capture intrinsically important features in the data, by
discovering an intuitive taxonomy over classes. We further quantitatively
measure the quality of our codes by applying it to the efficient image
retrieval as well as out-of-distribution (OOD) detection problems. For
ImageNet-100 retrieval problem, our learnt binary codes outperform 16 bit
HashNet using only 10 bits and also are as accurate as 10 dimensional real
representations. Finally, our learnt binary codes can perform OOD detection,
out-of-the-box, as accurately as a baseline that needs ~3000 samples to tune
its threshold, while we require none. Code and pre-trained models are available
at https://github.com/RAIVNLab/LLC.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MedNLI Is Not Immune: Natural Language Inference Artifacts in the Clinical Domain. (arXiv:2106.01491v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Herlihy_C/0/1/0/all/0/1">Christine Herlihy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rudinger_R/0/1/0/all/0/1">Rachel Rudinger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01491">
                                    <div class="article-summary-box-inner">
                                        <span>Crowdworker-constructed natural language inference (NLI) datasets have been
found to contain statistical artifacts associated with the annotation process
that allow hypothesis-only classifiers to achieve better-than-random
performance (Poliak et al., 2018; Gururanganet et al., 2018; Tsuchiya, 2018).
We investigate whether MedNLI, a physician-annotated dataset with premises
extracted from clinical notes, contains such artifacts (Romanov and Shivade,
2018). We find that entailed hypotheses contain generic versions of specific
concepts in the premise, as well as modifiers related to responsiveness,
duration, and probability. Neutral hypotheses feature conditions and behaviors
that co-occur with, or cause, the condition(s) in the premise. Contradiction
hypotheses feature explicit negation of the premise and implicit negation via
assertion of good health. Adversarial filtering demonstrates that performance
degrades when evaluated on the difficult subset. We provide partition
information and recommendations for alternative dataset construction strategies
for knowledge-intensive domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-Network Learning with Partially Aligned Graph Convolutional Networks. (arXiv:2106.01583v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_M/0/1/0/all/0/1">Meng Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01583">
                                    <div class="article-summary-box-inner">
                                        <span>Graph neural networks have been widely used for learning representations of
nodes for many downstream tasks on graph data. Existing models were designed
for the nodes on a single graph, which would not be able to utilize information
across multiple graphs. The real world does have multiple graphs where the
nodes are often partially aligned. For examples, knowledge graphs share a
number of named entities though they may have different relation schema;
collaboration networks on publications and awarded projects share some
researcher nodes who are authors and investigators, respectively; people use
multiple web services, shopping, tweeting, rating movies, and some may register
the same email account across the platforms. In this paper, I propose partially
aligned graph convolutional networks to learn node representations across the
models. I investigate multiple methods (including model sharing,
regularization, and alignment reconstruction) as well as theoretical analysis
to positively transfer knowledge across the (small) set of partially aligned
nodes. Extensive experiments on real-world knowledge graphs and collaboration
networks show the superior performance of our proposed methods on relation
classification and link prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimization of Heterogeneous Systems with AI Planning Heuristics and Machine Learning: A Performance and Energy Aware Approach. (arXiv:2106.01441v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Memeti_S/0/1/0/all/0/1">Suejb Memeti</a>, <a href="http://arxiv.org/find/cs/1/au:+Pllana_S/0/1/0/all/0/1">Sabri Pllana</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01441">
                                    <div class="article-summary-box-inner">
                                        <span>Heterogeneous computing systems provide high performance and energy
efficiency. However, to optimally utilize such systems, solutions that
distribute the work across host CPUs and accelerating devices are needed. In
this paper, we present a performance and energy aware approach that combines AI
planning heuristics for parameter space exploration with a machine learning
model for performance and energy evaluation to determine a near-optimal system
configuration. For data-parallel applications our approach determines a
near-optimal host-device distribution of work, number of processing units
required and the corresponding scheduling strategy. We evaluate our approach
for various heterogeneous systems accelerated with GPU or the Intel Xeon Phi.
The experimental results demonstrate that our approach finds a near-optimal
system configuration by evaluating only about 7% of reasonable configurations.
Furthermore, the performance per Joule estimation of system configurations
using our machine learning model is more than 1000x faster compared to the
system evaluation by program execution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Not All Knowledge Is Created Equal. (arXiv:2106.01489v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziyun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinshao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Haojin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_D/0/1/0/all/0/1">Di Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Robertson_N/0/1/0/all/0/1">Neil M. Robertson</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1">David A. Clifton</a>, <a href="http://arxiv.org/find/cs/1/au:+Meinel_C/0/1/0/all/0/1">Christoph Meinel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01489">
                                    <div class="article-summary-box-inner">
                                        <span>Mutual knowledge distillation (MKD) improves a model by distilling knowledge
from another model. However, not all knowledge is certain and correct,
especially under adverse conditions. For example, label noise usually leads to
less reliable models due to the undesired memorisation [1, 2]. Wrong knowledge
misleads the learning rather than helps. This problem can be handled by two
aspects: (i) improving the reliability of a model where the knowledge is from
(i.e., knowledge source&#x27;s reliability); (ii) selecting reliable knowledge for
distillation. In the literature, making a model more reliable is widely studied
while selective MKD receives little attention. Therefore, we focus on studying
selective MKD and highlight its importance in this work.

Concretely, a generic MKD framework, Confident knowledge selection followed
by Mutual Distillation (CMD), is designed. The key component of CMD is a
generic knowledge selection formulation, making the selection threshold either
static (CMD-S) or progressive (CMD-P). Additionally, CMD covers two special
cases: zero knowledge and all knowledge, leading to a unified MKD framework. We
empirically find CMD-P performs better than CMD-S. The main reason is that a
model&#x27;s knowledge upgrades and becomes confident as the training progresses.

Extensive experiments are present to demonstrate the effectiveness of CMD and
thoroughly justify the design of CMD. For example, CMD-P obtains new
state-of-the-art results in robustness against label noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Transformers are Deep Infinite-Dimensional Non-Mercer Binary Kernel Machines. (arXiv:2106.01506v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wright_M/0/1/0/all/0/1">Matthew A. Wright</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1">Joseph E. Gonzalez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01506">
                                    <div class="article-summary-box-inner">
                                        <span>Despite their ubiquity in core AI fields like natural language processing,
the mechanics of deep attention-based neural networks like the Transformer
model are not fully understood. In this article, we present a new perspective
towards understanding how Transformers work. In particular, we show that the
&quot;dot-product attention&quot; that is the core of the Transformer&#x27;s operation can be
characterized as a kernel learning method on a pair of Banach spaces. In
particular, the Transformer&#x27;s kernel is characterized as having an infinite
feature dimension. Along the way we consider an extension of the standard
kernel learning problem to a binary setting, where data come from two input
domains and a response is defined for every cross-domain pair. We prove a new
representer theorem for these binary kernel machines with non-Mercer
(indefinite, asymmetric) kernels (implying that the functions learned are
elements of reproducing kernel Banach spaces rather than Hilbert spaces), and
also prove a new universal approximation theorem showing that the Transformer
calculation can learn any binary non-Mercer reproducing kernel Banach space
pair. We experiment with new kernels in Transformers, and obtain results that
suggest the infinite dimensionality of the standard Transformer kernel is
partially responsible for its performance. This paper&#x27;s results provide a new
theoretical understanding of a very important but poorly understood model in
modern machine~learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Luna: Linear Unified Nested Attention. (arXiv:2106.01540v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xuezhe Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_X/0/1/0/all/0/1">Xiang Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1">Sinong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chunting Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1">Hao Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1">Luke Zettlemoyer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01540">
                                    <div class="article-summary-box-inner">
                                        <span>The quadratic computational and memory complexities of the Transformer&#x27;s
attention mechanism have limited its scalability for modeling long sequences.
In this paper, we propose Luna, a linear unified nested attention mechanism
that approximates softmax attention with two nested linear attention functions,
yielding only linear (as opposed to quadratic) time and space complexity.
Specifically, with the first attention function, Luna packs the input sequence
into a sequence of fixed length. Then, the packed sequence is unpacked using
the second attention function. As compared to a more traditional attention
mechanism, Luna introduces an additional sequence with a fixed length as input
and an additional corresponding output, which allows Luna to perform attention
operation linearly, while also storing adequate contextual information. We
perform extensive evaluations on three benchmarks of sequence modeling tasks:
long-context sequence modeling, neural machine translation and masked language
modeling for large-scale pretraining. Competitive or even better experimental
results demonstrate both the effectiveness and efficiency of Luna compared to a
variety</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Question Answering Over Temporal Knowledge Graphs. (arXiv:2106.01515v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saxena_A/0/1/0/all/0/1">Apoorv Saxena</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarti_S/0/1/0/all/0/1">Soumen Chakrabarti</a>, <a href="http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1">Partha Talukdar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01515">
                                    <div class="article-summary-box-inner">
                                        <span>Temporal Knowledge Graphs (Temporal KGs) extend regular Knowledge Graphs by
providing temporal scopes (start and end times) on each edge in the KG. While
Question Answering over KG (KGQA) has received some attention from the research
community, QA over Temporal KGs (Temporal KGQA) is a relatively unexplored
area. Lack of broad coverage datasets has been another factor limiting progress
in this area. We address this challenge by presenting CRONQUESTIONS, the
largest known Temporal KGQA dataset, clearly stratified into buckets of
structural complexity. CRONQUESTIONS expands the only known previous dataset by
a factor of 340x. We find that various state-of-the-art KGQA methods fall far
short of the desired performance on this new dataset. In response, we also
propose CRONKGQA, a transformer-based solution that exploits recent advances in
Temporal KG embeddings, and achieves performance superior to all baselines,
with an increase of 120% in accuracy over the next best performing method.
Through extensive experiments, we give detailed insights into the workings of
CRONKGQA, as well as situations where significant further improvements appear
possible. In addition to the dataset, we have released our code as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SIMLR: Machine Learning inside the SIR model for COVID-19 Forecasting. (arXiv:2106.01590v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vega_R/0/1/0/all/0/1">Roberto Vega</a>, <a href="http://arxiv.org/find/cs/1/au:+Flores_L/0/1/0/all/0/1">Leonardo Flores</a>, <a href="http://arxiv.org/find/cs/1/au:+Greiner_R/0/1/0/all/0/1">Russell Greiner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01590">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate forecasts of the number of newly infected people during an epidemic
are critical for making effective timely decisions. This paper addresses this
challenge using the SIMLR model, which incorporates machine learning (ML) into
the epidemiological SIR model. For each region, SIMLR tracks the changes in the
policies implemented at the government level, which it uses to estimate the
time-varying parameters of an SIR model for forecasting the number of new
infections 1- to 4-weeks in advance.It also forecasts the probability of
changes in those government policies at each of these future times, which is
essential for the longer-range forecasts. We applied SIMLR to data from regions
in Canada and in the United States,and show that its MAPE (mean average
percentage error) performance is as good as SOTA forecasting models, with the
added advantage of being an interpretable model. We expect that this approach
will be useful not only for forecasting COVID-19 infections, but also in
predicting the evolution of other infectious diseases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Limitations of Limited Context for Constituency Parsing. (arXiv:2106.01580v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuchen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1">Andrej Risteski</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01580">
                                    <div class="article-summary-box-inner">
                                        <span>Incorporating syntax into neural approaches in NLP has a multitude of
practical and scientific benefits. For instance, a language model that is
syntax-aware is likely to be able to produce better samples; even a
discriminative model like BERT with a syntax module could be used for core NLP
tasks like unsupervised syntactic parsing. Rapid progress in recent years was
arguably spurred on by the empirical success of the Parsing-Reading-Predict
architecture of (Shen et al., 2018a), later simplified by the Order Neuron LSTM
of (Shen et al., 2019). Most notably, this is the first time neural approaches
were able to successfully perform unsupervised syntactic parsing (evaluated by
various metrics like F-1 score).

However, even heuristic (much less fully mathematical) understanding of why
and when these architectures work is lagging severely behind. In this work, we
answer representational questions raised by the architectures in (Shen et al.,
2018a, 2019), as well as some transition-based syntax-aware language models
(Dyer et al., 2016): what kind of syntactic structure can current neural
approaches to syntax represent? Concretely, we ground this question in the
sandbox of probabilistic context-free-grammars (PCFGs), and identify a key
aspect of the representational power of these approaches: the amount and
directionality of context that the predictor has access to when forced to make
parsing decision. We show that with limited context (either bounded, or
unidirectional), there are PCFGs, for which these approaches cannot represent
the max-likelihood parse; conversely, if the context is unlimited, they can
represent the max-likelihood parse of any PCFG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Gradient Assisted Learning. (arXiv:2106.01425v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diao_E/0/1/0/all/0/1">Enmao Diao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1">Jie Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1">Vahid Tarokh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01425">
                                    <div class="article-summary-box-inner">
                                        <span>In distributed settings, collaborations between different entities, such as
financial institutions, medical centers, and retail markets, are crucial to
providing improved service and performance. However, the underlying entities
may have little interest in sharing their private data, proprietary models, and
objective functions. These privacy requirements have created new challenges for
collaboration. In this work, we propose Gradient Assisted Learning (GAL), a new
method for various entities to assist each other in supervised learning tasks
without sharing data, models, and objective functions. In this framework, all
participants collaboratively optimize the aggregate of local loss functions,
and each participant autonomously builds its own model by iteratively fitting
the gradients of the objective function. Experimental studies demonstrate that
Gradient Assisted Learning can achieve performance close to centralized
learning when all data, models, and objective functions are fully disclosed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Systematic Investigation of KB-Text Embedding Alignment at Scale. (arXiv:2106.01586v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1">Vardaan Pahuja</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1">Yu Gu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wenhu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Bahrami_M/0/1/0/all/0/1">Mehdi Bahrami</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1">Wei-Peng Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yu Su</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01586">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge bases (KBs) and text often contain complementary knowledge: KBs
store structured knowledge that can support long range reasoning, while text
stores more comprehensive and timely knowledge in an unstructured way.
Separately embedding the individual knowledge sources into vector spaces has
demonstrated tremendous successes in encoding the respective knowledge, but how
to jointly embed and reason with both knowledge sources to fully leverage the
complementary information is still largely an open problem. We conduct a
large-scale, systematic investigation of aligning KB and text embeddings for
joint reasoning. We set up a novel evaluation framework with two evaluation
tasks, few-shot link prediction and analogical reasoning, and evaluate an array
of KB-text embedding alignment methods. We also demonstrate how such alignment
can infuse textual information into KB embeddings for more accurate link
prediction on emerging entities and events, using COVID-19 as a case study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IoT Solutions with Multi-Sensor Fusion and Signal-Image Encoding for Secure Data Transfer and Decision Making. (arXiv:2106.01497v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sharma_P/0/1/0/all/0/1">Piyush K. Sharma</a>, <a href="http://arxiv.org/find/eess/1/au:+Dennison_M/0/1/0/all/0/1">Mark Dennison</a>, <a href="http://arxiv.org/find/eess/1/au:+Raglin_A/0/1/0/all/0/1">Adrienne Raglin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01497">
                                    <div class="article-summary-box-inner">
                                        <span>Deployment of Internet of Things (IoT) devices and Data Fusion techniques
have gained popularity in public and government domains. This usually requires
capturing and consolidating data from multiple sources. As datasets do not
necessarily originate from identical sensors, fused data typically results in a
complex data problem. Because military is investigating how heterogeneous IoT
devices can aid processes and tasks, we investigate a multi-sensor approach.
Moreover, we propose a signal to image encoding approach to transform
information (signal) to integrate (fuse) data from IoT wearable devices to an
image which is invertible and easier to visualize supporting decision making.
Furthermore, we investigate the challenge of enabling an intelligent
identification and detection operation and demonstrate the feasibility of the
proposed Deep Learning and Anomaly Detection models that can support future
application that utilizes hand gesture data from wearable devices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When Vision Transformers Outperform ResNets without Pretraining or Strong Data Augmentations. (arXiv:2106.01548v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiangning Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1">Cho-Jui Hsieh</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1">Boqing Gong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01548">
                                    <div class="article-summary-box-inner">
                                        <span>Vision Transformers (ViTs) and MLPs signal further efforts on replacing
hand-wired features or inductive biases with general-purpose neural
architectures. Existing works empower the models by massive data, such as
large-scale pretraining and/or repeated strong data augmentations, and still
report optimization-related problems (e.g., sensitivity to initialization and
learning rate). Hence, this paper investigates ViTs and MLP-Mixers from the
lens of loss geometry, intending to improve the models&#x27; data efficiency at
training and generalization at inference. Visualization and Hessian reveal
extremely sharp local minima of converged models. By promoting smoothness with
a recently proposed sharpness-aware optimizer, we substantially improve the
accuracy and robustness of ViTs and MLP-Mixers on various tasks spanning
supervised, adversarial, contrastive, and transfer learning (e.g., +5.3\% and
+11.0\% top-1 accuracy on ImageNet for ViT-B/16 and Mixer-B/16, respectively,
with the simple Inception-style preprocessing). We show that the improved
smoothness attributes to sparser active neurons in the first few layers. The
resultant ViTs outperform ResNets of similar size and throughput when trained
from scratch on ImageNet without large-scale pretraining or strong data
augmentations. They also possess more perceptive attention maps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ember: No-Code Context Enrichment via Similarity-Based Keyless Joins. (arXiv:2106.01501v1 [cs.DB])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Suri_S/0/1/0/all/0/1">Sahaana Suri</a>, <a href="http://arxiv.org/find/cs/1/au:+Ilyas_I/0/1/0/all/0/1">Ihab F. Ilyas</a>, <a href="http://arxiv.org/find/cs/1/au:+Re_C/0/1/0/all/0/1">Christopher R&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Rekatsinas_T/0/1/0/all/0/1">Theodoros Rekatsinas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01501">
                                    <div class="article-summary-box-inner">
                                        <span>Structured data, or data that adheres to a pre-defined schema, can suffer
from fragmented context: information describing a single entity can be
scattered across multiple datasets or tables tailored for specific business
needs, with no explicit linking keys (e.g., primary key-foreign key
relationships or heuristic functions). Context enrichment, or rebuilding
fragmented context, using keyless joins is an implicit or explicit step in
machine learning (ML) pipelines over structured data sources. This process is
tedious, domain-specific, and lacks support in now-prevalent no-code ML systems
that let users create ML pipelines using just input data and high-level
configuration files. In response, we propose Ember, a system that abstracts and
automates keyless joins to generalize context enrichment. Our key insight is
that Ember can enable a general keyless join operator by constructing an index
populated with task-specific embeddings. Ember learns these embeddings by
leveraging Transformer-based representation learning techniques. We describe
our core architectural principles and operators when developing Ember, and
empirically demonstrate that Ember allows users to develop no-code pipelines
for five domains, including search, recommendation and question answering, and
can exceed alternatives by up to 39% recall, with as little as a single line
configuration change.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weakly Supervised Learning Creates a Fusion of Modeling Cultures. (arXiv:2106.01485v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Tang_C/0/1/0/all/0/1">Chengliang Tang</a>, <a href="http://arxiv.org/find/stat/1/au:+Yuan_G/0/1/0/all/0/1">Gan Yuan</a>, <a href="http://arxiv.org/find/stat/1/au:+Zheng_T/0/1/0/all/0/1">Tian Zheng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01485">
                                    <div class="article-summary-box-inner">
                                        <span>The past two decades have witnessed the great success of the algorithmic
modeling framework advocated by Breiman et al. (2001). Nevertheless, the
excellent prediction performance of these black-box models rely heavily on the
availability of strong supervision, i.e. a large set of accurate and exact
ground-truth labels. In practice, strong supervision can be unavailable or
expensive, which calls for modeling techniques under weak supervision. In this
comment, we summarize the key concepts in weakly supervised learning and
discuss some recent developments in the field. Using algorithmic modeling alone
under a weak supervision might lead to unstable and misleading results. A
promising direction would be integrating the data modeling culture into such a
framework.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Normalizing Flows for Knockoff-free Controlled Feature Selection. (arXiv:2106.01528v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Hansen_D/0/1/0/all/0/1">Derek Hansen</a>, <a href="http://arxiv.org/find/stat/1/au:+Manzo_B/0/1/0/all/0/1">Brian Manzo</a>, <a href="http://arxiv.org/find/stat/1/au:+Regier_J/0/1/0/all/0/1">Jeffrey Regier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01528">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of controlled feature selection is to discover the features a
response depends on while limiting the proportion of false discoveries to a
predefined level. Recently, multiple methods have been proposed that use deep
learning to generate knockoffs for controlled feature selection through the
Model-X knockoff framework. We demonstrate, however, that these methods often
fail to control the false discovery rate (FDR). There are two reasons for this
shortcoming. First, these methods often learn inaccurate models of features.
Second, the &quot;swap&quot; property, which is required for knockoffs to be valid, is
often not well enforced. We propose a new procedure called FlowSelect that
remedies both of these problems. To more accurately model the features,
FlowSelect uses normalizing flows, the state-of-the-art method for density
estimation. To circumvent the need to enforce the swap property, FlowSelect
uses a novel MCMC-based procedure to directly compute p-values for each
feature. Asymptotically, FlowSelect controls the FDR exactly. Empirically,
FlowSelect controls the FDR well on both synthetic and semi-synthetic
benchmarks, whereas competing knockoff-based approaches fail to do so.
FlowSelect also demonstrates greater power on these benchmarks. Additionally,
using data from a genome-wide association study of soybeans, FlowSelect
correctly infers the genetic variants associated with specific soybean traits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inferring Black Hole Properties from Astronomical Multivariate Time Series with Bayesian Attentive Neural Processes. (arXiv:2106.01450v1 [astro-ph.IM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Park_J/0/1/0/all/0/1">Ji Won Park</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Villar_A/0/1/0/all/0/1">Ashley Villar</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Li_Y/0/1/0/all/0/1">Yin Li</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Jiang_Y/0/1/0/all/0/1">Yan-Fei Jiang</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1">Shirley Ho</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Lin_J/0/1/0/all/0/1">Joshua Yao-Yu Lin</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Marshall_P/0/1/0/all/0/1">Philip J. Marshall</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Roodman_A/0/1/0/all/0/1">Aaron Roodman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01450">
                                    <div class="article-summary-box-inner">
                                        <span>Among the most extreme objects in the Universe, active galactic nuclei (AGN)
are luminous centers of galaxies where a black hole feeds on surrounding
matter. The variability patterns of the light emitted by an AGN contain
information about the physical properties of the underlying black hole.
Upcoming telescopes will observe over 100 million AGN in multiple broadband
wavelengths, yielding a large sample of multivariate time series with long gaps
and irregular sampling. We present a method that reconstructs the AGN time
series and simultaneously infers the posterior probability density distribution
(PDF) over the physical quantities of the black hole, including its mass and
luminosity. We apply this method to a simulated dataset of 11,000 AGN and
report precision and accuracy of 0.4 dex and 0.3 dex in the inferred black hole
mass. This work is the first to address probabilistic time series
reconstruction and parameter inference for AGN in an end-to-end fashion.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimax Optimization with Smooth Algorithmic Adversaries. (arXiv:2106.01488v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fiez_T/0/1/0/all/0/1">Tanner Fiez</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1">Chi Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1">Praneeth Netrapalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Ratliff_L/0/1/0/all/0/1">Lillian J. Ratliff</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01488">
                                    <div class="article-summary-box-inner">
                                        <span>This paper considers minimax optimization $\min_x \max_y f(x, y)$ in the
challenging setting where $f$ can be both nonconvex in $x$ and nonconcave in
$y$. Though such optimization problems arise in many machine learning paradigms
including training generative adversarial networks (GANs) and adversarially
robust models, many fundamental issues remain in theory, such as the absence of
efficiently computable optimality notions, and cyclic or diverging behavior of
existing algorithms. Our framework sprouts from the practical consideration
that under a computational budget, the max-player can not fully maximize
$f(x,\cdot)$ since nonconcave maximization is NP-hard in general. So, we
propose a new algorithm for the min-player to play against smooth algorithms
deployed by the adversary (i.e., the max-player) instead of against full
maximization. Our algorithm is guaranteed to make monotonic progress (thus
having no limit cycles), and to find an appropriate &quot;stationary point&quot; in a
polynomial number of iterations. Our framework covers practical settings where
the smooth algorithms deployed by the adversary are multi-step stochastic
gradient ascent, and its accelerated version. We further provide complementing
experiments that confirm our theoretical findings and demonstrate the
effectiveness of the proposed approach in practice.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Ethical-Advice Taker: Do Language Models Understand Natural Language Interventions?. (arXiv:2106.01465v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1">Jieyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Khashabi_D/0/1/0/all/0/1">Daniel Khashabi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khot_T/0/1/0/all/0/1">Tushar Khot</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabharwal_A/0/1/0/all/0/1">Ashish Sabharwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1">Kai-Wei Chang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01465">
                                    <div class="article-summary-box-inner">
                                        <span>Is it possible to use natural language to intervene in a model&#x27;s behavior and
alter its prediction in a desired way? We investigate the effectiveness of
natural language interventions for reading-comprehension systems, studying this
in the context of social stereotypes. Specifically, we propose a new language
understanding task, Linguistic Ethical Interventions (LEI), where the goal is
to amend a question-answering (QA) model&#x27;s unethical behavior by communicating
context-specific principles of ethics and equity to it. To this end, we build
upon recent methods for quantifying a system&#x27;s social stereotypes, augmenting
them with different kinds of ethical interventions and the desired model
behavior under such interventions. Our zero-shot evaluation finds that even
today&#x27;s powerful neural language models are extremely poor ethical-advice
takers, that is, they respond surprisingly little to ethical interventions even
though these interventions are stated as simple sentences. Few-shot learning
improves model behavior but remains far from the desired outcome, especially
when evaluated for various types of generalization. Our new task thus poses a
novel language understanding challenge for the community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Memory Wrap: a Data-Efficient and Interpretable Extension to Image Classification Models. (arXiv:2106.01440v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosa_B/0/1/0/all/0/1">Biagio La Rosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Capobianco_R/0/1/0/all/0/1">Roberto Capobianco</a>, <a href="http://arxiv.org/find/cs/1/au:+Nardi_D/0/1/0/all/0/1">Daniele Nardi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01440">
                                    <div class="article-summary-box-inner">
                                        <span>Due to their black-box and data-hungry nature, deep learning techniques are
not yet widely adopted for real-world applications in critical domains, like
healthcare and justice. This paper presents Memory Wrap, a plug-and-play
extension to any image classification model. Memory Wrap improves both
data-efficiency and model interpretability, adopting a content-attention
mechanism between the input and some memories of past training samples. We show
that Memory Wrap outperforms standard classifiers when it learns from a limited
set of data, and it reaches comparable performance when it learns from the full
dataset. We discuss how its structure and content-attention mechanisms make
predictions interpretable, compared to standard classifiers. To this end, we
both show a method to build explanations by examples and counterfactuals, based
on the memory content, and how to exploit them to get insights about its
decision process. We test our approach on image classification tasks using
several architectures on three different datasets, namely CIFAR10, SVHN, and
CINIC10.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BERT-Defense: A Probabilistic Model Based on BERT to Combat Cognitively Inspired Orthographic Adversarial Attacks. (arXiv:2106.01452v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Keller_Y/0/1/0/all/0/1">Yannik Keller</a>, <a href="http://arxiv.org/find/cs/1/au:+Mackensen_J/0/1/0/all/0/1">Jan Mackensen</a>, <a href="http://arxiv.org/find/cs/1/au:+Eger_S/0/1/0/all/0/1">Steffen Eger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01452">
                                    <div class="article-summary-box-inner">
                                        <span>Adversarial attacks expose important blind spots of deep learning systems.
While word- and sentence-level attack scenarios mostly deal with finding
semantic paraphrases of the input that fool NLP models, character-level attacks
typically insert typos into the input stream. It is commonly thought that these
are easier to defend via spelling correction modules. In this work, we show
that both a standard spellchecker and the approach of Pruthi et al. (2019),
which trains to defend against insertions, deletions and swaps, perform poorly
on the character-level benchmark recently proposed in Eger and Benz (2020)
which includes more challenging attacks such as visual and phonetic
perturbations and missing word segmentations. In contrast, we show that an
untrained iterative approach which combines context-independent character-level
information with context-dependent information from BERT&#x27;s masked language
modeling can perform on par with human crowd-workers from Amazon Mechanical
Turk (AMT) supervised via 3-shot learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parallelizing Thompson Sampling. (arXiv:2106.01420v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Karbasi_A/0/1/0/all/0/1">Amin Karbasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mirrokni_V/0/1/0/all/0/1">Vahab Mirrokni</a>, <a href="http://arxiv.org/find/cs/1/au:+Shadravan_M/0/1/0/all/0/1">Mohammad Shadravan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01420">
                                    <div class="article-summary-box-inner">
                                        <span>How can we make use of information parallelism in online decision making
problems while efficiently balancing the exploration-exploitation trade-off? In
this paper, we introduce a batch Thompson Sampling framework for two canonical
online decision making problems, namely, stochastic multi-arm bandit and linear
contextual bandit with finitely many arms. Over a time horizon $T$, our
\textit{batch} Thompson Sampling policy achieves the same (asymptotic) regret
bound of a fully sequential one while carrying out only $O(\log T)$ batch
queries. To achieve this exponential reduction, i.e., reducing the number of
interactions from $T$ to $O(\log T)$, our batch policy dynamically determines
the duration of each batch in order to balance the exploration-exploitation
trade-off. We also demonstrate experimentally that dynamic batch allocation
dramatically outperforms natural baselines such as static batch allocations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Smooth Bilevel Programming for Sparse Regularization. (arXiv:2106.01429v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Poon_C/0/1/0/all/0/1">Clarice Poon</a>, <a href="http://arxiv.org/find/stat/1/au:+Peyre_G/0/1/0/all/0/1">Gabriel Peyr&#xe9;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01429">
                                    <div class="article-summary-box-inner">
                                        <span>Iteratively reweighted least square (IRLS) is a popular approach to solve
sparsity-enforcing regression problems in machine learning. State of the art
approaches are more efficient but typically rely on specific coordinate pruning
schemes. In this work, we show how a surprisingly simple reparametrization of
IRLS, coupled with a bilevel resolution (instead of an alternating scheme) is
able to achieve top performances on a wide range of sparsity (such as Lasso,
group Lasso and trace norm regularizations), regularization strength (including
hard constraints), and design matrices (ranging from correlated designs to
differential operators). Similarly to IRLS, our method only involves linear
systems resolutions, but in sharp contrast, corresponds to the minimization of
a smooth function. Despite being non-convex, we show that there is no spurious
minima and that saddle points are &quot;ridable&quot;, so that there always exists a
descent direction. We thus advocate for the use of a BFGS quasi-Newton solver,
which makes our approach simple, robust and efficient. We perform a numerical
benchmark of the convergence speed of our algorithm against state of the art
solvers for Lasso, group Lasso, trace norm and linearly constrained problems.
These results highlight the versatility of our approach, removing the need to
use different solvers depending on the specificity of the ML problem under
study.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SemiFL: Communication Efficient Semi-Supervised Federated Learning with Unlabeled Clients. (arXiv:2106.01432v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Diao_E/0/1/0/all/0/1">Enmao Diao</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1">Jie Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Tarokh_V/0/1/0/all/0/1">Vahid Tarokh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01432">
                                    <div class="article-summary-box-inner">
                                        <span>Federated Learning allows training machine learning models by using the
computation and private data resources of a large number of distributed clients
such as smartphones and IoT devices. Most existing works on Federated Learning
(FL) assume the clients have ground-truth labels. However, in many practical
scenarios, clients may be unable to label task-specific data, e.g., due to lack
of expertise. In this work, we consider a server that hosts a labeled dataset,
and wishes to leverage clients with unlabeled data for supervised learning. We
propose a new Federated Learning framework referred to as SemiFL in order to
address the problem of Semi-Supervised Federated Learning (SSFL). In SemiFL,
clients have completely unlabeled data, while the server has a small amount of
labeled data. SemiFL is communication efficient since it separates the training
of server-side supervised data and client-side unsupervised data. We
demonstrate various efficient strategies of SemiFL that enhance learning
performance. Extensive empirical evaluations demonstrate that our communication
efficient method can significantly improve the performance of a labeled server
with unlabeled clients. Moreover, we demonstrate that SemiFL can outperform
many existing FL results trained with fully supervised data, and perform
competitively with the state-of-the-art centralized Semi-Supervised Learning
(SSL) methods. For instance, in standard communication efficient scenarios, our
method can perform 93% accuracy on the CIFAR10 dataset with only 4000 labeled
samples at the server. Such accuracy is only 2% away from the result trained
from 50000 fully labeled data, and it improves about 30% upon existing SSFL
methods in the communication efficient setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour. (arXiv:2106.01434v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bian_X/0/1/0/all/0/1">Xihan Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Mendez_O/0/1/0/all/0/1">Oscar Mendez</a>, <a href="http://arxiv.org/find/cs/1/au:+Hadfield_S/0/1/0/all/0/1">Simon Hadfield</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01434">
                                    <div class="article-summary-box-inner">
                                        <span>Robots need to be able to work in multiple different environments. Even when
performing similar tasks, different behaviour should be deployed to best fit
the current environment. In this paper, We propose a new approach to
navigation, where it is treated as a multi-task learning problem. This enables
the robot to learn to behave differently in visual navigation tasks for
different environments while also learning shared expertise across
environments. We evaluated our approach in both simulated environments as well
as real-world data. Our method allows our system to converge with a 26%
reduction in training time, while also increasing accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One Representation to Rule Them All: Identifying Out-of-Support Examples in Few-shot Learning with Generic Representations. (arXiv:2106.01423v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kvinge_H/0/1/0/all/0/1">Henry Kvinge</a>, <a href="http://arxiv.org/find/cs/1/au:+Howland_S/0/1/0/all/0/1">Scott Howland</a>, <a href="http://arxiv.org/find/cs/1/au:+Courts_N/0/1/0/all/0/1">Nico Courts</a>, <a href="http://arxiv.org/find/cs/1/au:+Phillips_L/0/1/0/all/0/1">Lauren A. Phillips</a>, <a href="http://arxiv.org/find/cs/1/au:+Buckheit_J/0/1/0/all/0/1">John Buckheit</a>, <a href="http://arxiv.org/find/cs/1/au:+New_Z/0/1/0/all/0/1">Zachary New</a>, <a href="http://arxiv.org/find/cs/1/au:+Skomski_E/0/1/0/all/0/1">Elliott Skomski</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jung H. Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Tiwari_S/0/1/0/all/0/1">Sandeep Tiwari</a>, <a href="http://arxiv.org/find/cs/1/au:+Hibler_J/0/1/0/all/0/1">Jessica Hibler</a>, <a href="http://arxiv.org/find/cs/1/au:+Corley_C/0/1/0/all/0/1">Courtney D. Corley</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodas_N/0/1/0/all/0/1">Nathan O. Hodas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01423">
                                    <div class="article-summary-box-inner">
                                        <span>The field of few-shot learning has made remarkable strides in developing
powerful models that can operate in the small data regime. Nearly all of these
methods assume every unlabeled instance encountered will belong to a handful of
known classes for which one has examples. This can be problematic for
real-world use cases where one routinely finds &#x27;none-of-the-above&#x27; examples. In
this paper we describe this challenge of identifying what we term
&#x27;out-of-support&#x27; (OOS) examples. We describe how this problem is subtly
different from out-of-distribution detection and describe a new method of
identifying OOS examples within the Prototypical Networks framework using a
fixed point which we call the generic representation. We show that our method
outperforms other existing approaches in the literature as well as other
approaches that we propose in this paper. Finally, we investigate how the use
of such a generic point affects the geometry of a model&#x27;s feature space.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rectangular Flows for Manifold Learning. (arXiv:2106.01413v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Caterini_A/0/1/0/all/0/1">Anthony L. Caterini</a>, <a href="http://arxiv.org/find/stat/1/au:+Loaiza_Ganem_G/0/1/0/all/0/1">Gabriel Loaiza-Ganem</a>, <a href="http://arxiv.org/find/stat/1/au:+Pleiss_G/0/1/0/all/0/1">Geoff Pleiss</a>, <a href="http://arxiv.org/find/stat/1/au:+Cunningham_J/0/1/0/all/0/1">John P. Cunningham</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01413">
                                    <div class="article-summary-box-inner">
                                        <span>Normalizing flows are invertible neural networks with tractable
change-of-volume terms, which allows optimization of their parameters to be
efficiently performed via maximum likelihood. However, data of interest is
typically assumed to live in some (often unknown) low-dimensional manifold
embedded in high-dimensional ambient space. The result is a modelling mismatch
since -- by construction -- the invertibility requirement implies
high-dimensional support of the learned distribution. Injective flows, mapping
from low- to high-dimensional space, aim to fix this discrepancy by learning
distributions on manifolds, but the resulting volume-change term becomes more
challenging to evaluate. Current approaches either avoid computing this term
entirely using various heuristics, or assume the manifold is known beforehand
and therefore are not widely applicable. Instead, we propose two methods to
tractably calculate the gradient of this term with respect to the parameters of
the model, relying on careful use of automatic differentiation and techniques
from numerical linear algebra. Both approaches perform end-to-end nonlinear
manifold learning and density estimation for data projected onto this manifold.
We study the trade-offs between our proposed methods, empirically verify that
we outperform approaches ignoring the volume-change term by more accurately
learning manifolds and the corresponding distributions on them, and show
promising results on out-of-distribution detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Variational Empowerment as Representation Learning for Goal-Based Reinforcement Learning. (arXiv:2106.01404v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1">Jongwook Choi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1">Archit Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Honglak Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1">Sergey Levine</a>, <a href="http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1">Shixiang Shane Gu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01404">
                                    <div class="article-summary-box-inner">
                                        <span>Learning to reach goal states and learning diverse skills through mutual
information (MI) maximization have been proposed as principled frameworks for
self-supervised reinforcement learning, allowing agents to acquire broadly
applicable multitask policies with minimal reward engineering. Starting from a
simple observation that the standard goal-conditioned RL (GCRL) is encapsulated
by the optimization objective of variational empowerment, we discuss how GCRL
and MI-based RL can be generalized into a single family of methods, which we
name variational GCRL (VGCRL), interpreting variational MI maximization, or
variational empowerment, as representation learning methods that acquire
functionally-aware state representations for goal reaching. This novel
perspective allows us to: (1) derive simple but unexplored variants of GCRL to
study how adding small representation capacity can already expand its
capabilities; (2) investigate how discriminator function capacity and
smoothness determine the quality of discovered skills, or latent goals, through
modifying latent dimensionality and applying spectral normalization; (3) adapt
techniques such as hindsight experience replay (HER) from GCRL to MI-based RL;
and lastly, (4) propose a novel evaluation metric, named latent goal reaching
(LGR), for comparing empowerment algorithms with different choices of latent
dimensionality and discriminator parameterization. Through principled
mathematical derivations and careful experimental studies, our work lays a
novel foundation from which to evaluate, analyze, and develop representation
learning techniques in goal-based RL.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">q-RBFNN:A Quantum Calculus-based RBF Neural Network. (arXiv:2106.01370v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1">Syed Saiq Hussain</a>, <a href="http://arxiv.org/find/cs/1/au:+Usman_M/0/1/0/all/0/1">Muhammad Usman</a>, <a href="http://arxiv.org/find/cs/1/au:+Siddique_T/0/1/0/all/0/1">Taha Hasan Masood Siddique</a>, <a href="http://arxiv.org/find/cs/1/au:+Naseem_I/0/1/0/all/0/1">Imran Naseem</a>, <a href="http://arxiv.org/find/cs/1/au:+Togneri_R/0/1/0/all/0/1">Roberto Togneri</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennamoun_M/0/1/0/all/0/1">Mohammed Bennamoun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01370">
                                    <div class="article-summary-box-inner">
                                        <span>In this research a novel stochastic gradient descent based learning approach
for the radial basis function neural networks (RBFNN) is proposed. The proposed
method is based on the q-gradient which is also known as Jackson derivative. In
contrast to the conventional gradient, which finds the tangent, the q-gradient
finds the secant of the function and takes larger steps towards the optimal
solution. The proposed $q$-RBFNN is analyzed for its convergence performance in
the context of least square algorithm. In particular, a closed form expression
of the Wiener solution is obtained, and stability bounds of the learning rate
(step-size) is derived. The analytical results are validated through computer
simulation. Additionally, we propose an adaptive technique for the time-varying
$q$-parameter to improve convergence speed with no trade-offs in the steady
state performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Single-component gradient rules for variational quantum algorithms. (arXiv:2106.01388v1 [quant-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Hubregtsen_T/0/1/0/all/0/1">Thomas Hubregtsen</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Wilde_F/0/1/0/all/0/1">Frederik Wilde</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Qasim_S/0/1/0/all/0/1">Shozab Qasim</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Eisert_J/0/1/0/all/0/1">Jens Eisert</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01388">
                                    <div class="article-summary-box-inner">
                                        <span>Many near-term quantum computing algorithms are conceived as variational
quantum algorithms, in which parameterized quantum circuits are optimized in a
hybrid quantum-classical setup. Examples are variational quantum eigensolvers,
quantum approximate optimization algorithms as well as various algorithms in
the context of quantum-assisted machine learning. A common bottleneck of any
such algorithm is constituted by the optimization of the variational
parameters. A popular set of optimization methods work on the estimate of the
gradient, obtained by means of circuit evaluations. We will refer to the way in
which one can combine these circuit evaluations as gradient rules. This work
provides a comprehensive picture of the family of gradient rules that vary
parameters of quantum gates individually. The most prominent known members of
this family are the parameter shift rule and the finite differences method. To
unite this family, we propose a generalized parameter shift rule that expresses
all members of the aforementioned family as special cases, and discuss how all
of these can be seen as providing access to a linear combination of exact
first- and second-order derivatives. We further prove that a parameter shift
rule with one non-shifted evaluation and only one shifted circuit evaluation
can not exist does not exist, and introduce a novel perspective for approaching
new gradient rules.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Dual Script E2E framework for Multilingual and Code-Switching ASR. (arXiv:2106.01400v1 [eess.AS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kumar_M/0/1/0/all/0/1">Mari Ganesh Kumar</a>, <a href="http://arxiv.org/find/eess/1/au:+Kuriakose_J/0/1/0/all/0/1">Jom Kuriakose</a>, <a href="http://arxiv.org/find/eess/1/au:+Thyagachandran_A/0/1/0/all/0/1">Anand Thyagachandran</a>, <a href="http://arxiv.org/find/eess/1/au:+A_A/0/1/0/all/0/1">Arun Kumar A</a>, <a href="http://arxiv.org/find/eess/1/au:+Seth_A/0/1/0/all/0/1">Ashish Seth</a>, <a href="http://arxiv.org/find/eess/1/au:+Prasad_L/0/1/0/all/0/1">Lodagala Durga Prasad</a>, <a href="http://arxiv.org/find/eess/1/au:+Jaiswal_S/0/1/0/all/0/1">Saish Jaiswal</a>, <a href="http://arxiv.org/find/eess/1/au:+Prakash_A/0/1/0/all/0/1">Anusha Prakash</a>, <a href="http://arxiv.org/find/eess/1/au:+Murthy_H/0/1/0/all/0/1">Hema Murthy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01400">
                                    <div class="article-summary-box-inner">
                                        <span>India is home to multiple languages, and training automatic speech
recognition (ASR) systems for languages is challenging. Over time, each
language has adopted words from other languages, such as English, leading to
code-mixing. Most Indian languages also have their own unique scripts, which
poses a major limitation in training multilingual and code-switching ASR
systems.

Inspired by results in text-to-speech synthesis, in this work, we use an
in-house rule-based phoneme-level common label set (CLS) representation to
train multilingual and code-switching ASR for Indian languages. We propose two
end-to-end (E2E) ASR systems. In the first system, the E2E model is trained on
the CLS representation, and we use a novel data-driven back-end to recover the
native language script. In the second system, we propose a modification to the
E2E model, wherein the CLS representation and the native language characters
are used simultaneously for training. We show our results on the multilingual
and code-switching tasks of the Indic ASR Challenge 2021. Our best results
achieve 6% and 5% improvement (approx) in word error rate over the baseline
system for the multilingual and code-switching tasks, respectively, on the
challenge development data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Undecidability of Learnability. (arXiv:2106.01382v1 [cs.CC])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Caro_M/0/1/0/all/0/1">Matthias C. Caro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01382">
                                    <div class="article-summary-box-inner">
                                        <span>Machine learning researchers and practitioners steadily enlarge the multitude
of successful learning models. They achieve this through in-depth theoretical
analyses and experiential heuristics. However, there is no known
general-purpose procedure for rigorously evaluating whether newly proposed
models indeed successfully learn from data. We show that such a procedure
cannot exist. For PAC binary classification, uniform and universal online
learning, and exact learning through teacher-learner interactions, learnability
is in general undecidable, both in the sense of independence of the axioms in a
formal system and in the sense of uncomputability. Our proofs proceed via
computable constructions of function classes that encode the consistency
problem for formal systems and the halting problem for Turing machines into
complexity measures that characterize learnability. Our work shows that
undecidability appears in the theoretical foundations of machine learning:
There is no one-size-fits-all algorithm for deciding whether a machine learning
model can be successful. We cannot in general automatize the process of
assessing new learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On using distributed representations of source code for the detection of C security vulnerabilities. (arXiv:2106.01367v1 [cs.CR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Coimbra_D/0/1/0/all/0/1">David Coimbra</a>, <a href="http://arxiv.org/find/cs/1/au:+Reis_S/0/1/0/all/0/1">Sofia Reis</a>, <a href="http://arxiv.org/find/cs/1/au:+Abreu_R/0/1/0/all/0/1">Rui Abreu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasareanu_C/0/1/0/all/0/1">Corina P&#x103;s&#x103;reanu</a>, <a href="http://arxiv.org/find/cs/1/au:+Erdogmus_H/0/1/0/all/0/1">Hakan Erdogmus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01367">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents an evaluation of the code representation model Code2vec
when trained on the task of detecting security vulnerabilities in C source
code. We leverage the open-source library astminer to extract path-contexts
from the abstract syntax trees of a corpus of labeled C functions. Code2vec is
trained on the resulting path-contexts with the task of classifying a function
as vulnerable or non-vulnerable. Using the CodeXGLUE benchmark, we show that
the accuracy of Code2vec for this task is comparable to simple
transformer-based methods such as pre-trained RoBERTa, and outperforms more
naive NLP-based methods. We achieved an accuracy of 61.43% while maintaining
low computational requirements relative to larger models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automatic Assessment of the Design Quality of Python Programs with Personalized Feedback. (arXiv:2106.01399v1 [cs.SE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Orr_J/0/1/0/all/0/1">J. Walker Orr</a>, <a href="http://arxiv.org/find/cs/1/au:+Russell_N/0/1/0/all/0/1">Nathaniel Russell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01399">
                                    <div class="article-summary-box-inner">
                                        <span>The assessment of program functionality can generally be accomplished with
straight-forward unit tests. However, assessing the design quality of a program
is a much more difficult and nuanced problem. Design quality is an important
consideration since it affects the readability and maintainability of programs.
Assessing design quality and giving personalized feedback is very time
consuming task for instructors and teaching assistants. This limits the scale
of giving personalized feedback to small class settings. Further, design
quality is nuanced and is difficult to concisely express as a set of rules. For
these reasons, we propose a neural network model to both automatically assess
the design of a program and provide personalized feedback to guide students on
how to make corrections. The model&#x27;s effectiveness is evaluated on a corpus of
student programs written in Python. The model has an accuracy rate from 83.67%
to 94.27%, depending on the dataset, when predicting design scores as compared
to historical instructor assessment. Finally, we present a study where students
tried to improve the design of their programs based on the personalized
feedback produced by the model. Students who participated in the study improved
their program design scores by 19.58%.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Separated-Spectral-Distribution Estimation Based on Bayesian Inference with Single RGB Camera. (arXiv:2106.01861v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Kinoshita_Y/0/1/0/all/0/1">Yuma Kinoshita</a>, <a href="http://arxiv.org/find/eess/1/au:+Kiya_H/0/1/0/all/0/1">Hitoshi Kiya</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01861">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a novel method for separately estimating spectral
distributions from images captured by a typical RGB camera. The proposed method
allows us to separately estimate a spectral distribution of illumination,
reflectance, or camera sensitivity, while recent hyperspectral cameras are
limited to capturing a joint spectral distribution from a scene. In addition,
the use of Bayesian inference makes it possible to take into account prior
information of both spectral distributions and image noise as probability
distributions. As a result, the proposed method can estimate spectral
distributions in a unified way, and it can enhance the robustness of the
estimation against noise, which conventional spectral-distribution estimation
methods cannot. The use of Bayesian inference also enables us to obtain the
confidence of estimation results. In an experiment, the proposed method is
shown not only to outperform conventional estimation methods in terms of RMSE
but also to be robust against noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Anticipative Video Transformer. (arXiv:2106.02036v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Girdhar_R/0/1/0/all/0/1">Rohit Girdhar</a>, <a href="http://arxiv.org/find/cs/1/au:+Grauman_K/0/1/0/all/0/1">Kristen Grauman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.02036">
                                    <div class="article-summary-box-inner">
                                        <span>We propose Anticipative Video Transformer (AVT), an end-to-end
attention-based video modeling architecture that attends to the previously
observed video in order to anticipate future actions. We train the model
jointly to predict the next action in a video sequence, while also learning
frame feature encoders that are predictive of successive future frames&#x27;
features. Compared to existing temporal aggregation strategies, AVT has the
advantage of both maintaining the sequential progression of observed actions
while still capturing long-range dependencies--both critical for the
anticipation task. Through extensive experiments, we show that AVT obtains the
best reported performance on four popular action anticipation benchmarks:
EpicKitchens-55, EpicKitchens-100, EGTEA Gaze+, and 50-Salads, including
outperforming all submissions to the EpicKitchens-100 CVPR&#x27;21 challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>
    <section class="daily-content">
        <h2 class="daily-heading"><time datatime="2021-06-03">2021-06-03</time></h2>
        <ul class="sources card">
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CL"">cs.CL updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Measuring and Increasing Context Usage in Context-Aware Machine Translation. (arXiv:2105.03482v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fernandes_P/0/1/0/all/0/1">Patrick Fernandes</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_K/0/1/0/all/0/1">Kayo Yin</a>, <a href="http://arxiv.org/find/cs/1/au:+Neubig_G/0/1/0/all/0/1">Graham Neubig</a>, <a href="http://arxiv.org/find/cs/1/au:+Martins_A/0/1/0/all/0/1">Andr&#xe9; F. T. Martins</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03482">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work in neural machine translation has demonstrated both the necessity
and feasibility of using inter-sentential context -- context from sentences
other than those currently being translated. However, while many current
methods present model architectures that theoretically can use this extra
context, it is often not clear how much they do actually utilize it at
translation time. In this paper, we introduce a new metric, conditional
cross-mutual information, to quantify the usage of context by these models.
Using this metric, we measure how much document-level machine translation
systems use particular varieties of context. We find that target context is
referenced more than source context, and that conditioning on a longer context
has a diminishing effect on results. We then introduce a new, simple training
method, context-aware word dropout, to increase the usage of context by
context-aware models. Experiments show that our method increases context usage
and that this reflects on the translation quality according to metrics such as
BLEU and COMET, as well as performance on anaphoric pronoun resolution and
lexical cohesion contrastive datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adapting High-resource NMT Models to Translate Low-resource Related Languages without Parallel Data. (arXiv:2105.15071v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ko_W/0/1/0/all/0/1">Wei-Jen Ko</a>, <a href="http://arxiv.org/find/cs/1/au:+El_Kishky_A/0/1/0/all/0/1">Ahmed El-Kishky</a>, <a href="http://arxiv.org/find/cs/1/au:+Renduchintala_A/0/1/0/all/0/1">Adithya Renduchintala</a>, <a href="http://arxiv.org/find/cs/1/au:+Chaudhary_V/0/1/0/all/0/1">Vishrav Chaudhary</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_N/0/1/0/all/0/1">Naman Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Guzman_F/0/1/0/all/0/1">Francisco Guzm&#xe1;n</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1">Pascale Fung</a>, <a href="http://arxiv.org/find/cs/1/au:+Koehn_P/0/1/0/all/0/1">Philipp Koehn</a>, <a href="http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1">Mona Diab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.15071">
                                    <div class="article-summary-box-inner">
                                        <span>The scarcity of parallel data is a major obstacle for training high-quality
machine translation systems for low-resource languages. Fortunately, some
low-resource languages are linguistically related or similar to high-resource
languages; these related languages may share many lexical or syntactic
structures. In this work, we exploit this linguistic overlap to facilitate
translating to and from a low-resource language with only monolingual data, in
addition to any parallel data in the related high-resource language. Our
method, NMT-Adapt, combines denoising autoencoding, back-translation and
adversarial objectives to utilize monolingual data for low-resource adaptation.
We experiment on 7 languages from three different language families and show
that our technique significantly improves translation into low-resource
language compared to other translation baselines.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning Dense Representations of Phrases at Scale. (arXiv:2012.12624v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1">Jinhyuk Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Sung_M/0/1/0/all/0/1">Mujeen Sung</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jaewoo Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Danqi Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.12624">
                                    <div class="article-summary-box-inner">
                                        <span>Open-domain question answering can be reformulated as a phrase retrieval
problem, without the need for processing documents on-demand during inference
(Seo et al., 2019). However, current phrase retrieval models heavily depend on
sparse representations and still underperform retriever-reader approaches. In
this work, we show for the first time that we can learn dense representations
of phrases alone that achieve much stronger performance in open-domain QA. We
present an effective method to learn phrase representations from the
supervision of reading comprehension tasks, coupled with novel negative
sampling methods. We also propose a query-side fine-tuning strategy, which can
support transfer learning and reduce the discrepancy between training and
inference. On five popular open-domain QA datasets, our model DensePhrases
improves over previous phrase retrieval models by 15%-25% absolute accuracy and
matches the performance of state-of-the-art retriever-reader models. Our model
is easy to parallelize due to pure dense representations and processes more
than 10 questions per second on CPUs. Finally, we directly use our pre-indexed
dense phrase representations for two slot filling tasks, showing the promise of
utilizing DensePhrases as a dense knowledge base for downstream tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Intrinsic Bias Metrics Do Not Correlate with Application Bias. (arXiv:2012.15859v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Goldfarb_Tarrant_S/0/1/0/all/0/1">Seraphina Goldfarb-Tarrant</a>, <a href="http://arxiv.org/find/cs/1/au:+Marchant_R/0/1/0/all/0/1">Rebecca Marchant</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanchez_R/0/1/0/all/0/1">Ricardo Mu&#xf1;oz Sanchez</a>, <a href="http://arxiv.org/find/cs/1/au:+Pandya_M/0/1/0/all/0/1">Mugdha Pandya</a>, <a href="http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1">Adam Lopez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15859">
                                    <div class="article-summary-box-inner">
                                        <span>Natural Language Processing (NLP) systems learn harmful societal biases that
cause them to amplify inequality as they are deployed in more and more
situations. To guide efforts at debiasing these systems, the NLP community
relies on a variety of metrics that quantify bias in models. Some of these
metrics are intrinsic, measuring bias in word embedding spaces, and some are
extrinsic, measuring bias in downstream tasks that the word embeddings enable.
Do these intrinsic and extrinsic metrics correlate with each other? We compare
intrinsic and extrinsic metrics across hundreds of trained models covering
different tasks and experimental conditions. Our results show no reliable
correlation between these metrics that holds in all scenarios across tasks and
languages. We urge researchers working on debiasing to focus on extrinsic
measures of bias, and to make using these measures more feasible via creation
of new challenge sets and annotated test data. To aid this effort, we release
code, a new intrinsic metric, and an annotated test set focused on gender bias
in hate speech.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Training of Neural Retrievers for Open-Domain Question Answering. (arXiv:2101.00408v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sachan_D/0/1/0/all/0/1">Devendra Singh Sachan</a>, <a href="http://arxiv.org/find/cs/1/au:+Patwary_M/0/1/0/all/0/1">Mostofa Patwary</a>, <a href="http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1">Mohammad Shoeybi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kant_N/0/1/0/all/0/1">Neel Kant</a>, <a href="http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1">Wei Ping</a>, <a href="http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1">William L Hamilton</a>, <a href="http://arxiv.org/find/cs/1/au:+Catanzaro_B/0/1/0/all/0/1">Bryan Catanzaro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00408">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work on training neural retrievers for open-domain question answering
(OpenQA) has employed both supervised and unsupervised approaches. However, it
remains unclear how unsupervised and supervised methods can be used most
effectively for neural retrievers. In this work, we systematically study
retriever pre-training. We first propose an approach of unsupervised
pre-training with the Inverse Cloze Task and masked salient spans, followed by
supervised finetuning using question-context pairs. This approach leads to
absolute gains of 2+ points over the previous best result in the top-20
retrieval accuracy on Natural Questions and TriviaQA datasets.

We also explore two approaches for end-to-end supervised training of the
reader and retriever components in OpenQA models. In the first approach, the
reader considers each retrieved document separately while in the second
approach, the reader considers all the retrieved documents together. Our
experiments demonstrate the effectiveness of these approaches as we obtain new
state-of-the-art results. On the Natural Questions dataset, we obtain a top-20
retrieval accuracy of 84, an improvement of 5 points over the recent DPR model.
In addition, we achieve good results on answer extraction, outperforming recent
models like REALM and RAG by 3+ points. We further scale up end-to-end training
to large models and show consistent gains in performance over smaller models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">HyKnow: End-to-End Task-Oriented Dialog Modeling with Hybrid Knowledge Management. (arXiv:2105.06041v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1">Silin Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Takanobu_R/0/1/0/all/0/1">Ryuichi Takanobu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_W/0/1/0/all/0/1">Wei Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.06041">
                                    <div class="article-summary-box-inner">
                                        <span>Task-oriented dialog (TOD) systems typically manage structured knowledge
(e.g. ontologies and databases) to guide the goal-oriented conversations.
However, they fall short of handling dialog turns grounded on unstructured
knowledge (e.g. reviews and documents). In this paper, we formulate a task of
modeling TOD grounded on both structured and unstructured knowledge. To address
this task, we propose a TOD system with hybrid knowledge management, HyKnow. It
extends the belief state to manage both structured and unstructured knowledge,
and is the first end-to-end model that jointly optimizes dialog modeling
grounded on these two kinds of knowledge. We conduct experiments on the
modified version of MultiWOZ 2.1 dataset, where dialogs are grounded on hybrid
knowledge. Experimental results show that HyKnow has strong end-to-end
performance compared to existing TOD systems. It also outperforms the pipeline
knowledge management schemes, with higher unstructured knowledge retrieval
accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncovering Constraint-Based Behavior in Neural Models via Targeted Fine-Tuning. (arXiv:2106.01207v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Davis_F/0/1/0/all/0/1">Forrest Davis</a>, <a href="http://arxiv.org/find/cs/1/au:+Schijndel_M/0/1/0/all/0/1">Marten van Schijndel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01207">
                                    <div class="article-summary-box-inner">
                                        <span>A growing body of literature has focused on detailing the linguistic
knowledge embedded in large, pretrained language models. Existing work has
shown that non-linguistic biases in models can drive model behavior away from
linguistic generalizations. We hypothesized that competing linguistic processes
within a language, rather than just non-linguistic model biases, could obscure
underlying linguistic knowledge. We tested this claim by exploring a single
phenomenon in four languages: English, Chinese, Spanish, and Italian. While
human behavior has been found to be similar across languages, we find
cross-linguistic variation in model behavior. We show that competing processes
in a language act as constraints on model behavior and demonstrate that
targeted fine-tuning can re-weight the learned constraints, uncovering
otherwise dormant linguistic knowledge in models. Our results suggest that
models need to learn both the linguistic constraints in a language and their
relative ranking, with mismatches in either producing non-human-like behavior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Good is Your Tokenizer? On the Monolingual Performance of Multilingual Language Models. (arXiv:2012.15613v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rust_P/0/1/0/all/0/1">Phillip Rust</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfeiffer_J/0/1/0/all/0/1">Jonas Pfeiffer</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1">Sebastian Ruder</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15613">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we provide a systematic and comprehensive empirical comparison
of pretrained multilingual language models versus their monolingual
counterparts with regard to their monolingual task performance. We study a set
of nine typologically diverse languages with readily available pretrained
monolingual models on a set of five diverse monolingual downstream tasks. We
first aim to establish, via fair and controlled comparisons, if a gap between
the multilingual and the corresponding monolingual representation of that
language exists, and subsequently investigate the reason for any performance
difference. To disentangle conflating factors, we train new monolingual models
on the same data, with monolingually and multilingually trained tokenizers. We
find that while the pretraining data size is an important factor, a designated
monolingual tokenizer plays an equally important role in the downstream
performance. Our results show that languages that are adequately represented in
the multilingual model&#x27;s vocabulary exhibit negligible performance decreases
over their monolingual counterparts. We further find that replacing the
original multilingual tokenizer with the specialized monolingual tokenizer
improves the downstream performance of the multilingual model for almost every
task and language.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cross-document Coreference Resolution over Predicted Mentions. (arXiv:2106.01210v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cattan_A/0/1/0/all/0/1">Arie Cattan</a>, <a href="http://arxiv.org/find/cs/1/au:+Eirew_A/0/1/0/all/0/1">Alon Eirew</a>, <a href="http://arxiv.org/find/cs/1/au:+Stanovsky_G/0/1/0/all/0/1">Gabriel Stanovsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Joshi_M/0/1/0/all/0/1">Mandar Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dagan_I/0/1/0/all/0/1">Ido Dagan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01210">
                                    <div class="article-summary-box-inner">
                                        <span>Coreference resolution has been mostly investigated within a single document
scope, showing impressive progress in recent years based on end-to-end models.
However, the more challenging task of cross-document (CD) coreference
resolution remained relatively under-explored, with the few recent models
applied only to gold mentions. Here, we introduce the first end-to-end model
for CD coreference resolution from raw text, which extends the prominent model
for within-document coreference to the CD setting. Our model achieves
competitive results for event and entity coreference resolution on gold
mentions. More importantly, we set first baseline results, on the standard ECB+
dataset, for CD coreference resolution over predicted mentions. Further, our
model is simpler and more efficient than recent CD coreference resolution
systems, while not using any external resources.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Second-Order Neural Dependency Parsing with Message Passing and End-to-End Training. (arXiv:2010.05003v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05003">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose second-order graph-based neural dependency parsing
using message passing and end-to-end neural networks. We empirically show that
our approaches match the accuracy of very recent state-of-the-art second-order
graph-based neural dependency parsers and have significantly faster speed in
both training and testing. We also empirically show the advantage of
second-order parsing over first-order parsing and observe that the usefulness
of the head-selection structured constraint vanishes when using BERT embedding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">multiPRover: Generating Multiple Proofs for Improved Interpretability in Rule Reasoning. (arXiv:2106.01354v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Swarnadeep Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1">Prateek Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01354">
                                    <div class="article-summary-box-inner">
                                        <span>We focus on a type of linguistic formal reasoning where the goal is to reason
over explicit knowledge in the form of natural language facts and rules (Clark
et al., 2020). A recent work, named PRover (Saha et al., 2020), performs such
reasoning by answering a question and also generating a proof graph that
explains the answer. However, compositional reasoning is not always unique and
there may be multiple ways of reaching the correct answer. Thus, in our work,
we address a new and challenging problem of generating multiple proof graphs
for reasoning over natural language rule-bases. Each proof provides a different
rationale for the answer, thereby improving the interpretability of such
reasoning systems. In order to jointly learn from all proof graphs and exploit
the correlations between multiple proofs for a question, we pose this task as a
set generation problem over structured output spaces where each proof is
represented as a directed graph. We propose two variants of a proof-set
generation model, multiPRover. Our first model, Multilabel-multiPRover,
generates a set of proofs via multi-label classification and implicit
conditioning between the proofs; while the second model, Iterative-multiPRover,
generates proofs iteratively by explicitly conditioning on the previously
generated proofs. Experiments on multiple synthetic, zero-shot, and
human-paraphrased datasets reveal that both multiPRover models significantly
outperform PRover on datasets containing multiple gold proofs.
Iterative-multiPRover obtains state-of-the-art proof F1 in zero-shot scenarios
where all examples have single correct proofs. It also generalizes better to
questions requiring higher depths of reasoning where multiple proofs are more
frequent. Our code and models are publicly available at
https://github.com/swarnaHub/multiPRover</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low-resource expressive text-to-speech using data augmentation. (arXiv:2011.05707v2 [eess.AS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Huybrechts_G/0/1/0/all/0/1">Goeric Huybrechts</a>, <a href="http://arxiv.org/find/eess/1/au:+Merritt_T/0/1/0/all/0/1">Thomas Merritt</a>, <a href="http://arxiv.org/find/eess/1/au:+Comini_G/0/1/0/all/0/1">Giulia Comini</a>, <a href="http://arxiv.org/find/eess/1/au:+Perz_B/0/1/0/all/0/1">Bartek Perz</a>, <a href="http://arxiv.org/find/eess/1/au:+Shah_R/0/1/0/all/0/1">Raahil Shah</a>, <a href="http://arxiv.org/find/eess/1/au:+Lorenzo_Trueba_J/0/1/0/all/0/1">Jaime Lorenzo-Trueba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05707">
                                    <div class="article-summary-box-inner">
                                        <span>While recent neural text-to-speech (TTS) systems perform remarkably well,
they typically require a substantial amount of recordings from the target
speaker reading in the desired speaking style. In this work, we present a novel
3-step methodology to circumvent the costly operation of recording large
amounts of target data in order to build expressive style voices with as little
as 15 minutes of such recordings. First, we augment data via voice conversion
by leveraging recordings in the desired speaking style from other speakers.
Next, we use that synthetic data on top of the available recordings to train a
TTS model. Finally, we fine-tune that model to further increase quality. Our
evaluations show that the proposed changes bring significant improvements over
non-augmented models across many perceived aspects of synthesised speech. We
demonstrate the proposed approach on 2 styles (newscaster and conversational),
on various speakers, and on both single and multi-speaker models, illustrating
the robustness of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">&quot;Call me sexist, but...&quot;: Revisiting Sexism Detection Using Psychological Scales and Adversarial Samples. (arXiv:2004.12764v2 [cs.CY] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Samory_M/0/1/0/all/0/1">Mattia Samory</a>, <a href="http://arxiv.org/find/cs/1/au:+Sen_I/0/1/0/all/0/1">Indira Sen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kohne_J/0/1/0/all/0/1">Julian Kohne</a>, <a href="http://arxiv.org/find/cs/1/au:+Floeck_F/0/1/0/all/0/1">Fabian Floeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Wagner_C/0/1/0/all/0/1">Claudia Wagner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.12764">
                                    <div class="article-summary-box-inner">
                                        <span>Research has focused on automated methods to effectively detect sexism
online. Although overt sexism seems easy to spot, its subtle forms and manifold
expressions are not. In this paper, we outline the different dimensions of
sexism by grounding them in their implementation in psychological scales. From
the scales, we derive a codebook for sexism in social media, which we use to
annotate existing and novel datasets, surfacing their limitations in breadth
and validity with respect to the construct of sexism. Next, we leverage the
annotated datasets to generate adversarial examples, and test the reliability
of sexism detection methods. Results indicate that current machine learning
models pick up on a very narrow set of linguistic markers of sexism and do not
generalize well to out-of-domain examples. Yet, including diverse data and
adversarial examples at training time results in models that generalize better
and that are more robust to artifacts of data collection. By providing a
scale-based codebook and insights regarding the shortcomings of the
state-of-the-art, we hope to contribute to the development of better and
broader models for sexism detection, including reflections on theory-driven
approaches to data collection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WikiTableT: A Large-Scale Data-to-Text Dataset for Generating Wikipedia Article Sections. (arXiv:2012.14919v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1">Mingda Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiseman_S/0/1/0/all/0/1">Sam Wiseman</a>, <a href="http://arxiv.org/find/cs/1/au:+Gimpel_K/0/1/0/all/0/1">Kevin Gimpel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14919">
                                    <div class="article-summary-box-inner">
                                        <span>Datasets for data-to-text generation typically focus either on multi-domain,
single-sentence generation or on single-domain, long-form generation. In this
work, we cast generating Wikipedia sections as a data-to-text generation task
and create a large-scale dataset, WikiTableT, that pairs Wikipedia sections
with their corresponding tabular data and various metadata. WikiTableT contains
millions of instances, covering a broad range of topics, as well as a variety
of flavors of generation tasks with different levels of flexibility. We
benchmark several training and decoding strategies on WikiTableT. Our
qualitative analysis shows that the best approaches can generate fluent and
high quality texts but they struggle with coherence and factuality, showing the
potential for our dataset to inspire future work on long-form generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">More Identifiable yet Equally Performant Transformers for Text Classification. (arXiv:2106.01269v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhardwaj_R/0/1/0/all/0/1">Rishabh Bhardwaj</a>, <a href="http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1">Navonil Majumder</a>, <a href="http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1">Soujanya Poria</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1">Eduard Hovy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01269">
                                    <div class="article-summary-box-inner">
                                        <span>Interpretability is an important aspect of the trustworthiness of a model&#x27;s
predictions. Transformer&#x27;s predictions are widely explained by the attention
weights, i.e., a probability distribution generated at its self-attention unit
(head). Current empirical studies provide shreds of evidence that attention
weights are not explanations by proving that they are not unique. A recent
study showed theoretical justifications to this observation by proving the
non-identifiability of attention weights. For a given input to a head and its
output, if the attention weights generated in it are unique, we call the
weights identifiable. In this work, we provide deeper theoretical analysis and
empirical observations on the identifiability of attention weights. Ignored in
the previous works, we find the attention weights are more identifiable than we
currently perceive by uncovering the hidden role of the key vector. However,
the weights are still prone to be non-unique attentions that make them unfit
for interpretation. To tackle this issue, we provide a variant of the encoder
layer that decouples the relationship between key and value vector and provides
identifiable weights up to the desired length of the input. We prove the
applicability of such variations by providing empirical justifications on
varied text classification tasks. The implementations are available at
https://github.com/declare-lab/identifiable-transformers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Question Answering by Pretraining Span Selection. (arXiv:2101.00438v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ram_O/0/1/0/all/0/1">Ori Ram</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirstain_Y/0/1/0/all/0/1">Yuval Kirstain</a>, <a href="http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1">Jonathan Berant</a>, <a href="http://arxiv.org/find/cs/1/au:+Globerson_A/0/1/0/all/0/1">Amir Globerson</a>, <a href="http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1">Omer Levy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00438">
                                    <div class="article-summary-box-inner">
                                        <span>In several question answering benchmarks, pretrained models have reached
human parity through fine-tuning on an order of 100,000 annotated questions and
answers. We explore the more realistic few-shot setting, where only a few
hundred training examples are available, and observe that standard models
perform poorly, highlighting the discrepancy between current pretraining
objectives and question answering. We propose a new pretraining scheme tailored
for question answering: recurring span selection. Given a passage with multiple
sets of recurring spans, we mask in each set all recurring spans but one, and
ask the model to select the correct span in the passage for each masked span.
Masked spans are replaced with a special token, viewed as a question
representation, that is later used during fine-tuning to select the answer
span. The resulting model obtains surprisingly good results on multiple
benchmarks (e.g., 72.7 F1 on SQuAD with only 128 training examples), while
maintaining competitive performance in the high-resource setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraghVQA: Language-Guided Graph Neural Networks for Graph-based Visual Question Answering. (arXiv:2104.10283v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1">Weixin Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yanhao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zixuan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10283">
                                    <div class="article-summary-box-inner">
                                        <span>Images are more than a collection of objects or attributes -- they represent
a web of relationships among interconnected objects. Scene Graph has emerged as
a new modality for a structured graphical representation of images. Scene Graph
encodes objects as nodes connected via pairwise relations as edges. To support
question answering on scene graphs, we propose GraphVQA, a language-guided
graph neural network framework that translates and executes a natural language
question as multiple iterations of message passing among graph nodes. We
explore the design space of GraphVQA framework, and discuss the trade-off of
different design choices. Our experiments on GQA dataset show that GraphVQA
outperforms the state-of-the-art model by a large margin (88.43% vs. 94.78%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SocAoG: Incremental Graph Parsing for Social Relation Inference in Dialogues. (arXiv:2106.01006v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1">Liang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1">Yuan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yizhou Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Baolin Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhou Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Ying Nian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Song-Chun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01006">
                                    <div class="article-summary-box-inner">
                                        <span>Inferring social relations from dialogues is vital for building emotionally
intelligent robots to interpret human language better and act accordingly. We
model the social network as an And-or Graph, named SocAoG, for the consistency
of relations among a group and leveraging attributes as inference cues.
Moreover, we formulate a sequential structure prediction task, and propose an
$\alpha$-$\beta$-$\gamma$ strategy to incrementally parse SocAoG for the
dynamic inference upon any incoming utterance: (i) an $\alpha$ process
predicting attributes and relations conditioned on the semantics of dialogues,
(ii) a $\beta$ process updating the social relations based on related
attributes, and (iii) a $\gamma$ process updating individual&#x27;s attributes based
on interpersonal social relations. Empirical results on DialogRE and MovieGraph
show that our model infers social relations more accurately than the
state-of-the-art methods. Moreover, the ablation study shows the three
processes complement each other, and the case study demonstrates the dynamic
relational inference.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">T-BERT -- Model for Sentiment Analysis of Micro-blogs Integrating Topic Model and BERT. (arXiv:2106.01097v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Palani_S/0/1/0/all/0/1">Sarojadevi Palani</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajagopal_P/0/1/0/all/0/1">Prabhu Rajagopal</a>, <a href="http://arxiv.org/find/cs/1/au:+Pancholi_S/0/1/0/all/0/1">Sidharth Pancholi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01097">
                                    <div class="article-summary-box-inner">
                                        <span>Sentiment analysis (SA) has become an extensive research area in recent years
impacting diverse fields including ecommerce, consumer business, and politics,
driven by increasing adoption and usage of social media platforms. It is
challenging to extract topics and sentiments from unsupervised short texts
emerging in such contexts, as they may contain figurative words, strident data,
and co-existence of many possible meanings for a single word or phrase, all
contributing to obtaining incorrect topics. Most prior research is based on a
specific theme/rhetoric/focused-content on a clean dataset. In the work
reported here, the effectiveness of BERT(Bidirectional Encoder Representations
from Transformers) in sentiment classification tasks from a raw live dataset
taken from a popular microblogging platform is demonstrated. A novel T-BERT
framework is proposed to show the enhanced performance obtainable by combining
latent topics with contextual BERT embeddings. Numerical experiments were
conducted on an ensemble with about 42000 datasets using NimbleBox.ai platform
with a hardware configuration consisting of Nvidia Tesla K80(CUDA), 4 core CPU,
15GB RAM running on an isolated Google Cloud Platform instance. The empirical
results show that the model improves in performance while adding topics to BERT
and an accuracy rate of 90.81% on sentiment classification using BERT with the
proposed approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cascade versus Direct Speech Translation: Do the Differences Still Make a Difference?. (arXiv:2106.01045v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bentivogli_L/0/1/0/all/0/1">Luisa Bentivogli</a>, <a href="http://arxiv.org/find/cs/1/au:+Cettolo_M/0/1/0/all/0/1">Mauro Cettolo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaido_M/0/1/0/all/0/1">Marco Gaido</a>, <a href="http://arxiv.org/find/cs/1/au:+Karakanta_A/0/1/0/all/0/1">Alina Karakanta</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinelli_A/0/1/0/all/0/1">Alberto Martinelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Negri_M/0/1/0/all/0/1">Matteo Negri</a>, <a href="http://arxiv.org/find/cs/1/au:+Turchi_M/0/1/0/all/0/1">Marco Turchi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01045">
                                    <div class="article-summary-box-inner">
                                        <span>Five years after the first published proofs of concept, direct approaches to
speech translation (ST) are now competing with traditional cascade solutions.
In light of this steady progress, can we claim that the performance gap between
the two is closed? Starting from this question, we present a systematic
comparison between state-of-the-art systems representative of the two
paradigms. Focusing on three language directions
(English-German/Italian/Spanish), we conduct automatic and manual evaluations,
exploiting high-quality professional post-edits and annotations. Our
multi-faceted analysis on one of the few publicly available ST benchmarks
attests for the first time that: i) the gap between the two paradigms is now
closed, and ii) the subtle differences observed in their behavior are not
sufficient for humans neither to distinguish them nor to prefer one over the
other.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fusing Context Into Knowledge Graph for Commonsense Question Answering. (arXiv:2012.04808v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1">Yichong Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1">Chenguang Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1">Ruochen Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_M/0/1/0/all/0/1">Michael Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuedong Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04808">
                                    <div class="article-summary-box-inner">
                                        <span>Commonsense question answering (QA) requires a model to grasp commonsense and
factual knowledge to answer questions about world events. Many prior methods
couple language modeling with knowledge graphs (KG). However, although a KG
contains rich structural information, it lacks the context to provide a more
precise understanding of the concepts. This creates a gap when fusing knowledge
graphs into language modeling, especially when there is insufficient labeled
data. Thus, we propose to employ external entity descriptions to provide
contextual information for knowledge understanding. We retrieve descriptions of
related concepts from Wiktionary and feed them as additional input to
pre-trained language models. The resulting model achieves state-of-the-art
result in the CommonsenseQA dataset and the best result among non-generative
models in OpenBookQA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Distribution, Sparsity, and Inference-time Quantization of Attention Values in Transformers. (arXiv:2106.01335v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ji_T/0/1/0/all/0/1">Tianchu Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1">Shraddhan Jain</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferdman_M/0/1/0/all/0/1">Michael Ferdman</a>, <a href="http://arxiv.org/find/cs/1/au:+Milder_P/0/1/0/all/0/1">Peter Milder</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1">H. Andrew Schwartz</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1">Niranjan Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01335">
                                    <div class="article-summary-box-inner">
                                        <span>How much information do NLP tasks really need from a transformer&#x27;s attention
mechanism at application-time (inference)? From recent work, we know that there
is sparsity in transformers and that the floating-points within its computation
can be discretized to fewer values with minimal loss to task accuracies.
However, this requires retraining or even creating entirely new models, both of
which can be expensive and carbon-emitting. Focused on optimizations that do
not require training, we systematically study the full range of typical
attention values necessary. This informs the design of an inference-time
quantization technique using both pruning and log-scaled mapping which produces
only a few (e.g. $2^3$) unique values. Over the tasks of question answering and
sentiment analysis, we find nearly 80% of attention values can be pruned to
zeros with minimal ($&lt; 1.0\%$) relative loss in accuracy. We use this pruning
technique in conjunction with quantizing the attention values to only a 3-bit
format, without retraining, resulting in only a 0.8% accuracy reduction on
question answering with fine-tuned RoBERTa.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploiting Global Contextual Information for Document-level Named Entity Recognition. (arXiv:2106.00887v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zanbo Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_W/0/1/0/all/0/1">Wei Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_X/0/1/0/all/0/1">Xianling Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1">Shanshan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1">Pan Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1">Zhiyong He</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Sheng Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00887">
                                    <div class="article-summary-box-inner">
                                        <span>Most existing named entity recognition (NER) approaches are based on sequence
labeling models, which focus on capturing the local context dependencies.
However, the way of taking one sentence as input prevents the modeling of
non-sequential global context, which is useful especially when local context
information is limited or ambiguous. To this end, we propose a model called
Global Context enhanced Document-level NER (GCDoc) to leverage global
contextual information from two levels, i.e., both word and sentence. At
word-level, a document graph is constructed to model a wider range of
dependencies between words, then obtain an enriched contextual representation
for each word via graph neural networks (GNN). To avoid the interference of
noise information, we further propose two strategies. First we apply the
epistemic uncertainty theory to find out tokens whose representations are less
reliable, thereby helping prune the document graph. Then a selective auxiliary
classifier is proposed to effectively learn the weight of edges in document
graph and reduce the importance of noisy neighbour nodes. At sentence-level,
for appropriately modeling wider context beyond single sentence, we employ a
cross-sentence module which encodes adjacent sentences and fuses it with the
current sentence representation via attention and gating mechanisms. Extensive
experiments on two benchmark NER datasets (CoNLL 2003 and Ontonotes 5.0 English
dataset) demonstrate the effectiveness of our proposed model. Our model reaches
F1 score of 92.22 (93.40 with BERT) on CoNLL 2003 dataset and 88.32 (90.49 with
BERT) on Ontonotes 5.0 dataset, achieving new state-of-the-art performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating Informative Conclusions for Argumentative Texts. (arXiv:2106.01064v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Syed_S/0/1/0/all/0/1">Shahbaz Syed</a>, <a href="http://arxiv.org/find/cs/1/au:+Al_Khatib_K/0/1/0/all/0/1">Khalid Al-Khatib</a>, <a href="http://arxiv.org/find/cs/1/au:+Alshomary_M/0/1/0/all/0/1">Milad Alshomary</a>, <a href="http://arxiv.org/find/cs/1/au:+Wachsmuth_H/0/1/0/all/0/1">Henning Wachsmuth</a>, <a href="http://arxiv.org/find/cs/1/au:+Potthast_M/0/1/0/all/0/1">Martin Potthast</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01064">
                                    <div class="article-summary-box-inner">
                                        <span>The purpose of an argumentative text is to support a certain conclusion. Yet,
they are often omitted, expecting readers to infer them rather. While
appropriate when reading an individual text, this rhetorical device limits
accessibility when browsing many texts (e.g., on a search engine or on social
media). In these scenarios, an explicit conclusion makes for a good candidate
summary of an argumentative text. This is especially true if the conclusion is
informative, emphasizing specific concepts from the text. With this paper we
introduce the task of generating informative conclusions: First,
Webis-ConcluGen-21 is compiled, a large-scale corpus of 136,996 samples of
argumentative texts and their conclusions. Second, two paradigms for conclusion
generation are investigated; one extractive, the other abstractive in nature.
The latter exploits argumentative knowledge that augment the data via control
codes and finetuning the BART model on several subsets of the corpus. Third,
insights are provided into the suitability of our corpus for the task, the
differences between the two generation paradigms, the trade-off between
informativeness and conciseness, and the impact of encoding argumentative
knowledge. The corpus, code, and the trained models are publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">COM2SENSE: A Commonsense Reasoning Benchmark with Complementary Sentences. (arXiv:2106.00969v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1">Shikhar Singh</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_N/0/1/0/all/0/1">Nuan Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yu Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Alipoormolabashi_P/0/1/0/all/0/1">Pegah Alipoormolabashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1">Te-Lin Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1">Xuezhe Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1">Nanyun Peng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00969">
                                    <div class="article-summary-box-inner">
                                        <span>Commonsense reasoning is intuitive for humans but has been a long-term
challenge for artificial intelligence (AI). Recent advancements in pretrained
language models have shown promising results on several commonsense benchmark
datasets. However, the reliability and comprehensiveness of these benchmarks
towards assessing model&#x27;s commonsense reasoning ability remains unclear. To
this end, we introduce a new commonsense reasoning benchmark dataset comprising
natural language true/false statements, with each sample paired with its
complementary counterpart, resulting in 4k sentence pairs. We propose a
pairwise accuracy metric to reliably measure an agent&#x27;s ability to perform
commonsense reasoning over a given situation. The dataset is crowdsourced and
enhanced with an adversarial model-in-the-loop setup to incentivize challenging
samples. To facilitate a systematic analysis of commonsense capabilities, we
design our dataset along the dimensions of knowledge domains, reasoning
scenarios and numeracy. Experimental results demonstrate that our strongest
baseline (UnifiedQA-3B), after fine-tuning, achieves ~71% standard accuracy and
~51% pairwise accuracy, well below human performance (~95% for both metrics).
The dataset is available at https://github.com/PlusLabNLP/Com2Sense.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Finding the $K$-best Non-projective Dependency Trees. (arXiv:2106.00780v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zmigrod_R/0/1/0/all/0/1">Ran Zmigrod</a>, <a href="http://arxiv.org/find/cs/1/au:+Vieira_T/0/1/0/all/0/1">Tim Vieira</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00780">
                                    <div class="article-summary-box-inner">
                                        <span>The connection between the maximum spanning tree in a directed graph and the
best dependency tree of a sentence has been exploited by the NLP community.
However, for many dependency parsing schemes, an important detail of this
approach is that the spanning tree must have exactly one edge emanating from
the root. While work has been done to efficiently solve this problem for
finding the one-best dependency tree, no research has attempted to extend this
solution to finding the $K$-best dependency trees. This is arguably a more
important extension as a larger proportion of decoded trees will not be subject
to the root constraint of dependency trees. Indeed, we show that the rate of
root constraint violations increases by an average of $13$ times when decoding
with $K\!&#x3D;\!50$ as opposed to $K\!&#x3D;\!1$. In this paper, we provide a
simplification of the $K$-best spanning tree algorithm of Camerini et al.
(1980). Our simplification allows us to obtain a constant time speed-up over
the original algorithm. Furthermore, we present a novel extension of the
algorithm for decoding the $K$-best dependency trees of a graph which are
subject to a root constraint.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring Discourse Structures for Argument Impact Classification. (arXiv:2106.00976v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xin Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ou_J/0/1/0/all/0/1">Jiefu Ou</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yangqiu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1">Xin Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00976">
                                    <div class="article-summary-box-inner">
                                        <span>Discourse relations among arguments reveal logical structures of a debate
conversation. However, no prior work has explicitly studied how the sequence of
discourse relations influence a claim&#x27;s impact. This paper empirically shows
that the discourse relations between two arguments along the context path are
essential factors for identifying the persuasive power of an argument. We
further propose DisCOC to inject and fuse the sentence-level structural
discourse information with contextualized features derived from large-scale
language models. Experimental results and extensive analysis show that the
attention and gate mechanisms that explicitly model contexts and texts can
indeed help the argument impact classification task defined by Durmus et al.
(2019), and discourse structures among the context path of the claim to be
classified can further boost the performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End NLP Knowledge Graph Construction. (arXiv:2106.01167v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mondal_I/0/1/0/all/0/1">Ishani Mondal</a>, <a href="http://arxiv.org/find/cs/1/au:+Hou_Y/0/1/0/all/0/1">Yufang Hou</a>, <a href="http://arxiv.org/find/cs/1/au:+Jochim_C/0/1/0/all/0/1">Charles Jochim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01167">
                                    <div class="article-summary-box-inner">
                                        <span>This paper studies the end-to-end construction of an NLP Knowledge Graph (KG)
from scientific papers. We focus on extracting four types of relations:
evaluatedOn between tasks and datasets, evaluatedBy between tasks and
evaluation metrics, as well as coreferent and related relations between the
same type of entities. For instance, F1-score is coreferent with F-measure. We
introduce novel methods for each of these relation types and apply our final
framework (SciNLP-KG) to 30,000 NLP papers from ACL Anthology to build a
large-scale KG, which can facilitate automatically constructing scientific
leaderboards for the NLP community. The results of our experiments indicate
that the resulting KG contains high-quality information.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">When and Why does a Model Fail? A Human-in-the-loop Error Detection Framework for Sentiment Analysis. (arXiv:2106.00954v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhe Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1">Yufan Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmud_J/0/1/0/all/0/1">Jalal Mahmud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00954">
                                    <div class="article-summary-box-inner">
                                        <span>Although deep neural networks have been widely employed and proven effective
in sentiment analysis tasks, it remains challenging for model developers to
assess their models for erroneous predictions that might exist prior to
deployment. Once deployed, emergent errors can be hard to identify in
prediction run-time and impossible to trace back to their sources. To address
such gaps, in this paper we propose an error detection framework for sentiment
analysis based on explainable features. We perform global-level feature
validation with human-in-the-loop assessment, followed by an integration of
global and local-level feature contribution analysis. Experimental results show
that, given limited human-in-the-loop intervention, our method is able to
identify erroneous model predictions on unseen data with high precision.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DYPLOC: Dynamic Planning of Content Using Mixed Language Models for Text Generation. (arXiv:2106.00791v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hua_X/0/1/0/all/0/1">Xinyu Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Sreevatsa_A/0/1/0/all/0/1">Ashwin Sreevatsa</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Lu Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00791">
                                    <div class="article-summary-box-inner">
                                        <span>We study the task of long-form opinion text generation, which faces at least
two distinct challenges. First, existing neural generation models fall short of
coherence, thus requiring efficient content planning. Second, diverse types of
information are needed to guide the generator to cover both subjective and
objective content. To this end, we propose DYPLOC, a generation framework that
conducts dynamic planning of content while generating the output based on a
novel design of mixed language models. To enrich the generation with diverse
content, we further propose to use large pre-trained models to predict relevant
concepts and to generate claims. We experiment with two challenging tasks on
newly collected datasets: (1) argument generation with Reddit ChangeMyView, and
(2) writing articles using New York Times&#x27; Opinion section. Automatic
evaluation shows that our model significantly outperforms competitive
comparisons. Human judges further confirm that our generations are more
coherent with richer content.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">OntoGUM: Evaluating Contextualized SOTA Coreference Resolution on 12 More Genres. (arXiv:2106.00933v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yilun Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pradhan_S/0/1/0/all/0/1">Sameer Pradhan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeldes_A/0/1/0/all/0/1">Amir Zeldes</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00933">
                                    <div class="article-summary-box-inner">
                                        <span>SOTA coreference resolution produces increasingly impressive scores on the
OntoNotes benchmark. However lack of comparable data following the same scheme
for more genres makes it difficult to evaluate generalizability to open domain
data. This paper provides a dataset and comprehensive evaluation showing that
the latest neural LM based end-to-end systems degrade very substantially out of
domain. We make an OntoNotes-like coreference dataset called OntoGUM publicly
available, converted from GUM, an English corpus covering 12 genres, using
deterministic rules, which we evaluate. Thanks to the rich syntactic and
discourse annotations in GUM, we are able to create the largest human-annotated
coreference corpus following the OntoNotes guidelines, and the first to be
evaluated for consistency with the OntoNotes scheme. Out-of-domain evaluation
across 12 genres shows nearly 15-20% degradation for both deterministic and
deep learning systems, indicating a lack of generalizability or covert
overfitting in existing coreference resolution models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SyGNS: A Systematic Generalization Testbed Based on Natural Language Semantics. (arXiv:2106.01077v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yanaka_H/0/1/0/all/0/1">Hitomi Yanaka</a>, <a href="http://arxiv.org/find/cs/1/au:+Mineshima_K/0/1/0/all/0/1">Koji Mineshima</a>, <a href="http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1">Kentaro Inui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01077">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, deep neural networks (DNNs) have achieved great success in
semantically challenging NLP tasks, yet it remains unclear whether DNN models
can capture compositional meanings, those aspects of meaning that have been
long studied in formal semantics. To investigate this issue, we propose a
Systematic Generalization testbed based on Natural language Semantics (SyGNS),
whose challenge is to map natural language sentences to multiple forms of
scoped meaning representations, designed to account for various semantic
phenomena. Using SyGNS, we test whether neural networks can systematically
parse sentences involving novel combinations of logical expressions such as
quantifiers and negation. Experiments show that Transformer and GRU models can
generalize to unseen combinations of quantifiers, negations, and modifiers that
are similar to given training instances in form, but not to the others. We also
find that the generalization performance to unseen combinations is better when
the form of meaning representations is simpler. The data and code for SyGNS are
publicly available at https://github.com/verypluming/SyGNS.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rejuvenating Low-Frequency Words: Making the Most of Parallel Data in Non-Autoregressive Translation. (arXiv:2106.00903v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1">Liang Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1">Longyue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xuebo Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wong_D/0/1/0/all/0/1">Derek F. Wong</a>, <a href="http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1">Dacheng Tao</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhaopeng Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00903">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge distillation (KD) is commonly used to construct synthetic data for
training non-autoregressive translation (NAT) models. However, there exists a
discrepancy on low-frequency words between the distilled and the original data,
leading to more errors on predicting low-frequency words. To alleviate the
problem, we directly expose the raw data into NAT by leveraging pretraining. By
analyzing directed alignments, we found that KD makes low-frequency source
words aligned with targets more deterministically but fails to align sufficient
low-frequency words from target to source. Accordingly, we propose reverse KD
to rejuvenate more alignments for low-frequency target words. To make the most
of authentic and synthetic data, we combine these complementary approaches as a
new training strategy for further boosting NAT performance. We conduct
experiments on five translation benchmarks over two advanced architectures.
Results demonstrate that the proposed approach can significantly and
universally improve translation quality by reducing translation errors on
low-frequency words. Encouragingly, our approach achieves 28.2 and 33.9 BLEU
points on the WMT14 English-German and WMT16 Romanian-English datasets,
respectively. Our code, data, and trained models are available at
\url{https://github.com/longyuewangdcu/RLFW-NAT}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CoRI: Collective Relation Integration with Data Augmentation for Open Information Extraction. (arXiv:2106.00793v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1">Zhengbao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1">Jialong Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Sisman_B/0/1/0/all/0/1">Bunyamin Sisman</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1">Xin Luna Dong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00793">
                                    <div class="article-summary-box-inner">
                                        <span>Integrating extracted knowledge from the Web to knowledge graphs (KGs) can
facilitate tasks like question answering. We study relation integration that
aims to align free-text relations in subject-relation-object extractions to
relations in a target KG. To address the challenge that free-text relations are
ambiguous, previous methods exploit neighbor entities and relations for
additional context. However, the predictions are made independently, which can
be mutually inconsistent. We propose a two-stage Collective Relation
Integration (CoRI) model, where the first stage independently makes candidate
predictions, and the second stage employs a collective model that accesses all
candidate predictions to make globally coherent predictions. We further improve
the collective model with augmented data from the portion of the target KG that
is otherwise unused. Experiment results on two datasets show that CoRI can
significantly outperform the baselines, improving AUC from .677 to .748 and
from .716 to .780, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Word Embeddings with Categorical Modularity. (arXiv:2106.00877v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Casacuberta_S/0/1/0/all/0/1">S&#xed;lvia Casacuberta</a>, <a href="http://arxiv.org/find/cs/1/au:+Halevy_K/0/1/0/all/0/1">Karina Halevy</a>, <a href="http://arxiv.org/find/cs/1/au:+Blasi_D/0/1/0/all/0/1">Dami&#xe1;n E. Blasi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00877">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce categorical modularity, a novel low-resource intrinsic metric to
evaluate word embedding quality. Categorical modularity is a graph modularity
metric based on the $k$-nearest neighbor graph constructed with embedding
vectors of words from a fixed set of semantic categories, in which the goal is
to measure the proportion of words that have nearest neighbors within the same
categories. We use a core set of 500 words belonging to 59 neurobiologically
motivated semantic categories in 29 languages and analyze three word embedding
models per language (FastText, MUSE, and subs2vec). We find moderate to strong
positive correlations between categorical modularity and performance on the
monolingual tasks of sentiment analysis and word similarity calculation and on
the cross-lingual task of bilingual lexicon induction both to and from English.
Overall, we suggest that categorical modularity provides non-trivial predictive
information about downstream task performance, with breakdowns of correlations
by model suggesting some meta-predictive properties about semantic information
loss as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">John praised Mary because he? Implicit Causality Bias and Its Interaction with Explicit Cues in LMs. (arXiv:2106.01060v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kementchedjhieva_Y/0/1/0/all/0/1">Yova Kementchedjhieva</a>, <a href="http://arxiv.org/find/cs/1/au:+Anderson_M/0/1/0/all/0/1">Mark Anderson</a>, <a href="http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1">Anders S&#xf8;gaard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01060">
                                    <div class="article-summary-box-inner">
                                        <span>Some interpersonal verbs can implicitly attribute causality to either their
subject or their object and are therefore said to carry an implicit causality
(IC) bias. Through this bias, causal links can be inferred from a narrative,
aiding language comprehension. We investigate whether pre-trained language
models (PLMs) encode IC bias and use it at inference time. We find that to be
the case, albeit to different degrees, for three distinct PLM architectures.
However, causes do not always need to be implicit -- when a cause is explicitly
stated in a subordinate clause, an incongruent IC bias associated with the verb
in the main clause leads to a delay in human processing. We hypothesize that
the temporary challenge humans face in integrating the two contradicting
signals, one from the lexical semantics of the verb, one from the
sentence-level semantics, would be reflected in higher error rates for models
on tasks dependent on causal links. The results of our study lend support to
this hypothesis, suggesting that PLMs tend to prioritize lexical patterns over
higher-order signals.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A systematic review of Hate Speech automatic detection using Natural Language Processing. (arXiv:2106.00742v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jahan_M/0/1/0/all/0/1">Md Saroar Jahan</a>, <a href="http://arxiv.org/find/cs/1/au:+Oussalah_M/0/1/0/all/0/1">Mourad Oussalah</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00742">
                                    <div class="article-summary-box-inner">
                                        <span>With the multiplication of social media platforms, which offer anonymity,
easy access and online community formation, and online debate, the issue of
hate speech detection and tracking becomes a growing challenge to society,
individual, policy-makers and researchers. Despite efforts for leveraging
automatic techniques for automatic detection and monitoring, their performances
are still far from satisfactory, which constantly calls for future research on
the issue. This paper provides a systematic review of literature in this field,
with a focus on natural language processing and deep learning technologies,
highlighting the terminology, processing pipeline, core methods employed, with
a focal point on deep learning architecture. From a methodological perspective,
we adopt PRISMA guideline of systematic review of the last 10 years literature
from ACM Digital Library and Google Scholar. In the sequel, existing surveys,
limitations, and future research directions are extensively discussed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Higher-order Derivatives of Weighted Finite-state Machines. (arXiv:2106.00749v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zmigrod_R/0/1/0/all/0/1">Ran Zmigrod</a>, <a href="http://arxiv.org/find/cs/1/au:+Vieira_T/0/1/0/all/0/1">Tim Vieira</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00749">
                                    <div class="article-summary-box-inner">
                                        <span>Weighted finite-state machines are a fundamental building block of NLP
systems. They have withstood the test of time -- from their early use in noisy
channel models in the 1990s up to modern-day neurally parameterized conditional
random fields. This work examines the computation of higher-order derivatives
with respect to the normalization constant for weighted finite-state machines.
We provide a general algorithm for evaluating derivatives of all orders, which
has not been previously described in the literature. In the case of
second-order derivatives, our scheme runs in the optimal $\mathcal{O}(A^2 N^4)$
time where $A$ is the alphabet size and $N$ is the number of states. Our
algorithm is significantly faster than prior algorithms. Additionally, our
approach leads to a significantly faster algorithm for computing second-order
expectations, such as covariance matrices and gradients of first-order
expectations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Cluster-based Approach for Improving Isotropy in Contextual Embedding Space. (arXiv:2106.01183v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rajaee_S/0/1/0/all/0/1">Sara Rajaee</a>, <a href="http://arxiv.org/find/cs/1/au:+Pilehvar_M/0/1/0/all/0/1">Mohammad Taher Pilehvar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01183">
                                    <div class="article-summary-box-inner">
                                        <span>The representation degeneration problem in Contextual Word Representations
(CWRs) hurts the expressiveness of the embedding space by forming an
anisotropic cone where even unrelated words have excessively positive
correlations. Existing techniques for tackling this issue require a learning
process to re-train models with additional objectives and mostly employ a
global assessment to study isotropy. Our quantitative analysis over isotropy
shows that a local assessment could be more accurate due to the clustered
structure of CWRs. Based on this observation, we propose a local cluster-based
method to address the degeneration issue in contextual embedding spaces. We
show that in clusters including punctuations and stop words, local dominant
directions encode structural information, removing which can improve CWRs
performance on semantic tasks. Moreover, we find that tense information in verb
representations dominates sense semantics. We show that removing dominant
directions of verb representations can transform the space to better suit
semantic applications. Our experiments demonstrate that the proposed
cluster-based method can mitigate the degeneration problem on multiple tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Elaborative Simplification: Content Addition and Explanation Generation in Text Simplification. (arXiv:2010.10035v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Srikanth_N/0/1/0/all/0/1">Neha Srikanth</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Junyi Jessy Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.10035">
                                    <div class="article-summary-box-inner">
                                        <span>Much of modern-day text simplification research focuses on sentence-level
simplification, transforming original, more complex sentences into simplified
versions. However, adding content can often be useful when difficult concepts
and reasoning need to be explained. In this work, we present the first
data-driven study of content addition in text simplification, which we call
elaborative simplification. We introduce a new annotated dataset of 1.3K
instances of elaborative simplification in the Newsela corpus, and analyze how
entities, ideas, and concepts are elaborated through the lens of contextual
specificity. We establish baselines for elaboration generation using
large-scale pre-trained language models, and demonstrate that considering
contextual specificity during generation can improve performance. Our results
illustrate the complexities of elaborative simplification, suggesting many
interesting directions for future work.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Emotional Support Dialog Systems. (arXiv:2106.01144v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Siyang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1">Chujie Zheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Demasi_O/0/1/0/all/0/1">Orianna Demasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Sabour_S/0/1/0/all/0/1">Sahand Sabour</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yu Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1">Zhou Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01144">
                                    <div class="article-summary-box-inner">
                                        <span>Emotional support is a crucial ability for many conversation scenarios,
including social interactions, mental health support, and customer service
chats. Following reasonable procedures and using various support skills can
help to effectively provide support. However, due to the lack of a
well-designed task and corpora of effective emotional support conversations,
research on building emotional support into dialog systems remains untouched.
In this paper, we define the Emotional Support Conversation (ESC) task and
propose an ESC Framework, which is grounded on the Helping Skills Theory. We
construct an Emotion Support Conversation dataset (ESConv) with rich annotation
(especially support strategy) in a help-seeker and supporter mode. To ensure a
corpus of high-quality conversations that provide examples of effective
emotional support, we take extensive effort to design training tutorials for
supporters and several mechanisms for quality control during data collection.
Finally, we evaluate state-of-the-art dialog models with respect to the ability
to provide emotional support. Our results show the importance of support
strategies in providing effective emotional support and the utility of ESConv
in training more emotional support systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Abstract Meaning Representation for Knowledge Base Question Answering. (arXiv:2012.01707v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kapanipathi_P/0/1/0/all/0/1">Pavan Kapanipathi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abdelaziz_I/0/1/0/all/0/1">Ibrahim Abdelaziz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ravishankar_S/0/1/0/all/0/1">Srinivas Ravishankar</a>, <a href="http://arxiv.org/find/cs/1/au:+Roukos_S/0/1/0/all/0/1">Salim Roukos</a>, <a href="http://arxiv.org/find/cs/1/au:+Gray_A/0/1/0/all/0/1">Alexander Gray</a>, <a href="http://arxiv.org/find/cs/1/au:+Astudillo_R/0/1/0/all/0/1">Ramon Astudillo</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1">Maria Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Cornelio_C/0/1/0/all/0/1">Cristina Cornelio</a>, <a href="http://arxiv.org/find/cs/1/au:+Dana_S/0/1/0/all/0/1">Saswati Dana</a>, <a href="http://arxiv.org/find/cs/1/au:+Fokoue_A/0/1/0/all/0/1">Achille Fokoue</a>, <a href="http://arxiv.org/find/cs/1/au:+Garg_D/0/1/0/all/0/1">Dinesh Garg</a>, <a href="http://arxiv.org/find/cs/1/au:+Gliozzo_A/0/1/0/all/0/1">Alfio Gliozzo</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurajada_S/0/1/0/all/0/1">Sairam Gurajada</a>, <a href="http://arxiv.org/find/cs/1/au:+Karanam_H/0/1/0/all/0/1">Hima Karanam</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1">Naweed Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khandelwal_D/0/1/0/all/0/1">Dinesh Khandelwal</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1">Young-Suk Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yunyao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Luus_F/0/1/0/all/0/1">Francois Luus</a>, <a href="http://arxiv.org/find/cs/1/au:+Makondo_N/0/1/0/all/0/1">Ndivhuwo Makondo</a>, <a href="http://arxiv.org/find/cs/1/au:+Mihindukulasooriya_N/0/1/0/all/0/1">Nandana Mihindukulasooriya</a>, <a href="http://arxiv.org/find/cs/1/au:+Naseem_T/0/1/0/all/0/1">Tahira Naseem</a>, <a href="http://arxiv.org/find/cs/1/au:+Neelam_S/0/1/0/all/0/1">Sumit Neelam</a>, <a href="http://arxiv.org/find/cs/1/au:+Popa_L/0/1/0/all/0/1">Lucian Popa</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_R/0/1/0/all/0/1">Revanth Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Riegel_R/0/1/0/all/0/1">Ryan Riegel</a>, <a href="http://arxiv.org/find/cs/1/au:+Rossiello_G/0/1/0/all/0/1">Gaetano Rossiello</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_U/0/1/0/all/0/1">Udit Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhargav_G/0/1/0/all/0/1">G P Shrivatsa Bhargav</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1">Mo Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01707">
                                    <div class="article-summary-box-inner">
                                        <span>Knowledge base question answering (KBQA)is an important task in Natural
Language Processing. Existing approaches face significant challenges including
complex question understanding, necessity for reasoning, and lack of large
end-to-end training datasets. In this work, we propose Neuro-Symbolic Question
Answering (NSQA), a modular KBQA system, that leverages (1) Abstract Meaning
Representation (AMR) parses for task-independent question understanding; (2) a
simple yet effective graph transformation approach to convert AMR parses into
candidate logical queries that are aligned to the KB; (3) a pipeline-based
approach which integrates multiple, reusable modules that are trained
specifically for their individual tasks (semantic parser, entity
andrelationship linkers, and neuro-symbolic reasoner) and do not require
end-to-end training data. NSQA achieves state-of-the-art performance on two
prominent KBQA datasets based on DBpedia (QALD-9 and LC-QuAD1.0). Furthermore,
our analysis emphasizes that AMR is a powerful tool for KBQA systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topic-Driven and Knowledge-Aware Transformer for Dialogue Emotion Detection. (arXiv:2106.01071v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhu_L/0/1/0/all/0/1">Lixing Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Pergola_G/0/1/0/all/0/1">Gabriele Pergola</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_L/0/1/0/all/0/1">Lin Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Deyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yulan He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01071">
                                    <div class="article-summary-box-inner">
                                        <span>Emotion detection in dialogues is challenging as it often requires the
identification of thematic topics underlying a conversation, the relevant
commonsense knowledge, and the intricate transition patterns between the
affective states. In this paper, we propose a Topic-Driven Knowledge-Aware
Transformer to handle the challenges above. We firstly design a topic-augmented
language model (LM) with an additional layer specialized for topic detection.
The topic-augmented LM is then combined with commonsense statements derived
from a knowledge base based on the dialogue contextual information. Finally, a
transformer-based encoder-decoder architecture fuses the topical and
commonsense information, and performs the emotion label sequence prediction.
The model has been experimented on four datasets in dialogue emotion detection,
demonstrating its superiority empirically over the existing state-of-the-art
approaches. Quantitative and qualitative results show that the model can
discover topics which help in distinguishing emotion categories.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning. (arXiv:2105.04165v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1">Ran Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shibiao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1">Liang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Siyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Song-Chun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04165">
                                    <div class="article-summary-box-inner">
                                        <span>Geometry problem solving has attracted much attention in the NLP community
recently. The task is challenging as it requires abstract problem understanding
and symbolic reasoning with axiomatic knowledge. However, current datasets are
either small in scale or not publicly available. Thus, we construct a new
large-scale benchmark, Geometry3K, consisting of 3,002 geometry problems with
dense annotation in formal language. We further propose a novel geometry
solving approach with formal language and symbolic reasoning, called
Interpretable Geometry Problem Solver (Inter-GPS). Inter-GPS first parses the
problem text and diagram into formal language automatically via rule-based text
parsing and neural object detecting, respectively. Unlike implicit learning in
existing methods, Inter-GPS incorporates theorem knowledge as conditional rules
and performs symbolic reasoning step by step. Also, a theorem predictor is
designed to infer the theorem application sequence fed to the symbolic solver
for the more efficient and reasonable searching path. Extensive experiments on
the Geometry3K and GEOS datasets demonstrate that Inter-GPS achieves
significant improvements over existing methods. The project with code and data
is available at https://lupantech.github.io/inter-gps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Can Sequence-to-Sequence Models Crack Substitution Ciphers?. (arXiv:2012.15229v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aldarrab_N/0/1/0/all/0/1">Nada Aldarrab</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15229">
                                    <div class="article-summary-box-inner">
                                        <span>Decipherment of historical ciphers is a challenging problem. The language of
the target plaintext might be unknown, and ciphertext can have a lot of noise.
State-of-the-art decipherment methods use beam search and a neural language
model to score candidate plaintext hypotheses for a given cipher, assuming the
plaintext language is known. We propose an end-to-end multilingual model for
solving simple substitution ciphers. We test our model on synthetic and real
historical ciphers and show that our proposed method can decipher text without
explicit language identification while still being robust to noise.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topic-Aware Evidence Reasoning and Stance-Aware Aggregation for Fact Verification. (arXiv:2106.01191v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Si_J/0/1/0/all/0/1">Jiasheng Si</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1">Deyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1">Tongzhe Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1">Xingyu Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1">Yulan He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01191">
                                    <div class="article-summary-box-inner">
                                        <span>Fact verification is a challenging task that requires simultaneously
reasoning and aggregating over multiple retrieved pieces of evidence to
evaluate the truthfulness of a claim. Existing approaches typically (i) explore
the semantic interaction between the claim and evidence at different
granularity levels but fail to capture their topical consistency during the
reasoning process, which we believe is crucial for verification; (ii) aggregate
multiple pieces of evidence equally without considering their implicit stances
to the claim, thereby introducing spurious information. To alleviate the above
issues, we propose a novel topic-aware evidence reasoning and stance-aware
aggregation model for more accurate fact verification, with the following four
key properties: 1) checking topical consistency between the claim and evidence;
2) maintaining topical coherence among multiple pieces of evidence; 3) ensuring
semantic similarity between the global topic information and the semantic
representation of evidence; 4) aggregating evidence based on their implicit
stances to the claim. Extensive experiments conducted on the two benchmark
datasets demonstrate the superiority of the proposed model over several
state-of-the-art approaches for fact verification. The source code can be
obtained from https://github.com/jasenchn/TARSA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Have Attention Heads in BERT Learned Constituency Grammar?. (arXiv:2102.07926v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1">Ziyang Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.07926">
                                    <div class="article-summary-box-inner">
                                        <span>With the success of pre-trained language models in recent years, more and
more researchers focus on opening the &quot;black box&quot; of these models. Following
this interest, we carry out a qualitative and quantitative analysis of
constituency grammar in attention heads of BERT and RoBERTa. We employ the
syntactic distance method to extract implicit constituency grammar from the
attention weights of each head. Our results show that there exist heads that
can induce some grammar types much better than baselines, suggesting that some
heads act as a proxy for constituency grammar. We also analyze how attention
heads&#x27; constituency grammar inducing (CGI) ability changes after fine-tuning
with two kinds of tasks, including sentence meaning similarity (SMS) tasks and
natural language inference (NLI) tasks. Our results suggest that SMS tasks
decrease the average CGI ability of upper layers, while NLI tasks increase it.
Lastly, we investigate the connections between CGI ability and natural language
understanding ability on QQP and MNLI tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VAULT: VAriable Unified Long Text Representation for Machine Reading Comprehension. (arXiv:2105.03229v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wen_H/0/1/0/all/0/1">Haoyang Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferritto_A/0/1/0/all/0/1">Anthony Ferritto</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1">Heng Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Florian_R/0/1/0/all/0/1">Radu Florian</a>, <a href="http://arxiv.org/find/cs/1/au:+Sil_A/0/1/0/all/0/1">Avirup Sil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03229">
                                    <div class="article-summary-box-inner">
                                        <span>Existing models on Machine Reading Comprehension (MRC) require complex model
architecture for effectively modeling long texts with paragraph representation
and classification, thereby making inference computationally inefficient for
production use. In this work, we propose VAULT: a light-weight and
parallel-efficient paragraph representation for MRC based on contextualized
representation from long document input, trained using a new Gaussian
distribution-based objective that pays close attention to the partially correct
instances that are close to the ground-truth. We validate our VAULT
architecture showing experimental results on two benchmark MRC datasets that
require long context modeling; one Wikipedia-based (Natural Questions (NQ)) and
the other on TechNotes (TechQA). VAULT can achieve comparable performance on NQ
with a state-of-the-art (SOTA) complex document modeling approach while being
16 times faster, demonstrating the efficiency of our proposed model. We also
demonstrate that our model can also be effectively adapted to a completely
different domain -- TechQA -- with large improvement over a model fine-tuned on
a previously published large PLM.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pay Attention to MLPs. (arXiv:2105.08050v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hanxiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1">Zihang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+So_D/0/1/0/all/0/1">David R. So</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08050">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have become one of the most important architectural innovations
in deep learning and have enabled many breakthroughs over the past few years.
Here we propose a simple network architecture, gMLP, based on MLPs with gating,
and show that it can perform as well as Transformers in key language and vision
applications. Our comparisons show that self-attention is not critical for
Vision Transformers, as gMLP can achieve the same accuracy. For BERT, our model
achieves parity with Transformers on pretraining perplexity and is better on
some downstream NLP tasks. On finetuning tasks where gMLP performs worse,
making the gMLP model substantially larger can close the gap with Transformers.
In general, our experiments show that gMLP can scale as well as Transformers
over increased data and compute.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Faster Re-translation Using Non-Autoregressive Model For Simultaneous Neural Machine Translation. (arXiv:2012.14681v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Han_H/0/1/0/all/0/1">Hyojung Han</a>, <a href="http://arxiv.org/find/cs/1/au:+Indurthi_S/0/1/0/all/0/1">Sathish Indurthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaidi_M/0/1/0/all/0/1">Mohd Abbas Zaidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lakumarapu_N/0/1/0/all/0/1">Nikhil Kumar Lakumarapu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1">Beomseok Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sangha Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1">Chanwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_I/0/1/0/all/0/1">Inchul Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14681">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, simultaneous translation has gathered a lot of attention since it
enables compelling applications such as subtitle translation for a live event
or real-time video-call translation. Some of these translation applications
allow editing of partial translation giving rise to re-translation approaches.
The current re-translation approaches are based on autoregressive sequence
generation models (ReTA), which generate tar-get tokens in the (partial)
translation sequentially. The multiple re-translations with sequential
generation inReTAmodelslead to an increased inference time gap between the
incoming source input and the corresponding target output as the source input
grows. Besides, due to the large number of inference operations involved, the
ReTA models are not favorable for resource-constrained devices. In this work,
we propose a faster re-translation system based on a non-autoregressive
sequence generation model (FReTNA) to overcome the aforementioned limitations.
We evaluate the proposed model on multiple translation tasks and our model
reduces the inference times by several orders and achieves a competitive
BLEUscore compared to the ReTA and streaming (Wait-k) models.The proposed model
reduces the average computation time by a factor of 20 when compared to the
ReTA model by incurring a small drop in the translation quality. It also
outperforms the streaming-based Wait-k model both in terms of computation time
(1.5 times lower) and translation quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning. (arXiv:2105.03654v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bach_N/0/1/0/all/0/1">Nguyen Bach</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhongqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03654">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in Named Entity Recognition (NER) show that document-level
contexts can significantly improve model performance. In many application
scenarios, however, such contexts are not available. In this paper, we propose
to find external contexts of a sentence by retrieving and selecting a set of
semantically relevant texts through a search engine, with the original sentence
as the query. We find empirically that the contextual representations computed
on the retrieval-based input view, constructed through the concatenation of a
sentence and its external contexts, can achieve significantly improved
performance compared to the original input view based only on the sentence.
Furthermore, we can improve the model performance of both input views by
Cooperative Learning, a training method that encourages the two input views to
produce similar contextual representations or output label distributions.
Experiments show that our approach can achieve new state-of-the-art performance
on 8 NER data sets across 5 domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Supervised Document Similarity Ranking via Contextualized Language Models and Hierarchical Inference. (arXiv:2106.01186v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ginzburg_D/0/1/0/all/0/1">Dvir Ginzburg</a>, <a href="http://arxiv.org/find/cs/1/au:+Malkiel_I/0/1/0/all/0/1">Itzik Malkiel</a>, <a href="http://arxiv.org/find/cs/1/au:+Barkan_O/0/1/0/all/0/1">Oren Barkan</a>, <a href="http://arxiv.org/find/cs/1/au:+Caciularu_A/0/1/0/all/0/1">Avi Caciularu</a>, <a href="http://arxiv.org/find/cs/1/au:+Koenigstein_N/0/1/0/all/0/1">Noam Koenigstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01186">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel model for the problem of ranking a collection of documents
according to their semantic similarity to a source (query) document. While the
problem of document-to-document similarity ranking has been studied, most
modern methods are limited to relatively short documents or rely on the
existence of &quot;ground-truth&quot; similarity labels. Yet, in most common real-world
cases, similarity ranking is an unsupervised problem as similarity labels are
unavailable. Moreover, an ideal model should not be restricted by documents&#x27;
length. Hence, we introduce SDR, a self-supervised method for document
similarity that can be applied to documents of arbitrary length. Importantly,
SDR can be effectively applied to extremely long documents, exceeding the 4,096
maximal token limits of Longformer. Extensive evaluations on large document
datasets show that SDR significantly outperforms its alternatives across all
metrics. To accelerate future research on unlabeled long document similarity
ranking, and as an additional contribution to the community, we herein publish
two human-annotated test sets of long documents similarity evaluation. The SDR
code and datasets are publicly available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating SOAP Notes from Doctor-Patient Conversations Using Modular Summarization Techniques. (arXiv:2005.01795v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krishna_K/0/1/0/all/0/1">Kundan Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosla_S/0/1/0/all/0/1">Sopan Khosla</a>, <a href="http://arxiv.org/find/cs/1/au:+Bigham_J/0/1/0/all/0/1">Jeffrey P. Bigham</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01795">
                                    <div class="article-summary-box-inner">
                                        <span>Following each patient visit, physicians draft long semi-structured clinical
summaries called SOAP notes. While invaluable to clinicians and researchers,
creating digital SOAP notes is burdensome, contributing to physician burnout.
In this paper, we introduce the first complete pipelines to leverage deep
summarization models to generate these notes based on transcripts of
conversations between physicians and patients. After exploring a spectrum of
methods across the extractive-abstractive spectrum, we propose Cluster2Sent, an
algorithm that (i) extracts important utterances relevant to each summary
section; (ii) clusters together related utterances; and then (iii) generates
one summary sentence per cluster. Cluster2Sent outperforms its purely
abstractive counterpart by 8 ROUGE-1 points, and produces significantly more
factual and coherent sentences as assessed by expert human evaluators. For
reproducibility, we demonstrate similar benefits on the publicly available AMI
dataset. Our results speak to the benefits of structuring summaries into
sections and annotating supporting evidence when constructing summarization
corpora.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Database Reasoning Over Text. (arXiv:2106.01074v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1">James Thorne</a>, <a href="http://arxiv.org/find/cs/1/au:+Yazdani_M/0/1/0/all/0/1">Majid Yazdani</a>, <a href="http://arxiv.org/find/cs/1/au:+Saeidi_M/0/1/0/all/0/1">Marzieh Saeidi</a>, <a href="http://arxiv.org/find/cs/1/au:+Silvestri_F/0/1/0/all/0/1">Fabrizio Silvestri</a>, <a href="http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1">Sebastian Riedel</a>, <a href="http://arxiv.org/find/cs/1/au:+Halevy_A/0/1/0/all/0/1">Alon Halevy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01074">
                                    <div class="article-summary-box-inner">
                                        <span>Neural models have shown impressive performance gains in answering queries
from natural language text. However, existing works are unable to support
database queries, such as &quot;List/Count all female athletes who were born in 20th
century&quot;, which require reasoning over sets of relevant facts with operations
such as join, filtering and aggregation. We show that while state-of-the-art
transformer models perform very well for small databases, they exhibit
limitations in processing noisy data, numerical operations, and queries that
aggregate facts. We propose a modular architecture to answer these
database-style queries over multiple spans from text and aggregating these at
scale. We evaluate the architecture using WikiNLDB, a novel dataset for
exploring such queries. Our architecture scales to databases containing
thousands of facts whereas contemporary models are limited by how many facts
can be encoded. In direct comparison on small databases, our approach increases
overall answer accuracy from 85% to 90%. On larger databases, our approach
retains its accuracy whereas transformer baselines could not encode the
context.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization. (arXiv:2106.01317v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yichen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1">Asli Celikyilmaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Smolensky_P/0/1/0/all/0/1">Paul Smolensky</a>, <a href="http://arxiv.org/find/cs/1/au:+Soulos_P/0/1/0/all/0/1">Paul Soulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1">Sudha Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Palangi_H/0/1/0/all/0/1">Hamid Palangi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_R/0/1/0/all/0/1">Roland Fernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_C/0/1/0/all/0/1">Caitlin Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01317">
                                    <div class="article-summary-box-inner">
                                        <span>Abstractive summarization, the task of generating a concise summary of input
documents, requires: (1) reasoning over the source document to determine the
salient pieces of information scattered across the long document, and (2)
composing a cohesive text by reconstructing these salient facts into a shorter
summary that faithfully reflects the complex relations connecting these facts.
In this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture
that enriches the original Transformer (Vaswani et al., 2017) with the
explicitly compositional Tensor Product Representation (TPR), for the task of
abstractive summarization. The key feature of our model is a structural bias
that we introduce by encoding two separate representations for each token to
represent the syntactic structure (with role vectors) and semantic content
(with filler vectors) separately. The model then binds the role and filler
vectors into the TPR as the layer output. We argue that the structured
intermediate representations enable the model to take better control of the
contents (salient facts) and structures (the syntax that connects the facts)
when generating the summary. Empirically, we show that our TP-TRANSFORMER
outperforms the Transformer and the original TP-TRANSFORMER significantly on
several abstractive summarization datasets based on both automatic and human
evaluations. On several syntactic and semantic probing tasks, we demonstrate
the emergent structural information in the role vectors and improved syntactic
interpretability in the TPR layer outputs. Code and models are available at
https://github.com/jiangycTarheel/TPT-Summ.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VECO: Variable and Flexible Cross-lingual Pre-training for Language Understanding and Generation. (arXiv:2010.16046v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1">Fuli Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1">Jiahao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1">Yijia Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bi_B/0/1/0/all/0/1">Bin Bi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Songfang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Si_L/0/1/0/all/0/1">Luo Si</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.16046">
                                    <div class="article-summary-box-inner">
                                        <span>Existing work in multilingual pretraining has demonstrated the potential of
cross-lingual transferability by training a unified Transformer encoder for
multiple languages. However, much of this work only relies on the shared
vocabulary and bilingual contexts to encourage the correlation across
languages, which is loose and implicit for aligning the contextual
representations between languages. In this paper, we plug a cross-attention
module into the Transformer encoder to explicitly build the interdependence
between languages. It can effectively avoid the degeneration of predicting
masked words only conditioned on the context in its own language. More
importantly, when fine-tuning on downstream tasks, the cross-attention module
can be plugged in or out on-demand, thus naturally benefiting a wider range of
cross-lingual tasks, from language understanding to generation.

As a result, the proposed cross-lingual model delivers new state-of-the-art
results on various cross-lingual understanding tasks of the XTREME benchmark,
covering text classification, sequence labeling, question answering, and
sentence retrieval. For cross-lingual generation tasks, it also outperforms all
existing cross-lingual models and state-of-the-art Transformer variants on
WMT14 English-to-German and English-to-French translation datasets, with gains
of up to 1~2 BLEU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study. (arXiv:2106.00872v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaushik_D/0/1/0/all/0/1">Divyansh Kaushik</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1">Wen-tau Yih</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00872">
                                    <div class="article-summary-box-inner">
                                        <span>In adversarial data collection (ADC), a human workforce interacts with a
model in real time, attempting to produce examples that elicit incorrect
predictions. Researchers hope that models trained on these more challenging
datasets will rely less on superficial patterns, and thus be less brittle.
However, despite ADC&#x27;s intuitive appeal, it remains unclear when training on
adversarial datasets produces more robust models. In this paper, we conduct a
large-scale controlled study focused on question answering, assigning workers
at random to compose questions either (i) adversarially (with a model in the
loop); or (ii) in the standard fashion (without a model). Across a variety of
models and datasets, we find that models trained on adversarial data usually
perform better on other adversarial datasets but worse on a diverse collection
of out-of-domain evaluation sets. Finally, we provide a qualitative analysis of
adversarial (vs standard) data, identifying key differences and offering
guidance for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Robustness of Text-to-SQL Models against Synonym Substitution. (arXiv:2106.01065v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gan_Y/0/1/0/all/0/1">Yujian Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xinyun Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Qiuping Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Purver_M/0/1/0/all/0/1">Matthew Purver</a>, <a href="http://arxiv.org/find/cs/1/au:+Woodward_J/0/1/0/all/0/1">John R. Woodward</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1">Jinxia Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1">Pengsheng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01065">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there has been significant progress in studying neural networks to
translate text descriptions into SQL queries. Despite achieving good
performance on some public benchmarks, existing text-to-SQL models typically
rely on the lexical matching between words in natural language (NL) questions
and tokens in table schemas, which may render the models vulnerable to attacks
that break the schema linking mechanism. In this work, we investigate the
robustness of text-to-SQL models to synonym substitution. In particular, we
introduce Spider-Syn, a human-curated dataset based on the Spider benchmark for
text-to-SQL translation. NL questions in Spider-Syn are modified from Spider,
by replacing their schema-related words with manually selected synonyms that
reflect real-world question paraphrases. We observe that the accuracy
dramatically drops by eliminating such explicit correspondence between NL
questions and table schemas, even if the synonyms are not adversarially
selected to conduct worst-case adversarial attacks. Finally, we present two
categories of approaches to improve the model robustness. The first category of
approaches utilizes additional synonym annotations for table schemas by
modifying the model input, while the second category is based on adversarial
training. We demonstrate that both categories of approaches significantly
outperform their counterparts without the defense, and the first category of
approaches are more effective.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-Training Sampling with Monolingual Data Uncertainty for Neural Machine Translation. (arXiv:2106.00941v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1">Wenxiang Jiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1">Zhaopeng Tu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_S/0/1/0/all/0/1">Shuming Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1">Michael R. Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1">Irwin King</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00941">
                                    <div class="article-summary-box-inner">
                                        <span>Self-training has proven effective for improving NMT performance by
augmenting model training with synthetic parallel data. The common practice is
to construct synthetic data based on a randomly sampled subset of large-scale
monolingual data, which we empirically show is sub-optimal. In this work, we
propose to improve the sampling procedure by selecting the most informative
monolingual sentences to complement the parallel data. To this end, we compute
the uncertainty of monolingual sentences using the bilingual dictionary
extracted from the parallel data. Intuitively, monolingual sentences with lower
uncertainty generally correspond to easy-to-translate patterns which may not
provide additional gains. Accordingly, we design an uncertainty-based sampling
strategy to efficiently exploit the monolingual data for self-training, in
which monolingual sentences with higher uncertainty would be sampled with
higher probability. Experimental results on large-scale WMT
English$\Rightarrow$German and English$\Rightarrow$Chinese datasets demonstrate
the effectiveness of the proposed approach. Extensive analyses suggest that
emphasizing the learning on uncertain monolingual sentences by our approach
does improve the translation quality of high-uncertainty sentences and also
benefits the prediction of low-frequency words at the target side.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Making Pre-trained Language Models Better Few-shot Learners. (arXiv:2012.15723v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1">Tianyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fisch_A/0/1/0/all/0/1">Adam Fisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Danqi Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15723">
                                    <div class="article-summary-box-inner">
                                        <span>The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot
performance solely by leveraging a natural-language prompt and a few task
demonstrations as input context. Inspired by their findings, we study few-shot
learning in a more practical scenario, where we use smaller language models for
which fine-tuning is computationally efficient. We present LM-BFF--better
few-shot fine-tuning of language models--a suite of simple and complementary
techniques for fine-tuning language models on a small number of annotated
examples. Our approach includes (1) prompt-based fine-tuning together with a
novel pipeline for automating prompt generation; and (2) a refined strategy for
dynamically and selectively incorporating demonstrations into each context.
Finally, we present a systematic evaluation for analyzing few-shot performance
on a range of NLP tasks, including classification and regression. Our
experiments demonstrate that our methods combine to dramatically outperform
standard fine-tuning procedures in this low resource setting, achieving up to
30% absolute improvement, and 11% on average across all tasks. Our approach
makes minimal assumptions on task resources and domain expertise, and hence
constitutes a strong task-agnostic method for few-shot learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">High-Quality Diversification for Task-Oriented Dialogue Systems. (arXiv:2106.00891v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zhiwen Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kulkarni_H/0/1/0/all/0/1">Hrishikesh Kulkarni</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1">Grace Hui Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00891">
                                    <div class="article-summary-box-inner">
                                        <span>Many task-oriented dialogue systems use deep reinforcement learning (DRL) to
learn policies that respond to the user appropriately and complete the tasks
successfully. Training DRL agents with diverse dialogue trajectories prepare
them well for rare user requests and unseen situations. One effective
diversification method is to let the agent interact with a diverse set of
learned user models. However, trajectories created by these artificial user
models may contain generation errors, which can quickly propagate into the
agent&#x27;s policy. It is thus important to control the quality of the
diversification and resist the noise. In this paper, we propose a novel
dialogue diversification method for task-oriented dialogue systems trained in
simulators. Our method, Intermittent Short Extension Ensemble (I-SEE),
constrains the intensity to interact with an ensemble of diverse user models
and effectively controls the quality of the diversification. Evaluations on the
Multiwoz dataset show that I-SEE successfully boosts the performance of several
state-of-the-art DRL dialogue agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Examining the Inductive Bias of Neural Language Models with Artificial Languages. (arXiv:2106.01044v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+White_J/0/1/0/all/0/1">Jennifer C. White</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01044">
                                    <div class="article-summary-box-inner">
                                        <span>Since language models are used to model a wide variety of languages, it is
natural to ask whether the neural architectures used for the task have
inductive biases towards modeling particular types of languages. Investigation
of these biases has proved complicated due to the many variables that appear in
the experimental setup. Languages vary in many typological dimensions, and it
is difficult to single out one or two to investigate without the others acting
as confounders. We propose a novel method for investigating the inductive
biases of language models using artificial languages. These languages are
constructed to allow us to create parallel corpora across languages that differ
only in the typological feature being investigated, such as word order. We then
use them to train and test language models. This constitutes a fully controlled
causal framework, and demonstrates how grammar engineering can serve as a
useful tool for analyzing neural models. Using this method, we find that
commonly used neural architectures exhibit different inductive biases: LSTMs
display little preference with respect to word ordering, while transformers
display a clear preference for some orderings over others. Further, we find
that neither the inductive bias of the LSTM nor that of the transformer appears
to reflect any tendencies that we see in attested natural languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Figurative Language in Recognizing Textual Entailment. (arXiv:2106.01195v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chakrabarty_T/0/1/0/all/0/1">Tuhin Chakrabarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1">Debanjan Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Poliak_A/0/1/0/all/0/1">Adam Poliak</a>, <a href="http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1">Smaranda Muresan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01195">
                                    <div class="article-summary-box-inner">
                                        <span>We introduce a collection of recognizing textual entailment (RTE) datasets
focused on figurative language. We leverage five existing datasets annotated
for a variety of figurative language -- simile, metaphor, and irony -- and
frame them into over 12,500 RTE examples.We evaluate how well state-of-the-art
models trained on popular RTE datasets capture different aspects of figurative
language. Our results and analyses indicate that these models might not
sufficiently capture figurative language, struggling to perform pragmatic
inference and reasoning about world knowledge. Ultimately, our datasets provide
a challenging testbed for evaluating RTE models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Arithmetic Word Problems with Transformers and Preprocessing of Problem Text. (arXiv:2106.00893v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Griffith_K/0/1/0/all/0/1">Kaden Griffith</a>, <a href="http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1">Jugal Kalita</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00893">
                                    <div class="article-summary-box-inner">
                                        <span>This paper outlines the use of Transformer networks trained to translate math
word problems to equivalent arithmetic expressions in infix, prefix, and
postfix notations. We compare results produced by many neural configurations
and find that most configurations outperform previously reported approaches on
three of four datasets with significant increases in accuracy of over 20
percentage points. The best neural approaches boost accuracy by 30% when
compared to the previous state-of-the-art on some datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhanced Universal Dependency Parsing with Second-Order Inference and Mixture of Training Data. (arXiv:2006.01414v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.01414">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the system used in our submission to the \textit{IWPT
2020 Shared Task}. Our system is a graph-based parser with second-order
inference. For the low-resource Tamil corpus, we specially mixed the training
data of Tamil with other languages and significantly improved the performance
of Tamil. Due to our misunderstanding of the submission requirements, we
submitted graphs that are not connected, which makes our system only rank
\textbf{6th} over 10 teams. However, after we fixed this problem, our system is
0.6 ELAS higher than the team that ranked \textbf{1st} in the official results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Infusing Finetuning with Semantic Dependencies. (arXiv:2012.05395v4 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1">Zhaofeng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1">Noah A. Smith</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.05395">
                                    <div class="article-summary-box-inner">
                                        <span>For natural language processing systems, two kinds of evidence support the
use of text representations from neural language models &quot;pretrained&quot; on large
unannotated corpora: performance on application-inspired benchmarks (Peters et
al., 2018, inter alia), and the emergence of syntactic abstractions in those
representations (Tenney et al., 2019, inter alia). On the other hand, the lack
of grounded supervision calls into question how well these representations can
ever capture meaning (Bender and Koller, 2020). We apply novel probes to recent
language models -- specifically focusing on predicate-argument structure as
operationalized by semantic dependencies (Ivanova et al., 2012) -- and find
that, unlike syntax, semantics is not brought to the surface by today&#x27;s
pretrained models. We then use convolutional graph encoders to explicitly
incorporate semantic parses into task-specific finetuning, yielding benefits to
natural language understanding (NLU) tasks in the GLUE benchmark. This approach
demonstrates the potential for general-purpose (rather than task-specific)
linguistic supervision, above and beyond conventional pretraining and
finetuning. Several diagnostics help to localize the benefits of our approach.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accented Speech Recognition: A Survey. (arXiv:2104.10747v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hinsvark_A/0/1/0/all/0/1">Arthur Hinsvark</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Delworth_N/0/1/0/all/0/1">Natalie Delworth</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Rio_M/0/1/0/all/0/1">Miguel Del Rio</a> (1), <a href="http://arxiv.org/find/cs/1/au:+McNamara_Q/0/1/0/all/0/1">Quinten McNamara</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Joshua Dong</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Westerman_R/0/1/0/all/0/1">Ryan Westerman</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Michelle Huang</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Palakapilly_J/0/1/0/all/0/1">Joseph Palakapilly</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Drexler_J/0/1/0/all/0/1">Jennifer Drexler</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Pirkin_I/0/1/0/all/0/1">Ilya Pirkin</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Bhandari_N/0/1/0/all/0/1">Nishchal Bhandari</a> (1), <a href="http://arxiv.org/find/cs/1/au:+Jette_M/0/1/0/all/0/1">Miguel Jette</a> (1) ((1) Rev.com)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10747">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic Speech Recognition (ASR) systems generalize poorly on accented
speech. The phonetic and linguistic variability of accents present hard
challenges for ASR systems today in both data collection and modeling
strategies. The resulting bias in ASR performance across accents comes at a
cost to both users and providers of ASR.

We present a survey of current promising approaches to accented speech
recognition and highlight the key challenges in the space. Approaches mostly
focus on single model generalization and accent feature engineering. Among the
challenges, lack of a standard benchmark makes research and comparison
especially difficult.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">embComp: Visual Interactive Comparison of Vector Embeddings. (arXiv:1911.01542v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heimerl_F/0/1/0/all/0/1">Florian Heimerl</a>, <a href="http://arxiv.org/find/cs/1/au:+Kralj_C/0/1/0/all/0/1">Christoph Kralj</a>, <a href="http://arxiv.org/find/cs/1/au:+Moller_T/0/1/0/all/0/1">Torsten M&#xf6;ller</a>, <a href="http://arxiv.org/find/cs/1/au:+Gleicher_M/0/1/0/all/0/1">Michael Gleicher</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.01542">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces embComp, a novel approach for comparing two embeddings
that capture the similarity between objects, such as word and document
embeddings. We survey scenarios where comparing these embedding spaces is
useful. From those scenarios, we derive common tasks, introduce visual analysis
methods that support these tasks, and combine them into a comprehensive system.
One of embComp&#x27;s central features are overview visualizations that are based on
metrics for measuring differences in the local structure around objects.
Summarizing these local metrics over the embeddings provides global overviews
of similarities and differences. Detail views allow comparison of the local
structure around selected objects and relating this local information to the
global views. Integrating and connecting all of these components, embComp
supports a range of analysis workflows that help understand similarities and
differences between embedding spaces. We assess our approach by applying it in
several use cases, including understanding corpora differences via word vector
embeddings, and understanding algorithmic differences in generating embeddings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Reservoir Transformers. (arXiv:2012.15045v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1">Sheng Shen</a>, <a href="http://arxiv.org/find/cs/1/au:+Baevski_A/0/1/0/all/0/1">Alexei Baevski</a>, <a href="http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1">Ari S. Morcos</a>, <a href="http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1">Kurt Keutzer</a>, <a href="http://arxiv.org/find/cs/1/au:+Auli_M/0/1/0/all/0/1">Michael Auli</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15045">
                                    <div class="article-summary-box-inner">
                                        <span>We demonstrate that transformers obtain impressive performance even when some
of the layers are randomly initialized and never updated. Inspired by old and
well-established ideas in machine learning, we explore a variety of non-linear
&quot;reservoir&quot; layers interspersed with regular transformer layers, and show
improvements in wall-clock compute time until convergence, as well as overall
performance, on various machine translation and (masked) language modelling
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">X-METRA-ADA: Cross-lingual Meta-Transfer Learning Adaptation to Natural Language Understanding and Question Answering. (arXiv:2104.09696v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mhamdi_M/0/1/0/all/0/1">Meryem M&#x27;hamdi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1">Doo Soon Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Dernoncourt_F/0/1/0/all/0/1">Franck Dernoncourt</a>, <a href="http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1">Trung Bui</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1">Xiang Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.09696">
                                    <div class="article-summary-box-inner">
                                        <span>Multilingual models, such as M-BERT and XLM-R, have gained increasing
popularity, due to their zero-shot cross-lingual transfer learning
capabilities. However, their generalization ability is still inconsistent for
typologically diverse languages and across different benchmarks. Recently,
meta-learning has garnered attention as a promising technique for enhancing
transfer learning under low-resource scenarios: particularly for cross-lingual
transfer in Natural Language Understanding (NLU). In this work, we propose
X-METRA-ADA, a cross-lingual MEta-TRAnsfer learning ADAptation approach for
NLU. Our approach adapts MAML, an optimization-based meta-learning approach, to
learn to adapt to new languages. We extensively evaluate our framework on two
challenging cross-lingual NLU tasks: multilingual task-oriented dialog and
typologically diverse question answering. We show that our approach outperforms
naive fine-tuning, reaching competitive performance on both tasks for most
languages. Our analysis reveals that X-METRA-ADA can leverage limited data for
faster adaptation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ARBERT &amp; MARBERT: Deep Bidirectional Transformers for Arabic. (arXiv:2101.01785v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abdul_Mageed_M/0/1/0/all/0/1">Muhammad Abdul-Mageed</a>, <a href="http://arxiv.org/find/cs/1/au:+Elmadany_A/0/1/0/all/0/1">AbdelRahim Elmadany</a>, <a href="http://arxiv.org/find/cs/1/au:+Nagoudi_E/0/1/0/all/0/1">El Moatez Billah Nagoudi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01785">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained language models (LMs) are currently integral to many natural
language processing systems. Although multilingual LMs were also introduced to
serve many languages, these have limitations such as being costly at inference
time and the size and diversity of non-English data involved in their
pre-training. We remedy these issues for a collection of diverse Arabic
varieties by introducing two powerful deep bidirectional transformer-based
models, ARBERT and MARBERT. To evaluate our models, we also introduce ARLUE, a
new benchmark for multi-dialectal Arabic language understanding evaluation.
ARLUE is built using $42$ datasets targeting six different task clusters,
allowing us to offer a series of standardized experiments under rich
conditions. When fine-tuned on ARLUE, our models collectively achieve new
state-of-the-art results across the majority of tasks (37 out of 48
classification tasks, on the 42 datasets). Our best model acquires the highest
ARLUE score (77.40) across all six task clusters, outperforming all other
models including XLM-R Large (~ 3.4 x larger size). Our models are publicly
available at https://github.com/UBC-NLP/marbert and ARLUE will be released
through the same repository.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">speechocean762: An Open-Source Non-native English Speech Corpus For Pronunciation Assessment. (arXiv:2104.01378v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Junbo Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhiwen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yongqing Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhiyong Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1">Qiong Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yukai Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1">Ke Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Povey_D/0/1/0/all/0/1">Daniel Povey</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yujun Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.01378">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces a new open-source speech corpus named &quot;speechocean762&quot;
designed for pronunciation assessment use, consisting of 5000 English
utterances from 250 non-native speakers, where half of the speakers are
children. Five experts annotated each of the utterances at sentence-level,
word-level and phoneme-level. A baseline system is released in open source to
illustrate the phoneme-level pronunciation assessment workflow on this corpus.
This corpus is allowed to be used freely for commercial and non-commercial
purposes. It is available for free download from OpenSLR, and the corresponding
baseline system is published in the Kaldi speech recognition toolkit.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Speakers Fill Lexical Semantic Gaps with Context. (arXiv:2010.02172v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Pimentel_T/0/1/0/all/0/1">Tiago Pimentel</a>, <a href="http://arxiv.org/find/cs/1/au:+Maudslay_R/0/1/0/all/0/1">Rowan Hall Maudslay</a>, <a href="http://arxiv.org/find/cs/1/au:+Blasi_D/0/1/0/all/0/1">Dami&#xe1;n Blasi</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.02172">
                                    <div class="article-summary-box-inner">
                                        <span>Lexical ambiguity is widespread in language, allowing for the reuse of
economical word forms and therefore making language more efficient. If
ambiguous words cannot be disambiguated from context, however, this gain in
efficiency might make language less clear -- resulting in frequent
miscommunication. For a language to be clear and efficiently encoded, we posit
that the lexical ambiguity of a word type should correlate with how much
information context provides about it, on average. To investigate whether this
is the case, we operationalise the lexical ambiguity of a word as the entropy
of meanings it can take, and provide two ways to estimate this -- one which
requires human annotation (using WordNet), and one which does not (using BERT),
making it readily applicable to a large number of languages. We validate these
measures by showing that, on six high-resource languages, there are significant
Pearson correlations between our BERT-based estimate of ambiguity and the
number of synonyms a word has in WordNet (e.g. $\rho &#x3D; 0.40$ in English). We
then test our main hypothesis -- that a word&#x27;s lexical ambiguity should
negatively correlate with its contextual uncertainty -- and find significant
correlations on all 18 typologically diverse languages we analyse. This
suggests that, in the presence of ambiguity, speakers compensate by making
contexts more informative.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">More Embeddings, Better Sequence Labelers?. (arXiv:2009.08330v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bach_N/0/1/0/all/0/1">Nguyen Bach</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhongqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08330">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work proposes a family of contextual embeddings that significantly
improves the accuracy of sequence labelers over non-contextual embeddings.
However, there is no definite conclusion on whether we can build better
sequence labelers by combining different kinds of embeddings in various
settings. In this paper, we conduct extensive experiments on 3 tasks over 18
datasets and 8 languages to study the accuracy of sequence labeling with
various embedding concatenations and make three observations: (1) concatenating
more embedding variants leads to better accuracy in rich-resource and
cross-domain settings and some conditions of low-resource settings; (2)
concatenating additional contextual sub-word embeddings with contextual
character embeddings hurts the accuracy in extremely low-resource settings; (3)
based on the conclusion of (1), concatenating additional similar contextual
embeddings cannot lead to further improvements. We hope these conclusions can
help people build stronger sequence labelers in various settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data Augmentation with Unsupervised Machine Translation Improvesthe Structural Similarity of Cross-lingual Word Embeddings. (arXiv:2006.00262v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nishikawa_S/0/1/0/all/0/1">Sosuke Nishikawa</a>, <a href="http://arxiv.org/find/cs/1/au:+Ri_R/0/1/0/all/0/1">Ryokan Ri</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsuruoka_Y/0/1/0/all/0/1">Yoshimasa Tsuruoka</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.00262">
                                    <div class="article-summary-box-inner">
                                        <span>Unsupervised cross-lingual word embedding (CLWE) methods learn a linear
transformation matrix that maps two monolingual embedding spaces that are
separately trained with monolingual corpora. This method relies on the
assumption that the two embedding spaces are structurally similar, which does
not necessarily hold true in general. In this paper, we argue that using a
pseudo-parallel corpus generated by an unsupervised machine translation model
facilitates the structural similarity of the two embedding spaces and improves
the quality of CLWEs in the unsupervised mapping method. We show that our
approach outperforms other alternative approaches given the same amount of
data, and, through detailed analysis, we show that data augmentation with the
pseudo data from unsupervised machine translation is especially effective for
mapping-based CLWEs because (1) the pseudo data makes the source and target
corpora (partially) parallel; (2) the pseudo data contains information on the
original language that helps to learn similar embedding spaces between the
source and target languages.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision. (arXiv:2012.14862v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Si Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yingzhuo Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenghao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Chenyan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaitao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jie Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1">Paul Bennett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14862">
                                    <div class="article-summary-box-inner">
                                        <span>The effectiveness of Neural Information Retrieval (Neu-IR) often depends on a
large scale of in-domain relevance training signals, which are not always
available in real-world ranking scenarios. To democratize the benefits of
Neu-IR, this paper presents MetaAdaptRank, a domain adaptive learning method
that generalizes Neu-IR models from label-rich source domains to few-shot
target domains. Drawing on source-domain massive relevance supervision,
MetaAdaptRank contrastively synthesizes a large number of weak supervision
signals for target domains and meta-learns to reweight these synthetic &quot;weak&quot;
data based on their benefits to the target-domain ranking accuracy of Neu-IR
models. Experiments on three TREC benchmarks in the web, news, and biomedical
domains show that MetaAdaptRank significantly improves the few-shot ranking
accuracy of Neu-IR models. Further analyses indicate that MetaAdaptRank thrives
from both its contrastive weak data synthesis and meta-reweighted data
selection. The code and data of this paper can be obtained from
https://github.com/thunlp/MetaAdaptRank.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">WARP: Word-level Adversarial ReProgramming. (arXiv:2101.00121v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hambardzumyan_K/0/1/0/all/0/1">Karen Hambardzumyan</a>, <a href="http://arxiv.org/find/cs/1/au:+Khachatrian_H/0/1/0/all/0/1">Hrant Khachatrian</a>, <a href="http://arxiv.org/find/cs/1/au:+May_J/0/1/0/all/0/1">Jonathan May</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00121">
                                    <div class="article-summary-box-inner">
                                        <span>Transfer learning from pretrained language models recently became the
dominant approach for solving many NLP tasks. A common approach to transfer
learning for multiple tasks that maximize parameter sharing trains one or more
task-specific layers on top of the language model. In this paper, we present an
alternative approach based on adversarial reprogramming, which extends earlier
work on automatic prompt generation. Adversarial reprogramming attempts to
learn task-specific word embeddings that, when concatenated to the input text,
instruct the language model to solve the specified task. Using up to 25K
trainable parameters per task, this approach outperforms all existing methods
with up to 25M trainable parameters on the public leaderboard of the GLUE
benchmark. Our method, initialized with task-specific human-readable prompts,
also works in a few-shot setting, outperforming GPT-3 on two SuperGLUE tasks
with just 32 training samples.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning by Semantic Similarity Makes Abstractive Summarization Better. (arXiv:2002.07767v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoon_W/0/1/0/all/0/1">Wonjin Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_Y/0/1/0/all/0/1">Yoon Sun Yeo</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_M/0/1/0/all/0/1">Minbyul Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_B/0/1/0/all/0/1">Bong-Jun Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1">Jaewoo Kang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.07767">
                                    <div class="article-summary-box-inner">
                                        <span>By harnessing pre-trained language models, summarization models had rapid
progress recently. However, the models are mainly assessed by automatic
evaluation metrics such as ROUGE. Although ROUGE is known for having a positive
correlation with human evaluation scores, it has been criticized for its
vulnerability and the gap between actual qualities. In this paper, we compare
the generated summaries from recent LM, BART, and the reference summaries from
a benchmark dataset, CNN/DM, using a crowd-sourced human evaluation metric.
Interestingly, model-generated summaries receive higher scores relative to
reference summaries. Stemming from our experimental results, we first argue the
intrinsic characteristics of the CNN/DM dataset, the progress of pre-trained
language models, and their ability to generalize on the training data. Finally,
we share our insights into the model-generated summaries and presents our
thought on learning methods for abstractive summarization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Unified Generative Framework for Various NER Subtasks. (arXiv:2106.01223v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1">Hang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gui_T/0/1/0/all/0/1">Tao Gui</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1">Junqi Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_Q/0/1/0/all/0/1">Qipeng Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1">Xipeng Qiu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01223">
                                    <div class="article-summary-box-inner">
                                        <span>Named Entity Recognition (NER) is the task of identifying spans that
represent entities in sentences. Whether the entity spans are nested or
discontinuous, the NER task can be categorized into the flat NER, nested NER,
and discontinuous NER subtasks. These subtasks have been mainly solved by the
token-level sequence labelling or span-level classification. However, these
solutions can hardly tackle the three kinds of NER subtasks concurrently. To
that end, we propose to formulate the NER subtasks as an entity span sequence
generation task, which can be solved by a unified sequence-to-sequence
(Seq2Seq) framework. Based on our unified framework, we can leverage the
pre-trained Seq2Seq model to solve all three kinds of NER subtasks without the
special design of the tagging schema or ways to enumerate spans. We exploit
three types of entity representations to linearize entities into a sequence.
Our proposed framework is easy-to-implement and achieves state-of-the-art
(SoTA) or near SoTA performance on eight English NER datasets, including two
flat NER datasets, three nested NER datasets, and three discontinuous NER
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Closer Look at Few-Shot Crosslingual Transfer: The Choice of Shots Matters. (arXiv:2012.15682v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1">Mengjie Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yi Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Shareghi_E/0/1/0/all/0/1">Ehsan Shareghi</a>, <a href="http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1">Ivan Vuli&#x107;</a>, <a href="http://arxiv.org/find/cs/1/au:+Reichart_R/0/1/0/all/0/1">Roi Reichart</a>, <a href="http://arxiv.org/find/cs/1/au:+Korhonen_A/0/1/0/all/0/1">Anna Korhonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15682">
                                    <div class="article-summary-box-inner">
                                        <span>Few-shot crosslingual transfer has been shown to outperform its zero-shot
counterpart with pretrained encoders like multilingual BERT. Despite its
growing popularity, little to no attention has been paid to standardizing and
analyzing the design of few-shot experiments. In this work, we highlight a
fundamental risk posed by this shortcoming, illustrating that the model
exhibits a high degree of sensitivity to the selection of few shots. We conduct
a large-scale experimental study on 40 sets of sampled few shots for six
diverse NLP tasks across up to 40 languages. We provide an analysis of success
and failure cases of few-shot transfer, which highlights the role of lexical
features. Additionally, we show that a straightforward full model finetuning
approach is quite effective for few-shot transfer, outperforming several
state-of-the-art few-shot approaches. As a step towards standardizing few-shot
crosslingual experimental designs, we make our sampled few shots publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is Sparse Attention more Interpretable?. (arXiv:2106.01087v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meister_C/0/1/0/all/0/1">Clara Meister</a>, <a href="http://arxiv.org/find/cs/1/au:+Lazov_S/0/1/0/all/0/1">Stefan Lazov</a>, <a href="http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1">Isabelle Augenstein</a>, <a href="http://arxiv.org/find/cs/1/au:+Cotterell_R/0/1/0/all/0/1">Ryan Cotterell</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01087">
                                    <div class="article-summary-box-inner">
                                        <span>Sparse attention has been claimed to increase model interpretability under
the assumption that it highlights influential inputs. Yet the attention
distribution is typically over representations internal to the model rather
than the inputs themselves, suggesting this assumption may not have merit. We
build on the recent work exploring the interpretability of attention; we design
a set of experiments to help us understand how sparsity affects our ability to
use attention as an explainability tool. On three text classification tasks, we
verify that only a weak relationship between inputs and co-indexed intermediate
representations exists -- under sparse attention and otherwise. Further, we do
not find any plausible mappings from sparse attention distributions to a sparse
set of influential inputs through other avenues. Rather, we observe in this
setting that inducing sparsity may make it less plausible that attention can be
used as a tool for understanding model behavior.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Superbizarre Is Not Superb: Derivational Morphology Improves BERT&#x27;s Interpretation of Complex Words. (arXiv:2101.00403v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hofmann_V/0/1/0/all/0/1">Valentin Hofmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Pierrehumbert_J/0/1/0/all/0/1">Janet B. Pierrehumbert</a>, <a href="http://arxiv.org/find/cs/1/au:+Schutze_H/0/1/0/all/0/1">Hinrich Sch&#xfc;tze</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00403">
                                    <div class="article-summary-box-inner">
                                        <span>How does the input segmentation of pretrained language models (PLMs) affect
their interpretations of complex words? We present the first study
investigating this question, taking BERT as the example PLM and focusing on its
semantic representations of English derivatives. We show that PLMs can be
interpreted as serial dual-route models, i.e., the meanings of complex words
are either stored or else need to be computed from the subwords, which implies
that maximally meaningful input tokens should allow for the best generalization
on new words. This hypothesis is confirmed by a series of semantic probing
tasks on which DelBERT (Derivation leveraging BERT), a model with derivational
input segmentation, substantially outperforms BERT with WordPiece segmentation.
Our results suggest that the generalization capabilities of PLMs could be
further improved if a morphologically-informed vocabulary of input tokens were
used.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Error-driven Fixed-Budget ASR Personalization for Accented Speakers. (arXiv:2103.03142v2 [cs.SD] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Awasthi_A/0/1/0/all/0/1">Abhijeet Awasthi</a>, <a href="http://arxiv.org/find/cs/1/au:+Kansal_A/0/1/0/all/0/1">Aman Kansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarawagi_S/0/1/0/all/0/1">Sunita Sarawagi</a>, <a href="http://arxiv.org/find/cs/1/au:+Jyothi_P/0/1/0/all/0/1">Preethi Jyothi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03142">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the task of personalizing ASR models while being constrained by a
fixed budget on recording speaker-specific utterances. Given a speaker and an
ASR model, we propose a method of identifying sentences for which the speaker&#x27;s
utterances are likely to be harder for the given ASR model to recognize. We
assume a tiny amount of speaker-specific data to learn phoneme-level error
models which help us select such sentences. We show that speaker&#x27;s utterances
on the sentences selected using our error model indeed have larger error rates
when compared to speaker&#x27;s utterances on randomly selected sentences. We find
that fine-tuning the ASR model on the sentence utterances selected with the
help of error models yield higher WER improvements in comparison to fine-tuning
on an equal number of randomly selected sentence utterances. Thus, our method
provides an efficient way of collecting speaker utterances under budget
constraints for personalizing ASR models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Global-Selector: A New Benchmark Dataset and Model Architecture for Multi-turn Response Selection. (arXiv:2106.01263v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Song_C/0/1/0/all/0/1">Chiyu Song</a>, <a href="http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1">Hongliang He</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_H/0/1/0/all/0/1">Huachuan Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1">Haofei Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_Z/0/1/0/all/0/1">Zhenzhong Lan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01263">
                                    <div class="article-summary-box-inner">
                                        <span>As an essential component of dialogue systems, multi-turn response selection
aims to pick out the optimal response among a set of candidates to improve the
dialogue fluency. In this paper, we investigate three problems of current
response selection approaches, especially for generation-based conversational
agents: (i) Existing approaches are often formulated as a sentence scoring
problem, which does not consider relationships between responses. (ii) Existing
models tend to select undesirable candidates that have large overlaps with the
dialogue history. (iii) Negative instances in training are mainly constructed
by random sampling from the corpus, whereas generated candidates in practice
typically have a closer distribution. To address the above problems, we create
a new dataset called ConvAI2+ and propose a new response selector called
Global-Selector. Experimental results show that Global-Selector trained on
ConvAI2+ have noticeable improvements in both accuracy and inference speed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Style is NOT a single variable: Case Studies for Cross-Style Language Understanding. (arXiv:1911.03663v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1">Dongyeop Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1">Eduard Hovy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.03663">
                                    <div class="article-summary-box-inner">
                                        <span>Every natural text is written in some style. Style is formed by a complex
combination of different stylistic factors, including formality markers,
emotions, metaphors, etc. One cannot form a complete understanding of a text
without considering these factors. The factors combine and co-vary in complex
ways to form styles. Studying the nature of the co-varying combinations sheds
light on stylistic language in general, sometimes called cross-style language
understanding. This paper provides the benchmark corpus (xSLUE) that combines
existing datasets and collects a new one for sentence-level cross-style
language understanding and evaluation. The benchmark contains text in 15
different styles under the proposed four theoretical groupings: figurative,
personal, affective, and interpersonal groups. For valid evaluation, we collect
an additional diagnostic set by annotating all 15 styles on the same text.
Using xSLUE, we propose three interesting cross-style applications in
classification, correlation, and generation. First, our proposed cross-style
classifier trained with multiple styles together helps improve overall
classification performance against individually-trained style classifiers.
Second, our study shows that some styles are highly dependent on each other in
human-written text. Finally, we find that combinations of some contradictive
styles likely generate stylistically less appropriate text. We believe our
benchmark and case studies help explore interesting future directions for
cross-style research. The preprocessed datasets and code are publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Differential Privacy for Text Analytics via Natural Text Sanitization. (arXiv:2106.01221v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1">Xiang Yue</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1">Minxin Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tianhao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yaliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1">Huan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chow_S/0/1/0/all/0/1">Sherman S. M. Chow</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01221">
                                    <div class="article-summary-box-inner">
                                        <span>Texts convey sophisticated knowledge. However, texts also convey sensitive
information. Despite the success of general-purpose language models and
domain-specific mechanisms with differential privacy (DP), existing text
sanitization mechanisms still provide low utility, as cursed by the
high-dimensional text representation. The companion issue of utilizing
sanitized texts for downstream analytics is also under-explored. This paper
takes a direct approach to text sanitization. Our insight is to consider both
sensitivity and similarity via our new local DP notion. The sanitized texts
also contribute to our sanitization-aware pretraining and fine-tuning, enabling
privacy-preserving natural language processing over the BERT language model
with promising utility. Surprisingly, the high utility does not boost up the
success rate of inference attacks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compositional Generalization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both?. (arXiv:2010.12725v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shaw_P/0/1/0/all/0/1">Peter Shaw</a>, <a href="http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1">Ming-Wei Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Pasupat_P/0/1/0/all/0/1">Panupong Pasupat</a>, <a href="http://arxiv.org/find/cs/1/au:+Toutanova_K/0/1/0/all/0/1">Kristina Toutanova</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.12725">
                                    <div class="article-summary-box-inner">
                                        <span>Sequence-to-sequence models excel at handling natural language variation, but
have been shown to struggle with out-of-distribution compositional
generalization. This has motivated new specialized architectures with stronger
compositional biases, but most of these approaches have only been evaluated on
synthetically-generated datasets, which are not representative of natural
language variation. In this work we ask: can we develop a semantic parsing
approach that handles both natural language variation and compositional
generalization? To better assess this capability, we propose new train and test
splits of non-synthetic datasets. We demonstrate that strong existing
approaches do not perform well across a broad set of evaluations. We also
propose NQG-T5, a hybrid model that combines a high-precision grammar-based
approach with a pre-trained sequence-to-sequence model. It outperforms existing
approaches across several compositional generalization challenges on
non-synthetic data, while also being competitive with the state-of-the-art on
standard evaluations. While still far from solving this problem, our study
highlights the importance of diverse evaluations and the open challenge of
handling both compositional generalization and natural language variation in
semantic parsing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quality Estimation for Image Captions Based on Large-scale Human Evaluations. (arXiv:1909.03396v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Levinboim_T/0/1/0/all/0/1">Tomer Levinboim</a>, <a href="http://arxiv.org/find/cs/1/au:+Thapliyal_A/0/1/0/all/0/1">Ashish V. Thapliyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1">Piyush Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1">Radu Soricut</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.03396">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic image captioning has improved significantly over the last few
years, but the problem is far from being solved, with state of the art models
still often producing low quality captions when used in the wild. In this
paper, we focus on the task of Quality Estimation (QE) for image captions,
which attempts to model the caption quality from a human perspective and
without access to ground-truth references, so that it can be applied at
prediction time to detect low-quality captions produced on previously unseen
images. For this task, we develop a human evaluation process that collects
coarse-grained caption annotations from crowdsourced users, which is then used
to collect a large scale dataset spanning more than 600k caption quality
ratings. We then carefully validate the quality of the collected ratings and
establish baseline models for this new QE task. Finally, we further collect
fine-grained caption quality annotations from trained raters, and use them to
demonstrate that QE models trained over the coarse ratings can effectively
detect and filter out low-quality image captions, thereby improving the user
experience from captioning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lower Perplexity is Not Always Human-Like. (arXiv:2106.01229v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kuribayashi_T/0/1/0/all/0/1">Tatsuki Kuribayashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Oseki_Y/0/1/0/all/0/1">Yohei Oseki</a>, <a href="http://arxiv.org/find/cs/1/au:+Ito_T/0/1/0/all/0/1">Takumi Ito</a>, <a href="http://arxiv.org/find/cs/1/au:+Yoshida_R/0/1/0/all/0/1">Ryo Yoshida</a>, <a href="http://arxiv.org/find/cs/1/au:+Asahara_M/0/1/0/all/0/1">Masayuki Asahara</a>, <a href="http://arxiv.org/find/cs/1/au:+Inui_K/0/1/0/all/0/1">Kentaro Inui</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01229">
                                    <div class="article-summary-box-inner">
                                        <span>In computational psycholinguistics, various language models have been
evaluated against human reading behavior (e.g., eye movement) to build
human-like computational models. However, most previous efforts have focused
almost exclusively on English, despite the recent trend towards linguistic
universal within the general community. In order to fill the gap, this paper
investigates whether the established results in computational psycholinguistics
can be generalized across languages. Specifically, we re-examine an established
generalization -- the lower perplexity a language model has, the more
human-like the language model is -- in Japanese with typologically different
structures from English. Our experiments demonstrate that this established
generalization exhibits a surprising lack of universality; namely, lower
perplexity is not always human-like. Moreover, this discrepancy between English
and Japanese is further explored from the perspective of (non-)uniform
information density. Overall, our results suggest that a cross-lingual
evaluation will be necessary to construct human-like computational models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Label-aware Event Trigger and Argument Classification. (arXiv:2012.15243v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongming Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Haoyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1">Dan Roth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15243">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying events and mapping them to pre-defined event types has long been
an important natural language processing problem. Most previous work has been
heavily relying on labor-intensive and domain-specific annotations while
ignoring the semantic meaning contained in the labels of the event types. As a
result, the learned models cannot effectively generalize to new domains, where
new event types could be introduced. In this paper, we propose an unsupervised
event extraction pipeline, which first identifies events with available tools
(e.g., SRL) and then automatically maps them to pre-defined event types with
our proposed unsupervised classification model. Rather than relying on
annotated data, our model matches the semantics of identified events with those
of event type labels. Specifically, we leverage pre-trained language models to
contextually represent pre-defined types for both event triggers and arguments.
After we map identified events to the target types via representation
similarity, we use the event ontology (e.g., argument type &quot;Victim&quot; can only
appear as the argument of event type &quot;Attack&quot;) as global constraints to
regularize the prediction. The proposed approach is shown to be very effective
when tested on the ACE-2005 dataset, which has 33 trigger and 22 argument
types. Without using any annotation, we successfully map 83% of the triggers
and 54% of the arguments to the correct types, almost doubling the performance
of previous zero-shot approaches.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Metaphor Generation with Conceptual Mappings. (arXiv:2106.01228v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Stowe_K/0/1/0/all/0/1">Kevin Stowe</a>, <a href="http://arxiv.org/find/cs/1/au:+Chakrabarty_T/0/1/0/all/0/1">Tuhin Chakrabarty</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_N/0/1/0/all/0/1">Nanyun Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Muresan_S/0/1/0/all/0/1">Smaranda Muresan</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1">Iryna Gurevych</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01228">
                                    <div class="article-summary-box-inner">
                                        <span>Generating metaphors is a difficult task as it requires understanding nuanced
relationships between abstract concepts. In this paper, we aim to generate a
metaphoric sentence given a literal expression by replacing relevant verbs.
Guided by conceptual metaphor theory, we propose to control the generation
process by encoding conceptual mappings between cognitive domains to generate
meaningful metaphoric expressions. To achieve this, we develop two methods: 1)
using FrameNet-based embeddings to learn mappings between domains and applying
them at the lexical level (CM-Lex), and 2) deriving source/target pairs to
train a controlled seq-to-seq generation model (CM-BART). We assess our methods
through automatic and human evaluation for basic metaphoricity and conceptual
metaphor presence. We show that the unsupervised CM-Lex model is competitive
with recent deep learning metaphor generation systems, and CM-BART outperforms
all other models both in automatic and human evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evidence-based Factual Error Correction. (arXiv:2106.01072v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1">James Thorne</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1">Andreas Vlachos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01072">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the task of factual error correction: performing edits
to a claim so that the generated rewrite is better supported by evidence. This
extends the well-studied task of fact verification by providing a mechanism to
correct written texts that are refuted or only partially supported by evidence.
We demonstrate that it is feasible to train factual error correction systems
from existing fact checking datasets which only contain labeled claims
accompanied by evidence, but not the correction. We achieve this by employing a
two-stage distant supervision approach that incorporates evidence into masked
claims when generating corrections. Our approach, based on the T5 transformer
and using retrieved evidence, achieved better results than existing work which
used a pointer copy network and gold evidence, producing accurate factual error
corrections for 5x more instances in human evaluation and a .125 increase in
SARI score. The evaluation is conducted on a dataset of 65,000 instances based
on a recent fact verification shared task and we release it to enable further
work on the task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and Non-Local Relations. (arXiv:2106.01093v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_R/0/1/0/all/0/1">Ruisheng Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lu Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhi Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Su Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1">Kai Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01093">
                                    <div class="article-summary-box-inner">
                                        <span>This work aims to tackle the challenging heterogeneous graph encoding problem
in the text-to-SQL task. Previous methods are typically node-centric and merely
utilize different weight matrices to parameterize edge types, which 1) ignore
the rich semantics embedded in the topological structure of edges, and 2) fail
to distinguish local and non-local relations for each node. To this end, we
propose a Line Graph Enhanced Text-to-SQL (LGESQL) model to mine the underlying
relational features without constructing meta-paths. By virtue of the line
graph, messages propagate more efficiently through not only connections between
nodes, but also the topology of directed edges. Furthermore, both local and
non-local relations are integrated distinctively during the graph iteration. We
also design an auxiliary task called graph pruning to improve the
discriminative capability of the encoder. Our framework achieves
state-of-the-art results (62.8% with Glove, 72.0% with Electra) on the
cross-domain text-to-SQL benchmark Spider at the time of writing.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilingual Medical Question Answering and Information Retrieval for Rural Health Intelligence Access. (arXiv:2106.01251v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vinod_V/0/1/0/all/0/1">Vishal Vinod</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1">Susmit Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaurav_V/0/1/0/all/0/1">Vipul Gaurav</a>, <a href="http://arxiv.org/find/cs/1/au:+R_P/0/1/0/all/0/1">Pallavi R</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1">Savita Choudhary</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01251">
                                    <div class="article-summary-box-inner">
                                        <span>In rural regions of several developing countries, access to quality
healthcare, medical infrastructure, and professional diagnosis is largely
unavailable. Many of these regions are gradually gaining access to internet
infrastructure, although not with a strong enough connection to allow for
sustained communication with a medical practitioner. Several deaths resulting
from this lack of medical access, absence of patient&#x27;s previous health records,
and the unavailability of information in indigenous languages can be easily
prevented. In this paper, we describe an approach leveraging the phenomenal
progress in Machine Learning and NLP (Natural Language Processing) techniques
to design a model that is low-resource, multilingual, and a preliminary
first-point-of-contact medical assistant. Our contribution includes defining
the NLP pipeline required for named-entity-recognition, language-agnostic
sentence embedding, natural language translation, information retrieval,
question answering, and generative pre-training for final query processing. We
obtain promising results for this pipeline and preliminary results for EHR
(Electronic Health Record) analysis with text summarization for medical
practitioners to peruse for their diagnosis. Through this NLP pipeline, we aim
to provide preliminary medical information to the user and do not claim to
supplant diagnosis from qualified medical practitioners. Using the input from
subject matter experts, we have compiled a large corpus to pre-train and
fine-tune our BioBERT based NLP model for the specific tasks. We expect recent
advances in NLP architectures, several of which are efficient and
privacy-preserving models, to further the impact of our solution and improve on
individual task performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Partial-Label Learning. (arXiv:2106.00984v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yunfeng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1">Guoxian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhongmin Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Lizhen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Domeniconi_C/0/1/0/all/0/1">Carlotta Domeniconi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00984">
                                    <div class="article-summary-box-inner">
                                        <span>Partial-label learning (PLL) generally focuses on inducing a noise-tolerant
multi-class classifier by training on overly-annotated samples, each of which
is annotated with a set of labels, but only one is the valid label. A basic
promise of existing PLL solutions is that there are sufficient partial-label
(PL) samples for training. However, it is more common than not to have just few
PL samples at hand when dealing with new tasks. Furthermore, existing few-shot
learning algorithms assume precise labels of the support set; as such,
irrelevant labels may seriously mislead the meta-learner and thus lead to a
compromised performance. How to enable PLL under a few-shot learning setting is
an important problem, but not yet well studied. In this paper, we introduce an
approach called FsPLL (Few-shot PLL). FsPLL first performs adaptive distance
metric learning by an embedding network and rectifying prototypes on the tasks
previously encountered. Next, it calculates the prototype of each class of a
new task in the embedding network. An unseen example can then be classified via
its distance to each prototype. Experimental results on widely-used few-shot
datasets (Omniglot and miniImageNet) demonstrate that our FsPLL can achieve a
superior performance than the state-of-the-art methods across different
settings, and it needs fewer samples for quickly adapting to new tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Who Blames or Endorses Whom? Entity-to-Entity Directed Sentiment Extraction in News Text. (arXiv:2106.01033v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1">Kunwoo Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zhufeng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Joo_J/0/1/0/all/0/1">Jungseock Joo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01033">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding who blames or supports whom in news text is a critical research
question in computational social science. Traditional methods and datasets for
sentiment analysis are, however, not suitable for the domain of political text
as they do not consider the direction of sentiments expressed between entities.
In this paper, we propose a novel NLP task of identifying directed sentiment
relationship between political entities from a given news document, which we
call directed sentiment extraction. From a million-scale news corpus, we
construct a dataset of news sentences where sentiment relations of political
entities are manually annotated. We present a simple but effective approach for
utilizing a pretrained transformer, which infers the target class by predicting
multiple question-answering tasks and combining the outcomes. We demonstrate
the utility of our proposed method for social science research questions by
analyzing positive and negative opinions between political entities in two
major events: 2016 U.S. presidential election and COVID-19. The newly proposed
problem, data, and method will facilitate future studies on interdisciplinary
NLP methods and applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">belabBERT: a Dutch RoBERTa-based language model applied to psychiatric classification. (arXiv:2106.01091v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wouts_J/0/1/0/all/0/1">Joppe Wouts</a>, <a href="http://arxiv.org/find/cs/1/au:+Boer_J/0/1/0/all/0/1">Janna de Boer</a>, <a href="http://arxiv.org/find/cs/1/au:+Voppel_A/0/1/0/all/0/1">Alban Voppel</a>, <a href="http://arxiv.org/find/cs/1/au:+Brederoo_S/0/1/0/all/0/1">Sanne Brederoo</a>, <a href="http://arxiv.org/find/cs/1/au:+Splunter_S/0/1/0/all/0/1">Sander van Splunter</a>, <a href="http://arxiv.org/find/cs/1/au:+Sommer_I/0/1/0/all/0/1">Iris Sommer</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01091">
                                    <div class="article-summary-box-inner">
                                        <span>Natural language processing (NLP) is becoming an important means for
automatic recognition of human traits and states, such as intoxication,
presence of psychiatric disorders, presence of airway disorders and states of
stress. Such applications have the potential to be an important pillar for
online help lines, and may gradually be introduced into eHealth modules.
However, NLP is language specific and for languages such as Dutch, NLP models
are scarce. As a result, recent Dutch NLP models have a low capture of long
range semantic dependencies over sentences. To overcome this, here we present
belabBERT, a new Dutch language model extending the RoBERTa architecture.
belabBERT is trained on a large Dutch corpus (+32 GB) of web crawled texts. We
applied belabBERT to the classification of psychiatric illnesses. First, we
evaluated the strength of text-based classification using belabBERT, and
compared the results to the existing RobBERT model. Then, we compared the
performance of belabBERT to audio classification for psychiatric disorders.
Finally, a brief exploration was performed, extending the framework to a hybrid
text- and audio-based classification. Our results show that belabBERT
outperformed the current best text classification network for Dutch, RobBERT.
belabBERT also outperformed classification based on audio alone.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving low-resource ASR performance with untranscribed out-of-domain data. (arXiv:2106.01227v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Billa_J/0/1/0/all/0/1">Jayadev Billa</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01227">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-supervised training (SST) is a common approach to leverage
untranscribed/unlabeled speech data to improve automatic speech recognition
performance in low-resource languages. However, if the available unlabeled
speech is mismatched to the target domain, SST is not as effective, and in many
cases performs worse than the original system. In this paper, we address the
issue of low-resource ASR when only untranscribed out-of-domain speech data is
readily available in the target language. Specifically, we look to improve
performance on conversational/telephony speech (target domain) using web
resources, in particular YouTube data, which more closely resembles
news/topical broadcast data. Leveraging SST, we show that while in some cases
simply pooling the out-of-domain data with the training data lowers word error
rate (WER), in all cases, we see improvements if we train first with the
out-of-domain data and then fine-tune the resulting model with the original
training data. Using 2000 hours of speed perturbed YouTube audio in each target
language, with semi-supervised transcripts, we show improvements on multiple
languages/data sets, of up to 16.3% relative improvement in WER over the
baseline systems and up to 7.4% relative improvement in WER over a system that
simply pools the out-of-domain data with the training data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IrEne: Interpretable Energy Prediction for Transformers. (arXiv:2106.01199v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Cao_Q/0/1/0/all/0/1">Qingqing Cao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lal_Y/0/1/0/all/0/1">Yash Kumar Lal</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_H/0/1/0/all/0/1">Harsh Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_A/0/1/0/all/0/1">Aruna Balasubramanian</a>, <a href="http://arxiv.org/find/cs/1/au:+Balasubramanian_N/0/1/0/all/0/1">Niranjan Balasubramanian</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01199">
                                    <div class="article-summary-box-inner">
                                        <span>Existing software-based energy measurements of NLP models are not accurate
because they do not consider the complex interactions between energy
consumption and model execution. We present IrEne, an interpretable and
extensible energy prediction system that accurately predicts the inference
energy consumption of a wide range of Transformer-based NLP models. IrEne
constructs a model tree graph that breaks down the NLP model into modules that
are further broken down into low-level machine learning (ML) primitives. IrEne
predicts the inference energy consumption of the ML primitives as a function of
generalizable features and fine-grained runtime resource usage. IrEne then
aggregates these low-level predictions recursively to predict the energy of
each module and finally of the entire model. Experiments across multiple
Transformer models show IrEne predicts inference energy consumption of
transformer models with an error of under 7% compared to the ground truth. In
contrast, existing energy models see an error of over 50%. We also show how
IrEne can be used to conduct energy bottleneck analysis and to easily evaluate
the energy impact of different architectural choices. We release the code and
data at https://github.com/StonyBrookNLP/irene.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hi-Transformer: Hierarchical Interactive Transformer for Efficient and Effective Long Document Modeling. (arXiv:2106.01040v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chuhan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1">Tao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongfeng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01040">
                                    <div class="article-summary-box-inner">
                                        <span>Transformer is important for text modeling. However, it has difficulty in
handling long documents due to the quadratic complexity with input text length.
In order to handle this problem, we propose a hierarchical interactive
Transformer (Hi-Transformer) for efficient and effective long document
modeling. Hi-Transformer models documents in a hierarchical way, i.e., first
learns sentence representations and then learns document representations. It
can effectively reduce the complexity and meanwhile capture global document
context in the modeling of each sentence. More specifically, we first use a
sentence Transformer to learn the representations of each sentence. Then we use
a document Transformer to model the global document context from these sentence
representations. Next, we use another sentence Transformer to enhance sentence
modeling using the global document context. Finally, we use hierarchical
pooling method to obtain document embedding. Extensive experiments on three
benchmark datasets validate the efficiency and effectiveness of Hi-Transformer
in long document modeling.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DynaEval: Unifying Turn and Dialogue Level Evaluation. (arXiv:2106.01112v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+DHaro_L/0/1/0/all/0/1">Luis Fernando D&#x27;Haro</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yan Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Friedrichs_T/0/1/0/all/0/1">Thomas Friedrichs</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_G/0/1/0/all/0/1">Grandee Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haizhou Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01112">
                                    <div class="article-summary-box-inner">
                                        <span>A dialogue is essentially a multi-turn interaction among interlocutors.
Effective evaluation metrics should reflect the dynamics of such interaction.
Existing automatic metrics are focused very much on the turn-level quality,
while ignoring such dynamics. To this end, we propose DynaEval, a unified
automatic evaluation framework which is not only capable of performing
turn-level evaluation, but also holistically considers the quality of the
entire dialogue. In DynaEval, the graph convolutional network (GCN) is adopted
to model a dialogue in totality, where the graph nodes denote each individual
utterance and the edges represent the dependency between pairs of utterances. A
contrastive loss is then applied to distinguish well-formed dialogues from
carefully constructed negative samples. Experiments show that DynaEval
significantly outperforms the state-of-the-art dialogue coherence model, and
correlates strongly with human judgements across multiple dialogue evaluation
aspects at both turn and dialogue level.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Use of Formal Ethical Reviews in NLP Literature: Historical Trends and Current Practices. (arXiv:2106.01105v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Santy_S/0/1/0/all/0/1">Sebastin Santy</a>, <a href="http://arxiv.org/find/cs/1/au:+Rani_A/0/1/0/all/0/1">Anku Rani</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhury_M/0/1/0/all/0/1">Monojit Choudhury</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01105">
                                    <div class="article-summary-box-inner">
                                        <span>Ethical aspects of research in language technologies have received much
attention recently. It is a standard practice to get a study involving human
subjects reviewed and approved by a professional ethics committee/board of the
institution. How commonly do we see mention of ethical approvals in NLP
research? What types of research or aspects of studies are usually subject to
such reviews? With the rising concerns and discourse around the ethics of NLP,
do we also observe a rise in formal ethical reviews of NLP studies? And, if so,
would this imply that there is a heightened awareness of ethical issues that
was previously lacking? We aim to address these questions by conducting a
detailed quantitative and qualitative analysis of the ACL Anthology, as well as
comparing the trends in our field to those of other related disciplines, such
as cognitive science, machine learning, data mining, and systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Bot-Generated Text by Characterizing Linguistic Accommodation in Human-Bot Interactions. (arXiv:2106.01170v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bhatt_P/0/1/0/all/0/1">Paras Bhatt</a>, <a href="http://arxiv.org/find/cs/1/au:+Rios_A/0/1/0/all/0/1">Anthony Rios</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01170">
                                    <div class="article-summary-box-inner">
                                        <span>Language generation models&#x27; democratization benefits many domains, from
answering health-related questions to enhancing education by providing
AI-driven tutoring services. However, language generation models&#x27;
democratization also makes it easier to generate human-like text at-scale for
nefarious activities, from spreading misinformation to targeting specific
groups with hate speech. Thus, it is essential to understand how people
interact with bots and develop methods to detect bot-generated text. This paper
shows that bot-generated text detection methods are more robust across datasets
and models if we use information about how people respond to it rather than
using the bot&#x27;s text directly. We also analyze linguistic alignment, providing
insight into differences between human-human and human-bot conversations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues. (arXiv:2106.00920v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1">Rishabh Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Balachandran_V/0/1/0/all/0/1">Vidhisha Balachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Vashishth_S/0/1/0/all/0/1">Shikhar Vashishth</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1">Alan Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1">Yulia Tsvetkov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00920">
                                    <div class="article-summary-box-inner">
                                        <span>To successfully negotiate a deal, it is not enough to communicate fluently:
pragmatic planning of persuasive negotiation strategies is essential. While
modern dialogue agents excel at generating fluent sentences, they still lack
pragmatic grounding and cannot reason strategically. We present DialoGraph, a
negotiation system that incorporates pragmatic strategies in a negotiation
dialogue using graph neural networks. DialoGraph explicitly incorporates
dependencies between sequences of strategies to enable improved and
interpretable prediction of next optimal strategies, given the dialogue
context. Our graph-based method outperforms prior state-of-the-art negotiation
models both in the accuracy of strategy/dialogue act prediction and in the
quality of downstream dialogue response generation. We qualitatively show
further benefits of learned strategy-graphs in providing explicit associations
between effective negotiation strategies over the course of the dialogue,
leading to interpretable and strategic dialogues.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One Teacher is Enough? Pre-trained Language Model Distillation from Multiple Teachers. (arXiv:2106.01023v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chuhan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongfeng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01023">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained language models (PLMs) achieve great success in NLP. However,
their huge model sizes hinder their applications in many practical systems.
Knowledge distillation is a popular technique to compress PLMs, which learns a
small student model from a large teacher PLM. However, the knowledge learned
from a single teacher may be limited and even biased, resulting in low-quality
student model. In this paper, we propose a multi-teacher knowledge distillation
framework named MT-BERT for pre-trained language model compression, which can
train high-quality student model from multiple teacher PLMs. In MT-BERT we
design a multi-teacher co-finetuning method to jointly finetune multiple
teacher PLMs in downstream tasks with shared pooling and prediction layers to
align their output space for better collaborative teaching. In addition, we
propose a multi-teacher hidden loss and a multi-teacher distillation loss to
transfer the useful knowledge in both hidden states and soft labels from
multiple teacher PLMs to the student model. Experiments on three benchmark
datasets validate the effectiveness of MT-BERT in compressing PLMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why Machine Reading Comprehension Models Learn Shortcuts?. (arXiv:2106.01024v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1">Yuxuan Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chen Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yansong Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1">Quzhe Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1">Dongyan Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01024">
                                    <div class="article-summary-box-inner">
                                        <span>Recent studies report that many machine reading comprehension (MRC) models
can perform closely to or even better than humans on benchmark datasets.
However, existing works indicate that many MRC models may learn shortcuts to
outwit these benchmarks, but the performance is unsatisfactory in real-world
applications. In this work, we attempt to explore, instead of the expected
comprehension skills, why these models learn the shortcuts. Based on the
observation that a large portion of questions in current datasets have shortcut
solutions, we argue that larger proportion of shortcut questions in training
data make models rely on shortcut tricks excessively. To investigate this
hypothesis, we carefully design two synthetic datasets with annotations that
indicate whether a question can be answered using shortcut solutions. We
further propose two new methods to quantitatively analyze the learning
difficulty regarding shortcut and challenging questions, and revealing the
inherent learning mechanism behind the different performance between the two
kinds of questions. A thorough empirical analysis shows that MRC models tend to
learn shortcut questions earlier than challenging questions, and the high
proportions of shortcut questions in training sets hinder models from exploring
the sophisticated reasoning skills in the later stage of training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Out-of-Domain Detection via Pre-trained Transformers. (arXiv:2106.00948v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Keyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_T/0/1/0/all/0/1">Tongzheng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shikun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yihao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00948">
                                    <div class="article-summary-box-inner">
                                        <span>Deployed real-world machine learning applications are often subject to
uncontrolled and even potentially malicious inputs. Those out-of-domain inputs
can lead to unpredictable outputs and sometimes catastrophic safety issues.
Prior studies on out-of-domain detection require in-domain task labels and are
limited to supervised classification scenarios. Our work tackles the problem of
detecting out-of-domain samples with only unsupervised in-domain data. We
utilize the latent representations of pre-trained transformers and propose a
simple yet effective method to transform features across all layers to
construct out-of-domain detectors efficiently. Two domain-specific fine-tuning
approaches are further proposed to boost detection accuracy. Our empirical
evaluations of related methods on two datasets validate that our method greatly
improves out-of-domain detection ability in a more general scenario.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Minimax and Neyman-Pearson Meta-Learning for Outlier Languages. (arXiv:2106.01051v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ponti_E/0/1/0/all/0/1">Edoardo Maria Ponti</a>, <a href="http://arxiv.org/find/cs/1/au:+Aralikatte_R/0/1/0/all/0/1">Rahul Aralikatte</a>, <a href="http://arxiv.org/find/cs/1/au:+Shrivastava_D/0/1/0/all/0/1">Disha Shrivastava</a>, <a href="http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1">Siva Reddy</a>, <a href="http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1">Anders S&#xf8;gaard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01051">
                                    <div class="article-summary-box-inner">
                                        <span>Model-agnostic meta-learning (MAML) has been recently put forth as a strategy
to learn resource-poor languages in a sample-efficient fashion. Nevertheless,
the properties of these languages are often not well represented by those
available during training. Hence, we argue that the i.i.d. assumption ingrained
in MAML makes it ill-suited for cross-lingual NLP. In fact, under a
decision-theoretic framework, MAML can be interpreted as minimising the
expected risk across training languages (with a uniform prior), which is known
as Bayes criterion. To increase its robustness to outlier languages, we create
two variants of MAML based on alternative criteria: Minimax MAML reduces the
maximum risk across languages, while Neyman-Pearson MAML constrains the risk in
each language to a maximum threshold. Both criteria constitute fully
differentiable two-player games. In light of this, we propose a new adaptive
optimiser solving for a local approximation to their Nash equilibrium. We
evaluate both model variants on two popular NLP tasks, part-of-speech tagging
and question answering. We report gains for their average and minimum
performance across low-resource languages in zero- and few-shot settings,
compared to joint multi-source transfer and vanilla MAML.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Comparing Test Sets with Item Response Theory. (arXiv:2106.00840v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vania_C/0/1/0/all/0/1">Clara Vania</a>, <a href="http://arxiv.org/find/cs/1/au:+Htut_P/0/1/0/all/0/1">Phu Mon Htut</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">William Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mungra_D/0/1/0/all/0/1">Dhara Mungra</a>, <a href="http://arxiv.org/find/cs/1/au:+Pang_R/0/1/0/all/0/1">Richard Yuanzhe Pang</a>, <a href="http://arxiv.org/find/cs/1/au:+Phang_J/0/1/0/all/0/1">Jason Phang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Haokun Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1">Kyunghyun Cho</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1">Samuel R. Bowman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00840">
                                    <div class="article-summary-box-inner">
                                        <span>Recent years have seen numerous NLP datasets introduced to evaluate the
performance of fine-tuned models on natural language understanding tasks.
Recent results from large pretrained models, though, show that many of these
datasets are largely saturated and unlikely to be able to detect further
progress. What kind of datasets are still effective at discriminating among
strong models, and what kind of datasets should we expect to be able to detect
future improvements? To measure this uniformly across datasets, we draw on Item
Response Theory and evaluate 29 datasets using predictions from 18 pretrained
Transformer models on individual test examples. We find that Quoref, HellaSwag,
and MC-TACO are best suited for distinguishing among state-of-the-art models,
while SNLI, MNLI, and CommitmentBank seem to be saturated for current strong
models. We also observe span selection task format, which is used for QA
datasets like QAMR or SQuAD2.0, is effective in differentiating between strong
and weak models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Answer Generation for Retrieval-based Question Answering Systems. (arXiv:2106.00955v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1">Chao-Chun Hsu</a>, <a href="http://arxiv.org/find/cs/1/au:+Lind_E/0/1/0/all/0/1">Eric Lind</a>, <a href="http://arxiv.org/find/cs/1/au:+Soldaini_L/0/1/0/all/0/1">Luca Soldaini</a>, <a href="http://arxiv.org/find/cs/1/au:+Moschitti_A/0/1/0/all/0/1">Alessandro Moschitti</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00955">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advancements in transformer-based models have greatly improved the
ability of Question Answering (QA) systems to provide correct answers; in
particular, answer sentence selection (AS2) models, core components of
retrieval-based systems, have achieved impressive results. While generally
effective, these models fail to provide a satisfying answer when all retrieved
candidates are of poor quality, even if they contain correct information. In
AS2, models are trained to select the best answer sentence among a set of
candidates retrieved for a given question. In this work, we propose to generate
answers from a set of AS2 top candidates. Rather than selecting the best
candidate, we train a sequence to sequence transformer model to generate an
answer from a candidate set. Our tests on three English AS2 datasets show
improvement up to 32 absolute points in accuracy over the state of the art.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">What Ingredients Make for an Effective Crowdsourcing Protocol for Difficult NLU Data Collection Tasks?. (arXiv:2106.00794v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nangia_N/0/1/0/all/0/1">Nikita Nangia</a>, <a href="http://arxiv.org/find/cs/1/au:+Sugawara_S/0/1/0/all/0/1">Saku Sugawara</a>, <a href="http://arxiv.org/find/cs/1/au:+Trivedi_H/0/1/0/all/0/1">Harsh Trivedi</a>, <a href="http://arxiv.org/find/cs/1/au:+Warstadt_A/0/1/0/all/0/1">Alex Warstadt</a>, <a href="http://arxiv.org/find/cs/1/au:+Vania_C/0/1/0/all/0/1">Clara Vania</a>, <a href="http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1">Samuel R. Bowman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00794">
                                    <div class="article-summary-box-inner">
                                        <span>Crowdsourcing is widely used to create data for common natural language
understanding tasks. Despite the importance of these datasets for measuring and
refining model understanding of language, there has been little focus on the
crowdsourcing methods used for collecting the datasets. In this paper, we
compare the efficacy of interventions that have been proposed in prior work as
ways of improving data quality. We use multiple-choice question answering as a
testbed and run a randomized trial by assigning crowdworkers to write questions
under one of four different data collection protocols. We find that asking
workers to write explanations for their examples is an ineffective stand-alone
strategy for boosting NLU example difficulty. However, we find that training
crowdworkers, and then using an iterative process of collecting data, sending
feedback, and qualifying workers based on expert judgments is an effective
means of collecting challenging data. But using crowdsourced, instead of expert
judgments, to qualify workers and send feedback does not prove to be effective.
We observe that the data from the iterative protocol with expert assessments is
more challenging by several measures. Notably, the human--model gap on the
unanimous agreement portion of this data is, on average, twice as large as the
gap for the baseline protocol data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ConvoSumm: Conversation Summarization Benchmark and Improved Abstractive Summarization with Argument Mining. (arXiv:2106.00829v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fabbri_A/0/1/0/all/0/1">Alexander R. Fabbri</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahman_F/0/1/0/all/0/1">Faiaz Rahman</a>, <a href="http://arxiv.org/find/cs/1/au:+Rizvi_I/0/1/0/all/0/1">Imad Rizvi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1">Borui Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1">Haoran Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mehdad_Y/0/1/0/all/0/1">Yashar Mehdad</a>, <a href="http://arxiv.org/find/cs/1/au:+Radev_D/0/1/0/all/0/1">Dragomir Radev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00829">
                                    <div class="article-summary-box-inner">
                                        <span>While online conversations can cover a vast amount of information in many
different formats, abstractive text summarization has primarily focused on
modeling solely news articles. This research gap is due, in part, to the lack
of standardized datasets for summarizing online discussions. To address this
gap, we design annotation protocols motivated by an
issues--viewpoints--assertions framework to crowdsource four new datasets on
diverse online conversation forms of news comments, discussion forums,
community question answering forums, and email threads. We benchmark
state-of-the-art models on our datasets and analyze characteristics associated
with the data. To create a comprehensive benchmark, we also evaluate these
models on widely-used conversation summarization datasets to establish strong
baselines in this domain. Furthermore, we incorporate argument mining through
graph construction to directly model the issues, viewpoints, and assertions
present in a conversation and filter noisy input, showing comparable or
improved results according to automatic and human evaluations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">RevCore: Review-augmented Conversational Recommendation. (arXiv:2106.00957v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1">Yu Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Junwei Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1">Yan Song</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1">Zichen Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_S/0/1/0/all/0/1">Shuguang Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Youzheng Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1">Xiaodong He</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00957">
                                    <div class="article-summary-box-inner">
                                        <span>Existing conversational recommendation (CR) systems usually suffer from
insufficient item information when conducted on short dialogue history and
unfamiliar items. Incorporating external information (e.g., reviews) is a
potential solution to alleviate this problem. Given that reviews often provide
a rich and detailed user experience on different interests, they are potential
ideal resources for providing high-quality recommendations within an
informative conversation. In this paper, we design a novel end-to-end
framework, namely, Review-augmented Conversational Recommender (RevCore), where
reviews are seamlessly incorporated to enrich item information and assist in
generating both coherent and informative responses. In detail, we extract
sentiment-consistent reviews, perform review-enriched and entity-based
recommendations for item suggestions, as well as use a review-attentive
encoder-decoder for response generation. Experimental results demonstrate the
superiority of our approach in yielding better performance on both
recommendation and conversation responding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Multi-Level Attention Model for Evidence-Based Fact Checking. (arXiv:2106.00950v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kruengkrai_C/0/1/0/all/0/1">Canasai Kruengkrai</a>, <a href="http://arxiv.org/find/cs/1/au:+Yamagishi_J/0/1/0/all/0/1">Junichi Yamagishi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xin Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00950">
                                    <div class="article-summary-box-inner">
                                        <span>Evidence-based fact checking aims to verify the truthfulness of a claim
against evidence extracted from textual sources. Learning a representation that
effectively captures relations between a claim and evidence can be challenging.
Recent state-of-the-art approaches have developed increasingly sophisticated
models based on graph structures. We present a simple model that can be trained
on sequence structures. Our model enables inter-sentence attentions at
different levels and can benefit from joint training. Results on a large-scale
dataset for Fact Extraction and VERification (FEVER) show that our model
outperforms the graph-based approaches and yields 1.09% and 1.42% improvements
in label accuracy and FEVER score, respectively, over the best published model.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Claim Matching Beyond English to Scale Global Fact-Checking. (arXiv:2106.00853v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kazemi_A/0/1/0/all/0/1">Ashkan Kazemi</a>, <a href="http://arxiv.org/find/cs/1/au:+Garimella_K/0/1/0/all/0/1">Kiran Garimella</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaffney_D/0/1/0/all/0/1">Devin Gaffney</a>, <a href="http://arxiv.org/find/cs/1/au:+Hale_S/0/1/0/all/0/1">Scott A. Hale</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00853">
                                    <div class="article-summary-box-inner">
                                        <span>Manual fact-checking does not scale well to serve the needs of the internet.
This issue is further compounded in non-English contexts. In this paper, we
discuss claim matching as a possible solution to scale fact-checking. We define
claim matching as the task of identifying pairs of textual messages containing
claims that can be served with one fact-check. We construct a novel dataset of
WhatsApp tipline and public group messages alongside fact-checked claims that
are first annotated for containing &quot;claim-like statements&quot; and then matched
with potentially similar items and annotated for claim matching. Our dataset
contains content in high-resource (English, Hindi) and lower-resource (Bengali,
Malayalam, Tamil) languages. We train our own embedding model using knowledge
distillation and a high-quality &quot;teacher&quot; model in order to address the
imbalance in embedding quality between the low- and high-resource languages in
our dataset. We provide evaluations on the performance of our solution and
compare with baselines and existing state-of-the-art multilingual embedding
models, namely LASER and LaBSE. We demonstrate that our performance exceeds
LASER and LaBSE in all settings. We release our annotated datasets, codebooks,
and trained embedding model to allow for further research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Passage Retrieval with Hashing for Open-domain Question Answering. (arXiv:2106.00882v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yamada_I/0/1/0/all/0/1">Ikuya Yamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1">Akari Asai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00882">
                                    <div class="article-summary-box-inner">
                                        <span>Most state-of-the-art open-domain question answering systems use a neural
retrieval model to encode passages into continuous vectors and extract them
from a knowledge source. However, such retrieval models often require large
memory to run because of the massive size of their passage index. In this
paper, we introduce Binary Passage Retriever (BPR), a memory-efficient neural
retrieval model that integrates a learning-to-hash technique into the
state-of-the-art Dense Passage Retriever (DPR) to represent the passage index
using compact binary codes rather than continuous vectors. BPR is trained with
a multi-task objective over two tasks: efficient candidate generation based on
binary codes and accurate reranking based on continuous vectors. Compared with
DPR, BPR substantially reduces the memory cost from 65GB to 2GB without a loss
of accuracy on two standard open-domain question answering benchmarks: Natural
Questions and TriviaQA. Our code and trained models are available at
https://github.com/studio-ousia/bpr.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Discrete Cosine Transform as Universal Sentence Encoder. (arXiv:2106.00934v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Almarwani_N/0/1/0/all/0/1">Nada Almarwani</a>, <a href="http://arxiv.org/find/cs/1/au:+Diab_M/0/1/0/all/0/1">Mona Diab</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00934">
                                    <div class="article-summary-box-inner">
                                        <span>Modern sentence encoders are used to generate dense vector representations
that capture the underlying linguistic characteristics for a sequence of words,
including phrases, sentences, or paragraphs. These kinds of representations are
ideal for training a classifier for an end task such as sentiment analysis,
question answering and text classification. Different models have been proposed
to efficiently generate general purpose sentence representations to be used in
pretraining protocols. While averaging is the most commonly used efficient
sentence encoder, Discrete Cosine Transform (DCT) was recently proposed as an
alternative that captures the underlying syntactic characteristics of a given
text without compromising practical efficiency compared to averaging. However,
as with most other sentence encoders, the DCT sentence encoder was only
evaluated in English. To this end, we utilize DCT encoder to generate universal
sentence representation for different languages such as German, French, Spanish
and Russian. The experimental results clearly show the superior effectiveness
of DCT encoding in which consistent performance improvements are achieved over
strong baselines on multiple standardized datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Implicit Representations of Meaning in Neural Language Models. (arXiv:2106.00737v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1">Belinda Z. Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Nye_M/0/1/0/all/0/1">Maxwell Nye</a>, <a href="http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1">Jacob Andreas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00737">
                                    <div class="article-summary-box-inner">
                                        <span>Does the effectiveness of neural language models derive entirely from
accurate modeling of surface word co-occurrence statistics, or do these models
represent and reason about the world they describe? In BART and T5 transformer
language models, we identify contextual word representations that function as
models of entities and situations as they evolve throughout a discourse. These
neural representations have functional similarities to linguistic models of
dynamic semantics: they support a linear readout of each entity&#x27;s current
properties and relations, and can be manipulated with predictable effects on
language generation. Our results indicate that prediction in pretrained neural
language models is supported, at least in part, by dynamic representations of
meaning and implicit simulation of entity state, and that this behavior can be
learned with only text as training data. Code and data are available at
https://github.com/belindal/state-probes .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Part of Speech and Universal Dependency effects on English Arabic Machine Translation. (arXiv:2106.00745v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1">Omri Abend</a>, <a href="http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1">Leshem Choshen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolaev_D/0/1/0/all/0/1">Dmitry Nikolaev</a>, <a href="http://arxiv.org/find/cs/1/au:+Rafaeli_O/0/1/0/all/0/1">Ofek Rafaeli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00745">
                                    <div class="article-summary-box-inner">
                                        <span>In this research paper, I will elaborate on a method to evaluate machine
translation models based on their performance on underlying syntactical
phenomena between English and Arabic languages. This method is especially
important as such &quot;neural&quot; and &quot;machine learning&quot; are hard to fine-tune and
change. Thus, finding a way to evaluate them easily and diversely would greatly
help the task of bettering them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conversational Question Answering: A Survey. (arXiv:2106.00874v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zaib_M/0/1/0/all/0/1">Munazza Zaib</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Emma Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1">Quan Z. Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1">Adnan Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00874">
                                    <div class="article-summary-box-inner">
                                        <span>Question answering (QA) systems provide a way of querying the information
available in various formats including, but not limited to, unstructured and
structured data in natural languages. It constitutes a considerable part of
conversational artificial intelligence (AI) which has led to the introduction
of a special research topic on Conversational Question Answering (CQA), wherein
a system is required to understand the given context and then engages in
multi-turn QA to satisfy the user&#x27;s information needs. Whilst the focus of most
of the existing research work is subjected to single-turn QA, the field of
multi-turn QA has recently grasped attention and prominence owing to the
availability of large-scale, multi-turn QA datasets and the development of
pre-trained language models. With a good amount of models and research papers
adding to the literature every year recently, there is a dire need of arranging
and presenting the related work in a unified manner to streamline future
research. This survey, therefore, is an effort to present a comprehensive
review of the state-of-the-art research trends of CQA primarily based on
reviewed papers from 2016-2021. Our findings show that there has been a trend
shift from single-turn to multi-turn QA which empowers the field of
Conversational AI from different perspectives. This survey is intended to
provide an epitome for the research community with the hope of laying a strong
foundation for the field of CQA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Search Methods for Sufficient, Socially-Aligned Feature Importance Explanations with In-Distribution Counterfactuals. (arXiv:2106.00786v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hase_P/0/1/0/all/0/1">Peter Hase</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Harry Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00786">
                                    <div class="article-summary-box-inner">
                                        <span>Feature importance (FI) estimates are a popular form of explanation, and they
are commonly created and evaluated by computing the change in model confidence
caused by removing certain input features at test time. For example, in the
standard Sufficiency metric, only the top-k most important tokens are kept. In
this paper, we study several under-explored dimensions of FI-based
explanations, providing conceptual and empirical improvements for this form of
explanation. First, we advance a new argument for why it can be problematic to
remove features from an input when creating or evaluating explanations: the
fact that these counterfactual inputs are out-of-distribution (OOD) to models
implies that the resulting explanations are socially misaligned. The crux of
the problem is that the model prior and random weight initialization influence
the explanations (and explanation metrics) in unintended ways. To resolve this
issue, we propose a simple alteration to the model training process, which
results in more socially aligned explanations and metrics. Second, we compare
among five approaches for removing features from model inputs. We find that
some methods produce more OOD counterfactuals than others, and we make
recommendations for selecting a feature-replacement function. Finally, we
introduce four search-based methods for identifying FI explanations and compare
them to strong baselines, including LIME, Integrated Gradients, and random
search. On experiments with six diverse text classification datasets, we find
that the only method that consistently outperforms random search is a Parallel
Local Search that we introduce. Improvements over the second-best method are as
large as 5.4 points for Sufficiency and 17 points for Comprehensiveness. All
supporting code is publicly available at
https://github.com/peterbhase/ExplanationSearch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parameter-Efficient Neural Question Answering Models via Graph-Enriched Document Representations. (arXiv:2106.00851v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Castricato_L/0/1/0/all/0/1">Louis Castricato</a>, <a href="http://arxiv.org/find/cs/1/au:+Fitz_S/0/1/0/all/0/1">Stephen Fitz</a>, <a href="http://arxiv.org/find/cs/1/au:+Shin_W/0/1/0/all/0/1">Won Young Shin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00851">
                                    <div class="article-summary-box-inner">
                                        <span>As the computational footprint of modern NLP systems grows, it becomes
increasingly important to arrive at more efficient models. We show that by
employing graph convolutional document representation, we can arrive at a
question answering system that performs comparably to, and in some cases
exceeds the SOTA solutions, while using less than 5\% of their resources in
terms of trainable parameters. As it currently stands, a major issue in
applying GCNs to NLP is document representation. In this paper, we show that a
GCN enriched document representation greatly improves the results seen in
HotPotQA, even when using a trivial topology. Our model (gQA), performs
admirably when compared to the current SOTA, and requires little to no
preprocessing. In Shao et al. 2020, the authors suggest that graph networks are
not necessary for good performance in multi-hop QA. In this paper, we suggest
that large language models are not necessary for good performance by showing a
na\&quot;{i}ve implementation of a GCN performs comparably to SoTA models based on
pretrained language models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.CV"">cs.CV updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1">Joni Korpihalkola</a>, <a href="http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1">Tuomo Sipola</a>, <a href="http://arxiv.org/find/cs/1/au:+Puuska_S/0/1/0/all/0/1">Samir Puuska</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1">Tero Kokkonen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00517">
                                    <div class="article-summary-box-inner">
                                        <span>Computer vision and machine learning can be used to automate various tasks in
cancer diagnostic and detection. If an attacker can manipulate the automated
processing, the results can be devastating and in the worst case lead to wrong
diagnosis and treatment. In this research, the goal is to demonstrate the use
of one-pixel attacks in a real-life scenario with a real pathology dataset,
TUPAC16, which consists of digitized whole-slide images. We attack against the
IBM CODAIT&#x27;s MAX breast cancer detector using adversarial images. These
adversarial examples are found using differential evolution to perform the
one-pixel modification to the images in the dataset. The results indicate that
a minor one-pixel modification of a whole slide image under analysis can affect
the diagnosis by reversing the automatic diagnosis result. The attack poses a
threat from the cyber security perspective: the one-pixel method can be used as
an attack vector by a motivated attacker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Balancing Biases and Preserving Privacy on Balanced Faces in the Wild. (arXiv:2103.09118v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1">Joseph P Robinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_C/0/1/0/all/0/1">Can Qin</a>, <a href="http://arxiv.org/find/cs/1/au:+Henon_Y/0/1/0/all/0/1">Yann Henon</a>, <a href="http://arxiv.org/find/cs/1/au:+Timoner_S/0/1/0/all/0/1">Samson Timoner</a>, <a href="http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1">Yun Fu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.09118">
                                    <div class="article-summary-box-inner">
                                        <span>There are demographic biases in current models used for facial recognition
(FR). Our Balanced Faces In the Wild (BFW) dataset serves as a proxy to measure
bias across ethnicity and gender subgroups, allowing one to characterize FR
performances per subgroup. We show performances are non-optimal when a single
score threshold is used to determine whether sample pairs are genuine or
imposter. Across subgroups, performance ratings vary from the reported across
the entire dataset. Thus, claims of specific error rates only hold true for
populations matching that of the validation data. We mitigate the imbalanced
performances using a novel domain adaptation learning scheme on the facial
features extracted using state-of-the-art. Not only does this technique balance
performance, but it also boosts the overall performance. A benefit of the
proposed is to preserve identity information in facial features while removing
demographic knowledge in the lower dimensional features. The removal of
demographic knowledge prevents future potential biases from being injected into
decision-making. This removal satisfies privacy concerns. We explore why this
works qualitatively; we also show quantitatively that subgroup classifiers can
no longer learn from the features mapped by the proposed.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Lottery Jackpots Exist in Pre-trained Models. (arXiv:2104.08700v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yuxin Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_M/0/1/0/all/0/1">Mingbao Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Chao_F/0/1/0/all/0/1">Fei Chao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yongjian Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Feiyue Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Mingliang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1">Yonghong Tian</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_R/0/1/0/all/0/1">Rongrong Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08700">
                                    <div class="article-summary-box-inner">
                                        <span>Network pruning is an effective approach to reduce network complexity without
performance compromise. Existing studies achieve the sparsity of neural
networks via time-consuming weight tuning or complex search on networks with
expanded width, which greatly limits the applications of network pruning. In
this paper, we show that high-performing and sparse sub-networks without the
involvement of weight tuning, termed &quot;lottery jackpots&quot;, exist in pre-trained
models with unexpanded width. For example, we obtain a lottery jackpot that has
only 10% parameters and still reaches the performance of the original dense
VGGNet-19 without any modifications on the pre-trained weights. Furthermore, we
observe that the sparse masks derived from many existing pruning criteria have
a high overlap with the searched mask of our lottery jackpot, among which, the
magnitude-based pruning results in the most similar mask with ours. Based on
this insight, we initialize our sparse mask using the magnitude pruning,
resulting in at least 3x cost reduction on the lottery jackpot search while
achieves comparable or even better performance. Specifically, our
magnitude-based lottery jackpot removes 90% weights in the ResNet-50, while
easily obtains more than 70% top-1 accuracy using only 10 searching epochs on
ImageNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Inter-GPS: Interpretable Geometry Problem Solving with Formal Language and Symbolic Reasoning. (arXiv:2105.04165v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1">Pan Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1">Ran Gong</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1">Shibiao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1">Liang Qiu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1">Siyuan Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1">Xiaodan Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1">Song-Chun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.04165">
                                    <div class="article-summary-box-inner">
                                        <span>Geometry problem solving has attracted much attention in the NLP community
recently. The task is challenging as it requires abstract problem understanding
and symbolic reasoning with axiomatic knowledge. However, current datasets are
either small in scale or not publicly available. Thus, we construct a new
large-scale benchmark, Geometry3K, consisting of 3,002 geometry problems with
dense annotation in formal language. We further propose a novel geometry
solving approach with formal language and symbolic reasoning, called
Interpretable Geometry Problem Solver (Inter-GPS). Inter-GPS first parses the
problem text and diagram into formal language automatically via rule-based text
parsing and neural object detecting, respectively. Unlike implicit learning in
existing methods, Inter-GPS incorporates theorem knowledge as conditional rules
and performs symbolic reasoning step by step. Also, a theorem predictor is
designed to infer the theorem application sequence fed to the symbolic solver
for the more efficient and reasonable searching path. Extensive experiments on
the Geometry3K and GEOS datasets demonstrate that Inter-GPS achieves
significant improvements over existing methods. The project with code and data
is available at https://lupantech.github.io/inter-gps.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Active Surface Models. (arXiv:2011.08826v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1">Udaranga Wickramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1">Graham Knott</a>, <a href="http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1">Pascal Fua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08826">
                                    <div class="article-summary-box-inner">
                                        <span>Active Surface Models have a long history of being useful to model complex 3D
surfaces but only Active Contours have been used in conjunction with deep
networks, and then only to produce the data term as well as meta-parameter maps
controlling them. In this paper, we advocate a much tighter integration. We
introduce layers that implement them that can be integrated seamlessly into
Graph Convolutional Networks to enforce sophisticated smoothness priors at an
acceptable computational cost. We will show that the resulting Deep Active
Surface Models outperform equivalent architectures that use traditional
regularization loss terms to impose smoothness priors for 3D surface
reconstruction from 2D images and for 3D volume segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Semi-Supervised iNaturalist Challenge at the FGVC8 Workshop. (arXiv:2106.01364v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jong-Chyi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Maji_S/0/1/0/all/0/1">Subhransu Maji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01364">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-iNat is a challenging dataset for semi-supervised classification with a
long-tailed distribution of classes, fine-grained categories, and domain shifts
between labeled and unlabeled data. This dataset is behind the second iteration
of the semi-supervised recognition challenge to be held at the FGVC8 workshop
at CVPR 2021. Different from the previous one, this dataset (i) includes images
of species from different kingdoms in the natural taxonomy, (ii) is at a larger
scale --- with 810 in-class and 1629 out-of-class species for a total of 330k
images, and (iii) does not provide in/out-of-class labels, but provides coarse
taxonomic labels (kingdom and phylum) for the unlabeled images. This document
describes baseline results and the details of the dataset which is available
here: \url{https://github.com/cvl-umass/semi-inat-2021}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Continual Learning in Image Classification: An Empirical Survey. (arXiv:2101.10423v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mai_Z/0/1/0/all/0/1">Zheda Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruiwen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1">Jihwan Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Quispe_D/0/1/0/all/0/1">David Quispe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyunwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanner_S/0/1/0/all/0/1">Scott Sanner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10423">
                                    <div class="article-summary-box-inner">
                                        <span>Online continual learning for image classification studies the problem of
learning to classify images from an online stream of data and tasks, where
tasks may include new classes (class incremental) or data nonstationarity
(domain incremental). One of the key challenges of continual learning is to
avoid catastrophic forgetting (CF), i.e., forgetting old tasks in the presence
of more recent tasks. Over the past few years, many methods and tricks have
been introduced to address this problem, but many have not been fairly and
systematically compared under a variety of realistic and practical settings. To
better understand the relative advantages of various approaches and the
settings where they work best, this survey aims to (1) compare state-of-the-art
methods such as MIR, iCARL, and GDumb and determine which works best at
different experimental settings; (2) determine if the best class incremental
methods are also competitive in domain incremental setting; (3) evaluate the
performance of 7 simple but effective trick such as &quot;review&quot; trick and nearest
class mean (NCM) classifier to assess their relative impact. Regarding (1), we
observe iCaRL remains competitive when the memory buffer is small; GDumb
outperforms many recently proposed methods in medium-size datasets and MIR
performs the best in larger-scale datasets. For (2), we note that GDumb
performs quite poorly while MIR -- already competitive for (1) -- is also
strongly competitive in this very different but important setting. Overall,
this allows us to conclude that MIR is overall a strong and versatile method
across a wide variety of settings. For (3), we find that all 7 tricks are
beneficial, and when augmented with the &quot;review&quot; trick and NCM classifier, MIR
produces performance levels that bring online continual learning much closer to
its ultimate goal of matching offline training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Digital homotopy relations and digital homology theories. (arXiv:2106.01171v1 [math.AT])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Staecker_P/0/1/0/all/0/1">P. Christopher Staecker</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01171">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we prove results relating to two homotopy relations and four
homology theories developed in the topology of digital images.

We introduce a new type of homotopy relation for digitally continuous
functions which we call &quot;strong homotopy.&quot; Both digital homotopy and strong
homotopy are natural digitizations of classical topological homotopy: the
difference between them is analogous to the difference between digital
4-adjacency and 8-adjacency in the plane.

We also consider four different digital homology theories: a simplicial
homology theory by Arslan et al which is the homology of the clique complex, a
singular simplicial homology theory by D. W. Lee, a cubical homology theory by
Jamil and Ali, and a new kind of cubical homology for digital images with
$c_1$-adjacency which is easily computed, and generalizes a construction by
Karaca \&amp; Ege. We show that the two simplicial homology theories are isomorphic
to each other, but distinct from the two cubical theories.

We also show that homotopic maps have the same induced homomorphisms in the
cubical homology theory, and strong homotopic maps additionally have the same
induced homomorphisms in the simplicial theory.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">VideoForensicsHQ: Detecting High-quality Manipulated Face Videos. (arXiv:2005.10360v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fox_G/0/1/0/all/0/1">Gereon Fox</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1">Wentao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyeongwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Seidel_H/0/1/0/all/0/1">Hans-Peter Seidel</a>, <a href="http://arxiv.org/find/cs/1/au:+Elgharib_M/0/1/0/all/0/1">Mohamed Elgharib</a>, <a href="http://arxiv.org/find/cs/1/au:+Theobalt_C/0/1/0/all/0/1">Christian Theobalt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.10360">
                                    <div class="article-summary-box-inner">
                                        <span>There are concerns that new approaches to the synthesis of high quality face
videos may be misused to manipulate videos with malicious intent. The research
community therefore developed methods for the detection of modified footage and
assembled benchmark datasets for this task. In this paper, we examine how the
performance of forgery detectors depends on the presence of artefacts that the
human eye can see. We introduce a new benchmark dataset for face video forgery
detection, of unprecedented quality. It allows us to demonstrate that existing
detection techniques have difficulties detecting fakes that reliably fool the
human eye. We thus introduce a new family of detectors that examine
combinations of spatial and temporal features and outperform existing
approaches both in terms of detection accuracy and generalization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">CycleSegNet: Object Co-segmentation with Cycle Refinement and Region Correspondence. (arXiv:2101.01308v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guankai Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_G/0/1/0/all/0/1">Guosheng Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1">Qingyao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_R/0/1/0/all/0/1">Rui Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.01308">
                                    <div class="article-summary-box-inner">
                                        <span>Image co-segmentation is an active computer vision task that aims to segment
the common objects from a set of images. Recently, researchers design various
learning-based algorithms to undertake the co-segmentation task. The main
difficulty in this task is how to effectively transfer information between
images to make conditional predictions. In this paper, we present CycleSegNet,
a novel framework for the co-segmentation task. Our network design has two key
components: a region correspondence module which is the basic operation for
exchanging information between local image regions, and a cycle refinement
module, which utilizes ConvLSTMs to progressively update image representations
and exchange information in a cycle and iterative manner. Extensive experiments
demonstrate that our proposed method significantly outperforms the
state-of-the-art methods on four popular benchmark datasets -- PASCAL VOC
dataset, MSRC dataset, Internet dataset, and iCoseg dataset, by 2.6%, 7.7%,
2.2%, and 2.9%, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraghVQA: Language-Guided Graph Neural Networks for Graph-based Visual Question Answering. (arXiv:2104.10283v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_W/0/1/0/all/0/1">Weixin Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yanhao Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zixuan Liu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.10283">
                                    <div class="article-summary-box-inner">
                                        <span>Images are more than a collection of objects or attributes -- they represent
a web of relationships among interconnected objects. Scene Graph has emerged as
a new modality for a structured graphical representation of images. Scene Graph
encodes objects as nodes connected via pairwise relations as edges. To support
question answering on scene graphs, we propose GraphVQA, a language-guided
graph neural network framework that translates and executes a natural language
question as multiple iterations of message passing among graph nodes. We
explore the design space of GraphVQA framework, and discuss the trade-off of
different design choices. Our experiments on GQA dataset show that GraphVQA
outperforms the state-of-the-art model by a large margin (88.43% vs. 94.78%).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MPASNET: Motion Prior-Aware Siamese Network for Unsupervised Deep Crowd Segmentation in Video Scenes. (arXiv:2101.08609v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinhai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hua Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08609">
                                    <div class="article-summary-box-inner">
                                        <span>Crowd segmentation is a fundamental task serving as the basis of crowded
scene analysis, and it is highly desirable to obtain refined pixel-level
segmentation maps. However, it remains a challenging problem, as existing
approaches either require dense pixel-level annotations to train deep learning
models or merely produce rough segmentation maps from optical or particle flows
with physical models. In this paper, we propose the Motion Prior-Aware Siamese
Network (MPASNET) for unsupervised crowd semantic segmentation. This model not
only eliminates the need for annotation but also yields high-quality
segmentation maps. Specially, we first analyze the coherent motion patterns
across the frames and then apply a circular region merging strategy on the
collective particles to generate pseudo-labels. Moreover, we equip MPASNET with
siamese branches for augmentation-invariant regularization and siamese feature
aggregation. Experiments over benchmark datasets indicate that our model
outperforms the state-of-the-arts by more than 12% in terms of mIoU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Semantic Segmentation with Cross Pseudo Supervision. (arXiv:2106.01226v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1">Xiaokang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Yuan_Y/0/1/0/all/0/1">Yuhui Yuan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_G/0/1/0/all/0/1">Gang Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jingdong Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01226">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the semi-supervised semantic segmentation problem via
exploring both labeled data and extra unlabeled data. We propose a novel
consistency regularization approach, called cross pseudo supervision (CPS). Our
approach imposes the consistency on two segmentation networks perturbed with
different initialization for the same input image. The pseudo one-hot label
map, output from one perturbed segmentation network, is used to supervise the
other segmentation network with the standard cross-entropy loss, and vice
versa. The CPS consistency has two roles: encourage high similarity between the
predictions of two perturbed networks for the same input image, and expand
training data by using the unlabeled data with pseudo labels. Experiment
results show that our approach achieves the state-of-the-art semi-supervised
segmentation performance on Cityscapes and PASCAL VOC 2012.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Do Neural Networks Estimate Optical Flow? A Neuropsychology-Inspired Study. (arXiv:2004.09317v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jong_D/0/1/0/all/0/1">D. B. de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Paredes_Valles_F/0/1/0/all/0/1">F. Paredes-Vall&#xe9;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Croon_G/0/1/0/all/0/1">G. C. H. E. de Croon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.09317">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end trained convolutional neural networks have led to a breakthrough
in optical flow estimation. The most recent advances focus on improving the
optical flow estimation by improving the architecture and setting a new
benchmark on the publicly available MPI-Sintel dataset. Instead, in this
article, we investigate how deep neural networks estimate optical flow. A
better understanding of how these networks function is important for (i)
assessing their generalization capabilities to unseen inputs, and (ii)
suggesting changes to improve their performance. For our investigation, we
focus on FlowNetS, as it is the prototype of an encoder-decoder neural network
for optical flow estimation. Furthermore, we use a filter identification method
that has played a major role in uncovering the motion filters present in animal
brains in neuropsychological research. The method shows that the filters in the
deepest layer of FlowNetS are sensitive to a variety of motion patterns. Not
only do we find translation filters, as demonstrated in animal brains, but
thanks to the easier measurements in artificial neural networks, we even unveil
dilation, rotation, and occlusion filters. Furthermore, we find similarities in
the refinement part of the network and the perceptual filling-in process which
occurs in the mammal primary visual cortex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data augmentation and pre-trained networks for extremely low data regimes unsupervised visual inspection. (arXiv:2106.01277v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1">Pierre Gutierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Cordier_A/0/1/0/all/0/1">Antoine Cordier</a>, <a href="http://arxiv.org/find/cs/1/au:+Caldeira_T/0/1/0/all/0/1">Tha&#xef;s Caldeira</a>, <a href="http://arxiv.org/find/cs/1/au:+Sautory_T/0/1/0/all/0/1">Th&#xe9;ophile Sautory</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01277">
                                    <div class="article-summary-box-inner">
                                        <span>The use of deep features coming from pre-trained neural networks for
unsupervised anomaly detection purposes has recently gathered momentum in the
computer vision field. In particular, industrial inspection applications can
take advantage of such features, as demonstrated by the multiple successes of
related methods on the MVTec Anomaly Detection (MVTec AD) dataset. These
methods make use of neural networks pre-trained on auxiliary classification
tasks such as ImageNet. However, to our knowledge, no comparative study of
robustness to the low data regimes between these approaches has been conducted
yet. For quality inspection applications, the handling of limited sample sizes
may be crucial as large quantities of images are not available for small
series. In this work, we aim to compare three approaches based on deep
pre-trained features when varying the quantity of available data in MVTec AD:
KNN, Mahalanobis, and PaDiM. We show that although these methods are mostly
robust to small sample sizes, they still can benefit greatly from using data
augmentation in the original image space, which allows to deal with very small
production runs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DFGC 2021: A DeepFake Game Competition. (arXiv:2106.01217v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1">Bo Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1">Hongxing Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_J/0/1/0/all/0/1">Jing Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yuezun Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1">Siwei Lyu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1">Zhenan Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1">Han Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1">Baoying Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1">Yanjie Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shenghai Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Junrui Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yutong Yao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1">Boyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ling_H/0/1/0/all/0/1">Hefei Ling</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guosheng Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhiliang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_C/0/1/0/all/0/1">Changtao Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1">Changlei Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1">Shan He</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1">Xiaoyan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhuang_W/0/1/0/all/0/1">Wanyi Zhuang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01217">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents a summary of the DFGC 2021 competition. DeepFake
technology is developing fast, and realistic face-swaps are increasingly
deceiving and hard to detect. At the same time, DeepFake detection methods are
also improving. There is a two-party game between DeepFake creators and
detectors. This competition provides a common platform for benchmarking the
adversarial game between current state-of-the-art DeepFake creation and
detection methods. In this paper, we present the organization, results and top
solutions of this competition and also share our insights obtained during this
event. We also release the DFGC-21 testing dataset collected from our
participants to further benefit the research community.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Optimization of Areas Under Precision-Recall Curves with Provable Convergence. (arXiv:2104.08736v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Youzhi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tianbao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08736">
                                    <div class="article-summary-box-inner">
                                        <span>Areas under ROC (AUROC) and precision-recall curves (AUPRC) are common
metrics for evaluating classification performance for imbalanced problems.
Compared with AUROC, AUPRC is a more appropriate metric for highly imbalanced
datasets. While stochastic optimization of AUROC has been studied extensively,
principled stochastic optimization of AUPRC has been rarely explored. In this
work, we propose a principled technical method to optimize AUPRC for deep
learning. Our approach is based on maximizing the averaged precision (AP),
which is an unbiased point estimator of AUPRC. We cast the objective into a sum
of {\it dependent compositional functions} with inner functions dependent on
random variables of the outer level. We propose efficient adaptive and
non-adaptive stochastic algorithms with {\it provable convergence guarantee
under mild conditions} by leveraging recent advances in stochastic
compositional optimization. Extensive experimental results on image and graph
datasets demonstrate that our proposed method outperforms prior methods on
imbalanced problems in terms of AUPRC. To the best of our knowledge, our work
represents the first attempt to optimize AUPRC with provable convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Masked Face Recognition: Human vs. Machine. (arXiv:2103.01924v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Damer_N/0/1/0/all/0/1">Naser Damer</a>, <a href="http://arxiv.org/find/cs/1/au:+Boutros_F/0/1/0/all/0/1">Fadi Boutros</a>, <a href="http://arxiv.org/find/cs/1/au:+Sussmilch_M/0/1/0/all/0/1">Marius S&#xfc;&#xdf;milch</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1">Meiling Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kirchbuchner_F/0/1/0/all/0/1">Florian Kirchbuchner</a>, <a href="http://arxiv.org/find/cs/1/au:+Kuijper_A/0/1/0/all/0/1">Arjan Kuijper</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01924">
                                    <div class="article-summary-box-inner">
                                        <span>The recent COVID-19 pandemic has increased the focus on hygienic and
contactless identity verification methods. However, the pandemic led to the
wide use of face masks, essential to keep the pandemic under control. The
effect of wearing a mask on face recognition in a collaborative environment is
currently sensitive yet understudied issue. Recent reports have tackled this by
evaluating the masked probe effect on the performance of automatic face
recognition solutions. However, such solutions can fail in certain processes,
leading to performing the verification task by a human expert. This work
provides a joint evaluation and in-depth analyses of the face verification
performance of human experts in comparison to state-of-the-art automatic face
recognition solutions. This involves an extensive evaluation with 12 human
experts and 4 automatic recognition solutions. The study concludes with a set
of take-home messages on different aspects of the correlation between the
verification behavior of human and machine.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online and Real-Time Tracking in a Surveillance Scenario. (arXiv:2106.01153v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Urbann_O/0/1/0/all/0/1">Oliver Urbann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bredtmann_O/0/1/0/all/0/1">Oliver Bredtmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Otten_M/0/1/0/all/0/1">Maximilian Otten</a>, <a href="http://arxiv.org/find/cs/1/au:+Richter_J/0/1/0/all/0/1">Jan-Philip Richter</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_T/0/1/0/all/0/1">Thilo Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zibriczky_D/0/1/0/all/0/1">David Zibriczky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01153">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents an approach for tracking in a surveillance scenario.
Typical aspects for this scenario are a 24/7 operation with a static camera
mounted above the height of a human with many objects or people. The Multiple
Object Tracking Benchmark 20 (MOT20) reflects this scenario best. We can show
that our approach is real-time capable on this benchmark and outperforms all
other real-time capable approaches in HOTA, MOTA, and IDF1. We achieve this by
contributing a fast Siamese network reformulated for linear runtime (instead of
quadratic) to generate fingerprints from detections. Thus, it is possible to
associate the detections to Kalman filters based on multiple tracking specific
ratings: Cosine similarity of fingerprints, Intersection over Union, and pixel
distance ratio in the image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Long Term Motion Prediction Using Keyposes. (arXiv:2012.04731v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kiciroglu_S/0/1/0/all/0/1">Sena Kiciroglu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wei Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1">Mathieu Salzmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1">Pascal Fua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04731">
                                    <div class="article-summary-box-inner">
                                        <span>Long term human motion prediction is essential in safety-critical
applications such as human-robot interaction and autonomous driving. In this
paper, we show that, to achieve long term forecasting, predicting human pose at
every time instant is unnecessary. Instead, it is more effective to predict a
few keyposes and approximate intermediate ones by linearly interpolating the
keyposes.

We will demonstrate that our approach enables us to predict realistic motions
for up to 5 seconds in the future, which is far larger than the typical 1
second encountered in the literature. Over this extended time period, our
predictions are more realistic and better preserve the motion dynamics than
those state-of-the-art methods yield.

Furthermore, because we model future keyposes probabilistically, we can
generate multiple plausible future motions by sampling at inference time. This
is useful to model because people usually can do one of several things given
what they have already done.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Style Normalization and Restitution for Domain Generalization and Adaptation. (arXiv:2101.00588v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xin Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Lan_C/0/1/0/all/0/1">Cuiling Lan</a>, <a href="http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1">Wenjun Zeng</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhibo Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.00588">
                                    <div class="article-summary-box-inner">
                                        <span>For many practical computer vision applications, the learned models usually
have high performance on the datasets used for training but suffer from
significant performance degradation when deployed in new environments, where
there are usually style differences between the training images and the testing
images. An effective domain generalizable model is expected to be able to learn
feature representations that are both generalizable and discriminative. In this
paper, we design a novel Style Normalization and Restitution module (SNR) to
simultaneously ensure both high generalization and discrimination capability of
the networks. In the SNR module, particularly, we filter out the style
variations (e.g, illumination, color contrast) by performing Instance
Normalization (IN) to obtain style normalized features, where the discrepancy
among different samples and domains is reduced. However, such a process is
task-ignorant and inevitably removes some task-relevant discriminative
information, which could hurt the performance. To remedy this, we propose to
distill task-relevant discriminative features from the residual (i.e, the
difference between the original feature and the style normalized feature) and
add them back to the network to ensure high discrimination. Moreover, for
better disentanglement, we enforce a dual causality loss constraint in the
restitution step to encourage the better separation of task-relevant and
task-irrelevant features. We validate the effectiveness of our SNR on different
computer vision tasks, including classification, semantic segmentation, and
object detection. Experiments demonstrate that our SNR module is capable of
improving the performance of networks for domain generalization (DG) and
unsupervised domain adaptation (UDA) on many tasks. Code are available at
https://github.com/microsoft/SNR.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking conditional GAN training: An approach using geometrically structured latent manifolds. (arXiv:2011.13055v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ramasinghe_S/0/1/0/all/0/1">Sameera Ramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Farazi_M/0/1/0/all/0/1">Moshiur Farazi</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1">Salman Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Barnes_N/0/1/0/all/0/1">Nick Barnes</a>, <a href="http://arxiv.org/find/cs/1/au:+Gould_S/0/1/0/all/0/1">Stephen Gould</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.13055">
                                    <div class="article-summary-box-inner">
                                        <span>Conditional GANs (cGAN), in their rudimentary form, suffer from critical
drawbacks such as the lack of diversity in generated outputs and distortion
between the latent and output manifolds. Although efforts have been made to
improve results, they can suffer from unpleasant side-effects such as the
topology mismatch between latent and output spaces. In contrast, we tackle this
problem from a geometrical perspective and propose a novel training mechanism
that increases both the diversity and the visual quality of a vanilla cGAN, by
systematically encouraging a bi-lipschitz mapping between the latent and the
output manifolds. We validate the efficacy of our solution on a baseline cGAN
(i.e., Pix2Pix) which lacks diversity, and show that by only modifying its
training mechanism (i.e., with our proposed Pix2Pix-Geo), one can achieve more
diverse and realistic outputs on a broad set of image-to-image translation
tasks. Codes are available at https://github.com/samgregoost/Rethinking-CGANs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Quality Estimation for Image Captions Based on Large-scale Human Evaluations. (arXiv:1909.03396v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Levinboim_T/0/1/0/all/0/1">Tomer Levinboim</a>, <a href="http://arxiv.org/find/cs/1/au:+Thapliyal_A/0/1/0/all/0/1">Ashish V. Thapliyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1">Piyush Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Soricut_R/0/1/0/all/0/1">Radu Soricut</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.03396">
                                    <div class="article-summary-box-inner">
                                        <span>Automatic image captioning has improved significantly over the last few
years, but the problem is far from being solved, with state of the art models
still often producing low quality captions when used in the wild. In this
paper, we focus on the task of Quality Estimation (QE) for image captions,
which attempts to model the caption quality from a human perspective and
without access to ground-truth references, so that it can be applied at
prediction time to detect low-quality captions produced on previously unseen
images. For this task, we develop a human evaluation process that collects
coarse-grained caption annotations from crowdsourced users, which is then used
to collect a large scale dataset spanning more than 600k caption quality
ratings. We then carefully validate the quality of the collected ratings and
establish baseline models for this new QE task. Finally, we further collect
fine-grained caption quality annotations from trained raters, and use them to
demonstrate that QE models trained over the coarse ratings can effectively
detect and filter out low-quality image captions, thereby improving the user
experience from captioning systems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning. (arXiv:2012.00212v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_K/0/1/0/all/0/1">Kunming Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chuan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Shuaicheng Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_H/0/1/0/all/0/1">Haoqiang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jue Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1">Jian Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00212">
                                    <div class="article-summary-box-inner">
                                        <span>We present an unsupervised learning approach for optical flow estimation by
improving the upsampling and learning of pyramid network. We design a
self-guided upsample module to tackle the interpolation blur problem caused by
bilinear upsampling between pyramid levels. Moreover, we propose a pyramid
distillation loss to add supervision for intermediate levels via distilling the
finest flow as pseudo labels. By integrating these two components together, our
method achieves the best performance for unsupervised optical flow learning on
multiple leading benchmarks, including MPI-SIntel, KITTI 2012 and KITTI 2015.
In particular, we achieve EPE&#x3D;1.4 on KITTI 2012 and F1&#x3D;9.38% on KITTI 2015,
which outperform the previous state-of-the-art methods by 22.2% and 15.7%,
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Attention Based Semantic Segmentation on UAV Dataset for Natural Disaster Damage Assessment. (arXiv:2105.14540v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chowdhury_T/0/1/0/all/0/1">Tashnim Chowdhury</a>, <a href="http://arxiv.org/find/cs/1/au:+Rahnemoonfar_M/0/1/0/all/0/1">Maryam Rahnemoonfar</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14540">
                                    <div class="article-summary-box-inner">
                                        <span>The detrimental impacts of climate change include stronger and more
destructive hurricanes happening all over the world. Identifying different
damaged structures of an area including buildings and roads are vital since it
helps the rescue team to plan their efforts to minimize the damage caused by a
natural disaster. Semantic segmentation helps to identify different parts of an
image. We implement a novel self-attention based semantic segmentation model on
a high resolution UAV dataset and attain Mean IoU score of around 88% on the
test set. The result inspires to use self-attention schemes in natural disaster
damage assessment which will save human lives and reduce economic losses.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pay Attention to MLPs. (arXiv:2105.08050v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hanxiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1">Zihang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+So_D/0/1/0/all/0/1">David R. So</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08050">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have become one of the most important architectural innovations
in deep learning and have enabled many breakthroughs over the past few years.
Here we propose a simple network architecture, gMLP, based on MLPs with gating,
and show that it can perform as well as Transformers in key language and vision
applications. Our comparisons show that self-attention is not critical for
Vision Transformers, as gMLP can achieve the same accuracy. For BERT, our model
achieves parity with Transformers on pretraining perplexity and is better on
some downstream NLP tasks. On finetuning tasks where gMLP performs worse,
making the gMLP model substantially larger can close the gap with Transformers.
In general, our experiments show that gMLP can scale as well as Transformers
over increased data and compute.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ImVoxelNet: Image to Voxels Projection for Monocular and Multi-View General-Purpose 3D Object Detection. (arXiv:2106.01178v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rukhovich_D/0/1/0/all/0/1">Danila Rukhovich</a>, <a href="http://arxiv.org/find/cs/1/au:+Vorontsova_A/0/1/0/all/0/1">Anna Vorontsova</a>, <a href="http://arxiv.org/find/cs/1/au:+Konushin_A/0/1/0/all/0/1">Anton Konushin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01178">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we introduce the task of multi-view RGB-based 3D object
detection as an end-to-end optimization problem. To address this problem, we
propose ImVoxelNet, a novel fully convolutional method of 3D object detection
based on monocular or multi-view RGB images. The number of monocular images in
each multi-view input can variate during training and inference; actually, this
number might be unique for each multi-view input. ImVoxelNet successfully
handles both indoor and outdoor scenes, which makes it general-purpose.
Specifically, it achieves state-of-the-art results in car detection on KITTI
(monocular) and nuScenes (multi-view) benchmarks among all methods that accept
RGB images. Moreover, it surpasses existing RGB-based 3D object detection
methods on the SUN RGB-D dataset. On ScanNet, ImVoxelNet sets a new benchmark
for multi-view 3D object detection. The source code and the trained models are
available at \url{https://github.com/saic-vul/imvoxelnet}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchmarking CNN on 3D Anatomical Brain MRI: Architectures, Data Augmentation and Deep Ensemble Learning. (arXiv:2106.01132v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dufumier_B/0/1/0/all/0/1">Benoit Dufumier</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Battaglia_I/0/1/0/all/0/1">Ilaria Battaglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Victor_J/0/1/0/all/0/1">Julie Victor</a>, <a href="http://arxiv.org/find/cs/1/au:+Grigis_A/0/1/0/all/0/1">Antoine Grigis</a>, <a href="http://arxiv.org/find/cs/1/au:+Duchesnay_E/0/1/0/all/0/1">Edouard Duchesnay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01132">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Learning (DL) and specifically CNN models have become a de facto method
for a wide range of vision tasks, outperforming traditional machine learning
(ML) methods. Consequently, they drew a lot of attention in the neuroimaging
field in particular for phenotype prediction or computer-aided diagnosis.
However, most of the current studies often deal with small single-site cohorts,
along with a specific pre-processing pipeline and custom CNN architectures,
which make them difficult to compare to. We propose an extensive benchmark of
recent state-of-the-art (SOTA) 3D CNN, evaluating also the benefits of data
augmentation and deep ensemble learning, on both Voxel-Based Morphometry (VBM)
pre-processing and quasi-raw images. Experiments were conducted on a large
multi-site 3D brain anatomical MRI data-set comprising N&#x3D;10k scans on 3
challenging tasks: age prediction, sex classification, and schizophrenia
diagnosis. We found that all models provide significantly better predictions
with VBM images than quasi-raw data. This finding evolved as the training set
approaches 10k samples where quasi-raw data almost reach the performance of
VBM. Moreover, we showed that linear models perform comparably with SOTA CNN on
VBM data. We also demonstrated that DenseNet and tiny-DenseNet, a lighter
version that we proposed, provide a good compromise in terms of performance in
all data regime. Therefore, we suggest to employ them as the architectures by
default. Critically, we also showed that current CNN are still very biased
towards the acquisition site, even when trained with N&#x3D;10k multi-site images.
In this context, VBM pre-processing provides an efficient way to limit this
site effect. Surprisingly, we did not find any clear benefit from data
augmentation techniques. Finally, we proved that deep ensemble learning is well
suited to re-calibrate big CNN models without sacrificing performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Clustering Activation Maps for Emphysema Subtyping. (arXiv:2106.01351v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Xie_W/0/1/0/all/0/1">Weiyi Xie</a>, <a href="http://arxiv.org/find/eess/1/au:+Jacobs_C/0/1/0/all/0/1">Colin Jacobs</a>, <a href="http://arxiv.org/find/eess/1/au:+Ginneken_B/0/1/0/all/0/1">Bram van Ginneken</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01351">
                                    <div class="article-summary-box-inner">
                                        <span>We propose a deep learning clustering method that exploits dense features
from a segmentation network for emphysema subtyping from computed tomography
(CT) scans. Using dense features enables high-resolution visualization of image
regions corresponding to the cluster assignment via dense clustering activation
maps (dCAMs). This approach provides model interpretability. We evaluated
clustering results on 500 subjects from the COPDGenestudy, where radiologists
manually annotated emphysema sub-types according to their visual CT assessment.
We achieved a 43% unsupervised clustering accuracy, outperforming our baseline
at 41% and yielding results comparable to supervised classification at 45%. The
proposed method also offers a better cluster formation than the baseline,
achieving0.54 in silhouette coefficient and 0.55 in David-Bouldin scores.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robust Isometric Non-Rigid Structure-from-Motion. (arXiv:2010.04690v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Parashar_S/0/1/0/all/0/1">Shaifali Parashar</a>, <a href="http://arxiv.org/find/cs/1/au:+Bartoli_A/0/1/0/all/0/1">Adrien Bartoli</a>, <a href="http://arxiv.org/find/cs/1/au:+Pizarro_D/0/1/0/all/0/1">Daniel Pizarro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.04690">
                                    <div class="article-summary-box-inner">
                                        <span>Non-Rigid Structure-from-Motion (NRSfM) reconstructs a deformable 3D object
from the correspondences established between monocular 2D images. Current NRSfM
methods lack statistical robustness, which is the ability to cope with
correspondence errors.This prevents one to use automatically established
correspondences, which are prone to errors, thereby strongly limiting the scope
of NRSfM. We propose a three-step automatic pipeline to solve NRSfM robustly by
exploiting isometry. Step 1 computes the optical flow from correspondences,
step 2 reconstructs each 3D point&#x27;s normal vector using multiple reference
images and integrates them to form surfaces with the best reference and step 3
rejects the 3D points that break isometry in their local neighborhood.
Importantly, each step is designed to discard or flag erroneous
correspondences. Our contributions include the robustification of optical flow
by warp estimation, new fast analytic solutions to local normal reconstruction
and their robustification, and a new scale-independent measure of 3D local
isometric coherence. Experimental results show that our robust NRSfM method
consistently outperforms existing methods on both synthetic and real datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SpectralDefense: Detecting Adversarial Attacks on CNNs in the Fourier Domain. (arXiv:2103.03000v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Harder_P/0/1/0/all/0/1">Paula Harder</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfreundt_F/0/1/0/all/0/1">Franz-Josef Pfreundt</a>, <a href="http://arxiv.org/find/cs/1/au:+Keuper_M/0/1/0/all/0/1">Margret Keuper</a>, <a href="http://arxiv.org/find/cs/1/au:+Keuper_J/0/1/0/all/0/1">Janis Keuper</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.03000">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of convolutional neural networks (CNNs) in many computer
vision and image analysis tasks, they remain vulnerable against so-called
adversarial attacks: Small, crafted perturbations in the input images can lead
to false predictions. A possible defense is to detect adversarial examples. In
this work, we show how analysis in the Fourier domain of input images and
feature maps can be used to distinguish benign test samples from adversarial
images. We propose two novel detection methods: Our first method employs the
magnitude spectrum of the input images to detect an adversarial attack. This
simple and robust classifier can successfully detect adversarial perturbations
of three commonly used attack methods. The second method builds upon the first
and additionally extracts the phase of Fourier coefficients of feature-maps at
different layers of the network. With this extension, we are able to improve
adversarial detection rates compared to state-of-the-art detectors on five
different attack methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Effectiveness of Vision Transformers for Zero-shot Face Anti-Spoofing. (arXiv:2011.08019v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+George_A/0/1/0/all/0/1">Anjith George</a>, <a href="http://arxiv.org/find/cs/1/au:+Marcel_S/0/1/0/all/0/1">Sebastien Marcel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08019">
                                    <div class="article-summary-box-inner">
                                        <span>The vulnerability of face recognition systems to presentation attacks has
limited their application in security-critical scenarios. Automatic methods of
detecting such malicious attempts are essential for the safe use of facial
recognition technology. Although various methods have been suggested for
detecting such attacks, most of them over-fit the training set and fail in
generalizing to unseen attacks and environments. In this work, we use transfer
learning from the vision transformer model for the zero-shot anti-spoofing
task. The effectiveness of the proposed approach is demonstrated through
experiments in publicly available datasets. The proposed approach outperforms
the state-of-the-art methods in the zero-shot protocols in the HQ-WMCA and
SiW-M datasets by a large margin. Besides, the model achieves a significant
boost in cross-database performance as well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProSelfLC: Progressive Self Label Correction for Training Robust Deep Neural Networks. (arXiv:2005.03788v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinshao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1">Yang Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Kodirov_E/0/1/0/all/0/1">Elyor Kodirov</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1">David A. Clifton</a>, <a href="http://arxiv.org/find/cs/1/au:+Robertson_N/0/1/0/all/0/1">Neil M. Robertson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.03788">
                                    <div class="article-summary-box-inner">
                                        <span>To train robust deep neural networks (DNNs), we systematically study several
target modification approaches, which include output regularisation, self and
non-self label correction (LC). Two key issues are discovered: (1) Self LC is
the most appealing as it exploits its own knowledge and requires no extra
models. However, how to automatically decide the trust degree of a learner as
training goes is not well answered in the literature? (2) Some methods penalise
while the others reward low-entropy predictions, prompting us to ask which one
is better?

To resolve the first issue, taking two well-accepted propositions--deep
neural networks learn meaningful patterns before fitting noise [3] and minimum
entropy regularisation principle [10]--we propose a novel end-to-end method
named ProSelfLC, which is designed according to learning time and entropy.
Specifically, given a data point, we progressively increase trust in its
predicted label distribution versus its annotated one if a model has been
trained for enough time and the prediction is of low entropy (high confidence).
For the second issue, according to ProSelfLC, we empirically prove that it is
better to redefine a meaningful low-entropy status and optimise the learner
toward it. This serves as a defence of entropy minimisation.

We demonstrate the effectiveness of ProSelfLC through extensive experiments
in both clean and noisy settings. The source code is available at
https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021.

Keywords: entropy minimisation, maximum entropy, confidence penalty, self
knowledge distillation, label correction, label noise, semi-supervised
learning, output regularisation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IPatch: A Remote Adversarial Patch. (arXiv:2105.00113v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mirsky_Y/0/1/0/all/0/1">Yisroel Mirsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00113">
                                    <div class="article-summary-box-inner">
                                        <span>Applications such as autonomous vehicles and medical screening use deep
learning models to localize and identify hundreds of objects in a single frame.
In the past, it has been shown how an attacker can fool these models by placing
an adversarial patch within a scene. However, these patches must be placed in
the target location and do not explicitly alter the semantics elsewhere in the
image.

In this paper, we introduce a new type of adversarial patch which alters a
model&#x27;s perception of an image&#x27;s semantics. These patches can be placed
anywhere within an image to change the classification or semantics of locations
far from the patch. We call this new class of adversarial examples &#x60;remote
adversarial patches&#x27; (RAP).

We implement our own RAP called IPatch and perform an in-depth analysis on
image segmentation RAP attacks using five state-of-the-art architectures with
eight different encoders on the CamVid street view dataset. Moreover, we
demonstrate that the attack can be extended to object recognition models with
preliminary results on the popular YOLOv3 model. We found that the patch can
change the classification of a remote target region with a success rate of up
to 93% on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning an Animatable Detailed 3D Face Model from In-The-Wild Images. (arXiv:2012.04012v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_H/0/1/0/all/0/1">Haiwen Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1">Michael J. Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Bolkart_T/0/1/0/all/0/1">Timo Bolkart</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.04012">
                                    <div class="article-summary-box-inner">
                                        <span>While current monocular 3D face reconstruction methods can recover fine
geometric details, they suffer several limitations. Some methods produce faces
that cannot be realistically animated because they do not model how wrinkles
vary with expression. Other methods are trained on high-quality face scans and
do not generalize well to in-the-wild images. We present the first approach
that regresses 3D face shape and animatable details that are specific to an
individual but change with expression. Our model, DECA (Detailed Expression
Capture and Animation), is trained to robustly produce a UV displacement map
from a low-dimensional latent representation that consists of person-specific
detail parameters and generic expression parameters, while a regressor is
trained to predict detail, shape, albedo, expression, pose and illumination
parameters from a single image. To enable this, we introduce a novel
detail-consistency loss that disentangles person-specific details from
expression-dependent wrinkles. This disentanglement allows us to synthesize
realistic person-specific wrinkles by controlling expression parameters while
keeping person-specific details unchanged. DECA is learned from in-the-wild
images with no paired 3D supervision and achieves state-of-the-art shape
reconstruction accuracy on two benchmarks. Qualitative results on in-the-wild
data demonstrate DECA&#x27;s robustness and its ability to disentangle identity- and
expression-dependent details enabling animation of reconstructed faces. The
model and code are publicly available at https://deca.is.tue.mpg.de.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis. (arXiv:2011.10185v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhouyong Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shun Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wubin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1">Jingben Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yufan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Shilei Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1">Chunguo Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1">Luxi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.10185">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Convolutional Neural Networks (CNNs) are powerful models that have
achieved excellent performance on difficult computer vision tasks. Although
CNNs perform well whenever large labeled training samples are available, they
work badly on video frame synthesis due to objects deforming and moving, scene
lighting changes, and cameras moving in video sequence. In this paper, we
present a novel and general end-to-end architecture, called convolutional
Transformer or ConvTransformer, for video frame sequence learning and video
frame synthesis. The core ingredient of ConvTransformer is the proposed
attention layer, i.e., multi-head convolutional self-attention layer, that
learns the sequential dependence of video sequence. ConvTransformer uses an
encoder, built upon multi-head convolutional self-attention layer, to encode
the sequential dependence between the input frames, and then a decoder decodes
the long-term dependence between the target synthesized frames and the input
frames. Experiments on video future frame extrapolation task show
ConvTransformer to be superior in quality while being more parallelizable to
recent approaches built upon convolutional LSTM (ConvLSTM). To the best of our
knowledge, this is the first time that ConvTransformer architecture is proposed
and applied to video frame synthesis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Practical Lipreading with Distilled and Efficient Models. (arXiv:2007.06504v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1">Pingchuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1">Brais Martinez</a>, <a href="http://arxiv.org/find/cs/1/au:+Petridis_S/0/1/0/all/0/1">Stavros Petridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Pantic_M/0/1/0/all/0/1">Maja Pantic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06504">
                                    <div class="article-summary-box-inner">
                                        <span>Lipreading has witnessed a lot of progress due to the resurgence of neural
networks. Recent works have placed emphasis on aspects such as improving
performance by finding the optimal architecture or improving generalization.
However, there is still a significant gap between the current methodologies and
the requirements for an effective deployment of lipreading in practical
scenarios. In this work, we propose a series of innovations that significantly
bridge that gap: first, we raise the state-of-the-art performance by a wide
margin on LRW and LRW-1000 to 88.5% and 46.6%, respectively using
self-distillation. Secondly, we propose a series of architectural changes,
including a novel Depthwise Separable Temporal Convolutional Network (DS-TCN)
head, that slashes the computational cost to a fraction of the (already quite
efficient) original model. Thirdly, we show that knowledge distillation is a
very effective tool for recovering performance of the lightweight models. This
results in a range of models with different accuracy-efficiency trade-offs.
However, our most promising lightweight models are on par with the current
state-of-the-art while showing a reduction of 8.2x and 3.9x in terms of
computational cost and number of parameters, respectively, which we hope will
enable the deployment of lipreading models in practical applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Determining Chess Game State From an Image. (arXiv:2104.14963v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolflein_G/0/1/0/all/0/1">Georg W&#xf6;lflein</a>, <a href="http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1">Ognjen Arandjelovi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14963">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying the configuration of chess pieces from an image of a chessboard
is a problem in computer vision that has not yet been solved accurately.
However, it is important for helping amateur chess players improve their games
by facilitating automatic computer analysis without the overhead of manually
entering the pieces. Current approaches are limited by the lack of large
datasets and are not designed to adapt to unseen chess sets. This paper puts
forth a new dataset synthesised from a 3D model that is an order of magnitude
larger than existing ones. Trained on this dataset, a novel end-to-end chess
recognition system is presented that combines traditional computer vision
techniques with deep learning. It localises the chessboard using a RANSAC-based
algorithm that computes a projective transformation of the board onto a regular
grid. Using two convolutional neural networks, it then predicts an occupancy
mask for the squares in the warped image and finally classifies the pieces. The
described system achieves an error rate of 0.23% per square on the test set, 28
times better than the current state of the art. Further, a few-shot transfer
learning approach is developed that is able to adapt the inference system to a
previously unseen chess set using just two photos of the starting position,
obtaining a per-square accuracy of 99.83% on images of that new chess set. The
code, dataset, and trained models are made available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human-centric Spatio-Temporal Video Grounding With Visual Transformers. (arXiv:2011.05049v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zongheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yue Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Si Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xiaojie Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hongxu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05049">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce a novel task - Humancentric Spatio-Temporal Video
Grounding (HC-STVG). Unlike the existing referring expression tasks in images
or videos, by focusing on humans, HC-STVG aims to localize a spatiotemporal
tube of the target person from an untrimmed video based on a given textural
description. This task is useful, especially for healthcare and
security-related applications, where the surveillance videos can be extremely
long but only a specific person during a specific period of time is concerned.
HC-STVG is a video grounding task that requires both spatial (where) and
temporal (when) localization. Unfortunately, the existing grounding methods
cannot handle this task well. We tackle this task by proposing an effective
baseline method named Spatio-Temporal Grounding with Visual Transformers
(STGVT), which utilizes Visual Transformers to extract cross-modal
representations for video-sentence matching and temporal localization. To
facilitate this task, we also contribute an HC-STVG dataset consisting of 5,660
video-sentence pairs on complex multi-person scenes. Specifically, each video
lasts for 20 seconds, pairing with a natural query sentence with an average of
17.25 words. Extensive experiments are conducted on this dataset, demonstrating
the newly-proposed method outperforms the existing baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Coreset Selection for Rehearsal-based Continual Learning. (arXiv:2106.01085v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1">Jaehong Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1">Divyam Madaan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eunho Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01085">
                                    <div class="article-summary-box-inner">
                                        <span>A dataset is a shred of crucial evidence to describe a task. However, each
data point in the dataset does not have the same potential, as some of the data
points can be more representative or informative than others. This unequal
importance among the data points may have a large impact in rehearsal-based
continual learning, where we store a subset of the training examples (coreset)
to be replayed later to alleviate catastrophic forgetting. In continual
learning, the quality of the samples stored in the coreset directly affects the
model&#x27;s effectiveness and efficiency. The coreset selection problem becomes
even more important under realistic settings, such as imbalanced continual
learning or noisy data scenarios. To tackle this problem, we propose Online
Coreset Selection (OCS), a simple yet effective method that selects the most
representative and informative coreset at each iteration and trains them in an
online manner. Our proposed method maximizes the model&#x27;s adaptation to a target
dataset while selecting high-affinity samples to past tasks, which directly
inhibits catastrophic forgetting. We validate the effectiveness of our coreset
selection mechanism over various standard, imbalanced, and noisy datasets
against strong continual learning baselines, demonstrating that it improves
task adaptation and prevents catastrophic forgetting in a sample-efficient
manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TSI: Temporal Saliency Integration for Video Action Recognition. (arXiv:2106.01088v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1">Haisheng Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1">Jinyuan Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1">Dongliang Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Gan_W/0/1/0/all/0/1">Weihao Gan</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1">Wei Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Qiao_Y/0/1/0/all/0/1">Yu Qiao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01088">
                                    <div class="article-summary-box-inner">
                                        <span>Efficient spatiotemporal modeling is an important yet challenging problem for
video action recognition. Existing state-of-the-art methods exploit motion
clues to assist in short-term temporal modeling through temporal difference
over consecutive frames. However, background noises will be inevitably
introduced due to the camera movement. Besides, movements of different actions
can vary greatly. In this paper, we propose a Temporal Saliency Integration
(TSI) block, which mainly contains a Salient Motion Excitation (SME) module and
a Cross-scale Temporal Integration (CTI) module. Specifically, SME aims to
highlight the motion-sensitive area through local-global motion modeling, where
the background suppression and pyramidal feature difference are conducted
successively between neighboring frames to capture motion dynamics with less
background noises. CTI is designed to perform multi-scale temporal modeling
through a group of separate 1D convolutions respectively. Meanwhile, temporal
interactions across different scales are integrated with attention mechanism.
Through these two modules, long short-term temporal relationships can be
encoded efficiently by introducing limited additional parameters. Extensive
experiments are conducted on several popular benchmarks (i.e.,
Something-Something v1 &amp; v2, Kinetics-400, UCF-101, and HMDB-51), which
demonstrate the effectiveness and superiority of our proposed method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning based Full-reference and No-reference Quality Assessment Models for Compressed UGC Videos. (arXiv:2106.01111v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sun_W/0/1/0/all/0/1">Wei Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Min_X/0/1/0/all/0/1">Xiongkuo Min</a>, <a href="http://arxiv.org/find/eess/1/au:+Yi_F/0/1/0/all/0/1">Fuwang Yi</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01111">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a deep learning based video quality assessment
(VQA) framework to evaluate the quality of the compressed user&#x27;s generated
content (UGC) videos. The proposed VQA framework consists of three modules, the
feature extraction module, the quality regression module, and the quality
pooling module. For the feature extraction module, we fuse the features from
intermediate layers of the convolutional neural network (CNN) network into
final quality-aware feature representation, which enables the model to make
full use of visual information from low-level to high-level. Specifically, the
structure and texture similarities of feature maps extracted from all
intermediate layers are calculated as the feature representation for the full
reference (FR) VQA model, and the global mean and standard deviation of the
final feature maps fused by intermediate feature maps are calculated as the
feature representation for the no reference (NR) VQA model. For the quality
regression module, we use the fully connected (FC) layer to regress the
quality-aware features into frame-level scores. Finally, a
subjectively-inspired temporal pooling strategy is adopted to pool frame-level
scores into the video-level score. The proposed model achieves the best
performance among the state-of-the-art FR and NR VQA models on the Compressed
UGC VQA database and also achieves pretty good performance on the in-the-wild
UGC VQA databases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Unified Surgical Skill Assessment. (arXiv:2106.01035v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1">Daochang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiyue Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_T/0/1/0/all/0/1">Tingting Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yizhou Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Miao_R/0/1/0/all/0/1">Rulin Miao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shan_F/0/1/0/all/0/1">Fei Shan</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1">Ziyu Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01035">
                                    <div class="article-summary-box-inner">
                                        <span>Surgical skills have a great influence on surgical safety and patients&#x27;
well-being. Traditional assessment of surgical skills involves strenuous manual
efforts, which lacks efficiency and repeatability. Therefore, we attempt to
automatically predict how well the surgery is performed using the surgical
video. In this paper, a unified multi-path framework for automatic surgical
skill assessment is proposed, which takes care of multiple composing aspects of
surgical skills, including surgical tool usage, intraoperative event pattern,
and other skill proxies. The dependency relationships among these different
aspects are specially modeled by a path dependency module in the framework. We
conduct extensive experiments on the JIGSAWS dataset of simulated surgical
tasks, and a new clinical dataset of real laparoscopic surgeries. The proposed
framework achieves promising results on both datasets, with the
state-of-the-art on the simulated dataset advanced from 0.71 Spearman&#x27;s
correlation to 0.80. It is also shown that combining multiple skill aspects
yields better performance than relying on a single aspect.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net. (arXiv:2106.00952v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1">Tuan-Anh Nguyen Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dat-Thanh Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00952">
                                    <div class="article-summary-box-inner">
                                        <span>Information extraction from document images has received a lot of attention
recently, due to the need for digitizing a large volume of unstructured
documents such as invoices, receipts, bank transfers, etc. In this paper, we
propose a novel deep learning architecture for end-to-end information
extraction on the 2D character-grid embedding of the document, namely the
\textit{Multi-Stage Attentional U-Net}. To effectively capture the textual and
spatial relations between 2D elements, our model leverages a specialized
multi-stage encoder-decoders design, in conjunction with efficient uses of the
self-attention mechanism and the box convolution. Experimental results on
different datasets show that our model outperforms the baseline U-Net
architecture by a large margin while using 40\% fewer parameters. Moreover, it
also significantly improved the baseline in erroneous OCR and limited training
data scenario, thus becomes practical for real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Self-supervised Lesion Change Detection and Localisation in Longitudinal Multiple Sclerosis Brain Imaging. (arXiv:2106.00919v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+To_M/0/1/0/all/0/1">Minh-Son To</a>, <a href="http://arxiv.org/find/eess/1/au:+Sarno_I/0/1/0/all/0/1">Ian G Sarno</a>, <a href="http://arxiv.org/find/eess/1/au:+Chong_C/0/1/0/all/0/1">Chee Chong</a>, <a href="http://arxiv.org/find/eess/1/au:+Jenkinson_M/0/1/0/all/0/1">Mark Jenkinson</a>, <a href="http://arxiv.org/find/eess/1/au:+Carneiro_G/0/1/0/all/0/1">Gustavo Carneiro</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00919">
                                    <div class="article-summary-box-inner">
                                        <span>Longitudinal imaging forms an essential component in the management and
follow-up of many medical conditions. The presence of lesion changes on serial
imaging can have significant impact on clinical decision making, highlighting
the important role for automated change detection. Lesion changes can represent
anomalies in serial imaging, which implies a limited availability of
annotations and a wide variety of possible changes that need to be considered.
Hence, we introduce a new unsupervised anomaly detection and localisation
method trained exclusively with serial images that do not contain any lesion
changes. Our training automatically synthesises lesion changes in serial
images, introducing detection and localisation pseudo-labels that are used to
self-supervise the training of our model. Given the rarity of these lesion
changes in the synthesised images, we train the model with the imbalance robust
focal Tversky loss. When compared to supervised models trained on different
datasets, our method shows competitive performance in the detection and
localisation of new demyelinating lesions on longitudinal magnetic resonance
imaging in multiple sclerosis patients. Code for the models will be made
available on GitHub.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction of the Position of External Markers Using a Recurrent Neural Network Trained With Unbiased Online Recurrent Optimization for Safe Lung Cancer Radiotherapy. (arXiv:2106.01100v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pohl_M/0/1/0/all/0/1">Michel Pohl</a>, <a href="http://arxiv.org/find/eess/1/au:+Uesaka_M/0/1/0/all/0/1">Mitsuru Uesaka</a>, <a href="http://arxiv.org/find/eess/1/au:+Takahashi_H/0/1/0/all/0/1">Hiroyuki Takahashi</a>, <a href="http://arxiv.org/find/eess/1/au:+Demachi_K/0/1/0/all/0/1">Kazuyuki Demachi</a>, <a href="http://arxiv.org/find/eess/1/au:+Chhatkuli_R/0/1/0/all/0/1">Ritu Bhusal Chhatkuli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01100">
                                    <div class="article-summary-box-inner">
                                        <span>During lung cancer radiotherapy, the position of infrared reflective objects
on the chest can be recorded to estimate the tumor location. However,
radiotherapy systems usually have a latency inherent to robot control
limitations that impedes the radiation delivery precision. Not taking this
phenomenon into account may cause unwanted damage to healthy tissues and lead
to side effects such as radiation pneumonitis. In this research, we use nine
observation records of the three-dimensional position of three external markers
on the chest and abdomen of healthy individuals breathing during intervals from
73s to 222s. The sampling frequency is equal to 10Hz and the amplitudes of the
recorded trajectories range from 6mm to 40mm in the superior-inferior
direction. We forecast the location of each marker simultaneously with a
horizon value (the time interval in advance for which the prediction is made)
between 0.1s and 2.0s, using a recurrent neural network (RNN) trained with
unbiased online recurrent optimization (UORO). We compare its performance with
an RNN trained with real-time recurrent learning, least mean squares (LMS), and
offline linear regression. Training and cross-validation are performed during
the first minute of each sequence. On average, UORO achieves the lowest
root-mean-square (RMS) and maximum error, equal respectively to 1.3mm and
8.8mm, with a prediction time per time step lower than 2.8ms (Dell Intel core
i9-9900K 3.60Ghz). Linear regression has the lowest RMS error for the horizon
values 0.1s and 0.2s, followed by LMS for horizon values between 0.3s and 0.5s,
and UORO for horizon values greater than 0.6s.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Robust Classification Model by Counterfactual and Invariant Data Generation. (arXiv:2106.01127v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1">Chun-Hao Chang</a>, <a href="http://arxiv.org/find/cs/1/au:+Adam_G/0/1/0/all/0/1">George Alexandru Adam</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1">Anna Goldenberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01127">
                                    <div class="article-summary-box-inner">
                                        <span>Despite the success of machine learning applications in science, industry,
and society in general, many approaches are known to be non-robust, often
relying on spurious correlations to make predictions. Spuriousness occurs when
some features correlate with labels but are not causal; relying on such
features prevents models from generalizing to unseen environments where such
correlations break. In this work, we focus on image classification and propose
two data generation processes to reduce spuriousness. Given human annotations
of the subset of the features responsible (causal) for the labels (e.g.
bounding boxes), we modify this causal set to generate a surrogate image that
no longer has the same label (i.e. a counterfactual image). We also alter
non-causal features to generate images still recognized as the original labels,
which helps to learn a model invariant to these features. In several
challenging datasets, our data generations outperform state-of-the-art methods
in accuracy when spurious correlations break, and increase the saliency focus
on causal features providing better explanations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Novel Edge Detection Operator for Identifying Buildings in Augmented Reality Applications. (arXiv:2106.01055v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Orhei_C/0/1/0/all/0/1">Ciprian Orhei</a>, <a href="http://arxiv.org/find/cs/1/au:+Vert_S/0/1/0/all/0/1">Silviu Vert</a>, <a href="http://arxiv.org/find/cs/1/au:+Vasiu_R/0/1/0/all/0/1">Radu Vasiu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01055">
                                    <div class="article-summary-box-inner">
                                        <span>Augmented Reality is an environment-enhancing technology, widely applied in
many domains, such as tourism and culture. One of the major challenges in this
field is precise detection and extraction of building information through
Computer Vision techniques. Edge detection is one of the building blocks
operations for many feature extraction solutions in Computer Vision. AR systems
use edge detection for building extraction or for extraction of facade details
from buildings. In this paper, we propose a novel filter operator for edge
detection that aims to extract building contours or facade features better. The
proposed filter gives more weight for finding vertical and horizontal edges
that is an important feature for our aim.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Feedback Network for Mutually Boosted Stereo Image Super-Resolution and Disparity Estimation. (arXiv:2106.00985v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dai_Q/0/1/0/all/0/1">Qinyan Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Juncheng Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Yi_Q/0/1/0/all/0/1">Qiaosi Yi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1">Faming Fang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1">Guixu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00985">
                                    <div class="article-summary-box-inner">
                                        <span>Under stereo settings, the problem of image super-resolution (SR) and
disparity estimation are interrelated that the result of each problem could
help to solve the other. The effective exploitation of correspondence between
different views facilitates the SR performance, while the high-resolution (HR)
features with richer details benefit the correspondence estimation. According
to this motivation, we propose a Stereo Super-Resolution and Disparity
Estimation Feedback Network (SSRDE-FNet), which simultaneously handles the
stereo image super-resolution and disparity estimation in a unified framework
and interact them with each other to further improve their performance.
Specifically, the SSRDE-FNet is composed of two dual recursive sub-networks for
left and right views. Besides the cross-view information exploitation in the
low-resolution (LR) space, HR representations produced by the SR process are
utilized to perform HR disparity estimation with higher accuracy, through which
the HR features can be aggregated to generate a finer SR result. Afterward, the
proposed HR Disparity Information Feedback (HRDIF) mechanism delivers
information carried by HR disparity back to previous layers to further refine
the SR image reconstruction. Extensive experiments demonstrate the
effectiveness and advancement of SSRDE-FNet.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rethinking Cross-modal Interaction from a Top-down Perspective for Referring Video Object Segmentation. (arXiv:2106.01061v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liang_C/0/1/0/all/0/1">Chen Liang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yu Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tianfei Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wenguan Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1">Zongxin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1">Yunchao Wei</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yi Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01061">
                                    <div class="article-summary-box-inner">
                                        <span>Referring video object segmentation (RVOS) aims to segment video objects with
the guidance of natural language reference. Previous methods typically tackle
RVOS through directly grounding linguistic reference over the image lattice.
Such bottom-up strategy fails to explore object-level cues, easily leading to
inferior results. In this work, we instead put forward a two-stage, top-down
RVOS solution. First, an exhaustive set of object tracklets is constructed by
propagating object masks detected from several sampled frames to the entire
video. Second, a Transformer-based tracklet-language grounding module is
proposed, which models instance-level visual relations and cross-modal
interactions simultaneously and efficiently. Our model ranks first place on
CVPR2021 Referring Youtube-VOS challenge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tips and Tricks to Improve CNN-based Chest X-ray Diagnosis: A Survey. (arXiv:2106.00997v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Han_C/0/1/0/all/0/1">Changhee Han</a>, <a href="http://arxiv.org/find/eess/1/au:+Okamoto_T/0/1/0/all/0/1">Takayuki Okamoto</a>, <a href="http://arxiv.org/find/eess/1/au:+Takeuchi_K/0/1/0/all/0/1">Koichi Takeuchi</a>, <a href="http://arxiv.org/find/eess/1/au:+Katsios_D/0/1/0/all/0/1">Dimitris Katsios</a>, <a href="http://arxiv.org/find/eess/1/au:+Grushnikov_A/0/1/0/all/0/1">Andrey Grushnikov</a>, <a href="http://arxiv.org/find/eess/1/au:+Kobayashi_M/0/1/0/all/0/1">Masaaki Kobayashi</a>, <a href="http://arxiv.org/find/eess/1/au:+Choppin_A/0/1/0/all/0/1">Antoine Choppin</a>, <a href="http://arxiv.org/find/eess/1/au:+Kurashina_Y/0/1/0/all/0/1">Yutaka Kurashina</a>, <a href="http://arxiv.org/find/eess/1/au:+Shimahara_Y/0/1/0/all/0/1">Yuki Shimahara</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00997">
                                    <div class="article-summary-box-inner">
                                        <span>Convolutional Neural Networks (CNNs) intrinsically requires large-scale data
whereas Chest X-Ray (CXR) images tend to be data/annotation-scarce, leading to
over-fitting. Therefore, based on our development experience and related work,
this paper thoroughly introduces tricks to improve generalization in the CXR
diagnosis: how to (i) leverage additional data, (ii) augment/distillate data,
(iii) regularize training, and (iv) conduct efficient segmentation. As a
development example based on such optimization techniques, we also feature
LPIXEL&#x27;s CNN-based CXR solution, EIRL Chest Nodule, which improved
radiologists/non-radiologists&#x27; nodule detection sensitivity by 0.100/0.131,
respectively, while maintaining specificity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multi-task fully convolutional network for tree species mapping in dense forests using small training hyperspectral data. (arXiv:2106.00799v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosa_L/0/1/0/all/0/1">Laura Elena Cu&#xe9; La Rosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Sothe_C/0/1/0/all/0/1">Camile Sothe</a>, <a href="http://arxiv.org/find/cs/1/au:+Feitosa_R/0/1/0/all/0/1">Raul Queiroz Feitosa</a>, <a href="http://arxiv.org/find/cs/1/au:+Almeida_C/0/1/0/all/0/1">Cl&#xe1;udia Maria de Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Schimalski_M/0/1/0/all/0/1">Marcos Benedito Schimalski</a>, <a href="http://arxiv.org/find/cs/1/au:+Oliveira_D/0/1/0/all/0/1">Dario Augusto Borges Oliveira</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00799">
                                    <div class="article-summary-box-inner">
                                        <span>This work proposes a multi-task fully convolutional architecture for tree
species mapping in dense forests from sparse and scarce polygon-level
annotations using hyperspectral UAV-borne data. Our model implements a partial
loss function that enables dense tree semantic labeling outcomes from non-dense
training samples, and a distance regression complementary task that enforces
tree crown boundary constraints and substantially improves the model
performance. Our multi-task architecture uses a shared backbone network that
learns common representations for both tasks and two task-specific decoders,
one for the semantic segmentation output and one for the distance map
regression. We report that introducing the complementary task boosts the
semantic segmentation performance compared to the single-task counterpart in up
to 10% reaching an overall F1 score of 87.5% and an overall accuracy of 85.9%,
achieving state-of-art performance for tree species classification in tropical
forests.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ICDAR 2021 Competition on On-Line Signature Verification. (arXiv:2106.00739v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tolosana_R/0/1/0/all/0/1">Ruben Tolosana</a>, <a href="http://arxiv.org/find/cs/1/au:+Vera_Rodriguez_R/0/1/0/all/0/1">Ruben Vera-Rodriguez</a>, <a href="http://arxiv.org/find/cs/1/au:+Gonzalez_Garcia_C/0/1/0/all/0/1">Carlos Gonzalez-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Fierrez_J/0/1/0/all/0/1">Julian Fierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Rengifo_S/0/1/0/all/0/1">Santiago Rengifo</a>, <a href="http://arxiv.org/find/cs/1/au:+Morales_A/0/1/0/all/0/1">Aythami Morales</a>, <a href="http://arxiv.org/find/cs/1/au:+Ortega_Garcia_J/0/1/0/all/0/1">Javier Ortega-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Ruiz_Garcia_J/0/1/0/all/0/1">Juan Carlos Ruiz-Garcia</a>, <a href="http://arxiv.org/find/cs/1/au:+Romero_Tapiador_S/0/1/0/all/0/1">Sergio Romero-Tapiador</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1">Jiajia Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lai_S/0/1/0/all/0/1">Songxuan Lai</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1">Lianwen Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1">Yecheng Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Galbally_J/0/1/0/all/0/1">Javier Galbally</a>, <a href="http://arxiv.org/find/cs/1/au:+Diaz_M/0/1/0/all/0/1">Moises Diaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Ferrer_M/0/1/0/all/0/1">Miguel Angel Ferrer</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_Barrero_M/0/1/0/all/0/1">Marta Gomez-Barrero</a>, <a href="http://arxiv.org/find/cs/1/au:+Hodashinsky_I/0/1/0/all/0/1">Ilya Hodashinsky</a>, <a href="http://arxiv.org/find/cs/1/au:+Sarin_K/0/1/0/all/0/1">Konstantin Sarin</a>, <a href="http://arxiv.org/find/cs/1/au:+Slezkin_A/0/1/0/all/0/1">Artem Slezkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Bardamova_M/0/1/0/all/0/1">Marina Bardamova</a>, <a href="http://arxiv.org/find/cs/1/au:+Svetlakov_M/0/1/0/all/0/1">Mikhail Svetlakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Saleem_M/0/1/0/all/0/1">Mohammad Saleem</a>, <a href="http://arxiv.org/find/cs/1/au:+Szucs_C/0/1/0/all/0/1">Cintia Lia Sz&#xfc;cs</a>, <a href="http://arxiv.org/find/cs/1/au:+Kovari_B/0/1/0/all/0/1">Bence Kovari</a>, <a href="http://arxiv.org/find/cs/1/au:+Pulsmeyer_F/0/1/0/all/0/1">Falk Pulsmeyer</a>, <a href="http://arxiv.org/find/cs/1/au:+Wehbi_M/0/1/0/all/0/1">Mohamad Wehbi</a>, <a href="http://arxiv.org/find/cs/1/au:+Zanca_D/0/1/0/all/0/1">Dario Zanca</a>, <a href="http://arxiv.org/find/cs/1/au:+Ahmad_S/0/1/0/all/0/1">Sumaiya Ahmad</a>, <a href="http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1">Sarthak Mishra</a>, <a href="http://arxiv.org/find/cs/1/au:+Jabin_S/0/1/0/all/0/1">Suraiya Jabin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00739">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes the experimental framework and results of the ICDAR 2021
Competition on On-Line Signature Verification (SVC 2021). The goal of SVC 2021
is to evaluate the limits of on-line signature verification systems on popular
scenarios (office/mobile) and writing inputs (stylus/finger) through
large-scale public databases. Three different tasks are considered in the
competition, simulating realistic scenarios as both random and skilled
forgeries are simultaneously considered on each task. The results obtained in
SVC 2021 prove the high potential of deep learning methods. In particular, the
best on-line signature verification system of SVC 2021 obtained Equal Error
Rate (EER) values of 3.33% (Task 1), 7.41% (Task 2), and 6.04% (Task 3).

SVC 2021 will be established as an on-going competition, where researchers
can easily benchmark their systems against the state of the art in an open
common platform using large-scale public databases such as DeepSignDB and
SVC2021_EvalDB, and standard experimental protocols.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fourier Space Losses for Efficient Perceptual Image Super-Resolution. (arXiv:2106.00783v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Fuoli_D/0/1/0/all/0/1">Dario Fuoli</a>, <a href="http://arxiv.org/find/eess/1/au:+Gool_L/0/1/0/all/0/1">Luc Van Gool</a>, <a href="http://arxiv.org/find/eess/1/au:+Timofte_R/0/1/0/all/0/1">Radu Timofte</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00783">
                                    <div class="article-summary-box-inner">
                                        <span>Many super-resolution (SR) models are optimized for high performance only and
therefore lack efficiency due to large model complexity. As large models are
often not practical in real-world applications, we investigate and propose
novel loss functions, to enable SR with high perceptual quality from much more
efficient models. The representative power for a given low-complexity generator
network can only be fully leveraged by strong guidance towards the optimal set
of parameters. We show that it is possible to improve the performance of a
recently introduced efficient generator architecture solely with the
application of our proposed loss functions. In particular, we use a Fourier
space supervision loss for improved restoration of missing high-frequency (HF)
content from the ground truth image and design a discriminator architecture
working directly in the Fourier domain to better match the target HF
distribution. We show that our losses&#x27; direct emphasis on the frequencies in
Fourier-space significantly boosts the perceptual image quality, while at the
same time retaining high restoration quality in comparison to previously
proposed loss functions for this task. The performance is further improved by
utilizing a combination of spatial and frequency domain losses, as both
representations provide complementary information during training. On top of
that, the trained generator achieves comparable results with and is 2.4x and
48x faster than state-of-the-art perceptual SR methods RankSRGAN and SRFlow
respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">nnDetection: A Self-configuring Method for Medical Object Detection. (arXiv:2106.00817v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baumgartner_M/0/1/0/all/0/1">Michael Baumgartner</a>, <a href="http://arxiv.org/find/cs/1/au:+Jaeger_P/0/1/0/all/0/1">Paul F. Jaeger</a>, <a href="http://arxiv.org/find/cs/1/au:+Isensee_F/0/1/0/all/0/1">Fabian Isensee</a>, <a href="http://arxiv.org/find/cs/1/au:+Maier_Hein_K/0/1/0/all/0/1">Klaus H. Maier-Hein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00817">
                                    <div class="article-summary-box-inner">
                                        <span>Simultaneous localisation and categorization of objects in medical images,
also referred to as medical object detection, is of high clinical relevance
because diagnostic decisions often depend on rating of objects rather than e.g.
pixels. For this task, the cumbersome and iterative process of method
configuration constitutes a major research bottleneck. Recently, nnU-Net has
tackled this challenge for the task of image segmentation with great success.
Following nnU-Net&#x27;s agenda, in this work we systematize and automate the
configuration process for medical object detection. The resulting
self-configuring method, nnDetection, adapts itself without any manual
intervention to arbitrary medical detection problems while achieving results en
par with or superior to the state-of-the-art. We demonstrate the effectiveness
of nnDetection on two public benchmarks, ADAM and LUNA16, and propose 10
further medical object detection tasks on public data sets for comprehensive
method evaluation. Code is at https://github.com/MIC-DKFZ/nnDetection .</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">TransMIL: Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classication. (arXiv:2106.00908v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shao_Z/0/1/0/all/0/1">Zhuchen Shao</a>, <a href="http://arxiv.org/find/cs/1/au:+Bian_H/0/1/0/all/0/1">Hao Bian</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yifeng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1">Jian Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_X/0/1/0/all/0/1">Xiangyang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yongbing Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00908">
                                    <div class="article-summary-box-inner">
                                        <span>Multiple instance learning (MIL) is a powerful tool to solve the weakly
supervised classification in whole slide image (WSI) based pathology diagnosis.
However, the current MIL methods are usually based on independent and identical
distribution hypothesis, thus neglect the correlation among different
instances. To address this problem, we proposed a new framework, called
correlated MIL, and provided a proof for convergence. Based on this framework,
we devised a Transformer based MIL (TransMIL), which explored both
morphological and spatial information. The proposed TransMIL can effectively
deal with unbalanced/balanced and binary/multiple classification with great
visualization and interpretability. We conducted various experiments for three
different computational pathology problems and achieved better performance and
faster convergence compared with state-of-the-art methods. The test AUC for the
binary tumor classification can be up to 93.09% over CAMELYON16 dataset. And
the AUC over the cancer subtypes classification can be up to 96.03% and 98.82%
over TCGA-NSCLC dataset and TCGA-RCC dataset, respectively.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Cleaning and Structuring the Label Space of the iMet Collection 2020. (arXiv:2106.00815v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1">Vivien Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1">Sunnie S. Y. Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00815">
                                    <div class="article-summary-box-inner">
                                        <span>The iMet 2020 dataset is a valuable resource in the space of fine-grained art
attribution recognition, but we believe it has yet to reach its true potential.
We document the unique properties of the dataset and observe that many of the
attribute labels are noisy, more than is implied by the dataset description.
Oftentimes, there are also semantic relationships between the labels (e.g.,
identical, mutual exclusion, subsumption, overlap with uncertainty) which we
believe are underutilized. We propose an approach to cleaning and structuring
the iMet 2020 labels, and discuss the implications and value of doing so.
Further, we demonstrate the benefits of our proposed approach through several
experiments. Our code and cleaned labels are available at
https://github.com/sunniesuhyoung/iMet2020cleaned.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Refining the bounding volumes for lossless compression of voxelized point clouds geometry. (arXiv:2106.00828v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaya_E/0/1/0/all/0/1">Emre Can Kaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwarz_S/0/1/0/all/0/1">Sebastian Schwarz</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabus_I/0/1/0/all/0/1">Ioan Tabus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00828">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes a novel lossless compression method for point cloud
geometry, building on a recent lossy compression method that aimed at
reconstructing only the bounding volume of a point cloud. The proposed scheme
starts by partially reconstructing the geometry from the two depthmaps
associated to a single projection direction. The partial reconstruction
obtained from the depthmaps is completed to a full reconstruction of the point
cloud by sweeping section by section along one direction and encoding the
points which were not contained in the two depthmaps. The main ingredient is a
list-based encoding of the inner points (situated inside the feasible regions)
by a novel arithmetic three dimensional context coding procedure that
efficiently utilizes rotational invariances present in the input data.
State-of-the-art bits-per-voxel results are obtained on benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluating Recipes Generated from Functional Object-Oriented Network. (arXiv:2106.00728v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sakib_M/0/1/0/all/0/1">Md Sadman Sakib</a>, <a href="http://arxiv.org/find/cs/1/au:+Baez_H/0/1/0/all/0/1">Hailey Baez</a>, <a href="http://arxiv.org/find/cs/1/au:+Paulius_D/0/1/0/all/0/1">David Paulius</a>, <a href="http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1">Yu Sun</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00728">
                                    <div class="article-summary-box-inner">
                                        <span>The functional object-oriented network (FOON) has been introduced as a
knowledge representation, which takes the form of a graph, for symbolic task
planning. To get a sequential plan for a manipulation task, a robot can obtain
a task tree through a knowledge retrieval process from the FOON. To evaluate
the quality of an acquired task tree, we compare it with a conventional form of
task knowledge, such as recipes or manuals. We first automatically convert task
trees to recipes, and we then compare them with the human-created recipes in
the Recipe1M+ dataset via a survey. Our preliminary study finds no significant
difference between the recipes in Recipe1M+ and the recipes generated from FOON
task trees in terms of correctness, completeness, and clarity.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Rotation Equivariant Feature Image Pyramid Network for Object Detection in Optical Remote Sensing Imagery. (arXiv:2106.00880v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Shamsolmoali_P/0/1/0/all/0/1">Pourya Shamsolmoali</a>, <a href="http://arxiv.org/find/cs/1/au:+Zareapoor_M/0/1/0/all/0/1">Masoumeh Zareapoor</a>, <a href="http://arxiv.org/find/cs/1/au:+Chanussot_J/0/1/0/all/0/1">Jocelyn Chanussot</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1">Huiyu Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jie Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00880">
                                    <div class="article-summary-box-inner">
                                        <span>Over the last few years, there has been substantial progress in object
detection on remote sensing images (RSIs) where objects are generally
distributed with large-scale variations and have different types of
orientations. Nevertheless, most of the current convolution neural network
approaches lack the ability to deal with the challenges such as size and
rotation variations. To address these problems, we propose the rotation
equivariant feature image pyramid network (REFIPN), an image pyramid network
based on rotation equivariance convolution. The proposed pyramid network
extracts features in a wide range of scales and orientations by using novel
convolution filters. These features are used to generate vector fields and
determine the weight and angle of the highest-scoring orientation for all
spatial locations on an image. Finally, the extracted features go through the
prediction layers of the detector. The detection performance of the proposed
model is validated on two commonly used aerial benchmarks and the results show
our propose model can achieve state-of-the-art performance with satisfactory
efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Consumer Image Quality Prediction using Recurrent Neural Networks for Spatial Pooling. (arXiv:2106.00918v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korhonen_J/0/1/0/all/0/1">Jari Korhonen</a>, <a href="http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1">Yicheng Su</a>, <a href="http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1">Junyong You</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00918">
                                    <div class="article-summary-box-inner">
                                        <span>Promising results for subjective image quality prediction have been achieved
during the past few years by using convolutional neural networks (CNN).
However, the use of CNNs for high resolution image quality assessment remains a
challenge, since typical CNN architectures have been designed for small
resolution input images. In this study, we propose an image quality model that
attempts to mimic the attention mechanism of human visual system (HVS) by using
a recurrent neural network (RNN) for spatial pooling of the features extracted
from different spatial areas (patches) by a deep CNN-based feature extractor.
The experimental study, conducted by using images with different resolutions
from two recently published image quality datasets, indicates that the quality
prediction accuracy of the proposed method is competitive against benchmark
models representing the state-of-the-art, and the proposed method also performs
consistently on different resolution versions of the same dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Translational Symmetry-Aware Facade Parsing for 3D Building Reconstruction. (arXiv:2106.00912v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hantang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1">Wentong Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jianke Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00912">
                                    <div class="article-summary-box-inner">
                                        <span>Effectively parsing the facade is essential to 3D building reconstruction,
which is an important computer vision problem with a large amount of
applications in high precision map for navigation, computer aided design, and
city generation for digital entertainments. To this end, the key is how to
obtain the shape grammars from 2D images accurately and efficiently. Although
enjoying the merits of promising results on the semantic parsing, deep learning
methods cannot directly make use of the architectural rules, which play an
important role for man-made structures. In this paper, we present a novel
translational symmetry-based approach to improving the deep neural networks.
Our method employs deep learning models as the base parser, and a module taking
advantage of translational symmetry is used to refine the initial parsing
results. In contrast to conventional semantic segmentation or bounding box
prediction, we propose a novel scheme to fuse segmentation with anchor-free
detection in a single stage network, which enables the efficient training and
better convergence. After parsing the facades into shape grammars, we employ an
off-the-shelf rendering engine like Blender to reconstruct the realistic
high-quality 3D models using procedural modeling. We conduct experiments on
three public datasets, where our proposed approach outperforms the
state-of-the-art methods. In addition, we have illustrated the 3D building
models built from 2D facade images.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.IR"">cs.IR updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PairRank: Online Pairwise Learning to Rank by Divide-and-Conquer. (arXiv:2103.00368v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yiling Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huazheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Stephen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongning Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00368">
                                    <div class="article-summary-box-inner">
                                        <span>Online Learning to Rank (OL2R) eliminates the need of explicit relevance
annotation by directly optimizing the rankers from their interactions with
users. However, the required exploration drives it away from successful
practices in offline learning to rank, which limits OL2R&#x27;s empirical
performance and practical applicability. In this work, we propose to estimate a
pairwise learning to rank model online. In each round, candidate documents are
partitioned and ranked according to the model&#x27;s confidence on the estimated
pairwise rank order, and exploration is only performed on the uncertain pairs
of documents, i.e., \emph{divide-and-conquer}. Regret directly defined on the
number of mis-ordered pairs is proven, which connects the online solution&#x27;s
theoretical convergence with its expected ranking performance. Comparisons
against an extensive list of OL2R baselines on two public learning to rank
benchmark datasets demonstrate the effectiveness of the proposed solution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Timeline Length Selection for Flexible Timeline Summarization. (arXiv:2105.14201v1 [cs.AI] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1">Qianren Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hongdong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14201">
                                    <div class="article-summary-box-inner">
                                        <span>By producing summaries for long-running events, timeline summarization (TLS)
underpins many information retrieval tasks. Successful TLS requires identifying
an appropriate set of key dates (the timeline length) to cover. However, doing
so is challenging as the right length can change from one topic to another.
Existing TLS solutions either rely on an event-agnostic fixed length or an
expert-supplied setting. Neither of the strategies is desired for real-life TLS
scenarios. A fixed, event-agnostic setting ignores the diversity of events and
their development and hence can lead to low-quality TLS. Relying on
expert-crafted settings is neither scalable nor sustainable for processing many
dynamically changing events. This paper presents a better TLS approach for
automatically and dynamically determining the TLS timeline length. We achieve
this by employing the established elbow method from the machine learning
community to automatically find the minimum number of dates within the time
series to generate concise and informative summaries. We applied our approach
to four TLS datasets of English and Chinese and compared them against three
prior methods. Experimental results show that our approach delivers comparable
or even better summaries over state-of-art TLS methods, but it achieves this
without expert involvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Text Ranking with Meta Adapted Synthetic Weak Supervision. (arXiv:2012.14862v2 [cs.IR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1">Si Sun</a>, <a href="http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1">Yingzhuo Qian</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhenghao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Chenyan Xiong</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1">Kaitao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1">Jie Bao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1">Zhiyuan Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennett_P/0/1/0/all/0/1">Paul Bennett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.14862">
                                    <div class="article-summary-box-inner">
                                        <span>The effectiveness of Neural Information Retrieval (Neu-IR) often depends on a
large scale of in-domain relevance training signals, which are not always
available in real-world ranking scenarios. To democratize the benefits of
Neu-IR, this paper presents MetaAdaptRank, a domain adaptive learning method
that generalizes Neu-IR models from label-rich source domains to few-shot
target domains. Drawing on source-domain massive relevance supervision,
MetaAdaptRank contrastively synthesizes a large number of weak supervision
signals for target domains and meta-learns to reweight these synthetic &quot;weak&quot;
data based on their benefits to the target-domain ranking accuracy of Neu-IR
models. Experiments on three TREC benchmarks in the web, news, and biomedical
domains show that MetaAdaptRank significantly improves the few-shot ranking
accuracy of Neu-IR models. Further analyses indicate that MetaAdaptRank thrives
from both its contrastive weak data synthesis and meta-reweighted data
selection. The code and data of this paper can be obtained from
https://github.com/thunlp/MetaAdaptRank.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilingual Medical Question Answering and Information Retrieval for Rural Health Intelligence Access. (arXiv:2106.01251v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vinod_V/0/1/0/all/0/1">Vishal Vinod</a>, <a href="http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1">Susmit Agrawal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gaurav_V/0/1/0/all/0/1">Vipul Gaurav</a>, <a href="http://arxiv.org/find/cs/1/au:+R_P/0/1/0/all/0/1">Pallavi R</a>, <a href="http://arxiv.org/find/cs/1/au:+Choudhary_S/0/1/0/all/0/1">Savita Choudhary</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01251">
                                    <div class="article-summary-box-inner">
                                        <span>In rural regions of several developing countries, access to quality
healthcare, medical infrastructure, and professional diagnosis is largely
unavailable. Many of these regions are gradually gaining access to internet
infrastructure, although not with a strong enough connection to allow for
sustained communication with a medical practitioner. Several deaths resulting
from this lack of medical access, absence of patient&#x27;s previous health records,
and the unavailability of information in indigenous languages can be easily
prevented. In this paper, we describe an approach leveraging the phenomenal
progress in Machine Learning and NLP (Natural Language Processing) techniques
to design a model that is low-resource, multilingual, and a preliminary
first-point-of-contact medical assistant. Our contribution includes defining
the NLP pipeline required for named-entity-recognition, language-agnostic
sentence embedding, natural language translation, information retrieval,
question answering, and generative pre-training for final query processing. We
obtain promising results for this pipeline and preliminary results for EHR
(Electronic Health Record) analysis with text summarization for medical
practitioners to peruse for their diagnosis. Through this NLP pipeline, we aim
to provide preliminary medical information to the user and do not claim to
supplant diagnosis from qualified medical practitioners. Using the input from
subject matter experts, we have compiled a large corpus to pre-train and
fine-tune our BioBERT based NLP model for the specific tasks. We expect recent
advances in NLP architectures, several of which are efficient and
privacy-preserving models, to further the impact of our solution and improve on
individual task performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PP-Rec: News Recommendation with Personalized User Interest and Time-aware News Popularity. (arXiv:2106.01300v1 [cs.IR])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_T/0/1/0/all/0/1">Tao Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1">Fangzhao Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1">Chuhan Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yongfeng Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01300">
                                    <div class="article-summary-box-inner">
                                        <span>Personalized news recommendation methods are widely used in online news
services. These methods usually recommend news based on the matching between
news content and user interest inferred from historical behaviors. However,
these methods usually have difficulties in making accurate recommendations to
cold-start users, and tend to recommend similar news with those users have
read. In general, popular news usually contain important information and can
attract users with different interests. Besides, they are usually diverse in
content and topic. Thus, in this paper we propose to incorporate news
popularity information to alleviate the cold-start and diversity problems for
personalized news recommendation. In our method, the ranking score for
recommending a candidate news to a target user is the combination of a
personalized matching score and a news popularity score. The former is used to
capture the personalized user interest in news. The latter is used to measure
time-aware popularity of candidate news, which is predicted based on news
content, recency, and real-time CTR using a unified framework. Besides, we
propose a popularity-aware user encoder to eliminate the popularity bias in
user behaviors for accurate interest modeling. Experiments on two real-world
datasets show our method can effectively improve the accuracy and diversity for
news recommendation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A weighted unified informetrics based on Scopus and WoS. (arXiv:2106.01232v1 [cs.DL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khurana_P/0/1/0/all/0/1">Parul Khurana</a>, <a href="http://arxiv.org/find/cs/1/au:+Ganesan_G/0/1/0/all/0/1">Geetha Ganesan</a>, <a href="http://arxiv.org/find/cs/1/au:+Kumar_G/0/1/0/all/0/1">Gulshan Kumar</a>, <a href="http://arxiv.org/find/cs/1/au:+Sharma_K/0/1/0/all/0/1">Kiran Sharma</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01232">
                                    <div class="article-summary-box-inner">
                                        <span>Numerous indexing databases keep track of the number of publications,
citations, etc. in order to maintain the progress of science and individual.
However, the choice of journals and articles varies among these indexing
databases, hence the number of citations and h-index varies. There is no common
platform exists that can provide a single count for the number of publications,
citations, h-index, etc. To overcome this limitation, we have proposed a
weighted unified informetrics, named &quot;conflate&quot;. The proposed system takes into
account the input from multiple indexing databases and generates a single
output. Here, we have used the data from Scopus and WoS to generate a conflate
dataset. Further, a comparative analysis of conflate has been performed with
Scopus and WoS at three levels: author, organization, and journal. Finally, a
mapping is proposed between research publications and distributed ledger
technology in order to provide a transparent and distributed view to its
stakeholders.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Who Blames or Endorses Whom? Entity-to-Entity Directed Sentiment Extraction in News Text. (arXiv:2106.01033v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Park_K/0/1/0/all/0/1">Kunwoo Park</a>, <a href="http://arxiv.org/find/cs/1/au:+Pan_Z/0/1/0/all/0/1">Zhufeng Pan</a>, <a href="http://arxiv.org/find/cs/1/au:+Joo_J/0/1/0/all/0/1">Jungseock Joo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01033">
                                    <div class="article-summary-box-inner">
                                        <span>Understanding who blames or supports whom in news text is a critical research
question in computational social science. Traditional methods and datasets for
sentiment analysis are, however, not suitable for the domain of political text
as they do not consider the direction of sentiments expressed between entities.
In this paper, we propose a novel NLP task of identifying directed sentiment
relationship between political entities from a given news document, which we
call directed sentiment extraction. From a million-scale news corpus, we
construct a dataset of news sentences where sentiment relations of political
entities are manually annotated. We present a simple but effective approach for
utilizing a pretrained transformer, which infers the target class by predicting
multiple question-answering tasks and combining the outcomes. We demonstrate
the utility of our proposed method for social science research questions by
analyzing positive and negative opinions between political entities in two
major events: 2016 U.S. presidential election and COVID-19. The newly proposed
problem, data, and method will facilitate future studies on interdisciplinary
NLP methods and applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient Passage Retrieval with Hashing for Open-domain Question Answering. (arXiv:2106.00882v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yamada_I/0/1/0/all/0/1">Ikuya Yamada</a>, <a href="http://arxiv.org/find/cs/1/au:+Asai_A/0/1/0/all/0/1">Akari Asai</a>, <a href="http://arxiv.org/find/cs/1/au:+Hajishirzi_H/0/1/0/all/0/1">Hannaneh Hajishirzi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00882">
                                    <div class="article-summary-box-inner">
                                        <span>Most state-of-the-art open-domain question answering systems use a neural
retrieval model to encode passages into continuous vectors and extract them
from a knowledge source. However, such retrieval models often require large
memory to run because of the massive size of their passage index. In this
paper, we introduce Binary Passage Retriever (BPR), a memory-efficient neural
retrieval model that integrates a learning-to-hash technique into the
state-of-the-art Dense Passage Retriever (DPR) to represent the passage index
using compact binary codes rather than continuous vectors. BPR is trained with
a multi-task objective over two tasks: efficient candidate generation based on
binary codes and accurate reranking based on continuous vectors. Compared with
DPR, BPR substantially reduces the memory cost from 65GB to 2GB without a loss
of accuracy on two standard open-domain question answering benchmarks: Natural
Questions and TriviaQA. Our code and trained models are available at
https://github.com/studio-ousia/bpr.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Conversational Question Answering: A Survey. (arXiv:2106.00874v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zaib_M/0/1/0/all/0/1">Munazza Zaib</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1">Wei Emma Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sheng_Q/0/1/0/all/0/1">Quan Z. Sheng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahmood_A/0/1/0/all/0/1">Adnan Mahmood</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Yang Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00874">
                                    <div class="article-summary-box-inner">
                                        <span>Question answering (QA) systems provide a way of querying the information
available in various formats including, but not limited to, unstructured and
structured data in natural languages. It constitutes a considerable part of
conversational artificial intelligence (AI) which has led to the introduction
of a special research topic on Conversational Question Answering (CQA), wherein
a system is required to understand the given context and then engages in
multi-turn QA to satisfy the user&#x27;s information needs. Whilst the focus of most
of the existing research work is subjected to single-turn QA, the field of
multi-turn QA has recently grasped attention and prominence owing to the
availability of large-scale, multi-turn QA datasets and the development of
pre-trained language models. With a good amount of models and research papers
adding to the literature every year recently, there is a dire need of arranging
and presenting the related work in a unified manner to streamline future
research. This survey, therefore, is an effort to present a comprehensive
review of the state-of-the-art research trends of CQA primarily based on
reviewed papers from 2016-2021. Our findings show that there has been a trend
shift from single-turn to multi-turn QA which empowers the field of
Conversational AI from different perspectives. This survey is intended to
provide an epitome for the research community with the hope of laying a strong
foundation for the field of CQA.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Needle in a Haystack: Label-Efficient Evaluation under Extreme Class Imbalance. (arXiv:2006.06963v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marchant_N/0/1/0/all/0/1">Neil G. Marchant</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1">Benjamin I. P. Rubinstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06963">
                                    <div class="article-summary-box-inner">
                                        <span>Important tasks like record linkage and extreme classification demonstrate
extreme class imbalance, with 1 minority instance to every 1 million or more
majority instances. Obtaining a sufficient sample of all classes, even just to
achieve statistically-significant evaluation, is so challenging that most
current approaches yield poor estimates or incur impractical cost. Where
importance sampling has been levied against this challenge, restrictive
constraints are placed on performance metrics, estimates do not come with
appropriate guarantees, or evaluations cannot adapt to incoming labels. This
paper develops a framework for online evaluation based on adaptive importance
sampling. Given a target performance metric and model for $p(y|x)$, the
framework adapts a distribution over items to label in order to maximize
statistical precision. We establish strong consistency and a central limit
theorem for the resulting performance estimates, and instantiate our framework
with worked examples that leverage Dirichlet-tree models. Experiments
demonstrate an average MSE superior to state-of-the-art on fixed label budgets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Exploring modality-agnostic representations for music classification. (arXiv:2106.01149v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1">Ho-Hsiang Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Fuentes_M/0/1/0/all/0/1">Magdalena Fuentes</a>, <a href="http://arxiv.org/find/cs/1/au:+Bello_J/0/1/0/all/0/1">Juan P. Bello</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01149">
                                    <div class="article-summary-box-inner">
                                        <span>Music information is often conveyed or recorded across multiple data
modalities including but not limited to audio, images, text and scores.
However, music information retrieval research has almost exclusively focused on
single modality recognition, requiring development of separate models for each
modality. Some multi-modal works require multiple coexisting modalities given
to the model as inputs, constraining the use of these models to the few cases
where data from all modalities are available. To the best of our knowledge, no
existing model has the ability to take inputs from varying modalities, e.g.
images or sounds, and classify them into unified music categories. We explore
the use of cross-modal retrieval as a pretext task to learn modality-agnostic
representations, which can then be used as inputs to classifiers that are
independent of modality. We select instrument classification as an example task
for our study as both visual and audio components provide relevant semantic
information. We train music instrument classifiers that can take both images or
sounds as input, and perform comparably to sound-only or image-only
classifiers. Furthermore, we explore the case when there is limited labeled
data for a given modality, and the impact in performance by using labeled data
from other modalities. We are able to achieve almost 70% of best performing
system in a zero-shot setting. We provide a detailed analysis of experimental
results to understand the potential and limitations of the approach, and
discuss future steps towards modality-agnostic classifiers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.LG"">cs.LG updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Warming-up recurrent neural networks to maximize reachable multi-stability greatly improves learning. (arXiv:2106.01001v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vecoven_N/0/1/0/all/0/1">Nicolas Vecoven</a>, <a href="http://arxiv.org/find/cs/1/au:+Ernst_D/0/1/0/all/0/1">Damien Ernst</a>, <a href="http://arxiv.org/find/cs/1/au:+Drion_G/0/1/0/all/0/1">Guillaume Drion</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01001">
                                    <div class="article-summary-box-inner">
                                        <span>Training recurrent neural networks is known to be difficult when time
dependencies become long. Consequently, training standard gated cells such as
gated recurrent units and long-short term memory on benchmarks where long-term
memory is required remains an arduous task. In this work, we propose a general
way to initialize any recurrent network connectivity through a process called
&quot;warm-up&quot; to improve its capability to learn arbitrarily long time
dependencies. This initialization process is designed to maximize network
reachable multi-stability, i.e. the number of attractors within the network
that can be reached through relevant input trajectories. Warming-up is
performed before training, using stochastic gradient descent on a specifically
designed loss. We show that warming-up greatly improves recurrent neural
network performance on long-term memory benchmarks for multiple recurrent cell
types, but can sometimes impede precision. We therefore introduce a parallel
recurrent network structure with partial warm-up that is shown to greatly
improve learning on long time-series while maintaining high levels of
precision. This approach provides a general framework for improving learning
abilities of any recurrent cell type when long-term memory is required.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep learning-based multi-output quantile forecasting of PV generation. (arXiv:2106.01271v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dumas_J/0/1/0/all/0/1">Jonathan Dumas</a>, <a href="http://arxiv.org/find/cs/1/au:+Cointe_C/0/1/0/all/0/1">Colin Cointe</a>, <a href="http://arxiv.org/find/cs/1/au:+Fettweis_X/0/1/0/all/0/1">Xavier Fettweis</a>, <a href="http://arxiv.org/find/cs/1/au:+Cornelusse_B/0/1/0/all/0/1">Bertrand Corn&#xe9;lusse</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01271">
                                    <div class="article-summary-box-inner">
                                        <span>This paper develops probabilistic PV forecasters by taking advantage of
recent breakthroughs in deep learning. It tailored forecasting tool, named
encoder-decoder, is implemented to compute intraday multi-output PV quantiles
forecasts to efficiently capture the time correlation. The models are trained
using quantile regression, a non-parametric approach that assumes no prior
knowledge of the probabilistic forecasting distribution. The case study is
composed of PV production monitored on-site at the University of Li\&#x60;ege
(ULi\&#x60;ege), Belgium. The weather forecasts from the regional climate model
provided by the Laboratory of Climatology are used as inputs of the deep
learning models. The forecast quality is quantitatively assessed by the
continuous ranked probability and interval scores. The results indicate this
architecture improves the forecast quality and is computationally efficient to
be incorporated in an intraday decision-making tool for robust optimization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the experimental feasibility of quantum state reconstruction via machine learning. (arXiv:2012.09432v2 [quant-ph] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/quant-ph/1/au:+Lohani_S/0/1/0/all/0/1">Sanjaya Lohani</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Searles_T/0/1/0/all/0/1">Thomas A. Searles</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Kirby_B/0/1/0/all/0/1">Brian T. Kirby</a>, <a href="http://arxiv.org/find/quant-ph/1/au:+Glasser_R/0/1/0/all/0/1">Ryan T. Glasser</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.09432">
                                    <div class="article-summary-box-inner">
                                        <span>We determine the resource scaling of machine learning-based quantum state
reconstruction methods, in terms of inference and training, for systems of up
to four qubits when constrained to pure states. Further, we examine system
performance in the low-count regime, likely to be encountered in the tomography
of high-dimensional systems. Finally, we implement our quantum state
reconstruction method on an IBM Q quantum computer, and compare against both
unconstrained and constrained MLE state reconstruction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Continual Learning in Image Classification: An Empirical Survey. (arXiv:2101.10423v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mai_Z/0/1/0/all/0/1">Zheda Mai</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1">Ruiwen Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1">Jihwan Jeong</a>, <a href="http://arxiv.org/find/cs/1/au:+Quispe_D/0/1/0/all/0/1">David Quispe</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_H/0/1/0/all/0/1">Hyunwoo Kim</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanner_S/0/1/0/all/0/1">Scott Sanner</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.10423">
                                    <div class="article-summary-box-inner">
                                        <span>Online continual learning for image classification studies the problem of
learning to classify images from an online stream of data and tasks, where
tasks may include new classes (class incremental) or data nonstationarity
(domain incremental). One of the key challenges of continual learning is to
avoid catastrophic forgetting (CF), i.e., forgetting old tasks in the presence
of more recent tasks. Over the past few years, many methods and tricks have
been introduced to address this problem, but many have not been fairly and
systematically compared under a variety of realistic and practical settings. To
better understand the relative advantages of various approaches and the
settings where they work best, this survey aims to (1) compare state-of-the-art
methods such as MIR, iCARL, and GDumb and determine which works best at
different experimental settings; (2) determine if the best class incremental
methods are also competitive in domain incremental setting; (3) evaluate the
performance of 7 simple but effective trick such as &quot;review&quot; trick and nearest
class mean (NCM) classifier to assess their relative impact. Regarding (1), we
observe iCaRL remains competitive when the memory buffer is small; GDumb
outperforms many recently proposed methods in medium-size datasets and MIR
performs the best in larger-scale datasets. For (2), we note that GDumb
performs quite poorly while MIR -- already competitive for (1) -- is also
strongly competitive in this very different but important setting. Overall,
this allows us to conclude that MIR is overall a strong and versatile method
across a wide variety of settings. For (3), we find that all 7 tricks are
beneficial, and when augmented with the &quot;review&quot; trick and NCM classifier, MIR
produces performance levels that bring online continual learning much closer to
its ultimate goal of matching offline training.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Determining Chess Game State From an Image. (arXiv:2104.14963v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wolflein_G/0/1/0/all/0/1">Georg W&#xf6;lflein</a>, <a href="http://arxiv.org/find/cs/1/au:+Arandjelovic_O/0/1/0/all/0/1">Ognjen Arandjelovi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14963">
                                    <div class="article-summary-box-inner">
                                        <span>Identifying the configuration of chess pieces from an image of a chessboard
is a problem in computer vision that has not yet been solved accurately.
However, it is important for helping amateur chess players improve their games
by facilitating automatic computer analysis without the overhead of manually
entering the pieces. Current approaches are limited by the lack of large
datasets and are not designed to adapt to unseen chess sets. This paper puts
forth a new dataset synthesised from a 3D model that is an order of magnitude
larger than existing ones. Trained on this dataset, a novel end-to-end chess
recognition system is presented that combines traditional computer vision
techniques with deep learning. It localises the chessboard using a RANSAC-based
algorithm that computes a projective transformation of the board onto a regular
grid. Using two convolutional neural networks, it then predicts an occupancy
mask for the squares in the warped image and finally classifies the pieces. The
described system achieves an error rate of 0.23% per square on the test set, 28
times better than the current state of the art. Further, a few-shot transfer
learning approach is developed that is able to adapt the inference system to a
previously unseen chess set using just two photos of the starting position,
obtaining a per-square accuracy of 99.83% on images of that new chess set. The
code, dataset, and trained models are made available online.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchmarking the Performance of Bayesian Optimization across Multiple Experimental Materials Science Domains. (arXiv:2106.01309v1 [cond-mat.mtrl-sci])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cond-mat/1/au:+Liang_Q/0/1/0/all/0/1">Qiaohao Liang</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Gongora_A/0/1/0/all/0/1">Aldair E. Gongora</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Ren_Z/0/1/0/all/0/1">Zekun Ren</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Tiihonen_A/0/1/0/all/0/1">Armi Tiihonen</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Liu_Z/0/1/0/all/0/1">Zhe Liu</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Sun_S/0/1/0/all/0/1">Shijing Sun</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Deneault_J/0/1/0/all/0/1">James R. Deneault</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Bash_D/0/1/0/all/0/1">Daniil Bash</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Mekki_Berrada_F/0/1/0/all/0/1">Flore Mekki-Berrada</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Khan_S/0/1/0/all/0/1">Saif A. Khan</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Hippalgaonkar_K/0/1/0/all/0/1">Kedar Hippalgaonkar</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Maruyama_B/0/1/0/all/0/1">Benji Maruyama</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Brown_K/0/1/0/all/0/1">Keith A. Brown</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Fisher_J/0/1/0/all/0/1">John Fisher III</a>, <a href="http://arxiv.org/find/cond-mat/1/au:+Buonassisi_T/0/1/0/all/0/1">Tonio Buonassisi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01309">
                                    <div class="article-summary-box-inner">
                                        <span>In the field of machine learning (ML) for materials optimization, active
learning algorithms, such as Bayesian Optimization (BO), have been leveraged
for guiding autonomous and high-throughput experimentation systems. However,
very few studies have evaluated the efficiency of BO as a general optimization
algorithm across a broad range of experimental materials science domains. In
this work, we evaluate the performance of BO algorithms with a collection of
surrogate model and acquisition function pairs across five diverse experimental
materials systems, namely carbon nanotube polymer blends, silver nanoparticles,
lead-halide perovskites, as well as additively manufactured polymer structures
and shapes. By defining acceleration and enhancement metrics for general
materials optimization objectives, we find that for surrogate model selection,
Gaussian Process (GP) with anisotropic kernels (automatic relevance detection,
ARD) and Random Forests (RF) have comparable performance and both outperform
the commonly used GP without ARD. We discuss the implicit distributional
assumptions of RF and GP, and the benefits of using GP with anisotropic kernels
in detail. We provide practical insights for experimentalists on surrogate
model selection of BO during materials optimization campaigns.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Data augmentation and pre-trained networks for extremely low data regimes unsupervised visual inspection. (arXiv:2106.01277v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gutierrez_P/0/1/0/all/0/1">Pierre Gutierrez</a>, <a href="http://arxiv.org/find/cs/1/au:+Cordier_A/0/1/0/all/0/1">Antoine Cordier</a>, <a href="http://arxiv.org/find/cs/1/au:+Caldeira_T/0/1/0/all/0/1">Tha&#xef;s Caldeira</a>, <a href="http://arxiv.org/find/cs/1/au:+Sautory_T/0/1/0/all/0/1">Th&#xe9;ophile Sautory</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01277">
                                    <div class="article-summary-box-inner">
                                        <span>The use of deep features coming from pre-trained neural networks for
unsupervised anomaly detection purposes has recently gathered momentum in the
computer vision field. In particular, industrial inspection applications can
take advantage of such features, as demonstrated by the multiple successes of
related methods on the MVTec Anomaly Detection (MVTec AD) dataset. These
methods make use of neural networks pre-trained on auxiliary classification
tasks such as ImageNet. However, to our knowledge, no comparative study of
robustness to the low data regimes between these approaches has been conducted
yet. For quality inspection applications, the handling of limited sample sizes
may be crucial as large quantities of images are not available for small
series. In this work, we aim to compare three approaches based on deep
pre-trained features when varying the quantity of available data in MVTec AD:
KNN, Mahalanobis, and PaDiM. We show that although these methods are mostly
robust to small sample sizes, they still can benefit greatly from using data
augmentation in the original image space, which allows to deal with very small
production runs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Meta-strategy for Learning Tuning Parameters with Guarantees. (arXiv:2102.02504v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Meunier_D/0/1/0/all/0/1">Dimitri Meunier</a>, <a href="http://arxiv.org/find/stat/1/au:+Alquier_P/0/1/0/all/0/1">Pierre Alquier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.02504">
                                    <div class="article-summary-box-inner">
                                        <span>Online gradient methods, like the online gradient algorithm (OGA), often
depend on tuning parameters that are difficult to set in practice. We consider
an online meta-learning scenario, and we propose a meta-strategy to learn these
parameters from past tasks. Our strategy is based on the minimization of a
regret bound. It allows to learn the initialization and the step size in OGA
with guarantees. We provide a regret analysis of the strategy in the case of
convex losses. It suggests that, when there are parameters
$\theta_1,\dots,\theta_T$ solving well tasks $1,\dots,T$ respectively and that
are close enough one to each other, our strategy indeed improves on learning
each task in isolation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Privacy-Preserving and Trustable Multi-agent Learning Framework. (arXiv:2106.01242v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nagar_A/0/1/0/all/0/1">Anudit Nagar</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_C/0/1/0/all/0/1">Cuong Tran</a>, <a href="http://arxiv.org/find/cs/1/au:+Fioretto_F/0/1/0/all/0/1">Ferdinando Fioretto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01242">
                                    <div class="article-summary-box-inner">
                                        <span>Distributed multi-agent learning enables agents to cooperatively train a
model without requiring to share their datasets. While this setting ensures
some level of privacy, it has been shown that, even when data is not directly
shared, the training process is vulnerable to privacy attacks including data
reconstruction and model inversion attacks. Additionally, malicious agents that
train on inverted labels or random data, may arbitrarily weaken the accuracy of
the global model. This paper addresses these challenges and presents
Privacy-preserving and trustable Distributed Learning (PT-DL), a fully
decentralized framework that relies on Differential Privacy to guarantee strong
privacy protections of the agents&#x27; data, and Ethereum smart contracts to ensure
trustability. The paper shows that PT-DL is resilient up to a 50% collusion
attack, with high probability, in a malicious trust model and the experimental
evaluation illustrates the benefits of the proposed model as a
privacy-preserving and trustable distributed multi-agent learning system on
several classification tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Do Neural Networks Estimate Optical Flow? A Neuropsychology-Inspired Study. (arXiv:2004.09317v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jong_D/0/1/0/all/0/1">D. B. de Jong</a>, <a href="http://arxiv.org/find/cs/1/au:+Paredes_Valles_F/0/1/0/all/0/1">F. Paredes-Vall&#xe9;s</a>, <a href="http://arxiv.org/find/cs/1/au:+Croon_G/0/1/0/all/0/1">G. C. H. E. de Croon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.09317">
                                    <div class="article-summary-box-inner">
                                        <span>End-to-end trained convolutional neural networks have led to a breakthrough
in optical flow estimation. The most recent advances focus on improving the
optical flow estimation by improving the architecture and setting a new
benchmark on the publicly available MPI-Sintel dataset. Instead, in this
article, we investigate how deep neural networks estimate optical flow. A
better understanding of how these networks function is important for (i)
assessing their generalization capabilities to unseen inputs, and (ii)
suggesting changes to improve their performance. For our investigation, we
focus on FlowNetS, as it is the prototype of an encoder-decoder neural network
for optical flow estimation. Furthermore, we use a filter identification method
that has played a major role in uncovering the motion filters present in animal
brains in neuropsychological research. The method shows that the filters in the
deepest layer of FlowNetS are sensitive to a variety of motion patterns. Not
only do we find translation filters, as demonstrated in animal brains, but
thanks to the easier measurements in artificial neural networks, we even unveil
dilation, rotation, and occlusion filters. Furthermore, we find similarities in
the refinement part of the network and the perceptual filling-in process which
occurs in the mammal primary visual cortex.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Information Theoretic Measures for Fairness-aware Feature Selection. (arXiv:2106.00772v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Khodadadian_S/0/1/0/all/0/1">Sajad Khodadadian</a>, <a href="http://arxiv.org/find/cs/1/au:+Nafea_M/0/1/0/all/0/1">Mohamed Nafea</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghassami_A/0/1/0/all/0/1">AmirEmad Ghassami</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1">Negar Kiyavash</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00772">
                                    <div class="article-summary-box-inner">
                                        <span>Machine earning algorithms are increasingly used for consequential decision
making regarding individuals based on their relevant features. Features that
are relevant for accurate decisions may however lead to either explicit or
implicit forms of discrimination against unprivileged groups, such as those of
certain race or gender. This happens due to existing biases in the training
data, which are often replicated or even exacerbated by the learning algorithm.
Identifying and measuring these biases at the data level is a challenging
problem due to the interdependence among the features, and the decision
outcome. In this work, we develop a framework for fairness-aware feature
selection, based on information theoretic measures for the accuracy and
discriminatory impacts of features. Specifically, our goal is to design a
fairness utility score for each feature which quantifies how this feature
influences accurate as well as nondiscriminatory decisions. We first propose
information theoretic measures for the impact of different subsets of features
on the accuracy and discrimination of the model. Subsequently, we deduce the
marginal impact of each feature using Shapley value function. Our framework
depends on the joint statistics of the data rather than a particular classifier
design. We examine our proposed framework on real and synthetic data to
evaluate its performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Extendible, Graph-Neural-Network-Based Approach for Accurate Force Field Development of Large Flexible Organic Molecules. (arXiv:2106.00927v1 [physics.chem-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Wang_X/0/1/0/all/0/1">Xufei Wang</a>, <a href="http://arxiv.org/find/physics/1/au:+Xu_Y/0/1/0/all/0/1">Yuanda Xu</a>, <a href="http://arxiv.org/find/physics/1/au:+Zheng_H/0/1/0/all/0/1">Han Zheng</a>, <a href="http://arxiv.org/find/physics/1/au:+Yu_K/0/1/0/all/0/1">Kuang Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00927">
                                    <div class="article-summary-box-inner">
                                        <span>An accurate force field is the key to the success of all molecular mechanics
simulations on organic polymers and biomolecules. Accuracy beyond density
functional theory is often needed to describe the intermolecular interactions,
while most correlated wavefunction (CW) methods are prohibitively expensive for
large molecules. Therefore, it posts a great challenge to develop an extendible
ab initio force field for large flexible organic molecules at CW level of
accuracy. In this work, we face this challenge by combining the physics-driven
nonbonding potential with a data-driven subgraph neural network bonding model
(named sGNN). Tests on polyethylene glycol polymer chains show that our
strategy is highly accurate and robust for molecules of different sizes.
Therefore, we can develop the force field from small molecular fragments (with
sizes easily accessible to CW methods) and safely transfer it to large
polymers, thus opening a new path to the next-generation organic force fields.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">KO-PDE: Kernel Optimized Discovery of Partial Differential Equations with Varying Coefficients. (arXiv:2106.01078v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Yingtao Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1">Qiang Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yuntian Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1">Wenbo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1">Jun Zhu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01078">
                                    <div class="article-summary-box-inner">
                                        <span>Partial differential equations (PDEs) fitting scientific data can represent
physical laws with explainable mechanisms for various mathematically-oriented
subjects. Most natural dynamics are expressed by PDEs with varying coefficients
(PDEs-VC), which highlights the importance of PDE discovery. Previous
algorithms can discover some simple instances of PDEs-VC but fail in the
discovery of PDEs with coefficients of higher complexity, as a result of
coefficient estimation inaccuracy. In this paper, we propose KO-PDE, a kernel
optimized regression method that incorporates the kernel density estimation of
adjacent coefficients to reduce the coefficient estimation error. KO-PDE can
discover PDEs-VC on which previous baselines fail and is more robust against
inevitable noise in data. In experiments, the PDEs-VC of seven challenging
spatiotemporal scientific datasets in fluid dynamics are all discovered by
KO-PDE, while the three baselines render false results in most cases. With
state-of-the-art performance, KO-PDE sheds light on the automatic description
of natural phenomenons using discovered PDEs in the real world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pay Attention to MLPs. (arXiv:2105.08050v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1">Hanxiao Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Dai_Z/0/1/0/all/0/1">Zihang Dai</a>, <a href="http://arxiv.org/find/cs/1/au:+So_D/0/1/0/all/0/1">David R. So</a>, <a href="http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1">Quoc V. Le</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08050">
                                    <div class="article-summary-box-inner">
                                        <span>Transformers have become one of the most important architectural innovations
in deep learning and have enabled many breakthroughs over the past few years.
Here we propose a simple network architecture, gMLP, based on MLPs with gating,
and show that it can perform as well as Transformers in key language and vision
applications. Our comparisons show that self-attention is not critical for
Vision Transformers, as gMLP can achieve the same accuracy. For BERT, our model
achieves parity with Transformers on pretraining perplexity and is better on
some downstream NLP tasks. On finetuning tasks where gMLP performs worse,
making the gMLP model substantially larger can close the gap with Transformers.
In general, our experiments show that gMLP can scale as well as Transformers
over increased data and compute.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Personalized Glucose Level Forecasting Using Attention-based Recurrent Neural Networks. (arXiv:2106.00884v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Armandpour_M/0/1/0/all/0/1">Mohammadreza Armandpour</a>, <a href="http://arxiv.org/find/cs/1/au:+Kidd_B/0/1/0/all/0/1">Brian Kidd</a>, <a href="http://arxiv.org/find/cs/1/au:+Du_Y/0/1/0/all/0/1">Yu Du</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jianhua Z. Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00884">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the problem of blood glucose forecasting and provide
a deep personalized solution. Predicting blood glucose level in people with
diabetes has significant value because health complications of abnormal glucose
level are serious, sometimes even leading to death. Therefore, having a model
that can accurately and quickly warn patients of potential problems is
essential. To develop a better deep model for blood glucose forecasting, we
analyze the data and detect important patterns. These observations helped us to
propose a method that has several key advantages over existing methods: 1- it
learns a personalized model for each patient as well as a global model; 2- it
uses an attention mechanism and extracted time features to better learn
long-term dependencies in the data; 3- it introduces a new, robust training
procedure for time series data. We empirically show the efficacy of our model
on a real dataset.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GAMI-Net: An Explainable Neural Network based on Generalized Additive Models with Structured Interactions. (arXiv:2003.07132v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Yang_Z/0/1/0/all/0/1">Zebin Yang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_A/0/1/0/all/0/1">Aijun Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Sudjianto_A/0/1/0/all/0/1">Agus Sudjianto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2003.07132">
                                    <div class="article-summary-box-inner">
                                        <span>The lack of interpretability is an inevitable problem when using neural
network models in real applications. In this paper, an explainable neural
network based on generalized additive models with structured interactions
(GAMI-Net) is proposed to pursue a good balance between prediction accuracy and
model interpretability. GAMI-Net is a disentangled feedforward network with
multiple additive subnetworks; each subnetwork consists of multiple hidden
layers and is designed for capturing one main effect or one pairwise
interaction. Three interpretability aspects are further considered, including
a) sparsity, to select the most significant effects for parsimonious
representations; b) heredity, a pairwise interaction could only be included
when at least one of its parent main effects exists; and c) marginal clarity,
to make main effects and pairwise interactions mutually distinguishable. An
adaptive training algorithm is developed, where main effects are first trained
and then pairwise interactions are fitted to the residuals. Numerical
experiments on both synthetic functions and real-world datasets show that the
proposed model enjoys superior interpretability and it maintains competitive
prediction accuracy in comparison to the explainable boosting machine and other
classic machine learning models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Automated Timeline Length Selection for Flexible Timeline Summarization. (arXiv:2105.14201v1 [cs.AI] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1">Xi Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Mao_Q/0/1/0/all/0/1">Qianren Mao</a>, <a href="http://arxiv.org/find/cs/1/au:+Peng_H/0/1/0/all/0/1">Hao Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1">Hongdong Zhu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jianxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zheng Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.14201">
                                    <div class="article-summary-box-inner">
                                        <span>By producing summaries for long-running events, timeline summarization (TLS)
underpins many information retrieval tasks. Successful TLS requires identifying
an appropriate set of key dates (the timeline length) to cover. However, doing
so is challenging as the right length can change from one topic to another.
Existing TLS solutions either rely on an event-agnostic fixed length or an
expert-supplied setting. Neither of the strategies is desired for real-life TLS
scenarios. A fixed, event-agnostic setting ignores the diversity of events and
their development and hence can lead to low-quality TLS. Relying on
expert-crafted settings is neither scalable nor sustainable for processing many
dynamically changing events. This paper presents a better TLS approach for
automatically and dynamically determining the TLS timeline length. We achieve
this by employing the established elbow method from the machine learning
community to automatically find the minimum number of dates within the time
series to generate concise and informative summaries. We applied our approach
to four TLS datasets of English and Chinese and compared them against three
prior methods. Experimental results show that our approach delivers comparable
or even better summaries over state-of-art TLS methods, but it achieves this
without expert involvement.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Is good old GRAPPA dead?. (arXiv:2106.00753v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Ramzi_Z/0/1/0/all/0/1">Zaccharie Ramzi</a>, <a href="http://arxiv.org/find/eess/1/au:+Vignaud_A/0/1/0/all/0/1">Alexandre Vignaud</a>, <a href="http://arxiv.org/find/eess/1/au:+Starck_J/0/1/0/all/0/1">Jean-Luc Starck</a>, <a href="http://arxiv.org/find/eess/1/au:+Ciuciu_P/0/1/0/all/0/1">Philippe Ciuciu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00753">
                                    <div class="article-summary-box-inner">
                                        <span>We perform a qualitative analysis of performance of XPDNet, a
state-of-the-art deep learning approach for MRI reconstruction, compared to
GRAPPA, a classical approach. We do this in multiple settings, in particular
testing the robustness of the XPDNet to unseen settings, and show that the
XPDNet can to some degree generalize well.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">One-Pixel Attack Deceives Computer-Assisted Diagnosis of Cancer. (arXiv:2012.00517v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Korpihalkola_J/0/1/0/all/0/1">Joni Korpihalkola</a>, <a href="http://arxiv.org/find/cs/1/au:+Sipola_T/0/1/0/all/0/1">Tuomo Sipola</a>, <a href="http://arxiv.org/find/cs/1/au:+Puuska_S/0/1/0/all/0/1">Samir Puuska</a>, <a href="http://arxiv.org/find/cs/1/au:+Kokkonen_T/0/1/0/all/0/1">Tero Kokkonen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.00517">
                                    <div class="article-summary-box-inner">
                                        <span>Computer vision and machine learning can be used to automate various tasks in
cancer diagnostic and detection. If an attacker can manipulate the automated
processing, the results can be devastating and in the worst case lead to wrong
diagnosis and treatment. In this research, the goal is to demonstrate the use
of one-pixel attacks in a real-life scenario with a real pathology dataset,
TUPAC16, which consists of digitized whole-slide images. We attack against the
IBM CODAIT&#x27;s MAX breast cancer detector using adversarial images. These
adversarial examples are found using differential evolution to perform the
one-pixel modification to the images in the dataset. The results indicate that
a minor one-pixel modification of a whole slide image under analysis can affect
the diagnosis by reversing the automatic diagnosis result. The attack poses a
threat from the cyber security perspective: the one-pixel method can be used as
an attack vector by a motivated attacker.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SENTINEL: Taming Uncertainty with Ensemble-based Distributional Reinforcement Learning. (arXiv:2102.11075v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Eriksson_H/0/1/0/all/0/1">Hannes Eriksson</a>, <a href="http://arxiv.org/find/cs/1/au:+Basu_D/0/1/0/all/0/1">Debabrota Basu</a>, <a href="http://arxiv.org/find/cs/1/au:+Alibeigi_M/0/1/0/all/0/1">Mina Alibeigi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dimitrakakis_C/0/1/0/all/0/1">Christos Dimitrakakis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.11075">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we consider risk-sensitive sequential decision-making in
model-based Reinforcement Learning (RL). Our contributions are two-fold. First,
we introduce a novel and coherent quantification of risk, namely composite
risk, which quantifies joint effect of aleatory and epistemic risk during the
learning process. Existing works considered either aleatory or epistemic risk
individually, or an additive combination of the two. We prove that the additive
formulation is a particular case of the composite risk when the epistemic risk
measure is replaced with expectation. Thus, the composite risk provides an
estimate more sensitive to both aleatory and epistemic sources of uncertainties
than the individual and additive formulations. Following that, we propose to
use a bootstrapping method, SENTINEL-K, for performing distributional RL.
SENTINEL-K uses an ensemble of $K$ learners to estimate the return
distribution. We use the Follow The Regularised Leader (FTRL) to aggregate the
return distributions of $K$ learners and to estimate the composite risk. We
experimentally verify that SENTINEL-K estimates the return distribution better,
and while used with composite risk estimate, demonstrates better risk-sensitive
performance than state-of-the-art risk-sensitive and distributional RL
algorithms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Post-mortem on a deep learning contest: a Simpson&#x27;s paradox and the complementary roles of scale metrics versus shape metrics. (arXiv:2106.00734v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Martin_C/0/1/0/all/0/1">Charles H. Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00734">
                                    <div class="article-summary-box-inner">
                                        <span>To understand better the causes of good generalization performance in
state-of-the-art neural network (NN) models, we analyze of a corpus of models
that was made publicly-available for a contest to predict the generalization
accuracy of NNs. These models include a wide range of qualities and were
trained with a range of architectures and regularization hyperparameters. We
identify what amounts to a Simpson&#x27;s paradox: where &quot;scale&quot; metrics (from
traditional statistical learning theory) perform well overall but perform
poorly on subpartitions of the data of a given depth, when regularization
hyperparameters are varied; and where &quot;shape&quot; metrics (from Heavy-Tailed Self
Regularization theory) perform well on subpartitions of the data, when
hyperparameters are varied for models of a given depth, but perform poorly
overall when models with varying depths are aggregated. Our results highlight
the subtly of comparing models when both architectures and hyperparameters are
varied, as well as the complementary role of implicit scale versus implicit
shape parameters in understanding NN model quality. Our results also suggest
caution when one tries to extract causal insight with a single metric applied
to aggregate data, and they highlight the need to go beyond one-size-fits-all
metrics based on upper bounds from generalization theory to describe the
performance of state-of-the-art NN models. Based on these findings, we present
two novel shape metrics, one data-independent, and the other data-dependent,
which can predict trends in the test accuracy of a series of NNs, of a fixed
architecture/depth, when varying solver hyperparameters.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Federated Learning with Fair Averaging. (arXiv:2104.14937v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_X/0/1/0/all/0/1">Xiaoliang Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1">Jianzhong Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wen_C/0/1/0/all/0/1">Chenglu Wen</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Cheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1">Rongshan Yu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.14937">
                                    <div class="article-summary-box-inner">
                                        <span>Fairness has emerged as a critical problem in federated learning (FL). In
this work, we identify a cause of unfairness in FL -- \emph{conflicting}
gradients with large differences in the magnitudes. To address this issue, we
propose the federated fair averaging (FedFV) algorithm to mitigate potential
conflicts among clients before averaging their gradients. We first use the
cosine similarity to detect gradient conflicts, and then iteratively eliminate
such conflicts by modifying both the direction and the magnitude of the
gradients. We further show the theoretical foundation of FedFV to mitigate the
issue conflicting gradients and converge to Pareto stationary solutions.
Extensive experiments on a suite of federated datasets confirm that FedFV
compares favorably against state-of-the-art methods in terms of fairness,
accuracy and efficiency.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Image-Audio Encoding to Improve C2 Decision-Making in Multi-Domain Environment. (arXiv:2106.00787v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Sharma_P/0/1/0/all/0/1">Piyush K. Sharma</a>, <a href="http://arxiv.org/find/cs/1/au:+Raglin_A/0/1/0/all/0/1">Adrienne Raglin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00787">
                                    <div class="article-summary-box-inner">
                                        <span>The military is investigating methods to improve communication and agility in
its multi-domain operations (MDO). Nascent popularity of Internet of Things
(IoT) has gained traction in public and government domains. Its usage in MDO
may revolutionize future battlefields and may enable strategic advantage. While
this technology offers leverage to military capabilities, it comes with
challenges where one is the uncertainty and associated risk. A key question is
how can these uncertainties be addressed. Recently published studies proposed
information camouflage to transform information from one data domain to
another. As this is comparatively a new approach, we investigate challenges of
such transformations and how these associated uncertainties can be detected and
addressed, specifically unknown-unknowns to improve decision-making.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Offline Reinforcement Learning with Pseudometric Learning. (arXiv:2103.01948v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dadashi_R/0/1/0/all/0/1">Robert Dadashi</a>, <a href="http://arxiv.org/find/cs/1/au:+Rezaeifar_S/0/1/0/all/0/1">Shideh Rezaeifar</a>, <a href="http://arxiv.org/find/cs/1/au:+Vieillard_N/0/1/0/all/0/1">Nino Vieillard</a>, <a href="http://arxiv.org/find/cs/1/au:+Hussenot_L/0/1/0/all/0/1">L&#xe9;onard Hussenot</a>, <a href="http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1">Olivier Pietquin</a>, <a href="http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1">Matthieu Geist</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.01948">
                                    <div class="article-summary-box-inner">
                                        <span>Offline Reinforcement Learning methods seek to learn a policy from logged
transitions of an environment, without any interaction. In the presence of
function approximation, and under the assumption of limited coverage of the
state-action space of the environment, it is necessary to enforce the policy to
visit state-action pairs close to the support of logged transitions. In this
work, we propose an iterative procedure to learn a pseudometric (closely
related to bisimulation metrics) from logged transitions, and use it to define
this notion of closeness. We show its convergence and extend it to the function
approximation setting. We then use this pseudometric to define a new lookup
based bonus in an actor-critic algorithm: PLOFF. This bonus encourages the
actor to stay close, in terms of the defined pseudometric, to the support of
logged transitions. Finally, we evaluate the method on hand manipulation and
locomotion tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Stochastic Optimization of Areas Under Precision-Recall Curves with Provable Convergence. (arXiv:2104.08736v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qi_Q/0/1/0/all/0/1">Qi Qi</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Youzhi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1">Zhao Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1">Tianbao Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08736">
                                    <div class="article-summary-box-inner">
                                        <span>Areas under ROC (AUROC) and precision-recall curves (AUPRC) are common
metrics for evaluating classification performance for imbalanced problems.
Compared with AUROC, AUPRC is a more appropriate metric for highly imbalanced
datasets. While stochastic optimization of AUROC has been studied extensively,
principled stochastic optimization of AUPRC has been rarely explored. In this
work, we propose a principled technical method to optimize AUPRC for deep
learning. Our approach is based on maximizing the averaged precision (AP),
which is an unbiased point estimator of AUPRC. We cast the objective into a sum
of {\it dependent compositional functions} with inner functions dependent on
random variables of the outer level. We propose efficient adaptive and
non-adaptive stochastic algorithms with {\it provable convergence guarantee
under mild conditions} by leveraging recent advances in stochastic
compositional optimization. Extensive experimental results on image and graph
datasets demonstrate that our proposed method outperforms prior methods on
imbalanced problems in terms of AUPRC. To the best of our knowledge, our work
represents the first attempt to optimize AUPRC with provable convergence.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">IPatch: A Remote Adversarial Patch. (arXiv:2105.00113v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mirsky_Y/0/1/0/all/0/1">Yisroel Mirsky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.00113">
                                    <div class="article-summary-box-inner">
                                        <span>Applications such as autonomous vehicles and medical screening use deep
learning models to localize and identify hundreds of objects in a single frame.
In the past, it has been shown how an attacker can fool these models by placing
an adversarial patch within a scene. However, these patches must be placed in
the target location and do not explicitly alter the semantics elsewhere in the
image.

In this paper, we introduce a new type of adversarial patch which alters a
model&#x27;s perception of an image&#x27;s semantics. These patches can be placed
anywhere within an image to change the classification or semantics of locations
far from the patch. We call this new class of adversarial examples &#x60;remote
adversarial patches&#x27; (RAP).

We implement our own RAP called IPatch and perform an in-depth analysis on
image segmentation RAP attacks using five state-of-the-art architectures with
eight different encoders on the CamVid street view dataset. Moreover, we
demonstrate that the attack can be extended to object recognition models with
preliminary results on the popular YOLOv3 model. We found that the patch can
change the classification of a remote target region with a success rate of up
to 93% on average.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MPASNET: Motion Prior-Aware Siamese Network for Unsupervised Deep Crowd Segmentation in Video Scenes. (arXiv:2101.08609v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1">Jinhai Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hua Yang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08609">
                                    <div class="article-summary-box-inner">
                                        <span>Crowd segmentation is a fundamental task serving as the basis of crowded
scene analysis, and it is highly desirable to obtain refined pixel-level
segmentation maps. However, it remains a challenging problem, as existing
approaches either require dense pixel-level annotations to train deep learning
models or merely produce rough segmentation maps from optical or particle flows
with physical models. In this paper, we propose the Motion Prior-Aware Siamese
Network (MPASNET) for unsupervised crowd semantic segmentation. This model not
only eliminates the need for annotation but also yields high-quality
segmentation maps. Specially, we first analyze the coherent motion patterns
across the frames and then apply a circular region merging strategy on the
collective particles to generate pseudo-labels. Moreover, we equip MPASNET with
siamese branches for augmentation-invariant regularization and siamese feature
aggregation. Experiments over benchmark datasets indicate that our model
outperforms the state-of-the-arts by more than 12% in terms of mIoU.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fidelity and Privacy of Synthetic Medical Data. (arXiv:2101.08658v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mendelevitch_O/0/1/0/all/0/1">Ofer Mendelevitch</a>, <a href="http://arxiv.org/find/cs/1/au:+Lesh_M/0/1/0/all/0/1">Michael D. Lesh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2101.08658">
                                    <div class="article-summary-box-inner">
                                        <span>The digitization of medical records ushered in a new era of big data to
clinical science, and with it the possibility that data could be shared, to
multiply insights beyond what investigators could abstract from paper records.
The need to share individual-level medical data to accelerate innovation in
precision medicine continues to grow, and has never been more urgent, as
scientists grapple with the COVID-19 pandemic. However, enthusiasm for the use
of big data has been tempered by a fully appropriate concern for patient
autonomy and privacy. That is, the ability to extract private or confidential
information about an individual, in practice, renders it difficult to share
data, since significant infrastructure and data governance must be established
before data can be shared. Although HIPAA provided de-identification as an
approved mechanism for data sharing, linkage attacks were identified as a major
vulnerability. A variety of mechanisms have been established to avoid leaking
private information, such as field suppression or abstraction, strictly
limiting the amount of information that can be shared, or employing
mathematical techniques such as differential privacy. Another approach, which
we focus on here, is creating synthetic data that mimics the underlying data.
For synthetic data to be a useful mechanism in support of medical innovation
and a proxy for real-world evidence, one must demonstrate two properties of the
synthetic dataset: (1) any analysis on the real data must be matched by
analysis of the synthetic data (statistical fidelity) and (2) the synthetic
data must preserve privacy, with minimal risk of re-identification (privacy
guarantee). In this paper we propose a framework for quantifying the
statistical fidelity and privacy preservation properties of synthetic datasets
and demonstrate these metrics for synthetic data generated by Syntegra
technology.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Using a Neural Network to Detect Anomalies given an N-gram Profile. (arXiv:2104.05571v2 [cs.CR] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1">Byunggu Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1">Junwhan Kim</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.05571">
                                    <div class="article-summary-box-inner">
                                        <span>In order to detect unknown intrusions and runtime errors of computer
programs, the cyber-security community has developed various detection
techniques. Anomaly detection is an approach that is designed to profile the
normal runtime behavior of computer programs in order to detect intrusions and
errors as anomalous deviations from the observed normal. However, normal but
unobserved behavior can trigger false positives. This limitation has
significantly decreased the practical viability of anomaly detection
techniques. Reported approaches to this limitation span a simple alert
threshold definition to distribution models for approximating all normal
behavior based on the limited observation. However, each assumption or
approximation poses the potential for even greater false positive rates. This
paper presents our study on how to explain the presence of anomalies using a
neural network, particularly Long Short-Term Memory, independent of actual data
distributions. We present and compare three anomaly detection models, and
report on our experience running different types of attacks on an Apache
Hypertext Transfer Protocol server. We performed a comparative study, focusing
on each model&#x27;s ability to detect the onset of each attack while avoiding false
positives resulting from unknown normal behavior. Our best-performing model
detected the true onset of every attack with zero false positives.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Efficient and Interpretable Robot Manipulation with Graph Neural Networks. (arXiv:2102.13177v2 [cs.RO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1">Yixin Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_A/0/1/0/all/0/1">Austin S. Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Rai_A/0/1/0/all/0/1">Akshara Rai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.13177">
                                    <div class="article-summary-box-inner">
                                        <span>Many manipulation tasks can be naturally cast as a sequence of spatial
relationships and constraints between objects. We aim to discover and scale
these task-specific spatial relationships by representing manipulation tasks as
operations over graphs. To do this, we pose manipulating a large, variable
number of objects as a probabilistic classification problem over actions,
objects and goals, learned using graph neural networks (GNNs). Our formulation
first transforms the environment into a graph representation, then applies a
trained GNN policy to predict which object to manipulate towards which goal
state. Our GNN policies are trained using very few expert demonstrations on
simple tasks, and exhibit generalization over number and configurations of
objects in the environment and even to new, more complex tasks, while providing
interpretable explanations for their decision-making. We present experiments
which show that a single learned GNN policy can solve a variety of long-horizon
blockstacking and rearrangement tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Closeness and Uncertainty Aware Adversarial Examples Detection in Adversarial Machine Learning. (arXiv:2012.06390v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tuna_O/0/1/0/all/0/1">Omer Faruk Tuna</a>, <a href="http://arxiv.org/find/cs/1/au:+Catak_F/0/1/0/all/0/1">Ferhat Ozgur Catak</a>, <a href="http://arxiv.org/find/cs/1/au:+Eskil_M/0/1/0/all/0/1">M. Taner Eskil</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.06390">
                                    <div class="article-summary-box-inner">
                                        <span>While state-of-the-art Deep Neural Network (DNN) models are considered to be
robust to random perturbations, it was shown that these architectures are
highly vulnerable to deliberately crafted perturbations, albeit being
quasi-imperceptible. These vulnerabilities make it challenging to deploy DNN
models in security-critical areas. In recent years, many research studies have
been conducted to develop new attack methods and come up with new defense
techniques that enable more robust and reliable models. In this work, we
explore and assess the usage of different type of metrics for detecting
adversarial samples. We first leverage the usage of moment-based predictive
uncertainty estimates of a DNN classifier obtained using Monte-Carlo Dropout
Sampling. And we also introduce a new method that operates in the subspace of
deep features extracted by the model. We verified the effectiveness of our
approach on a range of standard datasets like MNIST (Digit), MNIST (Fashion)
and CIFAR-10. Our experiments show that these two different approaches
complement each other, and the combined usage of all the proposed metrics
yields up to 99 \% ROC-AUC scores regardless of the attack algorithm.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Practical Lipreading with Distilled and Efficient Models. (arXiv:2007.06504v3 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_P/0/1/0/all/0/1">Pingchuan Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Martinez_B/0/1/0/all/0/1">Brais Martinez</a>, <a href="http://arxiv.org/find/cs/1/au:+Petridis_S/0/1/0/all/0/1">Stavros Petridis</a>, <a href="http://arxiv.org/find/cs/1/au:+Pantic_M/0/1/0/all/0/1">Maja Pantic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.06504">
                                    <div class="article-summary-box-inner">
                                        <span>Lipreading has witnessed a lot of progress due to the resurgence of neural
networks. Recent works have placed emphasis on aspects such as improving
performance by finding the optimal architecture or improving generalization.
However, there is still a significant gap between the current methodologies and
the requirements for an effective deployment of lipreading in practical
scenarios. In this work, we propose a series of innovations that significantly
bridge that gap: first, we raise the state-of-the-art performance by a wide
margin on LRW and LRW-1000 to 88.5% and 46.6%, respectively using
self-distillation. Secondly, we propose a series of architectural changes,
including a novel Depthwise Separable Temporal Convolutional Network (DS-TCN)
head, that slashes the computational cost to a fraction of the (already quite
efficient) original model. Thirdly, we show that knowledge distillation is a
very effective tool for recovering performance of the lightweight models. This
results in a range of models with different accuracy-efficiency trade-offs.
However, our most promising lightweight models are on par with the current
state-of-the-art while showing a reduction of 8.2x and 3.9x in terms of
computational cost and number of parameters, respectively, which we hope will
enable the deployment of lipreading models in practical applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evidence-based Factual Error Correction. (arXiv:2106.01072v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Thorne_J/0/1/0/all/0/1">James Thorne</a>, <a href="http://arxiv.org/find/cs/1/au:+Vlachos_A/0/1/0/all/0/1">Andreas Vlachos</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01072">
                                    <div class="article-summary-box-inner">
                                        <span>This paper introduces the task of factual error correction: performing edits
to a claim so that the generated rewrite is better supported by evidence. This
extends the well-studied task of fact verification by providing a mechanism to
correct written texts that are refuted or only partially supported by evidence.
We demonstrate that it is feasible to train factual error correction systems
from existing fact checking datasets which only contain labeled claims
accompanied by evidence, but not the correction. We achieve this by employing a
two-stage distant supervision approach that incorporates evidence into masked
claims when generating corrections. Our approach, based on the T5 transformer
and using retrieved evidence, achieved better results than existing work which
used a pointer copy network and gold evidence, producing accurate factual error
corrections for 5x more instances in human evaluation and a .125 increase in
SARI score. The evaluation is conducted on a dataset of 65,000 instances based
on a recent fact verification shared task and we release it to enable further
work on the task.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Active Surface Models. (arXiv:2011.08826v4 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wickramasinghe_U/0/1/0/all/0/1">Udaranga Wickramasinghe</a>, <a href="http://arxiv.org/find/cs/1/au:+Knott_G/0/1/0/all/0/1">Graham Knott</a>, <a href="http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1">Pascal Fua</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.08826">
                                    <div class="article-summary-box-inner">
                                        <span>Active Surface Models have a long history of being useful to model complex 3D
surfaces but only Active Contours have been used in conjunction with deep
networks, and then only to produce the data term as well as meta-parameter maps
controlling them. In this paper, we advocate a much tighter integration. We
introduce layers that implement them that can be integrated seamlessly into
Graph Convolutional Networks to enforce sophisticated smoothness priors at an
acceptable computational cost. We will show that the resulting Deep Active
Surface Models outperform equivalent architectures that use traditional
regularization loss terms to impose smoothness priors for 3D surface
reconstruction from 2D images and for 3D volume segmentation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Causal Discovery in Knowledge Graphs by Exploiting Asymmetric Properties of Non-Gaussian Distributions. (arXiv:2106.01043v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Giriraj_R/0/1/0/all/0/1">Rohan Giriraj</a>, <a href="http://arxiv.org/find/cs/1/au:+Thomas_S/0/1/0/all/0/1">Sinnu Susan Thomas</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01043">
                                    <div class="article-summary-box-inner">
                                        <span>In recent years, causal modelling has been used widely to improve
generalization and to provide interpretability in machine learning models. To
determine cause-effect relationships in the absence of a randomized trial, we
can model causal systems with counterfactuals and interventions given enough
domain knowledge. However, there are several cases where domain knowledge is
almost absent and the only recourse is using a statistical method to estimate
causal relationships. While there have been several works done in estimating
causal relationships in unstructured data, we are yet to find a well-defined
framework for estimating causal relationships in Knowledge Graphs (KG). It is
commonly used to provide a semantic framework for data with complex
inter-domain relationships. In this work, we define a hybrid approach that
allows us to discover cause-effect relationships in KG. The proposed approach
is based around the finding of the instantaneous causal structure of a
non-experimental matrix using a non-Gaussian model, i.e; finding the causal
ordering of the variables in a non-Gaussian setting. The non-experimental
matrix is a low-dimensional tensor projection obtained by decomposing the
adjacency tensor of a KG. We use two different pre-existing algorithms, one for
the causal discovery and the other for decomposing the KG and combining them to
get the causal structure in a KG.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Distance-preserving Matrix Sketch. (arXiv:2009.03979v2 [cs.HC] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wilkinson_L/0/1/0/all/0/1">Leland Wilkinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1">Hengrui Luo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.03979">
                                    <div class="article-summary-box-inner">
                                        <span>Visualizing very large matrices involves many formidable problems. Various
popular solutions to these problems involve sampling, clustering, projection,
or feature selection to reduce the size and complexity of the original task. An
important aspect of these methods is how to preserve relative distances between
points in the higher-dimensional space after reducing rows and columns to fit
in a lower dimensional space. This aspect is important because conclusions
based on faulty visual reasoning can be harmful. Judging dissimilar points as
similar or similar points as dissimilar on the basis of a visualization can
lead to false conclusions. To ameliorate this bias and to make visualizations
of very large datasets feasible, we introduce two new algorithms that
respectively select a subset of rows and columns of a rectangular matrix. This
selection is designed to preserve relative distances as closely as possible. We
compare our matrix sketch to more traditional alternatives on a variety of
artificial and real datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improvement over Pinball Loss Support Vector Machine. (arXiv:2106.01109v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Anand_P/0/1/0/all/0/1">Pritam Anand</a>, <a href="http://arxiv.org/find/cs/1/au:+Rastogi_R/0/1/0/all/0/1">Reshma Rastogi</a>, <a href="http://arxiv.org/find/cs/1/au:+Chandra_S/0/1/0/all/0/1">Suresh Chandra</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01109">
                                    <div class="article-summary-box-inner">
                                        <span>Recently, there have been several papers that discuss the extension of the
Pinball loss Support Vector Machine (Pin-SVM) model, originally proposed by
Huang et al.,[1][2]. Pin-SVM classifier deals with the pinball loss function,
which has been defined in terms of the parameter $\tau$. The parameter $\tau$
can take values in $[ -1,1]$. The existing Pin-SVM model requires to solve the
same optimization problem for all values of $\tau$ in $[ -1,1]$. In this paper,
we improve the existing Pin-SVM model for the binary classification task. At
first, we note that there is major difficulty in Pin-SVM model (Huang et al.
[1]) for $ -1 \leq \tau &lt; 0$. Specifically, we show that the Pin-SVM model
requires the solution of different optimization problem for $ -1 \leq \tau &lt;
0$. We further propose a unified model termed as Unified Pin-SVM which results
in a QPP valid for all $-1\leq \tau \leq 1$ and hence more convenient to use.
The proposed Unified Pin-SVM model can obtain a significant improvement in
accuracy over the existing Pin-SVM model which has also been empirically
justified by extensive numerical experiments with real-world datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">deep21: a Deep Learning Method for 21cm Foreground Removal. (arXiv:2010.15843v2 [astro-ph.CO] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/astro-ph/1/au:+Makinen_T/0/1/0/all/0/1">T. Lucas Makinen</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Lancaster_L/0/1/0/all/0/1">Lachlan Lancaster</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Villaescusa_Navarro_F/0/1/0/all/0/1">Francisco Villaescusa-Navarro</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Melchior_P/0/1/0/all/0/1">Peter Melchior</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Ho_S/0/1/0/all/0/1">Shirley Ho</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Perreault_Levasseur_L/0/1/0/all/0/1">Laurence Perreault-Levasseur</a>, <a href="http://arxiv.org/find/astro-ph/1/au:+Spergel_D/0/1/0/all/0/1">David N. Spergel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.15843">
                                    <div class="article-summary-box-inner">
                                        <span>We seek to remove foreground contaminants from 21cm intensity mapping
observations. We demonstrate that a deep convolutional neural network (CNN)
with a UNet architecture and three-dimensional convolutions, trained on
simulated observations, can effectively separate frequency and spatial patterns
of the cosmic neutral hydrogen (HI) signal from foregrounds in the presence of
noise. Cleaned maps recover cosmological clustering statistics within 10% at
all relevant angular scales and frequencies. This amounts to a reduction in
prediction variance of over an order of magnitude on small angular scales
($\ell &gt; 300$), and improved accuracy for small radial scales ($k_{\parallel} &gt;
0.17\ \rm h\ Mpc^{-1})$ compared to standard Principal Component Analysis (PCA)
methods. We estimate posterior confidence intervals for the network&#x27;s
prediction by training an ensemble of UNets. Our approach demonstrates the
feasibility of analyzing 21cm intensity maps, as opposed to derived summary
statistics, for upcoming radio experiments, as long as the simulated foreground
model is sufficiently realistic. We provide the code used for this analysis on
Github https://github.com/tlmakinen/deep21 as well as a browser-based tutorial
for the experiment and UNet model via the accompanying
this http URL Colab notebook.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated Gradients. (arXiv:2009.13145v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1">Yifei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1">Yaodong Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Hongyang Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1">Yi Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1">Yuan Yao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.13145">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we introduce a provably stable architecture for Neural Ordinary
Differential Equations (ODEs) which achieves non-trivial adversarial robustness
under white-box adversarial attacks even when the network is trained naturally.
For most existing defense methods withstanding strong white-box attacks, to
improve robustness of neural networks, they need to be trained adversarially,
hence have to strike a trade-off between natural accuracy and adversarial
robustness. Inspired by dynamical system theory, we design a stabilized neural
ODE network named SONet whose ODE blocks are skew-symmetric and proved to be
input-output stable. With natural training, SONet can achieve comparable
robustness with the state-of-the-art adversarial defense methods, without
sacrificing natural accuracy. Even replacing only the first layer of a ResNet
by such a ODE block can exhibit further improvement in robustness, e.g., under
PGD-20 ($\ell_\infty&#x3D;0.031$) attack on CIFAR-10 dataset, it achieves 91.57\%
and natural accuracy and 62.35\% robust accuracy, while a counterpart
architecture of ResNet trained with TRADES achieves natural and robust accuracy
76.29\% and 45.24\%, respectively. To understand possible reasons behind this
surprisingly good result, we further explore the possible mechanism underlying
such an adversarial robustness. We show that the adaptive stepsize numerical
ODE solver, DOPRI5, has a gradient masking effect that fails the PGD attacks
which are sensitive to gradient information of training loss; on the other
hand, it cannot fool the CW attack of robust gradients and the SPSA attack that
is gradient-free. This provides a new explanation that the adversarial
robustness of ODE-based networks mainly comes from the obfuscated gradients in
numerical ODE solvers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Finite-sample Analysis of Interpolating Linear Classifiers in the Overparameterized Regime. (arXiv:2004.12019v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1">Niladri S. Chatterji</a>, <a href="http://arxiv.org/find/stat/1/au:+Long_P/0/1/0/all/0/1">Philip M. Long</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2004.12019">
                                    <div class="article-summary-box-inner">
                                        <span>We prove bounds on the population risk of the maximum margin algorithm for
two-class linear classification. For linearly separable training data, the
maximum margin algorithm has been shown in previous work to be equivalent to a
limit of training with logistic loss using gradient descent, as the training
error is driven to zero. We analyze this algorithm applied to random data
including misclassification noise. Our assumptions on the clean data include
the case in which the class-conditional distributions are standard normal
distributions. The misclassification noise may be chosen by an adversary,
subject to a limit on the fraction of corrupted labels. Our bounds show that,
with sufficient over-parameterization, the maximum margin algorithm trained on
noisy data can achieve nearly optimal population risk.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Expected Scalarised Returns Dominance: A New Solution Concept for Multi-Objective Decision Making. (arXiv:2106.01048v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hayes_C/0/1/0/all/0/1">Conor F. Hayes</a>, <a href="http://arxiv.org/find/cs/1/au:+Verstraeten_T/0/1/0/all/0/1">Timothy Verstraeten</a>, <a href="http://arxiv.org/find/cs/1/au:+Roijers_D/0/1/0/all/0/1">Diederik M. Roijers</a>, <a href="http://arxiv.org/find/cs/1/au:+Howley_E/0/1/0/all/0/1">Enda Howley</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannion_P/0/1/0/all/0/1">Patrick Mannion</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01048">
                                    <div class="article-summary-box-inner">
                                        <span>In many real-world scenarios, the utility of a user is derived from the
single execution of a policy. In this case, to apply multi-objective
reinforcement learning, the expected utility of the returns must be optimised.
Various scenarios exist where a user&#x27;s preferences over objectives (also known
as the utility function) are unknown or difficult to specify. In such
scenarios, a set of optimal policies must be learned. However, settings where
the expected utility must be maximised have been largely overlooked by the
multi-objective reinforcement learning community and, as a consequence, a set
of optimal solutions has yet to be defined. In this paper we address this
challenge by proposing first-order stochastic dominance as a criterion to build
solution sets to maximise expected utility. We also propose a new dominance
criterion, known as expected scalarised returns (ESR) dominance, that extends
first-order stochastic dominance to allow a set of optimal policies to be
learned in practice. We then define a new solution concept called the ESR set,
which is a set of policies that are ESR dominant. Finally, we define a new
multi-objective distributional tabular reinforcement learning (MOT-DRL)
algorithm to learn the ESR set in a multi-objective multi-armed bandit setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Coreset Selection for Rehearsal-based Continual Learning. (arXiv:2106.01085v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1">Jaehong Yoon</a>, <a href="http://arxiv.org/find/cs/1/au:+Madaan_D/0/1/0/all/0/1">Divyam Madaan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_E/0/1/0/all/0/1">Eunho Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hwang_S/0/1/0/all/0/1">Sung Ju Hwang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01085">
                                    <div class="article-summary-box-inner">
                                        <span>A dataset is a shred of crucial evidence to describe a task. However, each
data point in the dataset does not have the same potential, as some of the data
points can be more representative or informative than others. This unequal
importance among the data points may have a large impact in rehearsal-based
continual learning, where we store a subset of the training examples (coreset)
to be replayed later to alleviate catastrophic forgetting. In continual
learning, the quality of the samples stored in the coreset directly affects the
model&#x27;s effectiveness and efficiency. The coreset selection problem becomes
even more important under realistic settings, such as imbalanced continual
learning or noisy data scenarios. To tackle this problem, we propose Online
Coreset Selection (OCS), a simple yet effective method that selects the most
representative and informative coreset at each iteration and trains them in an
online manner. Our proposed method maximizes the model&#x27;s adaptation to a target
dataset while selecting high-affinity samples to past tasks, which directly
inhibits catastrophic forgetting. We validate the effectiveness of our coreset
selection mechanism over various standard, imbalanced, and noisy datasets
against strong continual learning baselines, demonstrating that it improves
task adaptation and prevents catastrophic forgetting in a sample-efficient
manner.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FIVES: Feature Interaction Via Edge Search for Large-Scale Tabular Data. (arXiv:2007.14573v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1">Yuexiang Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1">Zhen Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1">Yaliang Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1">Bolin Ding</a>, <a href="http://arxiv.org/find/cs/1/au:+Gurel_N/0/1/0/all/0/1">Nezihe Merve G&#xfc;rel</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Ce Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1">Minlie Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1">Wei Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.14573">
                                    <div class="article-summary-box-inner">
                                        <span>High-order interactive features capture the correlation between different
columns and thus are promising to enhance various learning tasks on ubiquitous
tabular data. To automate the generation of interactive features, existing
works either explicitly traverse the feature space or implicitly express the
interactions via intermediate activations of some designed models. These two
kinds of methods show that there is essentially a trade-off between feature
interpretability and search efficiency. To possess both of their merits, we
propose a novel method named Feature Interaction Via Edge Search (FIVES), which
formulates the task of interactive feature generation as searching for edges on
the defined feature graph. Specifically, we first present our theoretical
evidence that motivates us to search for useful interactive features with
increasing order. Then we instantiate this search strategy by optimizing both a
dedicated graph neural network (GNN) and the adjacency tensor associated with
the defined feature graph. In this way, the proposed FIVES method simplifies
the time-consuming traversal as a typical training course of GNN and enables
explicit feature generation according to the learned adjacency tensor.
Experimental results on both benchmark and real-world datasets show the
advantages of FIVES over several state-of-the-art methods. Moreover, the
interactive features identified by FIVES are deployed on the recommender system
of Taobao, a worldwide leading e-commerce platform. Results of an online A/B
testing further verify the effectiveness of the proposed method FIVES, and we
further provide FIVES as AI utilities for the customers of Alibaba Cloud.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Generating SOAP Notes from Doctor-Patient Conversations Using Modular Summarization Techniques. (arXiv:2005.01795v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krishna_K/0/1/0/all/0/1">Kundan Krishna</a>, <a href="http://arxiv.org/find/cs/1/au:+Khosla_S/0/1/0/all/0/1">Sopan Khosla</a>, <a href="http://arxiv.org/find/cs/1/au:+Bigham_J/0/1/0/all/0/1">Jeffrey P. Bigham</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.01795">
                                    <div class="article-summary-box-inner">
                                        <span>Following each patient visit, physicians draft long semi-structured clinical
summaries called SOAP notes. While invaluable to clinicians and researchers,
creating digital SOAP notes is burdensome, contributing to physician burnout.
In this paper, we introduce the first complete pipelines to leverage deep
summarization models to generate these notes based on transcripts of
conversations between physicians and patients. After exploring a spectrum of
methods across the extractive-abstractive spectrum, we propose Cluster2Sent, an
algorithm that (i) extracts important utterances relevant to each summary
section; (ii) clusters together related utterances; and then (iii) generates
one summary sentence per cluster. Cluster2Sent outperforms its purely
abstractive counterpart by 8 ROUGE-1 points, and produces significantly more
factual and coherent sentences as assessed by expert human evaluators. For
reproducibility, we demonstrate similar benefits on the publicly available AMI
dataset. Our results speak to the benefits of structuring summaries into
sections and annotating supporting evidence when constructing summarization
corpora.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evaluation Metrics for Graph Generative Models: Problems, Pitfalls, and Practical Solutions. (arXiv:2106.01098v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+OBray_L/0/1/0/all/0/1">Leslie O&#x27;Bray</a>, <a href="http://arxiv.org/find/cs/1/au:+Horn_M/0/1/0/all/0/1">Max Horn</a>, <a href="http://arxiv.org/find/cs/1/au:+Rieck_B/0/1/0/all/0/1">Bastian Rieck</a>, <a href="http://arxiv.org/find/cs/1/au:+Borgwardt_K/0/1/0/all/0/1">Karsten Borgwardt</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01098">
                                    <div class="article-summary-box-inner">
                                        <span>Graph generative models are a highly active branch of machine learning. Given
the steady development of new models of ever-increasing complexity, it is
necessary to provide a principled way to evaluate and compare them. In this
paper, we enumerate the desirable criteria for comparison metrics, discuss the
development of such metrics, and provide a comparison of their respective
expressive power. We perform a systematic evaluation of the main metrics in use
today, highlighting some of the challenges and pitfalls researchers
inadvertently can run into. We then describe a collection of suitable metrics,
give recommendations as to their practical suitability, and analyse their
behaviour on synthetically generated perturbed graphs as well as on recently
proposed graph generative models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Testing Group Fairness via Optimal Transport Projections. (arXiv:2106.01070v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Si_N/0/1/0/all/0/1">Nian Si</a>, <a href="http://arxiv.org/find/stat/1/au:+Murthy_K/0/1/0/all/0/1">Karthyek Murthy</a>, <a href="http://arxiv.org/find/stat/1/au:+Blanchet_J/0/1/0/all/0/1">Jose Blanchet</a>, <a href="http://arxiv.org/find/stat/1/au:+Nguyen_V/0/1/0/all/0/1">Viet Anh Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01070">
                                    <div class="article-summary-box-inner">
                                        <span>We present a statistical testing framework to detect if a given machine
learning classifier fails to satisfy a wide range of group fairness notions.
The proposed test is a flexible, interpretable, and statistically rigorous tool
for auditing whether exhibited biases are intrinsic to the algorithm or due to
the randomness in the data. The statistical challenges, which may arise from
multiple impact criteria that define group fairness and which are discontinuous
on model parameters, are conveniently tackled by projecting the empirical
measure onto the set of group-fair probability models using optimal transport.
This statistic is efficiently computed using linear programming and its
asymptotic distribution is explicitly obtained. The proposed framework can also
be used to test for testing composite fairness hypotheses and fairness with
multiple sensitive attributes. The optimal transport testing formulation
improves interpretability by characterizing the minimal covariate perturbations
that eliminate the bias observed in the audit.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Needle in a Haystack: Label-Efficient Evaluation under Extreme Class Imbalance. (arXiv:2006.06963v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Marchant_N/0/1/0/all/0/1">Neil G. Marchant</a>, <a href="http://arxiv.org/find/cs/1/au:+Rubinstein_B/0/1/0/all/0/1">Benjamin I. P. Rubinstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.06963">
                                    <div class="article-summary-box-inner">
                                        <span>Important tasks like record linkage and extreme classification demonstrate
extreme class imbalance, with 1 minority instance to every 1 million or more
majority instances. Obtaining a sufficient sample of all classes, even just to
achieve statistically-significant evaluation, is so challenging that most
current approaches yield poor estimates or incur impractical cost. Where
importance sampling has been levied against this challenge, restrictive
constraints are placed on performance metrics, estimates do not come with
appropriate guarantees, or evaluations cannot adapt to incoming labels. This
paper develops a framework for online evaluation based on adaptive importance
sampling. Given a target performance metric and model for $p(y|x)$, the
framework adapts a distribution over items to label in order to maximize
statistical precision. We establish strong consistency and a central limit
theorem for the resulting performance estimates, and instantiate our framework
with worked examples that leverage Dirichlet-tree models. Experiments
demonstrate an average MSE superior to state-of-the-art on fixed label budgets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Style is NOT a single variable: Case Studies for Cross-Style Language Understanding. (arXiv:1911.03663v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kang_D/0/1/0/all/0/1">Dongyeop Kang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1">Eduard Hovy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1911.03663">
                                    <div class="article-summary-box-inner">
                                        <span>Every natural text is written in some style. Style is formed by a complex
combination of different stylistic factors, including formality markers,
emotions, metaphors, etc. One cannot form a complete understanding of a text
without considering these factors. The factors combine and co-vary in complex
ways to form styles. Studying the nature of the co-varying combinations sheds
light on stylistic language in general, sometimes called cross-style language
understanding. This paper provides the benchmark corpus (xSLUE) that combines
existing datasets and collects a new one for sentence-level cross-style
language understanding and evaluation. The benchmark contains text in 15
different styles under the proposed four theoretical groupings: figurative,
personal, affective, and interpersonal groups. For valid evaluation, we collect
an additional diagnostic set by annotating all 15 styles on the same text.
Using xSLUE, we propose three interesting cross-style applications in
classification, correlation, and generation. First, our proposed cross-style
classifier trained with multiple styles together helps improve overall
classification performance against individually-trained style classifiers.
Second, our study shows that some styles are highly dependent on each other in
human-written text. Finally, we find that combinations of some contradictive
styles likely generate stylistically less appropriate text. We believe our
benchmark and case studies help explore interesting future directions for
cross-style research. The preprocessed datasets and code are publicly
available.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning to Rehearse in Long Sequence Memorization. (arXiv:2106.01096v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1">Zhu Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1">Chang Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jianxin Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1">Zhijie Lin</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1">Jingren Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1">Hongxia Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1">Zhou Zhao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01096">
                                    <div class="article-summary-box-inner">
                                        <span>Existing reasoning tasks often have an important assumption that the input
contents can be always accessed while reasoning, requiring unlimited storage
resources and suffering from severe time delay on long sequences. To achieve
efficient reasoning on long sequences with limited storage resources, memory
augmented neural networks introduce a human-like write-read memory to compress
and memorize the long input sequence in one pass, trying to answer subsequent
queries only based on the memory. But they have two serious drawbacks: 1) they
continually update the memory from current information and inevitably forget
the early contents; 2) they do not distinguish what information is important
and treat all contents equally. In this paper, we propose the Rehearsal Memory
(RM) to enhance long-sequence memorization by self-supervised rehearsal with a
history sampler. To alleviate the gradual forgetting of early information, we
design self-supervised rehearsal training with recollection and familiarity
tasks. Further, we design a history sampler to select informative fragments for
rehearsal training, making the memory focus on the crucial information. We
evaluate the performance of our rehearsal memory by the synthetic bAbI task and
several downstream tasks, including text/video question answering and
recommendation on long sequences.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Statistical optimality conditions for compressive ensembles. (arXiv:2106.01092v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Reeve_H/0/1/0/all/0/1">Henry W. J. Reeve</a>, <a href="http://arxiv.org/find/cs/1/au:+Kaban_A/0/1/0/all/0/1">Ata Kaban</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01092">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework for the theoretical analysis of ensembles of
low-complexity empirical risk minimisers trained on independent random
compressions of high-dimensional data. First we introduce a general
distribution-dependent upper-bound on the excess risk, framed in terms of a
natural notion of compressibility. This bound is independent of the dimension
of the original data representation, and explains the in-built regularisation
effect of the compressive approach. We then instantiate this general bound to
classification and regression tasks, considering Johnson-Lindenstrauss mappings
as the compression scheme. For each of these tasks, our strategy is to develop
a tight upper bound on the compressibility function, and by doing so we
discover distributional conditions of geometric nature under which the
compressive algorithm attains minimax-optimal rates up to at most
poly-logarithmic factors. In the case of compressive classification, this is
achieved with a mild geometric margin condition along with a flexible moment
condition that is significantly more general than the assumption of bounded
domain. In the case of regression with strongly convex smooth loss functions we
find that compressive regression is capable of exploiting spectral decay with
near-optimal guarantees. In addition, a key ingredient for our central upper
bound is a high probability uniform upper bound on the integrated deviation of
dependent empirical processes, which may be of independent interest.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Counterfactual Explanation with Multi-Agent Reinforcement Learning for Drug Target Prediction. (arXiv:2103.12983v2 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Tri Minh Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Quinn_T/0/1/0/all/0/1">Thomas P Quinn</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1">Thin Nguyen</a>, <a href="http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1">Truyen Tran</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.12983">
                                    <div class="article-summary-box-inner">
                                        <span>Motivation: Many high-performance DTA models have been proposed, but they are
mostly black-box and thus lack human interpretability. Explainable AI (XAI) can
make DTA models more trustworthy, and can also enable scientists to distill
biological knowledge from the models. Counterfactual explanation is one popular
approach to explaining the behaviour of a deep neural network, which works by
systematically answering the question &quot;How would the model output change if the
inputs were changed in this way?&quot;. Most counterfactual explanation methods only
operate on single input data. It remains an open problem how to extend
counterfactual-based XAI methods to DTA models, which have two inputs, one for
drug and one for target, that also happen to be discrete in nature.

Methods: We propose a multi-agent reinforcement learning framework,
Multi-Agent Counterfactual Drug target binding Affinity (MACDA), to generate
counterfactual explanations for the drug-protein complex. Our proposed
framework provides human-interpretable counterfactual instances while
optimizing both the input drug and target for counterfactual generation at the
same time.

Results: We benchmark the proposed MACDA framework using the Davis dataset
and find that our framework produces more parsimonious explanations with no
loss in explanation validity, as measured by encoding similarity and QED. We
then present a case study involving ABL1 and Nilotinib to demonstrate how MACDA
can explain the behaviour of a DTA model in the underlying substructure
interaction between inputs in its prediction, revealing mechanisms that align
with prior domain knowledge.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">More Embeddings, Better Sequence Labelers?. (arXiv:2009.08330v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bach_N/0/1/0/all/0/1">Nguyen Bach</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhongqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.08330">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work proposes a family of contextual embeddings that significantly
improves the accuracy of sequence labelers over non-contextual embeddings.
However, there is no definite conclusion on whether we can build better
sequence labelers by combining different kinds of embeddings in various
settings. In this paper, we conduct extensive experiments on 3 tasks over 18
datasets and 8 languages to study the accuracy of sequence labeling with
various embedding concatenations and make three observations: (1) concatenating
more embedding variants leads to better accuracy in rich-resource and
cross-domain settings and some conditions of low-resource settings; (2)
concatenating additional contextual sub-word embeddings with contextual
character embeddings hurts the accuracy in extremely low-resource settings; (3)
based on the conclusion of (1), concatenating additional similar contextual
embeddings cannot lead to further improvements. We hope these conclusions can
help people build stronger sequence labelers in various settings.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Frequency Estimation in Data Streams: Learning the Optimal Hashing Scheme. (arXiv:2007.09261v2 [cs.DS] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1">Dimitris Bertsimas</a>, <a href="http://arxiv.org/find/cs/1/au:+Digalakis_V/0/1/0/all/0/1">Vassilis Digalakis Jr</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2007.09261">
                                    <div class="article-summary-box-inner">
                                        <span>We present a novel approach for the problem of frequency estimation in data
streams that is based on optimization and machine learning. Contrary to
state-of-the-art streaming frequency estimation algorithms, which heavily rely
on random hashing to maintain the frequency distribution of the data steam
using limited storage, the proposed approach exploits an observed stream prefix
to near-optimally hash elements and compress the target frequency distribution.
We develop an exact mixed-integer linear optimization formulation, which
enables us to compute optimal or near-optimal hashing schemes for elements seen
in the observed stream prefix; then, we use machine learning to hash unseen
elements. Further, we develop an efficient block coordinate descent algorithm,
which, as we empirically show, produces high quality solutions, and, in a
special case, we are able to solve the proposed formulation exactly in linear
time using dynamic programming. We empirically evaluate the proposed approach
both on synthetic datasets and on real-world search query data. We show that
the proposed approach outperforms existing approaches by one to two orders of
magnitude in terms of its average (per element) estimation error and by 45-90%
in terms of its expected magnitude of estimation error.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Why is Attention Not So Interpretable?. (arXiv:2006.05656v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bai_B/0/1/0/all/0/1">Bing Bai</a>, <a href="http://arxiv.org/find/stat/1/au:+Liang_J/0/1/0/all/0/1">Jian Liang</a>, <a href="http://arxiv.org/find/stat/1/au:+Zhang_G/0/1/0/all/0/1">Guanhua Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1">Hao Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Bai_K/0/1/0/all/0/1">Kun Bai</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_F/0/1/0/all/0/1">Fei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.05656">
                                    <div class="article-summary-box-inner">
                                        <span>Attention-based methods have played important roles in model interpretations,
where the calculated attention weights are expected to highlight the critical
parts of inputs~(e.g., keywords in sentences). However, recent research found
that attention-as-importance interpretations often do not work as we expected.
For example, learned attention weights sometimes highlight less meaningful
tokens like &quot;[SEP]&quot;, &quot;,&quot;, and &quot;.&quot;, and are frequently uncorrelated with other
feature importance indicators like gradient-based measures. A recent debate
over whether attention is an explanation or not has drawn considerable
interest. In this paper, we demonstrate that one root cause of this phenomenon
is the combinatorial shortcuts, which means that, in addition to the
highlighted parts, the attention weights themselves may carry extra information
that could be utilized by downstream models after attention layers. As a
result, the attention weights are no longer pure importance indicators. We
theoretically analyze combinatorial shortcuts, design one intuitive experiment
to show their existence, and propose two methods to mitigate this issue. We
conduct empirical studies on attention-based interpretation models. The results
show that the proposed methods can effectively improve the interpretability of
attention mechanisms.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Detecting Rewards Deterioration in Episodic Reinforcement Learning. (arXiv:2010.11660v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Greenberg_I/0/1/0/all/0/1">Ido Greenberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1">Shie Mannor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.11660">
                                    <div class="article-summary-box-inner">
                                        <span>In many RL applications, once training ends, it is vital to detect any
deterioration in the agent performance as soon as possible. Furthermore, it
often has to be done without modifying the policy and under minimal assumptions
regarding the environment. In this paper, we address this problem by focusing
directly on the rewards and testing for degradation. We consider an episodic
framework, where the rewards within each episode are not independent, nor
identically-distributed, nor Markov. We present this problem as a multivariate
mean-shift detection problem with possibly partial observations. We define the
mean-shift in a way corresponding to deterioration of a temporal signal (such
as the rewards), and derive a test for this problem with optimal statistical
power. Empirically, on deteriorated rewards in control problems (generated
using various environment modifications), the test is demonstrated to be more
powerful than standard tests - often by orders of magnitude. We also suggest a
novel Bootstrap mechanism for False Alarm Rate control (BFAR), applicable to
episodic (non-i.i.d) signal and allowing our test to run sequentially in an
online manner. Our method does not rely on a learned model of the environment,
is entirely external to the agent, and in fact can be applied to detect changes
or drifts in any episodic signal.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unbiased Gradient Estimation for Variational Auto-Encoders using Coupled Markov Chains. (arXiv:2010.01845v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ruiz_F/0/1/0/all/0/1">Francisco J. R. Ruiz</a>, <a href="http://arxiv.org/find/cs/1/au:+Titsias_M/0/1/0/all/0/1">Michalis K. Titsias</a>, <a href="http://arxiv.org/find/cs/1/au:+Cemgil_T/0/1/0/all/0/1">Taylan Cemgil</a>, <a href="http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.01845">
                                    <div class="article-summary-box-inner">
                                        <span>The variational auto-encoder (VAE) is a deep latent variable model that has
two neural networks in an autoencoder-like architecture; one of them
parameterizes the model&#x27;s likelihood. Fitting its parameters via maximum
likelihood (ML) is challenging since the computation of the marginal likelihood
involves an intractable integral over the latent space; thus the VAE is trained
instead by maximizing a variational lower bound. Here, we develop a ML training
scheme for VAEs by introducing unbiased estimators of the log-likelihood
gradient. We obtain the estimators by augmenting the latent space with a set of
importance samples, similarly to the importance weighted auto-encoder (IWAE),
and then constructing a Markov chain Monte Carlo coupling procedure on this
augmented space. We provide the conditions under which the estimators can be
computed in finite time and with finite variance. We show experimentally that
VAEs fitted with unbiased estimators exhibit better predictive performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enriching Transformers with Structured Tensor-Product Representations for Abstractive Summarization. (arXiv:2106.01317v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yichen Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1">Asli Celikyilmaz</a>, <a href="http://arxiv.org/find/cs/1/au:+Smolensky_P/0/1/0/all/0/1">Paul Smolensky</a>, <a href="http://arxiv.org/find/cs/1/au:+Soulos_P/0/1/0/all/0/1">Paul Soulos</a>, <a href="http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1">Sudha Rao</a>, <a href="http://arxiv.org/find/cs/1/au:+Palangi_H/0/1/0/all/0/1">Hamid Palangi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fernandez_R/0/1/0/all/0/1">Roland Fernandez</a>, <a href="http://arxiv.org/find/cs/1/au:+Smith_C/0/1/0/all/0/1">Caitlin Smith</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>, <a href="http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1">Jianfeng Gao</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01317">
                                    <div class="article-summary-box-inner">
                                        <span>Abstractive summarization, the task of generating a concise summary of input
documents, requires: (1) reasoning over the source document to determine the
salient pieces of information scattered across the long document, and (2)
composing a cohesive text by reconstructing these salient facts into a shorter
summary that faithfully reflects the complex relations connecting these facts.
In this paper, we adapt TP-TRANSFORMER (Schlag et al., 2019), an architecture
that enriches the original Transformer (Vaswani et al., 2017) with the
explicitly compositional Tensor Product Representation (TPR), for the task of
abstractive summarization. The key feature of our model is a structural bias
that we introduce by encoding two separate representations for each token to
represent the syntactic structure (with role vectors) and semantic content
(with filler vectors) separately. The model then binds the role and filler
vectors into the TPR as the layer output. We argue that the structured
intermediate representations enable the model to take better control of the
contents (salient facts) and structures (the syntax that connects the facts)
when generating the summary. Empirically, we show that our TP-TRANSFORMER
outperforms the Transformer and the original TP-TRANSFORMER significantly on
several abstractive summarization datasets based on both automatic and human
evaluations. On several syntactic and semantic probing tasks, we demonstrate
the emergent structural information in the role vectors and improved syntactic
interpretability in the TPR layer outputs. Code and models are available at
https://github.com/jiangycTarheel/TPT-Summ.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Topological Feature Vectors for Chatter Detection in Turning Processes. (arXiv:1905.08671v3 [eess.SP] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Yesilli_M/0/1/0/all/0/1">Melih C. Yesilli</a>, <a href="http://arxiv.org/find/eess/1/au:+Khasawneh_F/0/1/0/all/0/1">Firas A. Khasawneh</a>, <a href="http://arxiv.org/find/eess/1/au:+Otto_A/0/1/0/all/0/1">Andreas Otto</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1905.08671">
                                    <div class="article-summary-box-inner">
                                        <span>Machining processes are most accurately described using complex dynamical
systems that include nonlinearities, time delays, and stochastic effects. Due
to the nature of these models as well as the practical challenges which include
time-varying parameters, the transition from numerical/analytical modeling of
machining to the analysis of real cutting signals remains challenging. Some
studies have focused on studying the time series of cutting processes using
machine learning algorithms with the goal of identifying and predicting
undesirable vibrations during machining referred to as chatter. These tools
typically decompose the signal using Wavelet Packet Transforms (WPT) or
Ensemble Empirical Mode Decomposition (EEMD). However, these methods require a
significant overhead in identifying the feature vectors before a classifier can
be trained. In this study, we present an alternative approach based on
featurizing the time series of the cutting process using its topological
features. We first embed the time series as a point cloud using Takens
embedding. We then utilize Support Vector Machine, Logistic Regression, Random
Forest and Gradient Boosting classifier combined with feature vectors derived
from persistence diagrams, a tool from persistent homology, to encode chatter&#x27;s
distinguishing characteristics. We present the results for several choices of
the topological feature vectors, and we compare our results to the WPT and EEMD
methods using experimental turning data. Our results show that in two out of
four cutting configurations the TDA-based features yield accuracies as high as
97%. We also show that combining Bezier curve approximation method and parallel
computing can reduce runtime for persistence diagram computation of a single
time series to less than a second thus making our approach suitable for online
chatter detection.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Depth Separations in Neural Networks: What is Actually Being Separated?. (arXiv:1904.06984v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Safran_I/0/1/0/all/0/1">Itay Safran</a>, <a href="http://arxiv.org/find/cs/1/au:+Eldan_R/0/1/0/all/0/1">Ronen Eldan</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1">Ohad Shamir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1904.06984">
                                    <div class="article-summary-box-inner">
                                        <span>Existing depth separation results for constant-depth networks essentially
show that certain radial functions in $\mathbb{R}^d$, which can be easily
approximated with depth $3$ networks, cannot be approximated by depth $2$
networks, even up to constant accuracy, unless their size is exponential in
$d$. However, the functions used to demonstrate this are rapidly oscillating,
with a Lipschitz parameter scaling polynomially with the dimension $d$ (or
equivalently, by scaling the function, the hardness result applies to
$\mathcal{O}(1)$-Lipschitz functions only when the target accuracy $\epsilon$
is at most $\text{poly}(1/d)$). In this paper, we study whether such depth
separations might still hold in the natural setting of
$\mathcal{O}(1)$-Lipschitz radial functions, when $\epsilon$ does not scale
with $d$. Perhaps surprisingly, we show that the answer is negative: In
contrast to the intuition suggested by previous work, it \emph{is} possible to
approximate $\mathcal{O}(1)$-Lipschitz radial functions with depth $2$, size
$\text{poly}(d)$ networks, for every constant $\epsilon$. We complement it by
showing that approximating such functions is also possible with depth $2$, size
$\text{poly}(1/\epsilon)$ networks, for every constant $d$. Finally, we show
that it is not possible to have polynomial dependence in both $d,1/\epsilon$
simultaneously. Overall, our results indicate that in order to show depth
separations for expressing $\mathcal{O}(1)$-Lipschitz functions with constant
accuracy -- if at all possible -- one would need fundamentally different
techniques than existing ones in the literature.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">NeRP: Neural Rearrangement Planning for Unknown Objects. (arXiv:2106.01352v1 [cs.RO])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Qureshi_A/0/1/0/all/0/1">Ahmed H. Qureshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Mousavian_A/0/1/0/all/0/1">Arsalan Mousavian</a>, <a href="http://arxiv.org/find/cs/1/au:+Paxton_C/0/1/0/all/0/1">Chris Paxton</a>, <a href="http://arxiv.org/find/cs/1/au:+Yip_M/0/1/0/all/0/1">Michael C. Yip</a>, <a href="http://arxiv.org/find/cs/1/au:+Fox_D/0/1/0/all/0/1">Dieter Fox</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01352">
                                    <div class="article-summary-box-inner">
                                        <span>Robots will be expected to manipulate a wide variety of objects in complex
and arbitrary ways as they become more widely used in human environments. As
such, the rearrangement of objects has been noted to be an important benchmark
for AI capabilities in recent years. We propose NeRP (Neural Rearrangement
Planning), a deep learning based approach for multi-step neural object
rearrangement planning which works with never-before-seen objects, that is
trained on simulation data, and generalizes to the real world. We compare NeRP
to several naive and model-based baselines, demonstrating that our approach is
measurably better and can efficiently arrange unseen objects in fewer steps and
with less planning time. Finally, we demonstrate it on several challenging
rearrangement problems in the real world.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair Principal Component Analysis and Filter Design. (arXiv:2002.06557v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zalcberg_G/0/1/0/all/0/1">Gad Zalcberg</a>, <a href="http://arxiv.org/find/cs/1/au:+Wiesel_A/0/1/0/all/0/1">Ami Wiesel</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.06557">
                                    <div class="article-summary-box-inner">
                                        <span>We consider Fair Principal Component Analysis (FPCA) and search for a low
dimensional subspace that spans multiple target vectors in a fair manner. FPCA
is defined as a non-concave maximization of the worst projected target norm
within a given set. The problem arises in filter design in signal processing,
and when incorporating fairness into dimensionality reduction schemes. The
state of the art approach to FPCA is via semidefinite relaxation and involves a
polynomial yet computationally expensive optimization. To allow scalability, we
propose to address FPCA using naive sub-gradient descent. We analyze the
landscape of the underlying optimization in the case of orthogonal targets. We
prove that the landscape is benign and that all local minima are globally
optimal. Interestingly, the SDR approach leads to sub-optimal solutions in this
simple case. Finally, we discuss the equivalence between orthogonal FPCA and
the design of normalized tight frames.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Interpretable Biomanufacturing Process Risk and Sensitivity Analyses for Quality-by-Design and Stability Control. (arXiv:1909.04261v4 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Xie_W/0/1/0/all/0/1">Wei Xie</a>, <a href="http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1">Bo Wang</a>, <a href="http://arxiv.org/find/stat/1/au:+Li_C/0/1/0/all/0/1">Cheng Li</a>, <a href="http://arxiv.org/find/stat/1/au:+Xie_D/0/1/0/all/0/1">Dongming Xie</a>, <a href="http://arxiv.org/find/stat/1/au:+Auclair_J/0/1/0/all/0/1">Jared Auclair</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1909.04261">
                                    <div class="article-summary-box-inner">
                                        <span>While biomanufacturing plays a significant role in supporting the economy and
ensuring public health, it faces critical challenges, including complexity,
high variability, lengthy lead time, and very limited process data, especially
for personalized new cell and gene biotherapeutics. Driven by these challenges,
we propose an interpretable semantic bioprocess probabilistic knowledge graph
and develop a game theory based risk and sensitivity analyses for production
process to facilitate quality-by-design and stability control. Specifically, by
exploring the causal relationships and interactions of critical process
parameters and quality attributes (CPPs/CQAs), we create a Bayesian network
based probabilistic knowledge graph characterizing the complex causal
interdependencies of all factors. Then, we introduce a Shapley value based
sensitivity analysis, which can correctly quantify the variation contribution
from each input factor on the outputs (i.e., productivity, product quality).
Since the bioprocess model coefficients are learned from limited process
observations, we derive the Bayesian posterior distribution to quantify model
uncertainty and further develop the Shapley value based sensitivity analysis to
evaluate the impact of estimation uncertainty from each set of model
coefficients. Therefore, the proposed bioprocess risk and sensitivity analyses
can identify the bottlenecks, guide the reliable process specifications and the
most &quot;informative&quot; data collection, and improve production stability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training. (arXiv:2106.01342v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Somepalli_G/0/1/0/all/0/1">Gowthami Somepalli</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldblum_M/0/1/0/all/0/1">Micah Goldblum</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwarzschild_A/0/1/0/all/0/1">Avi Schwarzschild</a>, <a href="http://arxiv.org/find/cs/1/au:+Bruss_C/0/1/0/all/0/1">C. Bayan Bruss</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1">Tom Goldstein</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01342">
                                    <div class="article-summary-box-inner">
                                        <span>Tabular data underpins numerous high-impact applications of machine learning
from fraud detection to genomics and healthcare. Classical approaches to
solving tabular problems, such as gradient boosting and random forests, are
widely used by practitioners. However, recent deep learning methods have
achieved a degree of performance competitive with popular techniques. We devise
a hybrid deep learning approach to solving tabular data problems. Our method,
SAINT, performs attention over both rows and columns, and it includes an
enhanced embedding method. We also study a new contrastive self-supervised
pre-training method for use when labels are scarce. SAINT consistently improves
performance over previous deep learning methods, and it even outperforms
gradient boosting methods, including XGBoost, CatBoost, and LightGBM, on
average over a variety of benchmark tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Explaining Data-Driven Decisions made by AI Systems: The Counterfactual Approach. (arXiv:2001.07417v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fernandez_Loria_C/0/1/0/all/0/1">Carlos Fern&#xe1;ndez-Lor&#xed;a</a>, <a href="http://arxiv.org/find/cs/1/au:+Provost_F/0/1/0/all/0/1">Foster Provost</a>, <a href="http://arxiv.org/find/cs/1/au:+Han_X/0/1/0/all/0/1">Xintian Han</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2001.07417">
                                    <div class="article-summary-box-inner">
                                        <span>We examine counterfactual explanations for explaining the decisions made by
model-based AI systems. The counterfactual approach we consider defines an
explanation as a set of the system&#x27;s data inputs that causally drives the
decision (i.e., changing the inputs in the set changes the decision) and is
irreducible (i.e., changing any subset of the inputs does not change the
decision). We (1) demonstrate how this framework may be used to provide
explanations for decisions made by general, data-driven AI systems that may
incorporate features with arbitrary data types and multiple predictive models,
and (2) propose a heuristic procedure to find the most useful explanations
depending on the context. We then contrast counterfactual explanations with
methods that explain model predictions by weighting features according to their
importance (e.g., SHAP, LIME) and present two fundamental reasons why we should
carefully consider whether importance-weight explanations are well-suited to
explain system decisions. Specifically, we show that (i) features that have a
large importance weight for a model prediction may not affect the corresponding
decision, and (ii) importance weights are insufficient to communicate whether
and how features influence decisions. We demonstrate this with several concise
examples and three detailed case studies that compare the counterfactual
approach with SHAP to illustrate various conditions under which counterfactual
explanations explain data-driven decisions better than importance weights.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decision Transformer: Reinforcement Learning via Sequence Modeling. (arXiv:2106.01345v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1">Lili Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1">Kevin Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Rajeswaran_A/0/1/0/all/0/1">Aravind Rajeswaran</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kimin Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1">Aditya Grover</a>, <a href="http://arxiv.org/find/cs/1/au:+Laskin_M/0/1/0/all/0/1">Michael Laskin</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Srinivas_A/0/1/0/all/0/1">Aravind Srinivas</a>, <a href="http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1">Igor Mordatch</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01345">
                                    <div class="article-summary-box-inner">
                                        <span>We present a framework that abstracts Reinforcement Learning (RL) as a
sequence modeling problem. This allows us to draw upon the simplicity and
scalability of the Transformer architecture, and associated advances in
language modeling such as GPT-x and BERT. In particular, we present Decision
Transformer, an architecture that casts the problem of RL as conditional
sequence modeling. Unlike prior approaches to RL that fit value functions or
compute policy gradients, Decision Transformer simply outputs the optimal
actions by leveraging a causally masked Transformer. By conditioning an
autoregressive model on the desired return (reward), past states, and actions,
our Decision Transformer model can generate future actions that achieve the
desired return. Despite its simplicity, Decision Transformer matches or exceeds
the performance of state-of-the-art model-free offline RL baselines on Atari,
OpenAI Gym, and Key-to-Door tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Compressing Large-Scale Transformer-Based Models: A Case Study on BERT. (arXiv:2002.11985v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ganesh_P/0/1/0/all/0/1">Prakhar Ganesh</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yao Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lou_X/0/1/0/all/0/1">Xin Lou</a>, <a href="http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1">Mohammad Ali Khan</a>, <a href="http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1">Yin Yang</a>, <a href="http://arxiv.org/find/cs/1/au:+Sajjad_H/0/1/0/all/0/1">Hassan Sajjad</a>, <a href="http://arxiv.org/find/cs/1/au:+Nakov_P/0/1/0/all/0/1">Preslav Nakov</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Deming Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Winslett_M/0/1/0/all/0/1">Marianne Winslett</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.11985">
                                    <div class="article-summary-box-inner">
                                        <span>Pre-trained Transformer-based models have achieved state-of-the-art
performance for various Natural Language Processing (NLP) tasks. However, these
models often have billions of parameters, and, thus, are too resource-hungry
and computation-intensive to suit low-capability devices or applications with
strict latency requirements. One potential remedy for this is model
compression, which has attracted a lot of research attention. Here, we
summarize the research in compressing Transformers, focusing on the especially
popular BERT model. In particular, we survey the state of the art in
compression for BERT, we clarify the current best practices for compressing
large-scale Transformer models, and we provide insights into the workings of
various methods. Our categorization and analysis also shed light on promising
future research directions for achieving lightweight, accurate, and generic NLP
models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Tight High Probability Bounds for Linear Stochastic Approximation with Fixed Stepsize. (arXiv:2106.01257v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1">Alain Durmus</a>, <a href="http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1">Eric Moulines</a>, <a href="http://arxiv.org/find/stat/1/au:+Naumov_A/0/1/0/all/0/1">Alexey Naumov</a>, <a href="http://arxiv.org/find/stat/1/au:+Samsonov_S/0/1/0/all/0/1">Sergey Samsonov</a>, <a href="http://arxiv.org/find/stat/1/au:+Scaman_K/0/1/0/all/0/1">Kevin Scaman</a>, <a href="http://arxiv.org/find/stat/1/au:+Wai_H/0/1/0/all/0/1">Hoi-To Wai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01257">
                                    <div class="article-summary-box-inner">
                                        <span>This paper provides a non-asymptotic analysis of linear stochastic
approximation (LSA) algorithms with fixed stepsize. This family of methods
arises in many machine learning tasks and is used to obtain approximate
solutions of a linear system $\bar{A}\theta &#x3D; \bar{b}$ for which $\bar{A}$ and
$\bar{b}$ can only be accessed through random estimates $\{({\bf A}_n, {\bf
b}_n): n \in \mathbb{N}^*\}$. Our analysis is based on new results regarding
moments and high probability bounds for products of matrices which are shown to
be tight. We derive high probability bounds on the performance of LSA under
weaker conditions on the sequence $\{({\bf A}_n, {\bf b}_n): n \in
\mathbb{N}^*\}$ than previous works. However, in contrast, we establish
polynomial concentration bounds with order depending on the stepsize. We show
that our conclusions cannot be improved without additional assumptions on the
sequence of random matrices $\{{\bf A}_n: n \in \mathbb{N}^*\}$, and in
particular that no Gaussian or exponential high probability bounds can hold.
Finally, we pay a particular attention to establishing bounds with sharp order
with respect to the number of iterations and the stepsize and whose leading
terms contain the covariance matrices appearing in the central limit theorems.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Addressing the Long-term Impact of ML Decisions via Policy Regret. (arXiv:2106.01325v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lindner_D/0/1/0/all/0/1">David Lindner</a>, <a href="http://arxiv.org/find/cs/1/au:+Heidari_H/0/1/0/all/0/1">Hoda Heidari</a>, <a href="http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1">Andreas Krause</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01325">
                                    <div class="article-summary-box-inner">
                                        <span>Machine Learning (ML) increasingly informs the allocation of opportunities to
individuals and communities in areas such as lending, education, employment,
and beyond. Such decisions often impact their subjects&#x27; future characteristics
and capabilities in an a priori unknown fashion. The decision-maker, therefore,
faces exploration-exploitation dilemmas akin to those in multi-armed bandits.
Following prior work, we model communities as arms. To capture the long-term
effects of ML-based allocation decisions, we study a setting in which the
reward from each arm evolves every time the decision-maker pulls that arm. We
focus on reward functions that are initially increasing in the number of pulls
but may become (and remain) decreasing after a certain point. We argue that an
acceptable sequential allocation of opportunities must take an arm&#x27;s potential
for growth into account. We capture these considerations through the notion of
policy regret, a much stronger notion than the often-studied external regret,
and present an algorithm with provably sub-linear policy regret for
sufficiently long time horizons. We empirically compare our algorithm with
several baselines and find that it consistently outperforms them, in particular
for long time horizons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessing the Causal Impact of COVID-19 Related Policies on Outbreak Dynamics: A Case Study in the US. (arXiv:2106.01315v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1">Jing Ma</a>, <a href="http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1">Yushun Dong</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zheng Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Mietchen_D/0/1/0/all/0/1">Daniel Mietchen</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1">Jundong Li</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01315">
                                    <div class="article-summary-box-inner">
                                        <span>To mitigate the spread of COVID-19 pandemic, decision-makers and public
authorities have announced various non-pharmaceutical policies. Analyzing the
causal impact of these policies in reducing the spread of COVID-19 is important
for future policy-making. The main challenge here is the existence of
unobserved confounders (e.g., vigilance of residents). Besides, as the
confounders may be time-varying during COVID-19 (e.g., vigilance of residents
changes in the course of the pandemic), it is even more difficult to capture
them. In this paper, we study the problem of assessing the causal effects of
different COVID-19 related policies on the outbreak dynamics in different
counties at any given time period. To this end, we integrate data about
different COVID-19 related policies (treatment) and outbreak dynamics (outcome)
for different United States counties over time and analyze them with respect to
variables that can infer the confounders, including the covariates of different
counties, their relational information and historical information. Based on
these data, we develop a neural network based causal effect estimation
framework which leverages above information in observational data and learns
the representations of time-varying (unobserved) confounders. In this way, it
enables us to quantify the causal impact of policies at different
granularities, ranging from a category of policies with a certain goal to a
specific policy type in this category. Besides, experimental results also
indicate the effectiveness of our proposed framework in capturing the
confounders for quantifying the causal impact of different policies. More
specifically, compared with several baseline methods, our framework captures
the outbreak dynamics more accurately, and our assessment of policies is more
consistent with existing epidemiological studies of COVID-19.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Semi-Supervised iNaturalist Challenge at the FGVC8 Workshop. (arXiv:2106.01364v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1">Jong-Chyi Su</a>, <a href="http://arxiv.org/find/cs/1/au:+Maji_S/0/1/0/all/0/1">Subhransu Maji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01364">
                                    <div class="article-summary-box-inner">
                                        <span>Semi-iNat is a challenging dataset for semi-supervised classification with a
long-tailed distribution of classes, fine-grained categories, and domain shifts
between labeled and unlabeled data. This dataset is behind the second iteration
of the semi-supervised recognition challenge to be held at the FGVC8 workshop
at CVPR 2021. Different from the previous one, this dataset (i) includes images
of species from different kingdoms in the natural taxonomy, (ii) is at a larger
scale --- with 810 in-class and 1629 out-of-class species for a total of 330k
images, and (iii) does not provide in/out-of-class labels, but provides coarse
taxonomic labels (kingdom and phylum) for the unlabeled images. This document
describes baseline results and the details of the dataset which is available
here: \url{https://github.com/cvl-umass/semi-inat-2021}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Survey Equivalence: A Procedure for Measuring Classifier Accuracy Against Human Labels. (arXiv:2106.01254v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Resnick_P/0/1/0/all/0/1">Paul Resnick</a>, <a href="http://arxiv.org/find/cs/1/au:+Kong_Y/0/1/0/all/0/1">Yuqing Kong</a>, <a href="http://arxiv.org/find/cs/1/au:+Schoenebeck_G/0/1/0/all/0/1">Grant Schoenebeck</a>, <a href="http://arxiv.org/find/cs/1/au:+Weninger_T/0/1/0/all/0/1">Tim Weninger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01254">
                                    <div class="article-summary-box-inner">
                                        <span>In many classification tasks, the ground truth is either noisy or subjective.
Examples include: which of two alternative paper titles is better? is this
comment toxic? what is the political leaning of this news article? We refer to
such tasks as survey settings because the ground truth is defined through a
survey of one or more human raters. In survey settings, conventional
measurements of classifier accuracy such as precision, recall, and
cross-entropy confound the quality of the classifier with the level of
agreement among human raters. Thus, they have no meaningful interpretation on
their own. We describe a procedure that, given a dataset with predictions from
a classifier and K ratings per item, rescales any accuracy measure into one
that has an intuitive interpretation. The key insight is to score the
classifier not against the best proxy for the ground truth, such as a majority
vote of the raters, but against a single human rater at a time. That score can
be compared to other predictors&#x27; scores, in particular predictors created by
combining labels from several other human raters. The survey equivalence of any
classifier is the minimum number of raters needed to produce the same expected
score as that found for the classifier.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">MNL-Bandit with Knapsacks. (arXiv:2106.01135v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Aznag_A/0/1/0/all/0/1">Abdellah Aznag</a>, <a href="http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1">Vineet Goyal</a>, <a href="http://arxiv.org/find/cs/1/au:+Perivier_N/0/1/0/all/0/1">Noemie Perivier</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01135">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a dynamic assortment selection problem where a seller has a fixed
inventory of $N$ substitutable products and faces an unknown demand that
arrives sequentially over $T$ periods. In each period, the seller needs to
decide on the assortment of products (of cardinality at most $K$) to offer to
the customers. The customer&#x27;s response follows an unknown multinomial logit
model (MNL) with parameters $v$. The goal of the seller is to maximize the
total expected revenue given the fixed initial inventory of $N$ products. We
give a policy that achieves a regret of $\tilde O\left(K \sqrt{K N T}\left(1 +
\frac{\sqrt{v_{\max}}}{q_{\min}}\text{OPT}\right) \right)$ under a mild
assumption on the model parameters. In particular, our policy achieves a
near-optimal $\tilde O(\sqrt{T})$ regret in the large inventory setting.

Our policy builds upon the UCB-based approach for MNL-bandit without
inventory constraints in [1] and addresses the inventory constraints through an
exponentially sized LP for which we present a tractable approximation while
keeping the $\tilde O(\sqrt{T})$ regret bound.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improved Rates for Differentially Private Stochastic Convex Optimization with Heavy-Tailed Data. (arXiv:2106.01336v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1">Gautam Kamath</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1">Xingtu Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1">Huanyu Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01336">
                                    <div class="article-summary-box-inner">
                                        <span>We study stochastic convex optimization with heavy-tailed data under the
constraint of differential privacy. Most prior work on this problem is
restricted to the case where the loss function is Lipschitz. Instead, as
introduced by Wang, Xiao, Devadas, and Xu, we study general convex loss
functions with the assumption that the distribution of gradients has bounded
$k$-th moments. We provide improved upper bounds on the excess population risk
under approximate differential privacy of
$\tilde{O}\left(\sqrt{\frac{d}{n}}+\left(\frac{d}{\epsilon
n}\right)^{\frac{k-1}{k}}\right)$ and
$\tilde{O}\left(\frac{d}{n}+\left(\frac{d}{\epsilon
n}\right)^{\frac{2k-2}{k}}\right)$ for convex and strongly convex loss
functions, respectively. We also prove nearly-matching lower bounds under the
constraint of pure differential privacy, giving strong evidence that our bounds
are tight.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Evidential Turing Processes. (arXiv:2106.01216v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kandemir_M/0/1/0/all/0/1">Melih Kandemir</a>, <a href="http://arxiv.org/find/cs/1/au:+Akgul_A/0/1/0/all/0/1">Abdullah Akg&#xfc;l</a>, <a href="http://arxiv.org/find/cs/1/au:+Haussmann_M/0/1/0/all/0/1">Manuel Haussmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Unal_G/0/1/0/all/0/1">Gozde Unal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01216">
                                    <div class="article-summary-box-inner">
                                        <span>A probabilistic classifier with reliable predictive uncertainties i) fits
successfully to the target domain data, ii) provides calibrated class
probabilities in difficult regions of the target domain (e.g. class overlap),
and iii) accurately identifies queries coming out of the target domain and
reject them. We introduce an original combination of evidential deep learning,
neural processes, and neural Turing machines capable of providing all three
essential properties mentioned above for total uncertainty quantification. We
observe our method on three image classification benchmarks and two neural net
architectures to consistently give competitive or superior scores with respect
to multiple uncertainty quantification metrics against state-of-the-art methods
explicitly tailored to one or a few of them. Our unified solution delivers an
implementation-friendly and computationally efficient recipe for safety
clearance and provides intellectual economy to an investigation of algorithmic
roots of epistemic awareness in deep neural nets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Spectral embedding for dynamic networks with stability guarantees. (arXiv:2106.01282v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Gallagher_I/0/1/0/all/0/1">Ian Gallagher</a>, <a href="http://arxiv.org/find/stat/1/au:+Jones_A/0/1/0/all/0/1">Andrew Jones</a>, <a href="http://arxiv.org/find/stat/1/au:+Rubin_Delanchy_P/0/1/0/all/0/1">Patrick Rubin-Delanchy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01282">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of embedding a dynamic network, to obtain
time-evolving vector representations of each node, which can then be used to
describe the changes in behaviour of a single node, one or more communities, or
the entire graph. Given this open-ended remit, we wish to guarantee stability
in the spatio-temporal positioning of the nodes: assigning the same position,
up to noise, to nodes behaving similarly at a given time (cross-sectional
stability) and a constant position, up to noise, to a single node behaving
similarly across different times (longitudinal stability). These properties are
defined formally within a generic dynamic latent position model. By showing how
this model can be recast as a multilayer random dot product graph, we
demonstrate that unfolded adjacency spectral embedding satisfies both stability
conditions, allowing, for example, spatio-temporal clustering under the dynamic
stochastic block model. We also show how alternative methods, such as omnibus,
independent or time-averaged spectral embedding, lack one or the other form of
stability.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Opening the Black Box of Deep Neural Networks in Physical Layer Communication. (arXiv:2106.01124v1 [eess.SP])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1">Jun Liu</a>, <a href="http://arxiv.org/find/eess/1/au:+Mei_K/0/1/0/all/0/1">Kai Mei</a>, <a href="http://arxiv.org/find/eess/1/au:+Ma_D/0/1/0/all/0/1">Dongtang Ma</a>, <a href="http://arxiv.org/find/eess/1/au:+Wei_J/0/1/0/all/0/1">Jibo Wei</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01124">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Neural Network (DNN)-based physical layer techniques are attracting
considerable interest due to their potential to enhance communication systems.
However, most studies in the physical layer have tended to focus on the
implement of DNN but not to theoretically understand how does a DNN work in a
communication system. In this letter, we aim to quantitatively analyse why DNNs
can achieve comparable performance in the physical layer comparing with
traditional techniques and its cost in terms of computational complexity. We
further investigate and also experimentally validate how information is flown
in a DNN-based communication system under the information theoretic concepts.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Benchmarking CNN on 3D Anatomical Brain MRI: Architectures, Data Augmentation and Deep Ensemble Learning. (arXiv:2106.01132v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dufumier_B/0/1/0/all/0/1">Benoit Dufumier</a>, <a href="http://arxiv.org/find/cs/1/au:+Gori_P/0/1/0/all/0/1">Pietro Gori</a>, <a href="http://arxiv.org/find/cs/1/au:+Battaglia_I/0/1/0/all/0/1">Ilaria Battaglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Victor_J/0/1/0/all/0/1">Julie Victor</a>, <a href="http://arxiv.org/find/cs/1/au:+Grigis_A/0/1/0/all/0/1">Antoine Grigis</a>, <a href="http://arxiv.org/find/cs/1/au:+Duchesnay_E/0/1/0/all/0/1">Edouard Duchesnay</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01132">
                                    <div class="article-summary-box-inner">
                                        <span>Deep Learning (DL) and specifically CNN models have become a de facto method
for a wide range of vision tasks, outperforming traditional machine learning
(ML) methods. Consequently, they drew a lot of attention in the neuroimaging
field in particular for phenotype prediction or computer-aided diagnosis.
However, most of the current studies often deal with small single-site cohorts,
along with a specific pre-processing pipeline and custom CNN architectures,
which make them difficult to compare to. We propose an extensive benchmark of
recent state-of-the-art (SOTA) 3D CNN, evaluating also the benefits of data
augmentation and deep ensemble learning, on both Voxel-Based Morphometry (VBM)
pre-processing and quasi-raw images. Experiments were conducted on a large
multi-site 3D brain anatomical MRI data-set comprising N&#x3D;10k scans on 3
challenging tasks: age prediction, sex classification, and schizophrenia
diagnosis. We found that all models provide significantly better predictions
with VBM images than quasi-raw data. This finding evolved as the training set
approaches 10k samples where quasi-raw data almost reach the performance of
VBM. Moreover, we showed that linear models perform comparably with SOTA CNN on
VBM data. We also demonstrated that DenseNet and tiny-DenseNet, a lighter
version that we proposed, provide a good compromise in terms of performance in
all data regime. Therefore, we suggest to employ them as the architectures by
default. Critically, we also showed that current CNN are still very biased
towards the acquisition site, even when trained with N&#x3D;10k multi-site images.
In this context, VBM pre-processing provides an efficient way to limit this
site effect. Surprisingly, we did not find any clear benefit from data
augmentation techniques. Finally, we proved that deep ensemble learning is well
suited to re-calibrate big CNN models without sacrificing performance.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Matrix factorisation and the interpretation of geodesic distance. (arXiv:2106.01260v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Whiteley_N/0/1/0/all/0/1">Nick Whiteley</a>, <a href="http://arxiv.org/find/stat/1/au:+Gray_A/0/1/0/all/0/1">Annie Gray</a>, <a href="http://arxiv.org/find/stat/1/au:+Rubin_Delanchy_P/0/1/0/all/0/1">Patrick Rubin-Delanchy</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01260">
                                    <div class="article-summary-box-inner">
                                        <span>Given a graph or similarity matrix, we consider the problem of recovering a
notion of true distance between the nodes, and so their true positions. Through
new insights into the manifold geometry underlying a generic latent position
model, we show that this can be accomplished in two steps: matrix
factorisation, followed by nonlinear dimension reduction. This combination is
effective because the point cloud obtained in the first step lives close to a
manifold in which latent distance is encoded as geodesic distance. Hence, a
nonlinear dimension reduction tool, approximating geodesic distance, can
recover the latent positions, up to a simple transformation. We give a detailed
account of the case where spectral embedding is used, followed by Isomap, and
provide encouraging experimental evidence for other combinations of techniques.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Towards Deeper Deep Reinforcement Learning. (arXiv:2106.01151v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bjorck_J/0/1/0/all/0/1">Johan Bjorck</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1">Carla P. Gomes</a>, <a href="http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1">Kilian Q. Weinberger</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01151">
                                    <div class="article-summary-box-inner">
                                        <span>In computer vision and natural language processing, innovations in model
architecture that lead to increases in model capacity have reliably translated
into gains in performance. In stark contrast with this trend, state-of-the-art
reinforcement learning (RL) algorithms often use only small MLPs, and gains in
performance typically originate from algorithmic innovations. It is natural to
hypothesize that small datasets in RL necessitate simple models to avoid
overfitting; however, this hypothesis is untested. In this paper we investigate
how RL agents are affected by exchanging the small MLPs with larger modern
networks with skip connections and normalization, focusing specifically on soft
actor-critic (SAC) algorithms. We verify, empirically, that na\&quot;ively adopting
such architectures leads to instabilities and poor performance, likely
contributing to the popularity of simple models in practice. However, we show
that dataset size is not the limiting factor, and instead argue that intrinsic
instability from the actor in SAC taking gradients through the critic is the
culprit. We demonstrate that a simple smoothing method can mitigate this issue,
which enables stable training with large modern architectures. After smoothing,
larger models yield dramatic performance improvements for state-of-the-art
agents -- suggesting that more &quot;easy&quot; gains may be had by focusing on model
architectures in addition to algorithmic innovations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Design and Comparison of Reward Functions in Reinforcement Learning for Energy Management of Sensor Nodes. (arXiv:2106.01114v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Rioual_Y/0/1/0/all/0/1">Yohann Rioual</a> (1), <a href="http://arxiv.org/find/eess/1/au:+Moullec_Y/0/1/0/all/0/1">Yannick Le Moullec</a> (2), <a href="http://arxiv.org/find/eess/1/au:+Laurent_J/0/1/0/all/0/1">Johann Laurent</a> (1), <a href="http://arxiv.org/find/eess/1/au:+Khan_M/0/1/0/all/0/1">Muhidul Islam Khan</a> (2), <a href="http://arxiv.org/find/eess/1/au:+Diguet_J/0/1/0/all/0/1">Jean-Philippe Diguet</a> (3) ((1) Lab-STICC, University Bretagne Sud, (2) Thomas Johann Seebeck Department of Electronics, Tallinn University of Technology, (3) IRL CNRS CROSSING)
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01114">
                                    <div class="article-summary-box-inner">
                                        <span>Interest in remote monitoring has grown thanks to recent advancements in
Internet-of-Things (IoT) paradigms. New applications have emerged, using small
devices called sensor nodes capable of collecting data from the environment and
processing it. However, more and more data are processed and transmitted with
longer operational periods. At the same, the battery technologies have not
improved fast enough to cope with these increasing needs. This makes the energy
consumption issue increasingly challenging and thus, miniaturized energy
harvesting devices have emerged to complement traditional energy sources.
Nevertheless, the harvested energy fluctuates significantly during the node
operation, increasing uncertainty in actually available energy resources.
Recently, approaches in energy management have been developed, in particular
using reinforcement learning approaches. However, in reinforcement learning,
the algorithm&#x27;s performance relies greatly on the reward function. In this
paper, we present two contributions. First, we explore five different reward
functions to identify the most suitable variables to use in such functions to
obtain the desired behaviour. Experiments were conducted using the Q-learning
algorithm to adjust the energy consumption depending on the energy harvested.
Results with the five reward functions illustrate how the choice thereof
impacts the energy consumption of the node. Secondly, we propose two additional
reward functions able to find the compromise between energy consumption and a
node performance using a non-fixed balancing parameter. Our simulation results
show that the proposed reward functions adjust the node&#x27;s performance depending
on the battery level and reduce the learning time.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Linear-Time Gromov Wasserstein Distances using Low Rank Couplings and Costs. (arXiv:2106.01128v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Scetbon_M/0/1/0/all/0/1">Meyer Scetbon</a>, <a href="http://arxiv.org/find/cs/1/au:+Peyre_G/0/1/0/all/0/1">Gabriel Peyr&#xe9;</a>, <a href="http://arxiv.org/find/cs/1/au:+Cuturi_M/0/1/0/all/0/1">Marco Cuturi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01128">
                                    <div class="article-summary-box-inner">
                                        <span>The ability to compare and align related datasets living in heterogeneous
spaces plays an increasingly important role in machine learning. The
Gromov-Wasserstein (GW) formalism can help tackle this problem. Its main goal
is to seek an assignment (more generally a coupling matrix) that can register
points across otherwise incomparable datasets. As a non-convex and quadratic
generalization of optimal transport (OT), GW is NP-hard. Yet, heuristics are
known to work reasonably well in practice, the state of the art approach being
to solve a sequence of nested regularized OT problems. While popular, that
heuristic remains too costly to scale, with cubic complexity in the number of
samples $n$. We show in this paper how a recent variant of the Sinkhorn
algorithm can substantially speed up the resolution of GW. That variant
restricts the set of admissible couplings to those admitting a low rank
factorization as the product of two sub-couplings. By updating alternatively
each sub-coupling, our algorithm computes a stationary point of the problem in
quadratic time with respect to the number of samples. When cost matrices have
themselves low rank, our algorithm has time complexity $\mathcal{O}(n)$. We
demonstrate the efficiency of our method on simulated and real data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Framing RNN as a kernel method: A neural ODE approach. (arXiv:2106.01202v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Fermanian_A/0/1/0/all/0/1">Adeline Fermanian</a>, <a href="http://arxiv.org/find/stat/1/au:+Marion_P/0/1/0/all/0/1">Pierre Marion</a>, <a href="http://arxiv.org/find/stat/1/au:+Vert_J/0/1/0/all/0/1">Jean-Philippe Vert</a>, <a href="http://arxiv.org/find/stat/1/au:+Biau_G/0/1/0/all/0/1">G&#xe9;rard Biau</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01202">
                                    <div class="article-summary-box-inner">
                                        <span>Building on the interpretation of a recurrent neural network (RNN) as a
continuous-time neural differential equation, we show, under appropriate
conditions, that the solution of a RNN can be viewed as a linear function of a
specific feature set of the input sequence, known as the signature. This
connection allows us to frame a RNN as a kernel method in a suitable
reproducing kernel Hilbert space. As a consequence, we obtain theoretical
guarantees on generalization and stability for a large class of recurrent
networks. Our results are illustrated on simulated datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Assessing the Reliability of Deep Learning Classifiers Through Robustness Evaluation and Operational Profiles. (arXiv:2106.01258v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1">Xingyu Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1">Wei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Banks_A/0/1/0/all/0/1">Alec Banks</a>, <a href="http://arxiv.org/find/cs/1/au:+Cox_V/0/1/0/all/0/1">Victoria Cox</a>, <a href="http://arxiv.org/find/cs/1/au:+Flynn_D/0/1/0/all/0/1">David Flynn</a>, <a href="http://arxiv.org/find/cs/1/au:+Schewe_S/0/1/0/all/0/1">Sven Schewe</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xiaowei Huang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01258">
                                    <div class="article-summary-box-inner">
                                        <span>The utilisation of Deep Learning (DL) is advancing into increasingly more
sophisticated applications. While it shows great potential to provide
transformational capabilities, DL also raises new challenges regarding its
reliability in critical functions. In this paper, we present a model-agnostic
reliability assessment method for DL classifiers, based on evidence from
robustness evaluation and the operational profile (OP) of a given application.
We partition the input space into small cells and then &quot;assemble&quot; their
robustness (to the ground truth) according to the OP, where estimators on the
cells&#x27; robustness and OPs are provided. Reliability estimates in terms of the
probability of misclassification per input (pmi) can be derived together with
confidence levels. A prototype tool is demonstrated with simplified case
studies. Model assumptions and extension to real-world applications are also
discussed. While our model easily uncovers the inherent difficulties of
assessing the DL dependability (e.g. lack of data with ground truth and
scalability issues), we provide preliminary/compromised solutions to advance in
this research direction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Accurate and Robust Deep Learning Framework for Solving Wave-Based Inverse Problems in the Super-Resolution Regime. (arXiv:2106.01143v1 [math.NA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Li_M/0/1/0/all/0/1">Matthew Li</a>, <a href="http://arxiv.org/find/math/1/au:+Demanet_L/0/1/0/all/0/1">Laurent Demanet</a>, <a href="http://arxiv.org/find/math/1/au:+Zepeda_Nunez_L/0/1/0/all/0/1">Leonardo Zepeda-N&#xfa;&#xf1;ez</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01143">
                                    <div class="article-summary-box-inner">
                                        <span>We propose an end-to-end deep learning framework that comprehensively solves
the inverse wave scattering problem across all length scales. Our framework
consists of the newly introduced wide-band butterfly network coupled with a
simple training procedure that dynamically injects noise during training. While
our trained network provides competitive results in classical imaging regimes,
most notably it also succeeds in the super-resolution regime where other
comparable methods fail. This encompasses both (i) reconstruction of scatterers
with sub-wavelength geometric features, and (ii) accurate imaging when two or
more scatterers are separated by less than the classical diffraction limit. We
demonstrate these properties are retained even in the presence of strong noise
and extend to scatterers not previously seen in the training set. In addition,
our network is straightforward to train requiring no restarts and has an online
runtime that is an order of magnitude faster than optimization-based
algorithms. We perform experiments with a variety of wave scattering mediums
and we demonstrate that our proposed framework outperforms both classical
inversion and competing network architectures that specialize in oscillatory
wave scattering data.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Solving Large-Scale Extensive-Form Network Security Games via Neural Fictitious Self-Play. (arXiv:2106.00897v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1">Wanqi Xue</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1">Youzhi Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1">Shuxin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinrun Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1">Bo An</a>, <a href="http://arxiv.org/find/cs/1/au:+Yeo_C/0/1/0/all/0/1">Chai Kiat Yeo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00897">
                                    <div class="article-summary-box-inner">
                                        <span>Securing networked infrastructures is important in the real world. The
problem of deploying security resources to protect against an attacker in
networked domains can be modeled as Network Security Games (NSGs).
Unfortunately, existing approaches, including the deep learning-based
approaches, are inefficient to solve large-scale extensive-form NSGs. In this
paper, we propose a novel learning paradigm, NSG-NFSP, to solve large-scale
extensive-form NSGs based on Neural Fictitious Self-Play (NFSP). Our main
contributions include: i) reforming the best response (BR) policy network in
NFSP to be a mapping from action-state pair to action-value, to make the
calculation of BR possible in NSGs; ii) converting the average policy network
of an NFSP agent into a metric-based classifier, helping the agent to assign
distributions only on legal actions rather than all actions; iii) enabling NFSP
with high-level actions, which can benefit training efficiency and stability in
NSGs; and iv) leveraging information contained in graphs of NSGs by learning
efficient graph node embeddings. Our algorithm significantly outperforms
state-of-the-art algorithms in both scalability and solution quality.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Invariant Policy Learning: A Causal Perspective. (arXiv:2106.00808v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saengkyongam_S/0/1/0/all/0/1">Sorawit Saengkyongam</a>, <a href="http://arxiv.org/find/cs/1/au:+Thams_N/0/1/0/all/0/1">Nikolaj Thams</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jonas Peters</a>, <a href="http://arxiv.org/find/cs/1/au:+Pfister_N/0/1/0/all/0/1">Niklas Pfister</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00808">
                                    <div class="article-summary-box-inner">
                                        <span>In the past decade, contextual bandit and reinforcement learning algorithms
have been successfully used in various interactive learning systems such as
online advertising, recommender systems, and dynamic pricing. However, they
have yet to be widely adopted in high-stakes application domains, such as
healthcare. One reason may be that existing approaches assume that the
underlying mechanisms are static in the sense that they do not change over time
or over different environments. In many real world systems, however, the
mechanisms are subject to shifts across environments which may invalidate the
static environment assumption. In this paper, we tackle the problem of
environmental shifts under the framework of offline contextual bandits. We view
the environmental shift problem through the lens of causality and propose
multi-environment contextual bandits that allow for changes in the underlying
mechanisms. We adopt the concept of invariance from the causality literature
and introduce the notion of policy invariance. We argue that policy invariance
is only relevant if unobserved confounders are present and show that, in that
case, an optimal invariant policy is guaranteed, under certain assumptions, to
generalize across environments. Our results do not only provide a solution to
the environmental shift problem but also establish concrete connections among
causality, invariance and contextual bandits.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Few-Shot Partial-Label Learning. (arXiv:2106.00984v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1">Yunfeng Zhao</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_G/0/1/0/all/0/1">Guoxian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1">Lei Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1">Zhongmin Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1">Lizhen Cui</a>, <a href="http://arxiv.org/find/cs/1/au:+Domeniconi_C/0/1/0/all/0/1">Carlotta Domeniconi</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00984">
                                    <div class="article-summary-box-inner">
                                        <span>Partial-label learning (PLL) generally focuses on inducing a noise-tolerant
multi-class classifier by training on overly-annotated samples, each of which
is annotated with a set of labels, but only one is the valid label. A basic
promise of existing PLL solutions is that there are sufficient partial-label
(PL) samples for training. However, it is more common than not to have just few
PL samples at hand when dealing with new tasks. Furthermore, existing few-shot
learning algorithms assume precise labels of the support set; as such,
irrelevant labels may seriously mislead the meta-learner and thus lead to a
compromised performance. How to enable PLL under a few-shot learning setting is
an important problem, but not yet well studied. In this paper, we introduce an
approach called FsPLL (Few-shot PLL). FsPLL first performs adaptive distance
metric learning by an embedding network and rectifying prototypes on the tasks
previously encountered. Next, it calculates the prototype of each class of a
new task in the embedding network. An unseen example can then be classified via
its distance to each prototype. Experimental results on widely-used few-shot
datasets (Omniglot and miniImageNet) demonstrate that our FsPLL can achieve a
superior performance than the state-of-the-art methods across different
settings, and it needs fewer samples for quickly adapting to new tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Communication-Efficient Split Learning Based on Analog Communication and Over the Air Aggregation. (arXiv:2106.00999v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krouka_M/0/1/0/all/0/1">Mounssif Krouka</a>, <a href="http://arxiv.org/find/cs/1/au:+Elgabli_A/0/1/0/all/0/1">Anis Elgabli</a>, <a href="http://arxiv.org/find/cs/1/au:+Issaid_C/0/1/0/all/0/1">Chaouki ben Issaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1">Mehdi Bennis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00999">
                                    <div class="article-summary-box-inner">
                                        <span>Split-learning (SL) has recently gained popularity due to its inherent
privacy-preserving capabilities and ability to enable collaborative inference
for devices with limited computational power. Standard SL algorithms assume an
ideal underlying digital communication system and ignore the problem of scarce
communication bandwidth. However, for a large number of agents, limited
bandwidth resources, and time-varying communication channels, the communication
bandwidth can become the bottleneck. To address this challenge, in this work,
we propose a novel SL framework to solve the remote inference problem that
introduces an additional layer at the agent side and constrains the choices of
the weights and the biases to ensure over the air aggregation. Hence, the
proposed approach maintains constant communication cost with respect to the
number of agents enabling remote inference under limited bandwidth. Numerical
results show that our proposed algorithm significantly outperforms the digital
implementation in terms of communication-efficiency, especially as the number
of agents grows large.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learn to Predict Equilibria via Fixed Point Networks. (arXiv:2106.00906v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Heaton_H/0/1/0/all/0/1">Howard Heaton</a>, <a href="http://arxiv.org/find/cs/1/au:+McKenzie_D/0/1/0/all/0/1">Daniel McKenzie</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1">Qiuwei Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_S/0/1/0/all/0/1">Samy Wu Fung</a>, <a href="http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1">Stanley Osher</a>, <a href="http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1">Wotao Yin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00906">
                                    <div class="article-summary-box-inner">
                                        <span>Systems of interacting agents can often be modeled as contextual games, where
the context encodes additional information, beyond the control of any agent
(e.g. weather for traffic and fiscal policy for market economies). In such
systems, the most likely outcome is given by a Nash equilibrium. In many
practical settings, only game equilibria are observed, while the optimal
parameters for a game model are unknown. This work introduces Nash Fixed Point
Networks (N-FPNs), a class of implicit-depth neural networks that output Nash
equilibria of contextual games. The N-FPN architecture fuses data-driven
modeling with provided constraints. Given equilibrium observations of a
contextual game, N-FPN parameters are learnt to predict equilibria outcomes
given only the context. We present an end-to-end training scheme for N-FPNs
that is simple and memory efficient to implement with existing
autodifferentiation tools. N-FPNs also exploit a novel constraint decoupling
scheme to avoid costly projections. Provided numerical examples show the
efficacy of N-FPNs on atomic and non-atomic games (e.g. traffic routing).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Search Methods for Sufficient, Socially-Aligned Feature Importance Explanations with In-Distribution Counterfactuals. (arXiv:2106.00786v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hase_P/0/1/0/all/0/1">Peter Hase</a>, <a href="http://arxiv.org/find/cs/1/au:+Xie_H/0/1/0/all/0/1">Harry Xie</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00786">
                                    <div class="article-summary-box-inner">
                                        <span>Feature importance (FI) estimates are a popular form of explanation, and they
are commonly created and evaluated by computing the change in model confidence
caused by removing certain input features at test time. For example, in the
standard Sufficiency metric, only the top-k most important tokens are kept. In
this paper, we study several under-explored dimensions of FI-based
explanations, providing conceptual and empirical improvements for this form of
explanation. First, we advance a new argument for why it can be problematic to
remove features from an input when creating or evaluating explanations: the
fact that these counterfactual inputs are out-of-distribution (OOD) to models
implies that the resulting explanations are socially misaligned. The crux of
the problem is that the model prior and random weight initialization influence
the explanations (and explanation metrics) in unintended ways. To resolve this
issue, we propose a simple alteration to the model training process, which
results in more socially aligned explanations and metrics. Second, we compare
among five approaches for removing features from model inputs. We find that
some methods produce more OOD counterfactuals than others, and we make
recommendations for selecting a feature-replacement function. Finally, we
introduce four search-based methods for identifying FI explanations and compare
them to strong baselines, including LIME, Integrated Gradients, and random
search. On experiments with six diverse text classification datasets, we find
that the only method that consistently outperforms random search is a Parallel
Local Search that we introduce. Improvements over the second-best method are as
large as 5.4 points for Sufficiency and 17 points for Comprehensiveness. All
supporting code is publicly available at
https://github.com/peterbhase/ExplanationSearch.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Out-of-Domain Detection via Pre-trained Transformers. (arXiv:2106.00948v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1">Keyang Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Ren_T/0/1/0/all/0/1">Tongzheng Ren</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1">Shikun Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1">Yihao Feng</a>, <a href="http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1">Caiming Xiong</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00948">
                                    <div class="article-summary-box-inner">
                                        <span>Deployed real-world machine learning applications are often subject to
uncontrolled and even potentially malicious inputs. Those out-of-domain inputs
can lead to unpredictable outputs and sometimes catastrophic safety issues.
Prior studies on out-of-domain detection require in-domain task labels and are
limited to supervised classification scenarios. Our work tackles the problem of
detecting out-of-domain samples with only unsupervised in-domain data. We
utilize the latent representations of pre-trained transformers and propose a
simple yet effective method to transform features across all layers to
construct out-of-domain detectors efficiently. Two domain-specific fine-tuning
approaches are further proposed to boost detection accuracy. Our empirical
evaluations of related methods on two datasets validate that our method greatly
improves out-of-domain detection ability in a more general scenario.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Concurrent Learning Based Tracking Control of Nonlinear Systems using Gaussian Process. (arXiv:2106.00910v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Bhandari_V/0/1/0/all/0/1">Vedant Bhandari</a>, <a href="http://arxiv.org/find/eess/1/au:+Kayacan_E/0/1/0/all/0/1">Erkan Kayacan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00910">
                                    <div class="article-summary-box-inner">
                                        <span>This paper demonstrates the applicability of the combination of concurrent
learning as a tool for parameter estimation and non-parametric Gaussian Process
for online disturbance learning. A control law is developed by using both
techniques sequentially in the context of feedback linearization. The
concurrent learning algorithm estimates the system parameters of structured
uncertainty without requiring persistent excitation, which are used in the
design of the feedback linearization law. Then, a non-parametric Gaussian
Process learns unstructured uncertainty. The closed-loop system stability for
the nth-order system is proven using the Lyapunov stability theorem. The
simulation results show that the tracking error is minimized (i) when true
values of model parameters have not been provided, (ii) in the presence of
disturbances introduced once the parameters have converged to their true values
and (iii) when system parameters have not converged to their true values in the
presence of disturbances.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Contrastive ACE: Domain Generalization Through Alignment of Causal Mechanisms. (arXiv:2106.00925v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1">Yunqi Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1">Furui Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1">Zhitang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lian_Q/0/1/0/all/0/1">Qing Lian</a>, <a href="http://arxiv.org/find/cs/1/au:+Hu_S/0/1/0/all/0/1">Shoubo Hu</a>, <a href="http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1">Jianye Hao</a>, <a href="http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1">Yik-Chung Wu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00925">
                                    <div class="article-summary-box-inner">
                                        <span>Domain generalization aims to learn knowledge invariant across different
distributions while semantically meaningful for downstream tasks from multiple
source domains, to improve the model&#x27;s generalization ability on unseen target
domains. The fundamental objective is to understand the underlying &quot;invariance&quot;
behind these observational distributions and such invariance has been shown to
have a close connection to causality. While many existing approaches make use
of the property that causal features are invariant across domains, we consider
the causal invariance of the average causal effect of the features to the
labels. This invariance regularizes our training approach in which
interventions are performed on features to enforce stability of the causal
prediction by the classifier across domains. Our work thus sheds some light on
the domain generalization problem by introducing invariance of the mechanisms
into the learning process. Experiments on several benchmark datasets
demonstrate the performance of the proposed method against SOTAs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Optimizing Functionals on the Space of Probabilities with Input Convex Neural Networks. (arXiv:2106.00774v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Alvarez_Melis_D/0/1/0/all/0/1">David Alvarez-Melis</a>, <a href="http://arxiv.org/find/stat/1/au:+Schiff_Y/0/1/0/all/0/1">Yair Schiff</a>, <a href="http://arxiv.org/find/stat/1/au:+Mroueh_Y/0/1/0/all/0/1">Youssef Mroueh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00774">
                                    <div class="article-summary-box-inner">
                                        <span>Gradient flows are a powerful tool for optimizing functionals in general
metric spaces, including the space of probabilities endowed with the
Wasserstein metric. A typical approach to solving this optimization problem
relies on its connection to the dynamic formulation of optimal transport and
the celebrated Jordan-Kinderlehrer-Otto (JKO) scheme. However, this formulation
involves optimization over convex functions, which is challenging, especially
in high dimensions. In this work, we propose an approach that relies on the
recently introduced input-convex neural networks (ICNN) to parameterize the
space of convex functions in order to approximate the JKO scheme, as well as in
designing functionals over measures that enjoy convergence guarantees. We
derive a computationally efficient implementation of this JKO-ICNN framework
and use various experiments to demonstrate its feasibility and validity in
approximating solutions of low-dimensional partial differential equations with
known solutions. We also explore the use of our JKO-ICNN approach in high
dimensions with an experiment in controlled generation for molecular discovery.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Compositionality of Neural Networks by Decoding Representations to Inputs. (arXiv:2106.00769v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1">Mike Wu</a>, <a href="http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1">Noah Goodman</a>, <a href="http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1">Stefano Ermon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00769">
                                    <div class="article-summary-box-inner">
                                        <span>In traditional software programs, we take for granted how easy it is to debug
code by tracing program logic from variables back to input, apply unit tests
and assertion statements to block erroneous behavior, and compose programs
together. But as the programs we write grow more complex, it becomes hard to
apply traditional software to applications like computer vision or natural
language. Although deep learning programs have demonstrated strong performance
on these applications, they sacrifice many of the functionalities of
traditional software programs. In this paper, we work towards bridging the
benefits of traditional and deep learning programs by jointly training a
generative model to constrain neural network activations to &quot;decode&quot; back to
inputs. Doing so enables practitioners to probe and track information encoded
in activation(s), apply assertion-like constraints on what information is
encoded in an activation, and compose separate neural networks together in a
plug-and-play fashion. In our experiments, we demonstrate applications of
decodable representations to out-of-distribution detection, adversarial
examples, calibration, and fairness -- while matching standard neural networks
in accuracy.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Some Ethical Issues in the Review Process of Machine Learning Conferences. (arXiv:2106.00810v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1">Alessio Russo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00810">
                                    <div class="article-summary-box-inner">
                                        <span>Recent successes in the Machine Learning community have led to a steep
increase in the number of papers submitted to conferences. This increase made
more prominent some of the issues that affect the current review process used
by these conferences. The review process has several issues that may undermine
the nature of scientific research, which is of being fully objective,
apolitical, unbiased and free of misconduct (such as plagiarism, cheating,
improper influence, and other improprieties). In this work, we study the
problem of reviewers&#x27; recruitment, infringements of the double-blind process,
fraudulent behaviors, biases in numerical ratings, and the appendix phenomenon
(i.e., the fact that it is becoming more common to publish results in the
appendix section of a paper). For each of these problems, we provide a short
description and possible solutions. The goal of this work is to raise awareness
in the Machine Learning community regarding these issues.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Efficacy of Adversarial Data Collection for Question Answering: Results from a Large-Scale Randomized Study. (arXiv:2106.00872v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaushik_D/0/1/0/all/0/1">Divyansh Kaushik</a>, <a href="http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1">Douwe Kiela</a>, <a href="http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1">Zachary C. Lipton</a>, <a href="http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1">Wen-tau Yih</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00872">
                                    <div class="article-summary-box-inner">
                                        <span>In adversarial data collection (ADC), a human workforce interacts with a
model in real time, attempting to produce examples that elicit incorrect
predictions. Researchers hope that models trained on these more challenging
datasets will rely less on superficial patterns, and thus be less brittle.
However, despite ADC&#x27;s intuitive appeal, it remains unclear when training on
adversarial datasets produces more robust models. In this paper, we conduct a
large-scale controlled study focused on question answering, assigning workers
at random to compose questions either (i) adversarially (with a model in the
loop); or (ii) in the standard fashion (without a model). Across a variety of
models and datasets, we find that models trained on adversarial data usually
perform better on other adversarial datasets but worse on a diverse collection
of out-of-domain evaluation sets. Finally, we provide a qualitative analysis of
adversarial (vs standard) data, identifying key differences and offering
guidance for future research.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multiresolution Graph Variational Autoencoder. (arXiv:2106.00967v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hy_T/0/1/0/all/0/1">Truong Son Hy</a>, <a href="http://arxiv.org/find/cs/1/au:+Kondor_R/0/1/0/all/0/1">Risi Kondor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00967">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose Multiresolution Graph Networks (MGN) and
Multiresolution Graph Variational Autoencoders (MGVAE) to learn and generate
graphs in a multiresolution and equivariant manner. At each resolution level,
MGN employs higher order message passing to encode the graph while learning to
partition it into mutually exclusive clusters and coarsening into a lower
resolution. MGVAE constructs a hierarchical generative model based on MGN to
variationally autoencode the hierarchy of coarsened graphs. Our proposed
framework is end-to-end permutation equivariant with respect to node ordering.
Our methods have been successful with several generative tasks including link
prediction on citation graphs, unsupervised molecular representation learning
to predict molecular properties, molecular generation, general graph generation
and graph-based image generation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Generalizable Approach to Learning Optimizers. (arXiv:2106.00958v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Almeida_D/0/1/0/all/0/1">Diogo Almeida</a>, <a href="http://arxiv.org/find/cs/1/au:+Winter_C/0/1/0/all/0/1">Clemens Winter</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jie Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1">Wojciech Zaremba</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00958">
                                    <div class="article-summary-box-inner">
                                        <span>A core issue with learning to optimize neural networks has been the lack of
generalization to real world problems. To address this, we describe a system
designed from a generalization-first perspective, learning to update optimizer
hyperparameters instead of model parameters directly using novel features,
actions, and a reward function. This system outperforms Adam at all neural
network tasks including on modalities not seen during training. We achieve 2x
speedups on ImageNet, and a 2.5x speedup on a language modeling task using over
5 orders of magnitude more compute than the training tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">End-to-End Information Extraction by Character-Level Embedding and Multi-Stage Attentional U-Net. (arXiv:2106.00952v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dang_T/0/1/0/all/0/1">Tuan-Anh Nguyen Dang</a>, <a href="http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1">Dat-Thanh Nguyen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00952">
                                    <div class="article-summary-box-inner">
                                        <span>Information extraction from document images has received a lot of attention
recently, due to the need for digitizing a large volume of unstructured
documents such as invoices, receipts, bank transfers, etc. In this paper, we
propose a novel deep learning architecture for end-to-end information
extraction on the 2D character-grid embedding of the document, namely the
\textit{Multi-Stage Attentional U-Net}. To effectively capture the textual and
spatial relations between 2D elements, our model leverages a specialized
multi-stage encoder-decoders design, in conjunction with efficient uses of the
self-attention mechanism and the box convolution. Experimental results on
different datasets show that our model outperforms the baseline U-Net
architecture by a large margin while using 40\% fewer parameters. Moreover, it
also significantly improved the baseline in erroneous OCR and limited training
data scenario, thus becomes practical for real-world applications.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Weighting vectors for machine learning: numerical harmonic analysis applied to boundary detection. (arXiv:2106.00827v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bunch_E/0/1/0/all/0/1">Eric Bunch</a>, <a href="http://arxiv.org/find/cs/1/au:+Kline_J/0/1/0/all/0/1">Jeffery Kline</a>, <a href="http://arxiv.org/find/cs/1/au:+Dickinson_D/0/1/0/all/0/1">Daniel Dickinson</a>, <a href="http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1">Suhaas Bhat</a>, <a href="http://arxiv.org/find/cs/1/au:+Fung_G/0/1/0/all/0/1">Glenn Fung</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00827">
                                    <div class="article-summary-box-inner">
                                        <span>Metric space magnitude, an active field of research in algebraic topology, is
a scalar quantity that summarizes the effective number of distinct points that
live in a general metric space. The {\em weighting vector} is a closely-related
concept that captures, in a nontrivial way, much of the underlying geometry of
the original metric space. Recent work has demonstrated that when the metric
space is Euclidean, the weighting vector serves as an effective tool for
boundary detection. We recast this result and show the weighting vector may be
viewed as a solution to a kernelized SVM. As one consequence, we apply this new
insight to the task of outlier detection, and we demonstrate performance that
is competitive or exceeds performance of state-of-the-art techniques on
benchmark data sets. Under mild assumptions, we show the weighting vector,
which has computational cost of matrix inversion, can be efficiently
approximated in linear time. We show how nearest neighbor methods can
approximate solutions to the minimization problems defined by SVMs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">The Generalized Mean Densest Subgraph Problem. (arXiv:2106.00909v1 [cs.DS])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Veldt_N/0/1/0/all/0/1">Nate Veldt</a>, <a href="http://arxiv.org/find/cs/1/au:+Benson_A/0/1/0/all/0/1">Austin R. Benson</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1">Jon Kleinberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00909">
                                    <div class="article-summary-box-inner">
                                        <span>Finding dense subgraphs of a large graph is a standard problem in graph
mining that has been studied extensively both for its theoretical richness and
its many practical applications. In this paper we introduce a new family of
dense subgraph objectives, parameterized by a single parameter $p$, based on
computing generalized means of degree sequences of a subgraph. Our objective
captures both the standard densest subgraph problem and the maximum $k$-core as
special cases, and provides a way to interpolate between and extrapolate beyond
these two objectives when searching for other notions of dense subgraphs. In
terms of algorithmic contributions, we first show that our objective can be
minimized in polynomial time for all $p \geq 1$ using repeated submodular
minimization. A major contribution of our work is analyzing the performance of
different types of peeling algorithms for dense subgraphs both in theory and
practice. We prove that the standard peeling algorithm can perform arbitrarily
poorly on our generalized objective, but we then design a more sophisticated
peeling method which for $p \geq 1$ has an approximation guarantee that is
always at least $1/2$ and converges to 1 as $p \rightarrow \infty$. In
practice, we show that this algorithm obtains extremely good approximations to
the optimal solution, scales to large graphs, and highlights a range of
different meaningful notions of density on graphs coming from numerous domains.
Furthermore, it is typically able to approximate the densest subgraph problem
better than the standard peeling algorithm, by better accounting for how the
removal of one node affects other nodes in its neighborhood.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-aware placement optimization of UAV base stations via decentralized multi-agent Q-learning. (arXiv:2106.00845v1 [cs.MA])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Omoniwa_B/0/1/0/all/0/1">Babatunji Omoniwa</a>, <a href="http://arxiv.org/find/cs/1/au:+Galkin_B/0/1/0/all/0/1">Boris Galkin</a>, <a href="http://arxiv.org/find/cs/1/au:+Dusparic_I/0/1/0/all/0/1">Ivana Dusparic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00845">
                                    <div class="article-summary-box-inner">
                                        <span>Unmanned aerial vehicles serving as aerial base stations (UAV-BSs) can be
deployed to provide wireless connectivity to ground devices in events of
increased network demand, points-of-failure in existing infrastructure, or
disasters. However, it is challenging to conserve the energy of UAVs during
prolonged coverage tasks, considering their limited on-board battery capacity.
Reinforcement learning-based (RL) approaches have been previously used to
improve energy utilization of multiple UAVs, however, a central cloud
controller is assumed to have complete knowledge of the end-devices&#x27; locations,
i.e., the controller periodically scans and sends updates for UAV
decision-making. This assumption is impractical in dynamic network environments
with mobile ground devices. To address this problem, we propose a decentralized
Q-learning approach, where each UAV-BS is equipped with an autonomous agent
that maximizes the connectivity to ground devices while improving its energy
utilization. Experimental results show that the proposed design significantly
outperforms the centralized approaches in jointly maximizing the number of
connected ground devices and the energy utilization of the UAV-BSs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">GraphDF: A Discrete Flow Model for Molecular Graph Generation. (arXiv:2102.01189v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1">Youzhi Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Yan_K/0/1/0/all/0/1">Keqiang Yan</a>, <a href="http://arxiv.org/find/cs/1/au:+Ji_S/0/1/0/all/0/1">Shuiwang Ji</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.01189">
                                    <div class="article-summary-box-inner">
                                        <span>We consider the problem of molecular graph generation using deep models.
While graphs are discrete, most existing methods use continuous latent
variables, resulting in inaccurate modeling of discrete graph structures. In
this work, we propose GraphDF, a novel discrete latent variable model for
molecular graph generation based on normalizing flow methods. GraphDF uses
invertible modulo shift transforms to map discrete latent variables to graph
nodes and edges. We show that the use of discrete latent variables reduces
computational costs and eliminates the negative effect of dequantization.
Comprehensive experimental results show that GraphDF outperforms prior methods
on random generation, property optimization, and constrained optimization
tasks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">QLSD: Quantised Langevin stochastic dynamics for Bayesian federated learning. (arXiv:2106.00797v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vono_M/0/1/0/all/0/1">Maxime Vono</a>, <a href="http://arxiv.org/find/cs/1/au:+Plassier_V/0/1/0/all/0/1">Vincent Plassier</a>, <a href="http://arxiv.org/find/cs/1/au:+Durmus_A/0/1/0/all/0/1">Alain Durmus</a>, <a href="http://arxiv.org/find/cs/1/au:+Dieuleveut_A/0/1/0/all/0/1">Aymeric Dieuleveut</a>, <a href="http://arxiv.org/find/cs/1/au:+Moulines_E/0/1/0/all/0/1">Eric Moulines</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00797">
                                    <div class="article-summary-box-inner">
                                        <span>Federated learning aims at conducting inference when data are decentralised
and locally stored on several clients, under two main constraints: data
ownership and communication overhead. In this paper, we address these issues
under the Bayesian paradigm. To this end, we propose a novel Markov chain Monte
Carlo algorithm coined \texttt{QLSD} built upon quantised versions of
stochastic gradient Langevin dynamics. To improve performance in a big data
regime, we introduce variance-reduced alternatives of our methodology referred
to as \texttt{QLSD}$^\star$ and \texttt{QLSD}$^{++}$. We provide both
non-asymptotic and asymptotic convergence guarantees for the proposed
algorithms and illustrate their benefits on several federated learning
benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online and Real-Time Tracking in a Surveillance Scenario. (arXiv:2106.01153v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Urbann_O/0/1/0/all/0/1">Oliver Urbann</a>, <a href="http://arxiv.org/find/cs/1/au:+Bredtmann_O/0/1/0/all/0/1">Oliver Bredtmann</a>, <a href="http://arxiv.org/find/cs/1/au:+Otten_M/0/1/0/all/0/1">Maximilian Otten</a>, <a href="http://arxiv.org/find/cs/1/au:+Richter_J/0/1/0/all/0/1">Jan-Philip Richter</a>, <a href="http://arxiv.org/find/cs/1/au:+Bauer_T/0/1/0/all/0/1">Thilo Bauer</a>, <a href="http://arxiv.org/find/cs/1/au:+Zibriczky_D/0/1/0/all/0/1">David Zibriczky</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01153">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents an approach for tracking in a surveillance scenario.
Typical aspects for this scenario are a 24/7 operation with a static camera
mounted above the height of a human with many objects or people. The Multiple
Object Tracking Benchmark 20 (MOT20) reflects this scenario best. We can show
that our approach is real-time capable on this benchmark and outperforms all
other real-time capable approaches in HOTA, MOTA, and IDF1. We achieve this by
contributing a fast Siamese network reformulated for linear runtime (instead of
quadratic) to generate fingerprints from detections. Thus, it is possible to
associate the detections to Kalman filters based on multiple tracking specific
ratings: Cosine similarity of fingerprints, Intersection over Union, and pixel
distance ratio in the image.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Differentiable Point Process with Its Application to Spiking Neural Networks. (arXiv:2106.00901v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kajino_H/0/1/0/all/0/1">Hiroshi Kajino</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00901">
                                    <div class="article-summary-box-inner">
                                        <span>This paper is concerned about a learning algorithm for a probabilistic model
of spiking neural networks (SNNs). Jimenez Rezende &amp; Gerstner (2014) proposed a
stochastic variational inference algorithm to train SNNs with hidden neurons.
The algorithm updates the variational distribution using the score function
gradient estimator, whose high variance often impedes the whole learning
algorithm. This paper presents an alternative gradient estimator for SNNs based
on the path-wise gradient estimator. The main technical difficulty is a lack of
a general method to differentiate a realization of an arbitrary point process,
which is necessary to derive the path-wise gradient estimator. We develop a
differentiable point process, which is the technical highlight of this paper,
and apply it to derive the path-wise gradient estimator for SNNs. We
investigate the effectiveness of our gradient estimator through numerical
simulation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Prediction of the Position of External Markers Using a Recurrent Neural Network Trained With Unbiased Online Recurrent Optimization for Safe Lung Cancer Radiotherapy. (arXiv:2106.01100v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Pohl_M/0/1/0/all/0/1">Michel Pohl</a>, <a href="http://arxiv.org/find/eess/1/au:+Uesaka_M/0/1/0/all/0/1">Mitsuru Uesaka</a>, <a href="http://arxiv.org/find/eess/1/au:+Takahashi_H/0/1/0/all/0/1">Hiroyuki Takahashi</a>, <a href="http://arxiv.org/find/eess/1/au:+Demachi_K/0/1/0/all/0/1">Kazuyuki Demachi</a>, <a href="http://arxiv.org/find/eess/1/au:+Chhatkuli_R/0/1/0/all/0/1">Ritu Bhusal Chhatkuli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01100">
                                    <div class="article-summary-box-inner">
                                        <span>During lung cancer radiotherapy, the position of infrared reflective objects
on the chest can be recorded to estimate the tumor location. However,
radiotherapy systems usually have a latency inherent to robot control
limitations that impedes the radiation delivery precision. Not taking this
phenomenon into account may cause unwanted damage to healthy tissues and lead
to side effects such as radiation pneumonitis. In this research, we use nine
observation records of the three-dimensional position of three external markers
on the chest and abdomen of healthy individuals breathing during intervals from
73s to 222s. The sampling frequency is equal to 10Hz and the amplitudes of the
recorded trajectories range from 6mm to 40mm in the superior-inferior
direction. We forecast the location of each marker simultaneously with a
horizon value (the time interval in advance for which the prediction is made)
between 0.1s and 2.0s, using a recurrent neural network (RNN) trained with
unbiased online recurrent optimization (UORO). We compare its performance with
an RNN trained with real-time recurrent learning, least mean squares (LMS), and
offline linear regression. Training and cross-validation are performed during
the first minute of each sequence. On average, UORO achieves the lowest
root-mean-square (RMS) and maximum error, equal respectively to 1.3mm and
8.8mm, with a prediction time per time step lower than 2.8ms (Dell Intel core
i9-9900K 3.60Ghz). Linear regression has the lowest RMS error for the horizon
values 0.1s and 0.2s, followed by LMS for horizon values between 0.3s and 0.5s,
and UORO for horizon values greater than 0.6s.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">A Thorough View of Exact Inference in Graphs from the Degree-4 Sum-of-Squares Hierarchy. (arXiv:2102.08019v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bello_K/0/1/0/all/0/1">Kevin Bello</a>, <a href="http://arxiv.org/find/cs/1/au:+Ke_C/0/1/0/all/0/1">Chuyang Ke</a>, <a href="http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1">Jean Honorio</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08019">
                                    <div class="article-summary-box-inner">
                                        <span>Performing inference in graphs is a common task within several machine
learning problems, e.g., image segmentation, community detection, among others.
For a given undirected connected graph, we tackle the statistical problem of
exactly recovering an unknown ground-truth binary labeling of the nodes from a
single corrupted observation of each edge. Such problem can be formulated as a
quadratic combinatorial optimization problem over the boolean hypercube, where
it has been shown before that one can (with high probability and in polynomial
time) exactly recover the ground-truth labeling of graphs that have an
isoperimetric number that grows with respect to the number of nodes (e.g.,
complete graphs, regular expanders). In this work, we apply a powerful
hierarchy of relaxations, known as the sum-of-squares (SoS) hierarchy, to the
combinatorial problem. Motivated by empirical evidence on the improvement in
exact recoverability, we center our attention on the degree-4 SoS relaxation
and set out to understand the origin of such improvement from a graph
theoretical perspective. We show that the solution of the dual of the relaxed
problem is related to finding edge weights of the Johnson and Kneser graphs,
where the weights fulfill the SoS constraints and intuitively allow the input
graph to increase its algebraic connectivity. Finally, as byproduct of our
analysis, we derive a novel Cheeger-type lower bound for the algebraic
connectivity of graphs with signed edge weights.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enhanced Universal Dependency Parsing with Second-Order Inference and Mixture of Training Data. (arXiv:2006.01414v3 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.01414">
                                    <div class="article-summary-box-inner">
                                        <span>This paper presents the system used in our submission to the \textit{IWPT
2020 Shared Task}. Our system is a graph-based parser with second-order
inference. For the low-resource Tamil corpus, we specially mixed the training
data of Tamil with other languages and significantly improved the performance
of Tamil. Due to our misunderstanding of the submission requirements, we
submitted graphs that are not connected, which makes our system only rank
\textbf{6th} over 10 teams. However, after we fixed this problem, our system is
0.6 ELAS higher than the team that ranked \textbf{1st} in the official results.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning. (arXiv:2105.03654v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1">Yong Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Bach_N/0/1/0/all/0/1">Nguyen Bach</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1">Zhongqiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Huang_F/0/1/0/all/0/1">Fei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.03654">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances in Named Entity Recognition (NER) show that document-level
contexts can significantly improve model performance. In many application
scenarios, however, such contexts are not available. In this paper, we propose
to find external contexts of a sentence by retrieving and selecting a set of
semantically relevant texts through a search engine, with the original sentence
as the query. We find empirically that the contextual representations computed
on the retrieval-based input view, constructed through the concatenation of a
sentence and its external contexts, can achieve significantly improved
performance compared to the original input view based only on the sentence.
Furthermore, we can improve the model performance of both input views by
Cooperative Learning, a training method that encourages the two input views to
produce similar contextual representations or output label distributions.
Experiments show that our approach can achieve new state-of-the-art performance
on 8 NER data sets across 5 domains.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Parametrization invariant interpretation of priors and posteriors. (arXiv:2105.08304v2 [math.ST] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Cerquides_J/0/1/0/all/0/1">Jesus Cerquides</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.08304">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper we leverage on probability over Riemannian manifolds to rethink
the interpretation of priors and posteriors in Bayesian inference. The main
mindshift is to move away from the idea that &quot;a prior distribution establishes
a probability distribution over the parameters of our model&quot; to the idea that
&quot;a prior distribution establishes a probability distribution over probability
distributions&quot;. To do that we assume that our probabilistic model is a
Riemannian manifold with the Fisher metric. Under this mindset, any
distribution over probability distributions should be &quot;intrinsic&quot;, that is,
invariant to the specific parametrization which is selected for the manifold.
We exemplify our ideas through a simple analysis of distributions over the
manifold of Bernoulli distributions. One of the major shortcomings of maximum a
posteriori estimates is that they depend on the parametrization. Based on the
understanding developed here, we can define the maximum a posteriori estimate
which is independent of the parametrization.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deterministic Variational Inference for Neural SDEs. (arXiv:2006.08973v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Look_A/0/1/0/all/0/1">Andreas Look</a>, <a href="http://arxiv.org/find/cs/1/au:+Kandemir_M/0/1/0/all/0/1">Melih Kandemir</a>, <a href="http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1">Jan Peters</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2006.08973">
                                    <div class="article-summary-box-inner">
                                        <span>Neural Stochastic Differential Equations (NSDEs) model the drift and
diffusion functions of a stochastic process as neural networks. While NSDEs are
known to predict time series accurately, their uncertainty quantification
properties remain unexplored. Currently, there are no approximate inference
methods, which allow flexible models and provide at the same time high quality
uncertainty estimates at a reasonable computational cost. Existing SDE
inference methods either make overly restrictive assumptions, e.g. linearity,
or rely on Monte Carlo integration that requires many samples at prediction
time for reliable uncertainty quantification. However, many real-world safety
critical applications necessitate highly expressive models that can quantify
prediction uncertainty at affordable computational cost. We introduce a
variational inference scheme that approximates the posterior distribution of a
NSDE governing a latent state space by a deterministic chain of operations. We
approximate the intractable data fit term of the evidence lower bound by a
novel bidimensional moment matching algorithm: vertical along the neural net
layers and horizontal along the time direction. Our algorithm achieves
uncertainty calibration scores that can be matched by its sampling-based
counterparts only at significantly higher computation cost, while providing as
accurate forecasts on system dynamics.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Complex Momentum for Optimization in Games. (arXiv:2102.08431v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Lorraine_J/0/1/0/all/0/1">Jonathan Lorraine</a>, <a href="http://arxiv.org/find/cs/1/au:+Acuna_D/0/1/0/all/0/1">David Acuna</a>, <a href="http://arxiv.org/find/cs/1/au:+Vicol_P/0/1/0/all/0/1">Paul Vicol</a>, <a href="http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1">David Duvenaud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2102.08431">
                                    <div class="article-summary-box-inner">
                                        <span>We generalize gradient descent with momentum for optimization in
differentiable games to have complex-valued momentum. We give theoretical
motivation for our method by proving convergence on bilinear zero-sum games for
simultaneous and alternating updates. Our method gives real-valued parameter
updates, making it a drop-in replacement for standard optimizers. We
empirically demonstrate that complex-valued momentum can improve convergence in
realistic adversarial games - like generative adversarial networks - by showing
we can find better solutions with an almost identical computational cost. We
also show a practical generalization to a complex-valued Adam variant, which we
use to train BigGAN to better inception scores on CIFAR-10.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Multilayer Network Analysis for Improved Credit Risk Prediction. (arXiv:2010.09559v3 [cs.SI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Oskarsdottir_M/0/1/0/all/0/1">Mar&#xed;a &#xd3;skarsd&#xf3;ttir</a>, <a href="http://arxiv.org/find/cs/1/au:+Bravo_C/0/1/0/all/0/1">Cristi&#xe1;n Bravo</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.09559">
                                    <div class="article-summary-box-inner">
                                        <span>We present a multilayer network model for credit risk assessment. Our model
accounts for multiple connections between borrowers (such as their geographic
location and their economic activity) and allows for explicitly modelling the
interaction between connected borrowers. We develop a multilayer personalized
PageRank algorithm that allows quantifying the strength of the default exposure
of any borrower in the network. We test our methodology in an agricultural
lending framework, where it has been suspected for a long time default
correlates between borrowers when they are subject to the same structural
risks. Our results show there are significant predictive gains just by
including centrality multilayer network information in the model, and these
gains are increased by more complex information such as the multilayer PageRank
variables. The results suggest default risk is highest when an individual is
connected to many defaulters, but this risk is mitigated by the size of the
neighbourhood of the individual, showing both default risk and financial
stability propagate throughout the network.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Unsupervised Representation Learning for Time Series with Temporal Neighborhood Coding. (arXiv:2106.00750v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tonekaboni_S/0/1/0/all/0/1">Sana Tonekaboni</a>, <a href="http://arxiv.org/find/cs/1/au:+Eytan_D/0/1/0/all/0/1">Danny Eytan</a>, <a href="http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1">Anna Goldenberg</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00750">
                                    <div class="article-summary-box-inner">
                                        <span>Time series are often complex and rich in information but sparsely labeled
and therefore challenging to model. In this paper, we propose a self-supervised
framework for learning generalizable representations for non-stationary time
series. Our approach, called Temporal Neighborhood Coding (TNC), takes
advantage of the local smoothness of a signal&#x27;s generative process to define
neighborhoods in time with stationary properties. Using a debiased contrastive
objective, our framework learns time series representations by ensuring that in
the encoding space, the distribution of signals from within a neighborhood is
distinguishable from the distribution of non-neighboring signals. Our
motivation stems from the medical field, where the ability to model the dynamic
nature of time series data is especially valuable for identifying, tracking,
and predicting the underlying patients&#x27; latent states in settings where
labeling data is practically impossible. We compare our method to recently
developed unsupervised representation learning approaches and demonstrate
superior performance on clustering and classification tasks for multiple
datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Robustifying Algorithms of Learning Latent Trees with Vector Variables. (arXiv:2106.00885v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Zhang_F/0/1/0/all/0/1">Fengzhuo Zhang</a>, <a href="http://arxiv.org/find/stat/1/au:+Tan_V/0/1/0/all/0/1">Vincent Y. F. Tan</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00885">
                                    <div class="article-summary-box-inner">
                                        <span>We consider learning the structures of Gaussian latent tree models with
vector observations when a subset of them are arbitrarily corrupted. First, we
present the sample complexities of Recursive Grouping (RG) and Chow-Liu
Recursive Grouping (CLRG) without the assumption that the effective depth is
bounded in the number of observed nodes, significantly generalizing the results
in Choi et al. (2011). We show that Chow-Liu initialization in CLRG greatly
reduces the sample complexity of RG from being exponential in the diameter of
the tree to only logarithmic in the diameter for the hidden Markov model (HMM).
Second, we robustify RG, CLRG, Neighbor Joining (NJ) and Spectral NJ (SNJ) by
using the truncated inner product. These robustified algorithms can tolerate a
number of corruptions up to the square root of the number of clean samples.
Finally, we derive the first known instance-dependent impossibility result for
structure learning of latent trees. The optimalities of the robust version of
CLRG and NJ are verified by comparing their sample complexities and the
impossibility result.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Predicting trends in the quality of state-of-the-art neural networks without access to training or testing data. (arXiv:2002.06716v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Martin_C/0/1/0/all/0/1">Charles H. Martin</a>, <a href="http://arxiv.org/find/cs/1/au:+Tongsu/0/1/0/all/0/1">Tongsu</a> (Serena) <a href="http://arxiv.org/find/cs/1/au:+Peng/0/1/0/all/0/1">Peng</a>, <a href="http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1">Michael W. Mahoney</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2002.06716">
                                    <div class="article-summary-box-inner">
                                        <span>In many applications, one works with neural network models trained by someone
else. For such pretrained models, one may not have access to training data or
test data. Moreover, one may not know details about the model, e.g., the
specifics of the training data, the loss function, the hyperparameter values,
etc. Given one or many pretrained models, it is a challenge to say anything
about the expected performance or quality of the models. Here, we address this
challenge by providing a detailed meta-analysis of hundreds of
publicly-available pretrained models. We examine norm based capacity control
metrics as well as power law based metrics from the recently-developed Theory
of Heavy-Tailed Self Regularization. We find that norm based metrics correlate
well with reported test accuracies for well-trained models, but that they often
cannot distinguish well-trained versus poorly-trained models. We also find that
power law based metrics can do much better -- quantitatively better at
discriminating among series of well-trained models with a given architecture;
and qualitatively better at discriminating well-trained versus poorly-trained
models. These methods can be used to identify when a pretrained neural network
has problems that cannot be detected simply by examining training/test
accuracies.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Partial Wasserstein Covering. (arXiv:2106.00886v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kawano_K/0/1/0/all/0/1">Keisuke Kawano</a>, <a href="http://arxiv.org/find/cs/1/au:+Koide_S/0/1/0/all/0/1">Satoshi Koide</a>, <a href="http://arxiv.org/find/cs/1/au:+Otaki_K/0/1/0/all/0/1">Keisuke Otaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00886">
                                    <div class="article-summary-box-inner">
                                        <span>We consider a general task called partial Wasserstein covering with the goal
of emulating a large dataset (e.g., application dataset) using a small dataset
(e.g., development dataset) in terms of the empirical distribution by selecting
a small subset from a candidate dataset and adding it to the small dataset. We
model this task as a discrete optimization problem with partial Wasserstein
divergence as an objective function. Although this problem is NP-hard, we prove
that it has the submodular property, allowing us to use a greedy algorithm with
a 0.63 approximation. However, the greedy algorithm is still inefficient
because it requires linear programming for each objective function evaluation.
To overcome this difficulty, we propose quasi-greedy algorithms for
acceleration, which consist of a series of techniques such as sensitivity
analysis based on strong duality and the so-called $C$-transform in the optimal
transport field. Experimentally, we demonstrate that we can efficiently make
two datasets similar in terms of partial Wasserstein divergence, including
driving scene datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hyperdimensional Computing for Efficient Distributed Classification with Randomized Neural Networks. (arXiv:2106.00881v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Rosato_A/0/1/0/all/0/1">Antonello Rosato</a>, <a href="http://arxiv.org/find/cs/1/au:+Panella_M/0/1/0/all/0/1">Massimo Panella</a>, <a href="http://arxiv.org/find/cs/1/au:+Kleyko_D/0/1/0/all/0/1">Denis Kleyko</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00881">
                                    <div class="article-summary-box-inner">
                                        <span>In the supervised learning domain, considering the recent prevalence of
algorithms with high computational cost, the attention is steering towards
simpler, lighter, and less computationally extensive training and inference
approaches. In particular, randomized algorithms are currently having a
resurgence, given their generalized elementary approach. By using randomized
neural networks, we study distributed classification, which can be employed in
situations were data cannot be stored at a central location nor shared. We
propose a more efficient solution for distributed classification by making use
of a lossy compression approach applied when sharing the local classifiers with
other agents. This approach originates from the framework of hyperdimensional
computing, and is adapted herein. The results of experiments on a collection of
datasets demonstrate that the proposed approach has usually higher accuracy
than local classifiers and getting close to the benchmark - the centralized
classifier. This work can be considered as the first step towards analyzing the
variegated horizon of distributed randomized neural networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FedHealth 2: Weighted Federated Transfer Learning via Batch Normalization for Personalized Healthcare. (arXiv:2106.01009v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1">Yiqiang Chen</a>, <a href="http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1">Wang Lu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1">Jindong Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Qin_X/0/1/0/all/0/1">Xin Qin</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01009">
                                    <div class="article-summary-box-inner">
                                        <span>The success of machine learning applications often needs a large quantity of
data. Recently, federated learning (FL) is attracting increasing attention due
to the demand for data privacy and security, especially in the medical field.
However, the performance of existing FL approaches often deteriorates when
there exist domain shifts among clients, and few previous works focus on
personalization in healthcare. In this article, we propose FedHealth 2, an
extension of FedHealth \cite{chen2020fedhealth} to tackle domain shifts and get
personalized models for local clients. FedHealth 2 obtains the client
similarities via a pretrained model, and then it averages all weighted models
with preserving local batch normalization. Wearable activity recognition and
COVID-19 auxiliary diagnosis experiments have evaluated that FedHealth 2 can
achieve better accuracy (10%+ improvement for activity recognition) and
personalized healthcare without compromising privacy and security.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pricing Algorithmic Insurance. (arXiv:2106.00839v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Bertsimas_D/0/1/0/all/0/1">Dimitris Bertsimas</a>, <a href="http://arxiv.org/find/cs/1/au:+Orfanoudaki_A/0/1/0/all/0/1">Agni Orfanoudaki</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00839">
                                    <div class="article-summary-box-inner">
                                        <span>As machine learning algorithms start to get integrated into the
decision-making process of companies and organizations, insurance products will
be developed to protect their owners from risk. We introduce the concept of
algorithmic insurance and present a quantitative framework to enable the
pricing of the derived insurance contracts. We propose an optimization
formulation to estimate the risk exposure and price for a binary classification
model. Our approach outlines how properties of the model, such as accuracy,
interpretability and generalizability, can influence the insurance contract
evaluation. To showcase a practical implementation of the proposed framework,
we present a case study of medical malpractice in the context of breast cancer
detection. Our analysis focuses on measuring the effect of the model parameters
on the expected financial loss and identifying the aspects of algorithmic
performance that predominantly affect the price of the contract.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Large-Scale Wasserstein Gradient Flows. (arXiv:2106.00736v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Mokrov_P/0/1/0/all/0/1">Petr Mokrov</a>, <a href="http://arxiv.org/find/cs/1/au:+Korotin_A/0/1/0/all/0/1">Alexander Korotin</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1">Lingxiao Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Genevay_A/0/1/0/all/0/1">Aude Genevay</a>, <a href="http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1">Justin Solomon</a>, <a href="http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1">Evgeny Burnaev</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00736">
                                    <div class="article-summary-box-inner">
                                        <span>Wasserstein gradient flows provide a powerful means of understanding and
solving many diffusion equations. Specifically, Fokker-Planck equations, which
model the diffusion of probability measures, can be understood as gradient
descent over entropy functionals in Wasserstein space. This equivalence,
introduced by Jordan, Kinderlehrer and Otto, inspired the so-called JKO scheme
to approximate these diffusion processes via an implicit discretization of the
gradient flow in Wasserstein space. Solving the optimization problem associated
to each JKO step, however, presents serious computational challenges. We
introduce a scalable method to approximate Wasserstein gradient flows, targeted
to machine learning applications. Our approach relies on input-convex neural
networks (ICNNs) to discretize the JKO steps, which can be optimized by
stochastic gradient descent. Unlike previous work, our method does not require
domain discretization or particle simulation. As a result, we can sample from
the measure at each time step of the diffusion and compute its probability
density. We demonstrate our algorithm&#x27;s performance by computing diffusions
following the Fokker-Planck equation and apply it to unnormalized density
sampling as well as nonlinear filtering.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">FairBatch: Batch Selection for Model Fairness. (arXiv:2012.01696v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roh_Y/0/1/0/all/0/1">Yuji Roh</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1">Kangwook Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Whang_S/0/1/0/all/0/1">Steven Euijong Whang</a>, <a href="http://arxiv.org/find/cs/1/au:+Suh_C/0/1/0/all/0/1">Changho Suh</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.01696">
                                    <div class="article-summary-box-inner">
                                        <span>Training a fair machine learning model is essential to prevent demographic
disparity. Existing techniques for improving model fairness require broad
changes in either data preprocessing or model training, rendering themselves
difficult-to-adopt for potentially already complex machine learning systems. We
address this problem via the lens of bilevel optimization. While keeping the
standard training algorithm as an inner optimizer, we incorporate an outer
optimizer so as to equip the inner problem with an additional functionality:
Adaptively selecting minibatch sizes for the purpose of improving model
fairness. Our batch selection algorithm, which we call FairBatch, implements
this optimization and supports prominent fairness measures: equal opportunity,
equalized odds, and demographic parity. FairBatch comes with a significant
implementation benefit -- it does not require any modification to data
preprocessing or model training. For instance, a single-line change of PyTorch
code for replacing batch selection part of model training suffices to employ
FairBatch. Our experiments conducted both on synthetic and benchmark real data
demonstrate that FairBatch can provide such functionalities while achieving
comparable (or even greater) performances against the state of the arts.
Furthermore, FairBatch can readily improve fairness of any pre-trained model
simply via fine-tuning. It is also compatible with existing batch selection
techniques intended for different purposes, such as faster convergence, thus
gracefully achieving multiple purposes.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Neural message passing for joint paratope-epitope prediction. (arXiv:2106.00757v1 [q-bio.QM])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/q-bio/1/au:+Vecchio_A/0/1/0/all/0/1">Alice Del Vecchio</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Deac_A/0/1/0/all/0/1">Andreea Deac</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Lio_P/0/1/0/all/0/1">Pietro Li&#xf2;</a>, <a href="http://arxiv.org/find/q-bio/1/au:+Velickovic_P/0/1/0/all/0/1">Petar Veli&#x10d;kovi&#x107;</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00757">
                                    <div class="article-summary-box-inner">
                                        <span>Antibodies are proteins in the immune system which bind to antigens to detect
and neutralise them. The binding sites in an antibody-antigen interaction are
known as the paratope and epitope, respectively, and the prediction of these
regions is key to vaccine and synthetic antibody development. Contrary to prior
art, we argue that paratope and epitope predictors require asymmetric
treatment, and propose distinct neural message passing architectures that are
geared towards the specific aspects of paratope and epitope prediction,
respectively. We obtain significant improvements on both tasks, setting the new
state-of-the-art and recovering favourable qualitative predictions on antigens
of relevance to COVID-19.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Motif Prediction with Graph Neural Networks. (arXiv:2106.00761v1 [cs.SI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Besta_M/0/1/0/all/0/1">Maciej Besta</a>, <a href="http://arxiv.org/find/cs/1/au:+Grob_R/0/1/0/all/0/1">Raphael Grob</a>, <a href="http://arxiv.org/find/cs/1/au:+Miglioli_C/0/1/0/all/0/1">Cesare Miglioli</a>, <a href="http://arxiv.org/find/cs/1/au:+Bernold_N/0/1/0/all/0/1">Nicola Bernold</a>, <a href="http://arxiv.org/find/cs/1/au:+Kwasniewski_G/0/1/0/all/0/1">Grzegorz Kwasniewski</a>, <a href="http://arxiv.org/find/cs/1/au:+Gjini_G/0/1/0/all/0/1">Gabriel Gjini</a>, <a href="http://arxiv.org/find/cs/1/au:+Kanakagiri_R/0/1/0/all/0/1">Raghavendra Kanakagiri</a>, <a href="http://arxiv.org/find/cs/1/au:+Ashkboos_S/0/1/0/all/0/1">Saleh Ashkboos</a>, <a href="http://arxiv.org/find/cs/1/au:+Gianinazzi_L/0/1/0/all/0/1">Lukas Gianinazzi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dryden_N/0/1/0/all/0/1">Nikoli Dryden</a>, <a href="http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1">Torsten Hoefler</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00761">
                                    <div class="article-summary-box-inner">
                                        <span>Link prediction is one of the central problems in graph mining. However,
recent studies highlight the importance of the higher-order network analysis,
where complex structures called motifs are the first-class citizens. We
illustrate that existing link prediction schemes fail to predict the appearance
of complex motifs in graph data. To address this issue, we propose a general
motif prediction problem. We establish the theoretical foundation of motif
prediction and we propose several heuristics that, for a fixed set of nodes in
a graph and a specified motif, assess the chances for this motif to appear. To
make the scores realistic, our heuristics - among others - consider
correlations between links, i.e., the potential impact of some arriving links
on the appearance of other parts of a given motif. Finally, for highest
accuracy, we develop a graph neural network (GNN) architecture for motif
prediction. Our architecture offers vertex features and sampling schemes that
capture the rich structural properties of motifs. While our heuristics are fast
and do not need any training, using GNNs ensures highest accuracy when
predicting the arrival of complex graph structures, both dense (e.g.,
k-cliques) and sparse (e.g., k-stars). Importantly, its advantages over schemes
based on uncorrelated link prediction increase with the increasing motif size
and complexity. We also successfully apply our architecture for predicting more
arbitrary clusters and communities, illustrating its potential for graph mining
beyond motif analysis.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Part of Speech and Universal Dependency effects on English Arabic Machine Translation. (arXiv:2106.00745v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1">Omri Abend</a>, <a href="http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1">Leshem Choshen</a>, <a href="http://arxiv.org/find/cs/1/au:+Nikolaev_D/0/1/0/all/0/1">Dmitry Nikolaev</a>, <a href="http://arxiv.org/find/cs/1/au:+Rafaeli_O/0/1/0/all/0/1">Ofek Rafaeli</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00745">
                                    <div class="article-summary-box-inner">
                                        <span>In this research paper, I will elaborate on a method to evaluate machine
translation models based on their performance on underlying syntactical
phenomena between English and Arabic languages. This method is especially
important as such &quot;neural&quot; and &quot;machine learning&quot; are hard to fine-tune and
change. Thus, finding a way to evaluate them easily and diversely would greatly
help the task of bettering them.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Second-Order Neural Dependency Parsing with Message Passing and End-to-End Training. (arXiv:2010.05003v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinyu Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1">Kewei Tu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2010.05003">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose second-order graph-based neural dependency parsing
using message passing and end-to-end neural networks. We empirically show that
our approaches match the accuracy of very recent state-of-the-art second-order
graph-based neural dependency parsers and have significantly faster speed in
both training and testing. We also empirically show the advantage of
second-order parsing over first-order parsing and observe that the usefulness
of the head-selection structured constraint vanishes when using BERT embedding.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">PairRank: Online Pairwise Learning to Rank by Divide-and-Conquer. (arXiv:2103.00368v3 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1">Yiling Jia</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Huazheng Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1">Stephen Guo</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1">Hongning Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2103.00368">
                                    <div class="article-summary-box-inner">
                                        <span>Online Learning to Rank (OL2R) eliminates the need of explicit relevance
annotation by directly optimizing the rankers from their interactions with
users. However, the required exploration drives it away from successful
practices in offline learning to rank, which limits OL2R&#x27;s empirical
performance and practical applicability. In this work, we propose to estimate a
pairwise learning to rank model online. In each round, candidate documents are
partitioned and ranked according to the model&#x27;s confidence on the estimated
pairwise rank order, and exploration is only performed on the uncertain pairs
of documents, i.e., \emph{divide-and-conquer}. Regret directly defined on the
number of mis-ordered pairs is proven, which connects the online solution&#x27;s
theoretical convergence with its expected ranking performance. Comparisons
against an extensive list of OL2R baselines on two public learning to rank
benchmark datasets demonstrate the effectiveness of the proposed solution.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Making Pre-trained Language Models Better Few-shot Learners. (arXiv:2012.15723v2 [cs.CL] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1">Tianyu Gao</a>, <a href="http://arxiv.org/find/cs/1/au:+Fisch_A/0/1/0/all/0/1">Adam Fisch</a>, <a href="http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1">Danqi Chen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2012.15723">
                                    <div class="article-summary-box-inner">
                                        <span>The recent GPT-3 model (Brown et al., 2020) achieves remarkable few-shot
performance solely by leveraging a natural-language prompt and a few task
demonstrations as input context. Inspired by their findings, we study few-shot
learning in a more practical scenario, where we use smaller language models for
which fine-tuning is computationally efficient. We present LM-BFF--better
few-shot fine-tuning of language models--a suite of simple and complementary
techniques for fine-tuning language models on a small number of annotated
examples. Our approach includes (1) prompt-based fine-tuning together with a
novel pipeline for automating prompt generation; and (2) a refined strategy for
dynamically and selectively incorporating demonstrations into each context.
Finally, we present a systematic evaluation for analyzing few-shot performance
on a range of NLP tasks, including classification and regression. Our
experiments demonstrate that our methods combine to dramatically outperform
standard fine-tuning procedures in this low resource setting, achieving up to
30% absolute improvement, and 11% on average across all tasks. Our approach
makes minimal assumptions on task resources and domain expertise, and hence
constitutes a strong task-agnostic method for few-shot learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning neural network potentials from experimental data via Differentiable Trajectory Reweighting. (arXiv:2106.01138v1 [physics.chem-ph])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/physics/1/au:+Thaler_S/0/1/0/all/0/1">Stephan Thaler</a>, <a href="http://arxiv.org/find/physics/1/au:+Zavadlav_J/0/1/0/all/0/1">Julija Zavadlav</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01138">
                                    <div class="article-summary-box-inner">
                                        <span>In molecular dynamics (MD), neural network (NN) potentials trained bottom-up
on quantum mechanical data have seen tremendous success recently. Top-down
approaches that learn NN potentials directly from experimental data have
received less attention, typically facing numerical and computational
challenges when backpropagating through MD simulations. We present the
Differentiable Trajectory Reweighting (DiffTRe) method, which bypasses
differentiation through the MD simulation for time-independent observables.
Leveraging thermodynamic perturbation theory, we avoid exploding gradients and
achieve around 2 orders of magnitude speed-up in gradient computation for
top-down learning. We show effectiveness of DiffTRe in learning NN potentials
for an atomistic model of diamond and a coarse-grained model of water based on
diverse experimental observables including thermodynamic, structural and
mechanical properties. Importantly, DiffTRe also generalizes bottom-up
structural coarse-graining methods such as iterative Boltzmann inversion to
arbitrary potentials. The presented method constitutes an important milestone
towards enriching NN potentials with experimental data, particularly when
accurate bottom-up data is unavailable.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">ProSelfLC: Progressive Self Label Correction for Training Robust Deep Neural Networks. (arXiv:2005.03788v6 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1">Xinshao Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Hua_Y/0/1/0/all/0/1">Yang Hua</a>, <a href="http://arxiv.org/find/cs/1/au:+Kodirov_E/0/1/0/all/0/1">Elyor Kodirov</a>, <a href="http://arxiv.org/find/cs/1/au:+Clifton_D/0/1/0/all/0/1">David A. Clifton</a>, <a href="http://arxiv.org/find/cs/1/au:+Robertson_N/0/1/0/all/0/1">Neil M. Robertson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2005.03788">
                                    <div class="article-summary-box-inner">
                                        <span>To train robust deep neural networks (DNNs), we systematically study several
target modification approaches, which include output regularisation, self and
non-self label correction (LC). Two key issues are discovered: (1) Self LC is
the most appealing as it exploits its own knowledge and requires no extra
models. However, how to automatically decide the trust degree of a learner as
training goes is not well answered in the literature? (2) Some methods penalise
while the others reward low-entropy predictions, prompting us to ask which one
is better?

To resolve the first issue, taking two well-accepted propositions--deep
neural networks learn meaningful patterns before fitting noise [3] and minimum
entropy regularisation principle [10]--we propose a novel end-to-end method
named ProSelfLC, which is designed according to learning time and entropy.
Specifically, given a data point, we progressively increase trust in its
predicted label distribution versus its annotated one if a model has been
trained for enough time and the prediction is of low entropy (high confidence).
For the second issue, according to ProSelfLC, we empirically prove that it is
better to redefine a meaningful low-entropy status and optimise the learner
toward it. This serves as a defence of entropy minimisation.

We demonstrate the effectiveness of ProSelfLC through extensive experiments
in both clean and noisy settings. The source code is available at
https://github.com/XinshaoAmosWang/ProSelfLC-CVPR2021.

Keywords: entropy minimisation, maximum entropy, confidence penalty, self
knowledge distillation, label correction, label noise, semi-supervised
learning, output regularisation</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Semi-Supervised Empirical Risk Minimization: When can unlabeled data improve prediction?. (arXiv:2009.00606v3 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Yuval_O/0/1/0/all/0/1">Oren Yuval</a>, <a href="http://arxiv.org/find/stat/1/au:+Rosset_S/0/1/0/all/0/1">Saharon Rosset</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2009.00606">
                                    <div class="article-summary-box-inner">
                                        <span>We present a general methodology for using unlabeled data to design semi
supervised learning (SSL) variants of the Empirical Risk Minimization (ERM)
learning process. Focusing on generalized linear regression, we provide a
careful treatment of the effectiveness of the SSL to improve prediction
performance. The key ideas are carefully considering the null model as a
competitor, and utilizing the unlabeled data to determine signal-noise
combinations where the SSL outperforms both the ERM learning and the null
model. In the special case of linear regression with Gaussian covariates, we
show that the previously suggested semi-supervised estimator is in fact not
capable of improving on both the supervised estimator and the null model
simultaneously. However, the new estimator presented in this work, can achieve
an improvement of $O(1/n)$ term over both competitors simultaneously. On the
other hand, we show that in other scenarios, such as non-Gaussian covariates,
misspecified linear regression, or generalized linear regression with
non-linear link functions, having unlabeled data can derive substantial
improvement in practice by applying our suggested SSL approach. Moreover, it is
possible to identify the situations where SSL improves prediction, by using the
results we establish throughout this work. This is shown empirically through
extensive simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">BGC: Multi-Agent Group Belief with Graph Clustering. (arXiv:2008.08808v3 [cs.AI] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhou_T/0/1/0/all/0/1">Tianze Zhou</a>, <a href="http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1">Fubiao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1">Pan Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1">Chenfei Wang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2008.08808">
                                    <div class="article-summary-box-inner">
                                        <span>Recent advances have witnessed that value decomposed-based multi-agent
reinforcement learning methods make an efficient performance in coordination
tasks. Most current methods assume that agents can make communication to assist
decisions, which is impractical in some situations. In this paper, we propose a
semi-communication method to enable agents can exchange information without
communication. Specifically, we introduce a group concept to help agents
learning a belief which is a type of consensus. With this consensus, adjacent
agents tend to accomplish similar sub-tasks to achieve cooperation. We design a
novel agent structure named Belief in Graph Clustering(BGC), composed of an
agent characteristic module, a belief module, and a fusion module. To represent
each agent characteristic, we use an MLP-based characteristic module to
generate agent unique features. Inspired by the neighborhood cognitive
consistency, we propose a group-based module to divide adjacent agents into a
small group and minimize in-group agents&#x27; beliefs to accomplish similar
sub-tasks. Finally, we use a hyper-network to merge these features and produce
agent actions. To overcome the agent consistent problem brought by GAT, a split
loss is introduced to distinguish different agents. Results reveal that the
proposed method achieves a significant improvement in the SMAC benchmark.
Because of the group concept, our approach maintains excellent performance with
an increase in the number of agents.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Diffusion Schr\&quot;odinger Bridge with Applications to Score-Based Generative Modeling. (arXiv:2106.01357v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Bortoli_V/0/1/0/all/0/1">Valentin De Bortoli</a>, <a href="http://arxiv.org/find/stat/1/au:+Thornton_J/0/1/0/all/0/1">James Thornton</a>, <a href="http://arxiv.org/find/stat/1/au:+Heng_J/0/1/0/all/0/1">Jeremy Heng</a>, <a href="http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1">Arnaud Doucet</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01357">
                                    <div class="article-summary-box-inner">
                                        <span>Progressively applying Gaussian noise transforms complex data distributions
to approximately Gaussian. Reversing this dynamic defines a generative model.
When the forward noising process is given by a Stochastic Differential Equation
(SDE), Song et al. (2021) demonstrate how the time inhomogeneous drift of the
associated reverse-time SDE may be estimated using score-matching. A limitation
of this approach is that the forward-time SDE must be run for a sufficiently
long time for the final distribution to be approximately Gaussian. In contrast,
solving the Schr\&quot;odinger Bridge problem (SB), i.e. an entropy-regularized
optimal transport problem on path spaces, yields diffusions which generate
samples from the data distribution in finite time. We present Diffusion SB
(DSB), an original approximation of the Iterative Proportional Fitting (IPF)
procedure to solve the SB problem, and provide theoretical analysis along with
generative modeling experiments. The first DSB iteration recovers the
methodology proposed by Song et al. (2021), with the flexibility of using
shorter time intervals, as subsequent DSB iterations reduce the discrepancy
between the final-time marginal of the forward (resp. backward) SDE with
respect to the prior (resp. data) distribution. Beyond generative modeling, DSB
offers a widely applicable computational optimal transport tool as the
continuous state-space analogue of the popular Sinkhorn algorithm (Cuturi,
2013).</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On Efficiently Explaining Graph-Based Classifiers. (arXiv:2106.01350v1 [cs.AI])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1">Xuanxiang Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Izza_Y/0/1/0/all/0/1">Yacine Izza</a>, <a href="http://arxiv.org/find/cs/1/au:+Ignatiev_A/0/1/0/all/0/1">Alexey Ignatiev</a>, <a href="http://arxiv.org/find/cs/1/au:+Marques_Silva_J/0/1/0/all/0/1">Joao Marques-Silva</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01350">
                                    <div class="article-summary-box-inner">
                                        <span>Recent work has shown that not only decision trees (DTs) may not be
interpretable but also proposed a polynomial-time algorithm for computing one
PI-explanation of a DT. This paper shows that for a wide range of classifiers,
globally referred to as decision graphs, and which include decision trees and
binary decision diagrams, but also their multi-valued variants, there exist
polynomial-time algorithms for computing one PI-explanation. In addition, the
paper also proposes a polynomial-time algorithm for computing one contrastive
explanation. These novel algorithms build on explanation graphs (XpG&#x27;s). XpG&#x27;s
denote a graph representation that enables both theoretical and practically
efficient computation of explanations for decision graphs. Furthermore, the
paper pro- poses a practically efficient solution for the enumeration of
explanations, and studies the complexity of deciding whether a given feature is
included in some explanation. For the concrete case of decision trees, the
paper shows that the set of all contrastive explanations can be enumerated in
polynomial time. Finally, the experimental results validate the practical
applicability of the algorithms proposed in the paper on a wide range of
publicly available benchmarks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">On the Convergence Rate of Off-Policy Policy Optimization Methods with Density-Ratio Correction. (arXiv:2106.00993v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1">Jiawei Huang</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1">Nan Jiang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00993">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we study the convergence properties of off-policy policy
improvement algorithms with state-action density ratio correction under
function approximation setting, where the objective function is formulated as a
max-max-min optimization problem. We characterize the bias of the learning
objective and present two strategies with finite-time convergence guarantees.
In our first strategy, we present algorithm P-SREDA with convergence rate
$O(\epsilon^{-3})$, whose dependency on $\epsilon$ is optimal. In our second
strategy, we propose a new off-policy actor-critic style algorithm named
O-SPIM. We prove that O-SPIM converges to a stationary point with total
complexity $O(\epsilon^{-4})$, which matches the convergence rate of some
recent actor-critic algorithms in the on-policy setting.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">How Good is SGD with Random Shuffling?. (arXiv:1908.00045v4 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Safran_I/0/1/0/all/0/1">Itay Safran</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1">Ohad Shamir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/1908.00045">
                                    <div class="article-summary-box-inner">
                                        <span>We study the performance of stochastic gradient descent (SGD) on smooth and
strongly-convex finite-sum optimization problems. In contrast to the majority
of existing theoretical works, which assume that individual functions are
sampled with replacement, we focus here on popular but poorly-understood
heuristics, which involve going over random permutations of the individual
functions. This setting has been investigated in several recent works, but the
optimal error rates remain unclear. In this paper, we provide lower bounds on
the expected optimization error with these heuristics (using SGD with any
constant step size), which elucidate their advantages and disadvantages. In
particular, we prove that after $k$ passes over $n$ individual functions, if
the functions are re-shuffled after every pass, the best possible optimization
error for SGD is at least $\Omega\left(1/(nk)^2+1/nk^3\right)$, which partially
corresponds to recently derived upper bounds. Moreover, if the functions are
only shuffled once, then the lower bound increases to $\Omega(1/nk^2)$. Since
there are strictly smaller upper bounds for repeated reshuffling, this proves
an inherent performance gap between SGD with single shuffling and repeated
shuffling. As a more minor contribution, we also provide a non-asymptotic
$\Omega(1/k^2)$ lower bound (independent of $n$) for the incremental gradient
method, when no random shuffling takes place. Finally, we provide an indication
that our lower bounds are tight, by proving matching upper bounds for
univariate quadratic functions.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Decision-making Oriented Clustering: Application to Pricing and Power Consumption Scheduling. (arXiv:2106.01021v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1">Chao Zhang</a>, <a href="http://arxiv.org/find/cs/1/au:+Lasaulce_S/0/1/0/all/0/1">Samson Lasaulce</a>, <a href="http://arxiv.org/find/cs/1/au:+Hennebel_M/0/1/0/all/0/1">Martin Hennebel</a>, <a href="http://arxiv.org/find/cs/1/au:+Saludjian_L/0/1/0/all/0/1">Lucas Saludjian</a>, <a href="http://arxiv.org/find/cs/1/au:+Panciatici_P/0/1/0/all/0/1">Patrick Panciatici</a>, <a href="http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1">H. Vincent Poor</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01021">
                                    <div class="article-summary-box-inner">
                                        <span>Data clustering is an instrumental tool in the area of energy resource
management. One problem with conventional clustering is that it does not take
the final use of the clustered data into account, which may lead to a very
suboptimal use of energy or computational resources. When clustered data are
used by a decision-making entity, it turns out that significant gains can be
obtained by tailoring the clustering scheme to the final task performed by the
decision-making entity. The key to having good final performance is to
automatically extract the important attributes of the data space that are
inherently relevant to the subsequent decision-making entity, and partition the
data space based on these attributes instead of partitioning the data space
based on predefined conventional metrics. For this purpose, we formulate the
framework of decision-making oriented clustering and propose an algorithm
providing a decision-based partition of the data space and good representative
decisions. By applying this novel framework and algorithm to a typical problem
of real-time pricing and that of power consumption scheduling, we obtain
several insightful analytical results such as the expression of the best
representative price profiles for real-time pricing and a very significant
reduction in terms of required clusters to perform power consumption scheduling
as shown by our simulations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Energy-Efficient Model Compression and Splitting for Collaborative Inference Over Time-Varying Channels. (arXiv:2106.00995v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Krouka_M/0/1/0/all/0/1">Mounssif Krouka</a>, <a href="http://arxiv.org/find/cs/1/au:+Elgabli_A/0/1/0/all/0/1">Anis Elgabli</a>, <a href="http://arxiv.org/find/cs/1/au:+Issaid_C/0/1/0/all/0/1">Chaouki Ben Issaid</a>, <a href="http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1">Mehdi Bennis</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00995">
                                    <div class="article-summary-box-inner">
                                        <span>Today&#x27;s intelligent applications can achieve high performance accuracy using
machine learning (ML) techniques, such as deep neural networks (DNNs).
Traditionally, in a remote DNN inference problem, an edge device transmits raw
data to a remote node that performs the inference task. However, this may incur
high transmission energy costs and puts data privacy at risk. In this paper, we
propose a technique to reduce the total energy bill at the edge device by
utilizing model compression and time-varying model split between the edge and
remote nodes. The time-varying representation accounts for time-varying
channels and can significantly reduce the total energy at the edge device while
maintaining high accuracy (low loss). We implement our approach in an image
classification task using the MNIST dataset, and the system environment is
simulated as a trajectory navigation scenario to emulate different channel
conditions. Numerical simulations show that our proposed solution results in
minimal energy consumption and $CO_2$ emission compared to the considered
baselines while exhibiting robust performance across different channel
conditions and bandwidth regime choices.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">JUMBO: Scalable Multi-task Bayesian Optimization using Offline Data. (arXiv:2106.00942v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hakhamaneshi_K/0/1/0/all/0/1">Kourosh Hakhamaneshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1">Pieter Abbeel</a>, <a href="http://arxiv.org/find/cs/1/au:+Stojanovic_V/0/1/0/all/0/1">Vladimir Stojanovic</a>, <a href="http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1">Aditya Grover</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00942">
                                    <div class="article-summary-box-inner">
                                        <span>The goal of Multi-task Bayesian Optimization (MBO) is to minimize the number
of queries required to accurately optimize a target black-box function, given
access to offline evaluations of other auxiliary functions. When offline
datasets are large, the scalability of prior approaches comes at the expense of
expressivity and inference quality. We propose JUMBO, an MBO algorithm that
sidesteps these limitations by querying additional data based on a combination
of acquisition signals derived from training two Gaussian Processes (GP): a
cold-GP operating directly in the input domain and a warm-GP that operates in
the feature space of a deep neural network pretrained using the offline data.
Such a decomposition can dynamically control the reliability of information
derived from the online and offline data and the use of pretrained neural
networks permits scalability to large offline datasets. Theoretically, we
derive regret bounds for JUMBO and show that it achieves no-regret under
conditions analogous to GP-UCB (Srinivas et. al. 2010). Empirically, we
demonstrate significant performance improvements over existing approaches on
two real-world optimization problems: hyper-parameter optimization and
automated circuit design.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Hybrid Ensemble optimized algorithm based on Genetic Programming for imbalanced data classification. (arXiv:2106.01176v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Roknizadeh_M/0/1/0/all/0/1">Maliheh Roknizadeh</a>, <a href="http://arxiv.org/find/cs/1/au:+Naeen_H/0/1/0/all/0/1">Hossein Monshizadeh Naeen</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01176">
                                    <div class="article-summary-box-inner">
                                        <span>One of the most significant current discussions in the field of data mining
is classifying imbalanced data. In recent years, several ways are proposed such
as algorithm level (internal) approaches, data level (external) techniques, and
cost-sensitive methods. Although extensive research has been carried out on
imbalanced data classification, however, several unsolved challenges remain
such as no attention to the importance of samples to balance, determine the
appropriate number of classifiers, and no optimization of classifiers in the
combination of classifiers. The purpose of this paper is to improve the
efficiency of the ensemble method in the sampling of training data sets,
especially in the minority class, and to determine better basic classifiers for
combining classifiers than existing methods. We proposed a hybrid ensemble
algorithm based on Genetic Programming (GP) for two classes of imbalanced data
classification. In this study uses historical data from UCI Machine Learning
Repository to assess minority classes in imbalanced datasets. The performance
of our proposed algorithm is evaluated by Rapid-miner studio v.7.5.
Experimental results show the performance of the proposed method on the
specified data sets in the size of the training set shows 40% and 50% better
accuracy than other dimensions of the minority class prediction.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">multiPRover: Generating Multiple Proofs for Improved Interpretability in Rule Reasoning. (arXiv:2106.01354v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1">Swarnadeep Saha</a>, <a href="http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1">Prateek Yadav</a>, <a href="http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1">Mohit Bansal</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01354">
                                    <div class="article-summary-box-inner">
                                        <span>We focus on a type of linguistic formal reasoning where the goal is to reason
over explicit knowledge in the form of natural language facts and rules (Clark
et al., 2020). A recent work, named PRover (Saha et al., 2020), performs such
reasoning by answering a question and also generating a proof graph that
explains the answer. However, compositional reasoning is not always unique and
there may be multiple ways of reaching the correct answer. Thus, in our work,
we address a new and challenging problem of generating multiple proof graphs
for reasoning over natural language rule-bases. Each proof provides a different
rationale for the answer, thereby improving the interpretability of such
reasoning systems. In order to jointly learn from all proof graphs and exploit
the correlations between multiple proofs for a question, we pose this task as a
set generation problem over structured output spaces where each proof is
represented as a directed graph. We propose two variants of a proof-set
generation model, multiPRover. Our first model, Multilabel-multiPRover,
generates a set of proofs via multi-label classification and implicit
conditioning between the proofs; while the second model, Iterative-multiPRover,
generates proofs iteratively by explicitly conditioning on the previously
generated proofs. Experiments on multiple synthetic, zero-shot, and
human-paraphrased datasets reveal that both multiPRover models significantly
outperform PRover on datasets containing multiple gold proofs.
Iterative-multiPRover obtains state-of-the-art proof F1 in zero-shot scenarios
where all examples have single correct proofs. It also generalizes better to
questions requiring higher depths of reasoning where multiple proofs are more
frequent. Our code and models are publicly available at
https://github.com/swarnaHub/multiPRover</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Latent Space Refinement for Deep Generative Models. (arXiv:2106.00792v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Winterhalder_R/0/1/0/all/0/1">Ramon Winterhalder</a>, <a href="http://arxiv.org/find/stat/1/au:+Bellagente_M/0/1/0/all/0/1">Marco Bellagente</a>, <a href="http://arxiv.org/find/stat/1/au:+Nachman_B/0/1/0/all/0/1">Benjamin Nachman</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00792">
                                    <div class="article-summary-box-inner">
                                        <span>Deep generative models are becoming widely used across science and industry
for a variety of purposes. A common challenge is achieving a precise implicit
or explicit representation of the data probability density. Recent proposals
have suggested using classifier weights to refine the learned density of deep
generative models. We extend this idea to all types of generative models and
show how latent space refinement via iterated generative modeling can
circumvent topological obstructions and improve precision. This methodology
also applies to cases were the target model is non-differentiable and has many
internal latent dimensions which must be marginalized over before refinement.
We demonstrate our Latent Space Refinement (LaSeR) protocol on a variety of
examples, focusing on the combinations of Normalizing Flows and Generative
Adversarial Networks.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Leveraging Pre-Images to Discover Nonlinear Relationships in Multivariate Environments. (arXiv:2106.00842v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vosoughi_M/0/1/0/all/0/1">M. Ali Vosoughi</a>, <a href="http://arxiv.org/find/cs/1/au:+Wismuller_A/0/1/0/all/0/1">Axel Wismuller</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00842">
                                    <div class="article-summary-box-inner">
                                        <span>Causal discovery, beyond the inference of a network as a collection of
connected dots, offers a crucial functionality in scientific discovery using
artificial intelligence. The questions that arise in multiple domains, such as
physics, physiology, the strategic decision in uncertain environments with
multiple agents, climatology, among many others, have roots in causality and
reasoning. It became apparent that many real-world temporal observations are
nonlinearly related to each other. While the number of observations can be as
high as millions of points, the number of temporal samples can be minimal due
to ethical or practical reasons, leading to the curse-of-dimensionality in
large-scale systems. This paper proposes a novel method using kernel principal
component analysis and pre-images to obtain nonlinear dependencies of
multivariate time-series data. We show that our method outperforms
state-of-the-art causal discovery methods when the observations are restricted
by time and are nonlinearly related. Extensive simulations on both real-world
and synthetic datasets with various topologies are provided to evaluate our
proposed methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Connections and Equivalences between the Nystr\&quot;om Method and Sparse Variational Gaussian Processes. (arXiv:2106.01121v1 [stat.ML])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wild_V/0/1/0/all/0/1">Veit Wild</a>, <a href="http://arxiv.org/find/stat/1/au:+Kanagawa_M/0/1/0/all/0/1">Motonobu Kanagawa</a>, <a href="http://arxiv.org/find/stat/1/au:+Sejdinovic_D/0/1/0/all/0/1">Dino Sejdinovic</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01121">
                                    <div class="article-summary-box-inner">
                                        <span>We investigate the connections between sparse approximation methods for
making kernel methods and Gaussian processes (GPs) scalable to massive data,
focusing on the Nystr\&quot;om method and the Sparse Variational Gaussian Processes
(SVGP). While sparse approximation methods for GPs and kernel methods share
some algebraic similarities, the literature lacks a deep understanding of how
and why they are related. This is a possible obstacle for the communications
between the GP and kernel communities, making it difficult to transfer results
from one side to the other. Our motivation is to remove this possible obstacle,
by clarifying the connections between the sparse approximations for GPs and
kernel methods. In this work, we study the two popular approaches, the
Nystr\&quot;om and SVGP approximations, in the context of a regression problem, and
establish various connections and equivalences between them. In particular, we
provide an RKHS interpretation of the SVGP approximation, and show that the
Evidence Lower Bound of the SVGP contains the objective function of the
Nystr\&quot;om approximation, revealing the origin of the algebraic equivalence
between the two approaches. We also study recently established convergence
results for the SVGP and how they are related to the approximation quality of
the Nystr\&quot;om method.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Uncertainty Characteristics Curves: A Systematic Assessment of Prediction Intervals. (arXiv:2106.00858v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Navratil_J/0/1/0/all/0/1">Jiri Navratil</a>, <a href="http://arxiv.org/find/cs/1/au:+Elder_B/0/1/0/all/0/1">Benjamin Elder</a>, <a href="http://arxiv.org/find/cs/1/au:+Arnold_M/0/1/0/all/0/1">Matthew Arnold</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1">Soumya Ghosh</a>, <a href="http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1">Prasanna Sattigeri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00858">
                                    <div class="article-summary-box-inner">
                                        <span>Accurate quantification of model uncertainty has long been recognized as a
fundamental requirement for trusted AI. In regression tasks, uncertainty is
typically quantified using prediction intervals calibrated to a specific
operating point, making evaluation and comparison across different studies
difficult. Our work leverages: (1) the concept of operating characteristics
curves and (2) the notion of a gain over a simple reference, to derive a novel
operating point agnostic assessment methodology for prediction intervals. The
paper describes the corresponding algorithm, provides a theoretical analysis,
and demonstrates its utility in multiple scenarios. We argue that the proposed
method addresses the current need for comprehensive assessment of prediction
intervals and thus represents a valuable addition to the uncertainty
quantification toolbox.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">DialoGraph: Incorporating Interpretable Strategy-Graph Networks into Negotiation Dialogues. (arXiv:2106.00920v1 [cs.CL])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Joshi_R/0/1/0/all/0/1">Rishabh Joshi</a>, <a href="http://arxiv.org/find/cs/1/au:+Balachandran_V/0/1/0/all/0/1">Vidhisha Balachandran</a>, <a href="http://arxiv.org/find/cs/1/au:+Vashishth_S/0/1/0/all/0/1">Shikhar Vashishth</a>, <a href="http://arxiv.org/find/cs/1/au:+Black_A/0/1/0/all/0/1">Alan Black</a>, <a href="http://arxiv.org/find/cs/1/au:+Tsvetkov_Y/0/1/0/all/0/1">Yulia Tsvetkov</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00920">
                                    <div class="article-summary-box-inner">
                                        <span>To successfully negotiate a deal, it is not enough to communicate fluently:
pragmatic planning of persuasive negotiation strategies is essential. While
modern dialogue agents excel at generating fluent sentences, they still lack
pragmatic grounding and cannot reason strategically. We present DialoGraph, a
negotiation system that incorporates pragmatic strategies in a negotiation
dialogue using graph neural networks. DialoGraph explicitly incorporates
dependencies between sequences of strategies to enable improved and
interpretable prediction of next optimal strategies, given the dialogue
context. Our graph-based method outperforms prior state-of-the-art negotiation
models both in the accuracy of strategy/dialogue act prediction and in the
quality of downstream dialogue response generation. We qualitatively show
further benefits of learned strategy-graphs in providing explicit associations
between effective negotiation strategies over the course of the dialogue,
leading to interpretable and strategic dialogues.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Empirical Comparison of Off-policy Prediction Learning Algorithms on the Collision Task. (arXiv:2106.00922v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1">Sina Ghiassian</a>, <a href="http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1">Richard S. Sutton</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00922">
                                    <div class="article-summary-box-inner">
                                        <span>Off-policy prediction -- learning the value function for one policy from data
generated while following another policy -- is one of the most challenging
subproblems in reinforcement learning. This paper presents empirical results
with eleven prominent off-policy learning algorithms that use linear function
approximation: five Gradient-TD methods, two Emphatic-TD methods, Off-policy
TD($\lambda$), Vtrace, and versions of Tree Backup and ABQ modified to apply to
a prediction setting. Our experiments used the Collision task, a small
idealized off-policy problem analogous to that of an autonomous car trying to
predict whether it will collide with an obstacle. We assessed the performance
of the algorithms according to their learning rate, asymptotic error level, and
sensitivity to step-size and bootstrapping parameters. By these measures, the
eleven algorithms can be partially ordered on the Collision task. In the top
tier, the two Emphatic-TD algorithms learned the fastest, reached the lowest
errors, and were robust to parameter settings. In the middle tier, the five
Gradient-TD algorithms and Off-policy TD($\lambda$) were more sensitive to the
bootstrapping parameter. The bottom tier comprised Vtrace, Tree Backup, and
ABQ; these algorithms were no faster and had higher asymptotic error than the
others. Our results are definitive for this task, though of course experiments
with more tasks are needed before an overall assessment of the algorithms&#x27;
merits can be made.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sharp bounds for the number of regions of maxout networks and vertices of Minkowski sums. (arXiv:2104.08135v1 [math.CO] CROSS LISTED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/math/1/au:+Montufar_G/0/1/0/all/0/1">Guido Mont&#xfa;far</a>, <a href="http://arxiv.org/find/math/1/au:+Ren_Y/0/1/0/all/0/1">Yue Ren</a>, <a href="http://arxiv.org/find/math/1/au:+Zhang_L/0/1/0/all/0/1">Leon Zhang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2104.08135">
                                    <div class="article-summary-box-inner">
                                        <span>We present results on the number of linear regions of the functions that can
be represented by artificial feedforward neural networks with maxout units. A
rank-k maxout unit is a function computing the maximum of $k$ linear functions.
For networks with a single layer of maxout units, the linear regions correspond
to the upper vertices of a Minkowski sum of polytopes. We obtain face counting
formulas in terms of the intersection posets of tropical hypersurfaces or the
number of upper faces of partial Minkowski sums, along with explicit sharp
upper bounds for the number of regions for any input dimension, any number of
units, and any ranks, in the cases with and without biases. Based on these
results we also obtain asymptotically sharp upper bounds for networks with
multiple layers.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An End-to-End Framework for Molecular Conformation Generation via Bilevel Programming. (arXiv:2105.07246v2 [cs.LG] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1">Minkai Xu</a>, <a href="http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1">Wujie Wang</a>, <a href="http://arxiv.org/find/cs/1/au:+Luo_S/0/1/0/all/0/1">Shitong Luo</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_C/0/1/0/all/0/1">Chence Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1">Yoshua Bengio</a>, <a href="http://arxiv.org/find/cs/1/au:+Gomez_Bombarelli_R/0/1/0/all/0/1">Rafael Gomez-Bombarelli</a>, <a href="http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1">Jian Tang</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2105.07246">
                                    <div class="article-summary-box-inner">
                                        <span>Predicting molecular conformations (or 3D structures) from molecular graphs
is a fundamental problem in many applications. Most existing approaches are
usually divided into two steps by first predicting the distances between atoms
and then generating a 3D structure through optimizing a distance geometry
problem. However, the distances predicted with such two-stage approaches may
not be able to consistently preserve the geometry of local atomic
neighborhoods, making the generated structures unsatisfying. In this paper, we
propose an end-to-end solution for molecular conformation prediction called
ConfVAE based on the conditional variational autoencoder framework.
Specifically, the molecular graph is first encoded in a latent space, and then
the 3D structures are generated by solving a principled bilevel optimization
program. Extensive experiments on several benchmark data sets prove the
effectiveness of our proposed approach over existing state-of-the-art
approaches. Code is available at
\url{https://github.com/MinkaiXu/ConfVAE-ICML21}.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Pathwise Conditioning of Gaussian Processes. (arXiv:2011.04026v2 [stat.ML] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/stat/1/au:+Wilson_J/0/1/0/all/0/1">James T. Wilson</a>, <a href="http://arxiv.org/find/stat/1/au:+Borovitskiy_V/0/1/0/all/0/1">Viacheslav Borovitskiy</a>, <a href="http://arxiv.org/find/stat/1/au:+Terenin_A/0/1/0/all/0/1">Alexander Terenin</a>, <a href="http://arxiv.org/find/stat/1/au:+Mostowsky_P/0/1/0/all/0/1">Peter Mostowsky</a>, <a href="http://arxiv.org/find/stat/1/au:+Deisenroth_M/0/1/0/all/0/1">Marc Peter Deisenroth</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.04026">
                                    <div class="article-summary-box-inner">
                                        <span>As Gaussian processes are used to answer increasingly complex questions,
analytic solutions become scarcer and scarcer. Monte Carlo methods act as a
convenient bridge for connecting intractable mathematical expressions with
actionable estimates via sampling. Conventional approaches for simulating
Gaussian process posteriors view samples as draws from marginal distributions
of process values at finite sets of input locations. This distribution-centric
characterization leads to generative strategies that scale cubically in the
size of the desired random vector. These methods are prohibitively expensive in
cases where we would, ideally, like to draw high-dimensional vectors or even
continuous sample paths. In this work, we investigate a different line of
reasoning: rather than focusing on distributions, we articulate Gaussian
conditionals at the level of random variables. We show how this pathwise
interpretation of conditioning gives rise to a general family of approximations
that lend themselves to efficiently sampling Gaussian process posteriors.
Starting from first principles, we derive these methods and analyze the
approximation errors they introduce. We, then, ground these results by
exploring the practical implications of pathwise conditioning in various
applied settings, such as global optimization and reinforcement learning.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Learning a Single Neuron with Bias Using Gradient Descent. (arXiv:2106.01101v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Vardi_G/0/1/0/all/0/1">Gal Vardi</a>, <a href="http://arxiv.org/find/cs/1/au:+Yehudai_G/0/1/0/all/0/1">Gilad Yehudai</a>, <a href="http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1">Ohad Shamir</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01101">
                                    <div class="article-summary-box-inner">
                                        <span>We theoretically study the fundamental problem of learning a single neuron
with a bias term ($\mathbf{x} \mapsto \sigma( + b)$) in
the realizable setting with the ReLU activation, using gradient descent.
Perhaps surprisingly, we show that this is a significantly different and more
challenging problem than the bias-less case (which was the focus of previous
works on single neurons), both in terms of the optimization geometry as well as
the ability of gradient methods to succeed in some scenarios. We provide a
detailed study of this problem, characterizing the critical points of the
objective, demonstrating failure cases, and providing positive convergence
guarantees under different sets of assumptions. To prove our results, we
develop some tools which may be of independent interest, and improve previous
results on learning single neurons.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Reinforcement Learning-based UAV Navigation and Control: A Soft Actor-Critic with Hindsight Experience Replay Approach. (arXiv:2106.01016v1 [eess.SY])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Lee_M/0/1/0/all/0/1">Myoung Hoon Lee</a>, <a href="http://arxiv.org/find/eess/1/au:+Moon_J/0/1/0/all/0/1">Jun Moon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01016">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose SACHER (soft actor-critic (SAC) with hindsight
experience replay (HER)), which constitutes a class of deep reinforcement
learning (DRL) algorithms. SAC is known as an off-policy model-free DRL
algorithm based on the maximum entropy framework, which outperforms earlier DRL
algorithms in terms of exploration, robustness and learning performance.
However, in SAC, maximizing the entropy-augmented objective may degrade the
optimality of the learning outcomes. HER is known as a sample-efficient replay
method that enhances the performance of off-policy DRL algorithms by allowing
them to learn from both failures and successes. We apply HER to SAC and propose
SACHER to improve the learning performance of SAC. More precisely, SACHER
achieves the desired optimal outcomes faster and more accurately than SAC,
since HER improves the sample efficiency of SAC. We apply SACHER to the
navigation and control problem of unmanned aerial vehicles (UAVs), where SACHER
generates the optimal navigation path of the UAV under various obstacles in
operation. Specifically, we show the effectiveness of SACHER in terms of the
tracking error and cumulative reward in UAV operation by comparing them with
those of state-of-the-art DRL algorithms, SAC and DDPG. Note that SACHER in UAV
navigation and control problems can be applied to arbitrary models of UAVs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Fair-Net: A Network Architecture For Reducing Performance Disparity Between Identifiable Sub-Populations. (arXiv:2106.00720v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Datta_A/0/1/0/all/0/1">Arghya Datta</a>, <a href="http://arxiv.org/find/cs/1/au:+Swamidass_S/0/1/0/all/0/1">S. Joshua Swamidass</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00720">
                                    <div class="article-summary-box-inner">
                                        <span>In real world datasets, particular groups are under-represented, much rarer
than others, and machine learning classifiers will often preform worse on
under-represented populations. This problem is aggravated across many domains
where datasets are class imbalanced, with a minority class far rarer than the
majority class. Naive approaches to handle under-representation and class
imbalance include training sub-population specific classifiers that handle
class imbalance or training a global classifier that overlooks sub-population
disparities and aims to achieve high overall accuracy by handling class
imbalance. In this study, we find that these approaches are vulnerable in class
imbalanced datasets with minority sub-populations. We introduced Fair-Net, a
branched multitask neural network architecture that improves both
classification accuracy and probability calibration across identifiable
sub-populations in class imbalanced datasets. Fair-Nets is a straightforward
extension to the output layer and error function of a network, so can be
incorporated in far more complex architectures. Empirical studies with three
real world benchmark datasets demonstrate that Fair-Net improves classification
and calibration performance, substantially reducing performance disparity
between gender and racial sub-populations.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Enabling Efficiency-Precision Trade-offs for Label Trees in Extreme Classification. (arXiv:2106.00730v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Baharav_T/0/1/0/all/0/1">Tavor Z. Baharav</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_D/0/1/0/all/0/1">Daniel L. Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Kolluri_K/0/1/0/all/0/1">Kedarnath Kolluri</a>, <a href="http://arxiv.org/find/cs/1/au:+Sanghavi_S/0/1/0/all/0/1">Sujay Sanghavi</a>, <a href="http://arxiv.org/find/cs/1/au:+Dhillon_I/0/1/0/all/0/1">Inderjit S. Dhillon</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00730">
                                    <div class="article-summary-box-inner">
                                        <span>Extreme multi-label classification (XMC) aims to learn a model that can tag
data points with a subset of relevant labels from an extremely large label set.
Real world e-commerce applications like personalized recommendations and
product advertising can be formulated as XMC problems, where the objective is
to predict for a user a small subset of items from a catalog of several million
products. For such applications, a common approach is to organize these labels
into a tree, enabling training and inference times that are logarithmic in the
number of labels. While training a model once a label tree is available is well
studied, designing the structure of the tree is a difficult task that is not
yet well understood, and can dramatically impact both model latency and
statistical performance. Existing approaches to tree construction fall at an
extreme point, either optimizing exclusively for statistical performance, or
for latency. We propose an efficient information theory inspired algorithm to
construct intermediary operating points that trade off between the benefits of
both. Our algorithm enables interpolation between these objectives, which was
not previously possible. We corroborate our theoretical analysis with numerical
results, showing that on the Wiki-500K benchmark dataset our method can reduce
a proxy for expected latency by up to 28% while maintaining the same accuracy
as Parabel. On several datasets derived from e-commerce customer logs, our
modified label tree is able to improve this expected latency metric by up to
20% while maintaining the same accuracy. Finally, we discuss challenges in
realizing these latency improvements in deployed models.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Online Detection of Vibration Anomalies Using Balanced Spiking Neural Networks. (arXiv:2106.00687v1 [cs.NE])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Dennler_N/0/1/0/all/0/1">Nik Dennler</a>, <a href="http://arxiv.org/find/cs/1/au:+Haessig_G/0/1/0/all/0/1">Germain Haessig</a>, <a href="http://arxiv.org/find/cs/1/au:+Cartiglia_M/0/1/0/all/0/1">Matteo Cartiglia</a>, <a href="http://arxiv.org/find/cs/1/au:+Indiveri_G/0/1/0/all/0/1">Giacomo Indiveri</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00687">
                                    <div class="article-summary-box-inner">
                                        <span>Vibration patterns yield valuable information about the health state of a
running machine, which is commonly exploited in predictive maintenance tasks
for large industrial systems. However, the overhead, in terms of size,
complexity and power budget, required by classical methods to exploit this
information is often prohibitive for smaller-scale applications such as
autonomous cars, drones or robotics. Here we propose a neuromorphic approach to
perform vibration analysis using spiking neural networks that can be applied to
a wide range of scenarios. We present a spike-based end-to-end pipeline able to
detect system anomalies from vibration data, using building blocks that are
compatible with analog-digital neuromorphic circuits. This pipeline operates in
an online unsupervised fashion, and relies on a cochlea model, on feedback
adaptation and on a balanced spiking neural network. We show that the proposed
method achieves state-of-the-art performance or better against two publicly
available data sets. Further, we demonstrate a working proof-of-concept
implemented on an asynchronous neuromorphic processor device. This work
represents a significant step towards the design and implementation of
autonomous low-power edge-computing devices for online vibration monitoring.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Low Complexity Recruitment for Collaborative Mobile Crowdsourcing Using Graph Neural Networks. (arXiv:2106.00717v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Hamrouni_A/0/1/0/all/0/1">Aymen Hamrouni</a>, <a href="http://arxiv.org/find/cs/1/au:+Ghazzai_H/0/1/0/all/0/1">Hakim Ghazzai</a>, <a href="http://arxiv.org/find/cs/1/au:+Alelyani_T/0/1/0/all/0/1">Turki Alelyani</a>, <a href="http://arxiv.org/find/cs/1/au:+Massoud_Y/0/1/0/all/0/1">Yehia Massoud</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00717">
                                    <div class="article-summary-box-inner">
                                        <span>Collaborative Mobile crowdsourcing (CMCS) allows entities, e.g., local
authorities or individuals, to hire a team of workers from the crowd of
connected people, to execute complex tasks. In this paper, we investigate two
different CMCS recruitment strategies allowing task requesters to form teams of
socially connected and skilled workers: i) a platform-based strategy where the
platform exploits its own knowledge about the workers to form a team and ii) a
leader-based strategy where the platform designates a group leader that
recruits its own suitable team given its own knowledge about its Social Network
(SN) neighbors. We first formulate the recruitment as an Integer Linear Program
(ILP) that optimally forms teams according to four fuzzy-logic-based criteria:
level of expertise, social relationship strength, recruitment cost, and
recruiter&#x27;s confidence level. To cope with NP-hardness, we design a novel
low-complexity CMCS recruitment approach relying on Graph Neural Networks
(GNNs), specifically graph embedding and clustering techniques, to shrink the
workers&#x27; search space and afterwards, exploiting a meta-heuristic genetic
algorithm to select appropriate workers. Simulation results applied on a
real-world dataset illustrate the performance of both proposed CMCS recruitment
approaches. It is shown that our proposed low-complexity GNN-based recruitment
algorithm achieves close performances to those of the baseline ILP with
significant computational time saving and ability to operate on large-scale
mobile crowdsourcing platforms. It is also shown that compared to the
leader-based strategy, the platform-based strategy recruits a more skilled team
but with lower SN relationships and higher cost.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Collaborative Nonstationary Multivariate Gaussian Process Model. (arXiv:2106.00719v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Meng_R/0/1/0/all/0/1">Rui Meng</a>, <a href="http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1">Herbie Lee</a>, <a href="http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1">Kristofer Bouchard</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00719">
                                    <div class="article-summary-box-inner">
                                        <span>Currently, multi-output Gaussian process regression models either do not
model nonstationarity or are associated with severe computational burdens and
storage demands. Nonstationary multi-variate Gaussian process models (NMGP) use
a nonstationary covariance function with an input-dependent linear model of
coregionalisation to jointly model input-dependent correlation, scale, and
smoothness of outputs. Variational sparse approximation relies on inducing
points to enable scalable computations. Here, we take the best of both worlds:
considering an inducing variable framework on the underlying latent functions
in NMGP, we propose a novel model called the collaborative nonstationary
Gaussian process model(CNMGP). For CNMGP, we derive computationally tractable
variational bounds amenable to doubly stochastic variational inference.
Together, this allows us to model data in which outputs do not share a common
input set, with a computational complexity that is independent of the size of
the inputs and outputs. We illustrate the performance of our method on
synthetic data and three real datasets and show that our model generally
pro-vides better predictive performance than the state-of-the-art, and also
provides estimates of time-varying correlations that differ across outputs.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">An Entropy Regularization Free Mechanism for Policy-based Reinforcement Learning. (arXiv:2106.00707v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1">Changnan Xiao</a>, <a href="http://arxiv.org/find/cs/1/au:+Shi_H/0/1/0/all/0/1">Haosen Shi</a>, <a href="http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1">Jiajun Fan</a>, <a href="http://arxiv.org/find/cs/1/au:+Deng_S/0/1/0/all/0/1">Shihong Deng</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00707">
                                    <div class="article-summary-box-inner">
                                        <span>Policy-based reinforcement learning methods suffer from the policy collapse
problem. We find valued-based reinforcement learning methods with
{\epsilon}-greedy mechanism are capable of enjoying three characteristics,
Closed-form Diversity, Objective-invariant Exploration and Adaptive Trade-off,
which help value-based methods avoid the policy collapse problem. However,
there does not exist a parallel mechanism for policy-based methods that
achieves all three characteristics. In this paper, we propose an entropy
regularization free mechanism that is designed for policy-based methods, which
achieves Closed-form Diversity, Objective-invariant Exploration and Adaptive
Trade-off. Our experiments show that our mechanism is super sample-efficient
for policy-based methods and boosts a policy-based baseline to a new
State-Of-The-Art on Arcade Learning Environment.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Symmetry-via-Duality: Invariant Neural Network Densities from Parameter-Space Correlators. (arXiv:2106.00694v1 [cs.LG])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Maiti_A/0/1/0/all/0/1">Anindita Maiti</a>, <a href="http://arxiv.org/find/cs/1/au:+Stoner_K/0/1/0/all/0/1">Keegan Stoner</a>, <a href="http://arxiv.org/find/cs/1/au:+Halverson_J/0/1/0/all/0/1">James Halverson</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00694">
                                    <div class="article-summary-box-inner">
                                        <span>Parameter-space and function-space provide two different duality frames in
which to study neural networks. We demonstrate that symmetries of network
densities may be determined via dual computations of network correlation
functions, even when the density is unknown and the network is not equivariant.
Symmetry-via-duality relies on invariance properties of the correlation
functions, which stem from the choice of network parameter distributions. Input
and output symmetries of neural network densities are determined, which recover
known Gaussian process results in the infinite width limit. The mechanism may
also be utilized to determine symmetries during training, when parameters are
correlated, as well as symmetries of the Neural Tangent Kernel. We demonstrate
that the amount of symmetry in the initialization density affects the accuracy
of networks trained on Fashion-MNIST, and that symmetry breaking helps only
when it is in the direction of ground truth.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
            <li class="source">
                <section>
                    <h3 class="source-name"><a class="source-name__link" href="http://export.arxiv.org/rss/cs.MM"">cs.MM updates on arXiv.org</a></h3>
                    <section class="articles-per-source">
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Sound-to-Imagination: Unsupervised Crossmodal Translation Using Deep Dense Network Architecture. (arXiv:2106.01266v1 [cs.SD])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Fanzeres_L/0/1/0/all/0/1">Leonardo A. Fanzeres</a>, <a href="http://arxiv.org/find/cs/1/au:+Nadeu_C/0/1/0/all/0/1">Climent Nadeu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01266">
                                    <div class="article-summary-box-inner">
                                        <span>The motivation of our research is to develop a sound-to-image (S2I)
translation system for enabling a human receiver to visually infer the
occurrence of sound related events. We expect the computer to &#x27;imagine&#x27; the
scene from the captured sound, generating original images that picture the
sound emitting source. Previous studies on similar topics opted for simplified
approaches using data with low content diversity and/or strong supervision.
Differently, we propose to perform unsupervised S2I translation using thousands
of distinct and unknown scenes, with slightly pre-cleaned data, just enough to
guarantee aural-visual semantic coherence. To that end, we employ conditional
generative adversarial networks (GANs) with a deep densely connected generator.
Besides, we implemented a moving-average adversarial loss to address GANs
training instability. Though the specified S2I translation problem is quite
challenging, we were able to generalize the translator model enough to obtain
more than 14%, in average, of interpretable and semantically coherent images
translated from unknown sounds. Additionally, we present a solution using
informativity classifiers to perform quantitative evaluation of S2I
translation.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Refining the bounding volumes for lossless compression of voxelized point clouds geometry. (arXiv:2106.00828v1 [cs.CV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Kaya_E/0/1/0/all/0/1">Emre Can Kaya</a>, <a href="http://arxiv.org/find/cs/1/au:+Schwarz_S/0/1/0/all/0/1">Sebastian Schwarz</a>, <a href="http://arxiv.org/find/cs/1/au:+Tabus_I/0/1/0/all/0/1">Ioan Tabus</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.00828">
                                    <div class="article-summary-box-inner">
                                        <span>This paper describes a novel lossless compression method for point cloud
geometry, building on a recent lossy compression method that aimed at
reconstructing only the bounding volume of a point cloud. The proposed scheme
starts by partially reconstructing the geometry from the two depthmaps
associated to a single projection direction. The partial reconstruction
obtained from the depthmaps is completed to a full reconstruction of the point
cloud by sweeping section by section along one direction and encoding the
points which were not contained in the two depthmaps. The main ingredient is a
list-based encoding of the inner points (situated inside the feasible regions)
by a novel arithmetic three dimensional context coding procedure that
efficiently utilizes rotational invariances present in the input data.
State-of-the-art bits-per-voxel results are obtained on benchmark datasets.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Human-centric Spatio-Temporal Video Grounding With Visual Transformers. (arXiv:2011.05049v2 [cs.CV] UPDATED)</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1">Zongheng Tang</a>, <a href="http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1">Yue Liao</a>, <a href="http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1">Si Liu</a>, <a href="http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1">Guanbin Li</a>, <a href="http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1">Xiaojie Jin</a>, <a href="http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1">Hongxu Jiang</a>, <a href="http://arxiv.org/find/cs/1/au:+Yu_Q/0/1/0/all/0/1">Qian Yu</a>, <a href="http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1">Dong Xu</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2011.05049">
                                    <div class="article-summary-box-inner">
                                        <span>In this work, we introduce a novel task - Humancentric Spatio-Temporal Video
Grounding (HC-STVG). Unlike the existing referring expression tasks in images
or videos, by focusing on humans, HC-STVG aims to localize a spatiotemporal
tube of the target person from an untrimmed video based on a given textural
description. This task is useful, especially for healthcare and
security-related applications, where the surveillance videos can be extremely
long but only a specific person during a specific period of time is concerned.
HC-STVG is a video grounding task that requires both spatial (where) and
temporal (when) localization. Unfortunately, the existing grounding methods
cannot handle this task well. We tackle this task by proposing an effective
baseline method named Spatio-Temporal Grounding with Visual Transformers
(STGVT), which utilizes Visual Transformers to extract cross-modal
representations for video-sentence matching and temporal localization. To
facilitate this task, we also contribute an HC-STVG dataset consisting of 5,660
video-sentence pairs on complex multi-person scenes. Specifically, each video
lasts for 20 seconds, pairing with a natural query sentence with an average of
17.25 words. Extensive experiments are conducted on this dataset, demonstrating
the newly-proposed method outperforms the existing baseline methods.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                        <article>
                            <details class="article-expander">
                                <summary class="article-expander__title">Deep Learning based Full-reference and No-reference Quality Assessment Models for Compressed UGC Videos. (arXiv:2106.01111v1 [eess.IV])</summary>
                                <div class="article-authors">
                                    <a href="http://arxiv.org/find/eess/1/au:+Sun_W/0/1/0/all/0/1">Wei Sun</a>, <a href="http://arxiv.org/find/eess/1/au:+Wang_T/0/1/0/all/0/1">Tao Wang</a>, <a href="http://arxiv.org/find/eess/1/au:+Min_X/0/1/0/all/0/1">Xiongkuo Min</a>, <a href="http://arxiv.org/find/eess/1/au:+Yi_F/0/1/0/all/0/1">Fuwang Yi</a>, <a href="http://arxiv.org/find/eess/1/au:+Zhai_G/0/1/0/all/0/1">Guangtao Zhai</a>
                                </div>
                                <a class="article-summary-link article-summary-box-outer" href="http://arxiv.org/abs/2106.01111">
                                    <div class="article-summary-box-inner">
                                        <span>In this paper, we propose a deep learning based video quality assessment
(VQA) framework to evaluate the quality of the compressed user&#x27;s generated
content (UGC) videos. The proposed VQA framework consists of three modules, the
feature extraction module, the quality regression module, and the quality
pooling module. For the feature extraction module, we fuse the features from
intermediate layers of the convolutional neural network (CNN) network into
final quality-aware feature representation, which enables the model to make
full use of visual information from low-level to high-level. Specifically, the
structure and texture similarities of feature maps extracted from all
intermediate layers are calculated as the feature representation for the full
reference (FR) VQA model, and the global mean and standard deviation of the
final feature maps fused by intermediate feature maps are calculated as the
feature representation for the no reference (NR) VQA model. For the quality
regression module, we use the fully connected (FC) layer to regress the
quality-aware features into frame-level scores. Finally, a
subjectively-inspired temporal pooling strategy is adopted to pool frame-level
scores into the video-level score. The proposed model achieves the best
performance among the state-of-the-art FR and NR VQA models on the Compressed
UGC VQA database and also achieves pretty good performance on the in-the-wild
UGC VQA databases.</span>
                                    </div>
                                </a>
                            </details>
                        </article>
                    </section>
            </li>
            <br>
        </ul>
    </section>

    <footer>
        <time id="build-timestamp" datetime="2021-06-08T22:44:25.110Z">2021-06-08T22:44:25.110Z</time>
    </footer>
    <script src="https://code.jquery.com/jquery-3.6.0.slim.min.js" integrity="sha256-u7e5khyithlIdTpu22PHhENmPcRdFiHRjhAuHcs05RI=" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/handlebars@latest/dist/handlebars.js"></script>
    <script src="highlightRegex.js"></script>
    <script src="index.js"></script>
    <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=386&t=tt&d=sDvlbgmeTw_E_GoVDGdggVOFT21w54hFtP9VETatnEM&cmo=ff4242&cmn=3dd13d"></script>
    <!-- %before-body-end.html% -->
</body>

</html>